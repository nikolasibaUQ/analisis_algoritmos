@article{doi:10.1177/09544062241277310,
author = {Marwa Allouch and Hana Mellouli and Hanen Mallek and Mondher Wali and Fakhreddine Dammak},
title = {Behavior of sandwich structures with 3D-printed auxetic and non-auxetic cores under low velocity impact: Experimental and computational analysis},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {0},
number = {0},
pages = {09544062241277310},
year = {2024a},
doi = {10.1177/09544062241277310},
URL = {https://doi-org.crai.referencistas.com/10.1177/09544062241277310},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09544062241277310},
abstract = {In recent years, impact-resistant structures are highly sought after in various fields such automotive and aerospace applications as they proved notable performances, garnering significant success. The aim of this study is to assess the behavior of the 3D-printable honeycombs subjected to low velocity impact, for providing insights into absorbed energy for different core designs: hexagonal, auxetic, and rectangular, considering an equal number of cells across all designs. This work reports the computational and experimental studies conducted for sandwich structures under different impact loading. The experimental impact tests are carried out using a drop weight impact-testing machine. The examined specimen comprises two face-sheets and architected cell core fabricated through the Fused Filament Fabrication (FFF) process made of polylactic acid (PLA). Variations in the geometric design of the cells result in the formation of cores with auxetic and non-auxetic topologies. Uniaxial tensile tests are performed to identify the mechanical properties of the involved biopolymer. The second attempt consists on comparing three architectural core structures under impact test using experimental and computational methods. Our findings highlight the specific influence of core topology on energy absorption in 3D-printed sandwich structures. Results indicate that while all three configurations (hexagonal, re-entrant, and rectangular) demonstrate comparable energy absorption values, the specific mechanisms and efficiencies vary, with re-entrant cores exhibiting distinct behaviors under impact.}
}

@article{doi:10.1243/09544119JEIM670,
author = {G Chen and B Schmutz and M Wullschleger and M J Pearcy and M A Schuetz},
title = {Computational investigations of mechanical failures of internal plate fixation},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {224},
number = {1},
pages = {119–126},
year = {2010b},
doi = {10.1243/09544119JEIM670},
note = {PMID:20225463},
URL = {https://doi-org.crai.referencistas.com/10.1243/09544119JEIM670},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09544119JEIM670},
abstract = {Abstract This paper investigated the biomechanics of two clinical cases of bone fracture treatments. Both fractures were treated with the same locking compression plate but with different numbers of screws as well as different plate materials. The fracture treated with 12 screws (rigid fixation) failed at 7 weeks with the plate breaking; the fracture with six screws (flexible fixation) endured the entire healing process. It was hypothesized that the plate failure in the unsuccessful case was due to the material fatigue induced by stress concentration in the plate. As the two clinical cases had different fracture locations and different plate materials, finite element simulations were undertaken for each fractured bone fixed by both a rigid and a flexible method. This enabled comparisons to be made between the rigid and flexible fixation methods. The fatigue life was assessed for each fixation method. The results showed that the stress in the rigid fixation methods could be significantly higher than that in flexible fixation methods. The fatigue analyses showed that, with the stress level in flexible fixation (i.e. with fewer screws), the plate was able to endure 2000 days, and that the plate in rigid fixation could fail by fatigue fracture in 20 days. The paper concludes that the rigid fixation method resulted in serious stress concentrations in the plate, which induced fatigue failure. The flexible fixation gave sufficient stability and was better for fracture healing.}
}

@article{doi:10.1177/0741088316650178,
author = {Scott A. Crossley and Kasia Muldner and Danielle S. McNamara},
title = {Idea Generation in Student Writing: Computational Assessments and Links to Successful Writing},
journal = {Written Communication},
volume = {33},
number = {3},
pages = {328–354},
year = {2016c},
doi = {10.1177/0741088316650178},
URL = {https://doi-org.crai.referencistas.com/10.1177/0741088316650178},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0741088316650178},
abstract = {Idea generation is an important component of most major theories of writing. However, few studies have linked idea generation in writing samples to assessments of writing quality or examined links between linguistic features in a text and idea generation. This study uses human ratings of idea generation, such as idea fluency, idea flexibility, idea originality, and idea elaboration, to analyze the extent to which idea generation relates to human judgments of essay quality in a corpus of college student essays. In conjunction with this analysis, linguistic features extracted from the essays are used to develop a predictive model of idea generation to further understand relations between the language features in an essay and the idea generation scores assigned to that essay. The results indicate that essays rated as containing a greater number of ideas that were flexible, original, and elaborated were judged to be of higher quality. Two of these features (elaboration and originality) were significant predictors of essay quality scores in a regression analysis that explained 33% of the variance in human scores. The results also indicate that idea generation is strongly linked to language features in essays. Specifically, the use of unique multiword units, more difficult words, semantic but not lexical similarities between paragraphs, and fewer word repetitions explained 80% of the variance in human scores of idea generation. These results have implications for writing theories and writing practice.}
}

@article{doi:10.1177/1350507620909130,
author = {Mark Dawson},
title = {Book Review: The Age of Disruption: Technology and Madness in Computational Capitalism},
journal = {Management Learning},
volume = {52},
number = {5},
pages = {652–657},
year = {2021d},
doi = {10.1177/1350507620909130},
URL = {https://doi-org.crai.referencistas.com/10.1177/1350507620909130},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1350507620909130}
}

@article{doi:10.1177/0957650918783923,
author = {Yongbo Du and Chang’an Wang and Pengqian Wang and Yi Meng and Zhichao Wang and Wei Yao and Defu Che},
title = {Computational fluid dynamics investigation on the effect of co-firing semi-coke and bituminous coal in a 300 MW tangentially fired boiler},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {233},
number = {2},
pages = {221–231},
year = {2019e},
doi = {10.1177/0957650918783923},
URL = {https://doi-org.crai.referencistas.com/10.1177/0957650918783923},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0957650918783923},
abstract = {In this paper, the effect of co-firing semi-coke in a 300 MW tangentially fired boiler was numerically investigated. The results indicate that the incomplete combustion heat loss and NOx emission both increase with semi-coke co-fired ratio. Semi-coke may be injected into the furnace at a different height, which can lead to different thermal efficiency and NOx emission. It is suggested that semi-coke should not be fed from the top or bottom layer burners, since this could give rise to high carbon content respectively in fly ash and bottom slag. In addition, injecting semi-coke from the top burners could significantly increase the NOx emission. Under 1/2 co-firing ratio, the optimal fuel allocation is that feeding semi-coke from the B, D, and E layer burners. The growth in semi-coke particle size could increase the unburned carbon loss and NOx emission. It is highly recommended to reduce the unburned carbon loss under semi-coke co-fired condition by increasing the stoichiometric ratio of primary air for semi-coke. As it is increased from 0.25 to 0.3, the combustion efficiency of the co-fired condition is 99.47%, the same as when only firing bituminous coal, and the NOx emission is about 30% higher.}
}

@article{doi:10.1068/p2808rvw,
author = {E Forde and Adriane E Seiffert},
title = {Reviews: Handbook of Clinical and Experimental Neuropsychology, High-Level Motion Processing: Computational, Neurobiological, and Psychophysical Perspectives},
journal = {Perception},
volume = {28},
number = {8},
pages = {1051–1054},
year = {1999f},
doi = {10.1068/p2808rvw},
URL = {https://doi-org.crai.referencistas.com/10.1068/p2808rvw},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p2808rvw}
}

@article{doi:10.1177/2043820618808668,
author = {Jennifer Gabrys},
title = {Sensors experiencing environments, environments becoming computational},
journal = {Dialogues in Human Geography},
volume = {9},
number = {1},
pages = {121–124},
year = {2019g},
doi = {10.1177/2043820618808668},
URL = {https://doi-org.crai.referencistas.com/10.1177/2043820618808668},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2043820618808668}
}

@article{doi:10.2190/J570-9MKA-7BHN-ULN9,
author = {John S. Harris},
title = {Global Thinking, or the Utility of Trivia},
journal = {Journal of Technical Writing and Communication},
volume = {31},
number = {3},
pages = {223–239},
year = {2001h},
doi = {10.2190/J570-9MKA-7BHN-ULN9},
URL = {https://doi-org.crai.referencistas.com/10.2190/J570-9MKA-7BHN-ULN9},
eprint = {https://doi-org.crai.referencistas.com/10.2190/J570-9MKA-7BHN-ULN9},
abstract = {The constant emphasis on specialization produces university graduates who do not or cannot look at problems broadly. As a result, engineers, scientists and executives—indeed graduates in all fields—including the supposedly broad-based humanities—often cannot solve problems that require knowledge outside of their specializations. Or their narrowness causes them to commit embarrassing blunders that could be avoided if they took a broader view. The case of the British Westland Lysander P12 Ground Strafer aircraft illustrates the problem of narrow thinking. Very little direct information is available on this ingenious but obscure prototype airplane, but by examining many peripheral matters we can determine not only why the P12 was built but also how it was built. Further, we can also determine why it failed. Had the initial designers approached the problem in a broad way, and using information that was then available, they would have seen in advance that the project would fail. The case is instructive as an industrial problem, but it also demonstrates the value of global thinking methodology.}
}

@article{doi:10.1177/001316447303300422,
author = {Dennis Hunt and Bikkar S. Randhawa},
title = {Relationship Between and Among Cognitive Variables and Achievement in Computational Science},
journal = {Educational and Psychological Measurement},
volume = {33},
number = {4},
pages = {921–928},
year = {1973i},
doi = {10.1177/001316447303300422},
URL = {https://doi-org.crai.referencistas.com/10.1177/001316447303300422},
eprint = {https://doi-org.crai.referencistas.com/10.1177/001316447303300422}
}

@article{doi:10.1177/003754976801100208,
author = {Stephen J. Kahne},
title = {Computational questions in optimal control, quasilinearization and hybrid computers},
journal = {SIMULATION},
volume = {11},
number = {2},
pages = {81–86},
year = {1968j},
doi = {10.1177/003754976801100208},
URL = {https://doi-org.crai.referencistas.com/10.1177/003754976801100208},
eprint = {https://doi-org.crai.referencistas.com/10.1177/003754976801100208}
}

@article{doi:10.1177/1468087420910348,
author = {Jann Koch and Christian Schürch and Yuri M Wright and Konstantinos Boulouchos},
title = {Reactive computational fluid dynamics modelling methane–hydrogen admixtures in internal combustion engines part II: Large eddy simulation},
journal = {International Journal of Engine Research},
volume = {22},
number = {6},
pages = {2054–2068},
year = {2021k},
doi = {10.1177/1468087420910348},
URL = {https://doi-org.crai.referencistas.com/10.1177/1468087420910348},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1468087420910348},
abstract = {Fuels based on admixtures of methane/natural gas and hydrogen are a promising way to reduce CO2 emissions of spark ignition engines and increase their efficiency. A lot of work was conducted experimentally, whereas only limited numerical work is available in the context of three-dimensional modelling of the full engine cycle. This work addresses this fact by proposing a reactive computational fluid dynamics modelling framework to consider the effects of hydrogen addition on the combustion process. Part I of this two-part study focuses on the modelling and crucial considerations in order to predict the mean cycle based on the G-equation combustion model using the Reynolds-averaged Navier–Stokes equations. There, the effect of increased burning speed was globally captured by increasing the flame speed coefficient A, appearing in the considered flame speed closure. The proposed simplified modelling of the early flame stage proved to be robust for the conducted hydrogen variation from 0 to 50 vol% H2 for stoichiometric and lean operation. Scope of this work, Part II, are cyclic fluctuations and the hydrogen influence thereon using large eddy simulation and the proposed modelling framework. The model is probed towards its capabilities to predict the fluctuation of the combustion process for 0 and 50 vol% H2 and correlations influencing the observed peak pressure of the individual cycle are presented. It is shown that the considered approach is capable to reproduce the cyclic fluctuations of the combustion process under the influence of hydrogen addition as well as lean operation. The importance of the early flame phase with respect to arising fluctuations is highlighted as well as the contribution of the resolved scales in terms of the flame front wrinkling.}
}

@article{doi:10.1177/1094428113484970,
author = {Bertolt Meyer and Andreas Glenz},
title = {Team Faultline Measures: A Computational Comparison and a New Approach to Multiple Subgroups},
journal = {Organizational Research Methods},
volume = {16},
number = {3},
pages = {393–424},
year = {2013l},
doi = {10.1177/1094428113484970},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094428113484970},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094428113484970},
abstract = {Team faultlines—hypothetical dividing lines based on member attributes that split a team into relatively homogeneous subgroups—influence team processes across contexts, as recent meta-analytic findings show. We review the available faultline measures with regard to their properties and identify several limitations, including dealing with more than two subgroups. We thus propose a new cluster-based approach, average silhouette width (ASW), that identifies the number of subgroups and subgroup membership. We then compare the measures with 1,400 simulated teams with varying properties and investigate their factor structure and their behavior under missing values. We also investigate the predictive validity of the measures with data from real work teams. Results show that different measures respond to different team features in different ways but that most of them load on two correlated factors. Taken together, the ASW measure had the most favorable attributes and was the only measure that accurately determined subgroup membership in the presence of more than two subgroups. We discuss limitations and further research opportunities pertaining to faultline measures and provide software for calculating all investigated measures at http://www.group-faultlines.org.}
}

@article{doi:10.1177/155005940904000308,
author = {Tiia Saunamäki and Mervi Jehkonen and Eero Huupponen and Olli Polo and Sari-Leena Himanen},
title = {Visual Dysfunction and Computational Sleep Depth Changes in Obstructive Sleep Apnea Syndrome},
journal = {Clinical EEG and Neuroscience},
volume = {40},
number = {3},
pages = {162–167},
year = {2009m},
doi = {10.1177/155005940904000308},
note = {PMID:19715178},
URL = {https://doi-org.crai.referencistas.com/10.1177/155005940904000308},
eprint = {https://doi-org.crai.referencistas.com/10.1177/155005940904000308},
abstract = {The aims of this study are to clarify whether patients with obstructive sleep apnea syndrome (OSAS) have a decline in verbally or visually-based cognitive abilities and whether the possible decline is related to particular sleep depth changes. In addition, the effect of continuous positive airway pressure (CPAP) on the possible changes is investigated. Fifteen OSAS patients and 15 healthy controls joined two full-night polysomnographies, including a computational measure of deep sleep percentage (DS%) bilaterally from the frontal, central and occipital channels, and a neuropsychological assessment. After a 6-month CPAP the patients underwent one more full-night polysomnography with computational DS% analysis and a neuropsychological assessment. At the baseline, the OSAS patients had poorer performance in the Picture Completion, in the Digit Symbol and in copying the Rey-Osterrieth Complex Figure Test (ROCFT) compared to the controls. The patients also showed reduced DS% in all 6 electrographic (EEG) channels compared to controls. The patients had an inter-hemispheric difference showing less deep sleep in the right hemisphere than in the left hemisphere both frontopolarly and centrally, while the controls showed this inter-hemispheric difference only frontopolarly. After CPAP the patients still had poorer performance in the Picture Completion and in the ROCFT. The patients continued to show reduced DS% in all 3 channels of the right hemisphere and occipitally in the left hemisphere, also the inter-hemispheric difference frontopolarly and centrally remained. OSAS patients have mild visually based cognitive dysfunction and reduced amount of deep sleep in the right hemisphere even after CPAP.}
}

@article{doi:10.1366/000370278774331521,
author = {Alexander Scheeline and R. J. Klueppel and David M. Coleman and John P. Walters},
title = {Computational Procedures for Characterization of High Voltage Spark Sources},
journal = {Applied Spectroscopy},
volume = {32},
number = {2},
pages = {224–238},
year = {1978n},
doi = {10.1366/000370278774331521},
URL = {https://doi-org.crai.referencistas.com/10.1366/000370278774331521},
eprint = {https://doi-org.crai.referencistas.com/10.1366/000370278774331521},
abstract = {Equations and a calculation procedure for modeling the operation of an electronic, adjustable-waveform and other types of high voltage spark sources are presented. The equations return time-dependent capacitor voltage and charging current and the calculation procedure returns complete break patterns. Comparisons between laboratory and computed results indicate the calculations predict experiment with accuracy in the 1 to 5% relative error range. This is sufficient to make the calculation procedure useful for characterization of research or production spark sources.}
}

@article{doi:10.1179/174328405X58850,
author = {S. Shanmugasundaram and J. J. Biernacki and R. Subramanian},
title = {Variation in boron doping by planar diffusion – a comparative study of computational hydrodynamics and experimental observations},
journal = {Materials Science and Technology},
volume = {21},
number = {9},
pages = {1103–1110},
year = {2005o},
doi = {10.1179/174328405X58850},
URL = {https://doi-org.crai.referencistas.com/10.1179/174328405X58850},
eprint = {https://doi-org.crai.referencistas.com/10.1179/174328405X58850},
abstract = {Resistivity maps for Si wafers processed using BN solid sources and hydrogen injection were compared to convective flow patterns predicted computationally. The convective flow patterns were found to mirror the resistivity maps, with low velocity flow domains being associated with high resistivity regions on the wafer and high velocity flow with low resistivity regions. Subtle changes in both the flow patterns and resistivity maps as a function of location within the furnace were consistently reflected in both computed flow domains and measured resistitivies. Finally, axially eccentric placement of the wafer–source stack was found to promote convection between wafer–source pairs by as much as a factor of five.}
}

@article{doi:10.1177/07356331231174454,
author = {Yoonhee Shin and Jaewon Jung and Joerg Zumbach and Eunseon Yi},
title = {The Effects of Worked-Out Example and Metacognitive Scaffolding on Problem-Solving Programming},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {6},
pages = {1312–1331},
year = {2023p},
doi = {10.1177/07356331231174454},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331231174454},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331231174454},
abstract = {This study explores the effects of worked-out examples and metacognitive scaffolding on novice learners’ knowledge performance, cognitive loads, and self-regulation skills in problem-solving programming. 126 undergraduate students in a computer programming fundamentals course were randomly assigned to one of four groups: 1) task performance with a traditional WOE (TW), 2) task performance with a faded WOE (FW), 3) task performance with traditional WOE and metacognitive scaffolding (TWM), and 4) task performance with a faded WOE and metacognitive scaffolding (FWM). Over the course of 3 weeks, participants in these four groups were asked to solve programming problems using Python with WOE and metacognitive scaffolding. The results demonstrate that the provision of metacognitive scaffolding with faded WOE (FWM) is the most effective for problem-solving programming and self-regulation skills. In addition, an interaction effect exists between the two treatments for the germane load in FWM. Therefore, results in this study provide empirical insights into ways to effectively apply WOE and metacognitive scaffolding to problem-solving processes for programming-based complex problem-solving, especially for novice learners.}
}

@article{doi:10.1177/1059712319839386,
author = {Diogo Fernando Trevisan and Lorraine Becerra and Priscila Benitez and Thomas S Higbee and João Paulo Gois},
title = {A review of the use of computational technology in applied behavior analysis},
journal = {Adaptive Behavior},
volume = {27},
number = {3},
pages = {183–196},
year = {2019q},
doi = {10.1177/1059712319839386},
URL = {https://doi-org.crai.referencistas.com/10.1177/1059712319839386},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1059712319839386},
abstract = {Applied behavior analysis (ABA) is a behavioral science that aims to teach specific and socially relevant behaviors to people with different repertoires. Technology can aid behavior analysis interventions supporting different educational agents (e.g. psychologists, parents, and teachers) as well as patients. In this article, we reviewed how researchers are using technology in ABA interventions with children with autism spectrum disorder (ASD). We present the results obtained from a systematic review of the literature. The purpose was to map the employment of the computational technology in ABA interventions, as well as to discuss the primary technologies used, their benefits, and their limitations. Based on our review, we noticed that technology-based interventions are in the early stages of development. We evidenced it by the methodological limitations in many of the studies we found, and the relatively simplistic nature of many of the technological applications (e.g. inability to customize the software to meet individual learner needs). We also provide suggestions, based on these findings, for how researchers may advance the studies in this area to improve the lives of children with ASD and their families.}
}

@article{doi:10.2466/pms.1985.60.1.203,
author = {Lucia Vaina and Youcef Bennour},
title = {A Computational Approach to Visual Recognition of Arm Movements},
journal = {Perceptual and Motor Skills},
volume = {60},
number = {1},
pages = {203–228},
year = {1985r},
doi = {10.2466/pms.1985.60.1.203},
note = {PMID:3982933},
URL = {https://doi-org.crai.referencistas.com/10.2466/pms.1985.60.1.203},
eprint = {https://doi-org.crai.referencistas.com/10.2466/pms.1985.60.1.203},
abstract = {A representation for the visual recognition of skilled arm movements is proposed that lies within Mart and Vaina’s (1982) three-dimensional model representation for shape movements. Algorithms for segmenting arm movements into pieces are proposed. It is suggested that for a large class of arm movements recognition could be reliably achieved based only on the description of the hand shape and path in the body coordinates, without needing the detailed description of the variation of all the joint angles of the arm.}
}

@article{doi:10.1177/0954410017740922,
author = {Yanhui Wu and Guangyao An and Zhiyang Chen and Bo Wang},
title = {Computational analysis of vortices near casing in a transonic axial compressor rotor},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {233},
number = {2},
pages = {710–724},
year = {2019s},
doi = {10.1177/0954410017740922},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410017740922},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410017740922},
abstract = {Complicated flowfields near casing in a transonic axial flow compressor rotor have been numerically investigated in this paper. Two vortex identification methods, namely the Eigenvector Method and Lambda 2 Method, are introduced as important tools for the graphical representation of the concentrated vortices arising from tip leakage flow and blade boundary layer separation. The analysis of the numerical results reveals that multiple tip vortices whose development are dependent on the variation of shock wave configuration are observed at conditions around the peak efficiency point. However, with the decrease of the massflow rate, only the well-known tip leakage vortex and the second tip vortex are left in the tip region due to the disappearance of the second shock wave. Then when the massflow rate further decreases to the stall limit, an deceleration flow region emerges downstream of the shock wave due to an increasing interaction between the first shock wave and the well-known tip leakage vortex. The tip leakage vortex further experiences a bubble-type and then spiral-type breakdown at near stall flow conditions. In addition, the validity of the two vortex identification methods is also discussed in this paper. It is found that both methods are able to identify and accentuate the concentrated streamwise vortices near casing when a vortex is not disrupted. However, if the vortex breakdown occurs, only Eigenvector Method can describe the breakdown region in a deep view.}
}

@article{doi:10.1177/0036850419874231,
author = {Liang Zhang and JiaWei Zhou and Bo Zhang and Wei Gong},
title = {Semi-analytical and computational investigation of different fibrous structures affecting the performance of fibrous media},
journal = {Science Progress},
volume = {103},
number = {1},
pages = {0036850419874231},
year = {2020t},
doi = {10.1177/0036850419874231},
note = {PMID:31829857},
URL = {https://doi-org.crai.referencistas.com/10.1177/0036850419874231},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0036850419874231},
abstract = {Three arrangement types of fibrous media have been established including “Mesh” (layered distribution), “Para” (unidirectional distribution), and “Nurbs” (random distribution), with fiber diameters ranging from 5 to 7 µm and solid volume fractions ranging from 14.58% to 21.95%. To describe the filtration performance, particles trajectories, and the influence of structural parameters of fibrous media, the computation fluid dynamics is adopted. The filtration efficiency and the pressure drop of fibrous media are calculated in computation fluid dynamics and semi-analytical model. It is found that the arrangement types have significant effects on the filtration efficiency and show the limitation of the semi-analytical model. With the Stokes number larger than 1, the numerical results and semi-analytical model have great consistency in the filtration efficiency for the “Mesh” and “Para” types than “Nurbs” type. Meanwhile, the pressure drop between the numerical results and the semi-analytical model is always consistent.}
}

