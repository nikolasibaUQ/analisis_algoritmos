@article{doi:10.1177/0734282918809793,
author = {Roberto A. Abreu-Mendoza and Yaira Chamorro and Esmeralda Matute},
title = {Psychometric Properties of the WRAT Math Computation Subtest in Mexican Adolescents},
journal = {Journal of Psychoeducational Assessment},
volume = {37},
number = {8},
pages = {957–972},
year = {2019a},
doi = {10.1177/0734282918809793},
URL = {https://doi-org.crai.referencistas.com/10.1177/0734282918809793},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0734282918809793},
abstract = {The goal of this study was to provide normative scores and examine the psychometric properties of the Math Computation subtest of the Wide Range Achievement Test–IV (WRAT-IV) for Mexican adolescents after the completion of junior high school. We group-administered this subtest to 1,318 first-year Mexican high school students. We then obtained its overall internal reliability and examined its underlying factor structure. Finally, we determined its concurrent and criterion validity by evaluating a subsample of 106 students that included adolescents with mathematical difficulty, mathematical talent, and typical performance. Results showed that the subtest has a good internal reliability and appropriate psychometric characteristics, suggesting its appropriateness for the detection of adolescents with particular difficulty or ability in mathematics. The exploratory factor analysis identified three factors: arithmetic, fractions and basic algebra, and rational numbers. There were also sex differences in the number of correct responses, but the effect size was small.}
}

@article{doi:10.1177/1094342012440466,
author = {E Wes Bethel and Mark Howison},
title = {Multi-core and many-core shared-memory parallel raycasting volume rendering optimization and tuning},
journal = {The International Journal of High Performance Computing Applications},
volume = {26},
number = {4},
pages = {399–412},
year = {2012b},
doi = {10.1177/1094342012440466},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342012440466},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342012440466},
abstract = {Given the computing industry trend of increasing processing capacity by adding more cores to a chip, the focus of this work is tuning the performance of a staple visualization algorithm, raycasting volume rendering, for shared-memory parallelism on multi-core CPUs and many-core GPUs. Our approach is to vary tunable algorithmic settings, along with known algorithmic optimizations and two different memory layouts, and measure performance in terms of absolute runtime and L2 memory cache misses. Our results indicate there is a wide variation in runtime performance on all platforms, as much as 254% for the tunable parameters we test on multi-core CPUs and 265% on many-core GPUs, and the optimal configurations vary across platforms, often in a non-obvious way. For example, our results indicate the optimal configurations on the GPU occur at a crossover point between those that maintain good cache utilization and those that saturate computational throughput. This result is likely to be extremely difficult to predict with an empirical performance model for this particular algorithm because it has an unstructured memory access pattern that varies locally for individual rays and globally for the selected viewpoint. Our results also show that optimal parameters on modern architectures are markedly different from those in previous studies run on older architectures. In addition, given the dramatic performance variation across platforms for both optimal algorithm settings and performance results, there is a clear benefit for production visualization and analysis codes to adopt a strategy for performance optimization through auto-tuning. These benefits will likely become more pronounced in the future as the number of cores per chip and the cost of moving data through the memory hierarchy both increase.}
}

@article{doi:10.1068/p230399,
author = {Muriel Boucart and Sandrine Delord and Anne Giersch},
title = {The Computation of Contour Information in Complex Objects},
journal = {Perception},
volume = {23},
number = {4},
pages = {399–409},
year = {1994c},
doi = {10.1068/p230399},
note = {PMID:7991341},
URL = {https://doi-org.crai.referencistas.com/10.1068/p230399},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p230399},
abstract = {Perceptual organisation, and especially the computation of contour information, has been the object of considerable interest in the last few years. In the first part of the paper we review recent accounts on the mechanisms involved in the processing of contour. In the second part we report an experiment designed to examine (1) how physical parameters such as spatial proximity and collinearity of elements affect the integration of global contour in objects and (2) whether the activation of stored representations of objects facilitates the computation of contour. Incomplete forms varying in the spacing and the alignment of line segments on their contour were used as stimuli in a matching task. Subjects were asked to decide which of two laterally displayed figures matched a reference form presented previously. The matching target and the distractor were physically identical but differed in their orientation. In one condition the reference object was always an outline drawing of an object. In a second condition the reference object was either a complete object or a more or less identifiable incomplete form. Little variation in performance was found for forms having continuous and discontinuous contour up to a spacing of 5 pixels (10.8 min) between elements. Response times and errors increased abruptly beyond this limit. This effect occurred in the two conditions of reference stimulus, suggesting that the computation of contour information is more affected by physical constraints at early processes than by high-level processes involving activation of stored structural representations of objects.}
}

@article{doi:10.1111/j.1745-6916.2006.00007.x,
author = {Ap Dijksterhuis and Loran F. Nordgren},
title = {A Theory of Unconscious Thought},
journal = {Perspectives on Psychological Science},
volume = {1},
number = {2},
pages = {95–109},
year = {2006d},
doi = {10.1111/j.1745-6916.2006.00007.x},
note = {PMID:26151465},
URL = {https://doi-org.crai.referencistas.com/10.1111/j.1745-6916.2006.00007.x},
eprint = {https://doi-org.crai.referencistas.com/10.1111/j.1745-6916.2006.00007.x},
abstract = {We present a theory about human thought named the unconscious-thought theory (UTT). The theory is applicable to decision making, impression formation, attitude formation and change, problem solving, and creativity. It distinguishes between two modes of thought: unconscious and conscious. Unconscious thought and conscious thought have different characteristics, and these different characteristics make each mode preferable under different circumstances. For instance, contrary to popular belief, decisions about simple issues can be better tackled by conscious thought, whereas decisions about complex matters can be better approached with unconscious thought. The relations between the theory and decision strategies, and between the theory and intuition, are discussed. We end by discussing caveats and future directions.}
}

@article{doi:10.1177/0267658321993873,
author = {Shuo Feng},
title = {The computation and suspension of presuppositions by L1-Mandarin Chinese L2-English speakers},
journal = {Second Language Research},
volume = {38},
number = {4},
pages = {737–763},
year = {2022e},
doi = {10.1177/0267658321993873},
URL = {https://doi-org.crai.referencistas.com/10.1177/0267658321993873},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0267658321993873},
abstract = {The Interface Hypothesis proposes that second language (L2) learners, even at highly proficient levels, often fail to integrate information at the external interfaces where grammar interacts with other cognitive systems. While much early L2 work has focused on the syntax–discourse interface or scalar implicatures at the semantics–pragmatics interface, the present article adds to this line of research by exploring another understudied phenomenon at the semantics–pragmatics interface, namely, presuppositions. Furthermore, this study explores both inference computation and suspension via a covered-box picture-selection task. Specifically, this study investigates the interpretation of the presupposition trigger stop and stop under negation. The results from 38 native English speakers and 41 first language (L1) Mandarin Chinese learners of English indicated similar response patterns between native and L2 groups in computing presuppositions but not in suspending presuppositions. That is, L2 learners were less likely to suspend presuppositions than native speakers. This study contributes to a more precise understanding of L2 acquisition at the external interface level, as well as computation and suspension of pragmatic inferences.}
}

@article{doi:10.1068/b12979,
author = {Leila Floriani and Paola Magillo},
title = {Algorithms for Visibility Computation on Terrains: A Survey},
journal = {Environment and Planning B: Planning and Design},
volume = {30},
number = {5},
pages = {709–728},
year = {2003f},
doi = {10.1068/b12979},
URL = {https://doi-org.crai.referencistas.com/10.1068/b12979},
eprint = {https://doi-org.crai.referencistas.com/10.1068/b12979},
abstract = {Several environment applications require the computation of visibility information on a terrain. Examples are optimal placement of observation points, line-of-sight communication, and computation of hidden as well as scenic paths. Visibility computations on a terrain may involve either one or many viewpoints, and range from visibility queries (for example, testing whether a given query point is visible), to the computation of structures that encode the visible portions of the surface. In this paper, the authors consider a number of visibility problems on terrains and present an overview of algorithms to tackle such problems on triangulated irregular networks and regular square grids.}
}

@article{doi:10.1177/0954410012464602,
author = {Debin Fu and Yong Yu},
title = {Simulation of gas flow and additional thrust with missile launching from concentric canister launcher},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {227},
number = {12},
pages = {1977–1987},
year = {2013g},
doi = {10.1177/0954410012464602},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410012464602},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410012464602},
abstract = {A computational fluid dynamics method has been applied to simulate the exhaust gas flow and the additional thrust during a missile launching from concentric canister launcher. The unsteady, axisymmetric Reynolds-averaged Navier–Stokes equations with renormalization group turbulence model are numerically solved here. The dynamic mesh method is utilized to simulate the movement of the missile. Computational fluid dynamics results show that the additional thrust is an important thrust and fluctuates with the movement of the missile for launching from concentric canister launcher. The mechanism for producing and influencing the additional thrust is typically relevant to the choking states of exhaust gases at the inlet and outlet of the annular tube of concentric canister launcher, responding to the jet impinging on the bottom of the launcher, the approximate wall jet, and the friction effect in the tube.}
}

@article{doi:10.1177/1032373208095480,
author = {Delfina Gomes},
title = {The interplay of conceptions of accounting and schools of thought in accounting history},
journal = {Accounting History},
volume = {13},
number = {4},
pages = {479–509},
year = {2008h},
doi = {10.1177/1032373208095480},
URL = {https://doi-org.crai.referencistas.com/10.1177/1032373208095480},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1032373208095480},
abstract = {Paralleling the advent of different conceptions of accounting in the past two decades or so is the distinction between what are now known as the “traditional” and “new” schools of accounting history research. Viewing accounting as a social practice, as opposed to a mere technical practice, orientates the historical researcher firmly into the arena of the new accounting history, which recognizes the pervasive and enabling characteristics of accounting and gives rise to concerns about studying the implications of accounting change on organizational and social functioning. This literature study examines the interplay of conceptions of accounting with schools of thought in the historical accounting literature. It seeks to enhance an understanding of the underlying connections between the conceptions of accounting embraced by researchers of contemporary accounting and the schools of thought adopted by historical accounting researchers. As the state of play in accounting history research appears to have become a little predictable, certain challenges are identified for accounting historians of the future.}
}

@article{doi:10.1177/109434209200600403,
author = {S. Lennart Johnsson and Luis F. Ortiz},
title = {Local Basic Linear Algebra Subroutines (Lblas) for Distributed Memory Architectures and Languages With Array Syntax},
journal = {The International Journal of Supercomputing Applications},
volume = {6},
number = {4},
pages = {322–350},
year = {1992i},
doi = {10.1177/109434209200600403},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434209200600403},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434209200600403},
abstract = {We describe a subset of the level-1, level-2, and level-3 BLAS implemented for each node of the Connection Machine system CM-200. The routines, collectively called LBLAS, have interfaces consistent with lan guages with an array syntax such as Fortran 90. One novel feature, important for distributed memory archi tectures, is the capability of performing computations on multiple instances of objects in a single call. The number of instances and their allocation across mem ory units, and the strides for the different axes within the local memories, are derived from an array descrip tor that contains type, shape, and data distribution in formation. Another novel feature of the LBLAS is a se lection of loop order for rank-1 updates and matrix- matrix multiplication based on array shapes, strides, and DRAM page faults. The peak efficiencies for the routines are in excess of 75%. Matrix-vector multiplica tion achieves a peak efficiency of 92%. The optimiza tion of loop ordering has a success rate exceeding 99.8% for matrices for which the sum of the lengths of the axes is at most 60. The success rate is even higher for all possible matrix shapes. The performance loss when a nonoptimal choice is made is less than ∼15% of peak and typically less than 1% of peak. We also show that the performance gain for high-rank updates may be as much as a factor of 6 over rank-1 updates.}
}

@article{doi:10.1177/002072097801500321,
author = {A. G. J. Macfarlane},
title = {Book Review: Matrix Computation for Engineers and Scientists},
journal = {International Journal of Electrical Engineering & Education},
volume = {15},
number = {3},
pages = {284–285},
year = {1978j},
doi = {10.1177/002072097801500321},
URL = {https://doi-org.crai.referencistas.com/10.1177/002072097801500321},
eprint = {https://doi-org.crai.referencistas.com/10.1177/002072097801500321}
}

@article{doi:10.1155/2014/815378,
author = {Abdul Waheed Malik and Benny Thörnberg and Muhammad Imran and Najeem Lawal},
title = {Hardware Architecture for Real-Time Computation of Image Component Feature Descriptors on a FPGA},
journal = {International Journal of Distributed Sensor Networks},
volume = {10},
number = {1},
pages = {815378},
year = {2014k},
doi = {10.1155/2014/815378},
URL = {https://doi-org.crai.referencistas.com/10.1155/2014/815378},
eprint = {https://doi-org.crai.referencistas.com/10.1155/2014/815378},
abstract = {This paper describes a hardware architecture for real-time image component labeling and the computation of image component feature descriptors. These descriptors are object related properties used to describe each image component. Embedded machine vision systems demand a robust performance and power efficiency as well as minimum area utilization, depending on the deployed application. In the proposed architecture, the hardware modules for component labeling and feature calculation run in parallel. A CMOS image sensor (MT9V032), operating at a maximum clock frequency of 27 MHz, was used to capture the images. The architecture was synthesized and implemented on a Xilinx Spartan-6 FPGA. The developed architecture is capable of processing 390 video frames per second of size 640 × 480 pixels. Dynamic power consumption is 13 mW at 86 frames per second.}
}

@article{doi:10.1068/p120203,
author = {Michael J Morgan},
title = {Mental Rotation: A Computationally Plausible Account of Transformation through Intermediate Steps},
journal = {Perception},
volume = {12},
number = {2},
pages = {203–211},
year = {1983l},
doi = {10.1068/p120203},
note = {PMID:6689208},
URL = {https://doi-org.crai.referencistas.com/10.1068/p120203},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p120203},
abstract = {A critical difficulty in theories of the ‘mental rotation’ phenomenon has been to find a computationally plausible reason why the rotation should occur in small intermediate steps. It is pointed out that this difficulty is peculiar to metrical representations: if spatial relations are presented symbolically but nonmetrically, then the iterative or recursive application of minimal transformations is memory saving. A program rotter is described to illustrate this principle.}
}

@article{doi:10.1177/17442591241252417,
author = {Y Quoc Nguyen and Trieu N Huynh and Khoa Le-Cao},
title = {Comparison of the induced flow obtained with 2D and 3D CFD simulations of a solar chimney at different width-to-gap ratios},
journal = {Journal of Building Physics},
volume = {48},
number = {1},
pages = {100–126},
year = {2024m},
doi = {10.1177/17442591241252417},
URL = {https://doi-org.crai.referencistas.com/10.1177/17442591241252417},
eprint = {https://doi-org.crai.referencistas.com/10.1177/17442591241252417},
abstract = {Solar chimneys are among the most common methods for natural ventilation of buildings. Computational Fluid Dynamics (CFD) has been widely applied in research and design of solar chimneys. Most of the previous studies are based on 2D CFD models which ignore the effects of the width (the third dimension) of the air channel. In addition, the applicability of 2D models for the solar chimneys with a low width-to-gap ratio is still questionable. This study investigates both 2D and 3D CFD models for window-sized vertical solar chimneys. The 2D model is applied to the domain comprising the central plane of the channel gap (G) and height (H) while the 3D model is applied to the domain consisting of the channel gap, height, and width (W). The flow fields, flow rates and thermal efficiencies computed with the 2D and 3D models at different heights, gaps, and widths are compared. The results show that W/G is the most crucial factor. The effects of the side walls are significant at a low W/G but gradually diminishes as W/G increases. At W/G = 15, the side wall effects are confined to a region of about 2.6% W. Particularly, for W/G>8, the differences between the 2D and 3D flow rates and thermal efficiencies are within ±5%. These findings offer a reference for researchers and engineers to select between 2D and 3D CFD models for a specific solar chimney.}
}

@article{doi:10.1177/1094342006064504,
author = {J. Nieplocha and V. Tipparaju and M. Krishnan and D. K. Panda},
title = {High Performance Remote Memory Access Communication: The Armci Approach},
journal = {The International Journal of High Performance Computing Applications},
volume = {20},
number = {2},
pages = {233–253},
year = {2006n},
doi = {10.1177/1094342006064504},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342006064504},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342006064504},
abstract = {This paper describes the Aggregate Remote Memory Copy Interface (ARMCI), a portable high performance remote memory access communication interface, developed oriinally under the U.S. Department of Energy (DOE) Advanced Computational Testing and Simulation Toolkit project and currently used and advanced as a part of the run-time layer of the DOE project, Programming Models for Scalble Parallel Computing. The paper discusses the model, addresses challenges of portable implementations, and demonstrates that ARMCI delivers high performance on a variety of platforms. Special emphasis is placed on the latency hiding mechanisms and ability to optimize noncotiguous data transfers.}
}

@article{doi:10.1260/175682909789498279,
author = {Michael V. Ol and Mark Reeder and Daniel Fredberg and Gregory Z. McGowan and Ashok Gopalarathnam and Jack R. Edwards},
title = {Computation vs. Experiment for High-Frequency Low-Reynolds Number Airfoil Plunge},
journal = {International Journal of Micro Air Vehicles},
volume = {1},
number = {2},
pages = {99–119},
year = {2009o},
doi = {10.1260/175682909789498279},
URL = {https://doi-org.crai.referencistas.com/10.1260/175682909789498279},
eprint = {https://doi-org.crai.referencistas.com/10.1260/175682909789498279},
abstract = {We seek to extend the literature on sinusoidal pure-plunge of 2D airfoils at high reduced frequency and low Reynolds number, by including effects of camber and nonzero mean incidence angle. We compare experimental results in a water tunnel using dye injection and 2D particle image velocimetry, with a set of computations in 2D – Immersed Boundary Method and unsteady Reynolds-Averaged Navier Stokes. The Re range is from 10,000 to 60,000, based on free stream velocity and airfoil chord, chosen to cover cases where transition in attached boundary layers would be of some importance, and where transition would only occur in the wake. Generally at high reduced frequency there is no Reynolds number effect. Mean angle of attack has significance, notionally, depending on whether it is below or above static stall. Computations were found to agree well with experimentally-derived velocity contours, vorticity contours and momentum in the wake. As found previously for the NACA0012, varying Strouhal number is found to control the topology of the wake, while varying reduced amplitude and reduced frequency together, but keeping Strouhal number constant, causes wake vortical structures to scale with the reduced amplitude of plunge. Flowfield periodicity – as evinced from comparison of instantaneous and time-averaged particle image velocimetry – is generally attained after two periods of oscillation from motion onset.}
}

@article{doi:10.1177/0278364906072038,
author = {Yizhar Or and Elon Rimon},
title = {Computation and Graphical Characterization of Robust Multiple-Contact                 Postures in Two-Dimensional Gravitational Environments},
journal = {The International Journal of Robotics Research},
volume = {25},
number = {11},
pages = {1071–1086},
year = {2006p},
doi = {10.1177/0278364906072038},
URL = {https://doi-org.crai.referencistas.com/10.1177/0278364906072038},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0278364906072038},
abstract = {This paper is concerned with computation and graphical characterization of robust equilibrium postures suited to quasistatic multi-legged locomotion. Quasistatic locomotion consists of postures in which the mechanism supports itself against gravity while moving its free limbs to new positions. A posture is robust if the contacts can passively support the mechanism against gravity as well as disturbance forces generated by its moving limbs. This paper is concerned with planar mechanisms supported by frictional contacts in two-dimensional gravitational environments. The kinematic structure of the mechanism is lumped into a rigid body B having the same contacts with the environment and a variable center of mass. Inertial forces generated by moving parts of the mechanism are lumped into a neighborhood of wrenches centered at the nominal gravitational wrench. The robust equilibrium postures associated with a given set of contacts become the center-of-mass locations of B that maintain equilibrium with respect to all wrenches in the given neighborhood. The paper formulates the computation of the robust center-of-mass locations as a linear programming problem. It provides graphical characterization of the robust center-of-mass locations, and gives a geometric algorithm for computing these center-of-mass locations. The paper reports experiments validating the equilibrium criterion on a two-legged prototype. Finally, it describes initial progress toward computation of robust equilibrium postures in three dimensions.}
}

@article{doi:10.1177/0037549716640877,
author = {Özgür Özmen and James J Nutaro and Laura L Pullum and Arvind Ramanathan},
title = {Analyzing the impact of modeling choices and assumptions in compartmental epidemiological models},
journal = {SIMULATION},
volume = {92},
number = {5},
pages = {459–472},
year = {2016q},
doi = {10.1177/0037549716640877},
URL = {https://doi-org.crai.referencistas.com/10.1177/0037549716640877},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0037549716640877},
abstract = {Computational disease spread models can be broadly classified into differential equation-based models (EBMs) and agent-based models (ABMs). We examine these models in the context of illuminating their hidden assumptions and the impact these may have on the model outcomes. Drawing relevant conclusions about the usability of a model requires reliable information regarding its modeling strategy and its associated assumptions. Hence, we aim to provide clear guidelines on the development of these models and delineate important modeling choices that cause the differences between the model outputs. In this study, we present a quantitative analysis of how the choice of model trajectories and temporal resolution (continuous versus discrete-event models), coupling between agents (instantaneous versus delayed interactions), and progress of patients from one stage of the disease to the next affect the overall outcomes of modeling disease spread. Our study reveals that the magnitude and velocity of the simulated epidemic depends critically on the selection of modeling principles, various assumptions of disease process, and the choice of time advance. In order to inform public health officials and improve reproducibility, these initial decisions of modelers should be carefully considered and recorded when building and documenting an ABM.}
}

@article{doi:10.3233/jid-2012-0009,
author = {Reza Shojanoori and Radmila Juric and Mahi Lohi},
title = {Computationally Significant Semantics in Pervasive     Healthcare},
journal = {Journal of Integrated Design and Process Science},
volume = {16},
number = {1},
pages = {43–62},
year = {2012r},
doi = {10.3233/jid-2012-0009},
URL = {https://doi-org.crai.referencistas.com/10.3233/jid-2012-0009},
eprint = {https://doi-org.crai.referencistas.com/10.3233/jid-2012-0009},
abstract = {Pervasive computing (PerC) is leading the way in a fast-growing trend of integrating transparently physical heterogeneous computational devices into our private and professional lives. The ubiquity of these devices and advances in developing software solutions in PerC across domains, have raised hopes for the creation of true wide-spread pervasive computing environments (PCE). In this paper we explore the possibility of applying semantics of PCEs in the healthcare domain, and in Self Care Homes (SeCH) in particular, in order to define and comment on its computationally significant semantics. Our aim is to illustrate that we can manipulate the computationally significant semantics of SeCH through OWL/SWRL enabled ontologies, as candidate technologies for achieving effective and automated decision making in SeCH. The possibility of reasoning upon OWL/SWRL enabled concepts and creating computations from them, and enables the delivery of healthcare services to SeCH residents. They are automatically supported by software applications generated from the Assistive Self Care Systems (ASeCS) software architecture, which hosts our OWL/SWRL enabled ontology and its reasoning.}
}

@article{doi:10.1177/109434209200600203,
author = {Dean F. Sittig and Mark A. Shifman and Prakash Nadkarni and Perry L. Miller},
title = {Parallel Computation for Medicine and Biology: Applications of Linda At Yale University},
journal = {The International Journal of Supercomputing Applications},
volume = {6},
number = {2},
pages = {147–163},
year = {1992s},
doi = {10.1177/109434209200600203},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434209200600203},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434209200600203},
abstract = {This article describes research in progress at the Yale University School of Medicine on the use of parallel computation in medicine and biology. We have experi mented with the parallelization of programs from sev eral different biomedical fields, using the machine-in dependent parallel programming language Linda. This research has helped us identify several general prob lem areas in which parallel computation can play a major role: namely, real-time computation, database searching, and computationally intensive algorithms. Methods for designing, debugging, and evaluating programs from each of these three problem areas are discussed. Results and evaluations of example pro grams implemented in each of these areas are pre sented. Finally, certain lessons learned are discussed.}
}

@article{doi:10.1177/1071181312561292,
author = {Ganyun Sun and Shengji Yao},
title = {A Framework for an Evolutionary Computation Approach to Supporting Concept Generation},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {56},
number = {1},
pages = {1972–1976},
year = {2012t},
doi = {10.1177/1071181312561292},
URL = {https://doi-org.crai.referencistas.com/10.1177/1071181312561292},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1071181312561292},
abstract = {This paper proposes a framework for an evolutionary computation approach to supporting concept generation in engineering design. This approach attempts to assist designers in increasing quantity and diversity of design concepts. The framework integrates the Theory of Inventive Problem Solving (TRIZ) methodology into an evolution process. First, the product resources are analyzed. The relationships between the resources are constructed using Genetic Programming. Second, contradictions between the relationships are identified based on the physical features of the resources and their relationships. Finally, principles for resolving contradictions in the TRIZ matrix guide designers to generate alternative design solutions. A case study is conducted to show how the approach works.}
}

