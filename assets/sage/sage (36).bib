@article{doi:10.1177/1094342012474997,
author = {Miguel O Bernabeu and James Southern and Nicholas Wilson and Peter Strazdins and Jonathan Cooper and Joe Pitt-Francis},
title = {Chaste: A case study of parallelisation of an open source finite-element solver with          applications to computational cardiac electrophysiology simulation},
journal = {The International Journal of High Performance Computing Applications},
volume = {28},
number = {1},
pages = {13–32},
year = {2014a},
doi = {10.1177/1094342012474997},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342012474997},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342012474997},
abstract = {The simulation of cardiac electrophysiology is a mature field in computational physiology. Recent advances in medical imaging, high-performance computing and numerical methods mean that computational models of electrical propagation in human heart tissue are ripe for use in patient-specific simulation for diagnosis, for prognosis and for selection of treatment methods. However, in order to move in this direction, it is necessary to make efficient use of modern petascale computing resources. This paper focuses on an existing open source simulation framework (Chaste) and documents work done to improve the parallel scaling on a small range of electrophysiology benchmark problems. These benchmarks involve the numerical solution of the monodomain or bidomain equations via the finite-element method. At the beginning of this study the electrophysiology libraries within Chaste were already enabled to run in parallel and were able to solve for electrical propagation using the monodomain or bidomain equations, but parallel efficiency dropped rapidly when run on more than about 64 processors. Throughout the course of the study, improvements were made to problem definition input; geometric mesh partitioning; finite-element assembly of large, sparse linear systems; problem-specific matrix preconditioning; numerical solution of the linear system; and output of the approximate solution. The consequence of these improvements is that, at the end of the study, Chaste is able to solve a monodomain benchmark problem in close to real time. While some of the improvements made to the parallel Chaste code are specific to cardiac electrophysiology, many of the techniques documented in this paper are generic to the parallel finite-element method in other scientific application areas.}
}

@article{doi:10.1177/1724600820903317,
author = {Marco Bolis and Arianna Vallerga and Maddalena Fratelli},
title = {Computational deconvolution of transcriptomic data for the study of tumor-infiltrating immune cells},
journal = {The International Journal of Biological Markers},
volume = {35},
number = {1_suppl},
pages = {20–22},
year = {2020b},
doi = {10.1177/1724600820903317},
note = {PMID:32079462},
URL = {https://doi-org.crai.referencistas.com/10.1177/1724600820903317},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1724600820903317},
abstract = {Cancer is a complex disease characterized by a wide array of mutually interacting components constituting the tumor microenvironment (connective tissue, vascular system, immune cells), many of which are targeted therapeutically. In particular, immune checkpoint inhibitors have recently become an established part of the treatment of cancer. Despite great promise, only a portion of the patients display durable response. Current research efforts are concentrated on the determination of tumor-specific biomarkers predictive of response, such as tumor mutational burden, microsatellite instability, and neo-antigen presentation. However, it is clear that several additional characteristics pertaining to the tumor microenvironment play a critical role in the effectiveness of immunotherapy. Here we comment on the computational methods that are used for the analysis of the tumor microenvironment components from transcriptomic data, discuss the critical needs, and foresee potential evolutions in the field.}
}

@article{doi:10.1177/0272989X211053794,
author = {Christopher J. Cadham and Marie Knoll and Luz María Sánchez-Romero and K. Michael Cummings and Clifford E. Douglas and Alex Liber and David Mendez and Rafael Meza and Ritesh Mistry and Aylin Sertkaya et al.},
title = {The Use of Expert Elicitation among Computational Modeling Studies in Health Research: A Systematic Review},
journal = {Medical Decision Making},
volume = {42},
number = {5},
pages = {684–703},
year = {2022c},
doi = {10.1177/0272989X211053794},
note = {PMID:34694168},
URL = {https://doi-org.crai.referencistas.com/10.1177/0272989X211053794},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0272989X211053794},
abstract = {Background Expert elicitation (EE) has been used across disciplines to estimate input parameters for computational modeling research when information is sparse or conflictual. Objectives We conducted a systematic review to compare EE methods used to generate model input parameters in health research. Data Sources PubMed and Web of Science. Study Eligibility Modeling studies that reported the use of EE as the source for model input probabilities were included if they were published in English before June 2021 and reported health outcomes. Data Abstraction and Synthesis Studies were classified as “formal” EE methods if they explicitly reported details of their elicitation process. Those that stated use of expert opinion but provided limited information were classified as “indeterminate” methods. In both groups, we abstracted citation details, study design, modeling methodology, a description of elicited parameters, and elicitation methods. Comparisons were made between elicitation methods. Study Appraisal Studies that conducted a formal EE were appraised on the reporting quality of the EE. Quality appraisal was not conducted for studies of indeterminate methods. Results The search identified 1520 articles, of which 152 were included. Of the included studies, 40 were classified as formal EE and 112 as indeterminate methods. Most studies were cost-effectiveness analyses (77.6%). Forty-seven indeterminate method studies provided no information on methods for generating estimates. Among formal EEs, the average reporting quality score was 9 out of 16. Limitations Elicitations on nonhealth topics and those reported in the gray literature were not included. Conclusions We found poor reporting of EE methods used in modeling studies, making it difficult to discern meaningful differences in approaches. Improved quality standards for EEs would improve the validity and replicability of computational models. Highlights We find extensive use of expert elicitation for the development of model input parameters, but most studies do not provide adequate details of their elicitation methods. Lack of reporting hinders greater discussion of the merits and challenges of using expert elicitation for model input parameter development. There is a need to establish expert elicitation best practices and reporting guidelines.}
}

@article{doi:10.1177/02646196241253534,
author = {Phia Damsma},
title = {Hearing a circle: An exploratory study of accessible sonification for young children with blindness and low vision},
journal = {British Journal of Visual Impairment},
volume = {0},
number = {0},
pages = {02646196241253534},
year = {2024d},
doi = {10.1177/02646196241253534},
URL = {https://doi-org.crai.referencistas.com/10.1177/02646196241253534},
eprint = {https://doi-org.crai.referencistas.com/10.1177/02646196241253534},
abstract = {This article describes a study of educational outcomes for 0- to 8-year-old children with blindness and low vision (BLV) who are learning sonification concepts. Children with BLV experience barriers to accessing education and careers in Science, Technology, Engineering and Mathematics (STEM), fields which traditionally rely heavily on visual representation of information. There is growing awareness of the potential of sonification, a technology to represent data and information in non-speech audio, to improve education access. While early learning of assistive technology skills is deemed essential for equity of access to education across the curriculum, children are generally not introduced to the concept of sonification at school until at academic level in secondary or tertiary education. Little is known about how young children with BLV engage with this promising technology. First, ‘CosmoBally on Sonoplanet’ is introduced, an accessible, educational game application for iPads and Android tablets. Then findings are shared from an anonymous online survey that collected formal responses from users of this app, using a combination of Likert-type scale and open-ended questions. The majority of the 17 respondents were (specialist) educators, and five of the respondents identified as having BLV. The survey investigated respondents’ perceptions of the capabilities of young children with BLV in using basic sonification in ‘CosmoBally on Sonoplanet’ to identify shapes – including a circle – to orientate in a digital grid and to create drawings on a touch screen. Results suggest that young children with BLV can learn sonification skills and additionally may build relevant non-sonification skills during this learning process. This article aims to provide a first insight into best practice around early learning of sonification as a potential tool for increased access and inclusion of children with BLV to STEM subjects in school.}
}

@article{doi:10.2500/ajra.2010.24.3428,
author = {Guilherme J.M. Garcia and John S. Rhee and Brent A. Senior and Julia S. Kimbell},
title = {Septal Deviation and Nasal Resistance: An Investigation using Virtual Surgery and Computational Fluid Dynamics},
journal = {American Journal of Rhinology & Allergy},
volume = {24},
number = {1},
pages = {e46–e53},
year = {2010e},
doi = {10.2500/ajra.2010.24.3428},
note = {PMID:20109325},
URL = {https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428},
eprint = {https://doi-org.crai.referencistas.com/10.2500/ajra.2010.24.3428},
abstract = {Background Septal deviation is an extremely common anatomic variation in healthy adults. However, there are no standard criteria to determine when a deviated septum is clinically relevant. Presently, selection of patients for septoplasty is based on mostly clinical examination, which is prone to observer bias and may lead to unsuccessful treatment. The objective of this article is twofold. First, we investigate whether the location of a septal deviation within the nasal passages affects nasal resistance. Second, we test whether computer simulations are consistent with rhinomanometry studies in predicting that anterior septal deviations increase nasal resistance more than posterior deviations. Methods A three-dimensional computational model of a healthy nose was created from computed tomography scans. Geometry-deforming software was used to produce models with septal deviations. Computational fluid dynamics techniques were used to simulate nasal airflow and compute nasal resistance. Results Our results revealed that the posterior nasal cavity can accommodate significant septal deviations without a substantial increase in airway resistance. In contrast, a deviation in the nasal valve region more than doubled nasal resistance. These findings are in good agreement with the rhinomanometry literature and with the observation that patients with anterior septal deviations benefit the most from septoplasty. Conclusions In the model, anterior septal deviations increased nasal resistance more than posterior deviations. This suggests, in agreement with the literature, that other causes of nasal obstruction (dysfunction of the nasal valve, allergy, etc.) should be carefully considered in patients with posterior septal deviations because such deviations may not affect nasal resistance. This study illustrates how computational modeling and virtual manipulation of the nasal geometry are useful to investigate nasal physiology.}
}

@article{doi:10.1177/1076217517707233,
author = {Julia Hagge},
title = {Scratching Beyond the Surface of Literacy: Programming for Early Adolescent Gifted Students},
journal = {Gifted Child Today},
volume = {40},
number = {3},
pages = {154–162},
year = {2017f},
doi = {10.1177/1076217517707233},
URL = {https://doi-org.crai.referencistas.com/10.1177/1076217517707233},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1076217517707233},
abstract = {Digital technology offers new possibilities for children to play, express themselves, learn, and communicate. A recent development in online practice is a shift toward youth engaged in computer programming online communities. Programming is argued to be the new literacy of the millennium. In this article, I examine the use of Scratch, an online programming community, as a means to support digital literacy for early adolescent gifted, talented, and creative students. In addition, I share the experiences of an early adolescent gifted student with Scratch and consider the use of Scratch to promote interdisciplinary curricular concepts.}
}

@article{doi:10.3233/FI-2011-534,
author = {Markus Holzer and Andreas Klein and Martin Kutrib and Oliver Ruepp},
title = {Computational Complexity of NURIKABE},
journal = {Fundamenta Informaticae},
volume = {110},
number = {1–4},
pages = {159–174},
year = {2011g},
doi = {10.3233/FI-2011-534},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2011-534},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2011-534},
abstract = {We show that the popular pencil puzzle NURIKABE is intractable from the computational complexity point of view, that is, it is NP-complete, even when the involved numbers are 1 and 2 only. To this end, we show how to simulate Boolean gates by the puzzle under consideration. Moreover, we also study some NURIKABE variants, which remain NP-complete, too.}
}

@article{doi:10.1177/14780771211070006,
author = {Anca-Simona Horvath},
title = {How we talk(ed) about it: Ways of speaking about computational architecture},
journal = {International Journal of Architectural Computing},
volume = {20},
number = {2},
pages = {150–175},
year = {2022h},
doi = {10.1177/14780771211070006},
URL = {https://doi-org.crai.referencistas.com/10.1177/14780771211070006},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14780771211070006},
abstract = {If we understand architecture as a three-part system formed by the building, its image, or drawings and images describing buildings, and the critical discourse around architecture, then the texts or ways of speaking about architecture play a key role in understanding the field and its development. By analysing a corpus of around 4.6 million words from texts written between 2005 and 2020 that form a part of critical discourse in computational architecture (understood as the result of the intense digitalization of the field), this paper aims to map ways of speaking about computational architecture. This contributes to architectural theory and might help gain a better understanding of the evolution of the digitalization of construction in general. Findings show that computational architecture is surrounded by a specific way of speaking, hybridized with words from fields such as biology, neuroscience, arts and humanities, and engineering. While some topics such as ‘sustainability’ or ‘biology’ come up consistently in the discourse, others, such as ‘people’ or ‘human’, have periods when they are more and less popular. After highlighting open research questions, the paper concludes by presenting a map of periodic and recurring topics in ways of speaking about computational architecture over the last 15 years, thus tracking and documenting long-term trends, and illuminating patterns in the broader field of digital construction.}
}

@article{doi:10.1177/02676583231160329,
author = {Eun Hee Kim},
title = {L1-transfer effects and the role of computational complexity in L2 pronoun interpretation},
journal = {Second Language Research},
volume = {40},
number = {3},
pages = {505–531},
year = {2024i},
doi = {10.1177/02676583231160329},
URL = {https://doi-org.crai.referencistas.com/10.1177/02676583231160329},
eprint = {https://doi-org.crai.referencistas.com/10.1177/02676583231160329},
abstract = {This study investigates pronoun interpretation by second language (L2) learners of English, focusing on whether first language (L1) transfer and/or processing difficulty affect L2 learners’ pronoun resolution. It is hypothesized that L2 learners’ non-target performance in L2-pronoun interpretation is attributable to two sources. The first is the computational complexity required for pronoun resolution, as argued in L1 acquisition by Grodzinsky and Reinhart and L2 acquisition by Slabakova et al. The second is how pronoun interpretation operates in L1. The hypothesis is tested by comparing Korean and Spanish L2-English learners’ interpretation of English pronouns using a Truth Value Judgment Task. Both groups had difficulty rejecting pronouns with local-referential antecedents when their proficiency levels were low. Additionally, Korean speakers showed more non-target responses than Spanish speakers due to their knowledge of pronoun interpretation in Korean. These results indicate that both L1 transfer and processing difficulty may be sources of L2 learners’ non-target pronoun interpretation, supporting the hypothesis of the study.}
}

@article{doi:10.1177/14782103231177107,
author = {J Jacob Kirksey and Kristin Mansell and Teresa Lansford},
title = {Literacy, numeracy, and problem-solving skills of adults with disabilities in STEM fields},
journal = {Policy Futures in Education},
volume = {22},
number = {3},
pages = {427–453},
year = {2024j},
doi = {10.1177/14782103231177107},
URL = {https://doi-org.crai.referencistas.com/10.1177/14782103231177107},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14782103231177107},
abstract = {To aid in the development of a globally competitive workforce, federal policymakers have expressed the priority of preparing students and adults with disabilities to succeed in science, technology, engineering, and mathematics (STEM) fields. Yet, no research has examined the extent to which information-processing, literacy, numeracy, and problem-solving skills in technologically rich environments may associate with having a STEM degree for various disability populations. This study analyzed the United States nationally representative data from the Programme for the International Assessment of Adult Competencies (PIAAC) to examine associations between adult skills and having a STEM degree for people with and without disabilities. No direct associations were found between adult skills and having a STEM degree for people with learning disabilities or for people without disabilities. These groups’ information processing, literacy, numeracy, and problem-solving skills were not determining factors in STEM degree attainment. However, findings suggest a significant association between problem-solving skills and having a STEM degree for people with visual and/or hearing impairments. Policy implications are discussed.}
}

@article{doi:10.1177/1077695820924309,
author = {Norman P. Lewis},
title = {Defining and Teaching Data Journalism: A Typology},
journal = {Journalism & Mass Communication Educator},
volume = {76},
number = {1},
pages = {78–90},
year = {2021k},
doi = {10.1177/1077695820924309},
URL = {https://doi-org.crai.referencistas.com/10.1177/1077695820924309},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1077695820924309},
abstract = {A thematic evaluation of data journalism courses resulted in a typology that parses the field and offers guidance to educators. At the center is pattern detection, preceded by data acquisition and cleaning, and followed by data representation. The typology advances academic understanding by offering a precise conceptualization that distinguishes data journalism from peripheral technologies and identifies coding as a supportive skill. It also enables a fresh definition of data journalism as the primary reliance on numerical evidence as a journalistic tool in detecting patterns, or the visual representation of numerical evidence to enable audiences to discern patterns.}
}

@article{doi:10.1243/14644193JMBD84,
author = {D W van Lopik and M Acar},
title = {Development of a multi-body computational model of human head and neck},
journal = {Proceedings of the Institution of Mechanical Engineers, Part K: Journal of Multi-body Dynamics},
volume = {221},
number = {2},
pages = {175–197},
year = {2007l},
doi = {10.1243/14644193JMBD84},
URL = {https://doi-org.crai.referencistas.com/10.1243/14644193JMBD84},
eprint = {https://doi-org.crai.referencistas.com/10.1243/14644193JMBD84},
abstract = {Abstract Experimental studies using human volunteers are limited to low acceleration impacts while whole cadavers, isolated cervical spine specimens, and impact dummies do not normally reflect the true human response. Computational modelling offers a cost effective and useful alternative to experimental methods to study the behaviour of the human head and neck and their response to impacts to gain insight into injury mechanisms. This article reports the approach used in the development of a detailed multi-body computational model that reproduces the head and cervical spine of an adult in the upright posture representing the natural lordosis of the neck with mid-sagittal symmetry. The model comprises simplified but accurate representations of the nine rigid bodies representing the head, seven cervical vertebrae of the neck, and the first thoracic vertebra, as well as the soft tissues, i.e. muscles, ligaments, and intervertebral discs. The rigid bodies are interconnected by non-linear viscoelastic intervertebral discs elements in flexion and extension, non-linear viscoelastic ligaments and supported through frictionless facet joints. Eighteen muscle groups and 69 individual muscle segments of the head and neck on each side of the body are also included in the model. Curving the muscle around the vertebrae and soft tissues of the neck during the motion of the neck is also modelled. Simulation is handled by the multi-body dynamic software MSC.visuaNastran4D. Muscle mechanics is handled by an external application, Virtual Muscle, in conjunction with MSC.visuaNastran4D that provides realistic muscle properties. Intervertebral discs are modelled as non-linear viscoelastic material in flexion and extension but represented by ‘bushing elements’ in Visual Nastran 4D, which allows stiffness and damping properties to be assigned to a joint with required number of degrees of freedom of the motion. Ligaments are modelled as non-linear viscoelastic spring-damper elements. As the model is constructed, the cervical spine motion segments are validated by comparing the segment response to published experimental data on the load-displacement behaviour for both small and large static loads. The response of the entire ligamentous cervical spine model to quasi-static flexion and extension loading is also compared to experimental data to validate the model before the effect of muscle stiffening is included. Moreover the moment-generating capacity of the neck muscle elements has been compared against in vivo experimental data. The main and coupled motions of the model segments are shown to be accurate and realistic, and the whole model is in good agreement with experimental findings from actual human cervical spine specimens. It has been shown that the model can predict the loads and deformations of the individual soft-tissue elements making the model suitable for injury analysis. The validation of the muscle elements shows the morphometric values, origins, and insertions selected to be reasonable. The muscles can be activated as required, providing a more realistic representation of the human head and neck. The curved musculature results in a more realistic representation of the change in muscle length during the head and neck motion.}
}

@article{doi:10.1177/0954410012453390,
author = {Vladislav Mantič-Lugo and Georgios Doulgeris and Riti Singh},
title = {Computational analysis of the effects of a boundary layer ingesting propulsion system in transonic flow},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {227},
number = {8},
pages = {1215–1232},
year = {2013m},
doi = {10.1177/0954410012453390},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410012453390},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410012453390},
abstract = {Continuous requirements for more efficient aircrafts lead to the design and analysis of novel propulsion configurations, with an example being the boundary layer ingestion. The complexity and integration challenges in such aircraft synergistic propulsion system characterize the research in this field, driven by the potential benefits. The aim of this article is to investigate the effects of boundary layer ingestion on the aerodynamics of a transonic wing, together with the quality of the flow ingested by the propulsion system. A two-dimensional computational model of a transonic airfoil with boundary layer ingesting propulsion system is developed in order to assess boundary layer ingestion for a commercial air transport at cruise conditions and highlight the complex integration issues arising from such configuration. A parametric analysis of the effects of flight conditions, nacelle geometry and engine operating point, on lift, pressure recovery, distortion, total pressure and velocity distribution at the intake, comes to enhance understanding of the performance of this configuration. The pressure distribution around the airfoil and the boundary layer growth are both substantially affected by the engine operating condition, which is represented by the mass flow ratio, with a direct impact on pressure recovery and lift. Mach number and angle of attack influences on lift and drag ingested are also investigated. Intake size and position on the airfoil appear to have significant effects on lift and losses ingested. In general, the results of this study include several aspects related to wing aerodynamics and ingested flow quality, which may facilitate design and integration of the boundary layer ingestion propulsion system for future commercial aircraft.}
}

@article{doi:10.1177/07482337221144143,
author = {Fatemeh Paridokht and Shiva Soury and Sara Karimi Zeverdegani},
title = {The simulation of the emission of iron fumes caused by shielded metal arc welding using a computational fluid dynamics method},
journal = {Toxicology and Industrial Health},
volume = {39},
number = {1},
pages = {36–48},
year = {2023n},
doi = {10.1177/07482337221144143},
note = {PMID:36464906},
URL = {https://doi-org.crai.referencistas.com/10.1177/07482337221144143},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07482337221144143},
abstract = {Computational fluid dynamics (CFD) is an indispensable simulation tool for predicting the emission of pollutants in the work environment. Welding is one of the most common industrial processes that might expose the operators and surrounding workers to certain hazardous gaseous metal fumes. In the present study, we used computational fluid dynamics (CFD) methodology for simulating the emission of iron fumes from the shielded metal arc welding (SMAW) procedure. A galvanized steel chamber was fabricated to measure the pollutant concentration and identify the size of the fume created by the SMAW. Then, the emission of welding aerosol was simulated using a method of computational fluid-particle dynamics with the ANSYS 2020 R1 software. The highest amount of welding fumes concentration was related to iron fumes (i.e., 3045 μg/m3 with a diameter of 0.25 μm). The results of the current study indicated that the local exhaust and general ventilation system can prevent the spreading of welding fumes to the welder’s breathing zone and the surrounding environment. CFD was also found to be an efficient method for predicting the emission of the iron fumes created by SMAW as well as for selecting an appropriate ventilation system. However, further studies that take the modeling of welding-generated emission of additional metal particles and gases into account will need to be undertaken.}
}

@article{doi:10.3233/jid-2017-0004,
author = {Carolyn E. Psenka and Kyoung-Yun Kim and Gül E. Okudan Kremer and Karl R. Haapala and Kathy L. Jackson},
title = {Translating Constructionist Learning to Engineering Design Education},
journal = {Journal of Integrated Design and Process Science},
volume = {21},
number = {2},
pages = {3–20},
year = {2017o},
doi = {10.3233/jid-2017-0004},
URL = {https://doi-org.crai.referencistas.com/10.3233/jid-2017-0004},
eprint = {https://doi-org.crai.referencistas.com/10.3233/jid-2017-0004},
abstract = {Constructionism is at once a learning epistemology, a theory of learning, and a pedagogical approach that literally places education in the hands of learners. Constructionism situates students and mentors together in student-directed, project-oriented environments, often enabled with state-of-the-art computational technologies, to foster playful exploration and experimentation. Over time, shared learning experiences in constructionist environments may lead to the formation of learning cultures. To orient the design of constructionist environments for designers of engineering design education, this paper provides a historical context for Seymour Papert’s development of constructionism and distinguishes it from Jean Piaget’s philosophy of constructivism. Constructionism is introduced as an effort targeted at the reform of traditional education. Examples of constructionist environments for learning are then provided. The applicability of constructionism for the design of learning environments for engineering design is also discussed and observations are given for designing the tools, strategies, and activities that comprise constructionist learning environments for engineering design education.}
}

@article{doi:10.1177/09720634241278878,
author = {Shruti Rathore and Praveen Dahiya},
title = {Drug Repurposing Using Computational Tools and Preventive Strategies for COVID-19 and Future Pandemics},
journal = {Journal of Health Management},
volume = {0},
number = {0},
pages = {09720634241278878},
year = {2024p},
doi = {10.1177/09720634241278878},
URL = {https://doi-org.crai.referencistas.com/10.1177/09720634241278878},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09720634241278878},
abstract = {Coronavirus disease-19 (COVID-19) was declared a global pandemic caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) that targets the lower respiratory tract in human species. Since the target receptor molecule is angiotensin-converting enzyme 2 (ACE2), which is highly expressed on the cell lining of the respiratory tract, the virus is responsible for causing acute respiratory distress syndrome (ARDS). Computational tools such as artificial intelligence, machine learning and deep learning-based platforms are used for drug repurposing, identification, and selection of target molecules that can be used for vaccine development and antiviral drug production. Computer-aided drug designing, molecular docking and homology modelling are some of the most widely used in silico models for drug discovery against COVID-19. It is important to take preventive measures to control the spread of the virus. The present review focuses on the computational tools used for recognising the target molecules for vaccine production, the transmission networks of COVID-19 and the long-term strategies to prevent future pandemics such as COVID-19.}
}

@article{doi:10.1177/039139880703000413,
author = {M. Stoiber and C. Grasl and S. Pirker and L. Huber and P. Gittler and H. Schima},
title = {Experimental Validation of Numerical Simulations: A Comparison of Computational Fluid Dynamics and the Oil Film Method},
journal = {The International Journal of Artificial Organs},
volume = {30},
number = {4},
pages = {363–368},
year = {2007q},
doi = {10.1177/039139880703000413},
note = {PMID:17520575},
URL = {https://doi-org.crai.referencistas.com/10.1177/039139880703000413},
eprint = {https://doi-org.crai.referencistas.com/10.1177/039139880703000413},
abstract = {Background Today Computational Fluid Dynamics (CFD) is used for simulating flow in many applications. The quality of the results, however, depends on various factors, like grid quality, boundary conditions and the computational model of the fluid. For this reason, it is important to validate the performed computation with experimental results. In this work, a comparison of numerical simulation with the oil film method was performed for two cardiovascular applications. Methods The investigations were conducted at various geometries, such as a bended cannula tubing, an impeller of a magnetically levitated rotary blood pump and tips of inflow cannulas. The oil film for the experimental validation was composed of black oil color and varnish. In the numerical simulation, color abrasion was displayed with a special post-processing tool by means of wall-attached pathlines. Results With the proper choice of numerical parameters, the computer simulations and the oil film method demonstrated good correlation. Improper generation of the simulation grid did lead to divergent results between the numerical simulation and the experiment. For the pump impeller as well as for the inflow cannulas, the calculation and the experiment showed similar flow patterns with backflow and stall zones. Conclusion The oil film method represents a fast and simple approach to help validate numerical simulations of fluid flow. The experimentally generated near wall flow patterns can be easily compared with the solution of the CFD analysis.}
}

@article{doi:10.1177/0734904118794844,
author = {Zhi Tang and Zheng Fang and Jiayun Sun and Tarek Beji and Bart Merci},
title = {Computational fluid dynamics simulations of the impact of a water spray on a fire-induced smoke layer inside a hood},
journal = {Journal of Fire Sciences},
volume = {36},
number = {5},
pages = {380–405},
year = {2018r},
doi = {10.1177/0734904118794844},
URL = {https://doi-org.crai.referencistas.com/10.1177/0734904118794844},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0734904118794844},
abstract = {This article presents computational fluid dynamics results of the impact of a water spray on the fire smoke layer inside a hood. The models and the settings of parameters are discussed. Three experiments are performed by means of computational fluid dynamics simulations, and the comparisons show good agreement between measured data and predicted results. The simulation results provide insight into the temperature and flow fields for the configuration at hand, revealing an entrainment effect. The influence of the water spray characteristics on the downward smoke displacement due to drag and cooling is explained. Furthermore, an extensive sensitivity study of the simulation results to input parameters and mesh size is performed. The inner spray angle (related to vertical water flux) and droplet size are shown to be key parameters when simulating downward smoke displacement caused by a spray.}
}

@article{doi:10.2304/pfie.2014.12.6.832,
author = {Hüseyin Tolu},
title = {The Politics of the ICT4ED (Fatih) Project in Turkey},
journal = {Policy Futures in Education},
volume = {12},
number = {6},
pages = {832–849},
year = {2014s},
doi = {10.2304/pfie.2014.12.6.832},
URL = {https://doi-org.crai.referencistas.com/10.2304/pfie.2014.12.6.832},
eprint = {https://doi-org.crai.referencistas.com/10.2304/pfie.2014.12.6.832},
abstract = {Information and communications technology (ICT) is crucial in any contemporary society, especially if its online presence is to be widely significant, but, in a national context, it is important to investigate whether there is a compelling ICT ‘politic’ in the education sector in Turkey. This study specifically focuses on the ICT for Educational Development (ICT4ED) (Fatih) project, valued at US$8 billion, which is an embodiment of future educational reform in centralist Turkey. The study investigates the level of policy-making capacity within the scope of the Fatih project, which promises to fully integrate ICT into education in order to solve many educational issues, such as establishing entrepreneurialism in education, improving ICT sectors, exporting educational services to other nations for profit, and, ultimately, meeting the overarching purpose of Turkey becoming a competitive nation. The discourse of the government is to explore technological opportunities within education in order to create new ‘profitable’ avenues that conceive education as a ‘commodity’ and a ‘private good’, which is another feature of fragmented centralisation through public-private partnership(s) for both covert and overt privatisations. While the Fatih project defines the future as having new, ‘fully integrated ICT in education’, this study presents three main normative arguments — with regard to the project’s political execution, technical development and philosophical conception — to refute its objectives and highlight that it is destined to fail, and to suggest what urgent matters the ICT4ED politic should highlight in future education.}
}

@article{doi:10.1177/1362361310363281,
author = {Jan P.H. Van Santen and Emily T. Prud’hommeaux and Lois M. Black and Margaret Mitchell},
title = {Computational prosodic markers for autism},
journal = {Autism},
volume = {14},
number = {3},
pages = {215–236},
year = {2010t},
doi = {10.1177/1362361310363281},
note = {PMID:20591942},
URL = {https://doi-org.crai.referencistas.com/10.1177/1362361310363281},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1362361310363281},
abstract = {We present results obtained with new instrumental methods for the acoustic analysis of prosody to evaluate prosody production by children with Autism Spectrum Disorder (ASD) and Typical Development (TD). Two tasks elicit focal stress — one in a vocal imitation paradigm, the other in a picture-description paradigm; a third task also uses a vocal imitation paradigm, and requires repeating stress patterns of two-syllable nonsense words. The instrumental methods differentiated significantly between the ASD and TD groups in all but the focal stress imitation task. The methods also showed smaller differences in the two vocal imitation tasks than in the picture-description task, as was predicted. In fact, in the nonsense word stress repetition task, the instrumental methods showed better performance for the ASD group. The methods also revealed that the acoustic features that predict auditory-perceptual judgment are not the same as those that differentiate between groups. Specifically, a key difference between the groups appears to be a difference in the balance between the various prosodic cues, such as pitch, amplitude, and duration, and not necessarily a difference in the strength or clarity with which prosodic contrasts are expressed.}
}

