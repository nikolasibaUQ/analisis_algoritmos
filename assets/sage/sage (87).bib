@article{doi:10.1177/20427530211030642,
author = {Hanan Aifan},
title = {Implementing a project-based collaborative learning approach using PowerPoint to improve students’ 21st- century skills},
journal = {E-Learning and Digital Media},
volume = {19},
number = {3},
pages = {258–273},
year = {2022a},
doi = {10.1177/20427530211030642},
URL = {https://doi-org.crai.referencistas.com/10.1177/20427530211030642},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20427530211030642},
abstract = {In this industrial age, skills required in most jobs are 21st-century skills. The current study aimed to investigate whether there is a relationship between implementing project-based collaborative learning using PowerPoint and improving students’ 21st-century skills from the students’ perspectives. It also examines whether there is a significant relationship between students’ attitudes toward learning collaboratively using PowerPoint to improve their 21st-century skills and their major. The participants of the study were 75 female students enrolled in an Educational Technology and Means course at Najran University. The findings revealed that there is a significant and positive relationship between implementing a project-based collaborative learning approach using PowerPoint and improving the students’ 21st-century skills, r (74) = 0.74 and p < 0.05. Additionally, the findings demonstrated that 21st-century skills improved the most through “actively collaborating with others” (M = 4.6, SD = 0.56). Additionally, there was no significant difference in students’ attitudes toward learning collaboratively using PowerPoint to improve their 21st-century skills in terms of human studies or scientific studies majors, t (37) = 1.97 and p > 0.05. The findings demonstrate that more research is required on the role of higher education in developing meaningful technology-based strategies to improve students’ 21st-century skills in learning environments.}
}

@article{doi:10.1155/2022/7874826,
author = {Areej Alhothali and Hifsa Khurshid and Muhammad Raza Ul Mustafa and Kawthar Mostafa Moria and Umer Rashid and Omaimah Omar Bamasag and George Kyzas},
title = {Evaluation of Contemporary Computational Techniques to Optimize Adsorption Process for Simultaneous Removal of COD and TOC in Wastewater},
journal = {Adsorption Science & Technology},
volume = {2022},
number = { },
pages = {7874826},
year = {2022b},
doi = {10.1155/2022/7874826},
URL = {https://doi-org.crai.referencistas.com/10.1155/2022/7874826},
eprint = {https://doi-org.crai.referencistas.com/10.1155/2022/7874826},
abstract = {This study was aimed at evaluating the artificial neural network (ANN), genetic algorithm (GA), adaptive neurofuzzy interference (ANFIS), and the response surface methodology (RSM) approaches for modeling and optimizing the simultaneous adsorptive removal of chemical oxygen demand (COD) and total organic carbon (TOC) in produced water (PW) using tea waste biochar (TWBC). Comparative analysis of RSM, ANN, and ANFIS models showed mean square error (MSE) as 5.29809, 1.49937, and 0.24164 for adsorption of COD and MSE of 0.11726, 0.10241, and 0.08747 for prediction of TOC adsorption, respectively. The study showed that ANFIS outperformed the ANN and RSM in terms of fast convergence, minimum MSE, and sum of square error for prediction of adsorption data. The adsorption parameters were optimized using ANFIS-surface plots, ANN-GA hybrid, RSM-GA hybrid, and RSM optimization tool in design expert (DE) software. Maximum COD (88.9%) and TOC (98.8%) removal were predicted at pH of 7, a dosage of 300 mg/L, and contact time of 60 mins using ANFIS-surface plots. The optimization approaches showed the performance in the following order: ANFIS-surface plots>ANN-GA>RSM-GA>RSM.}
}

@article{doi:10.1177/0954411920914859,
author = {Mohammed N Ashtiani and Mahmood-Reza Azghani and Mohamad Parnianpour and Kinda Khalaf},
title = {Effects of human stature and muscle strength on the standing strategies: A computational biomechanical study},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {234},
number = {7},
pages = {674–685},
year = {2020c},
doi = {10.1177/0954411920914859},
note = {PMID:32267825},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954411920914859},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954411920914859},
abstract = {It has been hypothesized that the muscular efforts exerted during standing may be altered by changes in personal factors, such as the body stature and muscular strength. The goal of this work was to assess the contribution of leg muscles using a biomechanical model in different physical conditions and various initial postures. An optimized inverse dynamics model was employed to find the maximum muscular effort in 23,040 postures. The simulation results showed that mid-range knee flexion could help the healthy and strong individuals maintain balance, but those with weaker muscle strength required more knee flexion. Individuals of weak muscular constitution as well as those with tall stature are at the highest risk of imbalance/falling. The number of imbalanced postures due to deficits in the calf and hamstring muscles was reduced by 7.5 times by strengthening the whole body musculature. The calf and the hamstring muscles play a key role in balance regardless of stature.}
}

@article{doi:10.1177/109434208700100102,
author = {Erich Bloch},
title = {Supercomputing and the Growth of Computational Science in the National Science Foundation},
journal = {The International Journal of Supercomputing Applications},
volume = {1},
number = {1},
pages = {5–8},
year = {1987d},
doi = {10.1177/109434208700100102},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434208700100102},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434208700100102}
}

@article{doi:10.1177/00420980221097590,
author = {Ryan Burns and Preston Welker},
title = {Interstitiality in the smart city: More than top-down and bottom-up smartness},
journal = {Urban Studies},
volume = {60},
number = {2},
pages = {308–324},
year = {2023e},
doi = {10.1177/00420980221097590},
note = {PMID:36741348},
URL = {https://doi-org.crai.referencistas.com/10.1177/00420980221097590},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00420980221097590},
abstract = {The critical research agenda on smart cities has tended to assume a largely top-down orientation in which powerful actors like the state and corporations enact programmes to embed Information & Communication Technologies (ICT) in the urban landscape. Because of the way research has framed this relation of power, the dominant response has been to seek social justice by either contesting these top-down exercises of (digital) power or by reconceptualising the smart city ‘from below’. In this paper, we join a growing chorus of voices recognising the importance of interstitial actors that influence the ways in which the smart city manifests. We draw on a five-year ongoing study in Calgary, Alberta, to examine two actor groups that are, properly, neither top-down nor bottom-up, but play an important role in envisioning, implementing and contesting how ‘smartness’ is framed. The first set of actors, situated between the top and bottom of the smart city hierarchy, are most prominently community associations, non-profit organisations and ad-hoc task groups. The second group is comprised of groups with different digital practices, whose spectre of marginalisation influences how digital systems are articulated and pursued. These actors strategically move between different interstices in order to enact particular kinds of political influence, and often influence smart cities by virtue of their absence, profoundly impacting urban political geographies of smartness.}
}

@article{doi:10.4137/CMC.S15710,
author = {Joshua Cates and Erik Bieging and Alan Morris and Gregory Gardner and Nazem Akoum and Eugene Kholmovski and Nassir Marrouche and Christopher McGann and Rob S. MacLeod},
title = {Computational Shape Models Characterize Shape Change of the Left Atrium in Atrial Fibrillation},
journal = {Clinical Medicine Insights: Cardiology},
volume = {8s1},
number = { },
pages = {CMC.S15710},
year = {2014f},
doi = {10.4137/CMC.S15710},
note = {PMID:26380559},
URL = {https://doi-org.crai.referencistas.com/10.4137/CMC.S15710},
eprint = {https://doi-org.crai.referencistas.com/10.4137/CMC.S15710},
abstract = {Shape change of the left atrium (LA) and LA appendage in atrial fibrillation (AF) patients is hypothesized to be linked to AF pathology and to play a role in thrombogenesis; however, many aspects of shape variation in the heart are poorly understood. To date, studies of the LA shape in AF have been limited to empirical observation and summary metrics, such as volume and its likeness to a sphere. This paper describes a more comprehensive approach to the study of the LA shape through the use of computationally derived statistical shape models. We describe practical approaches that we have developed to extract shape parameters automatically from the three-dimensional MR images of the patient. From these images and our techniques, we can produce a more comprehensive description of LA geometric variability than that has been previously possible. We present the methodology and results from two examples of specific analyses using shape models: (1) we describe statistically significant group differences between the normal control and AF patient populations (n = 137) and (2) we describe characteristic shapes of the LA appendage that are associated with the risk of thrombogenesis determined by transesophageal echocardiography (n = 203).}
}

@article{doi:10.1177/1360780418763824,
author = {Huw C Davies},
title = {Redefining Filter Bubbles as (Escapable) Socio-Technical Recursion},
journal = {Sociological Research Online},
volume = {23},
number = {3},
pages = {637–654},
year = {2018g},
doi = {10.1177/1360780418763824},
URL = {https://doi-org.crai.referencistas.com/10.1177/1360780418763824},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1360780418763824},
abstract = {Personalisation of media content is not a new phenomenon. Now, however, by configuring our search results and data feeds, algorithms that ‘learn’ from our digital footprint are determining what we see and hear. Pariser calls this the ‘Filter Bubble Effect’. Yet, despite concerns that this effect is a threat to deliberative democracy, we are told there is relatively little evidence to substantiate its existence. This article draws on a case study to argue that this is because the existing research looks for technical effects while neglecting our social lives. If we follow Foucault’s reasoning that systems of thought are also technologies, then we can see that material technologies (or what Foucault called ‘technologies of production’) and immaterial technologies (ideas formed in discourse) can co-constitute filter bubbles. Borrowing language from computing and science and technology studies, this leads to a redefinition of filter bubbles as socio-technical recursion. This case study illustrates just one potential combination of such material and immaterial technologies (namely, search engines and ideas that are encountered and formed during an individual’s social life within their culture and class) that can create socio-technical recursion. The article concludes by arguing the advantage of conceptualising filter bubbles in this way is that it offers us a theoretical foundation for breaking out of this recursion by simultaneously challenging the mediums and messages that sustain them.}
}

@article{doi:10.1177/1094342012436965,
author = {John M. Dennis and Mariana Vertenstein and Patrick H. Worley and Arthur A. Mirin and Anthony P. Craig and Robert Jacob and Sheri Mickelson},
title = {Computational performance of ultra-high-resolution capability in the Community Earth System Model},
journal = {The International Journal of High Performance Computing Applications},
volume = {26},
number = {1},
pages = {5–16},
year = {2012h},
doi = {10.1177/1094342012436965},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342012436965},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342012436965},
abstract = {With the fourth release of the Community Climate System Model, the ability to perform ultra-high-resolution climate simulations is now possible, enabling eddy-resolving ocean and sea-ice models to be coupled to a finite-volume atmosphere model for a range of atmospheric resolutions. This capability was made possible by enabling the model to use large scale parallelism, which required a significant refactoring of the software infrastructure. We describe the scalability of two ultra-high-resolution coupled configurations on leadership class computing platforms. We demonstrate the ability to utilize over 30,000 processor cores on a Cray XT5 system and over 60,000 cores on an IBM Blue Gene/P system to obtain climatologically relevant simulation rates for these configurations.}
}

@article{doi:10.1177/009430610803700611,
author = {Patrick Doreian},
title = {Clashing Paradigms and Mathematics in the Social Sciences},
journal = {Contemporary Sociology},
volume = {37},
number = {6},
pages = {542–545},
year = {2008i},
doi = {10.1177/009430610803700611},
URL = {https://doi-org.crai.referencistas.com/10.1177/009430610803700611},
eprint = {https://doi-org.crai.referencistas.com/10.1177/009430610803700611}
}

@article{doi:10.1177/14780771221148778,
author = {Ruwan Fernando and Ruby Michael},
title = {Solving planning problems with evolutionary computation},
journal = {International Journal of Architectural Computing},
volume = {21},
number = {4},
pages = {679–694},
year = {2023j},
doi = {10.1177/14780771221148778},
URL = {https://doi-org.crai.referencistas.com/10.1177/14780771221148778},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14780771221148778},
abstract = {Evolutionary design (ED) is a strategy that makes use of computational power to couple generative techniques with evaluation methods, to put forward designs that are better with each iteration. In this research, we present a representation scheme for solving spatial layout problems that is simple to implement as well as extend. The mechanisms for evaluation and mutation are defined and also shown to be extendable. Ultimately, the topic explored here is the ways in which ED and computation can enhance our design thinking and how computers can provide the background to new design processes and workflows.}
}

@article{doi:10.1177/09732586231206651,
author = {Nicholas Palmer and Harsha Chandir},
title = {Education Beyond Techno-global Rationality: Transnational Learning, Communicative Agency and the Neo-colonial Ethic},
journal = {Journal of Creative Communications},
volume = {19},
number = {1},
pages = {59–73},
year = {2024k},
doi = {10.1177/09732586231206651},
URL = {https://doi-org.crai.referencistas.com/10.1177/09732586231206651},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09732586231206651},
abstract = {The marriage of twenty-first-century horizons of technology and the global ideal constitutes techno-global rationality as it reflects contemporary impulses, frames and teleologies. Fast-paced automation, the importance of cosmopolitanism and the colonial legacy have come to dominate educational discourse and drive calls for streamlined educative practice. Although such efficiency models empower a transactional/linear mode of teaching and learning, they do little to privilege integrative voices, deliberation and intersubjective care found in global citizenship education (GCE) definitions. We argue such rationality has exacerbated a neo-colonial ethic that promulgates economic, political and cultural pressure to control and narrow otherwise diverse learning opportunities. Drawing from recent research into technology and GCE in two International Baccalaureate international schools, we note the importance of communicative outreach and agency in diversity. We also highlight the distorting effects of hyper-rationalised neo-colonial interpretations of global agency. This article will interest those seeking to develop global educational policy and practice along with revitalising interpretations of technology integration.}
}

@article{doi:10.1177/09544089231209314,
author = {Subhadip Pradhan and Samir Kumar Panda and Kalyani Panigrahi and Debabrata Dhupal},
title = {Computational approach for structural and thermal behavior of laser-machined micro-grooves on alumina ceramic using ANSYS},
journal = {Proceedings of the Institution of Mechanical Engineers, Part E: Journal of Process Mechanical Engineering},
volume = {0},
number = {0},
pages = {09544089231209314},
year = {2023l},
doi = {10.1177/09544089231209314},
URL = {https://doi-org.crai.referencistas.com/10.1177/09544089231209314},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09544089231209314},
abstract = {Heat affected zone on the micromachined material, a hindrance in achieving good precision and accuracy, which are adequate requirements for micromachined materials, is a drawback of nanosecond micromachining assisted by laser. The primary objective of this paper is to take into consideration a number of input parameters, such as the pulse width and the temperature of the laser beam, and study the effect that these parameters have on the heat flux generated as well as on the temperature distribution along the square grooves of 200 µm width and depth that are to be micro-machined on an alumina ceramic workpiece. However, processing of alumina ceramic on a micron-scale requires careful consideration to raise the quality standard. This will be accomplished by analyzing the data collected from the micro-machining process. Using the ANSYS® software, it is possible to visualize not only the region where heat is generated but also the way in which the input parameters influence the structural qualities of the micro machined groove surface. The many thermal models that have been constructed have revealed specific changes in the structural qualities that have had a significant impact on the upper width, the lower width, and the depth of the groove when applied to a variety of different parametric settings. Finally, developed analytical model is compared with the experimental models. The highest prediction error was found to be 1.68%, while, for constant 50 W power and 150–250 mm/s of speed, the average prediction error was determined to be 1.18%. As a result, the proposed model closely matches the experimental findings, and the proposed model can be used to estimate channel profile.}
}

@article{doi:10.1177/07417136231165007,
author = {Kevin M. Roessger},
title = {Attitudes Matter: Examining How Teaching Strategies for Attitudinal Change Help Adults Value Reflection and Calibrate Their Reflective Thinking},
journal = {Adult Education Quarterly},
volume = {73},
number = {3},
pages = {266–285},
year = {2023m},
doi = {10.1177/07417136231165007},
URL = {https://doi-org.crai.referencistas.com/10.1177/07417136231165007},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07417136231165007},
abstract = {Developing adults’ reflective thinking habits is an aim of adult education, but the best way to do it has been overlooked. Common strategies communicate the skills and knowledge needed to reflect while providing practice opportunities. Yet research indicates that reflective habits are comprised of not only skills and knowledge but also of attitudes toward reflection. This study investigated whether attitudinal change strategies in a reflective thinking workshop induced cognitive dissonance by helping adults appreciate reflection and calibrate their reflective behavior. Participants were randomly assigned to a skills-based or skills-based plus attitudinal change workshop. Pre-post measures of learners’ need for and engagement in reflection were taken. Multivariate analysis of covariance revealed that attitudinal change strategies induced dissonance by increasing the need for reflection while decreasing perceived engagement in reflection. Exclusively skills-based strategies failed to affect the need for reflection but increased perceived engagement in reflection, creating overconfidence. Implications for research and practice are offered.}
}

@article{doi:10.1177/003754979506500104,
author = {George W. Rogers and Jeffrey L. Solka and Carey E. Priebe},
title = {A PDP Approach to Localized Fractal Dimension Computation with Segmentation Boundaries},
journal = {SIMULATION},
volume = {65},
number = {1},
pages = {26–36},
year = {1995n},
doi = {10.1177/003754979506500104},
URL = {https://doi-org.crai.referencistas.com/10.1177/003754979506500104},
eprint = {https://doi-org.crai.referencistas.com/10.1177/003754979506500104},
abstract = {A parallel distributed processing approach to the computation of localized fractal dimension values in imagery is pre sented. This approach is a further development of the covering method which requires only nearest neighbor commu nication. A major benefit of our approach is the ability to readily incorporate any boundary information that may be available. Man y fractal textures or surfaces are fractal only in distribution. With this in mind, we show that compari son of the fractal dimension distribrctions via Kullback-Leibler can give an improved texture discrimination capability over comparison of computed fractal dimension. Results are presented for a set of textures.}
}

@article{doi:10.1177/1071181311551093,
author = {Randall Shumaker},
title = {From Teleoperation to Teammate: Applying Theory and Method from the Cognitive and Computational Sciences to Create Human-Robot Teams},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {55},
number = {1},
pages = {454–455},
year = {2011o},
doi = {10.1177/1071181311551093},
URL = {https://doi-org.crai.referencistas.com/10.1177/1071181311551093},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1071181311551093},
abstract = {The current generation of advanced robots essentially considers the external world, including humans, vehicles, and other robots, as navigational issues rather than as team members, opponents, or part of the ambient culture. But robotic systems need true Soldier-Robot Teams where each part of the team understands the roles, responsibilities, and required actions of the others and has the capability to provide the communication necessary to make the team successful. Accomplishing this within a mission context, accepted military doctrine, and social norms of the society in which the human-robot teams operate, represents a major theoretical and technological challenge for research in human-robot teams.}
}

@article{doi:10.1177/1045389X19898252,
author = {Tyler N Tallman and Hashim Hassan},
title = {A computational exploration of the effect of alignment and aspect ratio on alternating current conductivity in carbon nanofiber–modified epoxy},
journal = {Journal of Intelligent Material Systems and Structures},
volume = {31},
number = {5},
pages = {756–770},
year = {2020p},
doi = {10.1177/1045389X19898252},
URL = {https://doi-org.crai.referencistas.com/10.1177/1045389X19898252},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1045389X19898252},
abstract = {Carbon nanofiller–modified polymers have been the subject of intense study for years due to their potential use in diverse and far-reaching applications. The effect of nanofiller network parameters on macroscale direct current electrical transport has been thoroughly elucidated by extensive nano-to-microscale modeling. As a result, we now have great insight into how the conductive and piezoresistive properties of nanocomposites can be tailored through judicious control of the underlying nanofiller network. It is also well-known that carbon nanofiller–modified polymers possess frequency-dependent alternating current electrical properties. Even though work has been done to understand the alternating current properties of nanocomposites via experimental characterization and through the development of macroscale equivalent circuit models, much less has been done to understand how macroscale alternating current conductivity depends on microscale effects such as nanofiller alignment and aspect ratio. This is an important knowledge gap because, like direct current conductivity, the underlying nanofiller network ultimately gives rise to macroscale alternating current transport in these materials. To this end, we herein present an alternating current microscale percolation model for carbon filler–based polymer nanocomposites. After calibration against experimental complex impedance data from randomly ordered carbon nanofiber–modified epoxy, this model is used to explore the effect of carbon nanofiber alignment and aspect ratio on alternating current conductivity. These simulations show that alternating current conductivity generally increases with increasing alignment and with aspect ratio; however, the competing effects of alternating current and direct current percolation give rise to substantial variation in alternating current conductivity at low frequencies and with poor percolation. The methodology presented in this article provides a modeling tool by which nanocomposites with highly optimized alternating current properties can be developed through careful control and tailoring of nanofiller network properties for the realization of exotic, next-generation material functionality.}
}

@article{doi:10.1177/03010066231204815,
author = {Isabelle Viaud-Delmon},
title = {Book Review: Sensing in Social Interaction, the Taste for Cheese in Gourmet Shop (Learning in Doing: Social, Cognitive, and Computational Perspectives – Series) by Lorenza Mondada},
journal = {Perception},
volume = {53},
number = {1},
pages = {70–72},
year = {2024q},
doi = {10.1177/03010066231204815},
URL = {https://doi-org.crai.referencistas.com/10.1177/03010066231204815},
eprint = {https://doi-org.crai.referencistas.com/10.1177/03010066231204815}
}

@article{doi:10.1177/14780771231180258,
author = {Hang Xu and Tsung-Hsien Wang},
title = {A generative computational workflow to develop actionable renovation strategies for renewable built environments: A case study of Sheffield},
journal = {International Journal of Architectural Computing},
volume = {21},
number = {3},
pages = {516–535},
year = {2023r},
doi = {10.1177/14780771231180258},
URL = {https://doi-org.crai.referencistas.com/10.1177/14780771231180258},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14780771231180258},
abstract = {Urban building energy modelling (UBEM) is a prevalent research method to examine the multi-scale building to urban renovation in mitigating global energy-related carbon emissions. However, only a few studies delineate a complete workflow from generation to application using UBEM. In particular, to facilitate the designing of sustainable built environments, existing research needs to emphasize the integration of multi-scale energy performance evaluation within the design development process for architects and urban planners. The key challenges lie in the need for integrated datasets and incompatibility between software tools required for designing, modelling, and evaluation. This paper presents a comprehensive methodological framework to investigate applicable urban decarbonization strategies. A case study of Sheffield in the UK demonstrates the development of an automated and standardized computational workflow. This data-driven workflow aims to evaluate energy demand and supply scenarios at an urban scale to access the potential of decarbonizing built environments. The workflow is designed to be adaptable to various scales of urban regions, given a suitable geographic information system (GIS) dataset.}
}

@article{doi:10.1366/0003702053946056,
author = {Y. Leong Yeow and Y. K. Leong},
title = {A General Computational Method for Converting Normal Spectra into Derivative Spectra},
journal = {Applied Spectroscopy},
volume = {59},
number = {5},
pages = {584–592},
year = {2005s},
doi = {10.1366/0003702053946056},
note = {PMID:15969803},
URL = {https://doi-org.crai.referencistas.com/10.1366/0003702053946056},
eprint = {https://doi-org.crai.referencistas.com/10.1366/0003702053946056},
abstract = {The mathematical problem of converting a normal spectrum into the corresponding first- and second-derivative spectra is formulated as an integral equation of the first kind. Tikhonov regularization is then applied to solve the spectral conversion problem. The end result is a set of linear algebraic equations that takes in as input the original spectrum and produces as output the second-derivative spectrum, which is then integrated to yield the first-derivative spectrum. Noise amplification is kept under control by adjusting the regularization parameter (guided by generalized cross-validation) in the algebraic equations. The performance of this procedure is demonstrated by applying it to different types of spectral data taken from the literature.}
}

@article{doi:10.1177/1420326X19856041,
author = {Ying Zhang and Longtao Wang and Angui Li and Pengfei Tao},
title = {Performance evaluation by computational fluid dynamics modelling of the heavy gas dispersion with a low Froude number in a built environment},
journal = {Indoor and Built Environment},
volume = {29},
number = {5},
pages = {656–670},
year = {2020t},
doi = {10.1177/1420326X19856041},
URL = {https://doi-org.crai.referencistas.com/10.1177/1420326X19856041},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1420326X19856041},
abstract = {To evaluate the dispersion of a heavy gas, such as sulphur hexafluoride, with a low Froude number in a built environment, an experimental and numerical simulation study was conducted. The experiment was carried out using seven different injection inlet configurations in an experimental chamber. The release rate was found to have a great effect on the concentration in the lower part of the chamber. The obstacle in the middle of the chamber could cause a non-uniform distribution of concentration, particularly due to variations in locations and angles of the release outlets. Additionally, numerical simulations were carried out to evaluate four turbulence models: the standard k-ε model, the realizable k-ε model, the re-normalization group (RNG) k-ε model and the shear stress transport (SST) k-ω model. Four indicators were used to evaluate the turbulent model performance. In general, the SST k-ω model performed the best, with geometric mean bias (MG) = 0.968 and geometric variance (VG) = 1.09 at 0.055 m height, and with MG = 0.384 and VG = 2.80 at 0.6 m height. The standard k-ε model was the next best in performance, followed by the realizable k-ε and the RNG k-ε model.}
}

