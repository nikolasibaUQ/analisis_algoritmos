@article{doi:10.1177/1466138117725340,
author = {Corey M. Abramson and Jacqueline Joslyn and Katharine A. Rendle and Sarah B. Garrett and Daniel Dohan},
title = {The promises of computational ethnography: Improving transparency, replicability, and validity for realist approaches to ethnographic analysis},
journal = {Ethnography},
volume = {19},
number = {2},
pages = {254–284},
year = {2018a},
doi = {10.1177/1466138117725340},
URL = {https://doi-org.crai.referencistas.com/10.1177/1466138117725340},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1466138117725340},
abstract = {This article argues the advance of computational methods for analyzing, visualizing and disseminating social scientific data can provide substantial tools for ethnographers operating within the broadly realist ‘normal-scientific tradition’ (NST). While computation does not remove the fundamental challenges of method and measurement that are central to social research, new technologies provide resources for leveraging what NST researchers see as ethnography’s strengths (e.g. the production of in situ observations of people over time) while addressing what NST researchers see as ethnography’s weaknesses (e.g. questions of sample size, generalizability and analytical transparency). Specifically, we argue computational tools can help: (1) scale ethnography, (2) improve transparency, (3) allow basic replications, and (4) ultimately address fundamental concerns about internal and external validity. We explore these issues by illustrating the utility of three forms of ethnographic visualization enabled by computational advances – ethnographic heatmaps (ethnoarrays), a combination of participant observation data with techniques from social network analysis (SNA), and text mining. In doing so, we speak to the potential uses and challenges of nascent ‘computational ethnography.’}
}

@article{doi:10.1177/20563051231196880,
author = {Daniel Angus and Axel Bruns and Edward Hurcombe and Stephen Harrington and Xue Ying (Jane) Tan},
title = {Computational Communication Methods for Examining Problematic News-Sharing Practices on Facebook at Scale},
journal = {Social Media + Society},
volume = {9},
number = {3},
pages = {20563051231196880},
year = {2023b},
doi = {10.1177/20563051231196880},
URL = {https://doi-org.crai.referencistas.com/10.1177/20563051231196880},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20563051231196880},
abstract = {Social media, in general, and Facebook in particular, have been clearly identified as important platforms for the dissemination of mis- and disinformation and related problematic content. However, the patterns and processes of such dissemination are still not sufficiently understood. We detail a novel computational methodology that focusses on the identification of high-profile vectors of “fake news” and other problematic information in public Facebook spaces. The method enables examination of networks of content sharing that emerge between public pages and groups, and external sources, and the study of longitudinal dynamics of these networks as interests and allegiances shift and new developments (such as the COVID-19 pandemic or the US presidential elections) drive the emergence or decline of dominant themes. Through a case study of content captured between 2016 and 2021, we demonstrate how this methodology allows the development of a new and more comprehensive picture of the overall impact of “fake news,” in all its forms, on contemporary societies.}
}

@article{doi:10.1243/1350650981542236,
author = {P. Y. P. Chen and E. J. Hahn},
title = {Use of computational fluid dynamics in hydrodynamic lubrication},
journal = {Proceedings of the Institution of Mechanical Engineers, Part J: Journal of Engineering Tribology},
volume = {212},
number = {6},
pages = {427–436},
year = {1998c},
doi = {10.1243/1350650981542236},
URL = {https://doi-org.crai.referencistas.com/10.1243/1350650981542236},
eprint = {https://doi-org.crai.referencistas.com/10.1243/1350650981542236},
abstract = {Abstract This paper demonstrates the suitability of using computational fluid dynamics software for solving steady state hydrodynamic lubrication problems pertaining to slider bearings, step bearings, journal bearings and squeeze-film dampers under conditions of constant unidirectional or rotating loading. The relevance of the inertia and viscous terms which are neglected in the derivation of the Reynolds equation are briefly investigated for the above bearing and damper configurations and it is shown that the neglected viscous terms have negligible effect whereas the inertia effect predictions agree reasonably well with those reported in the literature.}
}

@article{doi:10.1177/0894439320914505,
author = {Yong Suk Choi and Hansung Kim and Dongyoung Sohn},
title = {Mapping Social Distress: A Computational Approach to Spatiotemporal Distribution of Anxiety},
journal = {Social Science Computer Review},
volume = {40},
number = {3},
pages = {598–617},
year = {2022d},
doi = {10.1177/0894439320914505},
URL = {https://doi-org.crai.referencistas.com/10.1177/0894439320914505},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0894439320914505},
abstract = {Anxiety is a pervasive emotional state that tends to arise in situations involving uncertainty due partly to social and contextual issues including competition, economic disparity, and social insecurity. Thus, distribution of aggregate emotions, such as in anxiety, may reveal an important picture of otherwise invisible social processes in which individuals interact with local and global opportunities, constraints, and potential threats. The aim of this study is to present a computational approach to the dynamic distribution of anxiety extracted from natural language expressions of users of Twitter, a popular global social media platform. We develop an unsupervised machine learning procedure based on a naive Bayes model to classify contents of anxiety, estimate the degree of anxiety, and construct a geographic map of spatiotemporal distribution of anxiety. To validate our mapping results, a multilevel statistical analysis was performed to examine how anxiety distribution is correlated with other district-level sociodemographic statistics such as rates of birth and early divorce. Implications for further research and extension are discussed.}
}

@article{doi:10.1177/0963721410386677,
author = {Simon Farrell and Stephan Lewandowsky},
title = {Computational Models as Aids to Better Reasoning in Psychology},
journal = {Current Directions in Psychological Science},
volume = {19},
number = {5},
pages = {329–335},
year = {2010e},
doi = {10.1177/0963721410386677},
URL = {https://doi-org.crai.referencistas.com/10.1177/0963721410386677},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0963721410386677},
abstract = {Scientists can reason about natural systems, including the mind and brain, in many ways, with each form of reasoning being associated with its own set of limitations. The limitations on human reasoning imply that the process of reasoning about theories and communicating those theories will be error prone; we must therefore be concerned about the reproducibility of theories whose very nature is shaped by constraints on human reasoning. The problem of reproducibility can be alleviated by computational modeling, which maximizes correspondence between the actual behavior of a posited system and its behavior inferred through reasoning and increases the fidelity of communication of our theories to others.}
}

@article{doi:10.1177/09567976211043426,
author = {Natasha Gandhi and Wanling Zou and Caroline Meyer and Sudeep Bhatia and Lukasz Walasek},
title = {Computational Methods for Predicting and Understanding Food Judgment},
journal = {Psychological Science},
volume = {33},
number = {4},
pages = {579–594},
year = {2022f},
doi = {10.1177/09567976211043426},
note = {PMID:35298316},
URL = {https://doi-org.crai.referencistas.com/10.1177/09567976211043426},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09567976211043426},
abstract = {People make subjective judgments about the healthiness of different foods every day, and these judgments in turn influence their food choices and health outcomes. Despite the importance of such judgments, there are few quantitative theories about their psychological underpinnings. This article introduces a novel computational approach that can approximate people’s knowledge representations for thousands of common foods. We used these representations to predict how both lay decision-makers (the general population) and experts judge the healthiness of individual foods. We also applied our method to predict the impact of behavioral interventions, such as the provision of front-of-pack nutrient and calorie information. Across multiple studies with data from 846 adults, our models achieved very high accuracy rates (r2 = .65–.77) and significantly outperformed competing models based on factual nutritional content. These results illustrate how new computational methods applied to established psychological theory can be used to better predict, understand, and influence health behavior.}
}

@article{doi:10.1243/PIME_PROC_1995_209_159_02,
author = {J C R Hunt},
title = {Practical and Fundamental Developments in the Computational Modelling of Fluid Flows},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {209},
number = {5},
pages = {297–314},
year = {1995g},
doi = {10.1243/PIME_PROC_1995_209_159_02},
URL = {https://doi-org.crai.referencistas.com/10.1243/PIME_PROC_1995_209_159_02},
eprint = {https://doi-org.crai.referencistas.com/10.1243/PIME_PROC_1995_209_159_02},
abstract = {The reasons for the recent growth of computational fluid dynamics (CFD) for industrial and environmental applications are briefly explained, and thence why the users and managers of CFD systems should understand the main underlying principles, the different options and future possibilities of this essential element in modern engineering design. The paper reviews in non-mathematical terms (a) current concepts of turbulence and the mechanisms that need to be modelled; (b) the three levels of computer code, classified according to their output level, their requirements for data and computational resources; (c) the way the codes are constructed and used; (d) how the results have to be interpreted and qualified for all practical applications; and (e) finally how CFD is developing, with better accuracy in specific areas and applications to more complex problems (with thermodynamics, chemistry, etc.) and even to flows where the turbulence is controlled interactively.}
}

@article{doi:10.1177/03064190231224334,
author = {Xiangdong Li and Sherman CP Cheung},
title = {A learning-centred computational fluid dynamics course for undergraduate engineering students},
journal = {International Journal of Mechanical Engineering Education},
volume = {0},
number = {0},
pages = {03064190231224334},
year = {2024h},
doi = {10.1177/03064190231224334},
URL = {https://doi-org.crai.referencistas.com/10.1177/03064190231224334},
eprint = {https://doi-org.crai.referencistas.com/10.1177/03064190231224334},
abstract = {The great demands for computational fluid dynamics (CFD) practitioners in industry have motivated universities to integrate CFD courses into undergraduate curricula. This article introduces a learning-centred CFD course that aims to train critical users of commercial CFD codes. The main features of the course include a project-based approach to learning and assessment-guided learning activities, both scaffolded by technologies. The implementation of the course is informed by contemporary pedagogical theories that encourage students to have the ownership of their own learning and constructively build their knowledge in an inclusive and supportive learning environment. The students upon completing the course have developed a conceptual understanding of the CFD principles and the importance of performing CFD simulations in a critical way, making them ready for more advanced CFD learning and practices. Course evaluation based on feedback from various sources demonstrates that the learning-centred approach is the key to the success of the course.}
}

@article{doi:10.1177/1468087416679570,
author = {Tommaso Lucchini and Augusto Della Torre and Gianluca D’Errico and Angelo Onorati and Noud Maes and Lambertus MT Somers and Gilles Hardy},
title = {A comprehensive methodology for computational fluid dynamics combustion modeling of industrial diesel engines},
journal = {International Journal of Engine Research},
volume = {18},
number = {1–2},
pages = {26–38},
year = {2017i},
doi = {10.1177/1468087416679570},
URL = {https://doi-org.crai.referencistas.com/10.1177/1468087416679570},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1468087416679570},
abstract = {Combustion control and optimization is of great importance to meet future emission standards in diesel engines: increase in break mean effective pressure at high loads and extension of the operating range of advanced combustion modes seem to be the most promising solutions to reduce fuel consumption and pollutant emissions at the same time. Within this context, detailed computational fluid dynamics tools are required to predict the different involved phenomena such as fuel–air mixing, unsteady diffusion combustion and formation of noxious species. Detailed kinetics, consistent spray models and high quality grids are necessary to perform predictive simulations which can be used either for design or diagnostic purposes. In this work, the authors present a comprehensive approach which was developed using an open-source computational fluid dynamics code. To minimize the pre-processing time and preserve results’ accuracy, algorithms for automatic mesh generation of spray-oriented grids were developed and successfully applied to different combustion chamber geometries. The Lagrangian approach was used to describe the spray evolution while the combustion process is modeled employing detailed chemistry and, eventually, considering turbulence–chemistry interaction. The proposed computational fluid dynamics methodology was first assessed considering inert and reacting experiments in a constant-volume vessel, where operating conditions typical of heavy-duty diesel engines were reproduced. Afterward, engine simulations were performed considering two different load points and two piston bowl geometries, respectively. Experimental validation was carried out by comparing computed and experimental data of in-cylinder pressure, heat release rate and pollutant emissions (NOx, CO and soot).}
}

@article{doi:10.3233/FI-2013-813,
author = {Andrzej Mróz},
title = {On the Computational Complexity of Bongartz’s Algorithm},
journal = {Fundamenta Informaticae},
volume = {123},
number = {3},
pages = {317–329},
year = {2013j},
doi = {10.3233/FI-2013-813},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2013-813},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2013-813},
abstract = {We study the complexity of Bongartz’s algorithm for determining a maximal common direct summand of a pair of modules M, N over k-algebra Λ; in particular, we estimate its pessimistic computational complexity 𝒪(rm6n2(n + m log n)), where m = dimkM ≤ n = dimkN and r is a number of common indecomposable direct summands of M and N. We improve the algorithm to another one of complexity 𝒪(rm4n2(n+m log m)) and we show that it applies to the isomorphism problem (having at least an exponential complexity in a direct approach). Moreover, we discuss a performance of both algorithms in practice and show that the “average” complexity is much lower, especially for the improved one (which becomes a part of QPA package for GAP computer algebra system).}
}

@article{doi:10.1260/147807707783600771,
author = {Neri Oxman},
title = {Get Real towards Performance-Driven Computational Geometry},
journal = {International Journal of Architectural Computing},
volume = {5},
number = {4},
pages = {663–684},
year = {2007k},
doi = {10.1260/147807707783600771},
URL = {https://doi-org.crai.referencistas.com/10.1260/147807707783600771},
eprint = {https://doi-org.crai.referencistas.com/10.1260/147807707783600771},
abstract = {In historic design conventions geometry has traditionally promoted descriptive manifestations of form. Beyond the realm of geometry, the concept of performance which may inform such manifestations also carries important potential for design generation. This work explores the relation between geometry and performance from a computational-geometry perspective. It does so by revisiting certain analytical tools offered in most of today’s 3-D modelers which support the evaluation of any generated surface geometry specifically curvature and draft angle analysis. It is demonstrated that these tools can be reconstructed with added functionality assigning 3-D geometrical features informed by structural and environmental performance respectively. In the examples illustrated surface thickness (as a function of structural performance) is assigned to curvature values, and transparency (as a function of light performance) is assigned to light analysis values. In a broader scope this work promotes a methodology of performance-informed form generation by means of computational geometry. Vector and tensor math was exploited to reconstruct existing analytical tools adapted to function as design generators.}
}

@article{doi:10.1177/02632764211048548,
author = {Luciana Parisi},
title = {Interactive Computation and Artificial Epistemologies},
journal = {Theory, Culture & Society},
volume = {38},
number = {7–8},
pages = {33–53},
year = {2021l},
doi = {10.1177/02632764211048548},
URL = {https://doi-org.crai.referencistas.com/10.1177/02632764211048548},
eprint = {https://doi-org.crai.referencistas.com/10.1177/02632764211048548},
abstract = {What is algorithmic thought? It is not possible to address this question without first reflecting on how the Universal Turing Machine transformed symbolic logic and brought to a halt the universality of mathematical formalism and the biocentric speciation of thought. The article draws on Sylvia Wynter’s discussion of the sociogenic principle to argue that both neurocognitive and formal models of automated cognition constitute the epistemological explanations of the origin of the human and of human sapience. Wynter’s argument will be related to Gilbert Simondon’s reflections on ‘technical mentality’ to consider how socio-techno-genic assemblages can challenge the biocentricism and the formalism of modern epistemology. This article turns to ludic logic as one possible example of techno-semiotic languages as a speculative overturning of sociogenic programming. Algorithmic rules become technique-signs coinciding not with classic formalism but with interactive localities without re-originating the universality of colonial and patriarchal cosmogony.}
}

@article{doi:10.1177/0735633116656454,
author = {Juhwa Park and Kwangsu Cho},
title = {Toward the Integration of Peer Reviewing and Computational Linguistics Approaches},
journal = {Journal of Educational Computing Research},
volume = {55},
number = {1},
pages = {123–144},
year = {2017m},
doi = {10.1177/0735633116656454},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633116656454},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633116656454},
abstract = {Previous research has shown the effectiveness of peer reviewing on the improvement of writing quality. However, the fact that students themselves, arguably novices, judged the improvement leads to concerns about the validity of peer reviewing. We measured writing quality before and after peer reviewing using Coh-Metrix, which computationally evaluates the linguistic properties of writings. Participants also evaluated the quality of their peer writings using the SWoRD system. Both measurements, particularly the computational measurement, confirmed the effectiveness of peer reviewing. In addition, the computational measures found that awareness of cohesion, including the clarity, explicitness, and concreteness of writing, improved over the course of peer reviewing. The results are discussed, along with their possible implications for the complementary roles of peer reviewing and computational writing measurements.}
}

@article{doi:10.1177/1046496410369561,
author = {Paul B. Paulus and Daniel S. Levine and Vincent Brown and Ali A. Minai and Simona Doboli},
title = {Modeling Ideational Creativity in Groups: Connecting Cognitive, Neural, and Computational Approaches},
journal = {Small Group Research},
volume = {41},
number = {6},
pages = {688–724},
year = {2010n},
doi = {10.1177/1046496410369561},
URL = {https://doi-org.crai.referencistas.com/10.1177/1046496410369561},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1046496410369561},
abstract = {Many creative activities take place in a group context, whether in short-term meetings, work teams, or by means of electronic interaction. The group creative process necessarily involves the exchange of ideas or information. Recent models of group creativity have focused on the cognitive underpinnings of this type of group creative process, primarily based on the group brainstorming literature. The authors describe an elaborated computational version of their cognitive model of group creativity and related computational models, and highlight some plausible neural bases for various involved processes. The major findings and theoretical perspectives in this literature are summarized and some potentially fruitful empirical and theoretical directions are highlighted. It is hoped that this comprehensive treatment can be a basis for integrating the present literature and providing useful predictions for further research on this topic.}
}

@article{doi:10.1177/1094342006074849,
author = {Omer Ozan Sonmez and Attila Gursoy},
title = {A Novel Economic-Based Scheduling Heuristic for Computational Grids},
journal = {The International Journal of High Performance Computing Applications},
volume = {21},
number = {1},
pages = {21–29},
year = {2007o},
doi = {10.1177/1094342006074849},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342006074849},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342006074849},
abstract = {In the economic-based computational grids we need effective schedulers not only to minimize the makespan but also to minimize the costs that are spent for the execution of the jobs. In this work, a novel economy driven job scheduling heuristic is proposed and a simulation application is developed by using GridSim toolkit to investigate the performance of the heuristic. The simulation-based experiments demonstrate the effectiveness of the proposed heuristic both in terms of parameter sweep and sequential workflow type of applications.}
}

@article{doi:10.1177/0846537120949974,
author = {William T. Tran and Ali Sadeghi-Naini and Fang-I Lu and Sonal Gandhi and Nicholas Meti and Muriel Brackstone and Eileen Rakovitch and Belinda Curpen},
title = {Computational Radiology in Breast Cancer Screening and Diagnosis Using Artificial Intelligence},
journal = {Canadian Association of Radiologists Journal},
volume = {72},
number = {1},
pages = {98–108},
year = {2021p},
doi = {10.1177/0846537120949974},
note = {PMID:32865001},
URL = {https://doi-org.crai.referencistas.com/10.1177/0846537120949974},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0846537120949974},
abstract = {Breast cancer screening has been shown to significantly reduce mortality in women. The increased utilization of screening examinations has led to growing demands for rapid and accurate diagnostic reporting. In modern breast imaging centers, full-field digital mammography (FFDM) has replaced traditional analog mammography, and this has opened new opportunities for developing computational frameworks to automate detection and diagnosis. Artificial intelligence (AI), and its subdomain of deep learning, is showing promising results and improvements on diagnostic accuracy, compared to previous computer-based methods, known as computer-aided detection and diagnosis. In this commentary, we review the current status of computational radiology, with a focus on deep neural networks used in breast cancer screening and diagnosis. Recent studies are developing a new generation of computer-aided detection and diagnosis systems, as well as leveraging AI-driven tools to efficiently interpret digital mammograms, and breast tomosynthesis imaging. The use of AI in computational radiology necessitates transparency and rigorous testing. However, the overall impact of AI to radiology workflows will potentially yield more efficient and standardized processes as well as improve the level of care to patients with high diagnostic accuracy.}
}

@article{doi:10.1177/00491241221122596,
author = {Andrea Voyer and Zachary D. Kline and Madison Danton and Tatiana Volkova},
title = {From Strange to Normal: Computational Approaches to Examining Immigrant Incorporation Through Shifts in the Mainstream},
journal = {Sociological Methods & Research},
volume = {51},
number = {4},
pages = {1540–1579},
year = {2022q},
doi = {10.1177/00491241221122596},
URL = {https://doi-org.crai.referencistas.com/10.1177/00491241221122596},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00491241221122596},
abstract = {This article presents a computational approach to examining immigrant incorporation through shifts in the social “mainstream.” Analyzing a historical corpus of American etiquette books, texts from 1922–2017 describing social norms, we identify mainstream shifts related to long-standing groups which once were and may currently still be seen as immigrant outsiders in the United States: Catholic, Chinese, Irish, Italian, Jewish, Mexican, and Muslim groups. The analysis takes a computational grounded theory approach, combining qualitative readings and computational text analyses. Using word embeddings, we operationalize the chosen groups as focal group concepts. We extract sections of text that are salient to the focal group concepts to create group-specific text corpora. Two computational approaches make it possible to examine mainstream shifts in these corpora. First, we use sentiment analysis to observe the positive sentiment in each corpus and its change over time. Second, we observe changes in each corpus’s position on a semantic dimension represented by the poles of “strange” and “normal.” The results indicate mainstream shifts through increases in positive sentiment and movement from strange to normal over time for most of the group-specific corpora. These research techniques can be adapted to other studies of social sentiment and symbolic inclusion.}
}

@article{doi:10.1518/106480407X255206,
author = {Damien J. Williams and Jan M. Noyes},
title = {Development of a User-Centered Computational Environment for Conceptual Design},
journal = {Ergonomics in Design},
volume = {15},
number = {4},
pages = {12–16},
year = {2007r},
doi = {10.1518/106480407X255206},
URL = {https://doi-org.crai.referencistas.com/10.1518/106480407X255206},
eprint = {https://doi-org.crai.referencistas.com/10.1518/106480407X255206},
abstract = {FEATURE AT A GLANCE: The earliest stage of the design process, known as conceptual design, is crucial to the overall effectiveness of the end product. Of particular importance is the search of the design space for ideas and concepts, which is restricted because of limitations in designers’ information-processing capabilities. One way to overcome this restriction is to implement computational intelligence to support and extend the search and exploration process. In this article, we report the outcome of a series of multidisciplinary workshops that identify seven key topics necessary for the future development of a generic user-centered computational environment to support conceptual design.}
}

@article{doi:10.1177/026119290903700509,
author = {Chihae Yang and Luis G. Valerio and Kirk B. Arvidson},
title = {Computational Toxicology Approaches at the US Food and Drug Administration},
journal = {Alternatives to Laboratory Animals},
volume = {37},
number = {5},
pages = {523–531},
year = {2009s},
doi = {10.1177/026119290903700509},
note = {PMID:20017581},
URL = {https://doi-org.crai.referencistas.com/10.1177/026119290903700509},
eprint = {https://doi-org.crai.referencistas.com/10.1177/026119290903700509},
abstract = {For over a decade, the United States Food and Drug Administration (US FDA) has been engaged in the applied research, development, and evaluation of computational toxicology methods used to support the safety evaluation of a diverse set of regulated products. The basis for evaluating computational toxicology methods is multi-factorial, including the potential for increased efficiency, reduction in the numbers of animals used, lower costs, and the need to explore emerging technologies that support the goals of the US FDA’s Critical Path Initiative (e.g. to make decision support information available early in the drug review process). The US FDA’s efforts have been facilitated by agency-approved data-sharing agreements between government and commercial software developers. This commentary review describes former and current scientific initiatives at the agency, in the area of computational toxicology methods. In particular, toxicology-based QSAR models, ToxML databases and knowledgebases will be addressed. Notably, many of the computational toxicology tools available are commercial products — however, several are emerging as non-commercial products, which are freely-available to the public, and which will facilitate the understanding of how these programs work and avoid the “black box” paradigm. Through productive collaborations, the US FDA Center for Drug Evaluation and Research, and the Center for Food Safety and Applied Nutrition, have worked together to evaluate, develop and apply these methods to chemical toxicity endpoints of regulatory interest.}
}

@article{doi:10.1177/0959354317722867,
author = {Silvano Zipoli Caiani},
title = {When the affordances disappear: Dynamical and computational explanations of optic ataxia},
journal = {Theory & Psychology},
volume = {27},
number = {5},
pages = {663–682},
year = {2017t},
doi = {10.1177/0959354317722867},
URL = {https://doi-org.crai.referencistas.com/10.1177/0959354317722867},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0959354317722867},
abstract = {Two options fuel the debate on the cognitive processes underlying the perception of affordances. On the one hand, the ecological theory of affordance fits with the methodological assumptions of the dynamical systems theory of cognition. On the other hand, it is nowadays common to conceive the perception of affordances within a computational framework. This article defends the explanatory power of a computational approach and aims to extend the concept of affordance beyond the boundaries of the dynamical systems theory of cognition. For that purpose, I consider the case of patients suffering from optic ataxia, a condition in which some aspects of visual guidance over reaching with the hand are lost following a lesion in the left parietal cortex. Etiological considerations, indeed, reveal that a computational approach to the perception of affordances allows for an explanation of ataxic behavior that is not available to the dynamical systems theory.}
}

