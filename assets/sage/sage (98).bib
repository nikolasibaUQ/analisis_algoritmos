@article{doi:10.1111/1467-8721.00132,
author = {Anthony Dickinson},
title = {Causal Learning: Association Versus Computation},
journal = {Current Directions in Psychological Science},
volume = {10},
number = {4},
pages = {127–132},
year = {2001a},
doi = {10.1111/1467-8721.00132},
URL = {https://doi-org.crai.referencistas.com/10.1111/1467-8721.00132},
eprint = {https://doi-org.crai.referencistas.com/10.1111/1467-8721.00132},
abstract = {Causal learning enables humans and other animals not only to predict important events or outcomes, but also to control their occurrence in the service of needs and desires. Computational theories assume that causal judgments are based on an estimate of the contingency between a causal cue and an outcome. However, human causal learning exhibits many of the characteristics of the associative learning processes thought to underlie animal conditioning. One problem for associative theory arises from the finding that judgments of the causal power of a cue can be revalued retrospectively after learning episodes when that cue is not present. However, if retrieved representations of cues can support learning, retrospective revaluation is anticipated by modified versions of standard associative theories.}
}

@article{doi:10.1243/0957650971537150,
author = {J Dunham},
title = {Modelling of spanwise mixing in compressor through-flow computations},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {211},
number = {3},
pages = {243–251},
year = {1997b},
doi = {10.1243/0957650971537150},
URL = {https://doi-org.crai.referencistas.com/10.1243/0957650971537150},
eprint = {https://doi-org.crai.referencistas.com/10.1243/0957650971537150},
abstract = {Abstract Although three-dimensional Navier-Stokes computations are coming into use more and more, streamline curvature through-flow computations are still needed, especially for multistage compressors, and where codes which run in minutes rather than hours are preferred. These methods have been made more realistic by taking account of end-wall effects and spanwise mixing by four aerodynamic mechanisms: turbulent diffusion, turbulent convection by secondary flow, spanwise migration of aerofoil boundary layer fluid and spanwise convection of fluid in blade wakes. This paper describes the models adopted in the DRA streamline curvature method for axial compressor design and analysis. Previous papers are summarized briefly before describing the new part of the model—that accounting for aerofoil boundary layers and wakes. Other changes to the previously published annulus wall boundary layer model have been made to enable it to cater for separations and end bends. The resulting code is evaluated against a range of experimental and computational results.}
}

@article{doi:10.3233/FI-2021-2056,
author = {Henning Fernau and Lakshmanan Kuppusamy and Rufus O. Oladele and Indhumathi Raman and Jérôme Durand-Lose and Jarkko Kari and Sergey Verlan},
title = {Improved Descriptional Complexity Results for Simple Semi-Conditional Grammars},
journal = {Fundamenta Informaticae},
volume = {181},
number = {2–3},
pages = {189–211},
year = {2021c},
doi = {10.3233/FI-2021-2056},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2056},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2056},
abstract = {A simple semi-conditional (SSC) grammar is a form of regulated rewriting system where the derivations are controlled either by a permitting string alone or by a forbidden string alone and this condition is specified in the rule. The maximum length i (j, resp.) of the permitting (forbidden, resp.) strings serves as a measure of descriptional complexity known as the degree of such grammars. In addition to the degree, the numbers of nonterminals and of conditional rules are also counted into the descriptional complexity measures of these grammars. We improve on some previously obtained results on the computational completeness of SSC grammars by minimizing the number of nonterminals and / or the number of conditional rules for a given degree (i, j). More specifically we prove, using a refined analysis of a normal form for type-0 grammars due to Geffert, that every recursively enumerable language is generated by an SSC grammar of (i) degree (2, 1) with eight conditional rules and nine nonterminals, (ii) degree (3, 1) with seven conditional rules and seven nonterminals (iii) degree (4, 1) with six conditional rules and seven nonterminals and (iv) degree (4, 1) with eight conditional rules and six nonterminals.}
}

@article{doi:10.1177/14680874211031370,
author = {Gaurav Guleria and Dario Lopez-Pintor and John E Dec and Dimitris Assanis},
title = {A comparative study of gasoline skeletal mechanisms under partial fuel stratification conditions using large eddy simulations},
journal = {International Journal of Engine Research},
volume = {23},
number = {10},
pages = {1658–1677},
year = {2022d},
doi = {10.1177/14680874211031370},
URL = {https://doi-org.crai.referencistas.com/10.1177/14680874211031370},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14680874211031370},
abstract = {Partial fuel stratification (PFS) is a low temperature combustion strategy that can alleviate high heat release rates of traditional low temperature combustion strategies by introducing compositional stratification in the combustion chamber using a split fuel injection strategy. In this study, a three-dimensional computational fluid dynamics (CFD) model with large eddy simulations and reduced detailed chemistry was used to model partial fuel stratification at three different stratified conditions. The double direct injection strategy injects 80% of the total fuel mass at −300 CAD aTDC and the remaining 20% of the fuel mass is injected at three different timings of −160, −50, −35 CAD to create low, medium, and high levels of compositional stratification, respectively. The PFS simulations were validated using experiments performed at Sandia National Laboratories on a single-cylinder research engine that operates on RD5-87, a research-grade E10 gasoline. The objective of this study is to compare the performance of three different reduced chemical kinetic mechanisms, namely SKM1, SKM2, and SKM3, at the three compositional stratification levels and identify the most suitable mechanism to reproduce the experimental data. Zero-dimensional chemical kinetic simulations were also performed to further understand differences in performance of the three reduced chemical kinetic mechanisms to explain variations in CFD derived heat release profiles. The modeling results indicate that SKM3 is the most suitable mechanism for partial fuel stratification modeling of research-grade gasoline. The results also show that the autoignition event progresses from the richer to the leaner compositional regions in the combustion chamber. Notably, the leaner regions that have less mass per unit volume, can contribute disproportionately more toward heat release as there are more cells at leaner equivalence ratio ranges. Overall, this study illuminates the underlying compositional stratification phenomena that control the heat release process in PFS combustion.}
}

@article{doi:10.1177/2167702614562040,
author = {Quentin J. M. Huys and Marc Guitart-Masip and Raymond J. Dolan and Peter Dayan},
title = {Decision-Theoretic Psychiatry},
journal = {Clinical Psychological Science},
volume = {3},
number = {3},
pages = {400–421},
year = {2015e},
doi = {10.1177/2167702614562040},
URL = {https://doi-org.crai.referencistas.com/10.1177/2167702614562040},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2167702614562040},
abstract = {Psychiatric disorders profoundly impair many aspects of decision making. Poor choices have negative consequences in the moment and make it very hard to navigate complex social environments. Computational neuroscience provides normative, neurobiologically informed descriptions of the components of decision making that serve as a platform for a principled exploration of dysfunctions. Here, we identify and discuss three classes of failure modes arising in these formalisms. They stem from abnormalities in the framing of problems or tasks, from the mechanisms of cognition used to solve the tasks, or from the historical data available from the environment.}
}

@article{doi:10.1177/097215090500600109,
author = {Robert J. Mockler},
title = {Stimulating Innovative Thinking: Learning How to Listen to What a Situation is Trying to Tell Us},
journal = {Global Business Review},
volume = {6},
number = {1},
pages = {125–152},
year = {2005f},
doi = {10.1177/097215090500600109},
URL = {https://doi-org.crai.referencistas.com/10.1177/097215090500600109},
eprint = {https://doi-org.crai.referencistas.com/10.1177/097215090500600109},
abstract = {While it is useful and necessary to know where the industry and competitive market now stands and how it works today in order to formulate threshold or survival strategies, more is needed. Gaining competitive advantage and deriving financial profit from the results over the intermediate and longer term requires studying where the competitive market might be heading. Therefore, systematically listening to what that market is saying about the future becomes a creative art as much as it is a science. This article discusses exploring future trends and possible effective responses to these trends.}
}

@article{doi:10.1177/147470491301100512,
author = {Austin John Jeffery and Todd K. Shackelford},
title = {Book Review: Pumping Dust},
journal = {Evolutionary Psychology},
volume = {11},
number = {5},
pages = {1077–1083},
year = {2013g},
doi = {10.1177/147470491301100512},
URL = {https://doi-org.crai.referencistas.com/10.1177/147470491301100512},
eprint = {https://doi-org.crai.referencistas.com/10.1177/147470491301100512}
}

@article{doi:10.1177/0829573520973087,
author = {Melissa Kang and Anne-Claude Bedard and Rhonda Martinussen},
title = {Rumination as a Moderating Effect Between Math Computation and Executive Function Skills in Elementary Students},
journal = {Canadian Journal of School Psychology},
volume = {36},
number = {3},
pages = {206–220},
year = {2021h},
doi = {10.1177/0829573520973087},
URL = {https://doi-org.crai.referencistas.com/10.1177/0829573520973087},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0829573520973087},
abstract = {Although students with stronger executive functions (EFs) tend to do better on math computation (MC) assessments than students with weaker EFs, stressful testing situations may lower or affect their mathematical ability. Rumination is one maladaptive coping strategy that can negatively affect EF processes, but little is known about how it impacts the relationship between EFs and MC. This study aimed to examine the relationship between students’ performance on a standardized MC task and ratings of EF ability as a function of their level of rumination. In a sample of students from Grades 4 to 6 (n = 72, mean age = 10.74), there was an interaction between EF scores and rumination in predicting MC. Students with weaker EF scores demonstrated worse math performance than students with stronger EF scores. Interestingly, their level of rumination moderated this association. Specifically, EF difficulties were only associated with less proficient MC performance among high ruminators; this association was not observed among those students reporting low rumination levels. For school psychologists, these findings provide insight into the potential causes of poor MC performance among students with average or better EFs.}
}

@article{doi:10.1177/07419325221117293,
author = {Sun A. Kim and Diane P. Bryant and Brian R. Bryant and Mikyung Shin and Min Wook Ok},
title = {A Multilevel Meta-Analysis of Whole Number Computation Interventions for Students With Learning Disabilities},
journal = {Remedial and Special Education},
volume = {44},
number = {4},
pages = {332–347},
year = {2023i},
doi = {10.1177/07419325221117293},
URL = {https://doi-org.crai.referencistas.com/10.1177/07419325221117293},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07419325221117293},
abstract = {The effects of whole number computation interventions among school students with learning disabilities in Grades K to 5 were examined using a multilevel meta-analysis. Applying a correlated and hierarchical effect model of robust variance estimation, we examined the intervention effects among 15 peer-reviewed articles and dissertations (two group-design and 13 single-case design studies) published between 1989 and 2021. Whole number computation interventions demonstrated a statistically significant and large effect on whole number computation outcomes ( = 3.74). The type of mathematical operations, type of whole number computation measures, and the number of instructional components did not significantly affect the magnitude of the effect size estimate. However, the results showed slightly larger average effect sizes for the addition problem, the accuracy measure, and the additional number of instructional components by one. The limitations and implications for the practice of the meta-analysis are discussed, and future research directions are proposed.}
}

@article{doi:10.1177/2055207619880671,
author = {Adi Kuntsman and Esperanza Miyake and Sam Martin},
title = {Re-thinking Digital Health: Data, Appisation and the (im)possibility of ‘Opting out’},
journal = {DIGITAL HEALTH},
volume = {5},
number = { },
pages = {2055207619880671},
year = {2019j},
doi = {10.1177/2055207619880671},
note = {PMID:31636917},
URL = {https://doi-org.crai.referencistas.com/10.1177/2055207619880671},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2055207619880671}
}

@article{doi:10.1177/10943420241268288,
author = {Mahesh Lakshminarasimhan and Oscar Antepara and Tuowen Zhao and Benjamin Sepanski and Protonu Basu and Hans Johansen and Mary Hall and Samuel Williams},
title = {Bricks: A high-performance portability layer for computations on block-structured grids},
journal = {The International Journal of High Performance Computing Applications},
volume = {0},
number = {0},
pages = {10943420241268288},
year = {2024k},
doi = {10.1177/10943420241268288},
URL = {https://doi-org.crai.referencistas.com/10.1177/10943420241268288},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10943420241268288},
abstract = {From partial differential equations to the convolutional neural networks in deep learning, to matrix operations in dense linear algebra, computations on structured grids dominate high-performance computing and machine learning. The performance of such computations is key to effective utilization of the billions of US dollar’s worth of GPU-accelerated systems such computations are run on. Concurrently, the end of Moore’s law and Dennard scaling are driving the specialization of compute and memory architectures. This specialization often makes performance brittle (small changes in function can have severe ramifications on performance), non-portable (vendors are increasingly motivated to develop their programming models tailored for their specialized architectures), and not performance portable (even a given computation may perform very differently from one architecture to the next). The mismatch between computations that reference data that is logically neighboring in N-dimensional space but physically distant in memory motivated the creation of Bricks — a novel data-structure transformation for multi-dimensional structured grids that reorders data into small, fixed-sized bricks of contiguously-packed data. Whereas a cache-line naturally captures spatial locality in only one dimension of a structured grid, Bricks can capture spatial locality in three or more dimensions. When coupled with a Python interface, a code-generator, and autotuning, the resultant BrickLib software provides not only raw performance, but also performance portability across multiple CPUs and GPUs, scalability in distributed memory, user productivity, and generality across computational domains. In this paper, we provide an overview of BrickLib and provide a series of vignettes on how it delivers on the aforementioned metrics.}
}

@article{doi:10.1177/0037549713505761,
author = {Juan-Ignacio Latorre and Emilio Jiménez},
title = {Simulation-based optimization of discrete event systems with alternative structural configurations using distributed computation and the Petri net paradigm},
journal = {SIMULATION},
volume = {89},
number = {11},
pages = {1310–1334},
year = {2013l},
doi = {10.1177/0037549713505761},
URL = {https://doi-org.crai.referencistas.com/10.1177/0037549713505761},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0037549713505761},
abstract = {Decision-making on discrete event systems with alternative structural configurations is a field with application to the efficient design and operation of many systems, ranging from manufacturing facilities to communication networks. The solution of this problem may be afforded by its transformation into an optimization problem. A variety of statements for this optimization problem can be presented by using different formalisms able to describe the model of the system. These different statements allow developing diverse optimization algorithms for solving the problem, which may be very demanding for a computer. In this paper, several approaches are presented in order to reduce the computing requirements needed by the mentioned algorithms, some of them are implemented in one processor and others are based on distributed computing. In particular, this paper presents a new distributed methodology, which associates sets of alternative structural configurations of the system to different alternative aggregation Petri net (AAPNs), regarding the number of available processors. Under certain conditions, this methodology alleviates the computational requirements for every processor and speeds up the optimization process. A case-study is presented and different techniques are applied to solve it, for illustrating diverse distributed and non-distributed methodologies, regarding the available processors, as well as for comparing their relative performance.}
}

@article{doi:10.1177/0954406211407260,
author = {RE Mickens},
title = {Thinking About Equations: A practical Guide for Developing Mathematical Intuition in the Physical Sciences and Engineering},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {225},
number = {8},
pages = {2003–2004},
year = {2011m},
doi = {10.1177/0954406211407260},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954406211407260},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954406211407260}
}

@article{doi:10.1243/09596518JSCE340,
author = {C Ocampo-Martinez and P Guerra and V Puig and J Quevedo},
title = {Actuator fault-tolerance evaluation of linear constrained model predictive control using zonotope-based set computations},
journal = {Proceedings of the Institution of Mechanical Engineers, Part I: Journal of Systems and Control Engineering},
volume = {221},
number = {6},
pages = {915–926},
year = {2007n},
doi = {10.1243/09596518JSCE340},
URL = {https://doi-org.crai.referencistas.com/10.1243/09596518JSCE340},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09596518JSCE340},
abstract = {Abstract This paper presents a computational procedure to evaluate the fault tolerance of a linear-constrained model predictive control (LCMPC) scheme for a given actuator fault configuration (AFC). Faults in actuators cause changes in the constraints related to control signals (inputs), which in turn modify the set of MPC feasible solutions. This fact may result in an empty set of admissible solutions for a given control objective. Therefore, the admissibility of the control law facing actuator faults can be determined by knowing the set of feasible solutions. One of the aims of this paper is to provide methods to compute this set and to evaluate the admissibility of the control law for a given AFC, once the control objective and the admissibility criteria have been established. In particular, the admissible solution set for the predictive control problem, including the effect of faults (either through reconfiguration or accommodation), is determined using an algorithm that is implemented using set computations based on zonotopes. Finally, the proposed method is tested on a real application consisting of a part of the Barcelona sewer network.}
}

@article{doi:10.1177/14749041221121477,
author = {Edgar Quilabert and Mauro C Moschetti},
title = {‘Most Likely You Go Your Way (and I’ll Go Mine)’: School-level enactment of an educational innovation policy in Barcelona},
journal = {European Educational Research Journal},
volume = {23},
number = {1},
pages = {87–107},
year = {2024o},
doi = {10.1177/14749041221121477},
URL = {https://doi-org.crai.referencistas.com/10.1177/14749041221121477},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14749041221121477},
abstract = {Narratives on innovation in education are spreading fast and both national and local educational administrations have been recently promoting innovation policies and programmes in many different European contexts. Academic literature analysing the potential benefits of innovation in education has expanded accordingly, with some international organizations increasingly commissioning research aiming to study the impacts of educational innovation, especially on learning outcomes. Interestingly, less attention has been given to analysing how these policies and programmes are translated into different practices at the school level. Drawing on a policy enactment framework, this paper aims to analyse the ways in which schools interpret top-down policy text and prescription on innovation and enact innovation in education. To do so, we focus on the case of Xarxes per al Canvi (XC), an educational innovation programme launched by the educational administration of the city of Barcelona in 2017 that aims to create school networks in order to stimulate knowledge sharing and innovation. Findings show how schools make sense of the innovation policy diversely. Policy enactment outcomes appear to be context-sensitive, with schools enacting its precepts in different ways, especially to serve their needs in increasingly competitive local education markets.}
}

@article{doi:10.1177/0306312719867768,
author = {Kasper Schiølin},
title = {Revolutionary dreams: Future essentialism and the sociotechnical imaginary of the fourth industrial revolution in Denmark},
journal = {Social Studies of Science},
volume = {50},
number = {4},
pages = {542–566},
year = {2020p},
doi = {10.1177/0306312719867768},
note = {PMID:31464575},
URL = {https://doi-org.crai.referencistas.com/10.1177/0306312719867768},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0306312719867768},
abstract = {In 2015, the World Economic Forum announced that the world was on the threshold of a ‘fourth industrial revolution’ driven by a fusion of cutting-edge technologies with unprecedented disruptive power. The next year, in 2016, the fourth industrial revolution appeared as the theme of the Forum’s annual meeting, and as the topic of a book by its founder and executive chairman, Klaus Schwab. Ever since, the Forum has made this impending revolution its top priority, maintaining that it will inevitably change everything we once know about the world and how to live in it, thus creating what I conceptualize as ‘future essentialism’. Within a short space of time, the vision of the fourth industrial revolution was institutionalized and publicly performed in various national settings around the world as a sociotechnical imaginary of a promising and desirable future soon to come. Through readings of original material published by the Forum, and through a case study of the reception of the fourth industrial revolution in Denmark, this article highlights and analyses three discursive strategies – ‘dialectics of pessimism and optimism’, ‘epochalism’ and ‘inevitability’ – in the transformation of a corporate, highly elitist vision of the future into policymaking and public reason on a national level.}
}

@article{doi:10.1177/0018726704045835,
author = {Graham Sewell},
title = {Yabba-Dabba-Doo! Evolutionary Psychology and the Rise of Flintstone Psychological Thinking in Organization and Management Studies},
journal = {Human Relations},
volume = {57},
number = {8},
pages = {923–955},
year = {2004q},
doi = {10.1177/0018726704045835},
URL = {https://doi-org.crai.referencistas.com/10.1177/0018726704045835},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0018726704045835},
abstract = {Seven years have passed since Nigel Nicholson published his manifesto for evolutionary psychology (EP) in Human Relations. Given EP’s continued popularity, this article undertakes a timely reappraisal of its assumptions and practical implications. In particular, it assesses EP’s claim to unify the social and natural sciences by establishing a foundation for psychology in the evolutionary biological sciences. I demonstrate that EP is found wanting in both these areas: it cannot satisfy the rigorous demands of experimental evolutionary biology and does not deal well with some of the key problems faced by mainstream psychologists. As a result, EP’s claims as they pertain to management and organizations are speculative and highly normative, despite vigorous protestations to the contrary.}
}

@article{doi:10.1177/1461444812450686,
author = {Ramesh Srinivasan},
title = {Re-thinking the cultural codes of new media: The question concerning ontology},
journal = {New Media & Society},
volume = {15},
number = {2},
pages = {203–223},
year = {2013r},
doi = {10.1177/1461444812450686},
URL = {https://doi-org.crai.referencistas.com/10.1177/1461444812450686},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1461444812450686},
abstract = {The digital world need not solely be conceived in Western, elite terms, but instead can and should be re-envisioned as a space that empowers the values, priorities, and ontologies held by global users from the ‘margins’, within the developing world. This paper asks us to re-consider the ontologies of the digital world in light of the cultural beliefs, languages, and value systems of emerging web users. I argue that as we design new media technologies and develop projects we must think about local ontologies and practices rather than singular Western-created representations of knowledge. I present several examples that think past rigid, hierarchical classifications, opening up the codes of new media to better listen to diverse community and cultural voices.}
}

@article{doi:10.3233/FI-2010-331,
author = {Bartek Wilczyński and Torgeir R. Hvidsten},
title = {A Computer Scientist’s Guide to the Regulatory Genome},
journal = {Fundamenta Informaticae},
volume = {103},
number = {1–4},
pages = {323–332},
year = {2010s},
doi = {10.3233/FI-2010-331},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2010-331},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2010-331},
abstract = {Recent years have seen a wealth of computational methods applied to problems stemming from molecular biology. In particular, with the completion of many new full genome sequences, great advances have been made in studying the role of non-protein-coding parts of the genome, reshaping our understanding of the role of DNA sequences. Recent breakthroughs in experimental technologies allowing us to inspect the innards of cells on a genomic scale has provided us with unprecedented amounts of data, posing new computational challenges for scientists working to uncover the secrets of life. Due to the binary-like nature of the DNA code and switch-like behavior of many regulatory mechanisms, many of the questions that are currently in focus in biology are surprisingly related to problems that have been of long-term interest to computer scientists. In this review, we present a glimpse into the current state of research in computational methods applied to modeling the regulatory genome. Our aim is to cover current approaches to selected problems from molecular biology that we consider most interesting from the perspective of computer scientists as well as highlight new challenges that will most likely draw the attention of computational biologists in the coming years.}
}

@article{doi:10.1177/1176934318759299,
author = {Xiaoyu Yu and Oleg N Reva},
title = {SWPhylo – A Novel Tool for Phylogenomic Inferences by Comparison of Oligonucleotide Patterns and Integration of Genome-Based and Gene-Based Phylogenetic Trees},
journal = {Evolutionary Bioinformatics},
volume = {14},
number = { },
pages = {1176934318759299},
year = {2018t},
doi = {10.1177/1176934318759299},
note = {PMID:29511354},
URL = {https://doi-org.crai.referencistas.com/10.1177/1176934318759299},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1176934318759299},
abstract = {Modern phylogenetic studies may benefit from the analysis of complete genome sequences of various microorganisms. Evolutionary inferences based on genome-scale analysis are believed to be more accurate than the gene-based alternative. However, the computational complexity of current phylogenomic procedures, inappropriateness of standard phylogenetic tools to process genome-wide data, and lack of reliable substitution models which correlates with alignment-free phylogenomic approaches deter microbiologists from using these opportunities. For example, the super-matrix and super-tree approaches of phylogenomics use multiple integrated genomic loci or individual gene-based trees to infer an overall consensus tree. However, these approaches potentially multiply errors of gene annotation and sequence alignment not mentioning the computational complexity and laboriousness of the methods. In this article, we demonstrate that the annotation- and alignment-free comparison of genome-wide tetranucleotide frequencies, termed oligonucleotide usage patterns (OUPs), allowed a fast and reliable inference of phylogenetic trees. These were congruent to the corresponding whole genome super-matrix trees in terms of tree topology when compared with other known approaches including 16S ribosomal RNA and GyrA protein sequence comparison, complete genome-based MAUVE, and CVTree methods. A Web-based program to perform the alignment-free OUP-based phylogenomic inferences was implemented at http://swphylo.bi.up.ac.za/. Applicability of the tool was tested on different taxa from subspecies to intergeneric levels. Distinguishing between closely related taxonomic units may be enforced by providing the program with alignments of marker protein sequences, eg, GyrA.}
}

