@article{doi:10.1177/1059712315589355,
author = {Eduardo Alonso and Michael Fairbank and Esther Mondragón},
title = {Back to optimality: a formal framework to express the dynamics of learning optimal behavior},
journal = {Adaptive Behavior},
volume = {23},
number = {4},
pages = {206–215},
year = {2015a},
doi = {10.1177/1059712315589355},
URL = {https://doi-org.crai.referencistas.com/10.1177/1059712315589355},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1059712315589355},
abstract = {Whether animals behave optimally is an open question of great importance, both theoretically and in practice. Attempts to answer this question focus on two aspects of the optimization problem, the quantity to be optimized and the optimization process itself. In this paper, we assume the abstract concept of cost as the quantity to be minimized and propose a reinforcement learning algorithm, called Value-Gradient Learning (VGL), as a computational model of behavior optimality. We prove that, unlike standard models of Reinforcement Learning, Temporal Difference in particular, VGL is guaranteed to converge to optimality under certain conditions. The core of the proof is the mathematical equivalence of VGL and Pontryagin’s Minimum Principle, a well-known optimization technique in systems and control theory. Given the similarity between VGL’s formulation and regulatory models of behavior, we argue that our algorithm may provide psychologists with a tool to formulate such models in optimization terms.}
}

@article{doi:10.1177/0960336020943987,
author = {José Manuel Amigo},
title = {Near-infrared hyperspectral image at a glance: Some personal thoughts},
journal = {NIR news},
volume = {31},
number = {5–6},
pages = {8–14},
year = {2020b},
doi = {10.1177/0960336020943987},
URL = {https://doi-org.crai.referencistas.com/10.1177/0960336020943987},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0960336020943987},
abstract = {First of all, I want to transmit my most humble thanks to all people who believe that I deserve the “2019 Thomas Hirschfeld” award (kindly supported by FOSS) for my work on near-infrared spectroscopy and, especially, applied on hyperspectral images. I must confess that this award caught me by surprise and that I felt a bit overwhelmed when I received it. It is an honour full of respect and responsibility. I have been given the opportunity of writing this article, and I will profit it to express different personal thoughts about general but relevant aspects of near infrared applied to hyperspectral imaging. Also, since I am more a practitioner in chemometrics (or machine learning or data mining, or …) than a developer, I will also include some insights about the beautiful combination of near-infrared hyperspectral image with chemometrics. This article is just a glimpse of constructive criticism with personal thoughts that comes from my little experience in this field. Therefore, and of course, all opinions here are open for constructive discussion with the only purpose of learning (like the machines do nowadays).}
}

@article{doi:10.3233/ISP-1984-3135701,
author = {J.J.M. Baar},
title = {Computation by finite element method of hydrodynamic coefficients of ships in shallow water},
journal = {International Shipbuilding Progress},
volume = {31},
number = {357},
pages = {120–130},
year = {1984c},
doi = {10.3233/ISP-1984-3135701},
URL = {https://doi-org.crai.referencistas.com/10.3233/ISP-1984-3135701},
eprint = {https://doi-org.crai.referencistas.com/10.3233/ISP-1984-3135701},
abstract = {Using two-dimensional linearized potential theory, strip theory and a finite element method, mathematical and numerical models are developed for the computation of the hydrodynamic coefficients of a slender ship form, travelling with forward speed in shallow water. The theory is applied to the computation of hydrodynamic mass and damping of a Todd Series ship model. Both experimental and numerical results are presented as functions of oscillatory frequency, water depth and forward speed.}
}

@article{doi:10.3233/FI-2021-2099,
author = {Kamila Barylska and Anna Gogolińska},
title = {Acyclic and Cyclic Reversing Computations in Petri Nets},
journal = {Fundamenta Informaticae},
volume = {184},
number = {4},
pages = {273–296},
year = {2022d},
doi = {10.3233/FI-2021-2099},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2099},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2099},
abstract = {Reversible computations constitute an unconventional form of computing where any sequence of performed operations can be undone by executing in reverse order at any point during a computation. It has been attracting increasing attention as it provides opportunities for low-power computation, being at the same time essential or eligible in various applications. In recent work, we have proposed a structural way of translating Reversing Petri Nets (RPNs) – a type of Petri nets that embeds reversible computation, to bounded Coloured Petri Nets (CPNs) – an extension of traditional Petri Nets, where tokens carry data values. Three reversing semantics are possible in RPNs: backtracking (reversing of the lately executed action), causal reversing (action can be reversed only when all its effects have been undone) and out of causal reversing (any previously performed action can be reversed). In this paper, we extend the RPN to CPN translation with formal proofs of correctness. Moreover, the possibility of introduction of cycles to RPNs is discussed. We analyze which type of cycles could be allowed in RPNs to ensure consistency with the current semantics. It emerged that the most interesting case related to cycles in RPNs occurs in causal semantics, where various interpretations of dependency result in different net’s behaviour during reversing. Three definitions of dependence are presented and discussed.}
}

@article{doi:10.1177/0956797620968787,
author = {Spencer Caplan and Alon Hafri and John C. Trueswell},
title = {Now You Hear Me, Later You Don’t: The Immediacy of Linguistic Computation and the Representation of Speech},
journal = {Psychological Science},
volume = {32},
number = {3},
pages = {410–423},
year = {2021e},
doi = {10.1177/0956797620968787},
note = {PMID:33617735},
URL = {https://doi-org.crai.referencistas.com/10.1177/0956797620968787},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0956797620968787},
abstract = {What happens to an acoustic signal after it enters the mind of a listener? Previous work has demonstrated that listeners maintain intermediate representations over time. However, the internal structure of such representations—be they the acoustic-phonetic signal or more general information about the probability of possible categories—remains underspecified. We present two experiments using a novel speaker-adaptation paradigm aimed at uncovering the format of speech representations. We exposed adult listeners (N = 297) to a speaker whose utterances contained acoustically ambiguous information concerning phones (and thus words), and we manipulated the temporal availability of disambiguating cues via visually presented text (presented before or after each utterance). Results from a traditional phoneme-categorization task showed that listeners adapted to a modified acoustic distribution when disambiguating text was provided before but not after the audio. These results support the position that speech representations consist of activation over categories and are inconsistent with direct maintenance of the acoustic-phonetic signal.}
}

@article{doi:10.1068/p6057,
author = {Mark Changizi},
title = {Harnessing Vision for Computation},
journal = {Perception},
volume = {37},
number = {7},
pages = {1131–1134},
year = {2008f},
doi = {10.1068/p6057},
note = {PMID:18773734},
URL = {https://doi-org.crai.referencistas.com/10.1068/p6057},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p6057},
abstract = {Might it be possible to harness the visual system to carry out artificial computations, somewhat akin to how DNA has been harnessed to carry out computation? I provide the beginnings of a research programme attempting to do this. In particular, new techniques are described for building ‘visual circuits’ (or ‘visual software’) using wire, NOT, OR, and AND gates in a visual modality such that our visual system acts as ‘visual hardware’ computing the circuit, and generating a resultant perception which is the output.}
}

@article{doi:10.1177/0142331216673423,
author = {G Dındış and A Karamancıoğlu},
title = {An edge determination algorithm for exact computation of the frequency response of linear interval systems},
journal = {Transactions of the Institute of Measurement and Control},
volume = {40},
number = {3},
pages = {987–994},
year = {2018g},
doi = {10.1177/0142331216673423},
URL = {https://doi-org.crai.referencistas.com/10.1177/0142331216673423},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0142331216673423},
abstract = {A novel algorithm, called the edge determination algorithm, for exact computation of the frequency response of a linear interval system is proposed. The algorithm formulates candidate curves for the frequency response boundaries as cubic Bezier curves. The edge determination algorithm operates on the cubic Bezier control points of these curves to obtain those, or their parts, that are on the frequency response boundaries. It presents the frequency response boundaries as an array whose entries are the cubic Bezier control points of the curves on the boundaries. Examples for two different cases are presented to illustrate the mechanics and validity of the algorithm.}
}

@article{doi:10.1177/00030651070550020501,
author = {Peter Fonagy and Mary Target},
title = {The Rooting of the Mind in the Body: New Links Between Attachment Theory and Psychoanalytic Thought},
journal = {Journal of the American Psychoanalytic Association},
volume = {55},
number = {2},
pages = {411–456},
year = {2007h},
doi = {10.1177/00030651070550020501},
note = {PMID:17601099},
URL = {https://doi-org.crai.referencistas.com/10.1177/00030651070550020501},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00030651070550020501},
abstract = {The relationship between psychoanalysis and attachment theory is complex indeed. A brief review of the psychoanalytic literature as it concerns attachment theory and research, and of the attachment literature as it pertains to psychoanalytic ideas, demonstrates an increasing interest in attachment theory within psychoanalysis. Some of the difficulties that attachment theory faces in relation to psychoanalytic ideas are traced to its links to the now dated cognitive science of the 1960s and 1970s. Today, however, a second-generation cognitive neuroscience seeks neurobiologically plausible accounts in which links with brain and body are seen as shaping mind and consciousness, which increasingly are seen as “embodied,” as emerging from or serving the needs of a physical being located in a specific time, place, and social context. This idea has also been at the core of much psychoanalytic thinking, which has historically affirmed the rootedness of symbolic thought in sensory, emotional, and enacted experience with objects. Now neurobiological advances supporting the concept of embodied cognition offer an opportunity to forge powerful links between the hitherto separate domains of attachment theory and psychoanalysis. Speculations about the nature of language are presented that emphasize the origin of internal working models (and of representations in general) in early sensorimotor and emotional experiences with a caregiver. It is argued that language and symbolic thought may be phylogenetically and ontogenetically embodied, built on a foundation of gestures and actions, and are thus profoundly influenced by the experience of early physical interaction with the primary object. Finally, the clinical and research implications of these ideas are discussed.}
}

@article{doi:10.1177/014233128901100501,
author = {R.M. Goodall},
title = {Minimisation of computation for digital controllers},
journal = {Transactions of the Institute of Measurement and Control},
volume = {11},
number = {5},
pages = {218–224},
year = {1989i},
doi = {10.1177/014233128901100501},
URL = {https://doi-org.crai.referencistas.com/10.1177/014233128901100501},
eprint = {https://doi-org.crai.referencistas.com/10.1177/014233128901100501},
abstract = {A novel Structure is described and analysed which has a number of advantages for the practical implementation of recursive digital filters in control applications. It is based upon the use of an established alternative to the usual z-1delay operator, but this has been developed into a standard form called a δ filter which is both robust and versatile. The advantages are shown to be in the simplicity of implementation, including the determination of word-lengths for the coefficients and variables. First- and second-order filter structures are given in detail, and simulations presented to demonstrate the operation of a few typical filters. Significant reductions in computation requirements are possible using the δ filter.}
}

@article{doi:10.1177/2472555216682725,
author = {Albert Gough and Andrew M. Stern and John Maier and Timothy Lezon and Tong-Ying Shun and Chakra Chennubhotla and Mark E. Schurdak and Steven A. Haney and D. Lansing Taylor},
title = {Biologically Relevant Heterogeneity: Metrics and Practical Insights},
journal = {SLAS DISCOVERY: Advancing the Science of Drug Discovery},
volume = {22},
number = {3},
pages = {213–237},
year = {2017j},
doi = {10.1177/2472555216682725},
note = {PMID:28231035},
URL = {https://doi-org.crai.referencistas.com/10.1177/2472555216682725},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2472555216682725},
abstract = {Heterogeneity is a fundamental property of biological systems at all scales that must be addressed in a wide range of biomedical applications, including basic biomedical research, drug discovery, diagnostics, and the implementation of precision medicine. There are a number of published approaches to characterizing heterogeneity in cells in vitro and in tissue sections. However, there are no generally accepted approaches for the detection and quantitation of heterogeneity that can be applied in a relatively high-throughput workflow. This review and perspective emphasizes the experimental methods that capture multiplexed cell-level data, as well as the need for standard metrics of the spatial, temporal, and population components of heterogeneity. A recommendation is made for the adoption of a set of three heterogeneity indices that can be implemented in any high-throughput workflow to optimize the decision-making process. In addition, a pairwise mutual information method is suggested as an approach to characterizing the spatial features of heterogeneity, especially in tissue-based imaging. Furthermore, metrics for temporal heterogeneity are in the early stages of development. Example studies indicate that the analysis of functional phenotypic heterogeneity can be exploited to guide decisions in the interpretation of biomedical experiments, drug discovery, diagnostics, and the design of optimal therapeutic strategies for individual patients.}
}

@article{doi:10.4137/EBO.S419,
author = {Glenn Hickey and Frank Dehne and Andrew Rau-Chaplin and Christian Blouin},
title = {SPR Distance Computation for Unrooted Trees},
journal = {Evolutionary Bioinformatics},
volume = {4},
number = { },
pages = {EBO.S419},
year = {2008k},
doi = {10.4137/EBO.S419},
note = {PMID:19204804},
URL = {https://doi-org.crai.referencistas.com/10.4137/EBO.S419},
eprint = {https://doi-org.crai.referencistas.com/10.4137/EBO.S419},
abstract = {The subtree prune and regraft distance (dSPR) between phylogenetic trees is important both as a general means of comparing phylogenetic tree topologies as well as a measure of lateral gene transfer (LGT). Although there has been extensive study on the computation of dSPR and similar metrics between rooted trees, much less is known about SPR distances for unrooted trees, which often arise in practice when the root is unresolved. We show that unrooted SPR distance computation is NP-Hard and verify which techniques from related work can and cannot be applied. We then present an efficient heuristic algorithm for this problem and benchmark it on a variety of synthetic datasets. Our algorithm computes the exact SPR distance between unrooted tree, and the heuristic element is only with respect to the algorithm’s computation time. Our method is a heuristic version of a fixed parameter tractability (FPT) approach and our experiments indicate that the running time behaves similar to FPT algorithms. For real data sets, our algorithm was able to quickly compute dSPR for the majority of trees that were part of a study of LGT in 144 prokaryotic genomes. Our analysis of its performance, especially with respect to searching and reduction rules, is applicable to computing many related distance measures.}
}

@article{doi:10.1177/1094342020964857,
author = {Bartosz Kohnke and Carsten Kutzner and Andreas Beckmann and Gert Lube and Ivo Kabadshow and Holger Dachsel and Helmut Grubmüller},
title = {A CUDA fast multipole method with highly efficient M2L far field evaluation},
journal = {The International Journal of High Performance Computing Applications},
volume = {35},
number = {1},
pages = {97–117},
year = {2021l},
doi = {10.1177/1094342020964857},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342020964857},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342020964857},
abstract = {Solving an N-body problem, electrostatic or gravitational, is a crucial task and the main computational bottleneck in many scientific applications. Its direct solution is an ubiquitous showcase example for the compute power of graphics processing units (GPUs). However, the naïve pairwise summation has computational complexity. The fast multipole method (FMM) can reduce runtime and complexity to for any specified precision. Here, we present a CUDA-accelerated, C++ FMM implementation for multi particle systems with potential that are found, e.g. in biomolecular simulations. The algorithm involves several operators to exchange information in an octree data structure. We focus on the Multipole-to-Local (M2L) operator, as its runtime is limiting for the overall performance. We propose, implement and benchmark three different M2L parallelization approaches. Approach (1) utilizes Unified Memory to minimize programming and porting efforts. It achieves decent speedups for only little implementation work. Approach (2) employs CUDA Dynamic Parallelism to significantly improve performance for high approximation accuracies. The presorted list-based approach (3) fits periodic boundary conditions particularly well. It exploits FMM operator symmetries to minimize both memory access and the number of complex multiplications. The result is a compute-bound implementation, i.e. performance is limited by arithmetic operations rather than by memory accesses. The complete CUDA parallelized FMM is incorporated within the GROMACS molecular dynamics package as an alternative Coulomb solver.}
}

@article{doi:10.2190/IC.28.1.c,
author = {Robert G. Kunzendorf and Franz Buker},
title = {Should Visual Images Be Defined as Depictive Neural Patterns, or as Conscious Sensations Constructed from “Imageless” Visual Thoughts?},
journal = {Imagination, Cognition and Personality},
volume = {28},
number = {1},
pages = {5–35},
year = {2008m},
doi = {10.2190/IC.28.1.c},
URL = {https://doi-org.crai.referencistas.com/10.2190/IC.28.1.c},
eprint = {https://doi-org.crai.referencistas.com/10.2190/IC.28.1.c},
abstract = {Greater vividness of visual imagery correlated significantly with improved performance on a task in which 112 subjects generated and tested hypotheses about the rules of three-point perspective (3PP), but not with improvement on a similar task in which another 116 subjects applied previously known rules of two-point perspective (2PP). Given the 100-year history of research finding zero correlation between image vividness and visuospatial reasoning, the 2PP results are interpreted as support for Külpe’s thesis that the imageless thinker’s existing knowledge of imageless rules allows for the solution of spatial problems, without any construction of visual images. The 3PP results are interpreted as support for Kunzendorf and Reynold’s thesis that the vivid imager’s construction of test images from newly hypothesized rules allows for the refinement of those imageless rules, with less reliance on overt mistakes for corrective feedback.}
}

@article{doi:10.1177/0272989X13514774,
author = {Jason Madan and Anthony E. Ades and Malcolm Price and Kathryn Maitland and Julie Jemutai and Paul Revill and Nicky J. Welton},
title = {Strategies for Efficient Computation of the Expected Value of Partial Perfect Information},
journal = {Medical Decision Making},
volume = {34},
number = {3},
pages = {327–342},
year = {2014n},
doi = {10.1177/0272989X13514774},
note = {PMID:24449434},
URL = {https://doi-org.crai.referencistas.com/10.1177/0272989X13514774},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0272989X13514774},
abstract = {Expected value of information methods evaluate the potential health benefits that can be obtained from conducting new research to reduce uncertainty in the parameters of a cost-effectiveness analysis model, hence reducing decision uncertainty. Expected value of partial perfect information (EVPPI) provides an upper limit to the health gains that can be obtained from conducting a new study on a subset of parameters in the cost-effectiveness analysis and can therefore be used as a sensitivity analysis to identify parameters that most contribute to decision uncertainty and to help guide decisions around which types of study are of most value to prioritize for funding. A common general approach is to use nested Monte Carlo simulation to obtain an estimate of EVPPI. This approach is computationally intensive, can lead to significant sampling bias if an inadequate number of inner samples are obtained, and incorrect results can be obtained if correlations between parameters are not dealt with appropriately. In this article, we set out a range of methods for estimating EVPPI that avoid the need for nested simulation: reparameterization of the net benefit function, Taylor series approximations, and restricted cubic spline estimation of conditional expectations. For each method, we set out the generalized functional form that net benefit must take for the method to be valid. By specifying this functional form, our methods are able to focus on components of the model in which approximation is required, avoiding the complexities involved in developing statistical approximations for the model as a whole. Our methods also allow for any correlations that might exist between model parameters. We illustrate the methods using an example of fluid resuscitation in African children with severe malaria.}
}

@article{doi:10.1177/002383098302600207,
author = {Brendan A. Maher and Theo C. Manschreck and Michael A.C. Molino},
title = {Redundancy, Pause Distributions and Thought Disorder in Schizophrenia},
journal = {Language and Speech},
volume = {26},
number = {2},
pages = {191–199},
year = {1983o},
doi = {10.1177/002383098302600207},
note = {PMID:6664181},
URL = {https://doi-org.crai.referencistas.com/10.1177/002383098302600207},
eprint = {https://doi-org.crai.referencistas.com/10.1177/002383098302600207},
abstract = {Recent studies have indicated that schizophrenics with current evidence of formal thought disorder (FTD) can be distinguished from schizophrenics without such disorder on measures of ability to use available redundancies in the recall of words, redundancy and lexicon variability of spoken language, and deficient motor synchrony in the production of rhythmic movements. This investigation examined pause patterns, redundancy, word frequency, and disordered thinking in a group of conservatively diagnosed schizophrenic patients, utilizing Butterworth’s model of language production. It was hypothesized that schizophrenics with FTD would be more vulnerable than those without FTD to breakdown in control processes of the interactive type than the autonomous type because of impaired capacities for involuntary attention. The results indicate that schizophrenics with FTD show a disruption of the normal systematic relationship between word redundancy and pauses in speech. This disruption is not found in schizophrenics without FTD, whose responses resemble those of normal speakers. The results are discussed in the light of attempts to integrate findings from language and motor research in schizophrenia.}
}

@article{doi:10.3233/ISP-220001,
author = {Guido Oud and Serge Toxopeus},
title = {A technique for efficient computation of steady yaw manoeuvres using CFD},
journal = {International Shipbuilding Progress},
volume = {69},
number = {1},
pages = {3–24},
year = {2022p},
doi = {10.3233/ISP-220001},
URL = {https://doi-org.crai.referencistas.com/10.3233/ISP-220001},
eprint = {https://doi-org.crai.referencistas.com/10.3233/ISP-220001},
abstract = {Hydrodynamic loads acting on a ship can nowadays be reliably obtained from Computational Fluid Dynamics (CFD) techniques. In particular for the determination of the hydrodynamic coefficients of a mathematical manoeuvring model, the forces and moments on a ship sailing at a drift angle or with a yaw rate can be computed efficiently with CFD. While computations with a drift angle are relatively straightforward, computations involving a yaw rate present a challenge. This challenge consists in how to deal with the grid, the setup and the ship encountering its own wake when rotating. A solution based on a single grid setup with consistent boundary conditions and utilising a body force wake damping zone to remedy this challenge is proposed in this paper, leading to an effective, fast, and accurate method to compute hydrodynamic loads of a ship in steady yaw manoeuvres.}
}

@article{doi:10.1177/00218863231175508,
author = {Ryan W. Quinn and Bret Crane and Jared D. Harris and Andrew Manikas},
title = {Designed Organizational Search: A Comparative Analysis of Alternative Procedures for Learning from Success},
journal = {The Journal of Applied Behavioral Science},
volume = {59},
number = {3},
pages = {391–425},
year = {2023q},
doi = {10.1177/00218863231175508},
URL = {https://doi-org.crai.referencistas.com/10.1177/00218863231175508},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00218863231175508},
abstract = {Sampling on the dependent variable is unlikely to be an effective way to learn and develop the strategy. Even so, organizations spend millions of dollars on processes such as Appreciative Inquiry that make inferences about how to adapt their strategies, routines, and practices based upon only successful examples. Two techniques that are common to this kind of learning process are searching solely for successful solutions and reframing search problems (e.g., unconditionally positive questions). We build a computational model by formalizing appreciative inquiry and comparing it with other, similar processes to understand their relative effectiveness. We find that the organizations simulated in our computational model almost always improved performance over time, despite learning solely from successful observations. Their relative effectiveness depended on the complexity of the problems, the number of iterations of learning, and how much the learning process preserved variety in potential solutions. These findings suggest that appreciative inquiry may be most effective when people take the cost and complexity of organizational problems into account before engaging in the learning process and adapt the process accordingly. These findings contribute to research on organizational learning by explaining why learners may benefit from structuring the way they communicate as they search, why reframing performance measures may dissolve search problems, and how designed organizational search enables managers to be more deliberate about organizational learning.}
}

@article{doi:10.1177/0143624411407950,
author = {GM Stavrakakis and NM Tomazinakis and NC Markatos},
title = {Modified ‘closure’ constants of the Standard k–ε turbulence model for the prediction of wind-induced natural ventilation},
journal = {Building Services Engineering Research and Technology},
volume = {33},
number = {3},
pages = {241–261},
year = {2012r},
doi = {10.1177/0143624411407950},
URL = {https://doi-org.crai.referencistas.com/10.1177/0143624411407950},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0143624411407950},
abstract = {In this study, wind-driven natural ventilation in buildings is investigated by means of computational fluid dynamics. The airflow in and around three pilot buildings, which correspond to the most common natural-ventilation designs, i.e. cross-, windward- and leeward- single-sided ventilation, is simulated by applying both the Standard and a modified k–ε turbulence model. The latter represents a Prandtl number-modified version of the Standard k–ε model, based on the flow-variable (velocity and turbulence variables) distributions and on the atmospheric boundary layer (ABL) assumptions. Numerical results of streamwise and vertical velocity components, as well as of pressure coefficients at the facades, obtained by both turbulence models are compared with available wind tunnel experimental data found in literature. It is concluded that both models applied are in acceptable agreement with measurements, especially for the mean streamwise velocity component, while the proposed modified model is more accurate as far as flow within the windward and the internal parts (i.e. within the building) of the domain is concerned. Practical application: This study focuses on the development of a modified k–ε turbulence model for the prediction of wind-driven natural ventilation. The analysis described represents a methodology to produce ‘closure’ parameters, such as Prandtl numbers, compatible with the incoming wind characteristics (ABL). It was found that for all ventilation cases studied, i.e. cross- and single-sided ventilation, the proposed modified model is more accurate compared with the Standard k–ε model, and it accounts for the dumping effect near the walls and for kinetic energy reduction in the impinging region adequately. It is satisfying that the modified k–ε model leads to acceptable engineering results within relatively practical computer resources.}
}

@article{doi:10.1177/1094342018774126,
author = {Karl-Robert Wichmann and Martin Kronbichler and Rainald Löhner and Wolfgang A Wall},
title = {Practical applicability of optimizations and performance models to complex stencil-based loop kernels in CFD},
journal = {The International Journal of High Performance Computing Applications},
volume = {33},
number = {4},
pages = {602–618},
year = {2019s},
doi = {10.1177/1094342018774126},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342018774126},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342018774126},
abstract = {This work investigates the application and interaction of optimization techniques and performance models in a computational fluid dynamics (CFD) approach employing an OpenMP parallelized, explicit, weakly compressible, finite difference–based solver for the incompressible Navier–Stokes equations using a five-point wide stencil. The presented loop and stencil optimizations lead to a 6.8× increase in per core throughput. In order to verify optimal CPU utilization, performance models are applied to the tuned code. Three different performance models are considered: a roofline-based model, utilizing purely theoretical figures, one which is enhanced by measurements, and the execution cache memory model. It is shown that the models provide reliable estimates for simple benchmarks, such as seven-point stencils for scalar Laplacians, but the estimate quality is significantly worse for the complex and tuned stencil. While it is possible to include even more details in the model, it eventually leads to a state in which it purely reproduces the benchmarks from which it was derived. Thus, the applied general-purpose performance models are found to inaccurately predict the actual performance. They overestimate the achievable performance by more than about 97% for highly tuned code. Through further code tuning, 66% of the predicted performance could be achieved.}
}

@article{doi:10.1177/0738894219881425,
author = {Joseph K Young and Steve Shellman},
title = {Protestors, terrorists or something else? How to think about dissident groups},
journal = {Conflict Management and Peace Science},
volume = {36},
number = {6},
pages = {645–660},
year = {2019t},
doi = {10.1177/0738894219881425},
URL = {https://doi-org.crai.referencistas.com/10.1177/0738894219881425},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0738894219881425},
abstract = {Many scholars of contentious politics claim there is no such thing as a group that uses only one tactic, yet scholars, pundits, and the public routinely use single-minded terms like protestors, dissidents, and terrorists. Other scholars and research programs suggest that some groups are specialists who tend to stick to a single tactic to achieve their goals, such as non-violence, violence, or specific kinds of violence, like terror. We make the claim that both sides of the debate are empirically valid and that both types of group exist. That is, some groups tend to specialize in a single tactic while others use a variety of tactics. This paper examines the empirical distribution of group types by examining the mix of tactics that groups employ. The analysis helps resolve part of the debate and pushes scholarly thinking in new directions about how often, why, and when groups operate across this spectrum.}
}

