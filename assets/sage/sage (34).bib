@article{doi:10.1177/1748006X15595875,
author = {Qadeer Ahmed and Fatai A Anifowose and Faisal Khan},
title = {System availability enhancement using computational intelligence–based decision tree predictive model},
journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
volume = {229},
number = {6},
pages = {612–626},
year = {2015a},
doi = {10.1177/1748006X15595875},
URL = {https://doi-org.crai.referencistas.com/10.1177/1748006X15595875},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1748006X15595875},
abstract = {System availability is a key performance measure in the process industry. It ensures continuous operation of facilities to meet production targets, personnel safety and environmental sustainability. Process machinery condition assessment, early fault detection and its management are vital elements to ensure overall system availability. These elements can be explored and managed effectively by extracting hidden knowledge from machinery vibration information to improve plant availability and safe operations. This article describes a decision tree–based computational intelligence model using machinery vibration data to detect machinery faults, their severity, and suggests appropriate action to avoid unscheduled failures. Vibration data for this work were collected using a machinery simulator and real-world machine to show the applicability of the proposed model. Later, the data were analyzed to detect faults using decision tree–based model that was developed in MATLAB. Fault detection classification accuracies of 98% during training and 93% during testing showed excellent performance of the proposed model. The model also revealed that the proposed formulation has capability of detecting faults correctly in the range of 98%−99%. The results showed that the proposed decision tree–based model is effective in evaluating the condition of process machinery and predicting unscheduled equipment breakdowns with better accuracy and with reduced human effort.}
}

@article{doi:10.1177/0739532917739870,
author = {Jan Lauren Boyles and Eric Meyer},
title = {Newsrooms accommodate data-based news work},
journal = {Newspaper Research Journal},
volume = {38},
number = {4},
pages = {428–438},
year = {2017b},
doi = {10.1177/0739532917739870},
URL = {https://doi-org.crai.referencistas.com/10.1177/0739532917739870},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0739532917739870},
abstract = {Similar to prior cycles of newsroom specialization, news organizations must integrate the expertise of data journalists. Based upon 18 in-depth interviews with data journalism leaders within American newspapers, this study examines how newsrooms are restructuring to accommodate data news work. More specifically, the research identifies four “critical junctures” by which newspapers expand data journalism operations. The interviews establish that expanding a paper’s commitment to data journalism requires reorganizing the newsroom with new layers of structural complexity.}
}

@article{doi:10.1177/27538699221128218,
author = {Nathan Crilly},
title = {Design research and the study of the possible},
journal = {Possibility Studies & Society},
volume = {1},
number = {1–2},
pages = {46–50},
year = {2023c},
doi = {10.1177/27538699221128218},
URL = {https://doi-org.crai.referencistas.com/10.1177/27538699221128218},
eprint = {https://doi-org.crai.referencistas.com/10.1177/27538699221128218},
abstract = {Design research has much to contribute to and much to gain from the emerging field of possibility studies. In this short essay, I discuss these opportunities with respect to four topics: (1) processes of mediation and representation, (2) systems perspectives on creative work, (3) methodological options for investigation, and (4) educational challenges that should be addressed. Considering design research’s contributions to each of these topics raises interesting questions that possibility studies might address as it develops. Conversely, possibility studies is already raising issues that design research should also attend to.}
}

@article{doi:10.1177/14703572241247836,
author = {Enzo D’Armenio and Maria Giulia Dondero},
title = {Introduction: hyper-visuality: images in the era of social platforms, digital archives and computational economies},
journal = {Visual Communication},
volume = {23},
number = {3},
pages = {405–425},
year = {2024d},
doi = {10.1177/14703572241247836},
URL = {https://doi-org.crai.referencistas.com/10.1177/14703572241247836},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14703572241247836},
abstract = {Images are today at the centre of multiple social and technological tensions as a consequence of the adoption of digital coding, of the massive diffusion of social networks and of the algorithmic processing to which they are subject, resulting in new opportunities for developing analytical inquiries and meaning-producing social actions. In this introduction, the authors intend to reconstruct the broad context that makes images one of the most important resources of the digital era and to focus on some of the research tracks that characterize it. In the first part, they begin by focusing on the relationship between images and the digital, which they retrace in accordance with the selection of three key moments: the transition from ontology to the epistemology of digital media; the opening, by social networks and portable devices, of a field for the computational study of contemporary cultures; and, finally, the analytical potential arising from the encounter between digital archives and computer algorithms. In the second part, they present the three axes around which this issue is structured: archives, identity and algorithms. They first of all discuss the concept of the archive, by presenting four different understandings it has come to bear in conjunction with digital encoding – the archive as heritage, resource, effect and as database. They go on to address the relation between images and identities, arguing that social platforms and visual apps are a new domain for identity experimentation and social aggregation. Finally, they discuss the issue of algorithms and more generally of the new computational economy that associates large amounts of data with their mobilization as operational images.}
}

@article{doi:10.1243/095440903769012902,
author = {B Diedrichs},
title = {On computational fluid dynamics modelling of crosswind effects for high-speed rolling stock},
journal = {Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit},
volume = {217},
number = {3},
pages = {203–226},
year = {2003e},
doi = {10.1243/095440903769012902},
URL = {https://doi-org.crai.referencistas.com/10.1243/095440903769012902},
eprint = {https://doi-org.crai.referencistas.com/10.1243/095440903769012902},
abstract = {Abstract This work addresses crosswind stability exemplified for the German Railway Deutsche Bahn AG high-speed train ICE 2. The scope of the work is to describe the flow by means of computational fluid dynamics past the leading two cars of the train for yaw angles in the range 12.2–40.0°. Three track formations are utilized. The basic results are the set of independent aerodynamic coefficients for the lead and subsequent cars. The results are to some extent compared with experimental data for ICE 2 and also with data obtained for the Swedish high-speed train X2000. A numerical sensitivity study is undertaken to quantify differences in the above results dependent on the grid density and quality, turbulence model, numerical scheme, location of inlet and outlet boundaries, turbulence intensity and flow simulation software.}
}

@article{doi:10.1177/0957650918790671,
author = {John Keithley Difuntorum and Louis Angelo M Danao},
title = {Improving VAWT performance through parametric studies of rotor design configurations using computational fluid dynamics},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {233},
number = {4},
pages = {489–509},
year = {2019f},
doi = {10.1177/0957650918790671},
URL = {https://doi-org.crai.referencistas.com/10.1177/0957650918790671},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0957650918790671},
abstract = {Vertical axis wind turbines present several advantages over the horizontal axis machines that make them suitable to a variety of wind conditions. However, due to the complexity of vertical axis wind turbine (VAWT) aerodynamics, available literature on VAWT performance in steady and turbulent wind conditions is limited. This paper aims to numerically predict the performance of a 5 kW VAWT under steady wind conditions through computational fluid dynamics modeling by varying turbine configuration parameters. Two-dimensional VAWT models using a cambered blade (1.5%) were created with open field boundary extents. Turbine configuration parameters studied include blade mounting position, blade fixing angle, and rotor solidity. Baseline case with peak Cp of 0.31 at tip-speed ratio of 4 has the following parameters: mounting position at 0.5c, zero fixing angle, and three blades (solidity = 0.3). Independent parametric studies were carried out and results show that a blade mounting position of 0.7c from the leading edge produces the best performance with maximum Cp = 0.315 while the worst case is a mounting position of 0.15c with peak Cp = 0.273. Fixing angle study reveals a toe-out setting of −1° producing the best performance with peak Cp of 0.315 and the worst setting at toe-in of 1.5° with peak Cp of 0.287. The solidity study resulted in the best case of four blades (solidity = 0.4) with peak Cp = 0.316 and the worst case of two blades (solidity = 0.2) with peak Cp = 0.283.}
}

@article{doi:10.1057/jit.2011.2,
author = {William H Dutton},
title = {The Politics of Next Generation Research Democratizing Research-Centred Computational Networks},
journal = {Journal of Information Technology},
volume = {26},
number = {2},
pages = {109–119},
year = {2011g},
doi = {10.1057/jit.2011.2},
URL = {https://doi-org.crai.referencistas.com/10.1057/jit.2011.2},
eprint = {https://doi-org.crai.referencistas.com/10.1057/jit.2011.2},
abstract = {Research on information technology has been focused primarily on the worlds of IT and management systems for business and government to the relative neglect of research on the digital and institutional infrastructures that underpin the research enterprise itself. When digital research is studied, the emphasis has been on the diffusion of technological innovations, rather than the social and political dynamics shaping the design and role of technologies in research. However, what researchers know, and with whom they collaborate, could be transformed through the strategic use of advances designed to support research, defined here as ‘research-centred computational networks’. This article presents a framework for conceptualizing the social and technological choices shaping the next generation of research in ways that could open – democratize – key aspects of the research process that move well beyond academic publication. The framework highlights the limited scope of innovation to date, and identifies a variety of factors that maintain and enhance institutional control over the research process, at the risk of losing the creative and productive bottom-up participation by networked researchers and citizen researchers among the public at large. Conceptualizing, prioritizing and advancing study of next generation research is one of the most significant but difficult challenges facing scholars of information technology.}
}

@article{doi:10.1177/20552076231186513,
author = {John Gardner and Daniel Herron and Nick McNally and Bryan Williams},
title = {Advancing the digital and computational capabilities of healthcare providers: A qualitative study of a hospital organisation in the NHS},
journal = {DIGITAL HEALTH},
volume = {9},
number = { },
pages = {20552076231186510},
year = {2023h},
doi = {10.1177/20552076231186513},
note = {PMID:36644660},
URL = {https://doi-org.crai.referencistas.com/10.1177/20552076231186513},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20552076231186513},
abstract = {Objective Healthcare systems require transformation to meet societal challenges and projected health demands. Digital and computational tools and approaches are fundamental to this transformation, and hospitals have a key role to play in their development and implementation. This paper reports on a study with the objective of exploring the challenges encountered by hospital leaders and innovators as they implement a strategy to become a data-driven hospital organisation. In doing so, this paper provides guidance to future leaders and innovators seeking to build computational and digital capabilities in complex clinical settings. Methods Interviews were undertaken with 42 participants associated with a large public hospital organisation within England’s National Health Service. Using the concept of institutional readiness as an analytical framework, the paper explores participants’ perspectives on the organisation’s capacity to support the development of, and benefit from, digital and computational approaches. Results Participants’ accounts reveal a range of specific institutional readiness criteria relating to organisational vision, technical capability, organisational agility, and talent and skills that, when met, enhance the organisations’ capacity to support the development and implementation of digital and computational tools. Participant accounts also reveal challenges relating to these criteria, such as unrealistic expectations and the necessary prioritisation of clinical work in resource-constrained settings. Conclusions The paper identifies a general set of institutional readiness criteria that can guide future hospital leaders and innovators aiming to improve their organisation’s digital and computational capability. The paper also illustrates the challenges of pursuing digital and computational innovation in resource-constrained hospital environments.}
}

@article{doi:10.1177/09544100241259904,
author = {Farshad Heidari and Keyvan Taheri and Maziar Janghorban},
title = {On the experimental results of functionally graded materials with computational mechanics approach: Review},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {0},
number = {0},
pages = {09544100241259904},
year = {2024i},
doi = {10.1177/09544100241259904},
URL = {https://doi-org.crai.referencistas.com/10.1177/09544100241259904},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09544100241259904},
abstract = {Functionally graded materials have been of great interest to researchers for the past two decades. The reason for this is that these materials have outstanding and special material properties compared to many other materials. One of the branches of engineering sciences that has studied these materials in particular during these years is computational mechanics. With this approach, especially static, vibration and buckling analysis, thousands of studies have been done on functionally graded materials. One drawback of these studies is that they are mostly done theoretically and the results of their modeling are not compared with laboratory results although one can find some experimental results in the literature. One reason for not comparing with experimental results could be that these experimental results are buried under tons of theoretical results and do not appear to researchers at all. Our aim in this mini-review is to bring some of these experimental results on functionally graded materials to the showcase for the attention of researchers. The experimental results presented in this article are categorized as follow: a) axially layered FG structure b) axially continuous FG structure c) layered FG structure with variation of properties in the thickness direction d) continuous FG structure with variation of properties in the thickness direction e) FG nanocomposite.}
}

@article{doi:10.1068/p7275,
author = {Donald D Hoffman and Manish Singh},
title = {Computational Evolutionary Perception},
journal = {Perception},
volume = {41},
number = {9},
pages = {1073–1091},
year = {2012j},
doi = {10.1068/p7275},
note = {PMID:23409373},
URL = {https://doi-org.crai.referencistas.com/10.1068/p7275},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p7275},
abstract = {Marr proposed that human vision constructs “a true description of what is there”. He argued that to understand human vision one must discover the features of the world it recovers and the constraints it uses in the process. Bayesian decision theory (BDT) is used in modern vision research as a probabilistic framework for understanding human vision along the lines laid out by Marr. Marr’s contribution to vision research is substantial and justly influential. We propose, however, that evolution by natural selection does not, in general, favor perceptions that are true descriptions of the objective world. Instead, research with evolutionary games shows that perceptual systems tuned solely to fitness routinely outcompete those tuned to truth. Fitness functions depend not just on the true state of the world, but also on the organism, its state, and the type of action. Thus, fitness and truth are distinct. Natural selection depends only on expected fitness. It shapes perceptual systems to guide fitter behavior, not to estimate truth. To study perception in an evolutionary context, we introduce the framework of Computational Evolutionary Perception (CEP). We show that CEP subsumes BDT, and reinterprets BDT as evaluating expected fitness rather than estimating truth.}
}

@article{doi:10.1177/0306419015604432,
author = {KS Jithish and PV Ajay Kumar},
title = {Analysis of turbulent flow through an orifice meter using experimental and computational fluid dynamics simulation approach—A case study},
journal = {International Journal of Mechanical Engineering Education},
volume = {43},
number = {4},
pages = {233–246},
year = {2015k},
doi = {10.1177/0306419015604432},
URL = {https://doi-org.crai.referencistas.com/10.1177/0306419015604432},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0306419015604432},
abstract = {This paper describes the use of computational fluid dynamics in teaching graduate students who were in a four‐year B. Tech program. Many of these students did not have a good background in mathematics, fluid dynamics, heat transfer, and programming; however, most of them were good at computer‐aided design in ProE and were very interested in learning computational fluid dynamics as a design tool in industries. Solidworks flow simulator was chosen as the computational fluid dynamics software to teach students the entire computational fluid dynamics process in a single integrated software environment. Based on projects, computational fluid dynamics numerical methods and fundamentals of heat transfer and fluid flow were introduced to help students understand the computational fluid dynamics process, interpret, and validate simulation results. The computational fluid dynamics simulation of an orifice meter is given as the basic example for the students. Orifice meters are the most common equipment used for measuring fluid flow because of their simple mechanical structure, versatility, and low cost. In this paper, computational fluid dynamics simulation has been used to predict the orifice flow with better accuracy. Computational fluid dynamics simulations have been performed using solidworks flow simulator and validated with the data available in published literature. A new system has been proposed to accurately measure the flow using orifice metering systems.}
}

@article{doi:10.1177/1091142103254579,
author = {Marianne F. Johnson},
title = {Differential Taxation of for-Profit and Nonprofit Firms: A Computational General Equilibrium Approach},
journal = {Public Finance Review},
volume = {31},
number = {6},
pages = {623–647},
year = {2003l},
doi = {10.1177/1091142103254579},
URL = {https://doi-org.crai.referencistas.com/10.1177/1091142103254579},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1091142103254579},
abstract = {A small-scale computational general equilibrium model is used to examine the efficiency costs of exempting commercial nonprofits from the corporate income tax when they compete directly with for-profit firms. Simulation results from differential-incidence experiments indicate significant welfare gains when the tax wedge is reduced at the margin between the for-profit and nonprofit firms and the change in government revenue is financed by lump-sum taxes. However, although welfare gains exist at the margin, average excess burden estimates suggest that some level of differential taxation is welfare-improving if nonprofits contribute to the production of a good with positive externalities. Results are compared with those from the literature on the differential taxation of corporate and noncorporate firms and are found generally consistent.}
}

@article{doi:10.1243/095765005X31261,
author = {F Martelli and S Pazzi and V Michelassi},
title = {Automatic computational fluid dynamics-based procedure for the optimization of a centrifugal impeller},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {219},
number = {7},
pages = {549–557},
year = {2005m},
doi = {10.1243/095765005X31261},
URL = {https://doi-org.crai.referencistas.com/10.1243/095765005X31261},
eprint = {https://doi-org.crai.referencistas.com/10.1243/095765005X31261},
abstract = {Abstract A typical centrifugal impeller characterized by a low flow coefficient and cylindrical blades is redesigned by means of an intelligent automatic search program. The procedure consists of a feasible sequential quadratic programming algorithm (Fletcher, R. Practical Methods of optimization, 2000 (Wiley)) coupled to a lazy learning (LL) interpolator 1 to speed-up the process. The program is able to handle geometric constraints to reduce the computational effort devoted to the analysis of non-physical configurations. The objective function evaluator is an in-house developed structured computational fluid dynamics (CFD) code. The LL approx-imator is called each time the stored database can provide a sufficiently accurate performance estimate for a given geometry, thus reducing the effective CFD computations. The impeller is represented by 25 geometric parameters describing the vane in the meridional and s-0 planes, the blade thickness, and the leading edge shape. The optimization is carried out on the impeller design point maximizing the polytropic efficiency with nearly constant flow coefficient and polytropic head. The optimization is accomplished by maintaining unaltered those geometrical parameters which have to be kept fixed in order to make the impeller fit the original stage. The optimization, carried out on a cluster of 16 PCs, is self-learning and leads to a geometry presenting an increased design point efficiency. The program is completely general and can be applied to any component which can be described by a finite number of geometrical parameters and computed by any numerical instrument to provide performance indices. The work presented in this paper was done under the METHOD EC funded project for the implementation of new technologies for optimization of centrifugal compressors.}
}

@article{doi:10.1177/0954406217737104,
author = {Niloufar Motazedi and Matthew P Cartmell and Jem A Rongong},
title = {Extending the functionality of a symbolic computational dynamic solver by using a novel term-tracking method},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {232},
number = {19},
pages = {3439–3452},
year = {2018n},
doi = {10.1177/0954406217737104},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954406217737104},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954406217737104},
abstract = {Symbolic computational dynamic solvers are currently under development in order to provide new and powerful tools for modelling nonlinear dynamical systems. Such solvers consist of two parts; the core solver, which comprises an approximate analytical method based on perturbation, averaging, or harmonic balance, and a specialised term-tracker. A term-tracking approach has been introduced to provide a powerful new feature into computational approximate analytical solutions by highlighting the many mathematical connections that exist, but which are invariably lost through processing, between the physical model of the system, the solution procedure itself, and the final result which is usually expressed in equation form. This is achieved by a highly robust process of term-tracking, recording, and identification of all the symbolic mathematical information within the problem. In this paper, the novel source and evolution encoding method is introduced for the first time and an implementation in Mathematica is described through the development of a specialised algorithm.}
}

@article{doi:10.1177/0956797618823540,
author = {Conrad Perry and Marco Zorzi and Johannes C. Ziegler},
title = {Understanding Dyslexia Through Personalized Large-Scale Computational Models},
journal = {Psychological Science},
volume = {30},
number = {3},
pages = {386–395},
year = {2019o},
doi = {10.1177/0956797618823540},
note = {PMID:30730792},
URL = {https://doi-org.crai.referencistas.com/10.1177/0956797618823540},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0956797618823540},
abstract = {Learning to read is foundational for literacy development, yet many children in primary school fail to become efficient readers despite normal intelligence and schooling. This condition, referred to as developmental dyslexia, has been hypothesized to occur because of deficits in vision, attention, auditory and temporal processes, and phonology and language. Here, we used a developmentally plausible computational model of reading acquisition to investigate how the core deficits of dyslexia determined individual learning outcomes for 622 children (388 with dyslexia). We found that individual learning trajectories could be simulated on the basis of three component skills related to orthography, phonology, and vocabulary. In contrast, single-deficit models captured the means but not the distribution of reading scores, and a model with noise added to all representations could not even capture the means. These results show that heterogeneity and individual differences in dyslexia profiles can be simulated only with a personalized computational model that allows for multiple deficits.}
}

@article{doi:10.2190/EC.44.4.a,
author = {P. G. Schrader and Kimberly A. Lawless},
title = {Research on Immersive Environments and 21st Century Skills: an Introduction to the Special Issue},
journal = {Journal of Educational Computing Research},
volume = {44},
number = {4},
pages = {385–390},
year = {2011p},
doi = {10.2190/EC.44.4.a},
URL = {https://doi-org.crai.referencistas.com/10.2190/EC.44.4.a},
eprint = {https://doi-org.crai.referencistas.com/10.2190/EC.44.4.a}
}

@article{doi:10.1177/19458924221137982,
author = {Praween Senanayake and Patrick Warfield-McAlpine and Hana Salati and Kimberley Bradshaw and Eugene Wong and Kiao Inthavong and Narinder Singh},
title = {The Impact of Adhesions on Nasal Airflow: A Quantitative Analysis Using Computational Fluid Dynamics},
journal = {American Journal of Rhinology & Allergy},
volume = {37},
number = {3},
pages = {273–283},
year = {2023q},
doi = {10.1177/19458924221137982},
note = {PMID:36373577},
URL = {https://doi-org.crai.referencistas.com/10.1177/19458924221137982},
eprint = {https://doi-org.crai.referencistas.com/10.1177/19458924221137982},
abstract = {Background Nasal adhesions (NAs) are a known complication of nasal airway surgery. Even minor NAs can lead to significant postoperative nasal airway obstruction (NAO). Division of such NAs often provides much greater relief than anticipated. Objective We examine the impact of NAs at various anatomical sites on nasal airflow and mucosal cooling using computational fluid dynamics (CFD) and multiple test subjects. Methods CT scans of healthy adult subjects were used to construct three-dimensional nasal airway computational models. A single virtual 2.5 mm diameter NA was placed at one of five sites commonly seen following NAO surgery within each nasal cavity bilaterally, resulting in 10 NA models and 1 NA-free control for each subject. CFD analysis was performed on each NA model and compared with the subject’s NA-free control model. Results 4 subjects were recruited to create 44 computational models. The NAs caused the airflow streamlines to separate, leading to a statistically significant increase in mucosal temperature immediately downstream to the NAs (wake region). Changes in the mucosal temperature in the wake region of the NAs were most prominent in anteriorly located NAs with a mean increase of 1.62 °C for the anterior inferior turbinate NAs (P < .001) and 0.63 °C for the internal valve NAs (P < .001). Conclusion NAs result in marked disruption to airflow patterns and reduced mucosal cooling on critical surfaces, particularly in the wake region. Reduced wake region mucosal cooling may be a contributing factor to the exaggerated perception of nasal obstruction experienced by patients with NAs.}
}

@article{doi:10.1177/0002716215569220,
author = {Dhavan V. Shah and Alex Hanna and Erik P. Bucy and Chris Wells and Vidal Quevedo},
title = {The Power of Television Images in a Social Media Age: Linking Biobehavioral and Computational Approaches via the Second Screen},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {225–245},
year = {2015r},
doi = {10.1177/0002716215569220},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
abstract = {There is considerable controversy surrounding the study of presidential debates, particularly efforts to connect their content and impact. Research has long debated whether the citizenry reacts to what candidates say, how they say it, or simply how they appear. This study uses detailed coding of the first 2012 debate between Barack Obama and Mitt Romney to test the relative influence of the candidates’ verbal persuasiveness and nonverbal features on viewers’ “second screen” behavior—their use of computers, tablets, and mobile phones to enhance or extend the televised viewing experience. To examine these relationships, we merged two datasets: (1) a shot-by-shot content analysis coded for functional, tonal, and visual elements of both candidates’ communication behavior during the debate; and (2) corresponding real-time measures, synched and lagged, of the volume and sentiment of Twitter expression about Obama and Romney. We find the candidates’ facial expressions and physical gestures to be more consistent and robust predictors of the volume and valence of Twitter expression than candidates’ persuasive strategies, verbal utterances, and voice tone during the debate.}
}

@article{doi:10.1068/p7327,
author = {William H Warren},
title = {Does This Computational Theory Solve the Right Problem? Marr, Gibson, and the Goal of Vision},
journal = {Perception},
volume = {41},
number = {9},
pages = {1053–1060},
year = {2012s},
doi = {10.1068/p7327},
note = {PMID:23409371},
URL = {https://doi-org.crai.referencistas.com/10.1068/p7327},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p7327},
abstract = {David Marr’s book Vision attempted to formulate a thoroughgoing formal theory of perception. Marr borrowed much of the “computational” level from James Gibson: a proper understanding of the goal of vision, the natural constraints, and the available information are prerequisite to describing the processes and mechanisms by which the goal is achieved. Yet, as a research program leading to a computational model of human vision, Marr’s program did not succeed. This article asks why, using the perception of 3D shape as a morality tale. Marr presumed that the goal of vision is to recover a general-purpose Euclidean description of the world, which can be deployed for any task or action. On this formulation, vision is underdetermined by information, which in turn necessitates auxiliary assumptions to solve the problem. But Marr’s assumptions did not actually reflect natural constraints, and consequently the solutions were not robust. We now know that humans do not in fact recover Euclidean structure—rather, they reliably perceive qualitative shape (hills, dales, courses, ridges), which is specified by the second-order differential structure of images. By recasting the goals of vision in terms of our perceptual competencies, and doing the hard work of analyzing the information available under ecological constraints, we can reformulate the problem so that perception is determined by information and prior knowledge is unnecessary.}
}

@article{doi:10.1177/1059712317726357,
author = {Philipp Zech and Simon Haller and Safoura Rezapour Lakani and Barry Ridge and Emre Ugur and Justus Piater},
title = {Computational models of affordance in robotics: a taxonomy and systematic classification},
journal = {Adaptive Behavior},
volume = {25},
number = {5},
pages = {235–271},
year = {2017t},
doi = {10.1177/1059712317726357},
URL = {https://doi-org.crai.referencistas.com/10.1177/1059712317726357},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1059712317726357},
abstract = {J. J. Gibson’s concept of affordance, one of the central pillars of ecological psychology, is a truly remarkable idea that provides a concise theory of animal perception predicated on environmental interaction. It is thus not surprising that this idea has also found its way into robotics research as one of the underlying theories for action perception. The success of the theory in this regard has meant that existing research is both abundant and diffuse by virtue of the pursuit of multiple different paths and techniques with the common goal of enabling robots to learn, perceive, and act upon affordances. Up until now, there has existed no systematic investigation of existing work in this field. Motivated by this circumstance, in this article, we begin by defining a taxonomy for computational models of affordances rooted in a comprehensive analysis of the most prominent theoretical ideas of import in the field. Subsequently, after performing a systematic literature review, we provide a classification of existing research within our proposed taxonomy. Finally, by both quantitatively and qualitatively assessing the data resulting from the classification process, we highlight gaps in the research terrain and outline open questions for the investigation of affordances in robotics that we believe will help inform future work, prioritize research goals, and potentially advance the field toward greater robot autonomy.}
}

