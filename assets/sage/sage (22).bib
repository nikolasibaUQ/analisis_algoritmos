@article{doi:10.1177/20552076221111941,
author = {Azadeh Akhavanallaf and Hadi Fayad and Yazdan Salimi and Antar Aly and Hassan Kharita and Huda Al Naemi and Habib Zaidi},
title = {An update on computational anthropomorphic anatomical models},
journal = {DIGITAL HEALTH},
volume = {8},
number = { },
pages = {20552076221111940},
year = {2022a},
doi = {10.1177/20552076221111941},
note = {PMID:35847523},
URL = {https://doi-org.crai.referencistas.com/10.1177/20552076221111941},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20552076221111941},
abstract = {The prevalent availability of high-performance computing coupled with validated computerized simulation platforms as open-source packages have motivated progress in the development of realistic anthropomorphic computational models of the human anatomy. The main application of these advanced tools focused on imaging physics and computational internal/external radiation dosimetry research. This paper provides an updated review of state-of-the-art developments and recent advances in the design of sophisticated computational models of the human anatomy with a particular focus on their use in radiation dosimetry calculations. The consolidation of flexible and realistic computational models with biological data and accurate radiation transport modeling tools enables the capability to produce dosimetric data reflecting actual setup in clinical setting. These simulation methodologies and results are helpful resources for the medical physics and medical imaging communities and are expected to impact the fields of medical imaging and dosimetry calculations profoundly.}
}

@article{doi:10.1177/0162353211416437,
author = {David Yun Dai},
title = {Hopeless Anarchy or Saving Pluralism? Reflections on Our Field in Response to Ambrose, VanTassel-Baska, Coleman, and Cross},
journal = {Journal for the Education of the Gifted},
volume = {34},
number = {5},
pages = {705–730},
year = {2011b},
doi = {10.1177/0162353211416437},
URL = {https://doi-org.crai.referencistas.com/10.1177/0162353211416437},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0162353211416437},
abstract = {In this response to Ambrose, VanTassel-Baska, Coleman, and Cross’s (2010) thought-provoking article on the nature and state of the field of gifted education, the author first discusses the role of disciplinary knowledge in his field. He argues that gifted education, as a normative and practical endeavor (i.e., a profession), is different from academic disciplines in research agendas and that technical rationality is not sufficient for identifying its “best practice.” The author then suggests a “flat” structure to facilitate close collaboration between theorists, researchers, and practitioners in tackling pressing problems and fashioning innovative practices. To facilitate discussion of explorations in our practice, he delineates three basic service models or paradigms in gifted education as follows: the gifted child paradigm, the talent development paradigm, and the differentiation paradigm. He proposes five criteria for assessing their strengths and potential weaknesses. Finally, he suggests that the best way of providing evidence-based best practice is through use-inspired, design studies, which not only address the question of whether a practical model works but also specify goals, assumptions, resources, processes, and constraints involved so that “how it works” is made transparent.}
}

@article{doi:10.1177/0036850419873799c,
author = {Walid El-Sharoud},
title = {Book Review: Hector J. Levesque, Thinking as computation},
journal = {Science Progress},
volume = {102},
number = {3},
pages = {279–279},
year = {2019c},
doi = {10.1177/0036850419873799c},
URL = {https://doi-org.crai.referencistas.com/10.1177/0036850419873799c},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0036850419873799c}
}

@article{doi:10.1177/0735633120945935,
author = {Yue Hu and Cheng-Huan Chen and Chien-Yuan Su},
title = {Exploring the Effectiveness and Moderators of Block-Based Visual Programming on Student Learning: A Meta-Analysis},
journal = {Journal of Educational Computing Research},
volume = {58},
number = {8},
pages = {1467–1493},
year = {2021d},
doi = {10.1177/0735633120945935},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
abstract = {Block-based visual programming tools, such as Scratch, Alice, and MIT App Inventor, provide an intuitive and easy-to-use editing interface through which to promote programming learning for novice students of various ages. However, very little attention has been paid to investigating these tools’ overall effects on students’ academic achievement and the study features that may moderate the effects of block-based visual programming from a comprehensive perspective. Thus, the present study carried out a meta-analysis to systemically examine 29 empirical studies (extracting 34 effect sizes) using experimental or quasi-experiments involving the programming learning effects of employing block-based visual programming tools to date (until the end of 2019). The results showed a small to medium significant positive overall mean effect size (fixed-effect model g = 0.37; random-effects model g = 0.47) of the use of these block-based visual programming tools with respect to students’ academic achievement. Furthermore, the overall mean effect size was significantly affected by the educational stage, programming tool used, experimental treatment, and school location. Discussions and implications based on the findings are provided.}
}

@article{doi:10.1177/2378023119849803,
author = {David M. Liu and Matthew J. Salganik},
title = {Successes and Struggles with Computational Reproducibility: Lessons from the Fragile Families Challenge},
journal = {Socius},
volume = {5},
number = { },
pages = {2378023119849803},
year = {2019e},
doi = {10.1177/2378023119849803},
URL = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
abstract = {Reproducibility is fundamental to science, and an important component of reproducibility is computational reproducibility: the ability of a researcher to recreate the results of a published study using the original author’s raw data and code. Although most people agree that computational reproducibility is important, it is still difficult to achieve in practice. In this article, the authors describe their approach to enabling computational reproducibility for the 12 articles in this special issue of Socius about the Fragile Families Challenge. The approach draws on two tools commonly used by professional software engineers but not widely used by academic researchers: software containers (e.g., Docker) and cloud computing (e.g., Amazon Web Services). These tools made it possible to standardize the computing environment around each submission, which will ease computational reproducibility both today and in the future. Drawing on their successes and struggles, the authors conclude with recommendations to researchers and journals.}
}

@article{doi:10.1177/0954410016671343,
author = {Long Liu and Hongda Li and Haisong Ang and Tianhang Xiao},
title = {Numerical investigation of flexible flapping wings using computational fluid dynamics/computational structural dynamics method},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {232},
number = {1},
pages = {85–95},
year = {2018f},
doi = {10.1177/0954410016671343},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410016671343},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410016671343},
abstract = {A fluid–structure interaction numerical simulation was performed to investigate the flow field around a flexible flapping wing using an in-house developed computational fluid dynamics/computational structural dynamics solver. The three-dimensional (3D) fluid–structure interaction of the flapping locomotion was predicted by loosely coupling preconditioned Navier–Stokes solutions and non-linear co-rotational structural solutions. The computational structural dynamic solver was specifically developed for highly flexible flapping wings by considering large geometric non-linear characteristics. The high fidelity of the developed methodology was validated by benchmark tests. Then, an analysis of flexible flapping wings was carried out with a specific focus on the unsteady aerodynamic mechanisms and effects of flexion on flexible flapping wings. Results demonstrate that the flexion will introduce different flow fields, and thus vary thrust generation and pressure distribution significantly. In the meanwhile, relationship between flapping frequency and flexion plays an important role on efficiency. Therefore, appropriate combination of frequency and flexion of flexible flapping wings provides higher efficiency. This study may give instruction for further design of flexible flapping wings.}
}

@article{doi:10.3233/IA-2011-0017,
author = {Paolo Mancarella and Francesca Toni},
title = {Computational logic in agent based systems},
journal = {Intelligenza Artificiale},
volume = {5},
number = {1},
pages = {139–143},
year = {2011g},
doi = {10.3233/IA-2011-0017},
URL = {https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017},
eprint = {https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017},
abstract = {We describe recent work on the deployment of computational logic to support the formalisation and implementation of agents in multi-agent systems. Several forms of computational logic systems are needed in this setting, including abductive, argumentative and preference-based systems. We briefly sketch the agent model called KGP, and an ongoing extension of it which is needed to model agents in distributed settings such as the Grid and, more generally, Service-Oriented Architectures.}
}

@article{doi:10.1177/2053951716670190,
author = {Daniel Marciniak},
title = {Computational text analysis: Thoughts on the contingencies of an evolving method},
journal = {Big Data & Society},
volume = {3},
number = {2},
pages = {2053951716670190},
year = {2016h},
doi = {10.1177/2053951716670190},
URL = {https://doi-org.crai.referencistas.com/10.1177/2053951716670190},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2053951716670190},
abstract = {Mapping a public discourse with the tools of computational text analysis comes with many contingencies in the areas of corpus curation, data processing and analysis, and visualisation. However, the complexity of algorithmic assemblies and the beauty of resulting images give the impression of ‘objectivity’. Instead of concealing uncertainties and artefacts in order to tell a coherent and all-encompassing story, retaining the variety of alternative assemblies may actually strengthen the method. By utilising the mobility of digital devices, we could create mutable mobiles that allow access to our laboratories and enable challenging rearrangements and interpretations.}
}

@article{doi:10.1177/0306419019838880,
author = {Steven A E Miller},
title = {A contemporary course on the introduction to computational fluid dynamics},
journal = {International Journal of Mechanical Engineering Education},
volume = {48},
number = {4},
pages = {315–334},
year = {2020i},
doi = {10.1177/0306419019838880},
URL = {https://doi-org.crai.referencistas.com/10.1177/0306419019838880},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0306419019838880},
abstract = {The University of Florida Department of Mechanical and Aerospace Engineering recently created a new senior technical elective in the field of computational fluid dynamics. The main objectives of the class are learning the process of computational fluid dynamics, skepticism, a course project that uses a popular commercial solver, and a course project that involves programming a simplified computational fluid dynamics code. The course covers introductory material, history, grid generation, numerics, equations of motion, boundary conditions, solvers, turbulence models, visualization, and a number of special topics. Skepticism is enforced throughout the course and forces students to justify the validity of their approach and question numerically generated results. Students in the class undertake a course project to predict a fundamental flow-field and compare predictions with excellent measurements from the open literature. They must also create a simplified computational fluid dynamics code to predict turbulent boundary layer flow. Students have integrated these lessons within student groups across the University of Florida. The emphasis of the course is on skepticism and increasing integration with the curriculum and student group activities. We present the class philosophy for teaching undergraduate computational fluid dynamics and the outcomes of the newly developed course.}
}

@article{doi:10.1177/07356331241240047,
author = {Monika Mladenović and Žana Žanko and Goran Zaharija},
title = {From Blocks to Text: Bridging Programming Misconceptions},
journal = {Journal of Educational Computing Research},
volume = {62},
number = {5},
pages = {1302–1326},
year = {2024j},
doi = {10.1177/07356331241240047},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331241240047},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331241240047},
abstract = {The use of a pedagogical approach mediated transfer with the bridging method has been successful in facilitating the transitions from block-based to text-based programming languages. Nevertheless, there is a lack of research addressing the impact of this transfer on programming misconceptions during the transition. The way programming concepts are taught to K-12 learners can later result in misconceptions for adult learners. The main objective was to examine the impact of mediated transfer using the bridging method pedagogical approach on the prevalence of programming misconceptions. We conducted a quasi-experimental study in school settings during informatics (computer science) classes among 163 sixth-grade students. The control group received traditional programming lectures using the text-based programming language, Python. Conversely, the experimental group utilized a mediated transfer pedagogical approach by starting with the block-based programming language MakeCode for micro:bit before transitioning to the text-based Python. Our findings indicate that the experimental group significantly reduced programming misconceptions in fundamental programming concepts: variables, sequencing, selection, and loops - compared to the control group. This suggests that the use of block-based programming language as an initial step in programming education, followed by a structured transition to text-based programming language, can effectively mitigate common misconceptions among K-12 learners.}
}

@article{doi:10.1179/030801803225010340,
author = {Roddam Narasimha},
title = {The Indian half of Needham’s question: some thoughts on axioms, models, algorithms, and computational positivism},
journal = {Interdisciplinary Science Reviews},
volume = {28},
number = {1},
pages = {54–66},
year = {2003k},
doi = {10.1179/030801803225010340},
URL = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
eprint = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
abstract = {Much debate has taken place on Joseph Needham’s question regarding ‘the failure of China and India to give rise to distinctively modern science while being ahead of Europe for fourteen previous centuries’. It is argued in this paper that while there is probably some truth in many of the sociocultural explanations that have been offered for the failure in India, they are in the final analysis not entirely convincing. The proposal in this paper is in two parts. The first is that the scientific revolution, which was part of a European miracle, was triggered in part by the advent of a variety of technologies from China and the new numeral system and other mathematical inventions from India - both via creative West Asian intermediaries. India had experienced a mathematical (more specifically algoristic or computational) revolution heralded by Ārya-bhata in the fifth century CE. The new computational power unleashed by this revolution combined with the classical Greek penchant for axiomatised modelmaking and a technology empowered experimental philosophy, in what appears to have been a very creative and uniquely European cultural fusion that led to the scientific (and later the industrial) revolution. The second part of the proposal is that there was an epistemological reason why the Indian mathematical revolution did not lead to a corresponding ‘distinctively modern’ scientific one. The Indic approach was basically not that of modelmakers but of ingenious algorisers, and showed a deep and studied distrust of axioms and physical models. This led to an attitude described here as ‘computational positivism’, which considers observation and computation as the only things that matter. In retrospect, that distrust appears not unjustified, especially in the light of twentieth century developments in quantum and classical mechanics and in logic; but it was historically expensive for India, as Europe achieved unreasonably and unexpectedly spectacular successes in science. To the Indians, it was Newton who was the extraordinary epistemological revolutionary, not Heisenberg or Gödel. In summary, Indian science could not move forward without the modelmaking and technology enabled experimental abilities that grew in the West, just as European modelmaking had earlier been unable to progress without the advent of powerful technologies and computational tools whose roots can be traced to China and India.}
}

@article{doi:10.1177/13675494231164874,
author = {Leona Nikolić},
title = {ECS-Ecrea Early Career Scholar Prize winner - An astrological genealogy of artificial intelligence: From ‘pseudo-sciences’ of divination to sciences of prediction},
journal = {European Journal of Cultural Studies},
volume = {26},
number = {2},
pages = {131–146},
year = {2023l},
doi = {10.1177/13675494231164874},
URL = {https://doi-org.crai.referencistas.com/10.1177/13675494231164874},
eprint = {https://doi-org.crai.referencistas.com/10.1177/13675494231164874},
abstract = {Algorithmic media have adopted and adapted divinatory practices and vernaculars of prediction, prophecy, probability, fortune-telling and forecasting – suggesting a possible link between artificial intelligence and pre-scientific modes of speculation. Statistical thinking and magical thinking, too, can be recognised as closely correlated epistemological systems for governing societies and ways of life. In fact, primitive astrological practices of looking up at the stars may represent one of the earliest statistical projects involving sophisticated calculations and data sets. Such pattern-making techniques could even be considered precursory to machine learning. As a point of departure for exploring these eclectic relationships between stars and data, magic and machines, I use a media archaeological methodology to question the historical roles of both astrological and computational divination in mediating methods of control, surveillance and knowledge production across transforming societal contexts. This methodology is especially relevant for examining historical narratives in the field of cultural studies as it makes apparent the hyper-connectedness between objects, cultural representation and sites of hegemonic contention. My findings reveal relationships between celestial pattern recognition and efforts to exert control over and manipulate the natural environment and its populations, the historical impact of meteorological and climatological practices for predicting and influencing future events with artificial intelligence, and links between statistics and algorithmic data biases. This article suggests a speculative genealogy of astrology and artificial intelligence, as well as a genealogy of the theological, scientific and machinic unconscious.}
}

@article{doi:10.1177/1094342004048538,
author = {Robert W. Numrich},
title = {Performance Metrics Based on Computational Action},
journal = {The International Journal of High Performance Computing Applications},
volume = {18},
number = {4},
pages = {449–458},
year = {2004m},
doi = {10.1177/1094342004048538},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342004048538},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342004048538},
abstract = {We propose a new performance metric based on computational action. We examine work as it evolves in time and compute computational action as the integral of the work function over time. We compare the action generated at less than full power with the action that could have been generated at full power. We claim that the goal of performance optimization is to minimize lost, or wasted, action. We calculate our metric for some computers in the Top500 list (http://www.top500.org) and propose a new ranking based on least action wasted. When work is a function of the resources applied, we use the classical techniques of the calculus of variations to minimize wasted action. From the result of this exercise, we calculate productivity as the ratio of work produced to resources used.}
}

@article{doi:10.1177/0002716215569446,
author = {Matthew Brook O’Donnell and Emily B. Falk},
title = {Big Data under the Microscope and Brains in Social Context: Integrating Methods from Computational Social Science and Neuroscience},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {274–289},
year = {2015n},
doi = {10.1177/0002716215569446},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
abstract = {Methods for analyzing neural and computational social science data are usually used by different types of scientists and generally seen as distinct, but they strongly complement one another. Computational social science methodologies can strengthen and contextualize individual-level analysis, specifically our understanding of the brain. Neuroscience can help to unpack the mechanisms that lead from micro- through meso- to macro-level observations. Integrating levels of analysis is essential to unified progress in social research. We present two example areas that illustrate this integration. First, combining egocentric social network data with neural variables from the “egos” provides insight about why and for whom certain types of antismoking messages may be more or less effective. Second, combining tools from natural language processing with neuroimaging reveals mechanisms involved in successful message propagation, and suggests links from microscopic to macroscopic scales.}
}

@article{doi:10.1177/1086296X231202722,
author = {Bradley Robinson},
title = {You Will Perish: A Case Study of Serendipitous Literacies and Novice Video Game Design},
journal = {Journal of Literacy Research},
volume = {55},
number = {3},
pages = {275–301},
year = {2023o},
doi = {10.1177/1086296X231202722},
URL = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
abstract = {This study focused on the digital design practices of Raul, a 15-year-old participant at a summer video game design camp for adolescents. As Raul developed his original game, You Will Perish, I wondered what his design process might reveal about (a) the practice of affectively and procedurally literate video game design and (b) the literacy pedagogies that can support such design. Guided by the concept of serendipity, I describe Raul’s design practice as an open process characterized by bouts of failure, chance, and discovery, and I examine how such forces shaped the emergence of his game. Using transversal analysis, I trace Raul’s design through an account of frustration and failure, perseverance and pride, showing how the challenges of the game’s creator become those of the game’s players. The study highlights the generative potential of serendipitous literacies wherever and whenever literacy happens.}
}

@article{doi:10.1179/0308018812Z.0000000006,
author = {Matt Spencer},
title = {Image and Practice: Visualization in Computational Fluid Dynamics Research},
journal = {Interdisciplinary Science Reviews},
volume = {37},
number = {1},
pages = {86–100},
year = {2012p},
doi = {10.1179/0308018812Z.0000000006},
URL = {https://doi-org.crai.referencistas.com/10.1179/0308018812Z.0000000006},
eprint = {https://doi-org.crai.referencistas.com/10.1179/0308018812Z.0000000006},
abstract = {In this study I examine the use of visualization within everyday research practices in computational physics. In doing so, I attempt to move from the well documented representational issues elicited by the concept of the image, to more microscale issues of the habitual structuring of the everyday that emerge when a specific example of science in the making is analysed. To this end, I focus on one specific example, of tracing a computational error through a fluid dynamics simulation of the ‘lock exchange’ experiment. This simulation is one small part of the research that goes on within one of Europe’s largest computational physics research groups, the Applied Modelling and Computation Group at Imperial College in London, where I am involved in ongoing ethnographic fieldwork research. Visualization is shown to play a central role, not just in daily routines of investigation and problem solving, but in the process of habituation through which scientists cultivate the dispositions through which everyday life gains its texture and form. Far from being a detachable representation of a part of a world, simulation is shown to come into being as a process within a world structured by the repetitions and improvizations that characterize research practice.}
}

@article{doi:10.1177/2167702614565359,
author = {Thomas V. Wiecki and Jeffrey Poland and Michael J. Frank},
title = {Model-Based Cognitive Neuroscience Approaches to Computational Psychiatry: Clustering and Classification},
journal = {Clinical Psychological Science},
volume = {3},
number = {3},
pages = {378–399},
year = {2015q},
doi = {10.1177/2167702614565359},
URL = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
abstract = {Psychiatric research is in crisis. We highlight efforts to overcome current challenges by focusing on the emerging field of computational psychiatry, which might enable the field to move from a symptom-based description of mental illness to descriptors based on objective computational multidimensional functional variables. We survey recent efforts toward this goal and describe a set of methods that together form a toolbox to aid this research program. We identify four levels in computational psychiatry: (a) behavioral tasks that index various psychological processes, (b) computational models that identify the generative psychological processes, (c) parameter-estimation methods concerned with quantitatively fitting these models to subject behavior by focusing on hierarchical Bayesian estimation as a rich framework with many desirable properties, and (d) machine-learning clustering methods that identify clinically significant conditions and subgroups of individuals. As a proof of principle, we apply these methods to two different data sets. Finally, we highlight challenges for future research.}
}

@article{doi:10.1177/0002716215570576,
author = {Rodrigo Zamith and Seth C. Lewis},
title = {Content Analysis and the Algorithmic Coder: What Computational Social Science Means for Traditional Modes of Media Analysis},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {307–318},
year = {2015r},
doi = {10.1177/0002716215570576},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215570576},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215570576},
abstract = {To deal with ever-larger datasets, media scholars are increasingly using computational analytic methods. This article focuses on how the traditional (manual) approach to conducting a content analysis—a primary method in the study of media messages—is being reconfigured, assesses what is gained and lost in turning to computational solutions, and builds on a “hybrid” approach to content analysis. We argue that computational methods are most fruitful when variables are readily identifiable in texts and when source material is easily parsed. Manual methods, though, are most appropriate for complex variables and when source material is not well digitized. These modes can be effectively combined throughout the process of content analysis to facilitate expansive and powerful analyses that are reliable and meaningful.}
}

@article{doi:10.1177/15485129211073612,
author = {Koen van der Zwet and Ana I Barros and Tom M van Engers and Peter M A Sloot},
title = {Promises and pitfalls of computational modelling for insurgency conflicts},
journal = {The Journal of Defense Modeling and Simulation},
volume = {20},
number = {3},
pages = {333–350},
year = {2023s},
doi = {10.1177/15485129211073612},
URL = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
eprint = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
abstract = {Insurgency conflicts pose significant challenges to societies globally. The increase of insurgency conflicts creates a need to understand how insurgencies arise, and to identify societal drivers of insurgencies or effective strategies to counter them. In this paper, we analyze the contributions of computational modeling methods for the analysis of insurgent conflicts. We formalize a specific literature-based analysis framework using the identified key factors and drivers, which enables the evaluation of specific models in this domain. Through a systematic literature search, we identify 64 computational models to apply our framework. We highlight the development and contributions of various methodologies through an in-depth analysis of 13 high-quality models. The evaluation of these computational models revealed promising directions and future topics to design specific simulation models for all identified factors. In addition, our analysis revealed specific pitfalls concerning validity issues for each of the modeling methods.}
}

@article{doi:10.2190/EC.49.4.g,
title = {Journal of Educational Computing Research Index—Contents of Volume 49, 2013},
journal = {Journal of Educational Computing Research},
volume = {49},
number = {4},
pages = {543–545},
year = {2013t},
doi = {10.2190/EC.49.4.g},
URL = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g},
eprint = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g}
}

