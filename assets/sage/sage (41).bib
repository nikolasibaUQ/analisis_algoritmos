@article{doi:10.1243/09576509JPE368,
author = {M A R Sadiq Al-Baghdadi and H A K Shahad Al-Janabi},
title = {Prediction of hygro—thermal stress distribution in proton exchange membranes using a three-dimensional multi-phase computational fluid dynamics model},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {221},
number = {7},
pages = {941–953},
year = {2007a},
doi = {10.1243/09576509JPE368},
URL = {https://doi-org.crai.referencistas.com/10.1243/09576509JPE368},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09576509JPE368},
abstract = {Abstract A three-dimensional, multi-phase, non-isothermal computational fluid dynamics model of a proton exchange membrane fuel cell has been developed to simulate the hygro and thermal stresses in polymer membrane, which developed during the cell operation. The behaviour of the membrane during the operation of a unit cell has been studied and investigated. The model accounts for both gas and liquid phase in the same computational domain, and thus allows for the implementation of phase change inside the gas diffusion layers. The model includes the transport of gaseous species, liquid water, protons, energy, and water dissolved in the ion-conducting polymer. The new feature of the present model is to incorporate the effect of hygro and thermal stresses into actual three-dimensional, multi-phase, non-isothermal fuel cell model. In addition to hygro—thermal stresses, the model features an algorithm that allows for a more realistic representation of the local activation overpotentials, which leads to improved prediction of the local current density distribution in high accuracy, and therefore, high accuracy prediction of temperature distribution in the cell and then thermal stresses. This model also takes into account convection and diffusion of different species in the channels as well as in the porous gas diffusion layer, heat transfer in the solids as well as in the gases, and electrochemical reactions.}
}

@article{doi:10.1177/0954411920923253,
author = {Karol Calò and Giuseppe De Nisco and Diego Gallo and Claudio Chiastra and Ayla Hoogendoorn and David A Steinman and Stefania Scarsoglio and Jolanda J Wentzel and Umberto Morbiducci},
title = {Exploring wall shear stress spatiotemporal heterogeneity in coronary arteries combining correlation-based analysis and complex networks with computational hemodynamics},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {234},
number = {11},
pages = {1209–1222},
year = {2020b},
doi = {10.1177/0954411920923253},
note = {PMID:32460666},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954411920923253},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954411920923253},
abstract = {Atherosclerosis at the early stage in coronary arteries has been associated with low cycle-average wall shear stress magnitude. However, parallel to the identification of an established active role for low wall shear stress in the onset/progression of the atherosclerotic disease, a weak association between lesions localization and low/oscillatory wall shear stress has been observed. In the attempt to fully identify the wall shear stress phenotype triggering early atherosclerosis in coronary arteries, this exploratory study aims at enriching the characterization of wall shear stress emerging features combining correlation-based analysis and complex networks theory with computational hemodynamics. The final goal is the characterization of the spatiotemporal and topological heterogeneity of wall shear stress waveforms along the cardiac cycle. In detail, here time-histories of wall shear stress magnitude and wall shear stress projection along the main flow direction and orthogonal to it (a measure of wall shear stress multidirectionality) are analyzed in a representative dataset of 10 left anterior descending pig coronary artery computational hemodynamics models. Among the main findings, we report that the proposed analysis quantitatively demonstrates that the model-specific inlet flow-rate shapes wall shear stress time-histories. Moreover, it emerges that a combined effect of low wall shear stress magnitude and of the shape of the wall shear stress–based descriptors time-histories could trigger atherosclerosis at its earliest stage. The findings of this work suggest for new experiments to provide a clearer determination of the wall shear stress phenotype which is at the basis of the so-called arterial hemodynamic risk hypothesis in coronary arteries.}
}

@article{doi:10.1177/20539517221080146,
author = {Hjalmar Bang Carlsen and Snorre Ralund},
title = {Computational grounded theory revisited: From computer-led to computer-assisted text analysis},
journal = {Big Data & Society},
volume = {9},
number = {1},
pages = {20539517221080144},
year = {2022c},
doi = {10.1177/20539517221080146},
URL = {https://doi-org.crai.referencistas.com/10.1177/20539517221080146},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20539517221080146},
abstract = {The size and variation in both meaning-making and populations that characterize much contemporary text data demand research processes that support both discovery, interpretation and measurement. We assess one dominant strategy within the social sciences that takes a computer-led approach to text analysis. The approach is coined computational grounded theory. This strategy, we argue, relies on a set of unwarranted assumptions, namely, that unsupervised models return natural clusters of meaning, that the researcher can understand text with limited immersion and that indirect validation is sufficient for ensuring unbiased and precise measurement. In response to this criticism, we develop a framework that is computer assisted. We argue that our reformulation of computational grounded theory better aligns with the principles within grounded theory, anthropological theory generation and ethnography.}
}

@article{doi:10.1177/1045389X13517314,
author = {A K Chaurasia and G D Seidel},
title = {Computational micromechanics analysis of electron-hopping-induced conductive paths and associated macroscale piezoresistive response in carbon nanotube–polymer nanocomposites},
journal = {Journal of Intelligent Material Systems and Structures},
volume = {25},
number = {17},
pages = {2141–2164},
year = {2014d},
doi = {10.1177/1045389X13517314},
URL = {https://doi-org.crai.referencistas.com/10.1177/1045389X13517314},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1045389X13517314},
abstract = {In this study, a computational model is developed using finite-element techniques within a continuum micromechanics framework to capture the effect of electron-hopping-induced conductive paths at the nanoscale which contribute to the macroscale piezoresistive response of the nanocomposite. This is achieved by tracking the position of the nanotubes under applied deformations and modifying the conductivity of the intertube region depending on the relative proximity of individual pairs of nanotubes. The formation and disruption of the electron-hopping pathways are highly dependent on intertube distances and under deformations can result in microstructural rearrangements in terms of electrostatic properties leading to transitions in material symmetries and component magnitudes of the effective electrostatic properties. Thus, in order to capture the complexities of changing inhomogeneous nanoscale electrostatic behavior, where analytical Eshelby’s approaches cannot be used, a computational micromechanics model is needed. The effective conductivity and piezoresistive strain tensor coefficients are evaluated using volume-averaged energy equivalencies for aligned CNT–polymer nanocomposites in the transverse direction exploring different volume fractions of CNTs in the polymer and the maximum electron-hopping range. The impact of the electron-hopping mechanism on the effective piezoresistive response is studied through the macroscale effective gauge factors under different loading conditions. The effective piezoresistive strain coefficients and macroscale effective gauge factors are observed to be nonlinear with applied macroscale strain and are highly dependent on the type of boundary conditions. The effective macroscale gauge factors observed in the current study have magnitudes comparable to experimental observations reported in the literature with higher gauge factors observed closer to the percolation threshold.}
}

@article{doi:10.1177/0954406218769919,
author = {Bruce Garvey and Liuqing Chen and Feng Shi and Ji Han and Peter RN Childs},
title = {New directions in computational, combinational and structural creativity},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {233},
number = {2},
pages = {425–431},
year = {2019e},
doi = {10.1177/0954406218769919},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954406218769919},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954406218769919},
abstract = {This paper examines how new and creative relationships in datasets, not easily revealed by conventional information retrieval methods and technologies, can be identified using a mix of established and new methods. The authors present how the integration of computerised morphological analysis with new computational models, incorporating web crawler, data processing networking and data mining algorithms, can help facilitate the identification of new ideas. Boden’s concept of ‘Combinational Creativity’ indicates a structured process, which generates unfamiliar combinations of familiar concepts and constructs allowing creative styles of thought. This structured approach has been constrained by the resultant combinatorial explosion and the dearth of easily accessible computer software and supporting methodologies, to help identify viable new solutions. Feature-enhanced computerised morphological analysis provides a new structural support tool for creativity and innovation. Morphological analysis systematically structures and examines all the possible relationships in a multidimensional, highly complex, usually non-quantifiable problem space. Computerisation of the process now permits large number of configurations (millions) in the problem space to be majorly reduced (typically > 95%), identifying only internally consistent solutions. These solutions are likely to embrace configurations containing something, which has not previously been considered, thus increasing the probability of some form of technological or design breakthrough and hence truly creative.}
}

@article{doi:10.1243/0954408011530253,
author = {A G Abdul Ghani and M M Farid and X D Chen and P Richards},
title = {A computational fluid dynamics study on the effect of sterilization temperatures on bacteria deactivation and vitamin destruction},
journal = {Proceedings of the Institution of Mechanical Engineers, Part E: Journal of Process Mechanical Engineering},
volume = {215},
number = {1},
pages = {9–17},
year = {2001f},
doi = {10.1243/0954408011530253},
URL = {https://doi-org.crai.referencistas.com/10.1243/0954408011530253},
eprint = {https://doi-org.crai.referencistas.com/10.1243/0954408011530253},
abstract = {Abstract The optimization of thermal processes such as sterilization relies on the accuracy of relevant kinetic data for bacterial inactivation and quality evolution. It is also dependent on the geometry and heating mechanism involved in the process. In these processes or systems, profiles of temperature distribution, bacteria concentration and concentrations of vitamins C (ascorbic acid), B1 (thiamin) and B2 (riboflavin) in a can filled with cherry juice during thermal sterilization have been obtained through numerical simulations. Different heating medium temperatures of 121, 130 and 140°C were tested. In order to generate these profiles, the continuity, momentum and energy equations are solved numerically, together with those of bacteria and vitamins concentrations, using the computational fluid dynamics code PHOENICS, combined with reaction kinetics models. Natural convection that occurs during thermal sterilization of viscous liquid (concentrated cherry juice, 74 °Brix) in a cylindrical can heated from all sides has been studied in this work. The simulations show clearly the dependences of the concentration of live bacteria and different vitamins on both the temperature distribution and the flow pattern as sterilization proceeds. The results also show that the best sterilization temperature may not always be 121 °C, depending on the quality requirements imposed on individual food material of concern.}
}

@article{doi:10.1177/00220345241265048,
author = {E. James and A.J. Caetano and P.T. Sharpe},
title = {Computational Methods for Image Analysis in Craniofacial Development and Disease},
journal = {Journal of Dental Research},
volume = {0},
number = {0},
pages = {00220345241265048},
year = {2024g},
doi = {10.1177/00220345241265048},
note = {PMID:39272216},
URL = {https://doi-org.crai.referencistas.com/10.1177/00220345241265048},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00220345241265048},
abstract = {Observation is at the center of all biological sciences. Advances in imaging technologies are therefore essential to derive novel biological insights to better understand the complex workings of living systems. Recent high-throughput sequencing and imaging techniques are allowing researchers to simultaneously address complex molecular variations spatially and temporarily in tissues and organs. The availability of increasingly large dataset sizes has allowed for the evolution of robust deep learning models, designed to interrogate biomedical imaging data. These models are emerging as transformative tools in diagnostic medicine. Combined, these advances allow for dynamic, quantitative, and predictive observations of entire organisms and tissues. Here, we address 3 main tasks of bioimage analysis, image restoration, segmentation, and tracking and discuss new computational tools allowing for 3-dimensional spatial genomics maps. Finally, we demonstrate how these advances have been applied in studies of craniofacial development and oral disease pathogenesis.}
}

@article{doi:10.1177/0391398818792757,
author = {Dominica PY Khoo and Andrew N Cookson and Harinderjit S Gill and Katharine H Fraser},
title = {Normal fluid stresses are prevalent in rotary ventricular assist devices: A computational fluid dynamics analysis},
journal = {The International Journal of Artificial Organs},
volume = {41},
number = {11},
pages = {738–751},
year = {2018h},
doi = {10.1177/0391398818792757},
note = {PMID:30141359},
URL = {https://doi-org.crai.referencistas.com/10.1177/0391398818792757},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0391398818792757},
abstract = {Despite the evolution of ventricular assist devices, ventricular assist device patients still suffer from complications due to the damage to blood by fluid dynamic stress. Since rotary ventricular assist devices are assumed to exert mainly shear stress, studies of blood damage are based on shear flow experiments. However, measurements and simulations of cell and protein deformation show normal and shear stresses deform, and potentially damage, cells and proteins differently. The aim was to use computational fluid dynamics to assess the prevalence of normal stress, in comparison with shear stress, in rotary ventricular assist devices. Our calculations showed normal stresses do occur in rotary ventricular assist devices: the fluid volumes experiencing normal stress above 10 Pa were 0.011 mL (0.092%) and 0.027 mL (0.39%) for the HeartWare HVAD and HeartMate II (HMII), and normal stresses over 100 Pa were present. However, the shear stress volumes were up to two orders of magnitude larger than the normal stress volumes. Considering thresholds for red blood cell and von Willebrand factor deformation by normal and shear stresses, the fluid volumes causing deformation by normal stress were between 2.5 and 5 times the size of those causing deformation by shear stress. The exposure times to the individual normal stress deformation regions were around 1 ms. The results clearly show, for the first time, that while blood within rotary ventricular assist devices experiences more shear stress at much higher magnitudes as compared with normal stress, there is sufficient normal stress exposure present to cause deformation of, and potentially damage to, the blood components. This study is the first to quantify the fluid stress components in real blood contacting devices.}
}

@article{doi:10.1177/1756829316646640,
author = {James Lankford and David Mayo and Inderjit Chopra},
title = {Computational investigation of insect-based flapping wings for micro air vehicle applications},
journal = {International Journal of Micro Air Vehicles},
volume = {8},
number = {2},
pages = {64–78},
year = {2016i},
doi = {10.1177/1756829316646640},
URL = {https://doi-org.crai.referencistas.com/10.1177/1756829316646640},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1756829316646640},
abstract = {In this study, a computational fluid dynamics analysis was performed on bio-inspired micro aerial vehicle scale rigid flapping wings. The computational fluid dynamics analysis used a compressible unsteady Reynolds Averaged Navier–Stokes solver with low-Mach number preconditioning to study the complex, highly vortical, three-dimensional flow of low aspect ratio flapping wings at micro aerial vehicle-scale Reynolds numbers. The wing was flapped at a constant 5 Hz flap frequency at a mean chord reference Reynolds number of 25,000. The flapping and pitching kinematics were set to match those of a previous experimental study resulting in a constant flap stroke of 107° at translational pitching angles of 40°, 50°, and 60°. The force and flowfield measurements of the previous flapping-wing experiment were used for the validation of the 3D computational fluid dynamics model. The objectives of this effort were to understand the unsteady aerodynamic mechanisms and their relation to force production and aerodynamic efficiency on a rigid wing undergoing an insect-type flapping motion with passive pitching kinematics. Overall, the computational fluid dynamics results showed good agreement with the measured experimental force data. Additionally, the computational fluid dynamics simulation was able to adequately predict the process of leading edge vortex formation and shedding observed during experimentation. A vorticity summation approach used to calculate the strength of the leading edge vortex from the experimental measurements and from the computational fluid dynamics predicted flowfields showed comparable results. The computational fluid dynamics results were utilized to further analyze the differences in the flowfield and leading edge vortex formation for the three pitch angles tested as well as the instantaneous aerodynamic loads and aerodynamic power.}
}

@article{doi:10.1177/1934578X221096966,
author = {Ying Liu and Han Yan and Hui-bin Jia and Li Pan and Jia-zheng Liu and Ya-wen Zhang and Jing Wang and Dao-gang Qin and Lei Ma and Ting Wang},
title = {Jiedu Huoxue Decoction for Cytokine Storm and Thrombosis in Severe COVID-19: A Combined Bioinformatics and Computational Chemistry Approach},
journal = {Natural Product Communications},
volume = {17},
number = {4},
pages = {1934578X221096966},
year = {2022j},
doi = {10.1177/1934578X221096966},
URL = {https://doi-org.crai.referencistas.com/10.1177/1934578X221096966},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1934578X221096966},
abstract = {Jiedu Huoxue Decoction (JHD), a recommended traditional prescription for patients with severe COVID-19, has appeared in the treatment protocols in China. Based on bioinformatics and computational chemistry methods, including molecular docking, molecular dynamics (MD) simulation, and Molecular Mechanics Generalized Born Surface Area (MM/GBSA) calculation, we aimed to reveal the mechanism of JHD in treating severe COVID-19. The compounds in JHD were obtained and screened on TCMSP, SwissADME, and ADMETLab platforms. The compound targets were obtained from TCMSP and STITCH, while COVID-19 targets were obtained from Genecards and NCBI. The protein-protein interaction network was constructed by using STRING. Gene Ontology (GO) and KEGG enrichment were performed with ClueGO and R language. AutoDock vina was employed for molecular docking. 100 ns MD simulation of the optimal docking complex was carried out with AmberTools 20. A total of 84 compounds and 29 potential targets of JHD for COVID-19 were collected. The key phytochemicals included quercetin, luteolin, β-sitosterol, puerarin, stigmasterol, kaempferol, and wogonin, which could regulate the immune system. The hub genes included IL6, IL10, VEGFA, IL1B, CCL2, HMOX1, DPP4, and ACE2. ACE2 and DPP4 were related to SARS-CoV-2 entering cells. GO and KEGG analysis showed that JHD could intervene in cytokine storm and endothelial proliferation and migration related to thrombosis. The molecular docking, 100 ns MD simulation, and MM/GBSA calculation confirmed that targets enriched in the COVID-19 pathway had high affinities with related compounds, and the conformations of the puerarin-ACE2, quercetin-EGFR, luteolin-EGFR, and quercetin-IL1B complexes were stable. In a word, JHD could treat COVID-19 by intervening in cytokine storm, thrombosis, and the entry of SARS-CoV-2, while regulating the immune system. These mechanisms were consistent with JHD’s therapeutic concept of “detoxification” and “promoting blood circulation and removing blood stasis” in treating COVID-19. The research provides a theoretical basis for the development and application of JHD.}
}

@article{doi:10.1080/17470218.2015.1134602,
author = {Pavel Logačev and Shravan Vasishth},
title = {Understanding underspecification: A comparison of two computational implementations},
journal = {Quarterly Journal of Experimental Psychology},
volume = {69},
number = {5},
pages = {996–1012},
year = {2016k},
doi = {10.1080/17470218.2015.1134602},
note = {PMID:26960441},
URL = {https://doi-org.crai.referencistas.com/10.1080/17470218.2015.1134602},
eprint = {https://doi-org.crai.referencistas.com/10.1080/17470218.2015.1134602},
abstract = {Swets et al. (2008. Underspecification of syntactic ambiguities: Evidence from self-paced reading. Memory and Cognition, 36(1), 201–216) presented evidence that the so-called ambiguity advantage [Traxler et al. (1998). Adjunct attachment is not a form of lexical ambiguity resolution. Journal of Memory and Language, 39(4), 558–592], which has been explained in terms of the Unrestricted Race Model, can equally well be explained by assuming underspecification in ambiguous conditions driven by task-demands. Specifically, if comprehension questions require that ambiguities be resolved, the parser tends to make an attachment: when questions are about superficial aspects of the target sentence, readers tend to pursue an underspecification strategy. It is reasonable to assume that individual differences in strategy will play a significant role in the application of such strategies, so that studying average behaviour may not be informative. In order to study the predictions of the good-enough processing theory, we implemented two versions of underspecification: the partial specification model (PSM), which is an implementation of the Swets et al. proposal, and a more parsimonious version, the non-specification model (NSM). We evaluate the relative fit of these two kinds of underspecification to Swets et al.’s data; as a baseline, we also fitted three models that assume no underspecification. We find that a model without underspecification provides a somewhat better fit than both underspecification models, while the NSM model provides a better fit than the PSM. We interpret the results as lack of unambiguous evidence in favour of underspecification; however, given that there is considerable existing evidence for good-enough processing in the literature, it is reasonable to assume that some underspecification might occur. Under this assumption, the results can be interpreted as tentative evidence for NSM over PSM. More generally, our work provides a method for choosing between models of real-time processes in sentence comprehension that make qualitative predictions about the relationship between several dependent variables. We believe that sentence processing research will greatly benefit from a wider use of such methods.}
}

@article{doi:10.1177/09544119221102704,
author = {Yongtao Lu and Yi Huo and Jia’ao Zou and Yanchen Li and Zhuoyue Yang and Hanxing Zhu and Chengwei Wu},
title = {Comparison of the design maps of TPMS based bone scaffolds using a computational modeling framework simultaneously considering various conditions},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {236},
number = {8},
pages = {1157–1168},
year = {2022l},
doi = {10.1177/09544119221102704},
note = {PMID:35647704},
URL = {https://doi-org.crai.referencistas.com/10.1177/09544119221102704},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09544119221102704},
abstract = {In recent years, the triply periodic minimal surface (TPMS)-based scaffolds have been served as one of the crucial types of structures for biological replacements, the energy absorber, etc. Meanwhile, the development of additive manufacturing (AM) has facilitated the production of TPMS scaffolds with complex microstructures. However, the design maps of TPMS scaffolds, especially considering the AM constraints, remain unclear, which has hindered the design and application of TPMS scaffolds. The aims of the present study were to develop an efficient computational modeling framework for investigating the design maps of TPMS scaffolds simultaneously considering the AM constraints, the biological requirements, and the structural anisotropy. To demonstrate the computational framework, five widely-used topologies of the TPMS-based scaffolds (i.e. the Diamond, the Gyroid, the Fischer-Koch S, the F-RD, and the Schwarz P) were used, whose design maps for the surface-to-volume ratio and the effective elastic modulus were also investigated. The results showed that as the porosities increase, the design ranges of the surface-to-volume ratios decreases for all the structures. Compared with the effect of the constraint for the pore size, the minimal structural thickness for AM constraint has a greater effect on the surface-to-volume ratio. Regarding the elastic modulus, in the region of low porosity (approximately 0.5–0.7), the range for the effective elastic modulus of Schwarz P is the widest (approximately 2.24–32.6 GPa), but the Gyroid can achieve both high porosity and low effective elastic modulus (e.g. 0.61 GPa at the porosity of 0.90). These results and the method developed in the present study provided important basis and guidance for the design and application of the TPMS-based porous structures.}
}

@article{doi:10.1177/1094342004048534,
author = {D. E. Post and R. P. Kendall},
title = {Software Project Management and Quality Engineering Practices for Complex,                 Coupled Multiphysics, Massively Parallel Computational Simulations: Lessons Learned                 From ASCI},
journal = {The International Journal of High Performance Computing Applications},
volume = {18},
number = {4},
pages = {399–416},
year = {2004m},
doi = {10.1177/1094342004048534},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342004048534},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342004048534},
abstract = {Many institutions are now developing large-scale, complex, coupled multiphysics computational simulations for massively parallel platforms for the simulation of the performance of nuclear weapons and certification of the stockpile, and for research in climate and weather prediction, magnetic and inertial fusion energy, environmental systems, astrophysics, aerodynamic design, combustion, biological and biochemical systems, and other areas. The successful development of these simulations is aided by attention to sound software project management and software engineering. We have developed “lessons learned” from a set of code projects that the Department of Energy National Nuclear Security Agency has sponsored to develop nuclear weapons simulations over the last 50 years. We find that some, but not all, of the software project management and development practices (rather than processes) commonly employed for non-technical software add value to the development of scientific software and we identify those that we judge add value. Another key finding, consistent with general software industry experience, is that the optimal project schedule and resource level are solely determined by the requirements once the requirements are fixed.}
}

@article{doi:10.1177/1535370216636722,
author = {Christian P Rivera and Alessandro Veneziani and Russell E Ware and Manu O Platt},
title = {Original Research: Sickle cell anemia and pediatric strokes: Computational fluid dynamics analysis in the middle cerebral artery},
journal = {Experimental Biology and Medicine},
volume = {241},
number = {7},
pages = {755–765},
year = {2016n},
doi = {10.1177/1535370216636722},
URL = {https://doi-org.crai.referencistas.com/10.1177/1535370216636722},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1535370216636722},
abstract = {Children with sickle cell anemia (SCA) have a high incidence of strokes, and transcranial Doppler (TCD) identifies at-risk patients by measuring blood velocities in large intracerebral arteries; time-averaged mean velocities greater than 200 cm/s confer high stroke risk and warrant therapeutic intervention with blood transfusions. Our objective was to use computational fluid dynamics to alter fluid and artery wall properties, to simulate scenarios causative of significantly elevated arterial blood velocities. Two-dimensional simulations were created and increasing percent stenoses were created in silico, with their locations varied among middle cerebral artery (MCA), internal carotid artery (ICA), and anterior cerebral artery (ACA). Stenoses placed in the MCA, ICA, or ACA generated local increases in velocity, but not sufficient to reach magnitudes > 200 cm/s, even up to 75% stenosis. Three-dimensional reconstructions of the MCA, ICA, and ACA from children with SCA were generated from magnetic resonance angiograms. Using finite element method, blood flow was simulated with realistic velocity waveforms to the ICA inlet. Three-dimensional reconstructions revealed an uneven, internal arterial wall surface in children with SCA and higher mean velocities in the MCA up to 145 cm/s compared to non-SCA reconstructions. There were also greater areas of flow recirculation and larger regions of low wall shear stress. Taken together, these bumps on the internal wall of the cerebral arteries could create local flow disturbances that, in aggregate, could elevate blood velocities in SCA. Identifying cellular causes of these microstructures as adhered blood cells or luminal narrowing due to endothelial hyperplasia induced by disturbed flow would provide new targets to treat children with SCA. The preliminary qualitative results provided here point out the critical role of 3D reconstruction of patient-specific vascular geometries and provide qualitative insight to complex interplay between vascular geometry and rheological properties possibly altered by SCA.}
}

@article{doi:10.3181/0704-MR-97,
author = {Harlan Robins and Michael Krasnitz and Arnold J. Levine},
title = {The Computational Detection of Functional Nucleotide Sequence Motifs in the Coding Regions of Organisms},
journal = {Experimental Biology and Medicine},
volume = {233},
number = {6},
pages = {665–673},
year = {2008o},
doi = {10.3181/0704-MR-97},
URL = {https://doi-org.crai.referencistas.com/10.3181/0704-MR-97},
eprint = {https://doi-org.crai.referencistas.com/10.3181/0704-MR-97},
abstract = {A new algorithm has been constructed for finding under- and overrepresented oligonucleotide motifs in the protein coding regions of genomes that have been normalized for G/C content, codon usage, and amino acid order. This Robins-Krasnitz algorithm has been employed to compare the oligonucleotide frequencies between many different prokaryotic genomes. Evidence is presented demonstrating that at least some of these sequence motifs are functionally important and selected for or against during the evolution of these prokaryotes. The applications of this method include the optimization of protein expression for synthetic genes in foreign organisms, identification of novel oligonucleotide signals used by the organism and the examination of evolutionary relationships not dependent upon different gene sequence trees.}
}

@article{doi:10.3233/AAC-190467,
author = {Cameron Shackell and Laurianne Sitbon},
title = {Computational opposition analysis using word embeddings: A method for strategising resonant informal argument},
journal = {Argument & Computation},
volume = {10},
number = {3},
pages = {301–317},
year = {2019p},
doi = {10.3233/AAC-190467},
URL = {https://doi-org.crai.referencistas.com/10.3233/AAC-190467},
eprint = {https://doi-org.crai.referencistas.com/10.3233/AAC-190467},
abstract = {In informal argument, an essential step is to ask what will “resonate” with a particular audience and hence persuade. Marketers, for example, may recommend a certain colour for a new soda can because it “pops” on Instagram; politicians may “fine-tune” diction for different social demographics. This paper engages the need to strategise for such resonance by offering a method for automating opposition analysis (OA), a technique from semiotics used in marketing and literary analysis to plot objects of interest on oppositional axes. Central to our computational approach is a reframing of texts as proxies for thought and opposition as the product of oscillation in thought in response to those proxies, a model to which the contextual similarity information contained in word embeddings is relevant. We illustrate our approach with an analysis of texts on gun control from ProCon.org, implementing a three-step method to: 1) identify relatively prominent signifiers; 2) rank possible opposition pairs on prominence and contextual similarity scores; and 3) derive plot values for proxies on opposition pair axes. The results are discussed in terms of strategies for informal argument that might be derived by those on each side of gun control.}
}

@article{doi:10.1177/0309524X241229169,
author = {Mujahid Shaik and Balaji Subramanian},
title = {Computational investigation and validation of new MEXICO experiment},
journal = {Wind Engineering},
volume = {48},
number = {4},
pages = {651–683},
year = {2024q},
doi = {10.1177/0309524X241229169},
URL = {https://doi-org.crai.referencistas.com/10.1177/0309524X241229169},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0309524X241229169},
abstract = {A computational investigation of New MEXICO test cases operating under axial flow conditions is reported. Three wind speed cases (10, 15, 24 m/s) corresponding to three different tip speed ratios (10, 6.67, 4.17) when the turbine operates at 425.1 rpm were considered. ANSYS CFX 2021R1 was employed to perform simulations using Single Reference Frame (SRF) and Multiple Reference Frame (MRF) approaches. The flow field is computed by solving unsteady Reynolds Averaged Navier-Stokes (uRANS) equations coupled with SST k-ω turbulence model and Gamma-Theta transition model. Validation involved comparing CFD-predicted integral quantities, static pressure distributions, and loads with corresponding experimental values demonstrating reasonably good agreement at all three wind speeds. Overall, SRF exhibited slightly better wake predictions (hypothetical), while MRF predictions were closer to measurements for integral quantities, static pressure and loads. This study demonstrates the utility of uRANS-based 3D CFD computations in wind turbine aerodynamics studies.}
}

@article{doi:10.1177/0361198196155000101,
author = {Hέlène Tattegrain-Veste and Thierry Bellet and Annie Pauziέ and Andrέ Chapon},
title = {Computational Driver Model in Transport Engineering: COSMODRIVE},
journal = {Transportation Research Record},
volume = {1550},
number = {1},
pages = {1–7},
year = {1996r},
doi = {10.1177/0361198196155000101},
URL = {https://doi-org.crai.referencistas.com/10.1177/0361198196155000101},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0361198196155000101},
abstract = {With regard to road safety issues, a deep understanding of the driver as a logic system is crucial to predict the most probable behavior according to the contextual elements. Knowledge and data about human functional abilities exist. But the problem is to organize and structure them. The development of a computational approach in driver modelization is addressed. In the first part, a brief historical overview is presented of available driver models in ergonomics and psychological areas, and the distinction between predictive and explicative models in an implementation perspective is the focus. In the second part, the computational aspect of the work is described, along with the software concepts, the cognitive modeling needs, and the implementation choices. Object-oriented techniques were chosen because they provide a modular overview of the general system and offer a convenient representation of cognitive processes. Object-oriented formalism, in particular object modeling technique diagrams, acts as a bridge between the two domains of computer science and the human sciences. The objective is to determine whether it is possible to implement reliably a driver model using the techniques from artificial intelligence and based on the theoretical knowledge from cognitive sciences research. This attempt to establish links between different scientific domains, requiring a common tool, is a challenge. A first step of a work that will have to be developed in a long-term time scale, taking into account its quite ambitious objective, is described.}
}

@article{doi:10.1518/hfes.45.1.47.27231,
author = {Gary Witus and R. Darin Ellis},
title = {Computational Modeling of Foveal Target Detection},
journal = {Human Factors},
volume = {45},
number = {1},
pages = {47–60},
year = {2003s},
doi = {10.1518/hfes.45.1.47.27231},
note = {PMID:12916581},
URL = {https://doi-org.crai.referencistas.com/10.1518/hfes.45.1.47.27231},
eprint = {https://doi-org.crai.referencistas.com/10.1518/hfes.45.1.47.27231},
abstract = {This paper presents the VDM 2000, a computational model of target detection designed for use in military developmental test and evaluation settings. The model integrates research results from the fields of early vision, object recognition, and psychophysics. The VDM2000 is image based and provides a criterion-independent measure of target conspicuity, referred to as the vehicle metric (VM). A large data set of human responses to photographs of military vehicles in a field setting was used to validate the model. The VM adjusted by a single calibration parameter accounts for approximately 80% of the variance in the validation data. The primary application of this model is to predict detection of military targets in daylight with the unaided eye. The model also has application to target detection prediction using infrared night vision systems. The model has potential as a tool to evaluate the visual properties of more general task settings.}
}

@article{doi:10.1177/0954406211415777,
author = {H T Zheng and L Cai and Y J Li and Z M Li},
title = {Computational fluid dynamics simulation of the supersonic steam ejector. Part 1: Comparative study of different equations of state},
journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
volume = {226},
number = {3},
pages = {709–714},
year = {2012t},
doi = {10.1177/0954406211415777},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954406211415777},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954406211415777},
abstract = {The aim of this study is to investigate the use of computational fluid dynamics in predicting the performance and geometry of the optimal design of a steam ejector used in a steam turbine. Many scholars have analysed the steam ejector using the ideal gas model, which lacks accuracy in terms of calculating the flow field of the ejector. This study is reported in a series of two papers. The first part covers the validation of CFX 11.0 results using different equations of state (EOS) on the converging–diverging nozzle flow field carried out with the experimental value. The IAPWS IF97 real gas model works well with the experimental value. The flow field of the ejector was analysed using different EOS after grid-dependent learning. The results show that the performance of the ejector was underestimated under the ideal gas model; the entrainment ratio was 20–40 per cent lower than when using the real gas model. The effect of the optimal geometrical design and operating conditions will be discussed in Part 2.}
}

