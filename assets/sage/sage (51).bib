@article{doi:10.1260/1478-0771.8.4.439,
author = {Ajla Aksamija and Ivanka Iordanova},
title = {Computational Environments with Multimodal Representations of Architectural Design Knowledge},
journal = {International Journal of Architectural Computing},
volume = {8},
number = {4},
pages = {439–460},
year = {2010a},
doi = {10.1260/1478-0771.8.4.439},
URL = {https://doi-org.crai.referencistas.com/10.1260/1478-0771.8.4.439},
eprint = {https://doi-org.crai.referencistas.com/10.1260/1478-0771.8.4.439},
abstract = {This article discusses interaction between multimodal representations of architectural design knowledge, particularly focusing on relating explicit and implicit types of information. The aim of the presented research is to develop a computational environment that combines several modes of representation, including and integrating different forms of architectural design knowledge. Development of an interactive digital-models library and ontological model of architectural design factors are discussed, which are complementary in nature. In a time when BIM software is seen as embodiment of domain knowledge and the future medium of architectural design, this paper presents an interaction between ontological representation of architectural design knowledge and its embodiment in interactive models, thus focusing on the process of design and design space exploration. In the digital environments that we propose, representation of different formats of knowledge, such as visual, linguistic or numeric, are integrated with relational and procedural information, design rules, and characteristics. Interactive search and query based on contextual constraints, and parametric variation of the model based on the information received from ontology are the underlying drivers for design exploration and development.}
}

@article{doi:10.1177/0049124196025001002,
author = {EDWARD E. BRENT},
title = {Expert Systems and their Role in Computational Sociology},
journal = {Sociological Methods & Research},
volume = {25},
number = {1},
pages = {31–59},
year = {1996b},
doi = {10.1177/0049124196025001002},
URL = {https://doi-org.crai.referencistas.com/10.1177/0049124196025001002},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0049124196025001002},
abstract = {This article examines in detail some of the principal strategies used by expert systems to represent and reason about knowledge. It identifies strengths and weaknesses of these different strategies, with particular reference to sociological knowledge as illustrated by the work of Erving Goffman. The article ends with a summary of the current status of expert systems in sociology and prospects for using expert systems to help create a systematic framework for computational sociology.}
}

@article{doi:10.1177/0391398820917145,
author = {Lizhi Cheng and Jianping Tan and Zhong Yun and Shuai Wang and Zheqin Yu},
title = {Analysis of flow field and hemolysis index in axial flow blood pump by computational fluid dynamics–discrete element method},
journal = {The International Journal of Artificial Organs},
volume = {44},
number = {1},
pages = {46–54},
year = {2021c},
doi = {10.1177/0391398820917145},
note = {PMID:32393086},
URL = {https://doi-org.crai.referencistas.com/10.1177/0391398820917145},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0391398820917145},
abstract = {To fully study the relationship between the internal flow field and hemolysis index in an axial flow blood pump, a computational fluid dynamics–discrete element method coupled calculation method was used. Through numerical analysis under conditions of 6000, 8000, and 10,000 r/min, it was found that there was flow separation of blood cell particles in the tip of the impeller and the guide vane behind the impeller. The flow field has a larger pressure gradient distribution, which reduces the lift ratio of the blood pump and easily causes blood cell damage. The study shows that the hemolysis index obtained by the computational fluid dynamics—discrete element method is 4.75% higher than that from the traditional computational fluid dynamics method, which indicates the impact of microcollision between erythrocyte particles and walls on hemolysis index and also further verifies the validity of the computational fluid dynamics–discrete element coupling method. Through the hydraulic and particle image velocimetry experiments of the blood pump, the coincidence between numerical calculation and experiment is analyzed from macro and micro aspects, which shows that the numerical calculation method is feasible.}
}

@article{doi:10.1177/1081286520975202,
author = {Hao Dong and Junzhi Cui and Yufeng Nie and Ke Jin and Xiaofei Guan and Zihao Yang},
title = {High-order three-scale computational method for elastic behavior analysis and strength prediction of axisymmetric composite structures with multiple spatial scales},
journal = {Mathematics and Mechanics of Solids},
volume = {26},
number = {6},
pages = {905–936},
year = {2021d},
doi = {10.1177/1081286520975202},
URL = {https://doi-org.crai.referencistas.com/10.1177/1081286520975202},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1081286520975202},
abstract = {A novel high-order three-scale (HOTS) computational method for elastic behavior analysis and strength prediction of axisymmetric composite structures with multiple spatial scales is developed in this paper. The multiple heterogeneities of axisymmetric composite structures we investigated are taken into account by periodic distributions of representative unit cells on the mesoscale and microscale. First, the new micro–meso–macro coupled HOTS computational model for elastic problems of axisymmetric composite structures is established based on multiscale asymptotic analysis, which breaks through the traditional multiscale assumptions and includes three main components. Two classes of mesoscopic and microscopic auxiliary cell functions are constructed on the mesoscale and microscale, respectively. The macroscopic homogenization problems are defined on global axisymmetric structures by twice up-scaling procedures from microscale to mesoscale and then from mesoscale to macroscale. Moreover, the asymptotic HOTS solutions are constructed for approximating multiscale elastic problems of axisymmetric structures and the numerical accuracy analysis of the HOTS solutions is given in detail. Then, the strength prediction formulas for axisymmetric composite structures with multiple spatial scales are presented based on the high-accuracy elastic behavior analysis from the proposed HOTS computational model. Furthermore, the corresponding HOTS numerical algorithm based on the finite element method (FEM) is presented for analyzing the mechanical behaviors and predicting the strength of axisymmetric composite structures with multiple spatial scales in detail. Finally, some numerical examples are reported to verify the feasibility and effectiveness of the proposed HOTS computational method. In this study, a unified three-scale computational framework is offered, which enables the simulation of mechanical behaviors of axisymmetric composite structures with multiple spatial scales.}
}

@article{doi:10.1260/1369-4332.18.7.1003,
author = {O. Hasançebi and S. Kazemzadeh Azad},
title = {Improving Computational Efficiency of Bat-Inspired Algorithm in Optimal Structural Design},
journal = {Advances in Structural Engineering},
volume = {18},
number = {7},
pages = {1003–1015},
year = {2015e},
doi = {10.1260/1369-4332.18.7.1003},
URL = {https://doi-org.crai.referencistas.com/10.1260/1369-4332.18.7.1003},
eprint = {https://doi-org.crai.referencistas.com/10.1260/1369-4332.18.7.1003},
abstract = {Bat-inspired (BI) algorithm is a recent metaheuristic optimization technique that simulates echolocation behavior of bats in seeking a design space. Along the same line with almost all metaheuristics, this algorithm also entails a large number of time-consuming structural analyses in structural design optimization applications. This study is focused on improving computational efficiency of the BI algorithm in optimum structural design. The number of structural analyses required by BI algorithm in the course of design optimization is reduced considerably by incorporating an upper bound strategy (UBS) into the solution procedure. The performance of the resulting algorithm, i.e. UBS integrated BI algorithm (UBI), is evaluated in discrete sizing optimization of large-scale steel skeletal structures designed for minimum weight according to American Institute of Steel Construction-Allowable Stress Design provisions. The numerical results verify that the UBI results in a significant gain in the computational efficiency of the standard algorithm.}
}

@article{doi:10.1177/15554120231211376,
author = {Lasse Juel Larsen and Bo Kampmann Walther},
title = {Fear of Monsters: Toward an Understanding of the Threat of the Computational Monster Read Through the Theoretical Lens  of Game-Play},
journal = {Games and Culture},
volume = {0},
number = {0},
pages = {15554120231211376},
year = {2023f},
doi = {10.1177/15554120231211376},
URL = {https://doi-org.crai.referencistas.com/10.1177/15554120231211376},
eprint = {https://doi-org.crai.referencistas.com/10.1177/15554120231211376},
abstract = {This article analyzes the configuration of fear generated by the computational monster in computer games. We view the monster as a computational entity, which we approach through our theory of game-play coupled with the concepts of loss aversion and endowment effect. Of particular interest is player perception of the threat posed by monsters as they perturb the experience of progression and the sensation of control within the game. We scrutinize this aspect from a situational as well as an existential perspective. Furthermore, we advance an analytical scheme of the threat of the computational monster, which is radically different from the traditional academic approach with its emphasis on the representation of monsters. Overall, we argue that the threat players perceive when facing monsters in computer games springs more from the computational nature of monsters—how they upset progression and the feeling of control—and less from the representation of the monster(s).}
}

@article{doi:10.1177/10298649020050S104,
author = {Patrik N. Juslin and Anders Friberg and Roberto Bresin},
title = {Toward a computational model of expression in music performance: The GERM model},
journal = {Musicae Scientiae},
volume = {5},
number = {1_suppl},
pages = {63–122},
year = {2001g},
doi = {10.1177/10298649020050S104},
URL = {https://doi-org.crai.referencistas.com/10.1177/10298649020050S104},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10298649020050S104},
abstract = {This article presents a computational model of expression in music performance: the GERM model. The purpose of the GERM model is to (a) describe the principal sources of variability in music performance, (b) emphasize the need to integrate different aspects of performance in a common model, and (c) provide some preliminaries (germ = a basis from which a thing may develop) for a computational model that simulates the different aspects. Drawing on previous research on performance, we propose that performance expression derives from four main sources of variability: (1) Generative Rules, which function to convey the generative structure in a musical manner (e.g., Clarke, 1988; Sundberg, 1988); (2) Emotional Expression, which is governed by the performer’s expressive intention (e.g., Juslin, 1997a); (3) Random Variations, which reflect internal timekeeper variance and motor delay variance (e.g., Gilden, 2001; Wing and Kristofferson, 1973); and (4) Movement Principles, which prescribe that certain features of the performance are shaped in accordance with biological motion (e.g., Shove and Repp, 1995). A preliminary version of the GERM model was implemented by means of computer synthesis. Synthesized performances were evaluated by musically trained participants in a listening test. The results from the test support a decomposition of expression in terms of the GERM model. Implications for future research on music performance are discussed.}
}

@article{doi:10.1260/1757-482X.3.3.147,
author = {Inchul Kim and Uriel Goldberg},
title = {Computational Investigation of Particle-Laden Jet Fuel Flow through a Constricted Pipe},
journal = {The Journal of Computational Multiphase Flows},
volume = {3},
number = {3},
pages = {147–163},
year = {2011h},
doi = {10.1260/1757-482X.3.3.147},
URL = {https://doi-org.crai.referencistas.com/10.1260/1757-482X.3.3.147},
eprint = {https://doi-org.crai.referencistas.com/10.1260/1757-482X.3.3.147},
abstract = {Accumulation of soot particles on the wall of a constricted pipe, through which JP4 liquid jet fuel flows, is investigated numerically, using a pipe with a bump on its wall. The effects of particle size, particle-to-fluid density ratio and carrier fluid flow Reynolds number, on particle accumulation, are investigated. When the particles’ size is relatively large, with particle-to-fluid density ratio greater than unity, and at relatively large Re number, the largest accumulation of particles occurs near the bump’s front wall where those particles are blocked by the protruding bump and are too massive to be carried away by the nearwall, low momentum carrier fluid. Conversely, when either the particles’ size or the carrier fluid Re number is relatively small, or the density ratio is less than unity, the largest accumulation of particles occurs in one of three regions: on the bump’s rear wall, near the center of the recirculation eddy, or at the flow detachment point. Particle-accumulation ratio on the bump’s wall decreases monotonically as the particle size decreases (with the mass concentration of particles at the pipe inlet held fixed).}
}

@article{doi:10.1177/0013916502238866,
author = {Benjamin Kuipers and Dan G. Tecuci and Brian J. Stankiewicz},
title = {The Skeleton In The Cognitive Map: A Computational and Empirical Exploration},
journal = {Environment and Behavior},
volume = {35},
number = {1},
pages = {81–106},
year = {2003i},
doi = {10.1177/0013916502238866},
URL = {https://doi-org.crai.referencistas.com/10.1177/0013916502238866},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0013916502238866},
abstract = {Experts seem to find routes in complex environments by finding a connection from the source to a “skeleton” of major paths, then moving within the skeleton to the neighborhood of the destination, making a final connection to the destination. The authors present a computational hypothesis that describes the skeleton as emerging from the interaction of three factors: (a) The topological map is represented as a bipartite graph of places and paths, where a path is a one-dimensional ordered set of places; (b) a traveler incrementally accumulates topological relationships, including the relation of a place to a path serving as a dividing boundary separating two regions; and (c) the wayfinding algorithm prefers paths rich in boundary relations so they are likely to acquire more boundary relations. This positive-feedback loop leads to an oligarchy of paths rich in boundary relations. The authors present preliminary computational and empirical tests for this hypothesis, and provide initial results.}
}

@article{doi:10.1177/027046769901900105,
author = {James E. Martin},
title = {Noncomputational Versus Computational Conceptions of Reason: Contrasting Educational Implications},
journal = {Bulletin of Science, Technology & Society},
volume = {19},
number = {1},
pages = {25–31},
year = {1999j},
doi = {10.1177/027046769901900105},
URL = {https://doi-org.crai.referencistas.com/10.1177/027046769901900105},
eprint = {https://doi-org.crai.referencistas.com/10.1177/027046769901900105},
abstract = {Current conceptions of the integration of computers into society often depend on the view that the human mind, as well as the computer, is a computational system. This view is widely taken to have broad implications for educational policy. We present a critique of the premise and some of the conclusions of the above argument. It is here shown that the thesis that the human mind is a computational system is, in principle, not scientifically supportable. It is also shown that, even if the computational theory of mind were held for non-scientific reasons, the educational implications often derived from it do not follow.}
}

@article{doi:10.1177/0735275114536387,
author = {Kent McClelland},
title = {Cycles of Conflict: A Computational Modeling Alternative to Collins’s Theory of Conflict Escalation},
journal = {Sociological Theory},
volume = {32},
number = {2},
pages = {100–127},
year = {2014k},
doi = {10.1177/0735275114536387},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735275114536387},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735275114536387},
abstract = {In a new theory of conflict escalation, Randall Collins engages critical issues of violent conflict and presents a compellingly plausible theoretical description based on his extensive empirical research. He also sets a new challenge for sociology: explaining the time dynamics of social interaction. However, despite heavy reliance on the quantitative concept of positive feedback loops in his theory, Collins presents no mathematical specification of the dynamic relationships among his variables. This article seeks to fill that gap by offering a computational model that can parsimoniously account for many features of Collins’s theory. My model uses perceptual control theory to create an agent-based computational model of the time dynamics of conflict. With greater conceptual clarity and more wide-ranging generalizability, my alternative model opens the door to further advances in theory development by revealing dynamic aspects of conflict escalation not found in Collins’s model.}
}

@article{doi:10.1260/0266-3511.28.3-4.215,
author = {Paul Nicholas and Martin Tamke},
title = {Computational Strategies for the Architectural Design of Bending Active Structures},
journal = {International Journal of Space Structures},
volume = {28},
number = {3–4},
pages = {215–228},
year = {2013l},
doi = {10.1260/0266-3511.28.3-4.215},
URL = {https://doi-org.crai.referencistas.com/10.1260/0266-3511.28.3-4.215},
eprint = {https://doi-org.crai.referencistas.com/10.1260/0266-3511.28.3-4.215},
abstract = {Active bending introduces a new level of integration into the design of architectural structures, and opens up new complexities for the architectural design process. In particular, the introduction of material variation reconfigures the design space. Through the precise specification of their stiffness, it is possible to control and pre-calibrate the bending behaviour of a composite element. This material capacity challenges architecture’s existing methods for design, specification and prediction. In this paper, we demonstrate how architects might connect the designed nature of composites with the design of bending-active structures, through computational strategies. We report three built structures that develop architecturally oriented design methods for bending-active systems using composite materials. These projects demonstrate the application and limits of the introduction of advanced engineering simulation into an architectural workflow, and the extension of architecture’s existing physics-based approaches.}
}

@article{doi:10.1177/0021998308094543,
author = {L. Ramajo and M. Reboredo and D. Santiago and M. Castro and D. Ramajo},
title = {Computational Approach of Dielectric Permitivities in BaTiO3—Epoxy Composites},
journal = {Journal of Composite Materials},
volume = {42},
number = {19},
pages = {2027–2037},
year = {2008m},
doi = {10.1177/0021998308094543},
URL = {https://doi-org.crai.referencistas.com/10.1177/0021998308094543},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0021998308094543},
abstract = {A numerical approach using a finite element method (FEM) was performed in order to determine the dielectric constant (ε’) of BaTiO 3—epoxy composites. In order to diminish computational resources and analyse simple models, composite topology was represented by periodic structures based on FCC configurations, but introducing novel packaging protocols, defining the way composites are filled as particle concentration is increased. The dielectric response of these anisotropic and periodic structures was mathematically represented through a quasi-static approximation using the Laplace equation. The amount of inclusions was varied in order to represent diluted and concentrated systems and structures were assessed for the whole feasible range of volume fractions. The numerical results were compared with experimental data concluding that only packaging protocols that consider higher particle—particle interaction are suitable to represent the dielectric behavior of concentrated-composite materials.}
}

@article{doi:10.3141/1836-08,
author = {Adel W. Sadek and Gary Spring and Brian L. Smith},
title = {Toward More Effective Transportation Applications of Computational Intelligence Paradigms},
journal = {Transportation Research Record},
volume = {1836},
number = {1},
pages = {57–63},
year = {2003n},
doi = {10.3141/1836-08},
URL = {https://doi-org.crai.referencistas.com/10.3141/1836-08},
eprint = {https://doi-org.crai.referencistas.com/10.3141/1836-08},
abstract = {While information technology has facilitated the collection of neverbefore-seen quantities of data, these data have not always provided the information needed by transportation professionals to support sound decision making. Computational intelligence (CI) has great potential to support the needs of transportation professionals. CI is a result of synergy among information processing technologies such as artificial neural networks (ANNs), fuzzy sets, and genetic algorithms. As the number of CI applications to transportation problems grows, so does the need to evaluate these systems. The issue of validating and evaluating transportation CI applications is addressed. A case study that evaluates the effectiveness of two CI paradigms, case-based reasoning and ANNs, for estimating the benefits of real-time traffic diversion is presented. The case study illustrates the need for regarding validation and evaluation as a part of the development effort and the need for tuning the design parameters of CI paradigms.}
}

@article{doi:10.1177/1461445619866985,
author = {Kun Sun and Wenxin Xiong},
title = {A computational model for measuring discourse complexity},
journal = {Discourse Studies},
volume = {21},
number = {6},
pages = {690–712},
year = {2019o},
doi = {10.1177/1461445619866985},
URL = {https://doi-org.crai.referencistas.com/10.1177/1461445619866985},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1461445619866985},
abstract = {In past studies, the few quantitative approaches to discourse structure were mostly confined to the presentation of the frequency of discourse relations. However, quantitative approaches should take into account both hierarchical and relational layers in the discourse structure. This study considers these factors and addresses the issue of how discourse relations and discourse units are related. It draws upon the available corpora of discourse structure (rhetorical structure theory-discourse treebank (RST-DT)) from a new perspective. Since an RST tree can be converted into a syntactic dependency tree, the data extracted from the RST-DT can be useful for calculating the discourse distance in much the same way as syntactic dependency distance is calculated. Discourse distance is also applicable to measuring the depth of the human processing of discourse. Furthermore, the data derived from the RST-DT are also easily converted into network data. This study finds that discourse structure has its discourse distance minimum and each type of RST relations has its range of discourse distance. The frequency distribution of discourse data basically follows the power law on several levels, while a network approach reveals how discourse units are arranged spatially in regular patterns. The two methods are mutually complementary in revealing the interaction between discourse relations and discourse units in a comprehensive manner, as well as in revealing how people process and comprehend discourse dynamically. Accordingly, we propose merging the two methods so as to yield a computational model for assessing discourse complexity and comprehension.}
}

@article{doi:10.1177/0023830912460513,
author = {Michael S Vitevitch and Holly L Storkel},
title = {Examining the Acquisition of Phonological Word Forms with Computational Experiments},
journal = {Language and Speech},
volume = {56},
number = {4},
pages = {493–527},
year = {2013p},
doi = {10.1177/0023830912460513},
note = {PMID:24597275},
URL = {https://doi-org.crai.referencistas.com/10.1177/0023830912460513},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0023830912460513},
abstract = {It has been hypothesized that known words in the lexicon strengthen newly formed representations of novel words, resulting in words with dense neighborhoods being learned more quickly than words with sparse neighborhoods. Tests of this hypothesis in a connectionist network showed that words with dense neighborhoods were learned better than words with sparse neighborhoods when the network was exposed to the words all at once (Experiment 1), or gradually over time, like human word-learners (Experiment 2). This pattern was also observed despite variation in the availability of processing resources in the networks (Experiment 3). A learning advantage for words with sparse neighborhoods was observed only when the network was initially exposed to words with sparse neighborhoods and exposed to dense neighborhoods later in training (Experiment 4). The benefits of computational experiments for increasing our understanding of language processes and for the treatment of language processing disorders are discussed.}
}

@article{doi:10.1177/1687814017734109,
author = {Miao Wang and Xinhai Xu and Xiaoguang Ren and Chao Li and Juan Chen and Xuejun Yang},
title = {Mesh partitioning using matrix value approximations for parallel computational fluid dynamics simulations},
journal = {Advances in Mechanical Engineering},
volume = {9},
number = {11},
pages = {1687814017734109},
year = {2017q},
doi = {10.1177/1687814017734109},
URL = {https://doi-org.crai.referencistas.com/10.1177/1687814017734109},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1687814017734109},
abstract = {Mesh partitioning is significant to the efficiency of parallel computational fluid dynamics simulations. The most time-consuming parts of parallel computational fluid dynamics simulations are iteratively solving linear systems derived from partial differential equation discretizations. This article aims at mesh partitioning for better iterative convergence feature of this procedure. For typical computational fluid dynamics simulations in which partial differential equations are discretized and solved after the mesh is partitioned, numerical information of the linear systems is not available yet during mesh partitioning. We propose to construct approximations for matrix elements and theoretically find out that for finite-volume-based problems, the face area can approximate the corresponding matrix element well. A mesh partitioning scheme using the matrix value approximations for better iterative convergence behavior is implemented and numerically testified. The results show that our method can capture the most important factor influencing the matrix values and achieve partitions with good performance throughout the simulations with non-uniform meshes. The novel partitioning strategy is general and easy to implement in various partitioning packages.}
}

@article{doi:10.1260/1475-472X.12.2.155,
author = {Samuel Wilkinson and Sean Hanna},
title = {Approximating Computational Fluid Dynamics for Generative Tall Building Design},
journal = {International Journal of Architectural Computing},
volume = {12},
number = {2},
pages = {155–177},
year = {2014r},
doi = {10.1260/1475-472X.12.2.155},
URL = {https://doi-org.crai.referencistas.com/10.1260/1475-472X.12.2.155},
eprint = {https://doi-org.crai.referencistas.com/10.1260/1475-472X.12.2.155},
abstract = {Background literature review, methodology, results, and analysis are presented for a novel approach to approximating wind pressure on tall buildings for the application of generative design exploration and optimisation. The predictions are approximations of time-averaged computational fluid dynamics (CFD) data with the aim of maintaining simulation accuracy but with improved speed. This is achieved through the use of a back-propagation artificial neural network (ANN) with vertex-based shape features as input and pressure as output. The training set consists of 600 procedurally generated tall building models, and the test set of 10 real building models; for all models in both sets, a feature vector is calculated for every vertex. Over the test set, mean absolute errors against the basis CFD are 1.99–4.44% (σ:2. 10–5.09%) with an on-line process time of 14.72–809.98s (0.028s/sample). Studies are also included on feature sensitivity, training set size, and comparison of CFD against prediction times. Results indicate that prediction time is only dependent on the number of test model vertices, and is therefore invariant to basis CFD time.}
}

@article{doi:10.3233/jid-2015-0018,
author = {Raymond Yeh},
title = {Convergence of Transdisciplinary Education},
journal = {Journal of Integrated Design and Process Science},
volume = {19},
number = {4},
pages = {3–8},
year = {2015s},
doi = {10.3233/jid-2015-0018},
URL = {https://doi-org.crai.referencistas.com/10.3233/jid-2015-0018},
eprint = {https://doi-org.crai.referencistas.com/10.3233/jid-2015-0018}
}

@article{doi:10.1177/147509020421800103,
author = {T Zhou and K V Wong},
title = {Studying atmospheric exposure risks during oil spills using a localized computational model},
journal = {Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment},
volume = {218},
number = {1},
pages = {23–30},
year = {2004t},
doi = {10.1177/147509020421800103},
URL = {https://doi-org.crai.referencistas.com/10.1177/147509020421800103},
eprint = {https://doi-org.crai.referencistas.com/10.1177/147509020421800103},
abstract = {This paper has investigated the risk of atmospheric exposure during oil spills. Air levels of volatile components (VCs) arising from oil spills under some hypothetical scenarios have been studied using a computational model. The computational results indicate that overexposure to benzene may exist under general conditions. A table summarizing the exposure risks under various conditions is presented which may be useful in exposure risk analysis during oil spill response. The exposure to other volatile hydrocarbon components is negligible. Exposure to sulphur components occurs, but the duration is very short.}
}

