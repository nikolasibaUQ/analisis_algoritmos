@article{doi:10.1177/104538902761696814,
author = {H. T. Banks and D. G. Cole and K. M. Furati and K. Ito and G. A. Pinter},
title = {A Computational Model for Sound Field Absorption by Acoustic Arrays},
journal = {Journal of Intelligent Material Systems and Structures},
volume = {13},
number = {4},
pages = {231–240},
year = {2002a},
doi = {10.1177/104538902761696814},
URL = {https://doi-org.crai.referencistas.com/10.1177/104538902761696814},
eprint = {https://doi-org.crai.referencistas.com/10.1177/104538902761696814},
abstract = {In this paper we discuss the sound absorption property of arrays of micro-acoustic actuators at a control surface. We use the wave equation over the half plane for the velocity potential with a boundary dissipation by a proportional pressure feedback law along the half plane boundary. The feedback gain over the array is described by a distributed shape function. We develop a computational method based on the Fourier transform and employ it for analyzing and evaluating the decay rate of acoustic energy. Specifically, we carry out computations for a diffusive random initial field and report on our resulting numerical findings.}
}

@article{doi:10.1177/05390184231170567,
author = {Jonathan Bendor and Philip Petrov},
title = {Between Michigan and Rochester: Identity-based thinking is cognitively primary},
journal = {Social Science Information},
volume = {62},
number = {1},
pages = {3–30},
year = {2023b},
doi = {10.1177/05390184231170567},
URL = {https://doi-org.crai.referencistas.com/10.1177/05390184231170567},
eprint = {https://doi-org.crai.referencistas.com/10.1177/05390184231170567},
abstract = {This article synthesizes a large body of research in the social and cognitive sciences to develop a distinctly cognitive understanding of political identity. Building on dual-process and computational theories of mind, the article defends three claims about the mental and behavioral implications of identity in political domains: (1) identity-based thinking is people’s default (often fast, automatic, and cognitively inaccessible) way of mentally representing politics and of drawing inferences based on those representations; (2) people are not limited to identity-based thinking and can sometimes learn to override it via slow, volitional, and conscious reasoning; and (3) the cognitive complexity of identity-based thinking is in-between the levels of mental sophistication that the Michigan and Rochester Schools in political science posit. This account of political identity illuminates, inter alia, why even low-information voters can quickly identify their political allies and opponents, why even high-information politicians can misperceive their constituents, why affective polarization has been increasing in the United States in recent decades, and why many normative theories of justice advise people to override identity-based thinking.}
}

@article{doi:10.1258/002367798780600070,
author = {G. Curry and H. C. Hughes and D. Loseby and S. Reynolds},
title = {Advances in cubicle design using computational fluid dynamics as a design tool},
journal = {Laboratory Animals},
volume = {32},
number = {2},
pages = {117–127},
year = {1998c},
doi = {10.1258/002367798780600070},
note = {PMID:9587893},
URL = {https://doi-org.crai.referencistas.com/10.1258/002367798780600070},
eprint = {https://doi-org.crai.referencistas.com/10.1258/002367798780600070},
abstract = {As part of a recent animal facility refurbishment, a cubicle containment system was designed to increase the amount of experimental space and also provide containment facilities to support the holding and use of specialized animal models. In order to achieve this, a series of computational fluid dynamic (CFD) studies was undertaken to evaluate the effects of different airflows and in order to optimize ventilation, a variety of exhaust/supply arrangements and animal loads was employed. These studies showed that air delivered via two, opposed, low level ducts, at a rate of 20 air changes per hour and exhausted high in the cubicle above the rack, was the optimal configuration resulting in minimal turbulence, stagnation and entrainment.}
}

@article{doi:10.1177/0954410011417541,
author = {LJ Johnston},
title = {Computational fluid dynamics analysis of multi-element, high-lift aerofoil sections at transonic manoeuvre conditions},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {226},
number = {8},
pages = {912–929},
year = {2012d},
doi = {10.1177/0954410011417541},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410011417541},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410011417541},
abstract = {The application of a previously developed computational method to the prediction of high-lift performance for multi-element aerofoil sections operating at transonic flow conditions is described. The flows are computed by solving the Reynolds-averaged Navier–Stokes equations, using a full differential Reynolds-stress turbulence model to evaluate the various Reynolds-stress components appearing in the governing mean-flow equations. Algebraic wall functions are used to bridge the molecular viscosity-dominated region immediately adjacent to the aerofoil surfaces. An unstructured grid-based computational fluid dynamics (CFD) methodology is used to deal with the geometric complexity of the multi-element aerofoil configurations. Initial results are presented for the viscous, transonic flow development around the SKF 1.1 supercritical aerofoil section, equipped with either a trailing-edge flap or a leading-edge slat. Predicted surface pressure distributions generally compare well with experimental data for the two high-lift aerofoil geometries considered, at a free-stream Mach number of 0.6 and over a range of incidence angles. There are some discrepancies in the regions immediately downstream of shock wave/boundary layer interactions, possibly resulting from the use of wall-function boundary conditions in the computations. Predicted Mach number contours indicate the complexity of the transonic flow fields for high-lift configurations, with the slat wake passing through an extensive supersonic-flow region, terminated by a normal shock wave, on the main aerofoil upper surface, for example.}
}

@article{doi:10.1177/1744259117750495,
author = {Václav Kočí and Jan Kočí and Jiří Maděra and Zbyšek Pavlík and Xianglin Gu and Weiping Zhang and Robert Černý},
title = {Thermal and hygric assessment of an inside-insulated brick wall: 2D critical experiment and computational analysis},
journal = {Journal of Building Physics},
volume = {41},
number = {6},
pages = {497–520},
year = {2018e},
doi = {10.1177/1744259117750495},
URL = {https://doi-org.crai.referencistas.com/10.1177/1744259117750495},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1744259117750495},
abstract = {A combined experimental-computational approach is used for the analysis of hygrothermal performance of a brick wall provided with interior thermal insulation system. A 2D laboratory experiment is performed to determine temperature and moisture fields in a characteristic segment of the envelope over a sufficiently long period including cold winter months. Then, a computational model of moisture and heat transport is developed, using an integral two-phase balance equation capable of distinguishing between the particular phases of water and an enthalpy-based heat balance equation. A 2D computational representation of the experiment is used for model calibration and identification of unknown parameters, resulting in a very good agreement of experimental and calculated fields, with R2 between 0.9687 and 0.9888. The calibrated model is subsequently used for a long-term hygrothermal assessment of the studied detail to demonstrate the functionality of the interior thermal insulation system, as well as the applicability of the developed model.}
}

@article{doi:10.1177/07356331221143832,
author = {Siu-Cheung Kong and Bowen Liu},
title = {Supporting the Self-Regulated Learning of Primary School Students With a Performance-Based Assessment Platform for Programming Education},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {5},
pages = {977–1007},
year = {2023f},
doi = {10.1177/07356331221143832},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331221143832},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331221143832},
abstract = {This study implemented and evaluated the innovative use of a performance-based assessment platform to support the development of self-regulated learning (SRL) in senior primary students as they completed programming tasks. We embedded SRL support features into a performance-based assessment platform as scaffolding to help the students implement problem-solving strategies. A mixed-methods approach was adopted to evaluate the intervention. The students’ perceptions of their SRL skills after working through the programming tasks were measured by a survey of 45 students. The quantitative results suggested that the students benefited from the performance-based assessment platform in developing their SRL skills. A thematic analysis of interview data from 20 students further indicated that the embedded SRL scaffolding and automatic marking function helped them to solve the programming tasks. The results demonstrate that a well-designed performance-based assessment platform with embedded SRL support can be an effective tool for developing students’ SRL. The qualitative results further revealed that algorithmic thinking is an aspect of programming for which students need more SRL support.}
}

@article{doi:10.1177/0954411912437124,
author = {Jeong Hyun Lee and Jin Sun Oh and Bye Ri Yoon and Seung Hong Choi and Kyehan Rhee and Jae Young Jho and Moon Hee Han},
title = {Computational analysis of blood clot dissolution using a vibrating catheter tip},
journal = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
volume = {226},
number = {4},
pages = {337–340},
year = {2012g},
doi = {10.1177/0954411912437124},
note = {PMID:22611874},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954411912437124},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954411912437124},
abstract = {We developed a novel concept of endovascular thrombolysis that employs a vibrating electroactive polymer actuator. In order to predict the efficacy of thrombolysis using the developed vibrating actuator, enzyme (plasminogen activator) perfusion into a clot was analyzed by solving flow fields and species transport equations considering the fluid structure interaction. In vitro thrombolysis experiments were also performed. Computational results showed that plasminogen activator perfusion into a clot was enhanced by actuator vibration at frequencies of 1 and 5 Hz. Plasminogen activator perfusion was affected by the actuator oscillation frequencies and amplitudes that were determined by electromechanical characteristics of a polymer actuator. Computed plasminogen activator perfused volumes were compared with experimentally measured dissolved clot volumes. The computed plasminogen activator perfusion volumes with threshold concentrations of 16% of the initial plasminogen activator concentration agreed well with the in vitro experimental data. This study showed the effectiveness of actuator oscillation on thrombolysis and the validity of the computational plasminogen activator perfusion model for predicting thrombolysis in complex flow fields induced by an oscillating actuator.}
}

@article{doi:10.1177/20539517211062885,
author = {Federica Lucivero and Nina Hallowell},
title = {Digital/computational phenotyping: What are the differences in the science and the ethics?},
journal = {Big Data & Society},
volume = {8},
number = {2},
pages = {20539517211062884},
year = {2021h},
doi = {10.1177/20539517211062885},
URL = {https://doi-org.crai.referencistas.com/10.1177/20539517211062885},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20539517211062885},
abstract = {The concept of ‘digital phenotyping’ was originally developed by researchers in the mental health field, but it has travelled to other disciplines and areas. This commentary draws upon our experiences of working in two scientific projects that are based at the University of Oxford’s Big Data Institute – The RADAR-AD project and The Minerva Initiative – which are developing algorithmic phenotyping technologies. We describe and analyse the concepts of digital biomarkers and computational phenotyping that underlie these projects, explain how they are linked to other research in digital phenotyping and compare and contrast some of their epistemological and ethical implications. In particular, we argue that the phenotyping paradigm in both projects is grounded on an assumption of ‘objectivity’ that is articulated in different ways depending on the role that is given to the computational/digital tools. Using the concept of ‘affordance’, we show how specific functionalities relate to potential uses and social implications of these technologies and argue that it is important to distinguish among them as the concept of digital phenotyping is increasingly being used with a variety of meanings.}
}

@article{doi:10.1177/10711813241276450,
author = {Abhinay Paladugu and Alicia Fernandes and Martijn IJtsma},
title = {The Use of Computational Modeling and Simulation to Design and Evaluate a Distributed Work System},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {0},
number = {0},
pages = {10711813241276450},
year = {2024i},
doi = {10.1177/10711813241276450},
URL = {https://doi-org.crai.referencistas.com/10.1177/10711813241276450},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10711813241276450},
abstract = {Designing integrated systems of humans and automation involves envisioning how work will be performed, how it is affected by technological capabilities, and what will be helpful to support system performance. This is challenging as interactions and dynamics can create emergent effects that are difficult to predict. This demonstration aims to demonstrate the power of computational simulation in designing, verifying, and validating integrated systems of humans and automation. The demo will include an introduction to the simulation framework Work Models that Compute (WMC) used for our ongoing research, how to develop a work model in WMC, a demo of the simulation, and a demo of postprocessing visualization to analyze the simulation results. The approach can be applied in all stages of system design. With an example in aviation, we show how we use computational modeling and simulation to evaluate the robustness of envisioned operations of humans working with automated systems.}
}

@article{doi:10.1177/0735633119887508,
author = {Yizhou Qian and James Lehman},
title = {An Investigation of High School Students’ Errors in Introductory Programming: A Data-Driven Approach},
journal = {Journal of Educational Computing Research},
volume = {58},
number = {5},
pages = {919–945},
year = {2020j},
doi = {10.1177/0735633119887508},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633119887508},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633119887508},
abstract = {This study implemented a data-driven approach to identify Chinese high school students’ common errors in a Java-based introductory programming course using the data in an automated assessment tool called the Mulberry. Students’ error-related behaviors were also analyzed, and their relationships to success in introductory programming were investigated. This study identified 15 common compilation errors and 6 common test errors. The results showed that these common errors accounted for a large proportion of all errors, so identifying the common errors is important to help students succeed in introductory programming courses. Based on these common errors, five underlying student difficulties were identified and are discussed. In addition, after analyzing existing measures of students’ error-related behaviors, we developed a measure called improvement rate to quantify students’ success in fixing errors. The results of our study suggest that students’ competence of improving code is important to their success in introductory programming. We recommend researchers design and develop automated assessment tools that provide feedback messages for common student errors and instructors who explicitly teach knowledge and skills of improving code in class.}
}

@article{doi:10.1243/09544070JAUTO450,
author = {K Robinson and M Wilson and M J Leathard and J G Hawley},
title = {Computational modelling of convective heat transfer in a simulated engine cooling gallery},
journal = {Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering},
volume = {221},
number = {9},
pages = {1147–1157},
year = {2007k},
doi = {10.1243/09544070JAUTO450},
URL = {https://doi-org.crai.referencistas.com/10.1243/09544070JAUTO450},
eprint = {https://doi-org.crai.referencistas.com/10.1243/09544070JAUTO450},
abstract = {Abstract Experimental data from internal combustion (IC) engines suggests that the use of proprietary computational fluid dynamics (CFD) codes for the prediction of coolant-side heat transfer within IC engine coolant jackets often results in underprediction of the convective heat transfer coefficient. An experimental and computational study, based on a coolant gallery simulator rig designed specifically to reproduce realistic IC engine operating conditions, has been conducted to explore this issue. It is shown that the standard ‘wall function’ approach normally used in CFD models to model near-wall conditions does not adequately represent some features of the flow that are relevant in convective heat transfer. Alternative modelling approaches are explored to account for these shortcomings and an empirical approach is shown to be successful; however, the methodology is not easily transferable to other situations.}
}

@article{doi:10.1177/089443930101900105,
author = {Desmond Saunders-Newton and Harold Scott},
title = {“But the Computer Said!”: Credible Uses of Computational Modeling in Public Sector Decision Making},
journal = {Social Science Computer Review},
volume = {19},
number = {1},
pages = {47–65},
year = {2001l},
doi = {10.1177/089443930101900105},
URL = {https://doi-org.crai.referencistas.com/10.1177/089443930101900105},
eprint = {https://doi-org.crai.referencistas.com/10.1177/089443930101900105},
abstract = {There has been a continued expansion of the uses of computer-based tools and techniques in public sector endeavors: from traditional notions of data collection and management (bean counting) to the processing of data into information that supports managerial activities. Advances in technology based on emerging work in decision theory, information science, and cognitive science will allow for use of these computational models in more expansive “advisory” roles to decision makers of all types. To what degree can public sector decision makers use computational models to support or advise decision making? As these new technologies become a routine part of the policy process, will a belief in computer omnipotence tempt public sector decision makers to abdicate personal responsibility for poor choices? The authors explore the choice-related implications associated with the increased use of computer-based models, define possible computer-based decision support models (CBDSMs), and present a typology of credible uses of CBDSMs.}
}

@article{doi:10.1177/109434209000400206,
author = {Susumu Shirayama and Kunio Kuwahara},
title = {Flow Visualization in Computational Fluid Dynamics},
journal = {The International Journal of Supercomputing Applications},
volume = {4},
number = {2},
pages = {66–80},
year = {1990m},
doi = {10.1177/109434209000400206},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434209000400206},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434209000400206},
abstract = {Several flow visualization techniques using the Lagran gian approach are proposed for analyzing the numerical solutions of unsteady flow fields computed by the Eu lerian approach. We show how these methods can be used to assess the validity of solutions and to extract the nature of the flow fields. The numerical algorithms for the flow solver and the flow visualization are introduced. The incompressible Navier-Stokes equations are solved using the extended MAC method and the compressible Euler equations are solved using the TVD MacCormack method. Most of the flow visualization methods are conventional. For vector fields, however, we introduce a particle tracing algorithm that is suitable for large amounts of numerical data. We present four flow visu alizations using these methods: flow past a circular cyl inder in two dimensions, shock wave propagation over a circular cylinder, flow past a sphere, and flow around an entire automobile.}
}

@article{doi:10.1177/1687814015606307,
author = {JB Sosa and G Urquiza and JC García and LL Castro},
title = {Computational fluid dynamics simulation and geometric design of hydraulic turbine draft tube},
journal = {Advances in Mechanical Engineering},
volume = {7},
number = {10},
pages = {1687814015606307},
year = {2015n},
doi = {10.1177/1687814015606307},
URL = {https://doi-org.crai.referencistas.com/10.1177/1687814015606307},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1687814015606307},
abstract = {Any hydraulic reaction turbine is installed with a draft tube that impacts widely the entire turbine performance, on which its functions are as follows: drive the flux in appropriate manner after it releases its energy to the runner; recover the suction head by a suction effect; and improve the dynamic energy in the runner outlet. All these functions are strongly linked to the geometric definition of the draft tube. This article proposes a geometric parametrization and analysis of a Francis turbine draft tube. Based on the parametric definition, geometric changes in the draft tube are proposed and the turbine performance is modeled by computational fluid dynamics; the boundary conditions are set by measurements performed in a hydroelectric power plant. This modeling allows us to see the influence of the draft tube shape on the entire turbine performance. The numerical analysis is based on the steady-state solution of the turbine component flows for different guide vanes opening and multiple modified draft tubes. The computational fluid dynamics predictions are validated using hydroelectric plant measurements. The prediction of the turbine performance is successful and it is linked to the draft tube geometric features; therefore, it is possible to obtain a draft tube parameter value that results in a desired turbine performance.}
}

@article{doi:10.1177/154193120004402124,
author = {Pamela S. Tsang},
title = {Mental Workload Beyond Computational Complexity},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {44},
number = {21},
pages = {3-468-3–471},
year = {2000o},
doi = {10.1177/154193120004402124},
URL = {https://doi-org.crai.referencistas.com/10.1177/154193120004402124},
eprint = {https://doi-org.crai.referencistas.com/10.1177/154193120004402124},
abstract = {The information processing approach traditionally has been the theoretical foundation of mental workload. Computational neurocognitive models are emerging approaches to understanding how the brain performs cognitive functions. Computational complexity refers to the many possibilities and ambiguities intrinsic in the environmental stimuli. These models agree that the brain has limited computational power. Utility and implications of the computational approaches to the understanding of mental workload, especially that of higher-level activities such as strategic control of dynamic multiple-task performance and situation awareness will be explored.}
}

@article{doi:10.1177/2398212818810591,
author = {Anthony G. Vaccaro and Stephen M. Fleming},
title = {Thinking about thinking: A coordinate-based meta-analysis of neuroimaging studies of metacognitive judgements},
journal = {Brain and Neuroscience Advances},
volume = {2},
number = { },
pages = {2398212818810591},
year = {2018p},
doi = {10.1177/2398212818810591},
note = {PMID:30542659},
URL = {https://doi-org.crai.referencistas.com/10.1177/2398212818810591},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2398212818810591},
abstract = {Metacognition supports reflection upon and control of other cognitive processes. Despite metacognition occupying a central role in human psychology, its neural substrates remain underdetermined, partly due to study-specific differences in task domain and type of metacognitive judgement under study. It is also unclear how metacognition relates to other apparently similar abilities that depend on recursive thought such as theory of mind or mentalising. Now that neuroimaging studies of metacognition are more prevalent, we have an opportunity to characterise consistencies in neural substrates identified across different analysis types and domains. Here we used quantitative activation likelihood estimation methods to synthesise findings from 47 neuroimaging studies on metacognition, divided into categories based on the target of metacognitive evaluation (memory and decision-making), analysis type (judgement-related activation, confidence-related activation, and predictors of metacognitive sensitivity), and, for metamemory judgements, temporal focus (prospective and retrospective). A domain-general network, including medial and lateral prefrontal cortex, precuneus, and insula was associated with the level of confidence in self-performance in both decision-making and memory tasks. We found preferential engagement of right anterior dorsolateral prefrontal cortex in metadecision experiments and bilateral parahippocampal cortex in metamemory experiments. Results on metacognitive sensitivity were inconclusive, likely due to fewer studies reporting this contrast. Finally, by comparing our results to meta-analyses of mentalising, we obtain evidence for common engagement of the ventromedial and anterior dorsomedial prefrontal cortex in both metacognition and mentalising, suggesting that these regions may support second-order representations for thinking about the thoughts of oneself and others.}
}

@article{doi:10.1177/1420326X17718053,
author = {Jihong Wang and Tengfei (Tim) Zhang and Hongbiao Zhou and Shugang Wang},
title = {Inverse design of aircraft cabin environment using computational fluid dynamics-based proper orthogonal decomposition method},
journal = {Indoor and Built Environment},
volume = {27},
number = {10},
pages = {1379–1391},
year = {2018q},
doi = {10.1177/1420326X17718053},
URL = {https://doi-org.crai.referencistas.com/10.1177/1420326X17718053},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1420326X17718053},
abstract = {To design a comfortable aircraft cabin environment, designers conventionally follow an iterative guess-and-correction procedure to determine the air-supply parameters. The conventional method has an extremely low efficiency but does not guarantee an optimal design. This investigation proposed an inverse design method based on a proper orthogonal decomposition of the thermo-flow data provided by full computational fluid dynamics simulations. The orthogonal spatial modes of the thermo-flow fields and corresponding coefficients were firstly extracted. Then, a thermo-flow field was expressed into a linear combination of the spatial modes with their coefficients. The coefficients for each spatial mode are functions of air-supply parameters, which can be interpolated. With a quick map of the cause–effect relationship between the air-supply parameters and the exhibited thermo-flow fields, the optimal air-supply parameters were determined from specific design targets. By setting the percentage of dissatisfied and the predicted mean vote as design targets, the proposed method was implemented for inverse determination of air-supply parameters in two aircraft cabins. The results show that the inverse design using computational fluid dynamics-based proper orthogonal decomposition method is viable. Most of computing time lies in the construction of data samples of thermo-flow fields, while the proper orthogonal decomposition analysis and data interpolation is efficient.}
}

@article{doi:10.1177/0049124115610347,
author = {Cristobal Young and Katherine Holsteen},
title = {Model Uncertainty and Robustness: A Computational Framework for Multimodel Analysis},
journal = {Sociological Methods & Research},
volume = {46},
number = {1},
pages = {3–40},
year = {2017r},
doi = {10.1177/0049124115610347},
URL = {https://doi-org.crai.referencistas.com/10.1177/0049124115610347},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0049124115610347},
abstract = {Model uncertainty is pervasive in social science. A key question is how robust empirical results are to sensible changes in model specification. We present a new approach and applied statistical software for computational multimodel analysis. Our approach proceeds in two steps: First, we estimate the modeling distribution of estimates across all combinations of possible controls as well as specified functional form issues, variable definitions, standard error calculations, and estimation commands. This allows analysts to present their core, preferred estimate in the context of a distribution of plausible estimates. Second, we develop a model influence analysis showing how each model ingredient affects the coefficient of interest. This shows which model assumptions, if any, are critical to obtaining an empirical result. We demonstrate the architecture and interpretation of multimodel analysis using data on the union wage premium, gender dynamics in mortgage lending, and tax flight migration among U.S. states. These illustrate how initial results can be strongly robust to alternative model specifications or remarkably dependent on a knife-edge specification.}
}

@article{doi:10.1177/07356331231213548,
author = {Xinli Zhang and Yuchen Chen and Danqing Li and Lailin Hu and Gwo-Jen Hwang and Yun-Fang Tu},
title = {Engaging Young Students in Effective Robotics Education: An Embodied Learning-Based Computer Programming Approach},
journal = {Journal of Educational Computing Research},
volume = {62},
number = {2},
pages = {532–558},
year = {2024s},
doi = {10.1177/07356331231213548},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331231213548},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331231213548},
abstract = {Robotics education has received widespread attention in K-12 education. Studies have pointed out that in robotics courses, learners face challenges in learning abstract content, such as constructing a robot with a good structure and writing programs to drive a robot to complete specific learning tasks. The present study proposed the embodied learning-based computer programming approach and applied it to the LEGO Mindstorms EV3 robotics course. To evaluate its effectiveness, a quasi-experiment was conducted in one public primary school to explore its effects on students’ learning achievement, learning motivation, learning attitudes, learning engagement, and cognitive load. The experimental group (40 students) adopted the embodied learning-based computer programming approach, while the control group (40 students) adopted the conventional computer programming approach. The results showed that the experimental group had significantly better learning achievement in robotics than the control group, and that there was no significant difference in the cognitive load of the two groups. In terms of learning motivation, although both groups showed improvement, the experimental group had higher intrinsic learning motivation. In addition, the experimental group outperformed the control group with regard to learning attitudes and learning engagement (including cognitive, behavioral, and emotional engagement). Accordingly, this study could contribute to future research for developing more effective robotics teaching approaches and computer programming activity design.}
}

@article{doi:10.1177/1056789508090748,
author = {A.H. Zhao and C.L. Chow},
title = {Computational Algorithms for a Damage-coupled Cyclic Viscoplasticity Material Model},
journal = {International Journal of Damage Mechanics},
volume = {18},
number = {6},
pages = {507–532},
year = {2009t},
doi = {10.1177/1056789508090748},
URL = {https://doi-org.crai.referencistas.com/10.1177/1056789508090748},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1056789508090748},
abstract = {The primary objective of this investigation is to develop efficient and robust computational schemes for a damage-coupled cyclic thermoviscoplasticity model for solder materials. Three constitutive integration algorithms, Euler, modified Euler, and semi-implicit algorithm for the model are examined. The three algorithms for the model are coded in the commercial finite element (FE) code ABAQUS (version 6.21) via its user-defined material subroutine UMAT. Two single-step algorithms of the substep scheme are applied for the modified Euler algorithm to control the error in the integration of constitutive laws. A semi-empirical formulation is established for an adaptive time stepping algorithm that is based on the Euler algorithm. The simulations of single-element, miniature specimen and notched specimen simulations have been conducted and compared with the test results under monotonic tensile, creep, and fatigue tests of 63Sn-37Pb solder. It is observed that the explicit algorithm consistently requires much less CPU time than others. The modified Euler algorithm has shown, on the other hand, to be not only efficient but also accurate. The semi-implicit algorithm yields an accurate solution. It is worth noting that the method is also effective by applying an appropriate integration scheme.}
}

