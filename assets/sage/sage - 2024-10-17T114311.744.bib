@article{doi:10.1177/0734282918809793,
author = {Roberto A. Abreu-Mendoza and Yaira Chamorro and Esmeralda Matute},
title = {Psychometric Properties of the WRAT Math Computation Subtest in Mexican Adolescents},
journal = {Journal of Psychoeducational Assessment},
volume = {37},
number = {8},
pages = {957–972},
year = {2019a},
doi = {10.1177/0734282918809793},
URL = {https://doi-org.crai.referencistas.com/10.1177/0734282918809793},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0734282918809793},
abstract = {The goal of this study was to provide normative scores and examine the psychometric properties of the Math Computation subtest of the Wide Range Achievement Test–IV (WRAT-IV) for Mexican adolescents after the completion of junior high school. We group-administered this subtest to 1,318 first-year Mexican high school students. We then obtained its overall internal reliability and examined its underlying factor structure. Finally, we determined its concurrent and criterion validity by evaluating a subsample of 106 students that included adolescents with mathematical difficulty, mathematical talent, and typical performance. Results showed that the subtest has a good internal reliability and appropriate psychometric characteristics, suggesting its appropriateness for the detection of adolescents with particular difficulty or ability in mathematics. The exploratory factor analysis identified three factors: arithmetic, fractions and basic algebra, and rational numbers. There were also sex differences in the number of correct responses, but the effect size was small.}
}

@article{doi:10.1177/1059712315589355,
author = {Eduardo Alonso and Michael Fairbank and Esther Mondragón},
title = {Back to optimality: a formal framework to express the dynamics of learning optimal behavior},
journal = {Adaptive Behavior},
volume = {23},
number = {4},
pages = {206–215},
year = {2015b},
doi = {10.1177/1059712315589355},
URL = {https://doi-org.crai.referencistas.com/10.1177/1059712315589355},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1059712315589355},
abstract = {Whether animals behave optimally is an open question of great importance, both theoretically and in practice. Attempts to answer this question focus on two aspects of the optimization problem, the quantity to be optimized and the optimization process itself. In this paper, we assume the abstract concept of cost as the quantity to be minimized and propose a reinforcement learning algorithm, called Value-Gradient Learning (VGL), as a computational model of behavior optimality. We prove that, unlike standard models of Reinforcement Learning, Temporal Difference in particular, VGL is guaranteed to converge to optimality under certain conditions. The core of the proof is the mathematical equivalence of VGL and Pontryagin’s Minimum Principle, a well-known optimization technique in systems and control theory. Given the similarity between VGL’s formulation and regulatory models of behavior, we argue that our algorithm may provide psychologists with a tool to formulate such models in optimization terms.}
}

@article{doi:10.3233/FI-2021-2099,
author = {Kamila Barylska and Anna Gogolińska},
title = {Acyclic and Cyclic Reversing Computations in Petri Nets},
journal = {Fundamenta Informaticae},
volume = {184},
number = {4},
pages = {273–296},
year = {2022c},
doi = {10.3233/FI-2021-2099},
URL = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2099},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FI-2021-2099},
abstract = {Reversible computations constitute an unconventional form of computing where any sequence of performed operations can be undone by executing in reverse order at any point during a computation. It has been attracting increasing attention as it provides opportunities for low-power computation, being at the same time essential or eligible in various applications. In recent work, we have proposed a structural way of translating Reversing Petri Nets (RPNs) – a type of Petri nets that embeds reversible computation, to bounded Coloured Petri Nets (CPNs) – an extension of traditional Petri Nets, where tokens carry data values. Three reversing semantics are possible in RPNs: backtracking (reversing of the lately executed action), causal reversing (action can be reversed only when all its effects have been undone) and out of causal reversing (any previously performed action can be reversed). In this paper, we extend the RPN to CPN translation with formal proofs of correctness. Moreover, the possibility of introduction of cycles to RPNs is discussed. We analyze which type of cycles could be allowed in RPNs to ensure consistency with the current semantics. It emerged that the most interesting case related to cycles in RPNs occurs in causal semantics, where various interpretations of dependency result in different net’s behaviour during reversing. Three definitions of dependence are presented and discussed.}
}

@article{doi:10.1177/1468087414566513,
author = {Joshua A Bittle and Timothy J Jacobs},
title = {A computationally efficient combustion trajectory prediction model developed for real-time diesel combustion control},
journal = {International Journal of Engine Research},
volume = {17},
number = {2},
pages = {246–258},
year = {2016d},
doi = {10.1177/1468087414566513},
URL = {https://doi-org.crai.referencistas.com/10.1177/1468087414566513},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1468087414566513},
abstract = {The heterogeneous nature of diesel combustion adds many complexities that make understanding the combustion process difficult. Many researchers have made great efforts in diagnostics, prediction, and control capabilities. In this work, a computationally efficient thermodynamic-based model (15 ms on 2010 dual core processor) has been created that predicts the combustion trajectory (path through the ϕ–T plane) with the goal of bridging the gap between typical off-line engine prediction simulations and on-line real-time engine control strategies. The ϕ–T plane is often used to help illustrate the soot and NOx formation behavior during diesel combustion. The experimental engine operating conditions shown illustrate how exhaust gas recirculation influences the combustion trajectory at different timings—that is, showing the typical soot–NOx trade-off for diesel engines and the defeat of this trade-off when low-temperature combustion is obtained. The major insight gained is that the low-temperature combustion trajectory looks similar to a conventional one with just subtle differences that keep it from moving into the soot formation region. Additionally, the traditional conceptual explanations for diesel combustion are explored relative to how they are illustrated by the combustion trajectory, especially the transition from premixed to mixing-controlled combustion. Understanding that behavior in this context aids in explaining the different observations for the low-temperature combustion modes. The fact that these observations are made using this simplified modeling approach is promising for future use of this type of thermodynamic-based models in real-time engine control.}
}

@article{doi:10.1068/p230399,
author = {Muriel Boucart and Sandrine Delord and Anne Giersch},
title = {The Computation of Contour Information in Complex Objects},
journal = {Perception},
volume = {23},
number = {4},
pages = {399–409},
year = {1994e},
doi = {10.1068/p230399},
note = {PMID:7991341},
URL = {https://doi-org.crai.referencistas.com/10.1068/p230399},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p230399},
abstract = {Perceptual organisation, and especially the computation of contour information, has been the object of considerable interest in the last few years. In the first part of the paper we review recent accounts on the mechanisms involved in the processing of contour. In the second part we report an experiment designed to examine (1) how physical parameters such as spatial proximity and collinearity of elements affect the integration of global contour in objects and (2) whether the activation of stored representations of objects facilitates the computation of contour. Incomplete forms varying in the spacing and the alignment of line segments on their contour were used as stimuli in a matching task. Subjects were asked to decide which of two laterally displayed figures matched a reference form presented previously. The matching target and the distractor were physically identical but differed in their orientation. In one condition the reference object was always an outline drawing of an object. In a second condition the reference object was either a complete object or a more or less identifiable incomplete form. Little variation in performance was found for forms having continuous and discontinuous contour up to a spacing of 5 pixels (10.8 min) between elements. Response times and errors increased abruptly beyond this limit. This effect occurred in the two conditions of reference stimulus, suggesting that the computation of contour information is more affected by physical constraints at early processes than by high-level processes involving activation of stored structural representations of objects.}
}

@article{doi:10.1177/10943420211027937,
author = {J. Austin Harris and Ran Chu and Sean M Couch and Anshu Dubey and Eirik Endeve and Antigoni Georgiadou and Rajeev Jain and Daniel Kasen and M P Laiu and OE B Messer et al.},
title = {Exascale models of stellar explosions: Quintessential multi-physics simulation},
journal = {The International Journal of High Performance Computing Applications},
volume = {36},
number = {1},
pages = {59–77},
year = {2022f},
doi = {10.1177/10943420211027937},
URL = {https://doi-org.crai.referencistas.com/10.1177/10943420211027937},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10943420211027937},
abstract = {The ExaStar project aims to deliver an efficient, versatile, and portable software ecosystem for multi-physics astrophysics simulations run on exascale machines. The code suite is a component-based multi-physics toolkit, built on the capabilities of current simulation codes (in particular Flash-X and Castro), and based on the massively parallel adaptive mesh refinement framework AMReX. It includes modules for hydrodynamics, advanced radiation transport, thermonuclear kinetics, and nuclear microphysics. The code will reach exascale efficiency by building upon current multi- and many-core packages integrated into an orchestration system that uses a combination of configuration tools, code translators, and a domain-specific asynchronous runtime to manage performance across a range of platform architectures. The target science includes multi-physics simulations of astrophysical explosions (such as supernovae and neutron star mergers) to understand the cosmic origin of the elements and the fundamental physics of matter and neutrinos under extreme conditions.}
}

@article{doi:10.4137/EBO.S419,
author = {Glenn Hickey and Frank Dehne and Andrew Rau-Chaplin and Christian Blouin},
title = {SPR Distance Computation for Unrooted Trees},
journal = {Evolutionary Bioinformatics},
volume = {4},
number = { },
pages = {EBO.S419},
year = {2008g},
doi = {10.4137/EBO.S419},
note = {PMID:19204804},
URL = {https://doi-org.crai.referencistas.com/10.4137/EBO.S419},
eprint = {https://doi-org.crai.referencistas.com/10.4137/EBO.S419},
abstract = {The subtree prune and regraft distance (dSPR) between phylogenetic trees is important both as a general means of comparing phylogenetic tree topologies as well as a measure of lateral gene transfer (LGT). Although there has been extensive study on the computation of dSPR and similar metrics between rooted trees, much less is known about SPR distances for unrooted trees, which often arise in practice when the root is unresolved. We show that unrooted SPR distance computation is NP-Hard and verify which techniques from related work can and cannot be applied. We then present an efficient heuristic algorithm for this problem and benchmark it on a variety of synthetic datasets. Our algorithm computes the exact SPR distance between unrooted tree, and the heuristic element is only with respect to the algorithm’s computation time. Our method is a heuristic version of a fixed parameter tractability (FPT) approach and our experiments indicate that the running time behaves similar to FPT algorithms. For real data sets, our algorithm was able to quickly compute dSPR for the majority of trees that were part of a study of LGT in 144 prokaryotic genomes. Our analysis of its performance, especially with respect to searching and reduction rules, is applicable to computing many related distance measures.}
}

@article{doi:10.1177/1094342020918305,
author = {Yang Liu and Wissam Sid-Lakhdar and Elizaveta Rebrova and Pieter Ghysels and Xiaoye Sherry Li},
title = {A parallel hierarchical blocked adaptive cross approximation algorithm},
journal = {The International Journal of High Performance Computing Applications},
volume = {34},
number = {4},
pages = {394–408},
year = {2020h},
doi = {10.1177/1094342020918305},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342020918305},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342020918305},
abstract = {This article presents a low-rank decomposition algorithm based on subsampling of matrix entries. The proposed algorithm first computes rank-revealing decompositions of submatrices with a blocked adaptive cross approximation (BACA) algorithm, and then applies a hierarchical merge operation via truncated singular value decompositions (H-BACA). The proposed algorithm significantly improves the convergence of the baseline ACA algorithm and achieves reduced computational complexity compared to the traditional decompositions such as rank-revealing QR. Numerical results demonstrate the efficiency, accuracy, and parallel scalability of the proposed algorithm.}
}

@article{doi:10.1177/027836498900800605,
author = {Anthony A. Maciejewski and Charles A. Klein},
title = {The Singular Value Decomposition: Computation and Applications to Robotics},
journal = {The International Journal of Robotics Research},
volume = {8},
number = {6},
pages = {63–79},
year = {1989i},
doi = {10.1177/027836498900800605},
URL = {https://doi-org.crai.referencistas.com/10.1177/027836498900800605},
eprint = {https://doi-org.crai.referencistas.com/10.1177/027836498900800605},
abstract = {The singular value decomposition has been extensively used for the analysis of the kinematic and dynamic characteristics of robotic manipulators. Due to a reputation for being nu merically expensive to compute, however, it has not been used for real-time applications. This work illustrates a for mulation for the singular value decomposition that takes advantage of the nature of robotics matrix calculations to ob tain a computationally feasible algorithm. Several applica tions, including the control of redundant manipulators and the optimization of dexterity, are discussed. A detailed illus tration of the use of the singular value decomposition to deal with the general problem of singularities is also presented.}
}

@article{doi:10.1068/p120203,
author = {Michael J Morgan},
title = {Mental Rotation: A Computationally Plausible Account of Transformation through Intermediate Steps},
journal = {Perception},
volume = {12},
number = {2},
pages = {203–211},
year = {1983j},
doi = {10.1068/p120203},
note = {PMID:6689208},
URL = {https://doi-org.crai.referencistas.com/10.1068/p120203},
eprint = {https://doi-org.crai.referencistas.com/10.1068/p120203},
abstract = {A critical difficulty in theories of the ‘mental rotation’ phenomenon has been to find a computationally plausible reason why the rotation should occur in small intermediate steps. It is pointed out that this difficulty is peculiar to metrical representations: if spatial relations are presented symbolically but nonmetrically, then the iterative or recursive application of minimal transformations is memory saving. A program rotter is described to illustrate this principle.}
}

@article{doi:10.1177/17442591241252417,
author = {Y Quoc Nguyen and Trieu N Huynh and Khoa Le-Cao},
title = {Comparison of the induced flow obtained with 2D and 3D CFD simulations of a solar chimney at different width-to-gap ratios},
journal = {Journal of Building Physics},
volume = {48},
number = {1},
pages = {100–126},
year = {2024k},
doi = {10.1177/17442591241252417},
URL = {https://doi-org.crai.referencistas.com/10.1177/17442591241252417},
eprint = {https://doi-org.crai.referencistas.com/10.1177/17442591241252417},
abstract = {Solar chimneys are among the most common methods for natural ventilation of buildings. Computational Fluid Dynamics (CFD) has been widely applied in research and design of solar chimneys. Most of the previous studies are based on 2D CFD models which ignore the effects of the width (the third dimension) of the air channel. In addition, the applicability of 2D models for the solar chimneys with a low width-to-gap ratio is still questionable. This study investigates both 2D and 3D CFD models for window-sized vertical solar chimneys. The 2D model is applied to the domain comprising the central plane of the channel gap (G) and height (H) while the 3D model is applied to the domain consisting of the channel gap, height, and width (W). The flow fields, flow rates and thermal efficiencies computed with the 2D and 3D models at different heights, gaps, and widths are compared. The results show that W/G is the most crucial factor. The effects of the side walls are significant at a low W/G but gradually diminishes as W/G increases. At W/G = 15, the side wall effects are confined to a region of about 2.6% W. Particularly, for W/G>8, the differences between the 2D and 3D flow rates and thermal efficiencies are within ±5%. These findings offer a reference for researchers and engineers to select between 2D and 3D CFD models for a specific solar chimney.}
}

@article{doi:10.1177/1094342006064504,
author = {J. Nieplocha and V. Tipparaju and M. Krishnan and D. K. Panda},
title = {High Performance Remote Memory Access Communication: The Armci Approach},
journal = {The International Journal of High Performance Computing Applications},
volume = {20},
number = {2},
pages = {233–253},
year = {2006l},
doi = {10.1177/1094342006064504},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342006064504},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342006064504},
abstract = {This paper describes the Aggregate Remote Memory Copy Interface (ARMCI), a portable high performance remote memory access communication interface, developed oriinally under the U.S. Department of Energy (DOE) Advanced Computational Testing and Simulation Toolkit project and currently used and advanced as a part of the run-time layer of the DOE project, Programming Models for Scalble Parallel Computing. The paper discusses the model, addresses challenges of portable implementations, and demonstrates that ARMCI delivers high performance on a variety of platforms. Special emphasis is placed on the latency hiding mechanisms and ability to optimize noncotiguous data transfers.}
}

@article{doi:10.1177/0278364906072038,
author = {Yizhar Or and Elon Rimon},
title = {Computation and Graphical Characterization of Robust Multiple-Contact                 Postures in Two-Dimensional Gravitational Environments},
journal = {The International Journal of Robotics Research},
volume = {25},
number = {11},
pages = {1071–1086},
year = {2006m},
doi = {10.1177/0278364906072038},
URL = {https://doi-org.crai.referencistas.com/10.1177/0278364906072038},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0278364906072038},
abstract = {This paper is concerned with computation and graphical characterization of robust equilibrium postures suited to quasistatic multi-legged locomotion. Quasistatic locomotion consists of postures in which the mechanism supports itself against gravity while moving its free limbs to new positions. A posture is robust if the contacts can passively support the mechanism against gravity as well as disturbance forces generated by its moving limbs. This paper is concerned with planar mechanisms supported by frictional contacts in two-dimensional gravitational environments. The kinematic structure of the mechanism is lumped into a rigid body B having the same contacts with the environment and a variable center of mass. Inertial forces generated by moving parts of the mechanism are lumped into a neighborhood of wrenches centered at the nominal gravitational wrench. The robust equilibrium postures associated with a given set of contacts become the center-of-mass locations of B that maintain equilibrium with respect to all wrenches in the given neighborhood. The paper formulates the computation of the robust center-of-mass locations as a linear programming problem. It provides graphical characterization of the robust center-of-mass locations, and gives a geometric algorithm for computing these center-of-mass locations. The paper reports experiments validating the equilibrium criterion on a two-legged prototype. Finally, it describes initial progress toward computation of robust equilibrium postures in three dimensions.}
}

@article{doi:10.3233/ISP-220001,
author = {Guido Oud and Serge Toxopeus},
title = {A technique for efficient computation of steady yaw manoeuvres using CFD},
journal = {International Shipbuilding Progress},
volume = {69},
number = {1},
pages = {3–24},
year = {2022n},
doi = {10.3233/ISP-220001},
URL = {https://doi-org.crai.referencistas.com/10.3233/ISP-220001},
eprint = {https://doi-org.crai.referencistas.com/10.3233/ISP-220001},
abstract = {Hydrodynamic loads acting on a ship can nowadays be reliably obtained from Computational Fluid Dynamics (CFD) techniques. In particular for the determination of the hydrodynamic coefficients of a mathematical manoeuvring model, the forces and moments on a ship sailing at a drift angle or with a yaw rate can be computed efficiently with CFD. While computations with a drift angle are relatively straightforward, computations involving a yaw rate present a challenge. This challenge consists in how to deal with the grid, the setup and the ship encountering its own wake when rotating. A solution based on a single grid setup with consistent boundary conditions and utilising a body force wake damping zone to remedy this challenge is proposed in this paper, leading to an effective, fast, and accurate method to compute hydrodynamic loads of a ship in steady yaw manoeuvres.}
}

@article{doi:10.1177/00218863231175508,
author = {Ryan W. Quinn and Bret Crane and Jared D. Harris and Andrew Manikas},
title = {Designed Organizational Search: A Comparative Analysis of Alternative Procedures for Learning from Success},
journal = {The Journal of Applied Behavioral Science},
volume = {59},
number = {3},
pages = {391–425},
year = {2023o},
doi = {10.1177/00218863231175508},
URL = {https://doi-org.crai.referencistas.com/10.1177/00218863231175508},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00218863231175508},
abstract = {Sampling on the dependent variable is unlikely to be an effective way to learn and develop the strategy. Even so, organizations spend millions of dollars on processes such as Appreciative Inquiry that make inferences about how to adapt their strategies, routines, and practices based upon only successful examples. Two techniques that are common to this kind of learning process are searching solely for successful solutions and reframing search problems (e.g., unconditionally positive questions). We build a computational model by formalizing appreciative inquiry and comparing it with other, similar processes to understand their relative effectiveness. We find that the organizations simulated in our computational model almost always improved performance over time, despite learning solely from successful observations. Their relative effectiveness depended on the complexity of the problems, the number of iterations of learning, and how much the learning process preserved variety in potential solutions. These findings suggest that appreciative inquiry may be most effective when people take the cost and complexity of organizational problems into account before engaging in the learning process and adapt the process accordingly. These findings contribute to research on organizational learning by explaining why learners may benefit from structuring the way they communicate as they search, why reframing performance measures may dissolve search problems, and how designed organizational search enables managers to be more deliberate about organizational learning.}
}

@article{doi:10.3233/jid-2012-0009,
author = {Reza Shojanoori and Radmila Juric and Mahi Lohi},
title = {Computationally Significant Semantics in Pervasive     Healthcare},
journal = {Journal of Integrated Design and Process Science},
volume = {16},
number = {1},
pages = {43–62},
year = {2012p},
doi = {10.3233/jid-2012-0009},
URL = {https://doi-org.crai.referencistas.com/10.3233/jid-2012-0009},
eprint = {https://doi-org.crai.referencistas.com/10.3233/jid-2012-0009},
abstract = {Pervasive computing (PerC) is leading the way in a fast-growing trend of integrating transparently physical heterogeneous computational devices into our private and professional lives. The ubiquity of these devices and advances in developing software solutions in PerC across domains, have raised hopes for the creation of true wide-spread pervasive computing environments (PCE). In this paper we explore the possibility of applying semantics of PCEs in the healthcare domain, and in Self Care Homes (SeCH) in particular, in order to define and comment on its computationally significant semantics. Our aim is to illustrate that we can manipulate the computationally significant semantics of SeCH through OWL/SWRL enabled ontologies, as candidate technologies for achieving effective and automated decision making in SeCH. The possibility of reasoning upon OWL/SWRL enabled concepts and creating computations from them, and enables the delivery of healthcare services to SeCH residents. They are automatically supported by software applications generated from the Assistive Self Care Systems (ASeCS) software architecture, which hosts our OWL/SWRL enabled ontology and its reasoning.}
}

@article{doi:10.1177/0143624411407950,
author = {GM Stavrakakis and NM Tomazinakis and NC Markatos},
title = {Modified ‘closure’ constants of the Standard k–ε turbulence model for the prediction of wind-induced natural ventilation},
journal = {Building Services Engineering Research and Technology},
volume = {33},
number = {3},
pages = {241–261},
year = {2012q},
doi = {10.1177/0143624411407950},
URL = {https://doi-org.crai.referencistas.com/10.1177/0143624411407950},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0143624411407950},
abstract = {In this study, wind-driven natural ventilation in buildings is investigated by means of computational fluid dynamics. The airflow in and around three pilot buildings, which correspond to the most common natural-ventilation designs, i.e. cross-, windward- and leeward- single-sided ventilation, is simulated by applying both the Standard and a modified k–ε turbulence model. The latter represents a Prandtl number-modified version of the Standard k–ε model, based on the flow-variable (velocity and turbulence variables) distributions and on the atmospheric boundary layer (ABL) assumptions. Numerical results of streamwise and vertical velocity components, as well as of pressure coefficients at the facades, obtained by both turbulence models are compared with available wind tunnel experimental data found in literature. It is concluded that both models applied are in acceptable agreement with measurements, especially for the mean streamwise velocity component, while the proposed modified model is more accurate as far as flow within the windward and the internal parts (i.e. within the building) of the domain is concerned. Practical application: This study focuses on the development of a modified k–ε turbulence model for the prediction of wind-driven natural ventilation. The analysis described represents a methodology to produce ‘closure’ parameters, such as Prandtl numbers, compatible with the incoming wind characteristics (ABL). It was found that for all ventilation cases studied, i.e. cross- and single-sided ventilation, the proposed modified model is more accurate compared with the Standard k–ε model, and it accounts for the dumping effect near the walls and for kinetic energy reduction in the impinging region adequately. It is satisfying that the modified k–ε model leads to acceptable engineering results within relatively practical computer resources.}
}

@article{doi:10.4137/BBI.S5983,
author = {Daisuke Tominaga},
title = {Periodicity Detection Method for Small-Sample Time Series Datasets},
journal = {Bioinformatics and Biology Insights},
volume = {4},
number = { },
pages = {BBI.S5983},
year = {2010r},
doi = {10.4137/BBI.S5983},
note = {PMID:21151841},
URL = {https://doi-org.crai.referencistas.com/10.4137/BBI.S5983},
eprint = {https://doi-org.crai.referencistas.com/10.4137/BBI.S5983},
abstract = {Time series of gene expression often exhibit periodic behavior under the influence of multiple signal pathways, and are represented by a model that incorporates multiple harmonics and noise. Most of these data, which are observed using DNA microarrays, consist of few sampling points in time, but most periodicity detection methods require a relatively large number of sampling points. We have previously developed a detection algorithm based on the discrete Fourier transform and Akaike’s information criterion. Here we demonstrate the performance of the algorithm for small-sample time series data through a comparison with conventional and newly proposed periodicity detection methods based on a statistical analysis of the power of harmonics. We show that this method has higher sensitivity for data consisting of multiple harmonics, and is more robust against noise than other methods. Although “combinatorial explosion” occurs for large datasets, the computational time is not a problem for small-sample datasets. The MATLAB/GNU Octave script of the algorithm is available on the author’s web site: http://www.cbrc.jp/%7Etominaga/piccolo/.}
}

@article{doi:10.1177/1094342018774126,
author = {Karl-Robert Wichmann and Martin Kronbichler and Rainald Löhner and Wolfgang A Wall},
title = {Practical applicability of optimizations and performance models to complex stencil-based loop kernels in CFD},
journal = {The International Journal of High Performance Computing Applications},
volume = {33},
number = {4},
pages = {602–618},
year = {2019s},
doi = {10.1177/1094342018774126},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342018774126},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342018774126},
abstract = {This work investigates the application and interaction of optimization techniques and performance models in a computational fluid dynamics (CFD) approach employing an OpenMP parallelized, explicit, weakly compressible, finite difference–based solver for the incompressible Navier–Stokes equations using a five-point wide stencil. The presented loop and stencil optimizations lead to a 6.8× increase in per core throughput. In order to verify optimal CPU utilization, performance models are applied to the tuned code. Three different performance models are considered: a roofline-based model, utilizing purely theoretical figures, one which is enhanced by measurements, and the execution cache memory model. It is shown that the models provide reliable estimates for simple benchmarks, such as seven-point stencils for scalar Laplacians, but the estimate quality is significantly worse for the complex and tuned stencil. While it is possible to include even more details in the model, it eventually leads to a state in which it purely reproduces the benchmarks from which it was derived. Thus, the applied general-purpose performance models are found to inaccurately predict the actual performance. They overestimate the achievable performance by more than about 97% for highly tuned code. Through further code tuning, 66% of the predicted performance could be achieved.}
}

@article{doi:10.1177/0738894219881425,
author = {Joseph K Young and Steve Shellman},
title = {Protestors, terrorists or something else? How to think about dissident groups},
journal = {Conflict Management and Peace Science},
volume = {36},
number = {6},
pages = {645–660},
year = {2019t},
doi = {10.1177/0738894219881425},
URL = {https://doi-org.crai.referencistas.com/10.1177/0738894219881425},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0738894219881425},
abstract = {Many scholars of contentious politics claim there is no such thing as a group that uses only one tactic, yet scholars, pundits, and the public routinely use single-minded terms like protestors, dissidents, and terrorists. Other scholars and research programs suggest that some groups are specialists who tend to stick to a single tactic to achieve their goals, such as non-violence, violence, or specific kinds of violence, like terror. We make the claim that both sides of the debate are empirically valid and that both types of group exist. That is, some groups tend to specialize in a single tactic while others use a variety of tactics. This paper examines the empirical distribution of group types by examining the mix of tactics that groups employ. The analysis helps resolve part of the debate and pushes scholarly thinking in new directions about how often, why, and when groups operate across this spectrum.}
}

