@article{doi:10.1243/0954410041872861,
author = {O O Bendiksen},
title = {Modern developments in computational aeroelasticity},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {218},
number = {3},
pages = {157–177},
year = {2004a},
doi = {10.1243/0954410041872861},
URL = {https://doi-org.crai.referencistas.com/10.1243/0954410041872861},
eprint = {https://doi-org.crai.referencistas.com/10.1243/0954410041872861},
abstract = {Abstract A survey of the main challenges in computational aeroelasticity is presented and recent ideas and developments are discussed. Advances over the past 25 years have to a large extent been paced by the required developments in computational fluid dynamics (CFD). The fluid-structure coupling problem remains of central importance and must be addressed in a rational manner in order to obtain accurate and reliable flutter solutions. In the direct Eulerian-Lagrangian computational scheme, a consistent and efficient fluid-structure coupling is obtained by modelling and integrating the fluid-structure system as a single dynamical system, without introducing normal or assumed modes, or an artificial “virtual surface” at the boundary. This computational approach effectively eliminates the phase integration errors associated with classical methods, where the fluid and the structure are integrated sequentially using different schemes. Numerical results are presented to contrast the efficacy of the various schemes in non-linear aeroelastic and aeroservoelastic calculations.}
}

@article{doi:10.1177/1475725716673004,
author = {Steve Charlton and Karen Ryder and Jacqui Taylor},
title = {Editorial},
journal = {Psychology Learning & Teaching},
volume = {15},
number = {3},
pages = {211–213},
year = {2016b},
doi = {10.1177/1475725716673004},
URL = {https://doi-org.crai.referencistas.com/10.1177/1475725716673004},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1475725716673004}
}

@article{doi:10.1177/0162353211416437,
author = {David Yun Dai},
title = {Hopeless Anarchy or Saving Pluralism? Reflections on Our Field in Response to Ambrose, VanTassel-Baska, Coleman, and Cross},
journal = {Journal for the Education of the Gifted},
volume = {34},
number = {5},
pages = {705–730},
year = {2011c},
doi = {10.1177/0162353211416437},
URL = {https://doi-org.crai.referencistas.com/10.1177/0162353211416437},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0162353211416437},
abstract = {In this response to Ambrose, VanTassel-Baska, Coleman, and Cross’s (2010) thought-provoking article on the nature and state of the field of gifted education, the author first discusses the role of disciplinary knowledge in his field. He argues that gifted education, as a normative and practical endeavor (i.e., a profession), is different from academic disciplines in research agendas and that technical rationality is not sufficient for identifying its “best practice.” The author then suggests a “flat” structure to facilitate close collaboration between theorists, researchers, and practitioners in tackling pressing problems and fashioning innovative practices. To facilitate discussion of explorations in our practice, he delineates three basic service models or paradigms in gifted education as follows: the gifted child paradigm, the talent development paradigm, and the differentiation paradigm. He proposes five criteria for assessing their strengths and potential weaknesses. Finally, he suggests that the best way of providing evidence-based best practice is through use-inspired, design studies, which not only address the question of whether a practical model works but also specify goals, assumptions, resources, processes, and constraints involved so that “how it works” is made transparent.}
}

@article{doi:10.1177/07356331231201342,
author = {Yun Dai and Ziyan Lin and Ang Liu and Dan Dai and Wenlan Wang},
title = {Effect of an Analogy-Based Approach of Artificial Intelligence Pedagogy in Upper Primary Schools},
journal = {Journal of Educational Computing Research},
volume = {61},
number = {8},
pages = {159–186},
year = {2024d},
doi = {10.1177/07356331231201342},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331231201342},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331231201342},
abstract = {Artificial intelligence (AI) has emerged as a prominent topic in K-12 education recently. However, pedagogical design has remained a major challenge, especially among young learners. Guided by the Zone of Proximal Development theory and AI education research literature, this design-based study proposes an analogy-based pedagogical approach to support AI teaching and learning in upper primary education. This pedagogical approach is centered on human–AI comparison, where humans are gradually shifted from an analogue to a contrast to make visible the attributes, mechanisms, and processes of AI. To evaluate its effectiveness, a quasi-experimental study with mixed methods was conducted. The quantitative comparison shows that the participants in the experimental group learning with the analogy-based pedagogical approach significantly outperformed their peers with the conventional direct instructional approach in all three dimensions of AI knowledge, skills, and ethical awareness. Qualitative analyses further reveal its pedagogical benefits, including demystifying AI through relatable and engaging learning, supporting student comprehension and skill mastery, and nurturing critical thinking and attitudes. The analogy-based approach contributes to the field of K-12 AI education with an age-appropriate, child-friendly pedagogical approach. Notably, AI education should prioritize teaching for student understanding, and AI should be recognized as an independent subject with interdisciplinary applications.}
}

@article{doi:10.1177/09713557221097178,
author = {İsa Deveci and Fatma Zehra Konuş},
title = {The Predictive Power of Turkish Middle School Students’ Entrepreneurial Competencies on STEM Attitudes},
journal = {The Journal of Entrepreneurship},
volume = {31},
number = {2},
pages = {425–457},
year = {2022e},
doi = {10.1177/09713557221097178},
URL = {https://doi-org.crai.referencistas.com/10.1177/09713557221097178},
eprint = {https://doi-org.crai.referencistas.com/10.1177/09713557221097178},
abstract = {The aim of this study was to investigate the correlational and causal relationship between middle school students’ entrepreneurial competencies and science, technology, engineering and mathematics (STEM) attitudes. A total of 648 middle school students (seventh and eighth grade) participated in this study. STEM attitude scale and two entrepreneurial competency scales that were developed in different studies in the literature were used as data collection tools. In addition, a simple regression, a multiple regression and a stepwise multiple regression analysis were executed to analyse the data. The correlational analysis showed that there was a moderate level, positive correlation between the STEM attitudes of students and their overall entrepreneurial competencies. Also, the multiple regression analysis showed that entrepreneurial competencies consisting of professionalism, risk-taking, creativity and tenacity explained 41% of the change in STEM attitude. The stepwise multiple regression analysis indicated that professionalism predicted the most the STEM attitude statistically more.}
}

@article{doi:10.1037/a0032947,
author = {Dietrich Dörner and C. Dominik Güss},
title = {PSI: A Computational Architecture of Cognition, Motivation, and Emotion},
journal = {Review of General Psychology},
volume = {17},
number = {3},
pages = {297–317},
year = {2013f},
doi = {10.1037/a0032947},
URL = {https://doi-org.crai.referencistas.com/10.1037/a0032947},
eprint = {https://doi-org.crai.referencistas.com/10.1037/a0032947},
abstract = {This article describes PSI theory, which is a formalized computational architecture of human psychological processes. In contrast to other existing theories, PSI theory not only models cognitive, but also motivational and emotional processes and their interactions. The article starts with a brief overview of the theory showing the connections between its different parts. We then discuss the theory’s components in greater detail. Key constructs and processes are the five basic human needs, the satisfaction of needs using the cognitive system, including perception, schemas in memory, planning, and action. Furthermore, emotions are defined and the role of emotions in cognitive and motivational processes is elaborated, referring to a specific example. The neural basis of the PSI theory is also highlighted referring to the “quad structure,” to specific brain areas, and to thinking as scanning in a neural network. Finally, some evidence for the validity of the theory is provided.}
}

@article{doi:10.1177/0036850419873799c,
author = {Walid El-Sharoud},
title = {Book Review: Hector J. Levesque, Thinking as computation},
journal = {Science Progress},
volume = {102},
number = {3},
pages = {279–279},
year = {2019g},
doi = {10.1177/0036850419873799c},
URL = {https://doi-org.crai.referencistas.com/10.1177/0036850419873799c},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0036850419873799c}
}

@article{doi:10.1177/0735633120945935,
author = {Yue Hu and Cheng-Huan Chen and Chien-Yuan Su},
title = {Exploring the Effectiveness and Moderators of Block-Based Visual Programming on Student Learning: A Meta-Analysis},
journal = {Journal of Educational Computing Research},
volume = {58},
number = {8},
pages = {1467–1493},
year = {2021h},
doi = {10.1177/0735633120945935},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633120945935},
abstract = {Block-based visual programming tools, such as Scratch, Alice, and MIT App Inventor, provide an intuitive and easy-to-use editing interface through which to promote programming learning for novice students of various ages. However, very little attention has been paid to investigating these tools’ overall effects on students’ academic achievement and the study features that may moderate the effects of block-based visual programming from a comprehensive perspective. Thus, the present study carried out a meta-analysis to systemically examine 29 empirical studies (extracting 34 effect sizes) using experimental or quasi-experiments involving the programming learning effects of employing block-based visual programming tools to date (until the end of 2019). The results showed a small to medium significant positive overall mean effect size (fixed-effect model g = 0.37; random-effects model g = 0.47) of the use of these block-based visual programming tools with respect to students’ academic achievement. Furthermore, the overall mean effect size was significantly affected by the educational stage, programming tool used, experimental treatment, and school location. Discussions and implications based on the findings are provided.}
}

@article{doi:10.1177/20438206221075714,
author = {Agnieszka Leszczynski and Sarah Elwood},
title = {Glitch epistemologies for computational cities},
journal = {Dialogues in Human Geography},
volume = {12},
number = {3},
pages = {361–378},
year = {2022i},
doi = {10.1177/20438206221075714},
URL = {https://doi-org.crai.referencistas.com/10.1177/20438206221075714},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20438206221075714},
abstract = {This intervention advances glitches as epistemological vectors for apprehending and engaging the significance of digitally-mediated spatialities that appear nonperformative against normative scripts of urban computational paradigms. Drawing on two strands of contemporary thinking about glitches as systemic design features of digital systems and as generative fissures within them, we mobilize a queer orientation that stays with the generative tensions of urban spatialities that present as idiosyncratic and as interrupting. We mobilize this epistemological approach through illustrative U.S. based examples of seemingly abandoned shared e-bikes, performatively ‘ugly’ homes, and wilful property dilapidation wrought through the registers of desire and aesthetics. In so doing, we show how glitch empistemologies render visible how the technocapitalist manufacturing of normative spatial desires for particular kinds of urban sociospatialities and aesthetic visual signatures are both secured and interrupted on digitally-mediated and -mediatized terrains. Glitch epistemologies establish the significance of small-scale disorientations in digital urban mediations, engaging these nonperformativities and non-computes as unexceptional openings onto everyday possibilities for politics in computational cities.}
}

@article{doi:10.1177/2378023119849803,
author = {David M. Liu and Matthew J. Salganik},
title = {Successes and Struggles with Computational Reproducibility: Lessons from the Fragile Families Challenge},
journal = {Socius},
volume = {5},
number = { },
pages = {2378023119849803},
year = {2019j},
doi = {10.1177/2378023119849803},
URL = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2378023119849803},
abstract = {Reproducibility is fundamental to science, and an important component of reproducibility is computational reproducibility: the ability of a researcher to recreate the results of a published study using the original author’s raw data and code. Although most people agree that computational reproducibility is important, it is still difficult to achieve in practice. In this article, the authors describe their approach to enabling computational reproducibility for the 12 articles in this special issue of Socius about the Fragile Families Challenge. The approach draws on two tools commonly used by professional software engineers but not widely used by academic researchers: software containers (e.g., Docker) and cloud computing (e.g., Amazon Web Services). These tools made it possible to standardize the computing environment around each submission, which will ease computational reproducibility both today and in the future. Drawing on their successes and struggles, the authors conclude with recommendations to researchers and journals.}
}

@article{doi:10.1177/0954410016671343,
author = {Long Liu and Hongda Li and Haisong Ang and Tianhang Xiao},
title = {Numerical investigation of flexible flapping wings using computational fluid dynamics/computational structural dynamics method},
journal = {Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering},
volume = {232},
number = {1},
pages = {85–95},
year = {2018k},
doi = {10.1177/0954410016671343},
URL = {https://doi-org.crai.referencistas.com/10.1177/0954410016671343},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0954410016671343},
abstract = {A fluid–structure interaction numerical simulation was performed to investigate the flow field around a flexible flapping wing using an in-house developed computational fluid dynamics/computational structural dynamics solver. The three-dimensional (3D) fluid–structure interaction of the flapping locomotion was predicted by loosely coupling preconditioned Navier–Stokes solutions and non-linear co-rotational structural solutions. The computational structural dynamic solver was specifically developed for highly flexible flapping wings by considering large geometric non-linear characteristics. The high fidelity of the developed methodology was validated by benchmark tests. Then, an analysis of flexible flapping wings was carried out with a specific focus on the unsteady aerodynamic mechanisms and effects of flexion on flexible flapping wings. Results demonstrate that the flexion will introduce different flow fields, and thus vary thrust generation and pressure distribution significantly. In the meanwhile, relationship between flapping frequency and flexion plays an important role on efficiency. Therefore, appropriate combination of frequency and flexion of flexible flapping wings provides higher efficiency. This study may give instruction for further design of flexible flapping wings.}
}

@article{doi:10.3233/IA-2011-0017,
author = {Paolo Mancarella and Francesca Toni},
title = {Computational logic in agent based systems},
journal = {Intelligenza Artificiale},
volume = {5},
number = {1},
pages = {139–143},
year = {2011l},
doi = {10.3233/IA-2011-0017},
URL = {https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017},
eprint = {https://doi-org.crai.referencistas.com/10.3233/IA-2011-0017},
abstract = {We describe recent work on the deployment of computational logic to support the formalisation and implementation of agents in multi-agent systems. Several forms of computational logic systems are needed in this setting, including abductive, argumentative and preference-based systems. We briefly sketch the agent model called KGP, and an ongoing extension of it which is needed to model agents in distributed settings such as the Grid and, more generally, Service-Oriented Architectures.}
}

@article{doi:10.2310/JIM.0b013e318224d8cc,
author = {Mary F. McGuire and Madurai Sriram Iyengar and David W. Mercer},
title = {Computational Approaches for Translational Clinical Research in Disease Progression},
journal = {Journal of Investigative Medicine},
volume = {59},
number = {6},
pages = {893–903},
year = {2011m},
doi = {10.2310/JIM.0b013e318224d8cc},
URL = {https://doi-org.crai.referencistas.com/10.2310/JIM.0b013e318224d8cc},
eprint = {https://doi-org.crai.referencistas.com/10.2310/JIM.0b013e318224d8cc},
abstract = {Today, there is an ever-increasing amount of biological and clinical data available that could be used to enhance a systems-based understanding of disease progression through innovative computational analysis. In this article, we review a selection of published research regarding computational methods, primarily from systems biology, which support translational research from the molecular level to the bedside, with a focus on applications in trauma and critical care. Trauma is the leading cause of mortality in Americans younger than 45 years, and its rapid progression offers both opportunities and challenges for computational analysis of trends in molecular patterns associated with outcomes and therapeutic interventions. This review presents methods and domain-specific examples that may inspire the development of new algorithms and computational methods that use both molecular and clinical data for diagnosis, prognosis, and therapy in disease progression.}
}

@article{doi:10.1177/0306419019838880,
author = {Steven A E Miller},
title = {A contemporary course on the introduction to computational fluid dynamics},
journal = {International Journal of Mechanical Engineering Education},
volume = {48},
number = {4},
pages = {315–334},
year = {2020n},
doi = {10.1177/0306419019838880},
URL = {https://doi-org.crai.referencistas.com/10.1177/0306419019838880},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0306419019838880},
abstract = {The University of Florida Department of Mechanical and Aerospace Engineering recently created a new senior technical elective in the field of computational fluid dynamics. The main objectives of the class are learning the process of computational fluid dynamics, skepticism, a course project that uses a popular commercial solver, and a course project that involves programming a simplified computational fluid dynamics code. The course covers introductory material, history, grid generation, numerics, equations of motion, boundary conditions, solvers, turbulence models, visualization, and a number of special topics. Skepticism is enforced throughout the course and forces students to justify the validity of their approach and question numerically generated results. Students in the class undertake a course project to predict a fundamental flow-field and compare predictions with excellent measurements from the open literature. They must also create a simplified computational fluid dynamics code to predict turbulent boundary layer flow. Students have integrated these lessons within student groups across the University of Florida. The emphasis of the course is on skepticism and increasing integration with the curriculum and student group activities. We present the class philosophy for teaching undergraduate computational fluid dynamics and the outcomes of the newly developed course.}
}

@article{doi:10.1177/07356331241240047,
author = {Monika Mladenović and Žana Žanko and Goran Zaharija},
title = {From Blocks to Text: Bridging Programming Misconceptions},
journal = {Journal of Educational Computing Research},
volume = {62},
number = {5},
pages = {1302–1326},
year = {2024o},
doi = {10.1177/07356331241240047},
URL = {https://doi-org.crai.referencistas.com/10.1177/07356331241240047},
eprint = {https://doi-org.crai.referencistas.com/10.1177/07356331241240047},
abstract = {The use of a pedagogical approach mediated transfer with the bridging method has been successful in facilitating the transitions from block-based to text-based programming languages. Nevertheless, there is a lack of research addressing the impact of this transfer on programming misconceptions during the transition. The way programming concepts are taught to K-12 learners can later result in misconceptions for adult learners. The main objective was to examine the impact of mediated transfer using the bridging method pedagogical approach on the prevalence of programming misconceptions. We conducted a quasi-experimental study in school settings during informatics (computer science) classes among 163 sixth-grade students. The control group received traditional programming lectures using the text-based programming language, Python. Conversely, the experimental group utilized a mediated transfer pedagogical approach by starting with the block-based programming language MakeCode for micro:bit before transitioning to the text-based Python. Our findings indicate that the experimental group significantly reduced programming misconceptions in fundamental programming concepts: variables, sequencing, selection, and loops - compared to the control group. This suggests that the use of block-based programming language as an initial step in programming education, followed by a structured transition to text-based programming language, can effectively mitigate common misconceptions among K-12 learners.}
}

@article{doi:10.1179/030801803225010340,
author = {Roddam Narasimha},
title = {The Indian half of Needham’s question: some thoughts on axioms, models, algorithms, and computational positivism},
journal = {Interdisciplinary Science Reviews},
volume = {28},
number = {1},
pages = {54–66},
year = {2003p},
doi = {10.1179/030801803225010340},
URL = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
eprint = {https://doi-org.crai.referencistas.com/10.1179/030801803225010340},
abstract = {Much debate has taken place on Joseph Needham’s question regarding ‘the failure of China and India to give rise to distinctively modern science while being ahead of Europe for fourteen previous centuries’. It is argued in this paper that while there is probably some truth in many of the sociocultural explanations that have been offered for the failure in India, they are in the final analysis not entirely convincing. The proposal in this paper is in two parts. The first is that the scientific revolution, which was part of a European miracle, was triggered in part by the advent of a variety of technologies from China and the new numeral system and other mathematical inventions from India - both via creative West Asian intermediaries. India had experienced a mathematical (more specifically algoristic or computational) revolution heralded by Ārya-bhata in the fifth century CE. The new computational power unleashed by this revolution combined with the classical Greek penchant for axiomatised modelmaking and a technology empowered experimental philosophy, in what appears to have been a very creative and uniquely European cultural fusion that led to the scientific (and later the industrial) revolution. The second part of the proposal is that there was an epistemological reason why the Indian mathematical revolution did not lead to a corresponding ‘distinctively modern’ scientific one. The Indic approach was basically not that of modelmakers but of ingenious algorisers, and showed a deep and studied distrust of axioms and physical models. This led to an attitude described here as ‘computational positivism’, which considers observation and computation as the only things that matter. In retrospect, that distrust appears not unjustified, especially in the light of twentieth century developments in quantum and classical mechanics and in logic; but it was historically expensive for India, as Europe achieved unreasonably and unexpectedly spectacular successes in science. To the Indians, it was Newton who was the extraordinary epistemological revolutionary, not Heisenberg or Gödel. In summary, Indian science could not move forward without the modelmaking and technology enabled experimental abilities that grew in the West, just as European modelmaking had earlier been unable to progress without the advent of powerful technologies and computational tools whose roots can be traced to China and India.}
}

@article{doi:10.1177/1094342004048538,
author = {Robert W. Numrich},
title = {Performance Metrics Based on Computational Action},
journal = {The International Journal of High Performance Computing Applications},
volume = {18},
number = {4},
pages = {449–458},
year = {2004q},
doi = {10.1177/1094342004048538},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342004048538},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342004048538},
abstract = {We propose a new performance metric based on computational action. We examine work as it evolves in time and compute computational action as the integral of the work function over time. We compare the action generated at less than full power with the action that could have been generated at full power. We claim that the goal of performance optimization is to minimize lost, or wasted, action. We calculate our metric for some computers in the Top500 list (http://www.top500.org) and propose a new ranking based on least action wasted. When work is a function of the resources applied, we use the classical techniques of the calculus of variations to minimize wasted action. From the result of this exercise, we calculate productivity as the ratio of work produced to resources used.}
}

@article{doi:10.1177/0002716215569446,
author = {Matthew Brook O’Donnell and Emily B. Falk},
title = {Big Data under the Microscope and Brains in Social Context: Integrating Methods from Computational Social Science and Neuroscience},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {274–289},
year = {2015r},
doi = {10.1177/0002716215569446},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569446},
abstract = {Methods for analyzing neural and computational social science data are usually used by different types of scientists and generally seen as distinct, but they strongly complement one another. Computational social science methodologies can strengthen and contextualize individual-level analysis, specifically our understanding of the brain. Neuroscience can help to unpack the mechanisms that lead from micro- through meso- to macro-level observations. Integrating levels of analysis is essential to unified progress in social research. We present two example areas that illustrate this integration. First, combining egocentric social network data with neural variables from the “egos” provides insight about why and for whom certain types of antismoking messages may be more or less effective. Second, combining tools from natural language processing with neuroimaging reveals mechanisms involved in successful message propagation, and suggests links from microscopic to macroscopic scales.}
}

@article{doi:10.1177/1086296X231202722,
author = {Bradley Robinson},
title = {You Will Perish: A Case Study of Serendipitous Literacies and Novice Video Game Design},
journal = {Journal of Literacy Research},
volume = {55},
number = {3},
pages = {275–301},
year = {2023s},
doi = {10.1177/1086296X231202722},
URL = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1086296X231202722},
abstract = {This study focused on the digital design practices of Raul, a 15-year-old participant at a summer video game design camp for adolescents. As Raul developed his original game, You Will Perish, I wondered what his design process might reveal about (a) the practice of affectively and procedurally literate video game design and (b) the literacy pedagogies that can support such design. Guided by the concept of serendipity, I describe Raul’s design practice as an open process characterized by bouts of failure, chance, and discovery, and I examine how such forces shaped the emergence of his game. Using transversal analysis, I trace Raul’s design through an account of frustration and failure, perseverance and pride, showing how the challenges of the game’s creator become those of the game’s players. The study highlights the generative potential of serendipitous literacies wherever and whenever literacy happens.}
}

@article{doi:10.1177/00375497221098417,
author = {Jesús Manuel Rodríguez-Núñez and Aned de León and Martín E Molinar-Tabares and Mario Flores-Acosta and SJ Castillo},
title = {Computational chaos control based on small perturbations for complex spectra simulation},
journal = {SIMULATION},
volume = {98},
number = {9},
pages = {835–846},
year = {2022t},
doi = {10.1177/00375497221098417},
URL = {https://doi-org.crai.referencistas.com/10.1177/00375497221098417},
eprint = {https://doi-org.crai.referencistas.com/10.1177/00375497221098417},
abstract = {In this paper, we propose to use a computational method of chaos control to simulate complex experimental spectra. This computational chaos control technique is based on the Ott–Grebogi–York (OGY) method. We chose the logistic map as the base mathematical model for the development of our work. For the numeric part, we created arbitrary precision algorithms to generate the solutions. This way, we completely eliminated any degradation of chaos from our results. These algorithms were also necessary for the proper perturbation process that the computational chaos control method requires. We control the chaos of the logistic map in two cases of Period 1 and one case of Period 2 to demonstrate that our control method works. The behavior of a complex experimental spectrum was taken and numerically simulated. The simulated spectrum was obtained by controlling the chaos of the logistic map in a variable way with the methods proposed in this work. Our results show that it is possible to simulate very complicated experimental spectra by computationally controlling the chaos of an equation unrelated to the experimental system.}
}

@article{doi:10.1177/20539517211047725,
author = {Petter Törnberg and Justus Uitermark},
title = {For a heterodox computational social science},
journal = {Big Data & Society},
volume = {8},
number = {2},
pages = {20539517211047724},
year = {2021u},
doi = {10.1177/20539517211047725},
URL = {https://doi-org.crai.referencistas.com/10.1177/20539517211047725},
eprint = {https://doi-org.crai.referencistas.com/10.1177/20539517211047725},
abstract = {The proliferation of digital data has been the impetus for the emergence of a new discipline for the study of social life: ‘computational social science’. Much research in this field is founded on the premise that society is a complex system with emergent structures that can be modeled or reconstructed through digital data. This paper suggests that computational social science serves practical and legitimizing functions for digital capitalism in much the same way that neoclassical economics does for neoliberalism. In recognition of this homology, this paper develops a critique of the complexity perspective of computational social science and argues for a heterodox computational social science founded on the meta-theory of critical realism that is critical, methodological pluralist, interpretative and explanative. This implies diverting computational social science’ computational methods and digital data so as to not be aimed at identifying invariant laws of social life, or optimizing state and corporate practices, but to instead be used as part of broader research strategies to identify contingent patterns, develop conjunctural explanations, and propose qualitatively different ways of organizing social life.}
}

@article{doi:10.1177/0735633121992594,
author = {Meng-Jung Tsai and Ching-Yeh Wang and An-Hsuan Wu and Chun-Ying Hsiao},
title = {The Development and Validation of the Robotics Learning Self-Efficacy Scale (RLSES)},
journal = {Journal of Educational Computing Research},
volume = {59},
number = {6},
pages = {1056–1074},
year = {2021v},
doi = {10.1177/0735633121992594},
URL = {https://doi-org.crai.referencistas.com/10.1177/0735633121992594},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0735633121992594},
abstract = {Robotics education has gradually been emphasized in contemporary school curricula; however, assessment tools for robotics learning are still limited. Based on Bloom’s Taxonomy of educational objectives, this study aimed to develop the Robotics Learning Self-Efficacy Scale (RLSES) with a two-level construct of five dimensions for assessing students’ self-efficacy for learning robotics. A total of 181 elementary, junior high and senior high school students (5th–12th graders) with robotics learning experience were selected as the sample of this study. A questionnaire including 32 candidate items designed for the initial version of the RLSES was administered to the sample. An exploratory factor analysis was conducted and, finally, 16 items were drawn for the final RLSES under five subscales (Comprehension, Practice, Analysis, Application, and Collaboration), with a total explained variance of 85.28%. The Cronbach’s alpha reliability was .97 for the overall scale, ranging from .87 to .95 for the subscales. The inter-correlation analysis showed evidence of discriminant validity. Regression analysis results supported that Practice and Comprehension self-efficacy were significant predictors of Analysis, Application, and Collaboration self-efficacy, confirming the two-level (2 × 3) construct of the RLSES. Significant differences among school levels were found and are discussed.}
}

@article{doi:10.1177/2167702614565359,
author = {Thomas V. Wiecki and Jeffrey Poland and Michael J. Frank},
title = {Model-Based Cognitive Neuroscience Approaches to Computational Psychiatry: Clustering and Classification},
journal = {Clinical Psychological Science},
volume = {3},
number = {3},
pages = {378–399},
year = {2015w},
doi = {10.1177/2167702614565359},
URL = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
eprint = {https://doi-org.crai.referencistas.com/10.1177/2167702614565359},
abstract = {Psychiatric research is in crisis. We highlight efforts to overcome current challenges by focusing on the emerging field of computational psychiatry, which might enable the field to move from a symptom-based description of mental illness to descriptors based on objective computational multidimensional functional variables. We survey recent efforts toward this goal and describe a set of methods that together form a toolbox to aid this research program. We identify four levels in computational psychiatry: (a) behavioral tasks that index various psychological processes, (b) computational models that identify the generative psychological processes, (c) parameter-estimation methods concerned with quantitatively fitting these models to subject behavior by focusing on hierarchical Bayesian estimation as a rich framework with many desirable properties, and (d) machine-learning clustering methods that identify clinically significant conditions and subgroups of individuals. As a proof of principle, we apply these methods to two different data sets. Finally, we highlight challenges for future research.}
}

@article{doi:10.1177/15485129211073612,
author = {Koen van der Zwet and Ana I Barros and Tom M van Engers and Peter M A Sloot},
title = {Promises and pitfalls of computational modelling for insurgency conflicts},
journal = {The Journal of Defense Modeling and Simulation},
volume = {20},
number = {3},
pages = {333–350},
year = {2023x},
doi = {10.1177/15485129211073612},
URL = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
eprint = {https://doi-org.crai.referencistas.com/10.1177/15485129211073612},
abstract = {Insurgency conflicts pose significant challenges to societies globally. The increase of insurgency conflicts creates a need to understand how insurgencies arise, and to identify societal drivers of insurgencies or effective strategies to counter them. In this paper, we analyze the contributions of computational modeling methods for the analysis of insurgent conflicts. We formalize a specific literature-based analysis framework using the identified key factors and drivers, which enables the evaluation of specific models in this domain. Through a systematic literature search, we identify 64 computational models to apply our framework. We highlight the development and contributions of various methodologies through an in-depth analysis of 13 high-quality models. The evaluation of these computational models revealed promising directions and future topics to design specific simulation models for all identified factors. In addition, our analysis revealed specific pitfalls concerning validity issues for each of the modeling methods.}
}

@article{doi:10.2190/EC.49.4.g,
title = {Journal of Educational Computing Research Index—Contents of Volume 49, 2013},
journal = {Journal of Educational Computing Research},
volume = {49},
number = {4},
pages = {543–545},
year = {2013y},
doi = {10.2190/EC.49.4.g},
URL = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g},
eprint = {https://doi-org.crai.referencistas.com/10.2190/EC.49.4.g}
}

