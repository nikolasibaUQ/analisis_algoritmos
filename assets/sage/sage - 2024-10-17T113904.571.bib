@article{doi:10.1177/10943420241280060,
author = {Cody J Balos and Marcus Day and Lucas Esclapez and Anne M Felden and David J Gardner and Malik Hassanaly and Daniel R Reynolds and Jon S Rood and Jean M Sexton and Nicholas T Wimer et al.},
title = {SUNDIALS time integrators for exascale applications with many independent systems of ordinary differential equations},
journal = {The International Journal of High Performance Computing Applications},
volume = {0},
number = {0},
pages = {10943420241280060},
year = {2024a},
doi = {10.1177/10943420241280060},
URL = {https://doi-org.crai.referencistas.com/10.1177/10943420241280060},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10943420241280060},
abstract = {Many complex systems can be accurately modeled as a set of coupled time-dependent partial differential equations (PDEs). However, solving such equations can be prohibitively expensive, easily taxing the world’s largest supercomputers. One pragmatic strategy for attacking such problems is to split the PDEs into components that can more easily be solved in isolation. This operator splitting approach is used ubiquitously across scientific domains, and in many cases leads to a set of ordinary differential equations (ODEs) that need to be solved as part of a larger “outer-loop” time-stepping approach. The SUNDIALS library provides a plethora of robust time integration algorithms for solving ODEs, and the U.S. Department of Energy Exascale Computing Project (ECP) has supported its extension to applications on exascale-capable computing hardware. In this paper, we highlight some SUNDIALS capabilities and its deployment in combustion and cosmology application codes (Pele and Nyx, respectively) where operator splitting gives rise to numerous, small ODE systems that must be solved concurrently.}
}

@article{doi:10.5772/56760,
author = {Enrique J. Bernabeu and Angel Valera and Javier Gomez-Moreno},
title = {Distance Computation Between Non-Holonomic Motions with Constant Accelerations},
journal = {International Journal of Advanced Robotic Systems},
volume = {10},
number = {9},
pages = {329},
year = {2013b},
doi = {10.5772/56760},
URL = {https://doi-org.crai.referencistas.com/10.5772/56760},
eprint = {https://doi-org.crai.referencistas.com/10.5772/56760},
abstract = {A method for computing the distance between two moving robots or between a mobile robot and a dynamic obstacle with linear or arc-like motions and with constant accelerations is presented in this paper. This distance is obtained without stepping or discretizing the motions of the robots or obstacles. The robots and obstacles are modelled by convex hulls. This technique obtains the future instant in time when two moving objects will be at their minimum translational distance - i.e., at their minimum separation or maximum penetration (if they will collide). This distance and the future instant in time are computed in parallel. This method is intended to be run each time new information from the world is received and, consequently, it can be used for generating collision-free trajectories for non-holonomic mobile robots.}
}

@article{doi:10.1177/02632764221141804,
author = {Ryan Bishop},
title = {Bernard Stiegler and the Internation Project: An Introduction},
journal = {Theory, Culture & Society},
volume = {39},
number = {7–8},
pages = {5–17},
year = {2022c},
doi = {10.1177/02632764221141804},
URL = {https://doi-org.crai.referencistas.com/10.1177/02632764221141804},
eprint = {https://doi-org.crai.referencistas.com/10.1177/02632764221141804},
abstract = {This article serves as the introduction to the Annual Review special section entitled ‘Bernard Stiegler and the Internation Project: Computational Practices and Circumscribed Futures’. As such, it introduces the collective undertaking of the Internation Project in relation to Stiegler’s long career as a thinker, educator and community organizer. The introduction pursues a number of themes addressed in the section’s contributions, including pharmacological logic, transindividuation, computational practices, bifurcation and negentropy (means of slowing entropic processes at individual and collective levels). All of these themes pertain to the climate crises the world collectively faces and posit means by which futures can be conceived in less detrimental and destructive economic, social, technological and intellectual ways. The Internation Collective as represented and furthered in this special section responds to the demands of climate crises through a macroeconomic model designed to combat entropy at various scales, from the bio-chemical to the biosphere.}
}

@article{doi:10.1177/1073858417750466,
author = {Luca Casartelli and Alessandra Federici and Emilia Biffi and Massimo Molteni and Luca Ronconi},
title = {Are We “Motorically” Wired to Others? High-Level Motor Computations and Their Role in Autism},
journal = {The Neuroscientist},
volume = {24},
number = {6},
pages = {568–581},
year = {2018d},
doi = {10.1177/1073858417750466},
note = {PMID:29271293},
URL = {https://doi-org.crai.referencistas.com/10.1177/1073858417750466},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1073858417750466},
abstract = {High-level motor computations reflect abstract components far apart from the mere motor performance. Neural correlates of these computations have been explored both in nonhuman and human primates, supporting the idea that our brain recruits complex nodes for motor representations. Of note, these computations have exciting implications for social cognition, and they also entail important challenges in the context of autism. Here, we focus on these challenges benefiting from recent studies addressing motor interference, motor resonance, and high-level motor planning. In addition, we suggest new ideas about how one maps and shares the (motor) space with others. Taken together, these issues inspire intriguing and fascinating questions about the social tendency of our high-level motor computations, and this tendency may indicate that we are “motorically” wired to others. Thus, after furnishing preliminary insights on putative neural nodes involved in these computations, we focus on how the hypothesized social nature of high-level motor computations may be anomalous or limited in autism, and why this represents a critical challenge for the future.}
}

@article{doi:10.1177/0748730412469499,
author = {Panagiotis Fotiadis and Daniel B. Forger},
title = {Modeling the Effects of the Circadian Clock on Cardiac Electrophysiology},
journal = {Journal of Biological Rhythms},
volume = {28},
number = {1},
pages = {69–78},
year = {2013e},
doi = {10.1177/0748730412469499},
note = {PMID:23382593},
URL = {https://doi-org.crai.referencistas.com/10.1177/0748730412469499},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0748730412469499},
abstract = {An internal circadian clock regulates the electrical activity of cardiac myocytes controlling the expression of potassium channel interacting protein–2 (KChIP2), which is a key regulator of cardiac electrical activity. Here, we examine how the circadian rhythm of KChIP2 expression affects the dynamics of human and murine ventricular action potentials (APs), as well as the intervals in the equivalent electrocardiograms (ECGs) reflecting the duration of depolarization and repolarization phases of the cardiac ventricular APs (QRS and QT intervals), with mathematical modeling. We show how the internal circadian clock can control the shape of APs and, in particular, predict AP, QRS, and QT interval prolongation following KChIP2 downregulation, as well as shortening of AP, QRS, and QT interval duration following KChIP2 upregulation. Based on the circadian expression of KChIP2, we can accurately predict the circadian rhythm in cardiac electrical activity and suggest the transient outward potassium currents as the key current for circadian rhythmicity. Our modeling work predicts a smaller effect of KChIP2 on AP and QT interval dynamics in humans. Taken together, these results support the role of KChIP2 as the key regulator of circadian rhythms in the electrical activity of the heart; we provide computational models that can be used to explore circadian rhythms in cardiac electrophysiology and susceptibility to arrhythmia.}
}

@article{doi:10.1177/002221949703000102,
author = {Herbert P. Ginsburg},
title = {Mathematics Learning Disabilities: A View From Developmental Psychology},
journal = {Journal of Learning Disabilities},
volume = {30},
number = {1},
pages = {20–33},
year = {1997f},
doi = {10.1177/002221949703000102},
note = {PMID:9009878},
URL = {https://doi-org.crai.referencistas.com/10.1177/002221949703000102},
eprint = {https://doi-org.crai.referencistas.com/10.1177/002221949703000102},
abstract = {U.S. education suffers from shortcomings that put even children possessing adequate intellectual abilities at risk for low mathematics achievement. Consequently, identifying and understanding children whose academic failure is influenced by a genuine learning disability requires a complex “developmental” research agenda. This perspective suggests the use of sensitive research methods—clinical interviews, ethnographies—to examine the development of children’s construction of knowledge in the context of schooling. Researchers should consider such factors as the adequacy of classroom instruction, the availability in children of informal knowledge, the role of motivation, the effects of specific interventions, the role and operation of different cognitive processes in constructing mathematical understanding, children’s difficulties across different areas of mathematics, and the development of children’s thinking throughout the school years.}
}

@article{doi:10.1155/2015/475150,
author = {Haiping Huang and Tianhe Gong and Ping Chen and Guoxia Qiu and Ruchuan Wang},
title = {Secure Two-Party Distance Computation Protocols with a Semihonest Third Party and Randomization for Privacy Protection in Wireless Sensor Networks},
journal = {International Journal of Distributed Sensor Networks},
volume = {11},
number = {7},
pages = {475150},
year = {2015g},
doi = {10.1155/2015/475150},
URL = {https://doi-org.crai.referencistas.com/10.1155/2015/475150},
eprint = {https://doi-org.crai.referencistas.com/10.1155/2015/475150},
abstract = {Scenarios in which two nodes who distrust each other in wireless sensor networks (WSNs) would like to know the distance between them are considered. The scenario is designed to protect the private information of WSNs, in this case each node’s location, from the other nodes and from a passive attacker. The goal of the present work is to provide two novel and secure two-party distance computation protocols based on a semihonest model, the first with aid of a third party and the second based on randomization technique. Both of these protocols can extend the calculated value into a real number field. The output of the distance computation and the intermediate values in the proposed protocols are also private and not accessible to a third party or any other attackers. When executing these two protocols, security is guaranteed, and the performances of communication and computation of them are found to be satisfactory when compared to those of other similar protocols.}
}

@article{doi:10.1177/0734904121993449,
author = {Wolfram Jahn and Frane Sazunic and Carlos Sing-Long},
title = {Towards real-time fire data synthesis using numerical simulations},
journal = {Journal of Fire Sciences},
volume = {39},
number = {3},
pages = {224–239},
year = {2021h},
doi = {10.1177/0734904121993449},
URL = {https://doi-org.crai.referencistas.com/10.1177/0734904121993449},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0734904121993449},
abstract = {Synthesising data from fire scenarios using fire simulations requires iterative running of these simulations. For real-time synthesising, faster-than-real-time simulations are thus necessary. In this article, different model types are assessed according to their complexity to determine the trade-off between the accuracy of the output and the required computing time. A threshold grid size for real-time computational fluid dynamic simulations is identified, and the implications of simplifying existing field fire models by turning off sub-models are assessed. In addition, a temperature correction for two zone models based on the conservation of energy of the hot layer is introduced, to account for spatial variations of temperature in the near field of the fire. The main conclusions are that real-time fire simulations with spatial resolution are possible and that it is not necessary to solve all fine-scale physics to reproduce temperature measurements accurately. There remains, however, a gap in performance between computational fluid dynamic models and zone models that must be explored to achieve faster-than-real-time fire simulations.}
}

@article{doi:10.1155/2013/847612,
author = {Chuan Jiang and Samuel H. Huang},
title = {A Computationally Efficient and Adaptive Approach for Online Embedded Machinery Diagnosis in Harsh Environments},
journal = {Advances in Mechanical Engineering},
volume = {5},
number = { },
pages = {847612},
year = {2013i},
doi = {10.1155/2013/847612},
URL = {https://doi-org.crai.referencistas.com/10.1155/2013/847612},
eprint = {https://doi-org.crai.referencistas.com/10.1155/2013/847612},
abstract = {Condition-based monitoring (CBM) has advanced to the stage where industry is now demanding machinery that possesses self-diagnosis ability. This need has spurred the CBM research to be applicable in more expanded areas over the past decades. There are two critical issues in implementing CBM in harsh environments using embedded systems: computational efficiency and adaptability. In this paper, a computationally efficient and adaptive approach including simple principal component analysis (SPCA) for feature dimensionality reduction and K-means clustering for classification is proposed for online embedded machinery diagnosis. Compared with the standard principal component analysis (PCA) and kernel principal component analysis (KPCA), SPCA is adaptive in nature and has lower algorithm complexity when dealing with a large amount of data. The effectiveness of the proposed approach is firstly validated using a standard rolling element bearing test dataset on a personal computer. It is then deployed on an embedded real-time controller and used to monitor a rotating shaft. It was found that the proposed approach scaled well, whereas the standard PCA-based approach broke down when data quantity increased to a certain level. Furthermore, the proposed approach achieved 90% accuracy when diagnosing an induced fault compared to 59% accuracy obtained using the standard PCA-based approach.}
}

@article{doi:10.1177/1368430204046139,
author = {Tatsuya Kameda and R. Scott Tindale},
title = {Evolutionary/Adaptive Thinking as a Meta-theory for Systematic Group                 Research: An Extended ‘Fungus-eater’ Approach},
journal = {Group Processes & Intergroup Relations},
volume = {7},
number = {4},
pages = {299–304},
year = {2004j},
doi = {10.1177/1368430204046139},
URL = {https://doi-org.crai.referencistas.com/10.1177/1368430204046139},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1368430204046139}
}

@article{doi:10.1177/02683962241283051,
author = {Shohil Kishore and David Sundaram and Michael David Myers},
title = {A temporal dynamics framework and methodology for computationally intensive social media research},
journal = {Journal of Information Technology},
volume = {0},
number = {0},
pages = {02683962241283051},
year = {2024k},
doi = {10.1177/02683962241283051},
URL = {https://doi-org.crai.referencistas.com/10.1177/02683962241283051},
eprint = {https://doi-org.crai.referencistas.com/10.1177/02683962241283051},
abstract = {The growing availability of expansive social media trace data (SMTD) offers researchers promising opportunities to create rich depictions of societal and social phenomena. Despite this potential, research analysing such data often struggles to construct novel theoretical insight. This paper argues that holistically incorporating temporality enhances data collection and data analysis, subsequently facilitating process theory construction from SMTD. Recommendations to integrate temporality are outlined in the proposed Temporal Dynamics Framework and Methodology (TDFM). We apply the TDFM to investigate the temporal dynamics of mental health discourse on Twitter (now X) across different phases of the COVID-19 pandemic, theoretically framed in the context of innate psychological needs satisfaction. The findings reveal dynamic shifts in social media use, indicating that different phases of the pandemic triggered changes in the needs motivating, and being motivated by, social media use. This illustrative case reflectively evaluates the TDFM’s usefulness in contextualising SMTD collection, analytical strategies, and process theory construction by incorporating a dynamic perspective on time.}
}

@article{doi:10.1177/10943420211020803,
author = {Tzanio Kolev and Paul Fischer and Misun Min and Jack Dongarra and Jed Brown and Veselin Dobrev and Tim Warburton and Stanimire Tomov and Mark S Shephard and Ahmad Abdelfattah et al.},
title = {Efficient exascale discretizations: High-order finite element methods},
journal = {The International Journal of High Performance Computing Applications},
volume = {35},
number = {6},
pages = {527–552},
year = {2021l},
doi = {10.1177/10943420211020803},
URL = {https://doi-org.crai.referencistas.com/10.1177/10943420211020803},
eprint = {https://doi-org.crai.referencistas.com/10.1177/10943420211020803},
abstract = {Efficient exploitation of exascale architectures requires rethinking of the numerical algorithms used in many large-scale applications. These architectures favor algorithms that expose ultra fine-grain parallelism and maximize the ratio of floating point operations to energy intensive data movement. One of the few viable approaches to achieve high efficiency in the area of PDE discretizations on unstructured grids is to use matrix-free/partially assembled high-order finite element methods, since these methods can increase the accuracy and/or lower the computational time due to reduced data motion. In this paper we provide an overview of the research and development activities in the Center for Efficient Exascale Discretizations (CEED), a co-design center in the Exascale Computing Project that is focused on the development of next-generation discretization software and algorithms to enable a wide range of finite element applications to run efficiently on future hardware. CEED is a research partnership involving more than 30 computational scientists from two US national labs and five universities, including members of the Nek5000, MFEM, MAGMA and PETSc projects. We discuss the CEED co-design activities based on targeted benchmarks, miniapps and discretization libraries and our work on performance optimizations for large-scale GPU architectures. We also provide a broad overview of research and development activities in areas such as unstructured adaptive mesh refinement algorithms, matrix-free linear solvers, high-order data visualization, and list examples of collaborations with several ECP and external applications.}
}

@article{doi:10.2190/BKML-B1QV-KDN4-8ULH,
author = {D. Midian Kurland and Roy D. Pea and Catherine Clement and Ronald Mawby},
title = {A Study of the Development of Programming Ability and Thinking Skills in High School Students},
journal = {Journal of Educational Computing Research},
volume = {2},
number = {4},
pages = {429–458},
year = {1986m},
doi = {10.2190/BKML-B1QV-KDN4-8ULH},
URL = {https://doi-org.crai.referencistas.com/10.2190/BKML-B1QV-KDN4-8ULH},
eprint = {https://doi-org.crai.referencistas.com/10.2190/BKML-B1QV-KDN4-8ULH},
abstract = {This article reports on a year-long study of high school students learning computer programming. The study examined three issues: 1) what is the impact of programming on particular mathematical and reasoning abilities?; 2) what cognitive skills or abilities best predict programming ability?; and 3) what do students actually understand about programming after two years of high school study? The results showed that even after two years of study, many students had only a rudimentary understanding of programming. Consequently, it was not surprising to also find that programming experience (as opposed to expertise) does not appear to transfer to other domains which share analogous formal properties. The article concludes that we need to more closely study the pedagogy of programming and how expertise can be better attained before we prematurely go looking for significant and wide reaching transfer effects from programming.}
}

@article{doi:10.1177/1971400918759812,
author = {Erika Kristina Lindstrøm and Jakob Schreiner and Geir Andre Ringstad and Victor Haughton and Per Kristian Eide and Kent-Andre Mardal},
title = {Comparison of phase-contrast MR and flow simulations for the study of CSF dynamics in the cervical spine},
journal = {The Neuroradiology Journal},
volume = {31},
number = {3},
pages = {292–298},
year = {2018n},
doi = {10.1177/1971400918759812},
note = {PMID:29464985},
URL = {https://doi-org.crai.referencistas.com/10.1177/1971400918759812},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1971400918759812},
abstract = {Background Investigators use phase-contrast magnetic resonance (PC-MR) and computational fluid dynamics (CFD) to assess cerebrospinal fluid dynamics. We compared qualitative and quantitative results from the two methods. Methods Four volunteers were imaged with a heavily T2-weighted volume gradient echo scan of the brain and cervical spine at 3T and with PC-MR. Velocities were calculated from PC-MR for each phase in the cardiac cycle. Mean pressure gradients in the PC-MR acquisition through the cardiac cycle were calculated with the Navier-Stokes equations. Volumetric MR images of the brain and upper spine were segmented and converted to meshes. Models of the subarachnoid space were created from volume images with the Vascular Modeling Toolkit. CFD simulations were performed with a previously verified flow solver. The flow patterns, velocities and pressures were compared in PC-MR and CFD flow images. Results PC-MR images consistently revealed more inhomogeneous flow patterns than CFD, especially in the anterolateral subarachnoid space where spinal nerve roots are located. On average, peak systolic and diastolic velocities in PC-MR exceeded those in CFD by 31% and 41%, respectively. On average, systolic and diastolic pressure gradients calculated from PC-MR exceeded those of CFD by 11% and 39%, respectively. Conclusions PC-MR shows local flow disturbances that are not evident in typical CFD. The velocities and pressure gradients calculated from PC-MR are systematically larger than those calculated from CFD.}
}

@article{doi:10.1177/14690667231164096,
author = {Mpho Mafata and Maria Stander and Keabetswe Masike and Astrid Buica},
title = {Exploratory data fusion of untargeted multimodal LC-HRMS with annotation by LCMS-TOF-ion mobility: White wine case study},
journal = {European Journal of Mass Spectrometry},
volume = {29},
number = {2},
pages = {111–122},
year = {2023o},
doi = {10.1177/14690667231164096},
note = {PMID:36942424},
URL = {https://doi-org.crai.referencistas.com/10.1177/14690667231164096},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14690667231164096},
abstract = {Applied sciences have increased focus on omics studies which merge data science with analytical tools. These studies often result in large amounts of data produced and the objective is to generate meaningful interpretations from them. This can sometimes mean combining and integrating different datasets through data fusion techniques. The most strategic course of action when dealing with products of unknown profile is to use exploratory approaches. For omics, this means using untargeted analytical methods and exploratory data analysis techniques. The current study aimed to perform data fusion on untargeted multimodal (negative and positive mode) liquid chromatography–high-resolution mass spectrometry data using multiple factor analysis. The data fusion results were interpreted using agglomerative hierarchical clustering on biplot projections. The study reduced the thousands of spectral signals processed to less than a hundred features (a primary parameter combination of retention time and mass-to-charge ratios, RT_m/z). The correlations between cluster members (samples and features from) were calculated and the top 10% highly correlated features were identified for each cluster. These features were then tentatively identified using secondary parameters (drift time, ion mobility constant and collision cross-section values) from the ion mobility spectra. These ion mobility (secondary) parameters can be used for future studies in wine chemical analysis and added to the growing list of annotated chemical signals in applied sciences.}
}

@article{doi:10.1177/1094342020905971,
author = {Roberto Porcù and Edie Miglio and Nicola Parolini and Mattia Penati and Noemi Vergopolan},
title = {HPC simulations of brownout: A noninteracting particles dynamic model},
journal = {The International Journal of High Performance Computing Applications},
volume = {34},
number = {3},
pages = {267–281},
year = {2020p},
doi = {10.1177/1094342020905971},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342020905971},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342020905971},
abstract = {Helicopters can experience brownout when flying close to a dusty surface. The uplifting of dust in the air can remarkably restrict the pilot’s visibility area. Consequently, a brownout can disorient the pilot and lead to the helicopter collision against the ground. Given its risks, brownout has become a high-priority problem for civil and military operations. Proper helicopter design is thus critical, as it has a strong influence over the shape and density of the cloud of dust that forms when brownout occurs. A way forward to improve aircraft design against brownout is the use of particle simulations. For simulations to be accurate and comparable to the real phenomenon, billions of particles are required. However, using a large number of particles, serial simulations can be slow and too computationally expensive to be performed. In this work, we investigate an message passing interface (MPI) + graphics processing unit (multi-GPU) approach to simulate brownout. In specific, we use a semi-implicit Euler method to consider the particle dynamics in a Lagrangian way, and we adopt a precomputed aerodynamic field. Here, we do not include particle–particle collisions in the model; this allows for independent trajectories and effective model parallelization. To support our methodology, we provide a speedup analysis of the parallelization concerning the serial and pure-MPI simulations. The results show (i) very high speedups of the MPI + multi-GPU implementation with respect to the serial and pure-MPI ones, (ii) excellent weak and strong scalability properties of the implemented time-integration algorithm, and (iii) the possibility to run realistic simulations of brownout with billions of particles at a relatively small computational cost. This work paves the way toward more realistic brownout simulations, and it highlights the potential of high-performance computing for aiding and advancing aircraft design for brownout mitigation.}
}

@article{doi:10.1177/1059712313488782,
author = {Kristsana Seepanomwan and Daniele Caligiore and Gianluca Baldassarre and Angelo Cangelosi},
title = {Modelling mental rotation in cognitive robots},
journal = {Adaptive Behavior},
volume = {21},
number = {4},
pages = {299–312},
year = {2013q},
doi = {10.1177/1059712313488782},
URL = {https://doi-org.crai.referencistas.com/10.1177/1059712313488782},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1059712313488782},
abstract = {Mental rotation concerns the cognitive processes that allow an agent mentally to rotate the image of an object in order to solve a given task, for example to say if two objects with different orientations are the same or different. Here we present a system-level bio-constrained model, developed within a neurorobotics framework, that provides an embodied account of mental rotation processes relying on neural mechanisms involving motor affordance encoding, motor simulation and the anticipation of the sensory consequences of actions (both visual and proprioceptive). This model and methodology are in agreement with the most recent theoretical and empirical research on mental rotation. The model was validated through experiments with a simulated humanoid robot (iCub) engaged in solving a classical mental rotation test. The results of the test show that the robot is able to solve the task and, in agreement with data from psychology experiments, exhibits response times linearly dependent on the angular disparity between the objects. This model represents a novel detailed operational account of the embodied brain mechanisms that may underlie mental rotation.}
}

@article{doi:10.1177/003754976500500410,
author = {T.D. Truitt},
title = {A discussion of the EAI approach to hybrid computation},
journal = {SIMULATION},
volume = {5},
number = {4},
pages = {248–257},
year = {1965r},
doi = {10.1177/003754976500500410},
URL = {https://doi-org.crai.referencistas.com/10.1177/003754976500500410},
eprint = {https://doi-org.crai.referencistas.com/10.1177/003754976500500410}
}

@article{doi:10.1177/0957650918822949,
author = {Zhenlong Wu and Qiang Wang and Hao Huang},
title = {A methodological exploration for efficient prediction of airfoil response to gusts in wind engineering},
journal = {Proceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy},
volume = {233},
number = {6},
pages = {738–750},
year = {2019s},
doi = {10.1177/0957650918822949},
URL = {https://doi-org.crai.referencistas.com/10.1177/0957650918822949},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0957650918822949},
abstract = {This paper presents several approaches for efficient estimation of airfoil response to gust via computational fluid dynamics and reduced-order modeling. A computational fluid dynamics code enabling simulation of aerodynamics under an arbitrary-shaped discrete gust is adopted. Convolution models using baseline sharp-edge gust response either obtained by the closed-form Küssner functions or computational fluid dynamics methods are established. A parametric approximation function model for gust response is identified via the least square optimization of the computational fluid dynamics-obtained sharp-edge responses. Finally, an example taking advantage of the aerodynamic response by the above methods to simulate the aeroelastics of an airfoil performing a plunging-twisting coupled motion under various gusts is presented. The present practice indicates that the reduced-order modelings are not only more efficient compared to direct computational fluid dynamics simulations, but also have a satisfactory accuracy in gust response predictions.}
}

@article{doi:10.1177/0037549716674806,
author = {Richard J Zamora and Arthur F Voter and Danny Perez and Nandakishore Santhi and Susan M Mniszewski and Sunil Thulasidasan and Stephan J Eidenbenz},
title = {Discrete event performance prediction of speculatively parallel temperature-accelerated dynamics},
journal = {SIMULATION},
volume = {92},
number = {12},
pages = {1065–1086},
year = {2016t},
doi = {10.1177/0037549716674806},
URL = {https://doi-org.crai.referencistas.com/10.1177/0037549716674806},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0037549716674806},
abstract = {Due to its unrivaled ability to predict the dynamical evolution of interacting atoms, molecular dynamics (MD) is a widely used computational method in theoretical chemistry, physics, biology, and engineering. Despite its success, MD is only capable of modeling timescales within several orders of magnitude of thermal vibrations, leaving out many important phenomena that occur at slower rates. The temperature-accelerated dynamics (TAD) method overcomes this limitation by thermally accelerating the state-to-state evolution captured by MD. Due to the algorithmically complex nature of the serial TAD procedure, implementations have yet to improve performance by parallelizing the concurrent exploration of multiple states. Here we utilize a discrete-event-based application simulator to introduce and explore a new speculatively parallel TAD (SpecTAD) method. We investigate the SpecTAD algorithm, without a full-scale implementation, by constructing an application simulator proxy (SpecTADSim). Following this method, we discover that a non-trivial relationship exists between the optimal SpecTAD parameter set and the number of CPU cores available at run-time. Furthermore, we find that a majority of the available SpecTAD boost can be achieved within an existing TAD application using relatively simple algorithm modifications.}
}

