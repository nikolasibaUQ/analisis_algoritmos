@article{RONGHUA2024e27753,
title = {Improved ant colony optimization for safe path planning of AUV},
journal = {Heliyon},
volume = {10},
number = {7},
pages = {e27753},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e27753},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024037848},
author = {Meng Ronghua and Cheng Xinhao and Wu Zhengjia and  {Du xuan}},
keywords = {Improved ant colony optimization, Safety factors, Dam inspections},
abstract = {In order to address the autonomous underwater vehicle navigation challenge for dam inspections, with the goal of enabling safe inspections and reliable obstacle avoidance, an improved smooth Ant Colony Optimization algorithm is proposed for path planning. This improved algorithm would optimize the smoothness of the path besides the robustness, avoidance of local optima, and fast computation speed. To achieve the goal of reducing turning time and improving the directional effect of path selection, a corner-turning heuristic function is introduced. Experimental simulation results show that the improved algorithm performs best than other algorithms in terms of path smoothness and iteration stability in path planning.}
}
@article{ARORA2022108615,
title = {Music as a blend of spirituality, culture, and mind mollifying drug},
journal = {Applied Acoustics},
volume = {189},
pages = {108615},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108615},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X2100709X},
author = {Shefali Arora and Abhinav Tyagi},
keywords = {Music, Science, Emotions, Society, Health, COVID-19 etc},
abstract = {Science inspires music more often than human imagination. Music is an integral part of all societies, including animal ones. It is behaving like an instrument for digesting information. It has been proven to help in healing the body, mind, and culture. Music can maintain and regulate emotion. It is a common thread among large social groups and is used as a tool to navigate through life. Real science and real music require a steady thinking process. It is a way of finding compatibility within a society as well as developing a link with other societies. Music plays a developmental role in a person’s identity, cultural worldview and permeates through life. In nutshell “Science explains Music and Music makes us The Human”}
}
@article{BURRIS1992175,
title = {Discriminator varieties and symbolic computation},
journal = {Journal of Symbolic Computation},
volume = {13},
number = {2},
pages = {175-207},
year = {1992},
issn = {0747-7171},
doi = {https://doi.org/10.1016/S0747-7171(08)80089-2},
url = {https://www.sciencedirect.com/science/article/pii/S0747717108800892},
author = {Stanley Burris},
abstract = {We look at two aspects of discriminator varieties which could be of considerable interest in symbolic computation:1.discriminator varieties are unitary (i.e., there is always a most general unifier of two unifiable terms), and2.every mathematical problem can be routinely cast in the form†p1 ≈ q1, …, pk ≈ qk implies the equation x ≈ y. Item (l) offers possibilities for implementations in computational logic, and (2) shows that Birkhoff's five rules of inference for equational logic are all one needs to prove theorems in mathematics.}
}
@article{XU2021104922,
title = {Brain decoding in multiple languages: Can cross-language brain decoding work?},
journal = {Brain and Language},
volume = {215},
pages = {104922},
year = {2021},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2021.104922},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X2100016X},
author = {Min Xu and Duo Li and Ping Li},
keywords = {Cross-language brain decoding, Neural representation, Multivariate pattern analysis, Computational modeling, Multilingualism},
abstract = {The approach of cross-language brain decoding is to use models of brain decoding from one language to decode stimuli of another language. It has the potential to provide new insights into how our brain represents multiple languages. While it is possible to decode semantic information across different languages from neuroimaging data, the approach’s overall success remains to be tested and depends on a number of factors such as cross-language similarity, age of acquisition/proficiency levels, and depth of language processing. We expect to see continued progress in this domain, from a traditional focus on words and concrete concepts toward the use of naturalistic experimental tasks involving higher-level language processing (e.g., discourse processing). The approach can also be applied to understand how cross-modal, cross-cultural, and other nonlinguistic factors may influence neural representations of different languages. This article provides an overview of cross-language brain decoding with suggestions for future research directions.}
}
@article{LAWRENCE2023100786,
title = {Translational argument technology: Engineering a step change in the argument web},
journal = {Journal of Web Semantics},
volume = {77},
pages = {100786},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100786},
url = {https://www.sciencedirect.com/science/article/pii/S157082682300015X},
author = {John Lawrence and Jacky Visser and Chris Reed},
keywords = {Argumentation, Argument analytics, Argument mining, Argument technology, Argument web, Debate technology},
abstract = {Following the establishment in 2006 of a representational standard for the computational handling of structures of argumentation, the Argument Interchange Format, it became possible to develop a vision for the coherent integration of multifarious services, components and tools that create, consume, navigate, analyse, evaluate and manipulate arguments and debates. This vision was the Argument Web with theoretical foundations laid by Rahwan et al. (2007), and practical engineering work described by Bex et al. (2013). Over the intervening period, the key challenge has been to demonstrate the practical and societal value of the Argument Web by taking its tools and applications to larger audiences. This paper lays out three approaches by which the Argument Web has been scaled up in this way, each in partnership with the BBC, and each with different kinds of evaluation and impact. Transitioning these technologies to large user groups paves the way for broader-scale uptake of the Argument Web and heralds the translation from lab to real-world application for a substantial research community working in argument technology.}
}
@article{ZHANG2010S238,
title = {Biomimetic Construction of Category Mental Imagery Based on Recognition Mechanism of Visual Cortex of Human Brain},
journal = {Journal of Bionic Engineering},
volume = {7},
pages = {S238-S244},
year = {2010},
issn = {1672-6529},
doi = {https://doi.org/10.1016/S1672-6529(09)60241-9},
url = {https://www.sciencedirect.com/science/article/pii/S1672652909602419},
author = {Xianghe Zhang and Dan Wang and Luquan Ren and Pingping Liu},
keywords = {multi-dimensional space biomimetic informatics, artificial intelligence, cognitive science, mental imagery, visual cortex, object recognition},
abstract = {The principle of homology-continuity in Multi-Dimensional Biomimetic Informatics Space is applied to construct the identifying mechanism of category of deep representation of mental imagery. The model of each cerebral region involved in recognizing is established respectively and a feedforward method for establishing category mental imagery is proposed. First, the model of feature acquisition is developed based on Hubel-Wiesel model, and Gaussian function is used to simulate the simple cell receptive field to satisfy the specific function of visual cortex. Second, multiple input aggregation operation is employed to simulate the feature output of complex cells to get the invariance representation in feature space. Then, imagery basis is extracted by unsupervised learning algorithm based on the primary feature and category mental imagery is obtained by building Radial Basis Function (RBF) network. Finally, the system model is tested by training set and test set composed of real images. Experimental results show that the proposed method can establish valid deep representation of these samples, based on which the biomimetic construction of category mental imagery can be achieved. This method provides a new idea for solving imagery problem and studying imagery thinking.}
}
@article{GILBERT2018278,
title = {Decoding intentions of self and others from fMRI activity patterns},
journal = {NeuroImage},
volume = {172},
pages = {278-290},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2017.12.090},
url = {https://www.sciencedirect.com/science/article/pii/S105381191731114X},
author = {Sam J. Gilbert and Hoki Fung},
keywords = {Intentions, MVPA, fMRI},
abstract = {Previous studies using multi-voxel pattern analysis have decoded the content of participants' delayed intentions from patterns of fMRI data. Here we investigate whether this technique can be used to decode not only participants' own intentions, but also their representation of the intentions held by other people. In other words: if Sam is thinking about Hoki, can we decode the content of Hoki's intention by scanning Sam's brain? We additionally distinguished two components of intentions: action-plans versus goals, and included novel control analyses that allowed us to distinguish intending an outcome from simply expecting it to occur or simulating its consequences. Regions of frontal, parietal, and occipital cortex contained patterns from which it was possible to decode intentions of both self and other. Furthermore, crossclasification between self and other was possible, suggesting overlap between the two. Control analyses suggested that these results reflected visuo-spatial processes by which intentions were generated in our paradigm, rather than anything special about intentions per se. There was no evidence for any representation of intentions as mental states distinct from visuospatial processes involved in generating their content and/or simulating their outcomes. These findings suggest that the brain activity patterns decoded in intention-decoding fMRI studies may reflect domain-general processes rather than being intention-specific.}
}
@article{SCHUMNY1993319,
title = {Nanosystems - molecular machinery, manufacturing, and computation: by K. Eric Drexler. John Wiley & Sons, Chichester, England, 1992. ISBN 0-471-57518-6. 556 pages. Illustrated, Appendices, Glossary with detailed explanations, 337 references, extended Index.},
journal = {Computer Standards & Interfaces},
volume = {15},
number = {2},
pages = {319-320},
year = {1993},
note = {Object-Oriented Reference Models},
issn = {0920-5489},
doi = {https://doi.org/10.1016/0920-5489(93)90019-N},
url = {https://www.sciencedirect.com/science/article/pii/092054899390019N},
author = {Harald Schumny}
}
@article{ZHAO2024102465,
title = {GA-GGD: Improving semantic discriminability in graph contrastive learning via Generative Adversarial Network},
journal = {Information Fusion},
volume = {110},
pages = {102465},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102465},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002434},
author = {Jitao Zhao and Dongxiao He and Meng Ge and Yongqi Huang and Lianze Shan and Yongbin Qin and Zhiyong Feng},
keywords = {Graph representation learning, Generative Adversarial Network, Graph contrastive learning, Adversarial Machine Learning, Semantic discriminability},
abstract = {Graph contrastive learning has garnered considerable research interest due to its ability to effectively embed graph data without manual labels. Among them, methods based on Deep Graph Infomax (DGI) have been widely studied and favored in the industry because of their fast training speed, applicability to large-scale data. DGI-based methods usually obtain a noise graph through node shuffling. The proxy task of these methods encourages the encoder to distinguish whether the nodes come from the original graph or the noise graph, thereby maximizing the mutual information between the node representation and the graph it belongs to, while also maximizing the Jenson–Shannon divergence between the nodes of original graph and noise graph. However, we argue that these approaches only enable the encoder to differentiate between semantically meaningful graphs and noise graphs, but not to effectively identify different semantic graphs. This leads to the inability of the encoder to effectively embed information between different semantics, significantly reducing the robustness and affecting the performance of downstream tasks. In addition, this training mode makes the model more sensitive to attacks. To improve their semantic discriminability, we take advantage of the natural ability of generative adversarial networks to generate semantic data, proposing a method called Generative Adversarial Graph Group Discrimination (GA-GGD). Specifically, it consists of a graph group discriminator and a semantic attack generator. The discriminator aims to encode the graph and identify whether nodes originate from the original graph. The goal of the generator is to use random features and graph structure to find vulnerabilities of discriminator and generate node representations with similar but wrong semantic to confuse the discriminator. GA-GGD can improve the model’s semantic information embedding without significantly increasing computational overhead and memory occupancy. We test the effectiveness of the proposed model on commonly used data sets and large-scale datasets, as well as in various downstream tasks such as classification, clustering, and adversarial attacks defence. A wealth of experimental results confirm the efficacy of the proposed model.}
}
@article{SAYALI2023614,
title = {The costs and benefits of psychedelics on cognition and mood},
journal = {Neuron},
volume = {111},
number = {5},
pages = {614-630},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011527},
author = {Ceyda Sayalı and Frederick S. Barrett},
keywords = {psychedelics, cognitive control, meta-control, creativity, cognitive flexibility, cognitive stability, dopamine, serotonin, dose-dependency, baseline dependency},
abstract = {Summary
Anecdotal evidence has indicated that psychedelic substances may acutely enhance creative task performance, although empirical support for this claim is mixed at best. Clinical research has shown that psychedelics might have enduring effects on mood and well-being. However, there is no neurocognitive framework that ties acute changes in cognition to long-term effects in mood. In this review, we operationalize creativity within an emerging cognitive control framework and assess the current empirical evidence of the effects of psychedelics on creativity. Next, we leverage insights about the mechanisms and computations by which other psychoactive drugs act to enhance versus impair cognition, in particular to those that act on catecholamines, the neurophysiological consequences of which are relatively well understood. Finally, we use the same framework to link the suggested psychedelic-induced improvements in creativity with enduring psychedelic-induced improvements in mood.}
}
@article{MEY1988743,
title = {Computation and the soul},
journal = {Journal of Pragmatics},
volume = {12},
number = {5},
pages = {743-789},
year = {1988},
issn = {0378-2166},
doi = {https://doi.org/10.1016/0378-2166(88)90056-2},
url = {https://www.sciencedirect.com/science/article/pii/0378216688900562},
author = {Jacob L. Mey and Mary Talbot},
abstract = {This article is both a review of Sperber and Wilson's Relevance and a broader critical discussion of linguistic pragmatics, from which Relevance has arisen. Four separate sections focus on Communication, Assumptions, the Metaphor of the Black Box and the Principle of Relevance itself. The authors conclude that the reductionist model of the human mind as an information-processing device, developed by Sperber and Wilson, is irredeemably asocial and therefore relevant to neither communication nor cognition.}
}
@article{LIU2022102936,
title = {A review of spatially-explicit GeoAI applications in Urban Geography},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {112},
pages = {102936},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102936},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001339},
author = {Pengyuan Liu and Filip Biljecki},
keywords = {Urban studies, Deep learning, Socio-economics, Location encoder, Graph neural network},
abstract = {Urban Geography studies forms, social fabrics, and economic structures of cities from a geographic perspective. Catalysed by the increasingly abundant spatial big data, Urban Geography seeks new models and research paradigms to explain urban phenomena and address urban issues. Recent years have witnessed significant advances in spatially-explicit geospatial artificial intelligence (GeoAI), which integrates spatial studies and AI, primarily focusing on incorporating spatial thinking and concept into deep learning models for urban studies. This paper provides an overview of techniques and applications of spatially-explicit GeoAI in Urban Geography based on 581 papers identified using a systematic review approach. We examined and screened papers in three scopes of Urban Geography (Urban Dynamics, Social Differentiation of Urban Areas, and Social Sensing) and found that although GeoAI is a trending topic in geography and the applications of deep neural network-based methods are proliferating, the development of spatially-explicit GeoAI models is still at their early phase. We identified three challenges of existing models and advised future research direction towards developing multi-scale explainable spatially-explicit GeoAI. This review paper acquaints beginners with the basics of GeoAI and state-of-the-art and serve as an inspiration to attract more research in exploring the potential of spatially-explicit GeoAI in studying the socio-economic dimension of the city and urban life.}
}
@article{VERDECCHIA2022100767,
title = {The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {35},
pages = {100767},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000889},
author = {Roberto Verdecchia and Patricia Lago and Carol {de Vries}},
keywords = {Sustainability, Green IT, Energy efficiency, Digital infrastructures, Data centers, Cloud, Landscape, Qualitative research},
abstract = {Background:
Digital infrastructures, i.e., ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way?
Objective:
The goal of this study is to understand what is the future of sustainable digital infrastructures, in terms of: which solutions are, or will be, available to sustainably evolve digital infrastructures, and which are the related adoption factors, impediments, and open problems.
Method:
We carried out a 3-phase mixed-method qualitative empirical study, comprising semi-structured interviews, followed by focus groups, and a plenary session with parallel working groups. In total, we conducted 13 sessions involving 48 digital infrastructure practitioners and researchers.
Results:
From our investigation emerges a landscape for sustainable digital infrastructures, composed of 30 solutions, 5 adoption factors, 4 impediments, and 13 open problems. We further synthesized our results in 4 incremental scenarios, which outline the future evolution of sustainable digital infrastructures.
Conclusions:
From an initial shift from on-premise to the cloud, as time progresses, digital infrastructures are expected to become increasingly distributed, till it will be possible to dynamically allocate resources by following time, space, and energy. Numerous solutions will support this change, but digital infrastructures are envisaged to be able to evolve sustainably only by (i) gaining a wider awareness of digital sustainability, (ii) holding every party accountable for their sustainability throughout value chains, and (iii) establishing cross-domain collaborations.}
}
@article{SAMSONOVICH2022824,
title = {Key Advanced Research Initiative: A Manifesto for the New-Generation Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {213},
pages = {824-831},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.140},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922018397},
author = {Alexei V. Samsonovich and Sergey A. Shumsky and Valery E. Karpov and Artemy A. Kotov and Anton G. Kolonin},
keywords = {AGI, humanlike AI, strong AI, virtual evolution, machine learning, evolutionary computation, artificial creativity, anthropocentric AI},
abstract = {The goal here is to identify key directions for the future advanced research initiatives in Artificial Intelligence (AI) and beyond. The following areas are identified as having particular importance: (1) socially emotional, ethical, and moral AI, (2) self-developing and self-sustainable AI, and (3) human-analogous AI, inspired by the human psychology. As a result, a general concept is formulated with the intent to clarify and unify the currently popular slogans, including Artificial General Intelligence (AGI), Strong AI, Human-Level or Humanlike AI (HLAI), Brain-Inspired or Biologically Inspired Cognitive Architectures (BICA), and more. The key idea of the proposed concept is that future AI must open a new angle of view and new perspectives to humans, thereby enriching and transforming the society, helping it to solve its problems and taking the civilization to a new level. While being created by humans, for humans, and fully compatible with humans at the social level, it will not be “a human in silicon”, but rather an “alien”: intelligent, friendly, and welcome. Its principles will combine preprogrammed basic functions and its own natural ontogeny in a virtual social environment. Forms of implementation will range from virtual entities to wearable electronics and autonomous robots. The expected impact on the society will be immense and crucial for its survival.}
}
@article{WU2024112197,
title = {A multi-strategy three-way decision approach for tri-state risk loss under q-rung orthopair fuzzy environment},
journal = {Applied Soft Computing},
volume = {167},
pages = {112197},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112197},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624009712},
author = {Ping Wu and Yihua Zhong and Chuan Chen and Yanlin Wang and Chao Min},
keywords = {Three-way decision, q-rung orthopair fuzzy sets, Tri-state risk loss, Multi-strategy perspective, Threshold theorem},
abstract = {Addressing the decision-making challenge arising from the uncertainty of human cognition, three-way decision (3WD) and q-rung orthopair fuzzy sets (q-ROFSs) are integrated in this paper to propose a multi-strategy three-way decision approach (MS3WDA) for tri-state risk loss (TSRL) under q-rung orthopair fuzzy environment. Based on the ternary thinking of human cognition, the risk loss with hesitation state is considered and constructed under q-rung orthopair fuzzy environment. The TSRL with hesitation state is further constructed by combining the q-rung orthopair fuzzy (q-ROF) information. The conditional probability adopted by the original object classes is improved and extended by the three components of q-ROFSs. Next, the TSRL with q-ROF information and three components of q-ROFSs are integrated with decision-theoretic rough sets (DTRSs) to establish a novel 3WD model. Some relevant properties are also analyzed and discussed for the developed 3WD model. Then, its multi-strategy decision method is proposed based on the multi-strategy perspective. The related strategies with five different levels are designed by considering three different risk appetite perspectives and four different aspects of q-ROF information. The relevant threshold theorems are also given and proved to further provide the theoretical support for our MS3WDA. According to the five different strategies, we further derive the corresponding decision rules of MS3WDA. The key steps and specific algorithm are summarized for MS3WDA. Finally, a case study is provided to demonstrate the practicability and feasibility of MS3WDA. Meanwhile, the rationality, robustness and superiority of MS3WDA are further validated by the sensitivity analysis and comparative analysis.}
}
@article{WANG20221,
title = {The past and future of mapping the biomarkers of psychosis},
journal = {Current Opinion in Behavioral Sciences},
volume = {43},
pages = {1-5},
year = {2022},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2021.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352154621001261},
author = {Ling-Ling Wang and Simon SY Lui and Raymond CK Chan},
abstract = {Biomarker research has investigated the neurobiological basis for individual differences in liability to psychosis. However, few biomarkers for psychosis have been consistently found to be useful. This paper reviews several previous approaches to identify putative biomarkers of liability to psychosis, and then highlights the lessons that we have learned. We argue that limiting our research to clinical patients at the extreme of the psychosis continuum would likely obscure our knowledge as to how a minority of the general population would develop psychosis. Research on putative neurobiological origins of inter-individual differences in personality traits may be useful in mapping the biomarkers of psychosis. To identify biomarkers applicable to the general population, we advocate the transdiagnostic and psychosis continuum approach. We also advocate the use of multivariate analyses and computational modelling to tackle complex multi-modal datasets. More research should be conducted to study intra-individual variations over different ranges of timescale.}
}
@article{THANHEISER2024101176,
title = {Introduction to the virtual special issue: Mathematics that underpins social issues},
journal = {The Journal of Mathematical Behavior},
volume = {75},
pages = {101176},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101176},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000531},
author = {Eva Thanheiser and Ami Mamolo},
keywords = {Mathematics in Society, Educational Research, Social Issues, Mathematical Worldview, Numeracy, Mathematical Literacy},
abstract = {This Virtual Special Issue on Mathematics in Society: Exploring the Mathematics that Underpins Social Issues features 13 articles which expand our understanding of how people build, retain, communicate, apply, and comprehend mathematical ideas as they relate to social and societal issues. The focus is on education research that explores the ways in which mathematics and a mathematical worldview can influence choices, on educational, personal and societal levels. We take a broad view and raise questions about what it means to be mathematical in society, and we consider the multifaceted ways in which abilities to derive and interpret information presented mathematically are also necessary in and for society.}
}
@article{TABACHNECKSCHIJF1997305,
title = {CaMeRa: A computational model of multiple representations},
journal = {Cognitive Science},
volume = {21},
number = {3},
pages = {305-350},
year = {1997},
note = {Advances in analogy research: Integration of theory and data from the cognitive, computational, and neural sciences},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(99)80026-3},
url = {https://www.sciencedirect.com/science/article/pii/S0364021399800263},
author = {Hermina J.M. Tabachneck-Schijf and Anthony M. Leonardo and Herbert A. Simon},
abstract = {This research aims to clarify, by constructing and testing a computer simulation, the use of multiple representations in problem solving, focusing on their role in visual reasoning. The model is motivated by extensive experimental evidence in the literature for the features it incorporates, but this article focuses on the system's structure. We illustrate the model's behavior by simulating the cognitive and perceptual processes of an economics expert as he teaches some well-learned economics principles while drawing a graph on a blackboard. Data in the experimental literature and concurrent verbal protocols were used to guide construction of a linked production system and parallel network, CaMeRa (Computation with Multiple Representations), that employs a “Mind's Eye” representation for pictorial information, consisting of a bitmap and associated node-link structures. Propositional list structures are used to represent verbal information and reasoning. Small individual pieces from the different representations are linked on a sequential and temporary basis to form a reasoning and inferencing chain, using visually encoded information recalled to the Mind's Eye from long-term memory and from cues recognized on an external display. CaMeRa, like the expert, uses the diagrammatic and verbal representations to complement one another, thus exploiting the unique advantages of each.}
}
@incollection{TIN1994299,
title = {Baby-Sit: Towards a situation-theoretic computational environment},
editor = {Carlos Martín-Vide},
series = {North-Holland Linguistic Series: Linguistic Variations},
publisher = {Elsevier},
volume = {56},
pages = {299-308},
year = {1994},
booktitle = {Current Issues in Mathematical Linguistics},
issn = {0078-1592},
doi = {https://doi.org/10.1016/B978-0-444-81693-1.50034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444816931500348},
author = {Erkan Tin and Varol Akman},
abstract = {Publisher Summary
This chapter provides an overview of a situation-theoretic computational environment. Situation theory was first formulated in detail by Jon Barwise and John Perry in 1983. Various versions of the theory have been applied to a number of linguistic issues, resulting in what is commonly known as situation semantics. Individuals, properties, relations, spatio-temporal locations, and situations are the basic constructs of situation theory. The world is viewed as a collection of objects, sets of objects, properties, and relations. Infons are discrete items of information and situations are first-class objects that describe parts of the real world. Information flow is made possible by a network of abstract links among high-order uniformities, viz. situation types. The chapter presents a computational approach to situation theory and its associated environment (called BABY-SIT). The environment is dubbed BABY-SIT because it is believed that presently it includes far too many provisional, make-shift design decisions. The chapter highlights that compared to existing approaches, BABY-SIT enhances the basic features of situation theory.}
}
@article{MUNEEPEERAKUL2012123,
title = {The effect of scaling and connection on the sustainability of a socio-economic resource system},
journal = {Ecological Economics},
volume = {77},
pages = {123-128},
year = {2012},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2012.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S092180091200081X},
author = {Rachata Muneepeerakul and Murad R. Qubbaj},
keywords = {Sustainability, Scaling, Connection, Bifurcation, Population dynamics},
abstract = {Policy makers dealing with complex systems oftentimes rely on “linear thinking.” This is understandable due to the ease and convenience offered by the simplicity of such conceptualization. Although this line of thinking may help facilitate decision making processes, it is only as defensible as the degree at which the system under consideration behaves linearly. Recent work shows that diverse properties of cities exhibit power-law relationships with population size. Such relationships may invalidate the reliance on linear thinking. Furthermore, in the era of globalization, resources and people move virtually freely through bounds of any confines used to define a system. We incorporate into a simple resource-population model the power-law scaling behavior and the influence of import and immigration, and investigate their effects on sustainable growth of communities. We explore through bifurcation analysis the different scenarios of how an unsustainable system could be sustained. Import can be effective if: the import exceeds a critical level and a critical mass of people populates the system. In contrast, increasing immigration alone can rescue the intrinsically unsustainable system, both directly through people entering the system and indirectly by increasing its harvesting ability, although critical values exist that cause the population to sharply rise or shrink.}
}
@incollection{KIRWAN202047,
title = {Chapter 3 - Strategies, planning, and design},
editor = {Christopher Kirwan and Fu Zhiyong},
booktitle = {Smart Cities and Artificial Intelligence},
publisher = {Elsevier},
pages = {47-67},
year = {2020},
isbn = {978-0-12-817024-3},
doi = {https://doi.org/10.1016/B978-0-12-817024-3.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128170243000039},
author = {Christopher Kirwan and Fu Zhiyong},
keywords = {Citizen Engagement, Co-design, Data Visualization, Design Thinking, Generative Design, Information Architecture, Living Lab, Metadesign, Real-time Data, Simulation, Transdisciplinary Methods, User Experience},
abstract = {Traditional planning and design methodologies can now be augmented by new innovative tools and processes enabled by AI and smart technologies. These facilitate a more open-ended, multi-dimensional approach that incorporates diverse stakeholders to shape the potential of a collective intelligent operating system — one that best reflects the inherent nature of each unique city and urban condition. The design of smart cities must incorporate and adapt a combination of universal standards and localized policies through global civil society organizations and public-private-people partnerships established to serve the user and citizen as participants of the living city. New methods including co-design, co-creation, citizen participation and user experience (UX) feedback foster inclusive cities. Living labs and innovation hubs provide opportunities and spaces to prototype such initiatives. Transdisciplinary approaches are needed more than ever to expand our scope of inclusion to all life forms, including the rights of animals and nature as stakeholders. By applying a new combination of human and AI-enabled methods such as design thinking, machine learning and generative design, cities can now augment and improve their current state seamlessly, integrating technologies and management as an autopoietic smart city operating system.}
}
@article{WANG2025111994,
title = {A lightweight progressive joint transfer ensemble network inspired by the Markov process for imbalanced mechanical fault diagnosis},
journal = {Mechanical Systems and Signal Processing},
volume = {224},
pages = {111994},
year = {2025},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2024.111994},
url = {https://www.sciencedirect.com/science/article/pii/S0888327024008926},
author = {Changdong Wang and Jingli Yang and Huamin Jie and Zhen Tao and Zhenyu Zhao},
keywords = {Class imbalance, Ensemble learning, Fault diagnosis, Markov process, Progressive joint-transfer strategy},
abstract = {Owing to safety limitations and data collection costs, scenarios with imbalanced data usually arise, posing a great challenge for precise fault diagnosis. Targeting imbalanced fault diagnosis and the high computational cost of mainstream ensemble learning methods currently used, this article proposes a lightweight and accurate scheme based on a progressive joint-transfer ensemble network (PJTEN) and a Markov-lightweight strategy (MLS). Specifically, a PJTEN is developed, incorporating a multiple excitation-channel attention basic estimator and progressive joint-transfer strategy (PJTS) to maintain diversity of basic estimators better and focus more on key information from minority classes. Besides, the MLS guided by Markov transition probabilities is for the first time constructed for ensemble learning to reduce the network redundancy by alternating optimization. Using a standard dataset and a brand-new dataset of a real ship propulsion system, the proposed method achieves leading results in Accuracy, F1 score and MCC, compared with eight cutting-edge methods, thereby validating its substantial value. In terms of lightweight operation, such as temporal complexity (TC), spatial complexity (SC), and time efficiency, it is also ahead of the latest ensemble-based methods.}
}
@article{ALI2024100170,
title = {A Conceptual IoT Framework Based on Anova-F Feature Selection for Chronic Kidney Disease Detection Using Deep Learning Approach},
journal = {Intelligence-Based Medicine},
pages = {100170},
year = {2024},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2666521224000371},
author = {Morshed Ali and Saiful Islam and Mohammed Nasir Uddin and Ashraf Uddin},
keywords = {IoT, Classification, Machine Learning, Deep Learning, Feature Selection, Anova-F, Chronic Kidney, Disease},
abstract = {Chronic kidney disease (CKD) is becoming an increasingly significant health issue, especially in low-income countries where access to affordable treatment is limited. Additionally, CKD is associated with various dietary factors, including liver failure, diabetes, anemia, nerve damage, inflammation, peroxidation, obesity, and other related conditions. Therefore, early prediction of CKD is important to progress the functionality of the kidney. In recent times, IoT has been widely used in a diversity of healthcare sectors through the incorporation of monitoring devices such as digital sensors and medical devices for patient monitoring from remote places. To overcome the problem, this research proposed a conceptual architecture for CKD detection. The sensor layer of the architecture includes IoT devices to collect data and the proposed classifier, MLP (Multi-Layer Perceptron), utilizes the Anova-F feature selection technique to effectively detect CKD (Chronic Kidney Disease). In addition to MLP, four other classifiers including ANN (Artificial Neural Network), Simple RNN (Recurrent Neural Network), GRU (Gated Recurrent Unit), and SVM (Support Vector Machine), are employed for comparative analysis of accuracy. Furthermore, three additional feature selection techniques, namely Chi-squared, SFFS (Sequential Floating Forward Selection), and SBFS (Sequential Backward Floating Selection), are utilized to evaluate their impact on the accuracy of CKD detection. Our proposed method outperforms all other approaches with a remarkable accuracy of 99% while maintaining efficient computational time. This advancement is crucial in developing a highly accurate machine capable of predicting CKD in remote areas with ease.}
}
@article{KISELEV2022e09664,
title = {Predicting verbal reasoning from virtual community membership in a sample of Russian young adults},
journal = {Heliyon},
volume = {8},
number = {6},
pages = {e09664},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09664},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022009525},
author = {Pavel Kiselev and Valeriya Matsuta and Artem Feshchenko and Irina Bogdanovskaya and Boris Kiselev},
keywords = {Verbal reasoning, Social networking site, Virtual community, Machine learning},
abstract = {Predicting personality traits from social networking site profiles can help to assess individual differences in verbal reasoning without using long questionnaires. Inspired by earlier studies, which investigated whether abstract-thinking ability are predictable by social networking sites data, we used supervised machine learning to predict verbal-reasoning ability based on a proposed set of features extracted from virtual community membership. A large sample (N = 3,646) of Russian young adults aged 18–22 years approved access to the data from their social networking accounts and completed an online test on verbal reasoning. We experimented with binary classification machine-learning models for verbal-reasoning prediction. Prediction performance was tested on isolated control subsamples for men and women. The results of prediction on AUC-ROC metrics for control subsamples over 0.7 indicated reasonably good performance on predicting verbal-reasoning level. We also investigated the contribution of virtual community's genres to verbal reasoning level prediction for male and female participants. Theoretical interpretations of results stemming from both Vygotsky's sociocultural theory and behavioural genomics are discussed, including the implication that virtual communities make up a non-shared environment that can cause variance in verbal reasoning. We intend to conduct studies to explore the implications of the results further.}
}
@article{DOSSOU2021476,
title = {Development of a decision support tool for sustainable urban logistics optimization},
journal = {Procedia Computer Science},
volume = {184},
pages = {476-483},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.060},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006918},
author = {Paul-Eric Dossou and Axel Vermersch},
keywords = {Type your keywords here, separated by semicolons},
abstract = {Traffic flows are increasing in cities, partially due to congestions provoked by trucks. These congestions cause many problems such as pollution (gasoil, Carbon, etc.), noise, waste of time. Indeed, cities like Paris, Hamburg, Milan, and “Grand Paris Sud” conurbation are thinking about a sustainable alternative solution to road transportation. Then, a research based on co-creation methodology integrating all stakeholders (local authorities, companies, citizens) for elaborating an alternative solution to road transportation has been defined. This paper presents the architecture and the development of a decision aided tool for simulating and optimizing alternative solutions to road transportation}
}
@incollection{GARDNER2024103,
title = {Chapter 5 - Smart design for socially engaging environments},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {103-128},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000069},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Interaction, Physical computing, Play, Smart city, Smart cities, Social engagement, Social capital, Social interaction, Urban play, Urban technology},
abstract = {Smart city initiatives typically aim to optimize the efficiency of essential urban infrastructure and urban service delivery and performance. This chapter considers how smart technologies can also be deployed in ways to catalyze social interactions among citizens in urban public realm spaces to create socially engaging environments. Drawing on a range of concepts such as social cohesion, social capital, and object-centered sociality, this chapter considers how existing and speculative urban technology projects that combine spatial design thinking and physical computing can scaffold and amplify opportunities for social engagement. It considers how urban technology projects that mobilize tactics of proximity, curiosity, and play can create new and different ways for people to relate to each other in urban space.}
}
@article{MAO2025102712,
title = {A survey on pragmatic processing techniques},
journal = {Information Fusion},
volume = {114},
pages = {102712},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102712},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524004901},
author = {Rui Mao and Mengshi Ge and Sooji Han and Wei Li and Kai He and Luyao Zhu and Erik Cambria},
keywords = {Pragmatic processing, Metaphor understanding, Sarcasm detection, Personality recognition, Aspect extraction, Sentiment polarity detection},
abstract = {Pragmatics, situated in the domains of linguistics and computational linguistics, explores the influence of context on language interpretation, extending beyond the literal meaning of expressions. It constitutes a fundamental element for natural language understanding in machine intelligence. With the advancement of large language models, the research focus in natural language processing has predominantly shifted toward high-level task processing, inadvertently downplaying the importance of foundational pragmatic processing tasks. Nevertheless, pragmatics serves as a crucial medium for unraveling human language cognition. The exploration of pragmatic processing stands as a pivotal facet in realizing linguistic intelligence. This survey encompasses important pragmatic processing techniques for subjective and emotive tasks, such as personality recognition, sarcasm detection, metaphor understanding, aspect extraction, and sentiment polarity detection. It spans theoretical research, the forefront of pragmatic processing techniques, and downstream applications, aiming to highlight the significance of these low-level tasks in advancing natural language understanding and linguistic intelligence.}
}
@incollection{KAMPIS1991345,
title = {Chapter Seven - SELF-REPRODUCTION AND COMPUTATION},
editor = {GEORGE KAMPIS},
booktitle = {Self-Modifying Systems in Biology and Cognitive Science},
publisher = {Pergamon},
address = {Amsterdam},
pages = {345-403},
year = {1991},
volume = {6},
series = {IFSR International Series on Systems Science and Engineering},
isbn = {978-0-08-036979-2},
doi = {https://doi.org/10.1016/B978-0-08-036979-2.50012-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080369792500124},
author = {GEORGE KAMPIS}
}
@article{FALOMIR201931,
title = {Special issue on problem-solving, creativity and spatial reasoning},
journal = {Cognitive Systems Research},
volume = {58},
pages = {31-34},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S138904171930261X},
author = {Zoe Falomir and Ana-Maria Olteţeanu},
keywords = {Cognitive systems, Problem-solving, Creativity, Computational creativity, Spatial reasoning, Cognition, General artificial intelligence, Spatial cognition},
abstract = {Problem-solving, creativity and spatial reasoning are high level abilities of cognitive systems with high potential for synergies. However, they have been treated separately by different fields. This special issue presents research work on these topics, aiming to observe their interrelations in order to create theoretical approaches, methodologies and computational tools to advance work on creativity and spatial problem-solving in cognitive systems.}
}
@article{CASTROSCHEZ201465,
title = {Experience applying language processing techniques to develop educational software that allow active learning methodologies by advising students},
journal = {Journal of Network and Computer Applications},
volume = {41},
pages = {65-79},
year = {2014},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2013.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1084804513002166},
author = {J.J. Castro-Schez and M.A. Redondo and F. Jurado and J. Albusac},
keywords = {Environment for active learning, Formal languages techniques, Automatic assessment},
abstract = {This paper is focused on those systems that allow students to build their own knowledge by providing them with feedback regarding their actions while performing a problem based learning activity or while making changes to problem statements, so that a higher order thinking skill can be achieved. This feedback is the consequence of an automatic assessment. Particularly, we propose a method that makes use of Language Processor techniques for developing these kinds of systems. This method could be applied in subjects in which problem statements and solutions can be formalized by mean of a formal language and the problems can be solved in an algorithmic way. The method has been used to develop a number of tools that are partially described in this paper. Thus, we show that our approach is applicable in addressing the development of the aforementioned systems. One of these tools (a virtual laboratory for language processing) has been in use for several years in order to support home assignments. The data collected for these years are presented and analyzed in this paper. The results of the analysis confirm that this tool is effective in facilitating the achievement of learning outcomes.}
}
@article{MEICHENBAUM1969101,
title = {The effects of instructions and reinforcement on thinking and language behavior of schizophrenics},
journal = {Behaviour Research and Therapy},
volume = {7},
number = {1},
pages = {101-114},
year = {1969},
issn = {0005-7967},
doi = {https://doi.org/10.1016/0005-7967(69)90054-0},
url = {https://www.sciencedirect.com/science/article/pii/0005796769900540},
author = {Donald H. Meichenbaum},
abstract = {Six experimental groups and 2 control groups (N=48) were used to investigate the relative effectiveness of prolonged training of schizophrenics with contingent social and token reinforcement on (a) the level of abstraction as measured on a proverbs task, (b) the percentage of “sick talk” (% ST) emitted in a structured interview, (c) both verbal response classes of proverb abstraction and % ST. Prior to treatment, schizophrenic Ss compared with 20 nonpsychiatric hospitalized medical patients were significantly inferior on the proverbs task and emitted five times more ST in a structured interview. The results indicated that the experimental treatments were effective in decreasing % ST and increasing abstraction to proverbs with token reinforcement being most effective. Evidence for response and stimulus generalization was obtained.}
}
@incollection{KURGANSKAYA2024760,
title = {Multi-scale modeling of crystal-fluid interactions: State-of-the-art, challenges and prospects},
editor = {Klaus Wandelt and Gianlorenzo Bussetti},
booktitle = {Encyclopedia of Solid-Liquid Interfaces (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {760-792},
year = {2024},
isbn = {978-0-323-85670-6},
doi = {https://doi.org/10.1016/B978-0-323-85669-0.00034-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856690000349},
author = {I. Kurganskaya and R.D. Rohlfs and A. Luttge},
keywords = {Crystal-water interface, Electric double layer, Grand canonical Monte Carlo, Kinetic Monte Carlo, Kinetics, Mineral–water interface, Parameterization, Reaction pathways, Reaction probability, Reaction rates, Statistical mechanics of interfaces, Stepwave, Stochastic model, Upscaling, Voronoi},
abstract = {We describe theoretical and conceptual approaches to treat crystal-fluid interactions across the scales in the communities studying mineral-fluid interactions for a variety of purposes, from understanding fundamental principles to geological reservoir characterization and environmental mitigation. We delineate basics of theory, recent breakthroughs, and challenges in modeling approaches from the atomistic scale to the mesoscale. Quantum Mechanics, Molecular Dynamics, Kinetic Monte Carlo and Voronoi computational geometry are covered. We discuss possible theoretical and conceptual developments to overcome those challenges toward more reliable predictive models. A special attention is given to the development of interfaces between the techniques addressing different scales.}
}
@article{PATON200263,
title = {Process, structure and context in relation to integrative biology},
journal = {Biosystems},
volume = {64},
number = {1},
pages = {63-72},
year = {2002},
issn = {0303-2647},
doi = {https://doi.org/10.1016/S0303-2647(01)00176-9},
url = {https://www.sciencedirect.com/science/article/pii/S0303264701001769},
author = {Ray Paton},
keywords = {Ecology, Proteins, Category theory, Modelling, Function, Liver},
abstract = {This paper seeks to provide some integrative tools of thought regarding biological function related to ideas of process, structure, and context. The incorporation of linguistic and mathematical thinking is discussed within the context of managing thinking about natural systems as described by Robert Rosen. Examples from ecology, protein networks, and liver function are introduced to illustrate key ideas. It is hoped that these tools of thought, and the further work needed to mobilise such ideas, will continue to address a number of issues raised and pursued by Michael Conrad, such as the seed-germination model and vertical information processing.}
}
@incollection{OGRADY2020135,
title = {Cyber Security},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {135-141},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10532-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105323},
author = {Nathaniel O'Grady and Andrew C. Dwyer},
keywords = {Computing, Cybersecurity, Cyberspace, Digital, Infrastructure, Networks, Privacy, Software, Surveillance},
abstract = {As computation has become increasingly integrated into everyday life, critical infrastructure, state defense, and cybersecurity has become a new, crucial area of inquiry for geographers. This is due to the fast-changing, new securities that are being formed and enabled through, by and because of the growing role of computation. Geographers have studied cybersecurity as collectively constituted through a complex mixture of technologies, materialities, cultures, knowledges. In so doing, they have probed a range of phenomena crucial to cybersecurity; from technical processes such as encryption, malware infection, and threat detection, to the social arrangements and negotiations between various organizations and states, the implications of surveillance and big data on privacy, and how threats affect various infrastructure that support ways of life across the globe. Nevertheless, geographers do not simply consider cybersecurity as a mode of security imposed “online” or through digital technologies. Rather, in its practice, geographers have demonstrated how cybersecurity involves and invokes socio-political complications around criminality, protection, inequalities, privacy, surveillance, private enterprise, and the role of the state in the life of citizens.}
}
@article{FARHAT199435,
title = {Simulation of compressible viscous flows on a variety of MPPs: computational algorithms for unstructured dynamic meshes and performance results},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {119},
number = {1},
pages = {35-60},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/0045782594000751},
author = {Charbel Farhat and Stéphane Lanteri},
abstract = {We report here on our effort in simulating unsteady viscous flows on the iPSC-860, the CM-5 and the KSR-1 MPPs (Massively Parallel Processors), using a Monotonic Upwind Scheme for Conservation Laws finite volume/finite element method on fully unstructured fixed and moving grids. We advocate mesh partitioning with message passing as a portable paradigm for parallel processing. We present and discuss several performance results obtained on all three MPP systems in terms of interprocessor communication costs, I/O, scability and sheer performance.}
}
@article{BYLANDER1994165,
title = {The computational complexity of propositional STRIPS planning},
journal = {Artificial Intelligence},
volume = {69},
number = {1},
pages = {165-204},
year = {1994},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)90081-7},
url = {https://www.sciencedirect.com/science/article/pii/0004370294900817},
author = {Tom Bylander},
abstract = {I present several computational complexity results for propositional STRIPS planning, i.e., STRIPS planning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.}
}
@article{OLADEJO2024111880,
title = {The Hiking Optimization Algorithm: A novel human-based metaheuristic approach},
journal = {Knowledge-Based Systems},
volume = {296},
pages = {111880},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111880},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124005148},
author = {Sunday O. Oladejo and Stephen O. Ekwe and Seyedali Mirjalili},
keywords = {Optimization, Metaheuristics, Hiking, Tobler’s Hiking function, Algorithm, Benchmark, Problem solving},
abstract = {In this paper, a novel metaheuristic called ‘The Hiking Optimization Algorithm’ (HOA) is proposed. HOA is inspired by hiking, a popular recreational activity, in recognition of the similarity between the search landscapes of optimization problems and the mountainous terrains traversed by hikers. HOA’s mathematical model is premised on Tobler’s Hiking Function (THF), which determines the walking velocity of hikers (i.e. agents) by considering the elevation of the terrain and the distance covered. THF is employed in determining hikers’ positions in the course of solving an optimization problem. HOA’s performance is demonstrated by benchmarking with 29 well-known test functions (including unimodal, multimodal, fixed-dimension multimodal, and composite functions), three engineering design problems (EDPs), (including I-beam, tension/compression spring, and gear train problems) and two N-P Hard problems (i.e. Traveling Salesman’s and Knapsack Problems). Moreover, HOA’s results are verified by comparison to 14 other metaheuristics, including Teaching Learning Based Optimization (TLBO), Genetic Algorithm (GA), Differential Evolution (DE), Particle Swarm Optimization, Grey Wolf Optimizer (GWO) as well as newly introduced algorithms such as Komodo Mlipir Algorithm (KMA), Quadratic Interpolation Optimization (QIO), and Coronavirus Optimization Algorithm (COVIDOA). In this study, we employ statistical tests such as the Wilcoxon rank sum, Friedman test, and Dunn’s post hoc test for the performance evaluation. HOA’s results are competitive and, in many instances, outperform the aforementioned well-known metaheuristics. The source codes of HOA and related metaheuristics can be accessed publicly via this link: https://github.com/DayoSun/The-Hiking-Optimization-Algorithm.}
}
@article{TALL1999223,
title = {What Is the Object of the Encapsulation of a Process?},
journal = {The Journal of Mathematical Behavior},
volume = {18},
number = {2},
pages = {223-241},
year = {1999},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(99)00029-2},
url = {https://www.sciencedirect.com/science/article/pii/S0732312399000292},
author = {David Tall and Michael Thomas and Gary Davis and Eddie Gray and Adrian Simpson},
abstract = {Several theories have been proposed to describe the transition from process to object in mathematical thinking. Yet, what is the nature of this “object” produced by the “encapsulation” of a process? Here, we outline the development of some of the theories (including Piaget, Dienes, Davis, Greeno, Dubinsky, Sfard, Gray, and Tall) and consider the nature of the mental objects (apparently) produced through encapsulation and their role in the wider development of mathematical thinking. Does the same developmental route occur in geometry as in arithmetic and algebra? Is the same development used in axiomatic mathematics? What is the role played by imagery?}
}
@article{SHRYANE2020112806,
title = {Is cognitive behavioural therapy effective for individuals experiencing thought disorder?},
journal = {Psychiatry Research},
volume = {285},
pages = {112806},
year = {2020},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2020.112806},
url = {https://www.sciencedirect.com/science/article/pii/S0165178119302793},
author = {Nick Shryane and Richard Drake and Anthony P. Morrison and Jasper Palmier-Claus},
keywords = {Psychosis, Cognitive behavioural therapy, Thought disorder, Randomized Controlled Trial},
abstract = {Various clinical guidelines recommend cognitive behavioural therapy (CBT) to treat psychosis without reference to patients’ thought disorder. However, there is a risk that disorganized thinking hampers CBT. We tested the prediction that thought disorder would interfere with the effectiveness of CBT for hallucinations and delusions, compared to treatment as usual and supportive counselling, in secondary data from two large, single blind randomised controlled trials. We fitted latent growth curve models separately for the development of frequency and distress of symptoms. CBT was significantly more successful than counselling in reducing delusional frequency in the short term and hallucinatory distress at any point, even in those with relatively high thought disorder. We found little evidence that clinicians should restrict CBT in this subgroup of patients. Nevertheless, the findings highlight the importance of effective initial treatment of thought disorder in maximising the benefit of CBT for psychosis, particularly for reducing distress from hallucinations.}
}
@article{KONDINSKI20241071,
title = {Hacking decarbonization with a community-operated CreatorSpace},
journal = {Chem},
volume = {10},
number = {4},
pages = {1071-1083},
year = {2024},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2023.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S2451929423006198},
author = {Aleksandar Kondinski and Sebastian Mosbach and Jethro Akroyd and Andrew Breeson and Yong Ren Tan and Simon Rihm and Jiaru Bai and Markus Kraft},
keywords = {decarbonization, chemistry, knowledge graphs, agents, CreatorSpace},
abstract = {Summary
The pressing challenge of decarbonization encompasses a vast combinatorial space of interlinked technologies, thus necessitating an increased reliance on artificial intelligence (AI)-assisted molecular modeling and data analytics. Our backcasting analysis proposes a future rich in efficient decarbonization technologies, such as sustainable fuels for aviation and shipping, as well as carbon capture and utilization. We then retrace the path to this proposed future with the guidance of two constraints: the maximization of scientists’ creative capacities and the evolution of a world-centric AI. Our exploration leads us to the concept of a “CreatorSpace,” a distributed digital system resembling existing hackerspaces and makerspaces known for accelerating the prototyping of new technologies worldwide. The CreatorSpace serves as a virtual, semantic platform where chemists, engineers, and materials scientists can freely collaborate, integrating chemical knowledge with cross-scale, cross-technology tools, and operations. This streamlined molecular-to-process-design pathway facilitates a diverse array of solutions for decarbonization and other sustainability technologies.}
}
@article{HUANG200870,
title = {Investigating the cognitive behavior of generating idea sketches through neural network systems},
journal = {Design Studies},
volume = {29},
number = {1},
pages = {70-92},
year = {2008},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2007.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X07000750},
author = {Yinghsiu Huang},
keywords = {drawings, computer supported design, visual reasoning, neural network},
abstract = {Design can be regarded as a seeing–moving–seeing process, where designers repeatedly see and generate ideas that are based on what they have done. The crucial point of design thinking is how designers recognize ambiguous shapes from sketches and then transfer them into different shapes. This study attempts to conduct cognitive experiments to elucidate the sketching process and to simulate two types of sketching behavior used by neural network systems. When exhibiting the first type of sketching behavior, designers are able to transform their original sketches to satisfy requirements. Simulating this type of visual cognitive behavior by neural networks could help computers modify shapes to meet design requirements, as human designers do. When demonstrating the second type of sketching behavior, designers are able to see an ambiguous shape as different complete shapes so as to associate divergent design ideas. Another set of neural networks investigated in this study could also associate different shapes by adjusting the TSL and produce different idea sketches from the same shape.}
}
@article{ARORA1990131,
title = {Computational design optimization: A review and future directions},
journal = {Structural Safety},
volume = {7},
number = {2},
pages = {131-148},
year = {1990},
issn = {0167-4730},
doi = {https://doi.org/10.1016/0167-4730(90)90063-U},
url = {https://www.sciencedirect.com/science/article/pii/016747309090063U},
author = {Jasbir S. Arora},
keywords = {optimization methods, nonlinear problems, review, computational aspects, engineering design},
abstract = {A mathematical model for design optimization of engineering systems is defined. Computational algorithms to treat the model are reviewed and their features are discussed. The attributes of a good algorithm are given. Sequential quadratic programming algorithms that generate and use the approximate Hessian of the Lagrange function to calculate the search direction are the most recent methods. They are the most reliable methods among the available ones. Several other computational aspects, such as robust implementation of algorithms, use of a knowledge base, interactive use of optimization, and use of a database and database management system, are discussed. Recent developments in the field and future directions are presented.}
}
@incollection{MILLER2020181,
title = {Chapter eight - Data science and the exposome},
editor = {Gary W. Miller},
booktitle = {The Exposome (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {181-209},
year = {2020},
isbn = {978-0-12-814079-6},
doi = {https://doi.org/10.1016/B978-0-12-814079-6.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128140796000080},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, models, computational biology, machine learning, Bayesian methods, artificial intelligence, causal inference},
abstract = {Data science is focused on extracting meaningful value from complex datasets. Exposome-related data are certainly complex with information coming from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. It is unlikely that unsupervised approaches will allow for causal associations to be made, but with proper study design and appropriate statistical and computational models, it should be possible to derive meaningful connections between complex exposures and specific health outcomes. The complex types of data will undoubtedly require sophistical mathematical approaches, including bioinformatics, computational, machine learning, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive datasets that will result from exposome research.}
}
@article{CORDA2021100834,
title = {The secret of planets’ perihelion between Newton and Einstein},
journal = {Physics of the Dark Universe},
volume = {32},
pages = {100834},
year = {2021},
issn = {2212-6864},
doi = {https://doi.org/10.1016/j.dark.2021.100834},
url = {https://www.sciencedirect.com/science/article/pii/S2212686421000650},
author = {Christian Corda},
abstract = {Three different approaches show that, contrary to a longstanding conviction older than 160 years, the advance of Mercury’s perihelion can be achieved in Newtonian gravity with a very high precision by correctly analyzing the situation without neglecting Mercury’s mass. General relativity remains more precise than Newtonian physics, but Newtonian framework is more powerful than researchers and astronomers were thinking till now, at least for the case of Mercury. The Newtonian formula of the advance of planets’ perihelion breaks down for the other planets. The predicted Newtonian result is indeed too large for Venus and Earth. Therefore, it is also shown that corrections due to gravitational and rotational time dilation, in an intermediate framework which analyzes gravity between Newton and Einstein, solve the problem. By adding such corrections, a result consistent with the one of general relativity is indeed obtained. Thus, the most important results of this paper are two: (i) It is not correct that Newtonian theory cannot predict the anomalous rate of precession of the perihelion of planets’ orbit. The real problem is instead that a pure Newtonian prediction is too large. (ii) Perihelion’s precession can be achieved with the same precision of general relativity by extending Newtonian gravity through the inclusion of gravitational and rotational time dilation effects. This second result is in agreement with a couple of recent and interesting papers of Hansen, Hartong and Obers. Differently from such papers, in the present work the importance of rotational time dilation is also highlighted. Finally, it is important to stress that a better understanding of gravitational effects in an intermediate framework between Newtonian theory and general relativity, which is one of the goals of this paper, could, in principle, be crucial for a subsequent better understanding of the famous Dark Matter and Dark Energy problems.}
}
@article{RICAURTE2020102,
title = {Project-based learning as a strategy for multi-level training applied to undergraduate engineering students},
journal = {Education for Chemical Engineers},
volume = {33},
pages = {102-111},
year = {2020},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2020.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772820300464},
author = {Marvin Ricaurte and Alfredo Viloria},
keywords = {Project-based learning, Multi-level, Undergraduate students, Process engineering},
abstract = {This study presents a project-based learning methodology whose particularity is the inclusion of training at different levels of undergraduate engineering programs, which allows for the interaction among students from different semesters who work together on a common project. To show the applicability of the proposed methodology, a project for the industrial production of ethanol from sugar cane was considered. Students enrolled in Process Design (9th semester) and Computer-Assisted Technical Design (5th semester), courses included in the engineering programs offered by the Department of Chemical Engineering at Yachay Tech University (Ecuador), jointly developed it. The details of the project were presented to the students of the Introduction to Engineering course (3rd semester) to boost their interest in the engineering as applied science. The activities carried out in each of the courses are described in detail together with a description of how the learning outcomes were achieved thanks to the implementation of a multi-level training strategy. Teamwork and collaborative-integrated learning are the elements highlighted by the students who participated in the project. Some of the innovative aspects of the proposed methodology include professional training and multi-level learning, the development of logical thinking typical of engineers, the knowledge handover associated with the professional activities of process engineers engaged with real-world projects. Additionally, this methodology prizes the industrial experience that professors at the undergraduate level may have by allowing them to contribute with an engineering vision to the training of young people in engineering projects. This study was inspired by the principle of Constructive Alignment and by goal # 4 (quality education) of the 2030 Agenda for Sustainable Development.}
}
@article{MARIN2021100015,
title = {Human macrophage polarization in the response to Mycobacterium leprae genomic DNA},
journal = {Current Research in Microbial Sciences},
volume = {2},
pages = {100015},
year = {2021},
issn = {2666-5174},
doi = {https://doi.org/10.1016/j.crmicr.2020.100015},
url = {https://www.sciencedirect.com/science/article/pii/S2666517420300171},
author = {Alberto Marin and Kristopher {Van Huss} and John Corbett and Sangjin Kim and Jonathon Mohl and Bo-young Hong and Jorge Cervantes},
keywords = {RNAseq, , Leprosy, Macrophage polarization},
abstract = {Infection with Mycobacterium leprae, the causative organism of leprosy, is still endemic in numerous parts of the world including the southwestern United States. The broad variation of symptoms in the leprosy disease spectrum range from the milder tuberculoid leprosy (paucibacillary) to the more severe and disfiguring lepromatous leprosy (multibacillary). The established thinking in the health community is that host response, rather than M. leprae strain variation, is the reason for the range of disease severity. More recent discoveries suggest that macrophage polarization also plays a significant role in the spectrum of leprosy disease but to what degree it contributes is not fully established. In this study, we aimed to analyze if different strains of M. leprae elicit different transcription responses in human macrophages, and to examine the role of macrophage polarization in these responses. Genomic DNA from three different strains of M. leprae DNA (Strains NHDP, Br4923, and Thai-53) were used to stimulate human macrophages under three polarization conditions (M1, M1-activated, and M2). Transcriptome analysis revealed a large number of differentially expressed (DE) genes upon stimulation with DNA from M. leprae strain Thai-53 compared to strains NHDP and Br4923, independent of the macrophage polarization condition. We also found that macrophage polarization affects the responses to M. leprae DNA, with up-regulation of numerous interferon stimulated genes. These findings provide a deeper understanding of the role of macrophage polarization in the recognition of M. leprae DNA, with the potential to improve leprosy treatment strategies.}
}
@article{MONNAHAN2024107024,
title = {Toward good practices for Bayesian data-rich fisheries stock assessments using a modern statistical workflow},
journal = {Fisheries Research},
volume = {275},
pages = {107024},
year = {2024},
issn = {0165-7836},
doi = {https://doi.org/10.1016/j.fishres.2024.107024},
url = {https://www.sciencedirect.com/science/article/pii/S0165783624000882},
author = {Cole C. Monnahan},
keywords = {No-U-turn sampler (NUTS), Bayesian integration, Prior predictive checks, Posterior predictive checks, Cross validation},
abstract = {Bayesian inference has long been recognized as useful for fisheries stock assessments but it is less common than maximum likelihood approaches due to long run times and a lack of good practices. Recent computational advances leave developing good practices and user-friendly interfaces as the most important hurdles to wider use of this powerful statistical paradigm. Here, I argue that the modern Bayesian workflow proposed by Gelman et al. (2020) should form the basis for proposed good practices in fisheries sciences. Their workflow is a conceptual roadmap for iterative model building which includes the philosophical role of priors and how to apply statistical tools to construct them, how to validate and compare models, and how to overcome computational problems. Adapted for stock assessment, this leads to the following good practices for analysts. Diagnostics from multiple no-U-turn sampler (NUTS) chains (the recommended MCMC algorithm) should pass and be reported, specifically that the potential scale reduction Rˆ is <1.01 and the effective sample size is >400 for all parameters, and there are no NUTS divergences. When direct a priori information is unavailable on parameters, use prior predictive checking to build, assess, and adjust priors to enforce desired constraints on complexity, or to conform to a priori expectations or physical/biological limitations on derived quantities. Use posterior predictive checks to validate models by confirming simulated data and summaries (e.g., variance of compositional data) are similar to the observed counterparts. Process error variances can be estimated jointly with random effects and other parameters when desired, and should be for important model components. An approximate cross-validation technique called PSIS-LOO is the most practical tool for model selection, but can also provide important insights into model deficiencies. I also recommended that model developers build and parameterize models to have minimal parameter correlations and marginal variances close to one, have options for diverse (multivariate) priors, do predictive modeling, and ensure that the tools comprising a workflow are accessible and straightforward for routine use. I review, adapt, and illustrate a Bayesian workflow on AD Model Builder and Stock Synthesis models, but these good practices apply to models from any software platform, including Template Model Builder and Stan. Finally, I argue that the Bayesian and frequentist paradigms complement each other, with both helping analysts better understand different aspects of their models and data. Wider adoption of Bayesian methods using the good practices proposed here would therefore lead to improved scientific advice used to manage fisheries.}
}
@article{WEI2021189,
title = {Multi-core-, multi-thread-based optimization algorithm for large-scale traveling salesman problem},
journal = {Alexandria Engineering Journal},
volume = {60},
number = {1},
pages = {189-197},
year = {2021},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2020.06.055},
url = {https://www.sciencedirect.com/science/article/pii/S1110016820303227},
author = {Xin Wei and Liang Ma and Huizhen Zhang and Yong Liu},
keywords = {Multi-core, Multi-thread, Traveling Salesman Problem, Optimization Algorithm},
abstract = {With the rapid development of general hardware technology, microcomputers with multi-core CPUs have been widely applied in commercial services and household usage in the last ten years. Multi-core chips could, theoretically, lead to much better performance and computational efficiency than single-core chips. But so far, they have not shown general advantages for users, other than for operating systems and some specialized software. It is not easy to transform traditional single-core-based algorithms into multi-core-, multi-thread-based algorithms that can greatly improve efficiency, because of difficulties in computation and scheduling of hardware kernels, and because some programming languages cannot support multi-core, multi-thread programming. Therefore, a kind of multi-core-, multi-thread-based fast algorithm was designed and coded with Delphi language for the medium- and large-scale traveling salesman problem instances from TSPLIB, which can fully speed up the searching process without loss of quality. Experimental results show that the algorithm proposed can, under the given hardware limitations, take full advantage of multi-core chips and effectively balance the conflict between increasing problem size and computational efficiency and thus acquire satisfactory solutions.}
}
@article{GORDON2018273,
title = {Healthier Choices in School Cafeterias: A Systematic Review of Cafeteria Interventions},
journal = {The Journal of Pediatrics},
volume = {203},
pages = {273-279.e2},
year = {2018},
issn = {0022-3476},
doi = {https://doi.org/10.1016/j.jpeds.2018.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S0022347618309363},
author = {Katelyn Gordon and Linda Dynan and Robert Siegel},
keywords = {school cafeteria, behavioral economics, childhood obesity, food selection},
abstract = {Objective
To describe school cafeteria interventions in terms of a behavioral economics scheme and to assess which system is more likely to be effective in improving food selection or consumption.
Study design
With this systematic review, we categorize cafeteria interventions using the behavioral economics theory of Kahneman into system 1 (fast and intuitive thinking) and system 2 (slow and cognitively demanding) or mixed (having elements of system 1 and system 2). Pertinent studies were identified from review of the literature of interventions performed in school and cafeteria settings in children grades K-12 within the past 5 years (2012-2017) at time of search.
Results
In all, 48 of 978 studies met inclusion criteria. By defining success as a 30% improvement in a desired outcome or statistically significant reduction in body mass index, 89% of system 1, 67% of mixed (had both system 1 and 2 elements), and only 33% of system 2 interventions were successful.
Conclusions
This review found successful system 1 type school cafeteria interventions to be more common than system 2 type interventions and system 2 type interventions are less effective than system 1.}
}
@article{THOMPSON2024939,
title = {Leveraging marine biotechnology for an All-Atlantic sustainable blue economy},
journal = {Trends in Biotechnology},
volume = {42},
number = {8},
pages = {939-941},
year = {2024},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2023.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167779923003670},
author = {Cristiane Thompson and Alice C. Ortmann and Thulani Makhalanyane and Fabiano Thompson},
keywords = {All Atlantic, food security, biotechnology, low-carbon aquaculture, integrated multitrophic aquaculture, biofloc technology},
abstract = {Despite the lack of research, development, and innovation funds, especially in South Atlantic countries, the Atlantic is suited to supporting a sustainable marine bioeconomy. Novel low-carbon mariculture systems can provide food security, new drugs, and climate mitigation. We suggest how to develop this sustainable marine bioeconomy across the entire Atlantic.}
}
@article{WHEELER2020192,
title = {Ideology and predictive processing: coordination, bias, and polarization in socially constrained error minimization},
journal = {Current Opinion in Behavioral Sciences},
volume = {34},
pages = {192-198},
year = {2020},
note = {Political Ideologies},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2020.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352154620300632},
author = {Nathan E Wheeler and Suraiya Allidina and Elizabeth U Long and Stephen P Schneider and Ingrid J Haas and William A Cunningham},
abstract = {Recent models of cognition suggest that the brain may implement predictive processing, in which top-down expectations constrain incoming sensory data. In this perspective, expectations are updated (error minimization) only if sensory data sufficiently deviate from these expectations (prediction error). Although originally applied to perception, predictive processing is thought to generally characterize cognitive architecture, including the social cognitive processes involved in ideological thinking. Scaling up these simple computational principles to the social sphere outlines a path by which group members may adopt shared ideologies and beliefs to predict behavior and cooperate with each other. Because ideological judgments are of specific interest to others in our political groups, we may increasingly regulate each other’s thinking, sharing the process of error minimization. In this paper, we outline how this process of shared error minimization may lead to shared ideologies and beliefs that allow group members to predict and cooperate with each other, and how, as a consequence, political polarization and extremism may result.}
}
@article{MOLNAR20152667,
title = {Three Dimensional Applications in Teaching and Learning Processes},
journal = {Procedia - Social and Behavioral Sciences},
volume = {191},
pages = {2667-2673},
year = {2015},
note = {The Proceedings of 6th World Conference on educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.600},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815028608},
author = {György Molnár and András Benedek},
keywords = {ICT, 3D interactive system, new learning potential, Leonar3Do ;},
abstract = {In the world of today's information society the torrent of information we are dailyfaced with has to be appropriately transformed and translated in order to yield representationswe are somehow capable of understanding. By extending 2D representations to three-dimensional ones, pictorialcontents become more lifelike, getting closer to practice, creating the basis for a new view ofpictorial thinking, giving rise to the emergence to a very effective method of dealing withinformation overload. To depict three-dimensionalreality onto a two-dimensional plane of course constitutes an age-old scientific problem, theprincipal aim of the technique sought after being the exact representation.We also present a general review of Hungarian and international experienceson ICT application and its environment that comply with current practice.}
}
@article{CORPONI2021,
title = {Frontal lobes dysfunction across clinical clusters of acute schizophrenia},
journal = {Revista de Psiquiatría y Salud Mental},
year = {2021},
issn = {1888-9891},
doi = {https://doi.org/10.1016/j.rpsm.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1888989121001324},
author = {Filippo Corponi and Yana Zorkina and Daniel Stahl and Andrea Murru and Eduard Vieta and Alessandro Serretti and Аnna Morozova and Alexander Reznik and Georgiy Kostyuk and Vladimir Pavlovich Chekhonin},
keywords = {Schizophrenia, Frontal lobe, Precision medicine, Cluster analysis, Machine learning},
abstract = {Introduction
Schizophrenia is a clinical construct comprising manifold phenotypes underlying heterogeneous biological underpinnings. The Positive and Negative Syndrome Scale (PANSS) represents the standard tool in the clinical characterization of patients affected by schizophrenia, allowing to detect different clinical profiles within the disorder. Frontal lobes are a key area of brain dysfunction in schizophrenia. We investigated whether different clinical profiles in acute schizophrenia show differences in frontal lobes dysfunction or not.
Methods
We defined PANSS-derived principal components in a sample of 516 acute patients. These components were used as clustering variables in a finite-mixture model. Frontal lobe impairment, measured with the frontal assessment battery (FAB) score, was adjusted for disease duration and compared across the clinical clusters with ANCOVA. A supervised-learning approach was then implemented to reveal most informative PANSS items.
Results
A three-cluster solution emerged: a first profile with high-moderate expression for the positive and excitability/hostility component; a second profile scoring high on depression/anxiety and low on other components; a third profile, comprising the majority of the study population (74%), with a heavy affection on the negative-disorganization dimensions. After controlling for disease duration, frontal lobe impairment significantly differed across the aforementioned clusters, with the third cluster being the most affected. Two PANSS items presented the highest predictive value for FAB total score.
Conclusions
Among negative and disorganization symptoms, “difficulty in abstract thinking” and “lack of spontaneity/flow in conversation” are specifically mapped to higher levels of frontal lobes dysfunction, hinting at similar features with other neurological disorders involving frontal lobes.}
}
@article{LUCKRING2024100998,
title = {Prediction of concentrated vortex aerodynamics: Current CFD capability survey},
journal = {Progress in Aerospace Sciences},
volume = {147},
pages = {100998},
year = {2024},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2024.100998},
url = {https://www.sciencedirect.com/science/article/pii/S0376042124000241},
author = {James M. Luckring and Arthur Rizzi},
abstract = {Concentrated vortex flows contribute to the aerodynamic performance of aircraft at elevated load conditions. For military interests, the vortex flows are exploited at maneuver conditions of combat aircraft and missiles. For transport interests, the vortex flows are exploited at takeoff and landing conditions as well as at select transonic conditions. Aircraft applications of these vortex flows are reviewed with a historical perspective followed by a discussion of the underlying physics of a concentrated vortex flow. A hierarchy of computational fluid dynamics simulation technology is then presented followed by findings from a capability survey for predicting concentrated vortex flows with computational fluid dynamics. Results are focused on military and civil fixed-wing aircraft; only limited results are included for missiles, and rotary-wing applications are not assessed. Opportunities for predictive capability advancement are then reported with comments related to digital transformation interests. A hierarchical approach that merges a physics-based perspective of the concentrated vortex flows with a systems engineering viewpoint of the air vehicle is also used to frame much of the discussion.}
}
@article{ISMAILOVA2021341,
title = {Cognitive System to Clarify the Semantic Vulnerability and Destructive Substitutions},
journal = {Procedia Computer Science},
volume = {190},
pages = {341-360},
year = {2021},
note = {2020 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: Eleventh Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.06.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012898},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {cognitive system, information process, knowledge stage, cognitive interference, semantic web, functor-as-object, dynamics, semantic virus, variable sets, category theory},
abstract = {The development of special mathematics capable of directly taking into account the dynamics of the problem domain, as it turns out, is a non-trivial task. Its very formulation in a refined form and the fixation of the most important features cause noticeable complications in the target formalism, significantly complicating the development of software. A constructive solution to this problem is given, obtained using the original functor-as-object construction. The concept of semantic viralization is introduced. It is expected that the obtained computational model has a high innovative potential for the development of information systems designed for intensive data exchange.}
}
@article{JIANG2021116441,
title = {Impacts of COVID-19 on energy demand and consumption: Challenges, lessons and emerging opportunities},
journal = {Applied Energy},
volume = {285},
pages = {116441},
year = {2021},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.116441},
url = {https://www.sciencedirect.com/science/article/pii/S030626192100009X},
author = {Peng Jiang and Yee Van Fan and Jiří Jaromír Klemeš},
keywords = {COVID-19, Energy impacts, Environmental impacts, Energy recovery, Lessons, Emerging opportunities},
abstract = {COVID-19 has caused great challenges to the energy industry. Potential new practices and social forms being facilitated by the pandemics are having impacts on energy demand and consumption. Spatial and temporal heterogeneities of impacts appear gradually due to the dynamics of pandemics and mitigation measures. This paper overviews the impacts and challenges of COVID-19 pandemics on energy demand and consumption and highlights energy-related lessons and emerging opportunities. The discussion on energy-related issues is divided into four main sections: emergency situation and its impacts, environmental impacts and stabilising energy demand, recovering energy demand, and lessons and emerging opportunities. The changes in energy requirements are compared and analysed from multiple perspectives according to available data and information. In general, although the overall energy demand declines, the spatial and temporal variations are complicated. The energy intensity has presented apparent changes, the extra energy for COVID-19 fighting is non-negligible for stabilising energy demand, and the energy recovery in different regions presents significant differences. A crucial issue has been to allocate and find energy-related emerging opportunities for the post pandemics. This study could offer a direction in opening new avenues for increasing energy efficiency and promoting energy saving.}
}
@article{PISTIKOPOULOS2021107252,
title = {Process systems engineering – The generation next?},
journal = {Computers & Chemical Engineering},
volume = {147},
pages = {107252},
year = {2021},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2021.107252},
url = {https://www.sciencedirect.com/science/article/pii/S0098135421000302},
author = {E N Pistikopoulos and Ana Barbosa-Povoa and Jay H Lee and Ruth Misener and Alexander Mitsos and G V Reklaitis and V Venkatasubramanian and Fengqi You and Rafiqul Gani},
keywords = {Process systems engineering, Synthesis-design, Optimization, Control, Modelling, Supply chain},
abstract = {Process Systems Engineering (PSE) is the scientific discipline of integrating scales and components describing the behavior of a physicochemical system, via mathematical modelling, data analytics, design, optimization and control. PSE provides the ‘glue’ within scientific chemical engineering, and offers a scientific basis and computational tools towards addressing contemporary and future challenges such as in energy, environment, the ‘industry of tomorrow’ and sustainability. This perspective article offers a guide towards the next generation of PSE developments by looking at its history, core competencies, current status and ongoing trends.}
}
@article{YIN2022109800,
title = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
journal = {Applied Soft Computing},
volume = {131},
pages = {109800},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109800},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008493},
author = {Linfei Yin and Xinghui Cao and Senlin Wang},
keywords = {Deep fully connected models, Gray wolf optimizer, Adaptive differential evolution, Global search, Parameter optimization},
abstract = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization. Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51% lesser average computation time than the SASS algorithm, 99.63% less than the COLSHADE algorithm, and 89.52% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.}
}
@article{BERNABEI2023100172,
title = {Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100172},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000516},
author = {Margherita Bernabei and Silvia Colabianchi and Andrea Falegnami and Francesco Costantino},
keywords = {LLM, ChatGPT, Higher education, Essay generation},
abstract = {The accessibility of advanced Artificial Intelligence-based tools, like ChatGPT, has made Large Language Models (LLMs) readily available to students. These LLMs can generate original written content to assist students in their academic assessments. With the rapid adoption of LLMs, exemplified by the popularity of OpenAI's ChatGPT, there is a growing need to explore their application in education. Few studies examine students' use of LLMs as learning tools. This paper focuses on the application of ChatGPT in engineering higher education through an in-depth case study. It investigates whether engineering students can generate high-quality university essays with LLMs assistance, whether existing LLMs identification systems can detect essays produced with LLMs, and how students perceive the usefulness and acceptance of LLMs in learning. The research adopts a deductive/inductive approach, combining conceptualization and empirical evidence analysis. The study involves mechanical and management engineering students, who compose essays using LLMs. The essay assessment showed good results, but some recommendations emerged for teachers and students. Thirteen LLMs detectors were tested without achieving satisfactory results, suggesting to avoid LLMs ban. In addition, students were administered a questionnaire based on constructs and items that follow the technology acceptance models available in the literature. The results contribute to qualitative evidence by highlighting possible future research and educational practices.}
}
@article{GAN2021101212,
title = {Translating novel HPC techniques into efficient geoscience solutions},
journal = {Journal of Computational Science},
volume = {52},
pages = {101212},
year = {2021},
note = {Case Studies in Translational Computer Science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101212},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320305135},
author = {Lin Gan and Haohuan Fu and Guangwen Yang},
keywords = {Computational geoscience application, Numerical simulation, High performance computing, Translational computer science},
abstract = {Computational geoscience is an established field for better understanding and protecting our planet. It covers a wide range of different fields that are closely related to Earth systems. As a popular research area that largely relies on high performance computing, the efficient translation of novel techniques from computer science to practical geoscience solutions has emerged as an important and challenging problem. Based on a series of efforts in conducting interdisciplinary research in computer science and geoscience, this paper summarizes the measures we have taken and the lessons we have learned to successfully translate selected computational laboratory innovations into practical solutions.}
}
@article{MCLEAN20248,
title = {Autoantibodies against acetylcholine receptors are increased in archived serum samples from patients with schizophrenia},
journal = {Schizophrenia Research},
volume = {267},
pages = {8-13},
year = {2024},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2024.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0920996424001129},
author = {Ryan Thomas McLean and Elizabeth Buist and David {St. Clair} and Jun Wei},
keywords = {Neurotransmitter receptor, CHRM4, GRM3, CHRNA4, CHRNA5 neuroimmunology},
abstract = {Previous studies have demonstrated that the levels of IgG against neurotransmitter receptors are increased in patients with schizophrenia. Genome-wide association (GWA) studies of schizophrenia confirmed that 108 loci harbouring over 300 genes were associated with schizophrenia. Although the functional implications of genetic variants are unclear, theoretical functional alterations of these genes could be replicated by the presence of autoantibodies. This study examined the levels of plasma IgG antibodies against four neurotransmitter receptors, CHRM4, GRM3, CHRNA4 and CHRNA5, using an in-house ELISA in 247 patients with schizophrenia and 344 non-psychiatric controls. Four peptides were designed based on in silico analysis with computational prediction of HLA-DRB1 restricted and B-cell epitopes. The relationship between plasma IgG levels and psychiatric symptoms, as defined by the Operational Criteria Checklist for Psychotic Illness and Affective Illness (OPCRIT), were examined. The results showed that the levels of plasma IgG against peptides derived from CHRM4 and CHRNA4 were significantly increased in patients with schizophrenia compared with control subjects, but there was no significant association of plasma IgG levels with any symptom domain or any specific symptoms. These preliminary results suggest that CHRM4 and CHRNA4 may be novel targets for autoantibody responses in schizophrenia, although the pathogenic relationship between increased serum autoantibody levels and schizophrenia symptoms remains unclear.}
}
@incollection{MAGGIONI2010255,
title = {Knowledge Domains and Domain Learning},
editor = {Penelope Peterson and Eva Baker and Barry McGaw},
booktitle = {International Encyclopedia of Education (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {255-264},
year = {2010},
isbn = {978-0-08-044894-7},
doi = {https://doi.org/10.1016/B978-0-08-044894-7.00483-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080448947004838},
author = {L. Maggioni and P.A. Alexander},
keywords = {Discipline, Domain, History, Knowledge, Learning, Mathematics, Reading, Science, Writing},
abstract = {The roots of current disciplines and domains of study reach well back in history. An exploration of their development shows that these areas of knowledge have not only reflected cultural changes, but have also influenced societies, especially through formal educational systems. Besides being characterized by their focus on a particular part of the world, disciplines are also distinguished by a specific way of thinking about their respective domains of study. Psychological research has identified several features of these pathways to knowledge (e.g., reading, writing, history, mathematics, and science) that generally define the landscape of academic practice.}
}
@article{OMRAN2022114806,
title = {Valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment: Approaching green chemistry and circular economy principles},
journal = {Journal of Environmental Management},
volume = {311},
pages = {114806},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.114806},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722003796},
author = {Basma A. Omran and Kwang-Hyun Baek},
keywords = {Green synthesis, Zero-cost, Nanomaterials, Wastewater treatment, Sustainability},
abstract = {Water pollution is one of the most critical issues worldwide and is a priority in all scientific agendas. Green nanotechnology presents a plethora of promising avenues for wastewater treatment. This review discusses the current trends in the valorization of zero-cost, biodegradable, and readily available agro-industrial biowaste to produce green bio-nanocatalysts and bio-nanosorbents for wastewater treatment. The promising roles of green bio-nanocatalysts and bio-nanosorbents in removing organic and inorganic water contaminants are discussed. The potent antimicrobial activity of bio-derived nanodisinfectants against water-borne pathogenic microbes is reviewed. The bioactive molecules involved in the chelation and tailoring of green synthesized nanomaterials are highlighted along with the mechanisms involved. Furthermore, this review emphasizes how the valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment adheres to the fundamental principles of green chemistry, circular economy, nexus thinking, and zero-waste manufacturing. The potential economic, environmental, and health impacts of valorizing agro-industrial biowaste to green nanomaterials are highlighted. The challenges and future outlooks for the management of agro-industrial biowaste and safe application of green nanomaterials for wastewater treatment are summarized.}
}
@article{KUGURAKOVA2016217,
title = {Neurobiological Plausibility as Part of Criteria for Highly Realistic Cognitive Architectures},
journal = {Procedia Computer Science},
volume = {88},
pages = {217-223},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.428},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316842},
author = {Vlada Kugurakova and Maxim Talanov and Denis Ivanov},
keywords = {Lövheim cube, cognitive architectures, neurobiological realism},
abstract = {In this paper we analyze neurobiologically inspired approaches to implement emotions in computational systems. We propose the criteria for realistic cognitive architectures and analyze current architectures using aforementioned criteria. The analysis indicated several interesting architectures H-CogAff, BICA that inspired us to start the development of our own based on biological realistic approaches.}
}
@article{SHIBATA2021436,
title = {Sensitivity – Local index to control chaoticity or gradient globally –},
journal = {Neural Networks},
volume = {143},
pages = {436-451},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002471},
author = {Katsunari Shibata and Takuya Ejima and Yuki Tokumaru and Toshitaka Matsuki},
keywords = {Sensitivity, Sensitivity adjustment learning (SAL), Edge of chaos, Recurrent neural network (RNN), Deep feedforward neural network (DFNN), Vanishing gradient problem},
abstract = {Here, we introduce a fully local index named “sensitivity” for each neuron to control chaoticity or gradient globally in a neural network (NN). We also propose a learning method to adjust it named “sensitivity adjustment learning (SAL)”. The index is the gradient magnitude of its output with respect to its inputs. By adjusting its time average to 1.0 in each neuron, information transmission in the neuron changes to be moderate without shrinking or expanding for both forward and backward computations. That results in moderate information transmission through a layer of neurons when the weights and inputs are random. Therefore, SAL can control the chaoticity of the network dynamics in a recurrent NN (RNN). It can also solve the vanishing gradient problem in error backpropagation (BP) learning in a deep feedforward NN or an RNN. We demonstrate that when applying SAL to an RNN with small and random initial weights, log-sensitivity, which is the logarithm of RMS (root mean square) sensitivity over all the neurons, is equivalent to the maximum Lyapunov exponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP through time) to avoid the vanishing gradient problem in a 300-layer NN or an RNN that learns a problem with a lag of 300 steps between the first input and the output. Compared with manually fine-tuning the spectral radius of the weight matrix before learning, SAL’s continuous nonlinear learning nature prevents loss of sensitivities during learning, resulting in a significant improvement in learning performance.}
}
@incollection{ROCAVERT202065,
title = {Arts Bias},
editor = {Steven Pritzker and Mark Runco},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {65-68},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23612-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236122},
author = {Carla Rocavert},
keywords = {Algorithm, Arts, Bias, Creativity, Capitalism, Elite, Neoliberalism, Permanence, Technology, Utility},
abstract = {This entry posits that current debates around ‘arts bias’ are indicative of evolving definitions of creativity. It discusses themes of utility and permanence to illuminate tensions between historical conceptions of artistic creativity and newer fields, especially those which are driving the global economy toward an increasingly technologically-oriented paradigm under neoliberal capitalism. The arrival of computational creativity and the practice of applying algorithmic data technologies to artmaking are discussed.}
}
@article{RUTER2000519,
title = {Analysis, finite element computation and error estimation in transversely isotropic nearly incompressible finite elasticity},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {5},
pages = {519-541},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(99)00286-8},
url = {https://www.sciencedirect.com/science/article/pii/S0045782599002868},
author = {Marcus Rüter and Erwin Stein},
abstract = {In this paper we present constitutive models for nearly incompressible, transversely isotropic materials in finite hyperelasticity, particularly for reinforced rubber-like materials, which are of essential engineering interest. The theory is developed using a convected curvilinear coordinate system based on a mixed two-field displacement–pressure energy functional. Furthermore, an a posteriori error estimator without multiplicative constants is derived for non-linear anisotropic problems, which measures the discretization error in the first Piola–Kirchhoff stresses in the L2-norm by solving local Neumann problems with equilibrated tractions. Illustrative numerical examples demonstrate the anisotropic material behaviour of reinforced materials and the efficiency of using adaptive finite element methods.}
}
@article{ROBINSON2021,
title = {Development of the Organonitrogen Biodegradation Database: Teaching Bioinformatics and Collaborative Skills to Undergraduates during a Pandemic},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2351},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000745},
author = {Serina L. Robinson and Troy Biernath and Caleb Rosenthal and Dean Young and Lawrence P. Wackett and Betsy M. Martinez-Vaz},
abstract = {Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology.
ABSTRACT
Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology. The work presented here describes a fully online, collaborative research experience created to allow undergraduate students to learn those skills. The research experience was focused on the development and implementation of the Organonitrogen Biodegradation Database (ONDB, z.umn.edu/ondb). The ONDB was developed to catalog information about the cost, chemical properties, and biodegradation potential of commonly used organonitrogen compounds. A cross-institutional team of undergraduate researchers worked in collaboration with two faculty members and a postdoctoral fellow to develop the database. Students carried out extensive online literature searches and used a biodegradation prediction website to research and represent the microbial catabolism of different organonitrogen compounds. Participants employed computational tools such as R, Shiny, and flexdashboard to construct the database pages and interactive web interface for the ONDB. Worksheets and forms were created to encourage other students and researchers to gather information about organonitrogen compounds and expand the database. Student progress was evaluated through biweekly project meetings, presentations, and a final reflection. The ONDB undergraduate research experience provided a platform for students to learn bioinformatics skills while simultaneously developing a teaching and research tool for others.}
}
@article{ZMIGROD202034,
title = {The role of cognitive rigidity in political ideologies: theory, evidence, and future directions},
journal = {Current Opinion in Behavioral Sciences},
volume = {34},
pages = {34-39},
year = {2020},
note = {Political Ideologies},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2019.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2352154619301147},
author = {Leor Zmigrod},
abstract = {A contentious debate in political psychology has centred on the role of cognitive rigidity in shaping individuals’ political ideologies and worldviews. Early theories in the 1950s posited that strict ideological doctrines may tend to attract individuals with dispositions towards mental rigidity. This question has persisted: Does psychological rigidity foster a tendency towards ideological extremism? This review evaluates the empirical landscape with respect to the rigidity-of-the-extreme and the rigidity-of-the-right hypotheses and offers conceptual and methodological recommendations for future research avenues. The evidence suggests that cognitive rigidity is linked to ideological extremism, partisanship, and dogmatism across political and non-political ideologies. Advances in the measurement of ideological extremity and cognitive rigidity will facilitate further elucidation regarding how exactly the two hypotheses may be reconciled and why they have been historically placed in a potentially false competition. This synthesis suggests that a scientifically rigorous understanding of the cognitive roots of ideological thinking may be essential for developing effective antidotes to intolerance and intergroup hostility.}
}
@article{BULLEY20203457,
title = {Children Devise and Selectively Use Tools to Offload Cognition},
journal = {Current Biology},
volume = {30},
number = {17},
pages = {3457-3464.e3},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2020.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0960982220308514},
author = {Adam Bulley and Thomas McCarthy and Sam J. Gilbert and Thomas Suddendorf and Jonathan Redshaw},
keywords = {cognitive artifacts, cognitive offloading, cognitive development, extended mind, metacognition},
abstract = {Summary
From maps sketched in sand to supercomputing software, humans ubiquitously enhance cognitive performance by creating and using artifacts that bear mental load [1, 2, 3, 4, 5]. This extension of information processing into the environment has taken center stage in debates about the nature of cognition in humans and other animals [6, 7, 8, 9]. How does the human mind acquire such strategies? In two experiments, we investigated the developmental origins of cognitive offloading in 150 children aged between 4 and 11 years. We created a memory task in which children were required to recall the location of hidden targets. In one experiment, participants were provided with a pre-specified cognitive offloading opportunity: an option to mark the target locations with tokens during the hiding period. Even 4-year-old children quickly adopted this external strategy and, in line with a metacognitive account, children across ages offloaded more often when the task was more difficult. In a second experiment, we provided children with the means to devise their own cognitive offloading strategy. Very few younger children spontaneously devised a solution, but by ages 10 and 11, nearly all did so. In a follow-up test phase, a simple prompt greatly increased the rate at which the younger children devised an offloading strategy. These findings suggest that sensitivity to the difficulties of thinking arises early in development and improves throughout the early school years, with children learning to modify the world around them to compensate for their cognitive limits.}
}
@article{STRATFORD2022115813,
title = {Exploring the potential neurotoxicity of vaping vitamin E or vitamin E acetate},
journal = {Toxicology and Applied Pharmacology},
volume = {434},
pages = {115813},
year = {2022},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2021.115813},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X21004178},
author = {Kimberly Stratford and Prabha Kc and Susan Rudy and Anna-Sophie Weidner and Priscilla Callahan-Lyon and Luis G. Valerio},
keywords = {Pulmonary injury, Electronic Nicotine Delivery Systems (ENDS), Tobacco products, Electronic cigarettes, Vitamin E, Vitamin E acetate, E-Cigarette or Vaping Product Use-Associated Lung Injury (EVALI), Vaping, Neurotoxicity, Computational model},
abstract = {Serious adverse health effects have been reported with the use of vaping products, including neurologic disorders and e-cigarette or vaping product use-associated lung injury (EVALI). Vitamin E acetate, likely added as a diluent to cannabis-containing products, was linked to EVALI. Literature searches were performed on vitamin E and vitamin E acetate-associated neurotoxicity. Blood brain barrier (BBB) penetration potential of vitamin E and vitamin E acetate were evaluated using cheminformatic techniques. Review of the literature showed that the neurotoxic potential of inhalation exposures to these compounds in humans is unknown. Physico-chemical properties demonstrate these compounds are lipophilic, and molecular weights indicate vitamin E and vitamin E acetate have the potential for BBB permeability. Computational models also predict both compounds may cross the BBB via passive diffusion. Based on literature search, no experimental nonclinical studies and clinical information on the neurotoxic potential of vitamin E via inhalation. Neurotoxic effects from pyrolysis by-product, phenyl acetate, structurally analogous to vitamin E acetate, suggests vitamin E acetate has potential for central nervous system (CNS) impairment. Cheminformatic model predictions provide a theoretical basis for potential CNS permeability of these inhaled dietary ingredients suggesting prioritization to evaluate for potential hazard to the CNS.}
}
@article{WANG2022269,
title = {Intelligent Attack Analysis for IRS Communications with Incomplete Information},
journal = {Procedia Computer Science},
volume = {202},
pages = {269-276},
year = {2022},
note = {International Conference on Identification, Information and Knowledge in the internet of Things, 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.04.035},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922005695},
author = {Han Wang and Tianlin Zhu and Dapeng Li and Rui Jiang and Xiaoming Wang and Youyun Xu},
keywords = {IRS system, monitoring, attacking tactic, greedy, robust attack},
abstract = {Intelligent Reflection Surface (IRS) will be widely used in future communication system construction to reduce construction costs and improve coverage. However, IRS systems are generally equipped with controllers to receive wireless signal instructions, this increases the vulnerability of future communications. In this paper, we present an attack tactic to provide a way of thinking for the future defense deployment. At the beginning, the hacker cannot know the whole communication system, then it continuously attacks the IRS system, monitor the communication system, and sequentially learns new information about the system in each attacking round in order to attack more effectively in the next round. A two-layer optimal mathematical model is presented to describe the BS and the hacker’s decision. And the two-layer optimization which is difficult to solve is transformed into a single layer linear optimization by using equivalent transformation and dual transformation. A series of mathematical experiments are used to test different scenarios applicable to different monitoring style, and verify that the tactic proposed in this paper can effectively interfere with the system.}
}
@article{NOVIANTRI2023446,
title = {Unsteady State Temperature Distribution Inside House Based on Slope Roof},
journal = {Procedia Computer Science},
volume = {227},
pages = {446-453},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.545},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301712X},
author = {Viska Noviantri and Agus Diemas Prayoga and Denny Pratama},
keywords = {unsteady state heat equation, ghost point, finite difference method, slope roof},
abstract = {The house is a building that serves as a place to gather with family and also to get comfort. The house is designed so the occupants can feel aesthetically and functionally comfortable. It will be interesting to discuss the temperature inside the house as one of the comfort factors. The study aims to analyze the temperature conditions inside the house, which are influenced by the slope of the roof. A two-dimensional unsteady state heat equation represents this temperature since the temperature distribution satisfies the heat transfer concept and changes over time. This governing equation will be approximated by the forward time center space scheme as one finite difference method and completed by the quadratic ghost point method since the house domain is an irregular shape. Van Neumann criteria are applied here to analyze the stability of the computational approach for this numerical scheme. Furthermore, these schemes are implemented in MATLAB application to quantitatively and visually display temperature dynamics. Some simulations completed these approximations to see temperature variations over time. The results show that the bigger slope causes the average temperature to be cooler. In other words, the temperature in the house will be more comfortable when the roof slope gets bigger.}
}
@article{SAFARZYNSKA20121011,
title = {Evolutionary theorizing and modeling of sustainability transitions},
journal = {Research Policy},
volume = {41},
number = {6},
pages = {1011-1024},
year = {2012},
note = {Special Section on Sustainability Transitions},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2011.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0048733312000595},
author = {Karolina Safarzyńska and Koen Frenken and Jeroen C.J.M. {van den Bergh}},
keywords = {Coevolution, Evolutionary economics, Group selection, Lock-in, Niche, Regime, Social learning, Transition, Transition management},
abstract = {This paper argues that evolutionary thinking and modeling can contribute to the emerging research on sustainability transitions and their management. Evolutionary theory provides a range of concepts and mechanisms that are useful in making existing theorizing about transitions more precise and complete. In particular, we will discuss how the multi-level, multi-phase, co-evolutionary, and social learning dynamics underlying transitions can be addressed in evolutionary models. In addition, evolutionary theorizing offers suggestions for extending current theoretical frameworks of transitions. Group selection provides a good example. We review the small set of formal evolutionary models of sustainability transitions, and show that existing formal evolutionary models of technological, social and institutional change can provide useful inputs to transition research and management.}
}
@article{KOKIS200226,
title = {Heuristic and analytic processing: Age trends and associations with cognitive ability and cognitive styles},
journal = {Journal of Experimental Child Psychology},
volume = {83},
number = {1},
pages = {26-52},
year = {2002},
issn = {0022-0965},
doi = {https://doi.org/10.1016/S0022-0965(02)00121-2},
url = {https://www.sciencedirect.com/science/article/pii/S0022096502001212},
author = {Judite V. Kokis and Robyn Macpherson and Maggie E. Toplak and Richard F. West and Keith E. Stanovich},
abstract = {Developmental and individual differences in the tendency to favor analytic responses over heuristic responses were examined in children of two different ages (10- and 11-year-olds versus 13-year-olds), and of widely varying cognitive ability. Three tasks were examined that all required analytic processing to override heuristic processing: inductive reasoning, deductive reasoning under conditions of belief bias, and probabilistic reasoning. Significant increases in analytic responding with development were observed on the first two tasks. Cognitive ability was associated with analytic responding on all three tasks. Cognitive style measures such as actively open-minded thinking and need for cognition explained variance in analytic responding on the tasks after variance shared with cognitive ability had been controlled. The implications for dual-process theories of cognition and cognitive development are discussed.}
}
@article{CARVALHO2016169,
title = {Origins and evolution of enactive cognitive science: Toward an enactive cognitive architecture},
journal = {Biologically Inspired Cognitive Architectures},
volume = {16},
pages = {169-178},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X15000535},
author = {Leonardo Lana de Carvalho and Denis James Pereira and Sophia Andrade Coelho},
keywords = {Cognitive science, Enaction, Complex systems, Cognitive architecture},
abstract = {This paper presents a historical perspective on the origin of the enactive approach to cognitive science, starting chronologically from cybernetics, with the aim of clarifying its main concepts, such as enaction, autopoiesis, structural coupling and natural drift; thus showing their influences in computational approaches and models of cognitive architecture. Works of renowned authors, as well as some of their main commentators, were addressed to report the development of enactive approach. We indicate that the enactive approach transcends its original context within biology, and at a second moment within connectionism, changes the understanding of the relationships so far established between the body and the environment, and the ideas of conceptual relationships between the mind and the body. The influence on computational theories is of great importance, leading to new artificial intelligence systems as well as the proposition of complex, autopoietic and alive machines. Finally, the article stresses the importance of the enactive approach in the design of agents, understanding that previous approaches have very different cognitive architectures and that a prototypical model of enactive cognitive architecture is one of the largest challenges today.}
}
@article{GALLISTEL199243,
title = {Preverbal and verbal counting and computation},
journal = {Cognition},
volume = {44},
number = {1},
pages = {43-74},
year = {1992},
note = {Numerical Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(92)90050-R},
url = {https://www.sciencedirect.com/science/article/pii/001002779290050R},
author = {C.R. Gallistel and Rochel Gelman},
abstract = {We describe the preverbal system of counting and arithmetic reasoning revealed by experiments on numerical representations in animals. In this system, numerosities are represented by magnitudes, which are rapidly by inaccurately generated by the Meck and Church (1983) preverbal counting mechanism. We suggest the following. (1) The preverbal counting mechanisms is the source of the implicit principles that guide the acquisition of verbal counting. (2) The preverbal system of arithmetic computation provides the framework for the assimilation of the verbal system. (3) Learning to count involves, in part, learning a mapping from the preverbal numerical magnitudes to the verbal and written number symbols and the inverse mappings from these symbols to the preverbal magnitudes. (4) Subitizings is the use of the preverbal counting process and the mapping from the resulting magnitudes to number words in order to generate rapidly the number words for small numerosities. (5) The retrieval of the number facts, which plays a central role in verbal computation, is mediated via the inverse mappings from verbal and written numbers to the preverbal magnitudes and the use of these magnitudes to find the appropriate cells in tabular arrangements of the answers. (6) This model of the fact retrieval process accounts for the salient features of the reaction time differences and error patterns revealed by expriments on mental arithmetic. (7) The application of verbal and written computational algorithms goes on in parallel with, and is to some extent guided by, preverbal computations, both in the child and in the adult.}
}
@article{HAPPE2024112240,
title = {Authentic interdisciplinary online courses for alternative pathways into computer science},
journal = {Journal of Systems and Software},
pages = {112240},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112240},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400284X},
author = {Lucia Happe and Kai Marquardt},
keywords = {Interdisciplinary teaching, e-learning, Interest, Engagement, Diversity, Gender, Computer science education},
abstract = {The field of computer science (CS) is facing a crucial challenge in broadening participation and embracing diversity, especially among underrepresented gender groups. The presented interdisciplinary educational program is an efficient response to this challenge, designed to catalyze diversity in CS through engagement with complex, interest-driven problems. This paper outlines the program’s structure, elucidates the pedagogical underpinnings, and reflects on the emergent challenges and opportunities. We delve into how the fusion of CS with other academic disciplines can allure a more varied demographic, emphasizing the engagement of female high school students — a demographic pivotally positioned yet significantly untapped in CS. Through a systematic survey analysis, we measure the program’s efficacy in increasing interest in CS and in cultivating an appreciation for its application in addressing real-world, cross-disciplinary challenges. Our findings affirm the program’s success in bridging the engagement gap by leveraging students’ intrinsic interests, thus charting alternative pathways into the CS field. These insights underscore the critical role of interdisciplinary approaches, establishing a new standard for transformative CS educational methods.}
}
@article{YUKSEL2025100890,
title = {Transformation of labor: Educational robotics coding in elementary schools for 21st century skills},
journal = {Entertainment Computing},
volume = {52},
pages = {100890},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100890},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002581},
author = {Akça Okan Yüksel and Bilal Atasoy and Selçuk Özdemir},
keywords = {21st century skills, Educational robotics coding, Elementary school students, Sociocultural, Cognitive, Affective},
abstract = {This study aims to examine the effects of educational robotics activities on students’ 21st century skills. In the study, explanatory mixed method design was used. As a quantitative data collection tool, the 21st century skills scale was utilized [47]. In addition to quantitative data, qualitative data were collected from the teachers and students through semi-structured interviews. Within the scope of the research, students participated in robotic design courses with Arduino over the learning management system for ten weeks and participated in a competition with their products at the end of the activity. The activity was held with the participation of 62 students and 10 teachers. The findings of the study showed that educational robotic activities caused a significant increase in the affective domain of the students. While it did not cause any significant increase in the cognitive and sociocultural domains, the average scores of students increased on post-tests compared to the pretests for these two domains. In addition, students’ 21st century skills did not differ according to gender. Although there is no statistically significant difference in pretest–posttest results due to grade level, an increase was observed in posttest averages at each grade level. The observed increase in the post-tests, although not statistical, reveals the positive effect of educational robotic coding in terms of students’ 21st century skills. To support the results of the quantitative data, the analysis of the qualitative data revealed a consensus of both teachers and students on the contribution of such applications to the advancement of contemporary skills. In conclusion, the results of this study show that educational robotic coding can be used to develop 21st century skills of elementary school students.}
}
@article{DECOUGNY1994157,
title = {Load balancing for the parallel adaptive solution of partial differential equations},
journal = {Applied Numerical Mathematics},
volume = {16},
number = {1},
pages = {157-182},
year = {1994},
issn = {0168-9274},
doi = {https://doi.org/10.1016/0168-9274(94)00039-5},
url = {https://www.sciencedirect.com/science/article/pii/0168927494000395},
author = {H.L. deCougny and K.D. Devine and J.E. Flaherty and R.M. Loy and C. Özturan and M.S. Shephard},
abstract = {An adaptive technique for a partial differential system automatically adjusts a computational mesh or varies the order of a numerical procedure with a goal of obtaining a solution satisfying prescribed accuracy criteria in an optimal fashion. Processor load imbalances will, therefore, be introduced at adaptive enrichment steps during the course of a parallel computation. We develop and describe three procedures for retaining and restoring load balance that have low unit cost and are appropriate for use in an adaptive solution environment. Tiling balances load by using local optimality criteria within overlapping processor neighborhoods. Elemental data are migrated between processors within the same neighborhoods to restore balance. Tiling is restricted to uniform two-dimensional meshes and provides limited control of communications volume by priority-based element selection criteria. These shortcomings can potentially be overcome by creating a dynamic partition graph connecting processors and their neighboring regions. After coloring the edges of the graph, elemental data are iteratively transferred between processors by pairwise exchange to permit a more global migration. Octree decomposition of a spatial domain is a successful three-dimensional mesh generation strategy. The octree structure facilities a rapid load balancing procedure by performing tree traversals that (i) appraise subtree costs and (ii) partition spatial regions accordingly. Computational results are reported for two- and three-dimensional problems using nCUBE/2 hypercube, MasPar MP-2, and Thinking Machines CM-5 computers.}
}
@article{ALDRIDGE1967155,
title = {A wave analogue as a guide to ultrasonic thinking},
journal = {Ultrasonics},
volume = {5},
number = {3},
pages = {155-162},
year = {1967},
issn = {0041-624X},
doi = {https://doi.org/10.1016/S0041-624X(67)80060-X},
url = {https://www.sciencedirect.com/science/article/pii/S0041624X6780060X},
author = {E.E. Aldridge}
}
@incollection{VARGHESE202275,
title = {Chapter 4 - Principles in action},
editor = {George Varghese and Jun Xu},
booktitle = {Network Algorithmics (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {75-107},
year = {2022},
isbn = {978-0-12-809927-8},
doi = {https://doi.org/10.1016/B978-0-12-809927-8.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128099278000099},
author = {George Varghese and Jun Xu},
keywords = {Buffer validation, Dijkstra's algorithm, virtual circuit, transport protocols},
abstract = {Part 2 of the book begins a detailed look at specific network bottlenecks such as data copying and control transfer. While the principles are used in these later chapters, the focus of these later chapters is on the specific bottleneck being examined. Given that network algorithmics is as much a way of thinking as it is a set of techniques, it seems useful to round out Part 1 by seeing the principles in action on small, self contained, but nontrivial network problems. Thus this chapter provides examples of applying the principles in solving specific networking problems. The examples are drawn from real problems, and some of the solutions are used in real products. Unlike subsequent chapters, this chapter is not a collection of new material followed by a set of exercises. Instead, this chapter can be thought of as an extended set of exercises. In Section 4.1 to Section 4.15, 15 problems are motivated and described. Each problem is followed by a hint that suggests specific principles, which is then followed by a solution sketch. There are also a few exercises after each solution. In classes and seminars on the topic of this chapter, the audience enjoyed inventing solutions by themselves (after a few hints were provided), rather than directly seeing the final solutions.}
}
@article{HU2024112598,
title = {Unraveling the dynamics of stacking fault nucleation in ceramics: A case study of aluminum nitride},
journal = {Computational Materials Science},
volume = {231},
pages = {112598},
year = {2024},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2023.112598},
url = {https://www.sciencedirect.com/science/article/pii/S092702562300592X},
author = {Yixuan Hu and Yumeng Zhang and Simanta Lahkar and Xiaodong Wang and Qi An and Kolan {Madhav Reddy}},
keywords = {Ceramics, Aluminum nitride, Deformation, Stacking faults, Generalized stacking fault energy},
abstract = {Stacking fault (SF), originating from the emission of partial dislocations, wields significant influence over the structural and physicochemical traits of ceramic materials. Yet, the intricate atomic dynamics driving SF nucleation remain obscured. Here, we introduce an improved methodology for computing the generalized stacking fault energy (GSFE) in ceramics, integrating uneven Degrees of Freedom (DOFs) for distinct lattice sites. This refinement has yielded substantial energy advantages over the traditional rigid shift method inherited from metallic systems. Our findings underscore that the relaxation of nonmetallic N atoms within the SF region is pivotal for achieving a more realistic SF simulation. This, in turn, unveils the involvement of N atom migration within the SF region between different aluminum tetrahedral sites during SF nucleation. By alleviating the energy barrier, this relaxation contrasts with previous simulations where nonmetallic elements remained more rigid. This work demonstrates the atomic dynamics of SF nucleation in ceramics and breaks the conventional wisdom of uniformly applying constraints for GSFE computations.}
}
@article{CONRAD1991316,
journal = {Bulletin of Mathematical Biology},
volume = {53},
number = {1},
pages = {316-318},
year = {1991},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80052-7},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800527},
author = {Michael Conrad}
}
@article{MACLEOD2019101201,
title = {Mesoscopic modeling as a cognitive strategy for handling complex biological systems},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {78},
pages = {101201},
year = {2019},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2019.101201},
url = {https://www.sciencedirect.com/science/article/pii/S1369848618300839},
author = {Miles MacLeod and Nancy J. Nersessian},
keywords = {Mesoscopic modeling, Middle-out strategy, Systems biology, Model building, Mental modeling, Distributed cognition, Bounded rationality},
abstract = {In this paper we aim to give an analysis and cognitive rationalization of a common practice or strategy of modeling in systems biology known as a middle-out modeling strategy. The strategy in the cases we look at is facilitated through the construction of what can be called mesoscopic models. Many models built in computational systems biology are mesoscopic (midsize) in scale. Such models lack the sufficient fidelity to serve as robust predictors of the behaviors of complex biological systems, one of the signature goals of the field. This puts some pressure on the field to provide reasons for why and how these practices are warranted despite not meeting the stated goals of the field. Using the results of ethnographic study of problem-solving practices in systems biology, we aim to examine the middle-out strategy and mesoscopic modeling in detail and to show that these practices are rational responses to complex problem solving tasks on cognitive grounds in particular. However making this claim requires us to update the standard notion of bounded rationality to take account of how human cognition is coupled to computation in these contexts. Our account fleshes out the idea that has been raised by some philosophers on the “hybrid” nature of computational modeling and simulation. What we call “coupling” both extends modelers’ capacities to handle complex systems, but also produces various cognitive and computational constraints which need to be taken into account in any computational problem solving strategy seeking to maintain insight and control over the models produced.}
}
@incollection{WHITTEN201953,
title = {Chapter 4 - Guided Cognition Effects in Learning Mathematics},
editor = {William B. Whitten and Mitchell Rabinowitz and Sandra E. Whitten},
booktitle = {Guided Cognition for Learning},
publisher = {Academic Press},
pages = {53-108},
year = {2019},
isbn = {978-0-12-817538-5},
doi = {https://doi.org/10.1016/B978-0-12-817538-5.00004-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128175385000043},
author = {William B. Whitten and Mitchell Rabinowitz and Sandra E. Whitten},
keywords = {Advance organizers, Consolidators, Effective homework, Efficient homework, Guided Cognition design, Homework, Long-term or long-lasting learning, Middle school mathematics learning},
abstract = {This chapter reports 11 experiments that were done to determine whether Guided Cognition-designed homework facilitates learning middle school mathematics, and if so, to determine how it helps and what is learned. Experiments were performed in two middle schools and included 8th graders in two experiments and 7th graders in nine experiments. Mathematics topics ranged from fractions to integers to geometry. As in the literature experiments, students were in their normal school environment following their regular curriculum and were unaware that their learning was being observed. Guided Cognition design was found to be effective for learning mathematics. Working story problems that were enriched with cognitive events such as role play, divergent thinking, visualizing and illustrating, and relating to prior experience raised scores on unexpected quizzes by about a letter grade. Another unexpected quiz found that the improvements in problem-solving performance persisted for 6months. Guided Cognition homework was also found to be efficient in that students who worked eight problems and then performed four cognitive events performed as well on unexpected quizzes as students who worked 24 problems in the same time interval. Another pair of experiments determined that modest gains could be made from merely reading completed examples of cognitive events, but that these gains were not long-lasting. Performing the cognitive events was found to be most effective for long-term performance. Another experiment found that experiencing cognitive events after working some mathematics problems can help consolidate knowledge of how to work such problems.}
}
@article{BRANDT20051578,
title = {Mental spaces and cognitive semantics: A critical comment},
journal = {Journal of Pragmatics},
volume = {37},
number = {10},
pages = {1578-1594},
year = {2005},
note = {Conceptual Blending Theory},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2004.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0378216605000603},
author = {Per Aage Brandt},
keywords = {Mental Space Theory, Truth conditions, Spinoza, Semantic domains, Mental architecture, Material anchors},
abstract = {The article criticizes the negative influence of modern analytic, anti-semantic and anti-phenomenological thinking on cognitive semantics, and the errors or weaknesses of analysis it induces in current Mental Space Theory (MST). It also shows how a less inhibited theory of meaning, mental spaces and blending could develop more useful analyses of empirical occurrences, such as the artifacts called ‘material anchors’ and works of art — here exemplified by a painting by Matisse.}
}
@article{WOLLMANN2019278,
title = {Proposal for a model to hierarchize strategic decisions according to criteria of value innovation, sustainability and budgetary constraint},
journal = {Journal of Cleaner Production},
volume = {231},
pages = {278-289},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.05.190},
url = {https://www.sciencedirect.com/science/article/pii/S095965261931724X},
author = {Dewey Wollmann and Ubiratã Tortato},
keywords = {Complex adaptive systems, Analytic network process, BOCR analysis, Linear programming},
abstract = {Organizations need management models, which will enable their executives to develop systemic thinking. In addition, executives should keep in mind that: some decision-making processes should be shared; impose political influence according to their preferences; value innovation strategies may be present; it is essential to consider the environmental, economic and social dimensions of sustainability. In this context, this study describes a model to hierarchize strategic decisions according to criteria innovation value, sustainability and budgetary constraint, developed according to the methodology proposed by Mitroff et al. (1974). In addition to hierarchizing, the model allows identifying the degree of importance of each of the strategic decisions in the performance indicators defined as evaluation criteria and sub-criteria. In the conceptualization phase, the model is influenced by concepts that describe complex adaptive systems. Next, the Analytic Network Process with Benefits, Opportunities, Costs and Risks Analysis and Linear Programming techniques are used in order to define the mathematical structure that operationalizes the model. The use of a hypothetical example demonstrates the capacity of the model proposed in this work to support the decision-making process of an organization in the selection of its decision alternatives. Thus, the model can help the academic and business communities concerned with the progress of sustainable societies, insofar as it subsidizes decision-making for the development and implementation of new products and processes related to cleaner production.}
}
@article{NOST202223,
title = {Earth for AI: A Political Ecology of Data-Driven Climate Initiatives},
journal = {Geoforum},
volume = {130},
pages = {23-34},
year = {2022},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2022.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016718522000240},
author = {Eric Nost and Emma Colven},
keywords = {Adaptation, Artificial intelligence, Climate change, Digital geographies, Environmental data justice, Knowledge production},
abstract = {Emerging narratives around artificial intelligence (AI) and machine learning place great faith in these technologies’ ability to ameliorate threats posed by climate change. They promise the capacity to analyze vast amounts of more precise and real-time data, improving how decision-makers predict, respond, and adapt. Yet scholars in political ecology have long observed that technocentric approaches typically reduce complex human-environment relationships in ways that fail to account for social relations and power dynamics. This paper charts the emerging political economy of “climate AI” – the philanthropies, NGOs, private consultancies, and tech giants investing in data-driven climate initiatives. Mapping out two case studies, we show that environmental and climate crises are grist for tech solutions and find that many climate AI actors are interested in it for surveillance, greenwashing, and commodifying algorithms. We pay special attention to how neocolonial and racialized power structures manifest in climate AI and outline three ways for political ecologists and digital geographers to research its socio-materiality: how computational resources are environmentally embedded, how disasters become “shocks” that the AI industry capitalizes on, and how climate AI shapes material investment flows and landscapes. Highlighting how data-driven approaches to climate crises reproduce injustices already faced by marginalized communities, our analysis contributes to research on environmental data justice.}
}
@article{MOTANIETO2023103965,
title = {The Mexican Carbon Capture and Storage Platform: Construction of a boundary object for bridging the gaps between contexts, actors, and disciplines},
journal = {International Journal of Greenhouse Gas Control},
volume = {129},
pages = {103965},
year = {2023},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2023.103965},
url = {https://www.sciencedirect.com/science/article/pii/S1750583623001354},
author = {J. Mota-Nieto and J.A. Fernández-Reyes and P.M. García-Meneses},
keywords = {CCS/CCUS, Communication platform, Mexico, Boundary objects, Stakeholders},
abstract = {Carbon Capture and Storage (CCS) is a technology identified as a potential solution to mitigate climate change by reducing carbon emissions from large-scale emitters. If CCS is expected to be adopted globally, transparent and reliable data and information must be readily attainable to all stakeholders to support the technology choice and decision-making process. The implementation of CCS requires effective communication and collaboration strategies. Still, materials and communication platforms to inform stakeholders about the potential and contribution of CCS are predominantly accessible in English since ongoing projects are mainly located in English-speaking countries. The Mexican Carbon Capture and Storage platform (MeCCS) was developed as a digital sharing and learning space for national stakeholders to obtain and expand their knowledge about CCS technology in Spanish. It was constructed as a boundary object (BO) to bridge different communities and disciplines, facilitating communication, understanding, and cooperation. The platform includes diverse elements that combine science and art to produce dissemination materials for different audiences to help build critical thinking and inform them about CCS technology. The platform confirmed its capacity to transfer and translate knowledge one year after its launch. It also served to connect different audiences in Mexico and globally and identify further areas of research and CCS-related efforts.}
}
@article{ZHOU2024124298,
title = {Hyperspectral imaging combined with blood oxygen saturation for in vivo analysis of small intestinal necrosis tissue},
journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
volume = {315},
pages = {124298},
year = {2024},
issn = {1386-1425},
doi = {https://doi.org/10.1016/j.saa.2024.124298},
url = {https://www.sciencedirect.com/science/article/pii/S1386142524004645},
author = {Yao Zhou and LeChao Zhang and DanFei Huang and Yong Zhang and LiBin Zhu and Xiaoqing Chen and Guihua Cui and Qifan Chen and XiaoJing Chen and Shujat Ali},
keywords = {Hyperspectral imaging, Tissue oxygenation, Small intestine tissue, Isosbestic points},
abstract = {Acute mesenteric ischemia (AMI) is a clinically significant vascular and gastrointestinal condition, which is closely related to the blood supply of the small intestine. Unfortunately, it is still challenging to properly discriminate small intestinal tissues with different degrees of ischemia. In this study, hyperspectral imaging (HSI) was used to construct pseudo-color images of oxygen saturation about small intestinal tissues and to discriminate different degrees of ischemia. First, several small intestine tissue models of New Zealand white rabbits were prepared and collected their hyperspectral data. Then, a set of isosbestic points were used to linearly transform the measurement data twice to match the reference spectra of oxyhemoglobin and deoxyhemoglobin, respectively. The oxygen saturation was measured at the characteristic peak band of oxyhemoglobin (560 nm). Ultimately, using the oxygenated hemoglobin reflectance spectrum as the benchmark, we obtained the relative amount of median oxygen saturation in normal tissues was 70.0 %, the IQR was 10.1 %, the relative amount of median oxygen saturation in ischemic tissues was 49.6 %, and the IQR was 14.6 %. The results demonstrate that HSI combined with the oxygen saturation computation method can efficiently differentiate between normal and ischemic regions of the small intestinal tissues. This technique provides a powerful support for internist to discriminate small bowel tissues with different degrees of ischemia, and also provides a new way of thinking for the diagnosis of AMI.}
}
@article{JAGER2021133,
title = {Using agent-based modelling to explore behavioural dynamics affecting our climate},
journal = {Current Opinion in Psychology},
volume = {42},
pages = {133-139},
year = {2021},
note = {Psychology of Climate Change (2021)},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000968},
author = {Wander Jager},
keywords = {Agent based modelling, Social complexity, Computational social science, Social simulation, Artificial societies, Environmental behaviour, Climate, Psychology},
abstract = {This article introduces the methodology of agent-based modelling (ABM), explains how it contributes to understanding the dynamics of climate-relevant behaviour and discusses the challenges to implementing behavioural theory in ABMs. Next, an overview will be given on recent advances in environmentally relevant ABMs. The conclusions address the future of the ABM tool in the context of environmentally relevant behaviour in research and education.}
}
@article{MOAVENI2018452,
title = {Modified Hankel Interaction Index Array for Input-Output Pairing with Improved Characteristics},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {18},
pages = {452-457},
year = {2018},
note = {10th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.342},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318320251},
author = {Bijan Moaveni and Wolfgang Birk},
keywords = {Control configuration selection, Interaction measure, Hankel Interaction Index Array, System Gramians},
abstract = {In this study, a modified version of Hankel Interaction Index Array (HIIA) for control configuration selection is presented which can overcome some of its shortcomings, like e.g. scaling dependency, or not relating to closed loop system properties. Inspired by the relative gain array approach, the HIIA is reformulated in the relative gain thinking by considering the effect of closing loops. The ratio of the Hankel norm of the subsystems in closed and open loop are used to state a modified version of HIIA, which has improved characteristics compared to the original HIIA. Properties of the modified HIIA are discussed and benchmarked with established methods on three example cases.}
}
@article{MA2024100647,
title = {Design of online teaching interaction mode for vocational education based on gamified-learning},
journal = {Entertainment Computing},
volume = {50},
pages = {100647},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100647},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124000156},
author = {Zhongbao Ma and Wei Li},
keywords = {Gamified-learning, Traveler-type problems, Genetic-based algorithms, Game design},
abstract = {Along with the process of building China's modern vocational education system, China's higher vocational education has made great progress. With the development of computer and Internet technology, gamified learning, as a new way of learning, combines the advantages of computer games and online learning, which not only meets the needs of people to learn anytime and anywhere, but also increases the fun of learning activities. In this paper, we developed a gamified learning software with traveler-type problems as the research content, through the interaction with the game, so that students can think in the game and learn knowledge through the game. Through the questionnaire for research and analysis, this game is good game fun and can stimulate learning interest well. In addition, this paper carries out an in-depth study of the game's help system, optimizes the algorithm for the help system, and proposes an improved genetic algorithm. The reverse learning method is adopted to improve the accuracy and convergence speed of the optimal solution; then the Metropolis criterion is used to improve the crossover and mutation operators to enhance the local search ability of the algorithm; finally, the concept of realistic elite learning is introduced to further enhance the local search ability of the algorithm. The simulation results show that the algorithm is effectively improved in convergence performance and solution accuracy, which can significantly improve the response speed of the help system, effectively improve the game's fun, and improve the game's playability.}
}
@article{CHONG2016257,
title = {A generalized cognitive hierarchy model of games},
journal = {Games and Economic Behavior},
volume = {99},
pages = {257-274},
year = {2016},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2016.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0899825616300847},
author = {Juin-Kuan Chong and Teck-Hua Ho and Colin Camerer},
keywords = {Cognitive hierarchy, Level- model, Level- model, Generalized cognitive hierarchy, Non-equilibrium structural models, Behavioral game theory},
abstract = {Subjects in simple games frequently exhibit non-equilibrium behaviors. Cognitive hierarchy (CH) and level k (LK) are two prevailing structural models that capture such behaviors well. This paper proposes a generalized CH (GCH) model that nests a variant of the LK model, called LM. GCH differs from CH in two ways. First, each lower level's actual frequency is exponentially weighted with α to form level-k's belief on relative proportions; α captures stereotype bias. CH assumes no stereotype bias (α=1) and LM assumes extreme bias (α=∞). Second, GCH replaces random choice with minimum aversion for level 0. Level 0s are more likely to choose strategies that never yield the minimum payoff for any of the opponent's strategies. GCH captures behaviors better than CH and LK in fifty-five n×m games from four datasets. Robustness tests using three new games further validate GCHs descriptive strength over CH and LK.}
}
@incollection{DORFMAN1998395,
title = {Chapter 8 Problem solving, inhibition, and frontal lobe function},
editor = {Naftali Raz},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {125},
pages = {395-448},
year = {1998},
booktitle = {The Other Side of the Error Term},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(98)80010-1},
url = {https://www.sciencedirect.com/science/article/pii/S0166411598800101},
author = {Jennifer Dorfman},
abstract = {Traditionally, cognitive models of problem solving have not incorporated inhibitory mechanisms, conceiving of human thinking as similar to the computations carried out by a serial computer (e.g., Newell & Simon, 1972). This chapter seeks to demonstrate the importance of inhibition in problem solving by examining subject populations with selective impairments of cognitive inhibition associated with frontal lobe pathology. Studies of three groups with putative frontal lobe dysfunction are reviewed: patients with focal lesions of the prefrontal cortex; schizophrenics; and the normal elderly. It is argued that the basic deficits observed in these groups reflect breakdowns in a supervisory attentional system that modulates problem-solving activity and that is subserved by the frontal cortex (Shallice, 1982). It is concluded that it is time to abandon the computer metaphor of human problem solving and adopt a brain metaphor.}
}
@article{FU2013729,
title = {Expert representation of design repository space: A comparison to and validation of algorithmic output},
journal = {Design Studies},
volume = {34},
number = {6},
pages = {729-762},
year = {2013},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2013.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X13000495},
author = {Katherine Fu and Joel Chan and Christian Schunn and Jonathan Cagan and Kenneth Kotovsky},
keywords = {computer supported design, design by analogy, design methods, engineering design},
abstract = {Development of design-by-analogy tools is a promising design innovation research avenue. Previously, a method for computationally structuring patent databases as a basis for an automated design-by-analogy tool was introduced. To demonstrate its strengths and weaknesses, a computationally-generated structure is compared to four expert designers' mental models of the domain. Results indicate that, compared to experts, the computationally-generated structure is sensible in clustering of patents and organization of clusters. The computationally-generated structure represents a space in which experts can find common ground/consensus – making it promising to be intuitive/accessible to broad cohorts of designers. The computational method offers a resource-efficient way of usefully conceptualizing the space that is sensible to expert designers, while maintaining an element of unexpected representation of the space.}
}
@article{WILSON1997575,
title = {Computation and controversy: Value conflicts and social choices: R. KLING (Ed.) 2nd ed. Academic Press, New York (1996). xxiv + 961 pp., ISBN 0-12-415040-3},
journal = {Information Processing & Management},
volume = {33},
number = {4},
pages = {575-577},
year = {1997},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(97)82727-6},
url = {https://www.sciencedirect.com/science/article/pii/S0306457397827276},
author = {Tom Wilson}
}
@article{MOGILNER2019R915,
title = {Alex Mogilner},
journal = {Current Biology},
volume = {29},
number = {19},
pages = {R915-R917},
year = {2019},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.07.077},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219309571},
author = {Alex Mogilner}
}
@article{SHIN2023104897,
title = {Pedagogical discourse markers in online algebra learning: Unraveling instructor's communication using natural language processing},
journal = {Computers & Education},
volume = {205},
pages = {104897},
year = {2023},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104897},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523001744},
author = {Jinnie Shin and Renu Balyan and Michelle P. Banawan and Tracy Arner and Walter L. Leite and Danielle S. McNamara},
keywords = {Pedagogical communication, Online learning, Video lectures, Natural language processing},
abstract = {Despite the proliferation of video-based instruction and its benefits—such as promoting student autonomy and self-paced learning—the complexities of online teaching remain a challenge. To be effective, educators require extensive training in digital teaching methodologies. As such, there's a pressing need to examine and comprehend the intricacies of instructors' communication patterns within this context. This research addresses the pressing need to understand pedagogical discourse in online video lectures in Algebra classes by employing computational linguistic tools and natural language processing (NLP). Using transcripts from 125 Algebra 1 video lectures—comprising 4962 instances of pedagogical discourse—from five instructors at Math Nation, a virtual math learning environment, we analyzed the conveyance of linguistic, attitudinal, and emotional nuances. With the aid of 26 Coh-Metrix and SÉANCE features, we classified educators' language choices, achieving an accuracy of 86.7%. Furthermore, variations in language choices, as signified by discourse markers, were examined through a K-means clustering approach. The resulting 17 clusters were grouped into interpersonal, structural, and cognitive pedagogic functions. Through this exploration, we demonstrate the promising potential of NLP in efficiently deciphering pedagogical communication patterns in video lectures. These insights open a new avenue for research, aimed at assessing the efficacy of digital instruction by scrutinizing pedagogical discourse characteristics in computer-based learning environments.}
}