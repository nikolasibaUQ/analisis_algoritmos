@article{ZHENG2022104214,
title = {Evaluation of an automated phenotyping algorithm for rheumatoid arthritis},
journal = {Journal of Biomedical Informatics},
volume = {135},
pages = {104214},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104214},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422002192},
author = {Henry W. Zheng and Veena K. Ranganath and Lucas C. Perry and David A. Chetrit and Karla M. Criner and Angela Q. Pham and Richard Seto and Sitaram Vangala and David A. Elashoff and Alex A.T. Bui},
keywords = {Phenotyping algorithm, Computational phenotyping, Rheumatoid arthritis, PheKB},
abstract = {To better understand the challenges of generally implementing and adapting computational phenotyping approaches, the performance of a Phenotype KnowledgeBase (PheKB) algorithm for rheumatoid arthritis (RA) was evaluated on a University of California, Los Angeles (UCLA) patient population, focusing on examining its performance on ambiguous cases. The algorithm was evaluated on a cohort of 4,766 patients, along with a chart review of 300 patients by rheumatologists against accepted diagnostic guidelines. The performance revealed low sensitivity towards specific subtypes of positive RA cases, which suggests revisions in features used for phenotyping. A close examination of select cases also indicated a significant portion of patients with missing data, drawing attention to the need to consider data integrity as an integral part of phenotyping pipelines, as well as issues around the usability of various codes for distinguishing cases. We use patterns in the PheKB algorithm’s errors to further demonstrate important considerations when designing a phenotyping algorithm.}
}
@incollection{KATZ202453,
title = {Chapter Three - The role of big data and analytics in utilities innovation},
editor = {Reza Arghandeh and Yuxun Zhou},
booktitle = {Big Data Application in Power Systems (Second Edition)},
publisher = {Elsevier Science},
edition = {Second Edition},
pages = {53-68},
year = {2024},
isbn = {978-0-443-21524-7},
doi = {https://doi.org/10.1016/B978-0-443-21524-7.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443215247000037},
author = {Jeffrey S. Katz},
keywords = {Big data, Analytics, Data science, Smart grid, Power system simulation, Numerical weather analysis, Smarter energy research},
abstract = {The computational technology known as big data and its subsequent processing, analytics, are driving innovation in electric power system integration of renewable energy, outage prediction, processing of increasing volumes of smart grid data, as well as the velocity of such data. In the age of cybersecurity, the veracity of this data is also a factor. The almost concurrent rise of cognitive computing gives new importance to unstructured data such as drone images and text in maintenance reports. The intelligent connection of real-time numerical data with written and visual data gives rise to even more innovation. The benefits of high-precision weather modeling on power demand, grid damage, and solar- and wind-based generation are also considered.}
}
@article{LEBERRE2022103122,
title = {Systemic vulnerability of coastal territories to erosion and marine flooding: A conceptual and methodological approach applied to Brittany (France)},
journal = {International Journal of Disaster Risk Reduction},
volume = {78},
pages = {103122},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103122},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922003417},
author = {Iwan {Le Berre} and Catherine Meur-Ferec and Véronique Cuq and Elisabeth Guillou and Thibaud Lami and Nicolas {Le Dantec} and Pauline Letortu and Caroline Lummert and Manuelle Philippe and Mathias Rouan and Camille Noûs and Alain Hénaff},
keywords = {Coastal risks, Erosion, Flooding, Vulnerability, Web-GIS interface},
abstract = {The attractiveness of the coasts tends to increase their exposure to erosion and marine flooding risks. This exposure is exacerbated by the effects of climate change, in particular sea level rise. To contribute to strategic thinking on the vulnerability of coastal areas, it is essential to develop, share and collectively maintain relevant knowledge on risks. This article will present the thinking behind the setting up of a coastal risks observatory in Brittany, a region located in north-western France. It relies on a conceptual approach to systemic vulnerability based on four components: hazards, assets, management, and social representations. Hazards and assets underpin the notion of risk and tend to increase the vulnerability, management tends to mitigate it, and representations can play a part in increasing or decreasing it depending on the context. To understand and analyse this system of vulnerability, our approach is based on the generation of a set of 62 indicators combined into different types of indices. A web-GIS interface was developed to navigate through and map this system of vulnerability. The difficulties associated with this type of synthetic approach will be discussed, whether they are related to data availability, to the links between scientific research and operational territorial management requirements, or to an understanding of the dynamics of all of the vulnerability components and their interactions. Ultimately, the approach developed has been successful in mobilising scientific and operational stakeholders around the co-construction of a diagnosis of territories with regard to their vulnerability to coastal risks.}
}
@article{SHI2024100685,
title = {Drug development in the AI era: AlphaFold 3 is coming!},
journal = {The Innovation},
volume = {5},
number = {5},
pages = {100685},
year = {2024},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2024.100685},
url = {https://www.sciencedirect.com/science/article/pii/S2666675824001231},
author = {Yi Shi}
}
@article{KOWALCZUK2019206,
title = {The impact of the temperament model on the behavior of an autonomous driver},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {8},
pages = {206-210},
year = {2019},
note = {10th IFAC Symposium on Intelligent Autonomous Vehicles IAV 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.072},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319304033},
author = {Z. Kowalczuk and O. Piechowski and M. Czubenko},
keywords = {Learning, adaptation, autonomous vehicles, artificial intelligence, cognitive aspects},
abstract = {Because it is generally believed that the personality and temperament of a human driver influence his/her behavior on the road, the article presents a computational model of the temperament of an autonomous agent - a driver. First, a short review of the four ideas of Galen’s temperament in psychology is presented. Temperament traits are grouped into four other sets, one of which is chosen for implementation in the project of integration of the temperament model with the target autonomous agent. On the basis of this selection, it is proposed to modify, by introducing additional useful mechanisms of temperament, the existing model (ISD) of an autonomous robot and/or driver. In addition, other ways of extending the ISD model are indicated, as well as possible applications of the proposed system. The developed model may also be interesting for other research purposes in which the description of the human personality is important.}
}
@article{HOFFMAN202472,
title = {AI’s impact on war’s enduring nature},
journal = {Orbis},
volume = {68},
number = {1},
pages = {72-91},
year = {2024},
issn = {0030-4387},
doi = {https://doi.org/10.1016/j.orbis.2023.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0030438723000583},
author = {Frank Hoffman and Axel D'Amelio},
abstract = {This article reassesses the impact of Artificial Intelligence on war and revisits an article published in 2018 by one of the authors in Orbis. Despite the remarkable progress in generative AI, the authors contend that war’s essential nature will be impacted to a degree but will not be substantially altered.}
}
@article{JANG2024132519,
title = {Comparative study on gradient-free optimization methods for inverse source-term estimation of radioactive dispersion from nuclear accidents},
journal = {Journal of Hazardous Materials},
volume = {461},
pages = {132519},
year = {2024},
issn = {0304-3894},
doi = {https://doi.org/10.1016/j.jhazmat.2023.132519},
url = {https://www.sciencedirect.com/science/article/pii/S0304389423018022},
author = {Siho Jang and Juryong Park and Hyun-Ha Lee and Chun-Sil Jin and Eung Soo Kim},
keywords = {Gradient-free optimization, Multi-units & multiple radionuclides release scenario, Improving source-term estimation, Environmental radioactivity monitoring, GPU parallelization},
abstract = {In this study, we rigorously assess the performance of three gradient-free optimization algorithms—Ensemble Kalman Inversion (EKI), Particle Swarm Optimization (PSO), and Genetic Algorithm (GA)—for estimating source terms in diverse radionuclide release scenarios. Our analysis encompasses both single and multiple sources with varying radionuclide compositions, delving into the influence of decay constants and radioactivity on source estimation accuracy. Although estimating a single radionuclide from a single source exhibits outstanding results, estimating multiple radionuclides from a single source proves more arduous due to the limited information available for discerning gamma dose rates. Contrary to expectations, increasing the number of observation stations does not consistently improve the likelihood of finding accurate solutions in ill-posed inverse problems. Impressively, under our simulation settings, EKI demonstrates competitive performance in terms of convergence, accuracy, and runtime compared to PSO and GA, with GPU parallelization further bolstering computational efficiency. We explore strategies for enhancing source term estimation, including incorporating prior information, applying uncertainty removal techniques, and optimizing observation placement. Additionally, this study underscores the intricate role of relative error in determining multi-radionuclide estimation accuracy from gamma dose measurements. By employing the Gaussian plume model under steady-state conditions, our research lays the groundwork for future applications of Lagrangian dispersion models with real-time data integration. The insights gleaned from our study promise to advance environmental radioactivity monitoring and catalyze the development of cutting-edge, real-time source estimation technologies in full-scale systems.}
}
@article{OZTOP201343,
title = {Mirror neurons: Functions, mechanisms and models},
journal = {Neuroscience Letters},
volume = {540},
pages = {43-55},
year = {2013},
note = {The Mirror Neuron System},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2012.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0304394012013183},
author = {Erhan Oztop and Mitsuo Kawato and Michael A. Arbib},
keywords = {Mirror neuron, Computational model, Action recognition, imitation, language evolution, Mirror neuron development, Direct matching},
abstract = {Mirror neurons for manipulation fire both when the animal manipulates an object in a specific way and when it sees another animal (or the experimenter) perform an action that is more or less similar. Such neurons were originally found in macaque monkeys, in the ventral premotor cortex, area F5 and later also in the inferior parietal lobule. Recent neuroimaging data indicate that the adult human brain is endowed with a “mirror neuron system,” putatively containing mirror neurons and other neurons, for matching the observation and execution of actions. Mirror neurons may serve action recognition in monkeys as well as humans, whereas their putative role in imitation and language may be realized in human but not in monkey. This article shows the important role of computational models in providing sufficient and causal explanations for the observed phenomena involving mirror systems and the learning processes which form them, and underlines the need for additional circuitry to lift up the monkey mirror neuron circuit to sustain the posited cognitive functions attributed to the human mirror neuron system.}
}
@article{HAN20212821,
title = {Artificial protein assemblies with well-defined supramolecular protein nanostructures},
journal = {Biochemical Society Transactions},
volume = {49},
number = {6},
pages = {2821-2830},
year = {2021},
issn = {1470-8752},
doi = {https://doi.org/10.1042/BST20210808},
url = {https://www.sciencedirect.com/science/article/pii/S1470875221001033},
author = {Suyeong Han and Yongwon Jung},
keywords = {protein assembly, protein engineering, protein nanostructures},
abstract = {Nature uses a wide range of well-defined biomolecular assemblies in diverse cellular processes, where proteins are major building blocks for these supramolecular assemblies. Inspired by their natural counterparts, artificial protein-based assemblies have attracted strong interest as new bio-nanostructures, and strategies to construct ordered protein assemblies have been rapidly expanding. In this review, we provide an overview of very recent studies in the field of artificial protein assemblies, with the particular aim of introducing major assembly methods and unique features of these assemblies. Computational de novo designs were used to build various assemblies with artificial protein building blocks, which are unrelated to natural proteins. Small chemical ligands and metal ions have also been extensively used for strong and bio-orthogonal protein linking. Here, in addition to protein assemblies with well-defined sizes, protein oligomeric and array structures with rather undefined sizes (but with definite repeat protein assembly units) also will be discussed in the context of well-defined protein nanostructures. Lastly, we will introduce multiple examples showing how protein assemblies can be effectively used in various fields such as therapeutics and vaccine development. We believe that structures and functions of artificial protein assemblies will be continuously evolved, particularly according to specific application goals.}
}
@article{WANG2023100113,
title = {Scheduling power-to-ammonia plants considering uncertainty and periodicity of electricity prices},
journal = {Smart Energy},
volume = {11},
pages = {100113},
year = {2023},
issn = {2666-9552},
doi = {https://doi.org/10.1016/j.segy.2023.100113},
url = {https://www.sciencedirect.com/science/article/pii/S2666955223000205},
author = {Shunchao Wang and Pengfei Zhang and Tuo Zhuo and Hua Ye},
keywords = {Power-to-ammonia, Markov decision process, Hydrogen, Haber-Bosch reactor},
abstract = {Developing affordable and scalable energy storage solutions are essential to decarbonizing power systems. The conversion of renewable electricity into chemical energy carriers such as ammonia has attracted extensive attention from academia and industry. Many Power-to-Ammonia (PtA) plants have been conceptualized and developed worldwide in recent years. The PtA plant is an integration of multiple electrochemical processes, each with a distinct set of operational constraints and cost structure. One of the problems in the operation of PtA plants is the optimal scheduling of the hydrogen buffer in PtA plants considering the operational characteristics of electrochemical processes and the volatility and uncertainty of electricity prices. In this paper, a two-stage Markov-Decision-Process (MDP) approach is proposed. The computational challenges brought by the infinite optimization horizon and non-concavity of cost functions are resolved. The first stage solution is based on the periodic MDP approach, which captures the periodic structure of electricity prices. The second stage solution gives optimal real-time decisions based on a rolling-horizon MDP approach. Numerical results show that the accurate representations of the cost functions and the optimization horizon using the proposed method are necessary, while the linearization of cost functions and the truncation of the optimization horizon lead to notable deviations from the optimality.}
}
@incollection{HOLLAN199733,
title = {Chapter 2 - Information Visualization},
editor = {Marting G. Helander and Thomas K. Landauer and Prasad V. Prabhu},
booktitle = {Handbook of Human-Computer Interaction (Second Edition)},
publisher = {North-Holland},
edition = {Second Edition},
address = {Amsterdam},
pages = {33-48},
year = {1997},
isbn = {978-0-444-81862-1},
doi = {https://doi.org/10.1016/B978-044481862-1.50068-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444818621500686},
author = {James D. Hollan and Benjamin B. Bederson and Jonathan I. Helfman},
abstract = {Publisher Summary
Computation provides the most plastic representational medium and for that it can be employed to mimic successful mechanisms of earlier media and also enables novel techniques that were not previously possible. Computation-based information presentations promise to dramatically enrich the understandings as well as assist in navigating and effectively exploiting rapidly growing and increasingly complex information collections. This chapter surveys a sample of recent information visualization research. Information visualization has a long history, dating to the earliest forms of symbolic representation, and can be approached from multiple perspectives, ranging across psychology, epistemology, graphic design, linguistics, and semiology to newer perspectives emerging from cognitive science. The goal of this chapter is to provide a glimpse of current research as it attempts to communicate the exciting potential of new dynamic representations. To accomplish this, profiling is done for selected recent work from the research group. This chapter further discusses the beginnings of a paradigm shift for thinking about information, one that starts viewing information as being much more dynamic and reactive to the nature of people's tasks, activities, and even relationships with others.}
}
@article{ADABALA2005896,
title = {From virtualized resources to virtual computing grids: the In-VIGO system},
journal = {Future Generation Computer Systems},
volume = {21},
number = {6},
pages = {896-909},
year = {2005},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2003.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03002899},
author = {Sumalatha Adabala and Vineet Chadha and Puneet Chawla and Renato Figueiredo and José Fortes and Ivan Krsul and Andrea Matsunaga and Mauricio Tsugawa and Jian Zhang and Ming Zhao and Liping Zhu and Xiaomin Zhu},
keywords = {Virtual machines, Grid-computing, Middleware, Virtual data, Network computing},
abstract = {This paper describes the architecture of the first implementation of the In-VIGO grid-computing system. The architecture is designed to support computational tools for engineering and science research In Virtual Information Grid Organizations (as opposed to in vivo or in vitro experimental research). A novel aspect of In-VIGO is the extensive use of virtualization technology, emerging standards for grid-computing and other Internet middleware. In the context of In-VIGO, virtualization denotes the ability of resources to support multiplexing, manifolding and polymorphism (i.e. to simultaneously appear as multiple resources with possibly different functionalities). Virtualization technologies are available or emerging for all the resources needed to construct virtual grids which would ideally inherit the above mentioned properties. In particular, these technologies enable the creation of dynamic pools of virtual resources that can be aggregated on-demand for application-specific user-specific grid-computing. This change in paradigm from building grids out of physical resources to constructing virtual grids has many advantages but also requires new thinking on how to architect, manage and optimize the necessary middleware. This paper reviews the motivation for In-VIGO approach, discusses the technologies used, describes an early architecture for In-VIGO that represents a first step towards the end goal of building virtual information grids, and reports on first experiences with the In-VIGO software under development.}
}
@article{CLINDANIEL2024105890,
title = {Digital formation processes: A high-frequency, large-scale investigation},
journal = {Journal of Archaeological Science},
volume = {161},
pages = {105890},
year = {2024},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2023.105890},
url = {https://www.sciencedirect.com/science/article/pii/S030544032300170X},
author = {Jon Clindaniel and Matthew Magnani},
keywords = {Formation processes, Palimpsests, Big data, Digital materiality, Craigslist, Free stuff, Social stratification},
abstract = {Large sources of digital trace data (i.e. “Big Data”) have become increasingly important in the study of material culture. However, akin to the offline material culture traditionally studied by archaeologists, digital trace data is rarely a passive reflection of human behavior – it is a complex palimpsest produced through a variety of erasure and accretion formation processes. To better understand how digital trace palimpsests are formed and how digital formation processes influence and inform our ability to interpret the offline material processes they index, we introduce a computational method – high-frequency archaeological survey – which allows us to observe digital formation processes at a high temporal resolution, as well as a large spatial scale. Using this method every hour for one month, we surveyed posts from across the United States in Craigslist's “Free Stuff” category (popularly called “Curb Alert”), a user-generated source of big digital trace data, indexing material things that have been placed on users' curbs for removal by scavengers or trash collectors. For each post, we observed its time-to-erasure and any edits that were made during the study period – finding that the posts that survive represent a biased sample of those that were posted over the course of the month, conditioned by how recently and on what day the post is posted, the material characteristics of things that are posted about, as well as regional variation. Far from only being evidence of biased end-of-month data, however, we show that further analysis of identified digital formation processes can be an important object of study in its own right – in this case, shedding new light on social scientific questions linking the exchange of “free stuff” with the process of social stratification and urban inequality in the United States. Overall, our findings suggest the importance of accounting for and explicitly analyzing digital formation processes in studies that utilize digital trace data.}
}
@article{CHEN20247,
title = {QoE oriented intelligent online learning evaluation technology in B5G scenario},
journal = {Digital Communications and Networks},
volume = {10},
number = {1},
pages = {7-15},
year = {2024},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2022.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S2352864822001110},
author = {Mingzi Chen and Xin Wei and Peizhong Xie and Zhe Zhang},
keywords = {B5G, Online learning, Quality of experience},
abstract = {Students' demand for online learning has exploded during the post-COVID-19 pandemic era. However, due to their poor learning experience, students' dropout rate and learning performance of online learning are not always satisfactory. The technical advantages of Beyond Fifth Generation (B5G) can guarantee a good multimedia Quality of Experience (QoE). As a special case of multimedia services, online learning takes into account both the usability of the service and the cognitive development of the users. Factors that affect the Quality of Online Learning Experience (OL-QoE) become more complicated. To get over this dilemma, we propose a systematic scheme by integrating big data, Machine Learning (ML) technologies, and educational psychology theory. Specifically, we first formulate a general definition of OL-QoE by data analysis and experimental verification. This formula considers both the subjective and objective factors (i.e., video watching ratio and test scores) that most affect OL-QoE. Then, we induce an extended layer to the classic Broad Learning System (BLS) to construct an Extended Broad Learning System (EBLS) for the students' OL-QoE prediction. Since the extended layer can increase the width of the BLS model and reduce the redundant nodes of BLS, the proposed EBLS can achieve a trade-off between the prediction accuracy and computation complexity. Finally, we provide a series of early intervention suggestions for different types of students according to their predicted OL-QoE values. Through timely interventions, their OL-QoE and learning performance can be improved. Experimental results verify the effectiveness of the proposed scheme.}
}
@article{HAO2025115545,
title = {Temperature history reconstruction in steel box girders using limited data and proper orthogonal decomposition-based dimension reduction representation},
journal = {Measurement},
volume = {240},
pages = {115545},
year = {2025},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2024.115545},
url = {https://www.sciencedirect.com/science/article/pii/S0263224124014301},
author = {Jing Hao and Hailin Lu and Hongyou Cao and Yunlai Zhou},
keywords = {Temperature history reconstruction, High-frequency temperature component, Stochastic vector processes, Dimension reduction, Proper orthogonal decomposition},
abstract = {The monitoring temperature history of steel box girders inevitably contains gaps or anomalies due to the malfunctions of the structural health monitoring system. Traditional methods for reconstructing temperature histories face the challenge in accounting for the randomness of temperature variations caused by the uncertainty of complex environmental factors. This research proposes a framework for reconstructing the long-term temperature of steel box girders by combining the limited measurements with a proper orthogonal decomposition (POD) based dimension reduction representation approach, to account for the stochastic nature of daily temperature variations. Unlike the conventional Monte Carlo-based POD method, the developed POD-based dimension reduction representation approach effectively reduces the number of elementary random variables from thousands to two by introducing random functions serving as constraints, overcoming the challenge of high-dimensional random variables inherent in the Monte Carlo methods. The proposed approach divides the measured temperature histories into random high-frequency (HF) and deterministic low-frequency (LF) components and establishes the theoretical models of power spectral density and coherence functions of HF temperature components to accommodate the generation of HF temperature component samples, and finally reconstructs temperature samples by superimposing the LF components and generated HF component samples. The results from a practical example demonstrate that the statistical characteristics of representative HF temperature component samples generated by the POD-based dimension reduction representation align well with the corresponding targeted values, and the proposed method outperforms the traditional POD method, yielding a 60% efficiency enhancement without compromising computational accuracy. The developed framework owns apparent superiority in accuracy compared to the traditional POD and the long short-term memory methods, particularly in continuous and extensive missing data. Moreover, the reconstructed temperature samples with assigned probabilities present complete probability information from the level of total probability. These results advance the probabilistic methods in tackling long-term temperature history reconstruction.}
}
@article{QUARESIMIN20122290,
title = {Strategies for the assessment of nanocomposite mechanical properties},
journal = {Composites Part B: Engineering},
volume = {43},
number = {5},
pages = {2290-2297},
year = {2012},
issn = {1359-8368},
doi = {https://doi.org/10.1016/j.compositesb.2011.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1359836812000030},
author = {Marino Quaresimin and Marco Salviato and Michele Zappalorto},
keywords = {A. Nano-structures, B. Mechanical properties, B. Fracture toughness, Three-stage strategy (TSS)},
abstract = {The assessment of nanocomposite mechanical properties is a challenging task. Due to their hierarchical structure, which spans from nano to macro length-scales, a different way of thinking from traditional approaches is needed to account for the characteristic phenomena of each length-scale and bridge their effects from the smaller scale to the macroscale. In the present work, some important issues of nanocomposite modelling are discussed. Then, a classification of the available modelling strategies is proposed, according to the scale from which the problem is addressed. This comprehensive analysis is thought as a necessary tool for the development of new effective approaches.}
}
@article{WESTERBERG2004447,
title = {A retrospective on design and process synthesis},
journal = {Computers & Chemical Engineering},
volume = {28},
number = {4},
pages = {447-458},
year = {2004},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2003.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0098135403002564},
author = {Arthur W Westerberg},
keywords = {Design, Process, Synthesis},
abstract = {We discuss the impact over the past 40 years of process systems thinking on the design of chemical processes. We first explore the rich set of issues related to process design, only some of which are technical. We then briefly examine simulation, optimization and more extensively process synthesis ideas as they relate to design. Throughout we note that this progress is inextricably linked with the development of computer technology.}
}
@article{YAMANE2021102520,
title = {Humor meets morality: Joke generation based on moral judgement},
journal = {Information Processing & Management},
volume = {58},
number = {3},
pages = {102520},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102520},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321000297},
author = {Hiroaki Yamane and Yusuke Mori and Tatsuya Harada},
keywords = {Computational humor, Morality, Recurrent neural networks, Joke generation},
abstract = {Although humor enriches human lives, some jokes fail to amuse people because of a lack of morality. In this paper, we propose a mechanism capable of selecting humor based on moral criteria. To this end, we first construct a model based on an N-gram corpus and generate joke candidates using various template patterns. We then employ a moral judgement classifier based on a recurrent neural network and utilize the trained model for humor selection. The experimental results obtained from best–worst scaling demonstrate that this scheme is able to generate jokes with moral category labels. We confirmed that jokes about the classifier categorized as Loyalty and Authority, which are regarded as good in our study, are funnier than jokes about Fairness, Purity, Harm, Cheating, and Degradation. Although we did not confirm that there was a difference in the funny level between good and bad moral jokes, the results demonstrate that moral categories of humor can affect the funny level.}
}
@article{DEMURO20241,
title = {Artificial intelligence and the ethnographic encounter: Transhuman language ontologies, or what it means “to write like a human, think like a machine”},
journal = {Language & Communication},
volume = {96},
pages = {1-12},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000119},
author = {Eugenia Demuro and Laura Gurney},
keywords = {Artificial intelligence, Language ontologies, Ethnographic encounter, Transhumanism, Posthumanism},
abstract = {In this paper, we employ the language ontologies framework to artificial intelligence (specifically, OpenAI's ChatGPT) to investigate the ‘ethnographic encounter’ between human and non-human language users. Our focus is on the exchange and interplay between human language users and non-human artificial language generators in the production of written text. We analyse how such programs transform our understanding of what language is or might be; their practices to create language are unfamiliar, and yet they make sense to human interlocutors. Drawing from, and building on, the language ontologies framework, we discuss the practices involved in such encounters and suggest the need for an updated ‘toolkit’ in our understanding of language to account for transhuman interactions.}
}
@article{HU2018275,
title = {Can a machine have two systems for recognition, like human beings?},
journal = {Journal of Visual Communication and Image Representation},
volume = {56},
pages = {275-286},
year = {2018},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2018.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1047320318302232},
author = {Jiwei Hu and Kin-Man Lam and Ping Lou and Quan Liu and Wupeng Deng},
keywords = {Image annotation, Multi-labeling, Hierarchical tree structure, Feature-pool selection},
abstract = {Artificial Intelligence has attracted much of researchers’ attention in recent years. A question we always ask is: “Can machines replace human beings to some extent?” This paper aims to explore the knowledge learning for an image-annotation framework, which is an easy task for humans but a tough task for machines. This paper’s research is based on an assumption that machines have two systems of thinking, each of which handles the labels of images at different abstract levels. Based on this, a new hierarchical model for image annotation is introduced. We explore not only the relationships between the labels and the features used, but also the relationships between labels. More specifically, we divide labels into several hierarchies for efficient and accurate labeling, which are constructed using our Associative Memory Sharing method, proposed in this paper.}
}
@article{ZHANG20162579,
title = {Efficient vehicles path planning algorithm based on taxi GPS big data},
journal = {Optik},
volume = {127},
number = {5},
pages = {2579-2585},
year = {2016},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2015.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0030402615019075},
author = {Jindong Zhang and Weibin Meng and QiangQiang Liu and Haofeng Jiang and Yujie Feng and Gang Wang},
keywords = {Taxi GPS trajectory, Big data, Driving stratagem, Map matching, Optimal path},
abstract = {The driving thinking of taxi drivers is always hidden in a large amount of taxis GPS data. An efficient driving stratagem derived from taxi drivers is provided for private car drivers. The five million pieces of taxis GPS data in Nanjing, China are analyzed: firstly, the data preprocessing is conducted for the reduction measuring error of GPS data with the expurgation of the static point, the drifting point, and the relatively independent point; then, the road intersections through the regional extreme points are found to restore map with the following three algorithms: the path selection algorithm based on probability, the improved Prim path selection algorithm, and the improved Prim path selection algorithm based on probability; at last, the SPFA (Shortest Path Faster Algorithm) is applied to the measurement of the road map gained from the previous three algorithms for optimal path planning with 40 pairs of starting points and termination points, and making a comparison of the road length among three methods. Through the experimental comparison, the third method namely the improved Prim path selection algorithm based on probability which proved to be more optimal than others two methods produces an efficient driving route more accurately.}
}
@incollection{CORICELLI2009427,
title = {Chapter 20 - Reward-based emotions: affective evaluation of outcomes and regret learning},
editor = {Jean-Claude Dreher and Léon Tremblay},
booktitle = {Handbook of Reward and Decision Making},
publisher = {Academic Press},
address = {New York},
pages = {427-439},
year = {2009},
isbn = {978-0-12-374620-7},
doi = {https://doi.org/10.1016/B978-0-12-374620-7.00020-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123746207000200},
author = {Giorgio Coricelli and Aldo Rustichini},
abstract = {Publisher Summary
The emotions related to experiencing rewards or punishers are not independent from the outcomes that have not occurred. Indeed, it is the counterfactual reasoning between the obtained and unobtained outcomes that determines the quality and intensity of the emotional response. This chapter concerns the behavioral effects and the neural substrates of a class of reward-based emotions, which are emotions elicited by rewards and punishers. It describes how outcome evaluation is influenced by the level of responsibility in the process of choice (agency) and by the available information regarding alternative outcomes. The data reported in the chapter suggests that cognitive context, exemplified by counterfactual thinking exerts a modulatory influence on the orbitofrontal cortex activation to rewards and punishers. The orbitofrontal cortex is also critically involved in learning in environments where the information about the rewards of the alternative foregone actions is available. These processes are addressed in humans, both in the context of normal and altered brain functions.}
}
@incollection{BARBER20251,
title = {Cultural contributions to cognitive aging},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {1-16},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00042-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801000425},
author = {Nicolette Barber and Ioannis Valoumas and Chaipat Chunharas and Sirawaj Itthipuripat and Angela Gutchess},
keywords = {Aging, Attention, Autobiographical memory, Cognition, Cognitive aging, Cognitive neuroscience, Cross-cultural, Culture, Long-term memory, Memory},
abstract = {In this article, we review research on the influences of culture on cognitive aging, with a focus on long-term memory and attention. Given the small number of studies directly investigating cognitive aging across cultures, we draw on existing cross-cultural studies comparing brain and behavior in young adult samples. We outline the potential for future research and discuss the importance of adopting a cross-cultural lens to support cognition and well-being in older adults in diverse cultural contexts.}
}
@incollection{STANOVICH2008251,
title = {The Development of Rational Thought: A Taxonomy of Heuristics and Biases},
editor = {Robert V. Kail},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {36},
pages = {251-285},
year = {2008},
booktitle = {Advances in Child Development and Behavior},
issn = {0065-2407},
doi = {https://doi.org/10.1016/S0065-2407(08)00006-2},
url = {https://www.sciencedirect.com/science/article/pii/S0065240708000062},
author = {Keith E. Stanovich and Maggie E. Toplak and Richard F. West},
abstract = {Publisher Summary
The most well-known indicators of cognitive functioning—intelligence and cognitive ability tests—do not assess a critical aspect of thinking, which is the ability to think rationally. To think rationally means adopting appropriate goals, taking the appropriate action given one's goals and beliefs, and holding beliefs that are commensurate with available evidence. Standard intelligence tests do not assess such functions. Although intelligence tests assess the ability to focus on an immediate goal in the face of distraction, they do not assess whether a person has the tendency to develop goals that are rational in the first place. Likewise, intelligence tests are good measures of how well a person can hold beliefs in short-term memory and manipulate those beliefs, but they do not assess whether a person has the tendency to form beliefs rationally when presented with evidence. Similarly, intelligence tests are good measures of how efficiently a person processes information that has been provided, but they do not assess whether the person is a critical assessor of information as it is gathered in the natural environment.}
}
@article{MOFIDI2020110192,
title = {Intelligent buildings: An overview},
journal = {Energy and Buildings},
volume = {223},
pages = {110192},
year = {2020},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110192},
url = {https://www.sciencedirect.com/science/article/pii/S0378778819338289},
author = {Farhad Mofidi and Hashem Akbari},
keywords = {Intelligent building, Comfort, Energy conservation, Integrated control, Optimization, Productivity, Behavior modeling, Building simulation},
abstract = {The objective of this paper is to review the topics related to the optimized operation of intelligent buildings with respect to occupant comfort and energy consumption. To simultaneously optimize energy costs and indoor environmental quality, intelligent buildings should consider several continuously changing inputs including energy exchange processes across the building, sets of indoor and outdoor environmental parameters, energy prices, occupants’ presence, preferences, and behavior inside the building. Therefore, a well-structured framework supported by computational intelligence and optimization methods, environmental monitoring, and behavior modeling techniques, as well as comfort, productivity, and behavioral studies, are required to make optimal decisions for the indoor environment. In this paper, the main concepts, challenges, the latest studies, findings, and developments related to the six topics of (1) Occupant comfort conditions; (2) Occupant productivity; (3) Building control; (4) Computational optimization; (5) Occupant behavior modeling; (6) Environmental monitoring and analysis, in offices, commercial and residential buildings are reviewed. Moreover, future directions and challenges related to the optimized operation of intelligent buildings are discussed.}
}
@article{JOHNSON2023104327,
title = {Why is biomedical informatics hard? A fundamental framework},
journal = {Journal of Biomedical Informatics},
volume = {140},
pages = {104327},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104327},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423000485},
author = {Todd R. Johnson and Elmer V. Bernstam},
keywords = {Biomedical informatics, Scientific discipline, Data, Information, Knowledge, Definition, Philosophy of information},
abstract = {Building on previous work to define the scientific discipline of biomedical informatics, we present a framework that categorizes fundamental challenges into groups based on data, information, and knowledge, along with the transitions between these levels. We define each level and argue that the framework provides a basis for separating informatics problems from non-informatics problems, identifying fundamental challenges in biomedical informatics, and provides guidance regarding the search for general, reusable solutions to informatics problems. We distinguish between processing data (symbols) and processing meaning. Computational systems, that are the basis for modern information technology (IT), process data. In contrast, many important challenges in biomedicine, such as providing clinical decision support, require processing meaning, not data. Biomedical informatics is hard because of the fundamental mismatch between many biomedical problems and the capabilities of current technology.}
}
@article{RAMIREZPEDRAZA2021122,
title = {Decision-making bioinspired model for target definition and “satisfactor” selection for physiological needs},
journal = {Cognitive Systems Research},
volume = {66},
pages = {122-133},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300942},
author = {Raymundo Ramirez-Pedraza and Felix Ramos},
keywords = {Decision-making, Brain model, Satisfactor selection, Physiological need, Goal-driven},
abstract = {Every person, from an early age, has to make decisions to resolve situations that arise in life. In general, different people make different decisions in the same situation, since decision-making takes into account different factors such as age, emotional state, experience, among others. We can make decisions about situations that we classify as: more important than others, routine, unexpected, or trivial. However, making the correct decision(s) in a timely manner for these situations is one of the most complex and delicate challenges that human beings face. This is due to the arduous mental process required to be carried out. Providing such behavior to a virtual entity is possible through the use of Cognitive Architectures (CAs). CAs are an approach for modeling human intelligence and behavior. This paper presents an functional bioinspired computational decision-making model to satisfy the physiological needs of hunger and thirst. Our proposal considers as black boxes other cognitive functions that are part of a general CA (named Cuäyöllötl or brain in Nahuatl). In the proposed case study, it is proved that the decision-making process plays an essential role in determining the objective and selecting the object that satisfies the established need.}
}
@article{ABDULLAH2024100212,
title = {Recent development of combined heat transfer performance for engine systems: A comprehensive review},
journal = {Results in Surfaces and Interfaces},
volume = {15},
pages = {100212},
year = {2024},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2024.100212},
url = {https://www.sciencedirect.com/science/article/pii/S2666845924000321},
author = {Md. Abdullah and Mohammad {Zoynal Abedin}},
keywords = {Combined heat transfer, Performance, Engine system, Enhancement},
abstract = {Heat transfer regulation between engine components has a direct impact on engine efficiency and performance. Improving engine system efficiency, reducing emissions, and prolonging component life all depend on efficient heat management. This review looks at recent advancements in integrated heat transfer optimization to boost efficiency, reduce emissions, and improve engine system performance. This effort also investigates producing intricate heat transfer components with improved geometry using additive manufacturing techniques. With additive printing, designers may more easily construct complex structures and optimize heat transfer surfaces for better performance. The development of nanofluids and nanocoatings now allows for improving heat transfer qualities. Nanotechnology advancements have made this possible, and nanostructured materials' enhanced surface properties as well as thermal conductivity contribute to better heat dissipation in engine systems. The modern automotive and aerospace sectors have high standards, which are met through novel designs, materials, computational tools, and integrated cooling systems. Additionally, these improvements pave the way for more efficient and environmentally friendly engine operation. Because of the integration of computational technologies like numerical modeling and CFD, engineers can now see complex heat flow patterns and construct more efficient cooling solutions. Additive manufacturing has changed component manufacturing by enabling sophisticated designs that maximize heat transfer surfaces.}
}
@article{DIETRICH2008319,
title = {Imaging the imagination: The trouble with motor imagery},
journal = {Methods},
volume = {45},
number = {4},
pages = {319-324},
year = {2008},
note = {Neuroimaging in the sports sciences},
issn = {1046-2023},
doi = {https://doi.org/10.1016/j.ymeth.2008.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1046202308000765},
author = {Arne Dietrich},
keywords = {Brain, Cortex, Exercise, Explicit, Hypofrontality, Implicit, Mental training, Neuroimaging, Sports, Imagery},
abstract = {Sports and exercise psychology finds itself in a most unfortunate situation these days. While all other branches of the psychological sciences help themselves freely to the glitzy new toys of modern neuroscience—MRI and PET, mostly—exploring the neural underpinnings of whatever cognitive function they are interested in exploring, the sport sciences are left out of the fun for the simple reason that these imaging instruments preclude motion—the very thing then that is the subject of interest to them. There are several legitimate ways around this problem but the one that seems to be most popular is, I think, not—legitimate, that is. The basic idea, unduly sharpened here, is the following. Neuroimaging studies have shown that imagined and actual motion share the same neural substrates or, alternatively, imagining an action corresponds to a subliminal activation of the same brain areas required for its execution. It follows from this, the arguments runs, that motor imagery can be used as a proxy for real motor performance, et voilà, the sports sciences can go wild with all the snazzy brain imaging tools after all—just like everyone else. This notion is, I believe, misbegotten, a house of cards that threatens to cast a long shadow over the field. The present article, then, is, to be frank, intended to put a machete to this kind of thinking. It does this by exposing this conclusion to be based on an unholy marriage of selective data reporting and gross overgeneralization. The result is a wild goose chase fueled by wishful thinking.}
}
@article{BOUKHRIS201727,
title = {Co-creation in the Early Stage of Product-service System Development},
journal = {Procedia CIRP},
volume = {63},
pages = {27-32},
year = {2017},
note = {Manufacturing Systems 4.0 – Proceedings of the 50th CIRP Conference on Manufacturing Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2017.03.316},
url = {https://www.sciencedirect.com/science/article/pii/S2212827117305048},
author = {Aida Boukhris and Albrecht Fritzsche and Kathrin Möslein},
keywords = {Co-creation, product-service system, prototyping},
abstract = {Co-creation is a well-established topic in manufacturing research. Since 1999 there has been a wide range of publications about the involvement of customers in the design of end products. What is new, however, is the stakeholder, particularly user, integration at the early stage of development of product-service systems (PSS) for concept co-creation. In this paper, we evaluate the methods for PSS development at the fuzzy front-end, before we derive a co-creation oriented method that relies on prototyping at selected stages of the process. The first stage deals with the generation of a shared understanding of the concept to be developed, and in the second stage we converge towards the generation of the user requirements by employing a set of electronic tools to drive process and logic flow thinking within the group of co-creators. The methodology has been evaluated within three workshops involving 42 participants who were asked to design a decentralized bike-sharing system, where bike owners can generate revenues from their bikes by renting them out when not otherwise needed. In a future phase, the results will be compared to the outcomes of a workshop organized with a bike sharing company that is currently developing this model.}
}
@article{OLMEDO2015115,
title = {Quantitative characterization of chaordic tourist destination},
journal = {Tourism Management},
volume = {47},
pages = {115-126},
year = {2015},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2014.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0261517714001812},
author = {Elena Olmedo and Ruth Mateos},
keywords = {Complexity, Chaos, Chaordic system, Tourism Arrivals},
abstract = {This paper highlights the new horizons opening with the applications of concepts from the application of the complexity science to tourism data, which are traditionally treated from an intradisciplinar point of view. From this new point of view, tourism is considered as a complex adaptive system. Complexity theory is rooted in the hard sciences, and social sciences have adopted it in recent times. Going a step further, we introduce the concept of chaordic system in tourism. This new thinking has appeared in the social sciences as a response to the current need to cope with contradictions and inconsistencies, adapting evolution without losing essence. We propose considering tourism as a chaordic system and analyzing the resulting managerial consequences. We propose the use of a set of measures to quantify a system as chaordic. Finally, we empirically analyze tourist arrivals to Majorca (Spain) to verify the existence of a chaordic system.}
}
@incollection{GARDNER202451,
title = {Chapter 3 - Designing and prototyping smarter urban spaces},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {51-74},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00009-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000094},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Design education, Design pedagogy, Design process, Human-computer interaction, Interaction, Interaction design, IoT, Physical computing, Prototyping, Smart city, Urban technology},
abstract = {This chapter outlines how the concept of the smart city is explored and challenged in an undergraduate design course that adopts a cross-scale framework to design and prototype urban technology projects. It sets out an integrated and interdisciplinary approach to urban technology design that combines context-oriented spatial design methods with physical computing and interaction principles. It construes the design and prototyping of urban technology projects as sociotechnical thought experiments that can materialize ethical concerns and explore alternate ways that urban life can be lived with technology. The chapter concludes by outlining the themes that organize selected existing and speculative urban technology projects in the following chapters of the book.}
}
@article{CORTENBACH2024104869,
title = {The Dial-a-Ride problem with meeting points: A problem formulation for shared demand–responsive transit},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {169},
pages = {104869},
year = {2024},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2024.104869},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X24003905},
author = {L.E. Cortenbach and K. Gkiotsalitis and E.C. {van Berkum} and E. Walraven},
keywords = {Dial-a-Ride problem, Meeting points, Demand–responsive transit, Tabu search},
abstract = {In this paper, a formulation for the Dial-a-Ride Problem with Meeting Points (DARPmp) is introduced. The problem consists of defining routes that satisfy trip requests between pick-up and drop-off points while complying with time window, ride time, vehicle load, and route duration constraints. A set of meeting points is defined, and passengers may be asked to use these meeting points as alternative pickup or drop-off points if this results in routes with lower costs. Incorporating meeting points into the DARP is achieved by formulating a mixed-integer linear program. Two preprocessing steps and three valid inequalities are introduced, which improve the computational performance when solving the DARPmp to global optimality. Two versions of the Tabu Search metaheuristic are proposed to approximate the optimal solution in large-scale networks due to the NP-hardness of DARPmp. Performing numerical experiments with benchmark instances, this study demonstrates the benefits of DARPmp compared to DARP in terms of reducing vehicle running costs.}
}
@article{2016940,
title = {Anne Churchland},
journal = {Neuron},
volume = {92},
number = {5},
pages = {940-942},
year = {2016},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2016.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0896627316308662},
abstract = {Anne Churchland’s scientific experience has focused on understanding the neural circuits behind multisensory decision making. In an interview with Neuron, she discusses large-scale recordings in behaving animals, communication between experimental and theoretical labs, and the creation of her website anneslist.net to highlight women in systems and computational neuroscience in an effort to help close the gender gap in conference speakers.}
}
@article{ABDELHAMID2022101673,
title = {Discovering epistasis interactions in Alzheimer's disease using deep learning model},
journal = {Gene Reports},
volume = {29},
pages = {101673},
year = {2022},
issn = {2452-0144},
doi = {https://doi.org/10.1016/j.genrep.2022.101673},
url = {https://www.sciencedirect.com/science/article/pii/S2452014422001819},
author = {Marwa M. {Abd El Hamid} and Yasser M.K. Omar and Mohamed Shaheen and Mai S. Mabrouk},
keywords = {Alzheimer's disease, Epistasis interactions, Personalized medicine, Deep learning model, SHAP},
abstract = {Alzheimer's disease (AD) is the most common form of dementia. Single Nucleotide Polymorphisms (SNPs) are single nucleotide alterations that can be used as genomic markers disclosing susceptibility to complex diseases like AD. Epistasis has long been significant for recognizing the function of genetic pathways and the evolutionary dynamics of difficult genetic systems. Discovering epistasis interactions holds a vital key to personalized medicine (PM). PM needs a better understanding of the relationship between human genetic data and complex diseases. In this proposed work, a deep neural network (DNN) is applied using SHapley Additive exPlanations (SHAP) to get top 20, 100, 300, and 500 ranking SNPs responsible for AD risk through epistasis interactions. Multi-locus interaction analysis is performed on these identified SNPs using Multifactor Dimensionality Reduction (MDR). This constructive induction algorithm is integrated with DNN for discovering epistasis interactions in a computationally effective method. The proposed framework is applied to Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. The best accuracies are achieved using the top 500 SNPs, and the classification accuracies varied between 0.860 and 0.874 in the five-way interaction model. However, the classification accuracies of 2-way, 3-way, 4-way models varied between 0.663 and 0.670, 0.718 and 0.727, and 0.793 and 0.803, respectively. The results revealed that the reported accuracy scores of the proposed framework outperform the referenced literature work. The proposed framework presents high-ranked risk genes and promising epistasis interactions that may help in explaining the risk of AD.}
}
@article{BUSE2022396,
title = {Asynchronous Background Processing for accelerated simulation of wireless communication on multi-core systems},
journal = {Computer Communications},
volume = {193},
pages = {396-409},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2022.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0140366422002791},
author = {Dominik S. Buse and Georg Echterling and Falko Dressler},
keywords = {Parallel simulation, Wireless network simulation, Asynchronous parallelization, Vehicular networking},
abstract = {Discrete event simulation (DES) is an important tool for the development and analysis of wireless networks. However, with increasing network size and complexity, the computational effort and simulation time increases significantly, often exponentially. This increase in response time may be critical if DES is interfacing real-time systems like Hardware in the Loop (HIL) or network emulation. It also slows down development cycles of users designing or debugging simulation models. Most popular DES software packages run single-threaded. Thus, they achieve only limited performance improvements from more modern multi-core CPUs. At the same time, existing approaches for parallel simulation of networks do not perform well on wireless systems or require complex paradigm shifts in simulation models. In this paper, we propose Asynchronous Background Processing (ABP) to accelerate the simulation of wireless communication on multi-core systems. By moving expensive computation from the main thread into asynchronous tasks computed by background threads, it accelerates the progression of events and thus reduces response time. Tasks are started as early as possible to exploit the time the main thread spends processing other events, ideally providing results before they are needed in the simulation. We showcase the application of ABP using Veins, a popular vehicular network simulator, demonstrating speedups of up to 3.5 on typical desktop platforms. We further perform an in-depth analysis using advanced profiling techniques to investigate the effectiveness of the parallelization and guide further optimizations.}
}
@article{CAI2021106,
title = {The Neural Instantiation of an Abstract Cognitive Map for Economic Choice},
journal = {Neuroscience},
volume = {477},
pages = {106-114},
year = {2021},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2021.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0306452221004784},
author = {Xinying Cai},
keywords = {cognitive map, economic choice, orbitofrontal cortex, subjective value},
abstract = {Since the discovery of cognitive maps in rodent hippocampus (HC), the cognitive map has evolved from originally referring to spatial representations encoding locations and objects in Euclidean spaces to a general low-dimensional organization of information along selected feature dimensions. A cognitive map includes hypothetical constructs that bridge between environmental stimuli and the final overt behavior. To neuroeconomists, utility and utility functions are such constructs with neurobiological basis that drive choice behavior. Emergence of distinct functional neuron groups in the primate orbitofrontal cortex (OFC) during simple economic choice indicates the formation of an abstract cognitive map for organizing information of goods for value computation. Experimental evidence suggests that organization of neuronal activity in such cognitive map reflects the abstraction of core task features. Thus, such map can be adapted to accommodate economic choices under various task contexts.}
}
@article{2024100678,
title = {Erratum regarding missing Declaration of Competing Interest statements in previously published articles},
journal = {International Journal of Child-Computer Interaction},
volume = {41},
pages = {100678},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100678},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000473}
}
@article{WINSTON201292,
title = {The next 50years: A personal view},
journal = {Biologically Inspired Cognitive Architectures},
volume = {1},
pages = {92-99},
year = {2012},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2012.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X12000035},
author = {Patrick Henry Winston},
keywords = {Biologically inspired cognitive models, Human intelligence, Evolution of intelligence, Inner language, Story understanding, Directed perception},
abstract = {I review history, starting with Turing’s seminal paper, reaching back ultimately to when our species started to outperform other primates, searching for the questions that will help us develop a computational account of human intelligence. I answer that the right questions are: What’s different between us and the other primates and what’s the same. I answer the what’s different question by saying that we became symbolic in a way that enabled story understanding, directed perception, and easy communication, and other species did not. I argue against Turing’s reasoning-centered suggestions, offering that reasoning is just a special case of story understanding. I answer the what’s the same question by noting that our brains are largely engineered in the same exotic way, with information flowing in all directions at once. By way of example, I illustrate how these answers can influence a research program, describing the Genesis system, a system that works with short summaries of stories, provided in English, together with low-level common-sense rules and higher-level concept patterns, likewise expressed in English. Genesis answers questions, notes abstract concepts such as revenge, tells stories in a listener-aware way, and fills in story gaps using precedents. I conclude by suggesting, optimistically, that a genuine computational theory of human intelligence will emerge in the next 50years if we stick to the right, biologically inspired questions, and work toward biologically informed models.}
}
@incollection{VODOVOTZ20153,
title = {Chapter 1.1 - Interesting Times: The Translational Dilemma and the Need for Translational Systems Biology of Inflammation},
editor = {Yoram Vodovotz and Gary An},
booktitle = {Translational Systems Biology},
publisher = {Academic Press},
address = {Boston},
pages = {3-8},
year = {2015},
isbn = {978-0-12-397884-4},
doi = {https://doi.org/10.1016/B978-0-12-397884-4.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012397884400001X},
author = {Yoram Vodovotz and Gary An},
keywords = {Inflammation, translational research, Translational Dilemma, Translational Systems Biology, computational modeling},
abstract = {Inflammation and critical illness are the final common pathway for many diseases, many of them terminal, and for which there are essentially no medicines. We suggest that this failing is symptomatic of a fragmented continuum of health care and biomedical research, with the primary issue being the inability to translate basic science research into treatments effectively and efficiently, termed the Translational Dilemma. We assert that this present, sad state is due to numerous deficiencies in the way biomedical research is carried out. Accentuating the problem is the fact that the Translational Dilemma is most pronounced with respect to diseases, such as critical illness, that manifest features of so-called complex systems. To address these problems and thereby help alleviate the Translational Dilemma, we have used computational modeling with an explicitly applied focus on generating clinically actionable knowledge. We call this approach Translational Systems Biology. This investigative strategy is predicated on the use of dynamic computational modeling and associated computational methods of data analysis and aggregation to accelerate the Scientific Cycle with an explicit target of generating clinically actionable knowledge.}
}
@article{WOLTHUSEN2018178,
title = {Correlation Between Levels of Delusional Beliefs and Perfusion of the Hippocampus and an Associated Network in a Non–Help-Seeking Population},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {3},
number = {2},
pages = {178-186},
year = {2018},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2451902217301180},
author = {Rick P.F. Wolthusen and Garth Coombs and Emily A. Boeke and Stefan Ehrlich and Stephanie N. DeCross and Shahin Nasr and Daphne J. Holt},
keywords = {Arterial spin labeling, Delusion, fMRI, Hippocampus, Perfusion, Psychosis},
abstract = {Background
Delusions are a defining and common symptom of psychotic disorders. Recent evidence suggests that subclinical and clinical delusions may represent distinct stages on a phenomenological and biological continuum. However, few studies have tested whether subclinical psychotic experiences are associated with neural changes that are similar to those observed in clinical psychosis. For example, it is unclear if overactivity of the hippocampus, a replicated finding of neuroimaging studies of schizophrenia, is also present in individuals with subclinical psychotic symptoms.
Methods
To investigate this question, structural and pulsed arterial spin labeling scans were collected in 77 adult participants with no psychiatric history. An anatomical region of interest approach was used to extract resting perfusion of the hippocampus, and 15 other regions, from each individual. A self-report measure of delusional ideation was collected on the day of scanning.
Results
The level of delusional thinking (number of beliefs [r = .27, p = .02]), as well as the associated level of distress (r = .29, p = .02), was significantly correlated with hippocampal perfusion (averaged over right and left hemispheres). The correlations remained significant after controlling for age, hippocampal volume, symptoms of depression and anxiety, and image signal-to-noise ratio, and they were confirmed in a voxelwise regression analysis. The same association was observed in the thalamus and parahippocampal, lateral temporal, and cingulate cortices.
Conclusions
Similar to patients with schizophrenia, non–help-seeking individuals show elevated perfusion of a network of limbic regions in association with delusional beliefs.}
}
@article{COLOMBO2016291,
title = {Analysing the connectivity and communication of suicidal users on twitter},
journal = {Computer Communications},
volume = {73},
pages = {291-300},
year = {2016},
note = {Online Social Networks},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2015.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S014036641500256X},
author = {Gualtiero B. Colombo and Pete Burnap and Andrei Hodorog and Jonathan Scourfield},
keywords = {Social media, Social network analysis, Twitter, Computational social science, Suicide},
abstract = {In this paper we aim to understand the connectivity and communication characteristics of Twitter users who post content subsequently classified by human annotators as containing possible suicidal intent or thinking, commonly referred to as suicidal ideation. We achieve this understanding by analysing the characteristics of their social networks. Starting from a set of human annotated Tweets we retrieved the authors’ followers and friends lists, and identified users who retweeted the suicidal content. We subsequently built the social network graphs. Our results show a high degree of reciprocal connectivity between the authors of suicidal content when compared to other studies of Twitter users, suggesting a tightly-coupled virtual community. In addition, an analysis of the retweet graph has identified bridge nodes and hub nodes connecting users posting suicidal ideation with users who were not, thus suggesting a potential for information cascade and risk of a possible contagion effect. This is particularly emphasised by considering the combined graph merging friendship and retweeting links.}
}
@article{CAVEDON201514,
title = {“C׳Mon dude!”: Users adapt their behaviour to a robotic agent with an attention model},
journal = {International Journal of Human-Computer Studies},
volume = {80},
pages = {14-23},
year = {2015},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S1071581915000452},
author = {Lawrence Cavedon and Christian Kroos and Damith Herath and Denis Burnham and Laura Bishop and Yvonne Leung and Catherine J. Stevens},
keywords = {Human–robot interaction, Attention model, Social interaction, Evaluation, Engagement},
abstract = {Social cues facilitate engagement between interaction participants, whether they be two (or more) humans or a human and an artificial agent such as a robot. Previous work specific to human–agent/robot interaction has demonstrated the efficacy of implemented social behaviours, such as eye-gaze or facial gestures, for demonstrating the illusion of engagement and positively impacting interaction with a human. We describe the implementation of THAMBS, The Thinking Head Attention Model and Behavioural System, which is used to model attention controlling how a virtual agent reacts to external audio and visual stimuli within the context of an interaction with a human user. We evaluate the efficacy of THAMBS for a virtual agent mounted on a robotic platform in a controlled experimental setting, and collect both task- and behavioural-performance variables, along with self-reported ratings of engagement. Our results show that human subjects noticeably engaged more often, and in more interesting ways, with the robotic agent when THAMBS was activated, indicating that even a rudimentary display of attention by the robot elicits significantly increased attention by the human. Back-channelling had less of an effect on user behaviour. THAMBS and back-channelling did not interact and neither had an effect on self-report ratings. Our results concerning THAMBS hold implications for the design of successful human–robot interactive behaviours.}
}
@article{VIDES202258,
title = {A Subspace Method for Time Series Anomaly Detection in Cyber-Physical Systems},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {41},
pages = {58-63},
year = {2022},
note = {4th IFAC Workshop on Cyber-Physical and Human Systems CPHS 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.01.103},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323001106},
author = {Fredy Vides and Esteban Segura and Carlos Vargas-Agüero},
keywords = {Anomaly detection, Hankel matrix, time series analysis, sensors, signals},
abstract = {Time series anomaly detection is an important process for system monitoring and model switching, among other applications in cyber-physical systems. In this document we present a fast subspace method for time series anomaly detection, with a relatively low computational cost, that has been designed for anomaly detection in real sensor signals corresponding to dynamical systems. We also present some general results corresponding to the theoretical foundations of our method, together with a prototypical algorithm for time series anomaly detection. Some numerical examples corresponding to applications of the prototypical algorithm are presented, and some computational tools based on the theory and algorithms presented in this paper, are provided.}
}
@incollection{VANDERFORD2017105,
title = {Chapter 10 - Transferable Skills: How to Describe What You Really Know},
editor = {Teresa M. Evans and Natalie Lundsteen and Nathan L. Vanderford},
booktitle = {ReSearch},
publisher = {Academic Press},
pages = {105-118},
year = {2017},
isbn = {978-0-12-804297-7},
doi = {https://doi.org/10.1016/B978-0-12-804297-7.00010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042977000100},
author = {Nathan L. Vanderford},
keywords = {Alternative careers, Biomedical science, Career path, Communicating skills, Graduate student, Job market, Life science, Nontraditional career, PhD, Postdoc, Self-assessment, Transferable skills},
abstract = {Think beyond your label—years of academic life have pushed you to fine-tune a statement regarding your research interests that is short and to the point. It often starts with “I am a doctoral student in…” To hone your transferable skills, or the skills that are valued in research as well as other career areas, you have to break away from thinking about yourself in those terms. Prove that you can do the job even when you do not have direct job experience—you will do this by learning to think broadly and comprehensively about your transferable skills. Know how to identify your transferable skills. For everything that you have achieved in your life, there is an accompanying set of skills that will add value to you as a job applicant. Know how to describe them. Know how to portray your transferable skills in industry terms. There are phrases that resonate with key industries and organizations in their search for new recruits. Identify the correct terms to be understood in your chosen career field.}
}
@article{LEE2024101413,
title = {Cognitive flexibility training for impact in real-world settings},
journal = {Current Opinion in Behavioral Sciences},
volume = {59},
pages = {101413},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101413},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624000640},
author = {Liz Y Lee and Máiréad P Healy and Nastassja L Fischer and Ke Tong and Annabel SH Chen and Barbara J Sahakian and Zoe Kourtzi},
abstract = {Interacting with complex and dynamic environments challenges the brain’s ability to adapt to change. This key ability known as cognitive flexibility involves learning the structure of the environment, switching attention between features, dimensions and tasks, and adopting new rules in the face of uncertainty. Training cognitive flexibility has strong potential to improve adaptive behavior across the lifespan with impact in real-world settings (e.g. educational, clinical). Here, we review evidence on the role of cognitive training in improving executive functions and the factors that may enhance the effectiveness of training programs. We propose that personalized and adaptive training programs that focus on the multifaceted abilities comprising cognitive flexibility are key for promoting adaptive behavior and lifelong learning in real-world settings.}
}
@article{NABORS2003133,
title = {From fractions to proportional reasoning: a cognitive schemes of operation approach},
journal = {The Journal of Mathematical Behavior},
volume = {22},
number = {2},
pages = {133-179},
year = {2003},
note = {Fractions, ratio and proportional reasoning, Part A},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(03)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S073231230300018X},
author = {Wanda K Nabors},
keywords = {Fractions, Proportional reasoning, Teaching experiment, Cognitive schemes},
abstract = {Four seventh grade students participated in a constructivist teaching experiment in which manipulatives within a computer microworld were used to solve fractional reasoning tasks followed by tasks that involve concepts of rate, ratio and proportion. Through a retrospective analysis of video tapes, their thinking processes were analyzed from the perspective of the types of cognitive schemes of operation used as they engaged in the given problem situations. One result of the study indicates that the modifications of the students’ available schemes of operation when solving the fractional reasoning tasks formed a basis for the cognitive schemes of operation used in their solutions of tasks involving proportionality.}
}
@article{20214105,
title = {Introducing new group leaders: Lorenzo Calviello},
journal = {Molecular Cell},
volume = {81},
number = {20},
pages = {4105-4108},
year = {2021},
issn = {1097-2765},
doi = {https://doi.org/10.1016/j.molcel.2021.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S1097276521007334},
abstract = {Lorenzo Calviello tells us about his return to Milan, Italy, to set up his lab, which aims to untangle the complex life of mRNA using a mix of computational and experimental approaches; the kind of environment he hopes to promote as part of a wider scientific culture; and the importance of heavy metal and affordable education.}
}
@article{SCHACTER2012677,
title = {The Future of Memory: Remembering, Imagining, and the Brain},
journal = {Neuron},
volume = {76},
number = {4},
pages = {677-694},
year = {2012},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2012.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0896627312009919},
author = {Daniel L. Schacter and Donna Rose Addis and Demis Hassabis and Victoria C. Martin and R. Nathan Spreng and Karl K. Szpunar},
abstract = {During the past few years, there has been a dramatic increase in research examining the role of memory in imagination and future thinking. This work has revealed striking similarities between remembering the past and imagining or simulating the future, including the finding that a common brain network underlies both memory and imagination. Here, we discuss a number of key points that have emerged during recent years, focusing in particular on the importance of distinguishing between temporal and nontemporal factors in analyses of memory and imagination, the nature of differences between remembering the past and imagining the future, the identification of component processes that comprise the default network supporting memory-based simulations, and the finding that this network can couple flexibly with other networks to support complex goal-directed simulations. This growing area of research has broadened our conception of memory by highlighting the many ways in which memory supports adaptive functioning.}
}
@article{KIRGIL2022101668,
title = {“Do your part: Stay apart”: Collective intentionality and collective (in)action in US governor's COVID-19 press conferences},
journal = {Poetics},
volume = {93},
pages = {101668},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101668},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22000304},
author = {Z.M. Kirgil and A. Voyer},
keywords = {Collective intentionality, Leadership, Democrat, Republican, COVID-19},
abstract = {This mixed-methods study examines how political leaders mobilize collective intentionality during the COVID-19 pandemic in nine US States, and how collective intentionality differs across republican and democratic administrations. The results of our computational and qualitative analyses show that i) political leaders establish collective intentionality by emphasizing unity, vulnerability, action, and community boundaries; ii) political leaders’ call to collective action clashes with the inaction required by health guidelines; iii) social inequalities received little attention across all states compared to other themes; and iv) collective intentionality in democratic administrations is linked to individuals’ agency and actions, suggesting a bottom-up approach. Conversely, in republican administrations individuals’ contributions are downplayed compared to work and state-level action, indicating a top-down approach. This study demonstrates the theoretical and empirical value of collective intentionality in sociological research, and contributes to a better understanding of leadership and prosociality in times of crisis.}
}
@article{LEON2009539,
title = {The future of computer-aided innovation},
journal = {Computers in Industry},
volume = {60},
number = {8},
pages = {539-550},
year = {2009},
note = {Computer Aided Innovation},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2009.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0166361509001286},
author = {Noel Leon},
keywords = {Computer Aided Innovation, TRIZ, QFD},
abstract = {A new category of tools known as CAI (computer-aided innovation) is an emerging domain in the array of computer-aided technologies. CAI has been growing as a response to greater industry demands for reliability in new products. Some initial CAI ideas and concepts focused on assisting product designers in the early stage of the design process, but now a more comprehensive vision conceives CAI systems as beginning at the fuzzy front end of perceiving business opportunities and customer demands, then continuing during the creative stage in developing inventions and, further on, providing help up to the point of turning inventions into successful innovations in the marketplace. CAI methods and tools are partially inspired by Innovation Theories, such as TRIZ, QFD (Quality Function Development), Axiomatic Design, Synectics, General Theory of Innovation, Mind Mapping, Brain Storming, Lateral Thinking, and Kansei Engineering, among others. The goal of these new CAI tools under development is to assist innovators, inventors, designers, process developers and managers in their creative performance, with the expectation of changes in paradigms through the use of this new category of software tools. CAI, therefore, stands out as a departure from the usual trends. The latest approaches are presented and analyzed to derive conclusions regarding the present status and the future of these emerging tools.}
}
@article{TOWERS201025,
title = {An ecological reading of mathematical language in a Grade 3 classroom: A case of learning and teaching measurement estimation},
journal = {The Journal of Mathematical Behavior},
volume = {29},
number = {1},
pages = {25-40},
year = {2010},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2009.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S073231230900056X},
author = {Jo Towers and Kim Hunter},
keywords = {Classroom mathematical language, Ecological thinking, Measurement, Estimation},
abstract = {In our work in teacher education and professional development, we aim to help teachers to learn to participate in, and create, classroom ecologies that support students’ learning. In this article we focus on the challenges of developing a classroom ecology that provides mathematical sustenance for students. We pay particular attention to the ways in which classroom language can impede the development of a classroom ecology—one where all students are heard and where knowing is understood as participatory. We present recommendations for teaching practice drawn from an ecological reading of the classroom discourse during a series of lessons on measurement in a Grade 3 classroom.}
}
@article{BARAK20171,
title = {Recurrent neural networks as versatile tools of neuroscience research},
journal = {Current Opinion in Neurobiology},
volume = {46},
pages = {1-6},
year = {2017},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2017.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438817300429},
author = {Omri Barak},
abstract = {Recurrent neural networks (RNNs) are a class of computational models that are often used as a tool to explain neurobiological phenomena, considering anatomical, electrophysiological and computational constraints. RNNs can either be designed to implement a certain dynamical principle, or they can be trained by input–output examples. Recently, there has been large progress in utilizing trained RNNs both for computational tasks, and as explanations of neural phenomena. I will review how combining trained RNNs with reverse engineering can provide an alternative framework for modeling in neuroscience, potentially serving as a powerful hypothesis generation tool. Despite the recent progress and potential benefits, there are many fundamental gaps towards a theory of these networks. I will discuss these challenges and possible methods to attack them.}
}
@article{HEIKKURINEN20181654,
title = {Degrowth by means of technology? A treatise for an ethos of releasement},
journal = {Journal of Cleaner Production},
volume = {197},
pages = {1654-1665},
year = {2018},
note = {Technology and Degrowth},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2016.07.070},
url = {https://www.sciencedirect.com/science/article/pii/S0959652616309593},
author = {Pasi Heikkurinen},
keywords = {Degrowth, Ethics, Practice, Releasement, Sustainability, Technology},
abstract = {The large-scale ecological damage caused by growth societies calls for economic degrowth in terms of a radical decrease in matter/energy throughput. This article examines the role of modern technology in degrowth with a focus on the question of agency and its ethical implications. After conceptualising technology as practice, the paper finds that while technological practice encompasses an agency for social change, it is restricted to transforming the non-human world to human-made objects. This is because in technological practice the world and its objects unfold as a standing-reserve for human use. Due to this calculative and anthropocentric thinking, technological practice does not and cannot support the emergence of a kind of agency that either does or can let things be. Moreover, the more technological the practice, the more objects are utilised. The paper concludes that technological practice does not support the transition to degrowth, because it directs its agents towards the continuous transformation of non-human-made objects into human-made objects resulting in an increase in cumulative throughput. The paper thus suggests that an ethos of releasement is needed to attain, as well as to live in, a degrowth society. The rationale provided for refraining from the technological practice in order to contribute to ecologically sensible social change is the chief contribution of this paper.}
}
@article{SOBEL20101060,
title = {Interactions between causal models, theories, and social cognitive development},
journal = {Neural Networks},
volume = {23},
number = {8},
pages = {1060-1071},
year = {2010},
note = {Social Cognition: From Babies to Robots},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2010.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608010001176},
author = {David M. Sobel and David W. Buchanan and Jesse Butterfield and Odest Chadwicke Jenkins},
keywords = {Causal models, Pretense, Learning from testimony, Markov random fields, Causal generalization, Rational Model of Categorization},
abstract = {We propose a model of social cognitive development based not on a single modeling framework or the hypothesis that a single model accounts for children’s developing social cognition. Rather, we advocate a Causal Model approach (cf. Waldmann, 1996), in which models of social cognitive development take the same position as theories of social cognitive development, in that they generate novel empirical hypotheses. We describe this approach and present three examples across various aspects of social cognitive development. Our first example focuses on children’s understanding of pretense and involves only considering assumptions made by a computational framework. The second example focuses on children’s learning from “testimony”. It uses a modeling framework based on Markov random fields as a computational description of a set of empirical phenomena, and then tests a prediction of that description. The third example considers infants’ generalization of action learned from imitation. Here, we use a modified version of the Rational Model of Categorization to explain children’s inferences. Taken together, these examples suggest that research in social cognitive development can be assisted by considering how computational modeling can lead researchers towards testing novel hypotheses.}
}
@article{JIANG2023102217,
title = {Cooperative localization for master–salve multi-AUVs based on range measurements},
journal = {Physical Communication},
volume = {61},
pages = {102217},
year = {2023},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2023.102217},
url = {https://www.sciencedirect.com/science/article/pii/S1874490723002203},
author = {Ling Jiang and Wengen Gao and Yunfei Li and Mengxing Pan and Shaopeng Mu},
keywords = {AUV, Cooperative localization, Distance-dependent noise, Gaussian belief propagation},
abstract = {Underwater localization has consistently remained a prominent technical challenge for autonomous underwater vehicles (AUVs). The advent of cooperative localization techniques has emerged as a novel avenue for enhancing localization accuracy. The master–slave cooperative localization mode has gained widespread adoption due to its cost-effectiveness in implementation. In view of the complexity of underwater noise characteristics, in the multi-AUVs cooperative localization system, this paper addresses scenarios involving distance-dependent noise in a master–slave-based multi-AUVs cooperative localization system. To tackle the negative impact of distance-dependent noise and the non-linearity of the distance function, a two-step algorithm is proposed that combines maximum likelihood estimation and the Gaussian belief propagation algorithm (ML-GBP) to estimate the positions of AUVs. The maximum likelihood estimation is employed to cope with the interference caused by distance-dependent noise, and subsequently, the Gaussian belief propagation algorithm, based on range observations and reference information, is used to achieve accurate estimation of AUV positions and implement position correction. Simulation results demonstrate that the proposed ML-GBP algorithm outperforms traditional extended Kalman filter (EKF) and nonparametric belief propagation (NBP) methods by enhancing the localization accuracy of the system while exhibiting superior performance in terms of computational complexity and system communication overhead.}
}
@article{HAFRI2021475,
title = {The Perception of Relations},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {6},
pages = {475-492},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000085},
author = {Alon Hafri and Chaz Firestone},
keywords = {visual psychophysics, core cognition, intuitive physics, compositionality, structured representations, role-binding},
abstract = {The world contains not only objects and features (red apples, glass bowls, wooden tables), but also relations holding between them (apples contained in bowls, bowls supported by tables). Representations of these relations are often developmentally precocious and linguistically privileged; but how does the mind extract them in the first place? Although relations themselves cast no light onto our eyes, a growing body of work suggests that even very sophisticated relations display key signatures of automatic visual processing. Across physical, eventive, and social domains, relations such as support, fit, cause, chase, and even socially interact are extracted rapidly, are impossible to ignore, and influence other perceptual processes. Sophisticated and structured relations are not only judged and understood, but also seen — revealing surprisingly rich content in visual perception itself.}
}
@article{TILSTRA201366,
title = {Cognitive processes of middle grade readers when reading expository text with an assigned goal},
journal = {Learning and Individual Differences},
volume = {28},
pages = {66-74},
year = {2013},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2013.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S1041608013001271},
author = {Janet Tilstra and Kristen L. McMaster},
keywords = {Reading, Comprehension-building, Struggling readers, Think alouds, Cognitive processes, Expository text},
abstract = {The purpose of this study was to examine 5th-grade readers' cognitive processes during reading when assigned to read for a specific goal as compared to reading for general comprehension. Equal groups of good and struggling readers (N=40) read expository texts and thought aloud while reading. In addition, the readers completed a text retell to examine the impact of an assigned goal on comprehension. During reading in the specific goal condition, both groups of readers used more study statements (monitoring, repetitions, and paraphrases) and fewer inferences (elaborative, predictive, and text-based) when thinking aloud compared with general comprehension. No reliable condition differences were noted in the amount or type of information included in retells. Implications for developing readers' comprehension-building processes when assigned a goal for reading are discussed.}
}
@article{TANAKA201664,
title = {Modeling the motor cortex: Optimality, recurrent neural networks, and spatial dynamics},
journal = {Neuroscience Research},
volume = {104},
pages = {64-71},
year = {2016},
note = {Body representation in the brain},
issn = {0168-0102},
doi = {https://doi.org/10.1016/j.neures.2015.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0168010215002631},
author = {Hirokazu Tanaka},
keywords = {Body representation, Motor control, Computational modeling, Optimization, Neural computation},
abstract = {Specialization of motor function in the frontal lobe was first discovered in the seminal experiments by Fritsch and Hitzig and subsequently by Ferrier in the 19th century. It is, however, ironical that the functional and computational role of the motor cortex still remains unresolved. A computational understanding of the motor cortex equals to understanding what movement variables the motor neurons represent (movement representation problem) and how such movement variables are computed through the interaction with anatomically connected areas (neural computation problem). Electrophysiological experiments in the 20th century demonstrated that the neural activities in motor cortex correlated with a number of motor-related and cognitive variables, thereby igniting the controversy over movement representations in motor cortex. Despite substantial experimental efforts, the overwhelming complexity found in neural activities has impeded our understanding of how movements are represented in the motor cortex. Recent progresses in computational modeling have rekindled this controversy in the 21st century. Here, I review the recent developments in computational models of the motor cortex, with a focus on optimality models, recurrent neural network models and spatial dynamics models. Although individual models provide consistent pictures within their domains, our current understanding about functions of the motor cortex is still fragmented.}
}
@article{ZHANG2017427,
title = {Genomic Energy Landscapes},
journal = {Biophysical Journal},
volume = {112},
number = {3},
pages = {427-433},
year = {2017},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2016.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0006349516307743},
author = {Bin Zhang and Peter G. Wolynes},
abstract = {Energy landscape theory, developed in the context of protein folding, provides, to our knowledge, a new perspective on chromosome architecture. We review what has been learned concerning the topology and structure of both the interphase and mitotic chromosomes from effective energy landscapes constructed using Hi-C data. Energy landscape thinking raises new questions about the nonequilibrium dynamics of the chromosome and gene regulation.}
}
@article{NOSS201263,
title = {The design of a system to support exploratory learning of algebraic generalisation},
journal = {Computers & Education},
volume = {59},
number = {1},
pages = {63-81},
year = {2012},
note = {CAL 2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511002387},
author = {Richard Noss and Alexandra Poulovassilis and Eirini Geraniou and Sergio Gutierrez-Santos and Celia Hoyles and Ken Kahn and George D. Magoulas and Manolis Mavrikis},
keywords = {Exploratory learning, Algebraic generalisation, Intelligent support, Teacher assistance, Design},
abstract = {This paper charts the design and application of a system to support 11–14 year old students’ learning of algebraic generalisation, presenting students with the means to develop their understanding of the meaning of generality, see its power for mathematics and develop algebraic ways of thinking. We focus squarely on design, while taking account of both technical and pedagogical issues and challenges, and provide an account of how we have designed and built a system with a very close fit to our knowledge of students’ difficulties with the subject matter. We report the challenges involved in building a system that is both intelligent and exploratory, a learning environment in which both student and teacher are supported without explicit tutoring.}
}
@article{WALL201161,
title = {Structure–function relations are subtle in genetic regulatory networks},
journal = {Mathematical Biosciences},
volume = {231},
number = {1},
pages = {61-68},
year = {2011},
note = {Special issue on biological design principles},
issn = {0025-5564},
doi = {https://doi.org/10.1016/j.mbs.2011.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0025556411000150},
author = {Michael E. Wall},
keywords = {Gene regulation, Function prediction, Network motifs, , Computational biology, Synthetic biology},
abstract = {Recent studies have yielded insights into structure–function relations in genetic regulatory networks. Models of feed-forward loops show that the input–output behavior depends critically on the input signal as well as transcription interactions. Models of induction of the lac operon in Escherichia coli reveal the importance of metabolism in determining genetic regulatory network behavior. Combined experimental and computational studies of activation by MarA in E. coli show how mechanisms of transcription regulation, hidden at the level of genetic regulatory networks, can influence behavior. Together these studies illustrate that gene regulation is critically influenced by factors beyond the topology of genetic regulatory interactions. Prediction of the specific information processing roles of gene circuits is more difficult than we would like, but it is still possible. Thinking about evolution of proteins and networks might make it easier.}
}
@article{ZHANG2024110034,
title = {Comprehensive reliability assessment method for distribution networks considering IIDG low voltage ride-through control},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {159},
pages = {110034},
year = {2024},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2024.110034},
url = {https://www.sciencedirect.com/science/article/pii/S0142061524002552},
author = {Shuai Zhang and Wenxia Liu and Haiyang Wan and Tianlong Wang and Rui Cheng and Hanshen Li},
keywords = {Distribution networks, Reliability assessment, Low voltage ride through, Temporary fault, Permanent fault},
abstract = {Upon the large-scale integration of inverter-interfaced distributed generator (IIDG) into the grid, random faults in the distribution network can lead to momentary and sustained interruptions, significantly impacting system reliability. Although reliability methods have been widely used in distribution network adequacy assessment, using probabilistic method for reliability assessment including system dynamic security need to be investigated. To address this issue, a new method is designed to assess the reliability of distribution network using sequential Monte Carlo simulation. Firstly, the IIDG low-voltage ride-through (LVRT) control strategy is formulated, and the off-grid probability model for IIDG is developed based on the Gaussian distribution. Secondly, the component model is defined to consider the impact of random faults on power quality in security assessment. Following the fault tree analysis method, a protection action probability model was formulated to assess the failure probability of line current differential protection, IIDG anti-islanding protection, and reclosing protection. Finally, the method for momentary fault consequence analysis, based on depth-first search (DFS), and the method for sustained fault consequence analysis, based on the mixed-integer linear programming model, are developed. The study establishes a comprehensive probability reliability assessment framework. The validity of the method is demonstrated on the IEEE RBTS BUS6 F4 system, indicating good scalability.}
}
@article{SKLAD2014710,
title = {The Development of the Heuristics and Biases Scale (HBS)},
journal = {Procedia - Social and Behavioral Sciences},
volume = {112},
pages = {710-718},
year = {2014},
note = {International Conference on Education & Educational Psychology 2013 (ICEEPSY 2013)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.01.1221},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814012385},
author = {Marcin Sklad and Rene Diekstra},
keywords = {Cognitive Heuristics Biases Education Psychometric Scale},
abstract = {Problem Statement
There is no comprehensive tool capturing general vulnerability to biases caused by the use of heuristics. Existing tools focus only on one specific bias or on personality traits.
Research Questions
Can general vulnerability to heuristic thinking be assessed and what are the sub-dimensions of this construct? Can undergraduate students be successfully involved in the research process?
Purpose of the Study
To demonstrate the results of an educational experiment in which undergraduate students are involved in the first stage of development of the Heuristics and Biases Scale (HBS).
Research Methods
After getting acquainted with the underlying theory, students chose one specific bias or heuristic, investigated related results of the experiments and paradigms. At the later stage, under supervision, students developed items intended to capture the chosen bias. Finally, positively evaluated items were combined together and piloted. The psychometrical properties of the items and course outcomes were assessed.
Findings
Developed items formed scales with satisfactory reliability. Course received positive student evaluations, and the assessment indicated that the majority of students achieved intended learning outcomes.
Conclusions
The study indicates that it is possible to develop a psychometrically sound assessment to measure vulnerability to a range of common cognitive biases. Moreover, it is also possible to successfully involve undergraduate students in the development of a psychometrical tool.
Acknowledgments
Authors would like to thank the Students of University College Roosevelt contributing to this work as their Independent Research Projects or as a part of Social Psychology or Statistics Course.}
}
@incollection{HARSTON199029,
title = {3 - THE NEUROLOGICAL BASIS FOR NEURAL COMPUTATIONS},
editor = {Alianna J. Maren and Craig T. Harston and Robert M. Pap},
booktitle = {Handbook of Neural Computing Applications},
publisher = {Academic Press},
pages = {29-44},
year = {1990},
isbn = {978-0-12-546090-3},
doi = {https://doi.org/10.1016/B978-0-12-546090-3.50007-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780125460903500073},
author = {Craig T. Harston},
abstract = {Publisher Summary
This chapter focuses on using the human nervous system as a model for computer simulations. The brain, for example, can be better understood with computer simulations. Applying ideas from the human nervous system can solve difficult problems. There are several major design principles that can be found underlying the structural organization of different areas of the brain and that may offer long-term potential as models for design of artificial neural systems. The three major design principles are (1) layers of processing elements, (2) columns of processing elements, and (3) specialization of neural tissue into both specific and nonspecific systems. Several dynamic processes that occur in biological neural systems are integrally linked to the structures of computer simulations. These dynamics form the basis from which the higher properties of the system emerge. These structurally linked dynamic processes include distributed representation of information, temporal encoding of information, role of inhibition, and feedforward and feedback processing loops.}
}
@article{EHRENFELD2019102525,
title = {Online Public Spheres in the Era of Fake News: Implications for the Composition Classroom},
journal = {Computers and Composition},
volume = {54},
pages = {102525},
year = {2019},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2019.102525},
url = {https://www.sciencedirect.com/science/article/pii/S875546151830029X},
author = {Dan Ehrenfeld and Matt Barton},
keywords = {fake news, public sphere, social media, composition, misinformation, disinformation, critical thinking, media literacy},
abstract = {This article revisits Matt Barton's 2005 article "The Future of Rational-Critical Debate in Online Public Spheres" in light of recent debates around misinformation and disinformation, data-driven influence campaigns, the blurring line between social media and news media, and the algorithmic incentivization of “fake news.” While today’s social media platforms exhibit many of the qualities that C.W. Mills and Jürgen Habermas associate with a healthy public sphere—communication between strangers is participatory, immediate, accessible, and decentralized—this article raises questions about the extent to which everyday digital writing and circulation practices align with broader democratic aspirations. The goal of this article is to explore not only what these social and technological developments mean for the health of public discourse, but also how we, as teachers of writing, can meaningfully engage with them in our classrooms. An appendix includes ideas for assignments that engage students in critical reflection about their own participation in today’s online public spheres.}
}
@article{REN2024127126,
title = {FedBoosting: Federated learning with gradient protected boosting for text recognition},
journal = {Neurocomputing},
volume = {569},
pages = {127126},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.127126},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223012493},
author = {Hanchi Ren and Jingjing Deng and Xianghua Xie and Xiaoke Ma and Yichuan Wang},
keywords = {Deep learning, Federated learning, Privacy preserving},
abstract = {Conventional machine learning methodologies require the centralization of data for model training, which may be infeasible in situations where data sharing limitations are imposed due to concerns such as privacy and gradient protection. The Federated Learning (FL) framework enables the collaborative learning of a shared model without necessitating the centralization or sharing of data among the data proprietors. Nonetheless, in this paper, we demonstrate that the generalization capability of the joint model is suboptimal for Non-Independent and Non-Identically Distributed (Non-IID) data, particularly when employing the Federated Averaging (FedAvg) strategy as a result of the weight divergence phenomenon. Consequently, we present a novel boosting algorithm for FL to address both the generalization and gradient leakage challenges, as well as to facilitate accelerated convergence in gradient-based optimization. Furthermore, we introduce a secure gradient sharing protocol that incorporates Homomorphic Encryption (HE) and Differential Privacy (DP) to safeguard against gradient leakage attacks. Our empirical evaluation demonstrates that the proposed Federated Boosting (FedBoosting) technique yields significant enhancements in both prediction accuracy and computational efficiency in the visual text recognition task on publicly available benchmarks.}
}
@article{MAVERS2002187,
title = {Interpreting the externalised images of pupils’ conceptions of ICT: methods for the analysis of concept maps},
journal = {Computers & Education},
volume = {38},
number = {1},
pages = {187-207},
year = {2002},
issn = {0360-1315},
doi = {https://doi.org/10.1016/S0360-1315(01)00074-4},
url = {https://www.sciencedirect.com/science/article/pii/S0360131501000744},
author = {Diane Mavers and Bridget Somekh and Jane Restorick},
keywords = {Concept mapping, Representations, Learning, Networked technologies, Phenomenography},
abstract = {The ImpacT2 evaluation is using image based concept mapping as one method of exploring the impact of networked technologies on students' learning. In a pre-test administered in June 2000, students in three cohorts aged 10–11, 13–14 and 15–16, produced around 2000 ‘maps’. Entitled ‘Computers in My World’, these provide a means of students externalising mental representations of networked technologies. Using a phenomenographic approach, the study aims to identify qualitatively different patterns of thinking and trends in the development of pupils' concepts. Five quanititative measures emerged from heuristic analysis of the maps: nodes, links, connectivity, ‘Spheres of Thinking’ and ‘Zones of Use’. Analysis of the pre-test maps was carried out alongside analysis of pre-test questionnaires, using SPSS. The outcomes suggest correlations between pupils' experience and the constent of their maps. Phenomenographic interviewing of selected 11 year old pupils, which entailed handling control over to interviewees through the use of open-ended questions, enabled further exploration of their experiences and understandings of those experiences. A method for in-depth interviewing of young students is described. Data suggest that pupils have sophisticated ‘secondary artifacts’ or mental models of the nature of networked technologies and their role in today's world. This has implications for the way that ICT is used in schools and for its potential as a tool for students' learning.}
}
@incollection{CORTELLNICOLAU20241090,
title = {Agent-Based Modeling},
editor = {Efthymia Nikita and Thilo Rehren},
booktitle = {Encyclopedia of Archaeology (Second Edition) (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {1090-1098},
year = {2024},
isbn = {978-0-323-91856-5},
doi = {https://doi.org/10.1016/B978-0-323-90799-6.00094-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032390799600094X},
author = {Alfredo Cortell-Nicolau},
keywords = {Agency, Agent-based models, Coding, Complexity, Heuristic modeling, Hypothesis testing, Netlogo, Python, R, Reproducibility, Tactical modeling},
abstract = {This work constitutes a very brief overview of Agent-Based Modeling applied to archaeology. The aim is to provide a synthetic overview of the most fundamental concepts, so that researchers interested in starting to explore this methodological tool have a first contact with it. The text covers basic concepts, as well as offers an example of a simple simulation so that interested readers gain initial insight to this topic.}
}
@article{MENENDEZHERRERO2024210,
title = {Persistence of atoms in molecules: there is room beyond electron densities},
journal = {IUCrJ},
volume = {11},
number = {2},
pages = {210-223},
year = {2024},
issn = {2052-2525},
doi = {https://doi.org/10.1107/S2052252524000915},
url = {https://www.sciencedirect.com/science/article/pii/S2052252524000198},
author = {María Menéndez-Herrero and Ángel {Martín Pendás} and X. Zhang},
keywords = {computational modeling, density functional theory, molecular simulations, energy minimization, electron densities, Born maxima},
abstract = {The 3N-dimensional maxima of the square of the wavefunction, the so-called Born maxima, show beyond doubt that the electronic structure of atoms persists in molecules, either in their original ground state or some low-lying excited state. The electron density is only a low-dimensional projection of this much richer landscape.
Evidence that the electronic structure of atoms persists in molecules to a much greater extent than has been usually admitted is presented. This is achieved by resorting to N-electron real-space descriptors instead of one- or at most two-particle projections like the electron or exchange-correlation densities. Here, the 3N-dimensional maxima of the square of the wavefunction, the so-called Born maxima, are used. Since this technique is relatively unknown to the crystallographic community, a case-based approach is taken, revisiting first the Born maxima of atoms in their ground state and then some of their excited states. It is shown how they survive in molecules and that, beyond any doubt, the distribution of electrons around an atom in a molecule can be recognized as that of its isolated, in many cases excited, counterpart, relating this fact with the concept of energetic promotion. Several other cases that exemplify the applicability of the technique to solve chemical bonding conflicts and to introduce predictability in real-space analyses are also examined.}
}
@article{SPELDA2020102531,
title = {The future of human-artificial intelligence nexus and its environmental costs},
journal = {Futures},
volume = {117},
pages = {102531},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102531},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300215},
author = {Petr Spelda and Vit Stritecky},
keywords = {Machine learning, Artificial intelligence, Inductive generalisations, Anthropocene, Climate change},
abstract = {The environmental costs and energy constraints have become emerging issues for the future development of Machine Learning (ML) and Artificial Intelligence (AI). So far, the discussion on environmental impacts of ML/AI lacks a perspective reaching beyond quantitative measurements of the energy-related research costs. Building on the foundations laid down by Schwartz et al. (2019) in the GreenAI initiative, our argument considers two interlinked phenomena, the gratuitous generalisation capability and the future where ML/AI performs the majority of quantifiable inductive inferences. The gratuitous generalisation capability refers to a discrepancy between the cognitive demands of a task to be accomplished and the performance (accuracy) of a used ML/AI model. If the latter exceeds the former because the model was optimised to achieve the best possible accuracy, it becomes inefficient and its operation harmful to the environment. The future dominated by the non-anthropic induction describes a use of ML/AI so all-pervasive that most of the inductive inferences become furnished by ML/AI generalisations. The paper argues that the present debate deserves an expansion connecting the environmental costs of research and ineffective ML/AI uses (the issue of gratuitous generalisation capability) with the (near) future marked by the all-pervasive Human-Artificial Intelligence Nexus.}
}
@incollection{HORVATH1995315,
title = { - Feature-based support of conceptual design of mechanical products},
editor = {Mohamed E. Elarabi and Abdalla S. Wifi and A.S. Wifi},
booktitle = {Current Advances in Mechanical Design and Production VI},
publisher = {Pergamon},
address = {Oxford},
pages = {315-322},
year = {1995},
isbn = {978-0-08-042140-7},
doi = {https://doi.org/10.1016/B978-008042140-7/50029-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080421407500299},
author = {I. Horváth and Z. Bagoly and P. Kulcsár},
abstract = {Publisher Summary
The chapter presents a novel interpretation of conceptual design process that implies thinking in concepts rather than in functions. This chapter implements an interactive platform for early stage representation of designs. A framework, associative concept network (ACN), is elaborated to promote the development of a new computational model for concept spaces. It is also expected that higher level automation of conceptual design can be achieved based on ACNs. The reported research concentrates on the development and application of concept feature-objects (CFO). CFOs are functionally and morphologically parameterized three-dimensional skeletons that are arranged into an organ structure. Components of CFO descriptions are the physical ports, contact surfaces related to ports, bones between ports, DOF of ports, relevant physical parameters characterizing the energy transformation processes, and scientific and empirical descriptions of intentional transformations and environmental effects. Modeling entities for a given application are constructed by genetic modeling. The set of the new modeling entities can be used both for static analysis and dynamic simulation of mechanical products.}
}
@article{BROOKS2013947,
title = {The Primate Cerebellum Selectively Encodes Unexpected Self-Motion},
journal = {Current Biology},
volume = {23},
number = {11},
pages = {947-955},
year = {2013},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2013.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0960982213004375},
author = {Jessica X. Brooks and Kathleen E. Cullen},
abstract = {Summary
Background
The ability to distinguish sensory signals that register unexpected events (exafference) from those generated by voluntary actions (reafference) during self-motion is essential for accurate perception and behavior. The cerebellum is most commonly considered in relation to its contributions to the fine tuning of motor commands and sensorimotor calibration required for motor learning. During unexpected motion, however, the sensory prediction errors that drive motor learning potentially provide a neural basis for the computation underlying the distinction between reafference and exafference.
Results
Recording from monkeys during voluntary and applied self-motion, we demonstrate that individual cerebellar output neurons encode an explicit and selective representation of unexpected self-motion by means of an elegant computation that cancels the reafferent sensory effects of self-generated movements. During voluntary self-motion, the sensory responses of neurons that robustly encode unexpected movement are canceled. Neurons with vestibular and proprioceptive responses to applied head and body movements are unresponsive when the same motion is self-generated. When sensory reafference and exafference are experienced simultaneously, individual neurons provide a precise estimate of the detailed time course of exafference.
Conclusions
These results provide an explicit solution to the longstanding problem of understanding mechanisms by which the brain anticipates the sensory consequences of our voluntary actions. Specifically, by revealing a striking computation of a sensory prediction error signal that effectively distinguishes between the sensory consequences of self-generated and externally produced actions, our findings overturn the conventional thinking that the sensory errors coded by the cerebellum principally contribute to the fine tuning of motor activity required for motor learning.}
}
@article{SHAIKHOUNI2012392,
title = {Computers and Neurosurgery},
journal = {World Neurosurgery},
volume = {78},
number = {5},
pages = {392-398},
year = {2012},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2012.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S1878875012010169},
author = {Ammar Shaikhouni and J. Bradley Elder},
keywords = {Computers, Neuroimaging, Neurosurgery, Technology},
abstract = {At the turn of the twentieth century, the only computational device used in neurosurgical procedures was the brain of the surgeon. Today, most neurosurgical procedures rely at least in part on the use of a computer to help perform surgeries accurately and safely. The techniques that revolutionized neurosurgery were mostly developed after the 1950s. Just before that era, the transistor was invented in the late 1940s, and the integrated circuit was invented in the late 1950s. During this time, the first automated, programmable computational machines were introduced. The rapid progress in the field of neurosurgery not only occurred hand in hand with the development of modern computers, but one also can state that modern neurosurgery would not exist without computers. The focus of this article is the impact modern computers have had on the practice of neurosurgery. Neuroimaging, neuronavigation, and neuromodulation are examples of tools in the armamentarium of the modern neurosurgeon that owe each step in their evolution to progress made in computer technology. Advances in computer technology central to innovations in these fields are highlighted, with particular attention to neuroimaging. Developments over the last 10 years in areas of sensors and robotics that promise to transform the practice of neurosurgery further are discussed. Potential impacts of advances in computers related to neurosurgery in developing countries and underserved regions are also discussed. As this article illustrates, the computer, with its underlying and related technologies, is central to advances in neurosurgery over the last half century.}
}
@article{LIU2025103366,
title = {LoViT: Long Video Transformer for surgical phase recognition},
journal = {Medical Image Analysis},
volume = {99},
pages = {103366},
year = {2025},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103366},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524002913},
author = {Yang Liu and Maxence Boels and Luis C. Garcia-Peraza-Herrera and Tom Vercauteren and Prokar Dasgupta and Alejandro Granados and Sébastien Ourselin},
keywords = {Surgical phase recognition, Long videos, Temporally-rich spatial feature, Multi-scale, Phase transition-aware},
abstract = {Online surgical phase recognition plays a significant role towards building contextual tools that could quantify performance and oversee the execution of surgical workflows. Current approaches are limited since they train spatial feature extractors using frame-level supervision that could lead to incorrect predictions due to similar frames appearing at different phases, and poorly fuse local and global features due to computational constraints which can affect the analysis of long videos commonly encountered in surgical interventions. In this paper, we present a two-stage method, called Long Video Transformer (LoViT), emphasizing the development of a temporally-rich spatial feature extractor and a phase transition map. The temporally-rich spatial feature extractor is designed to capture critical temporal information within the surgical video frames. The phase transition map provides essential insights into the dynamic transitions between different surgical phases. LoViT combines these innovations with a multiscale temporal aggregator consisting of two cascaded L-Trans modules based on self-attention, followed by a G-Informer module based on ProbSparse self-attention for processing global temporal information. The multi-scale temporal head then leverages the temporally-rich spatial features and phase transition map to classify surgical phases using phase transition-aware supervision. Our approach outperforms state-of-the-art methods on the Cholec80 and AutoLaparo datasets consistently. Compared to Trans-SVNet, LoViT achieves a 2.4 pp (percentage point) improvement in video-level accuracy on Cholec80 and a 3.1 pp improvement on AutoLaparo. Our results demonstrate the effectiveness of our approach in achieving state-of-the-art performance of surgical phase recognition on two datasets of different surgical procedures and temporal sequencing characteristics. The project page is available at https://github.com/MRUIL/LoViT.}
}
@article{CAPONNETTO2021104823,
title = {Examining nursing student academic outcomes: A forty-year systematic review and meta-analysis},
journal = {Nurse Education Today},
volume = {100},
pages = {104823},
year = {2021},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2021.104823},
url = {https://www.sciencedirect.com/science/article/pii/S0260691721000800},
author = {Valeria Caponnetto and Angelo Dante and Vittorio Masotta and Carmen {La Cerra} and Cristina Petrucci and Celeste Marie Alfes and Loreto Lancia},
keywords = {Academic failure, Academic success, Attrition, Bachelor's degree, Determinants, Factors, Nursing student},
abstract = {Objectives
To synthesize the definitions of nursing students' academic outcomes and provide a quantitative synthesis of their associated and predictive factors.
Design
Systematic review and meta-analysis.
Data sources
Four scientific databases were searched until January 2020.
Review methods
Observational studies describing undergraduate nursing students' academic outcomes were included. Studies were analytically synthesized and meta-analyses were performed utilizing the Odds Ratio or Cohen's d as effect sizes.
Results
Eighteen studies, published from 1979 to 2018, were included in the review, nine were meta-analyzed. Studies involved 10,024 undergraduate nursing students and were mostly retrospective cohort (55.6%). Students were mostly female (75.4%) with a mean age ranging from 21.3 to 27.0 years. Meta-analysis revealed that being female (OR = 1.65, 95% CI = 1.26 to 2.12), having attended a Classical, Scientific or Academic high school (OR = 1.30, 95% IC = 1.16 to 1.46), and having reported higher final grades at the upper-secondary high school (Cohen's d = 0.42, 95% CI = 0.18 to 0.65) was significantly associated with student's ability to graduate within the regular duration of the program. Sensitivity analyses confirmed meta-analytic results and meta-analyses heterogeneity depended on study design. Contrasting and limited evidence were found for other investigated factors, and for academic outcomes different from graduation within the regular duration of the program.
Conclusions
Despite meta-analytic results, gender and upper-secondary school would be unethical students' entry selection criteria. Final upper-secondary school grades should be considered for this scope and purpose. Conflicting and limited evidence found for other factors, such as students' background, suggested the influence of local contexts on the phenomenon and its investigation. Investigating the role of modifiable individual variables, such as empathy and critical thinking, could contribute to the open debate about students' entry selection strategies. An improvement in methodological quality of future studies is recommended and expected.}
}
@article{GREEN2017125,
title = {Fluid reasoning predicts future mathematical performance among children and adolescents},
journal = {Journal of Experimental Child Psychology},
volume = {157},
pages = {125-143},
year = {2017},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2016.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0022096516302995},
author = {Chloe T. Green and Silvia A. Bunge and Victoria {Briones Chiongbian} and Maia Barrow and Emilio Ferrer},
keywords = {Children, Math, Cognitive development, Fluid reasoning, Working memory, Problem solving},
abstract = {The aim of this longitudinal study was to determine whether fluid reasoning (FR) plays a significant role in the acquisition of mathematics skills above and beyond the effects of other cognitive and numerical abilities. Using a longitudinal cohort sequential design, we examined how FR measured at three assessment occasions, spaced approximately 1.5years apart, predicted math outcomes for a group of 69 participants between ages 6 and 21years across all three assessment occasions. We used structural equation modeling (SEM) to examine the direct and indirect relations between children’s previous cognitive abilities and their future math achievement. A model including age, FR, vocabulary, and spatial skills accounted for 90% of the variance in future math achievement. In this model, FR was the only significant predictor of future math achievement; age, vocabulary, and spatial skills were not significant predictors. Thus, FR was the only predictor of future math achievement across a wide age range that spanned primary school and secondary school. These findings build on Cattell’s conceptualization of FR as a scaffold for learning, showing that this domain-general ability supports the acquisition of rudimentary math skills as well as the ability to solve more complex mathematical problems.}
}
@article{SOLEIMANIJAVID2024113958,
title = {Challenges and opportunities of occupant-centric building controls in real-world implementation: A critical review},
journal = {Energy and Buildings},
volume = {308},
pages = {113958},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.113958},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824000744},
author = {Atiye Soleimanijavid and Iason Konstantzos and Xiaoqi Liu},
keywords = {Occupant-centric control, Comfort, Sensing, Controls, Learning, Energy efficiency, Smart buildings},
abstract = {Over the past few decades, attention in buildings’ design and operation has gradually shifted from promoting only energy efficiency objectives to also addressing human comfort and well-being. Researchers have developed a wide range of control algorithms ranging from rule-based controls to complex learning approaches that can fully capture occupants’ personalized preferences in smart buildings. This direction of occupant-centric building controls can bridge the gap between occupants’ satisfaction and sustainability objectives. However, most of these promising technologies have not yet found their way into real-world applications. This study will perform a critical review on occupant-centric thermal and lighting control studies aiming to (i) analyze the strengths and weaknesses of different approaches; (ii) identify the requirements for these techniques to be implemented in real-world systems; and (iii) propose new research directions that will promote the usability of such controls and will be a catalyst towards their wide adoption. Computational complexity, integration with Building Automation Systems (BAS), data availability and data quality, scalability, and the lack of more research featuring actual building implementation emerge as critical barriers. Addressing these challenges is imperative for the successful deployment of occupant-centric controls in real-world applications.}
}
@article{ALBERT2013353,
title = {Extending SysML for Engineering Designers by Integration of the Contact & Channel – Approach (C&C2-A) for Function-Based Modeling of Technical Systems},
journal = {Procedia Computer Science},
volume = {16},
pages = {353-362},
year = {2013},
note = {2013 Conference on Systems Engineering Research},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.01.037},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913000380},
author = {Albers Albert and Zingel Christian},
keywords = {Function-based modeling, state-based structure modeling, SysML, Contact & Channel - Approach, C&C-A, Engineering design},
abstract = {Model-Based Systems Engineering (MBSE) is advancing rapidly in the domains of software and embedded systems. In contrast, mechanical engineers still have trouble in application of MBSE. SysML has established as the leading modeling language for multidisciplinary systems, but some limitations still hinder mechanical engineers from its application. The provided behavioral and structural diagrams seem to not being sufficiently capable to represent all relevant information regarding mechanical systems. This paper presents an extending profile which aims to overcome some of those limitations. The profile is based on the Contact & Channel – Approach (C&C2-A), which is well-proven in function-based modeling of technical systems comprising function-relevant structural properties. The goals of the C&C2-A are to retain a maximal solution space, to overcome component- afflicted thinking and to provide an adequate modeling approach for mechanical relevant information. A prototypic tool implementation of the extending SysML-profile, complemented by some automatisms in form of a plugin, is evaluated at the example of a small gearbox.}
}
@article{WU2024100295,
title = {Analyzing K-12 AI education: A large language model study of classroom instruction on learning theories, pedagogy, tools, and AI literacy},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100295},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100295},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000985},
author = {Di Wu and Meng Chen and Xu Chen and Xing Liu},
keywords = {AI education, Large language models, Pedagogical approaches, AI literacy},
abstract = {There is growing recognition among researchers and stakeholders about the significant impact of artificial intelligence (AI) technology on classroom instruction. As a crucial element in developing AI literacy, AI education in K-12 schools is increasingly gaining attention. However, most existing research on K-12 AI education relies on experiential methodologies and suffers from a lack of quantitative analysis based on extensive classroom data, hindering a comprehensive depiction of AI education's current state at these educational levels. To address this gap, this article employs the advanced semantic understanding capabilities of large language models (LLMs) to create an intelligent analysis framework that identifies learning theories, pedagogical approaches, learning tools, and levels of AI literacy in AI classroom instruction. Compared with the results of manual analysis, analysis based on LLMs can achieve more than 90% consistency. Our findings, based on the analysis of 98 classroom instruction videos in central Chinese cities, reveal that current AI classroom instruction insufficiently foster AI literacy, with only 35.71% addressing higher-level skills such as evaluating and creating AI. AI ethics are even less commonly addressed, featured in just 5.1% of classroom instruction. We classified AI classroom instruction into three categories: conceptual (50%), heuristic (18.37%), and experimental (31.63%). Correlation analysis suggests a significant relationship between the adoption of pedagogical approaches and the development of advanced AI literacy. Specifically, integrating Project-based/Problem-based learning (PBL) with Collaborative learning appears effective in cultivating the capacity to evaluate and create AI.}
}
@article{NORROS201461,
title = {Developing human factors/ergonomics as a design discipline},
journal = {Applied Ergonomics},
volume = {45},
number = {1},
pages = {61-71},
year = {2014},
note = {Systems Ergonomics/Human Factors},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2013.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0003687013000975},
author = {Leena Norros},
keywords = {Design thinking, Technology-in-use, Naturalistic approach, Core-task modelling},
abstract = {This paper deals with internal challenges that the human factors/ergonomics (HFE) research faces when wishing to strengthen its contribution to development of work systems. Three established characteristics of high-quality HFE, i.e., HFE takes a systems approach, HFE is design-driven, and HFE focuses on two closely related outcomes, performance and well-being, are taken as a starting point of a methodological discussion, in which conceptual innovations, e.g. adopting the technology-in-use perspective, are proposed to support development of HFE towards the high-quality aims. The feasibility of the proposed conceptual choices is demonstrated by introducing a naturalistic HFE analysis approach including four HFE functions. The gained experience of the use of this approach in a number of complex work domains allows the conclusion that becoming design-driven appears as that most difficult quality target for HFE to reach. Creating an own design discipline identity in a multi-voiced collaboration is the key internal challenge for human factors/ergonomics.}
}
@article{HOLMES201743,
title = {Motor cognition and neuroscience in sport psychology},
journal = {Current Opinion in Psychology},
volume = {16},
pages = {43-47},
year = {2017},
note = {Sport psychology},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2017.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X16301646},
author = {Paul S Holmes and David J Wright},
abstract = {Advances in technology have allowed research in cognitive neuroscience to contribute significantly to the discipline of sport psychology. In most cases, the research has become more rigorous and has directed current thinking on the mechanisms subserving a number of psychological theories and models of practice. Currently, the three most common neuroscience techniques informing sport and exercise research are electroencephalography, transcranial magnetic stimulation and functional magnetic resonance imaging. In this review, we highlight and discuss the contributions to sport psychology that have been made in recent years by applying these techniques, with a focus on the development of expertise, motor cognition, motor imagery and action observation.}
}
@article{OU2023e15530,
title = {Investigation and analysis of the current situation of programming education in primary and secondary schools},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e15530},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e15530},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023027378},
author = {Qizhong Ou and Weijie Liang and Zhenni He and Xiao Liu and Renxing Yang and Xiaojun Wu},
keywords = {Programming education in primary and secondary schools, Programming education for students, Programming learning, Investigation and current situation, Primary and secondary education},
abstract = {With the rapid development of the era of artificial intelligence, the application ability of programming is also highlighted. As one of the necessary abilities of social talents in the future, primary and secondary schools pay more and more attention to this, and programming education is also in full swing. Therefore, based on previous studies, this paper further clarifies the current situation when the current situation of programming education in primary and secondary schools is ambiguous. This paper is aimed at a wide range of primary and secondary school teachers. With 1500 teachers who participated in the online training class for programming teachers as the object in Chinese primary, middle and high school stages, mainly from the three levels of schools, teachers, and students. The questionnaire with good reliability and validity test was used as the research method, the survey data were statistically described and analyzed, and differences were analyzed using Microsoft Excel2019, SPSS26.0 and so on, it investigates and analyzes the current situation of programming education in primary and secondary schools. Results indicate that the overall quality of programming education offerings in elementary and secondary schools is subpar, and the construction of programming education curriculum in schools requires improvement. Nevertheless, schools prioritize improving students' comprehensive abilities, and teachers hold a positive attitude towards programming education and teaching. Although students demonstrate a strong interest in learning, their foundation is weak, resulting in poor learning outcomes. Consequently, the author provides specific recommendations regarding programming education's working mechanism, curriculum standard system, teacher training, and educational resources sharing to better develop programming education in primary and secondary schools.}
}
@article{HUNG20131,
title = {Conceptual Recombination: A method for producing exploratory and transformational creativity in creative works},
journal = {Knowledge-Based Systems},
volume = {53},
pages = {1-12},
year = {2013},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950705113002098},
author = {Edward C.K. Hung and Clifford S.T. Choy},
keywords = {Conceptual Recombination, Creative work ontology, Creative method, Computational creativity, Creativity Support Tools},
abstract = {Computational creativity researchers have long been searching for a reliable creative method of generating transformational creativity in Creativity Support Tools, in vain, especially when these systems are supposed to take in a user’s unfinished creative work and produce representational and creative outputs as continuations to the user input. In this paper we propose a new creative method called Conceptual Recombination to take up this challenge. We first define creative work for this study followed by creative work ontology to be the theoretical background of Conceptual Recombination. We further refer to application ontology and regard Conceptual Recombination as the task model for creative work ontology. In this task model there are three levels of prediction leading to the formations of output features, output structures, and their combinations as the final system outputs constrained by rules, biases, and homeomorphism. Furthermore, this new creative method allows the use of exploratory creativity on structures and transformational creativity on features to attain a balance between usefulness and novelty in system outputs. A 7-tuple computational model and the search mechanisms for exploratory and transformational creativity are also defined for it. Lastly, we evaluate Conceptual Recombination with our case study about producing a 2-dimensional asymmetrical shape with a given symmetrical shape to demonstrate its practicality and conclude that it not only offers a new reliable creative method for Creativity Support Tools, but also provides an objective evaluation method for transformational creativity.}
}
@article{BORG202041,
title = {On “the application of science to science itself:” chemistry, instruments, and the scientific labor process},
journal = {Studies in History and Philosophy of Science Part A},
volume = {79},
pages = {41-56},
year = {2020},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2019.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368118300529},
author = {George Borg},
keywords = {Instrumental revolution, Labor, Scientific revolution, Structure determination, Technology, Progress, Chemistry, Mechanization},
abstract = {The “Instrumental Revolution” in chemistry refers to a transitional period in the mid-20th century during which sophisticated instrumentation based on physical principles was introduced to solve chemical problems. Historical and philosophical reflection on whether the revolution was a scientific one has been dominated by general models of scientific revolution, in particular, those proposed by Thomas Kuhn, I. B. Cohen and Ian Hacking. In this article I propose that the Industrial Revolution is a useful model for understanding the transformation wrought by the increasingly important role of machines in chemical research. Drawing on Marx's analysis of that event, I argue that that the Instrumental Revolution bears a striking resemblance to the industrial one. I offer grounds for thinking that the resemblance is not fortuitous, but rather reflects a general pattern of development involving the mechanization of the labor process. It is suggested that the cognitive consequences of radical changes in the means of production, as exemplified in the Instrumental Revolution, warrant the consideration of whether the latter is an instance of a kind of revolution in science rather than a singular episode.}
}
@article{KAMEUGNE2024,
title = {Quadratic horizontally elastic not-first/not-last filtering algorithm for cumulative constraint},
journal = {European Journal of Operational Research},
year = {2024},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724006945},
author = {Roger Kameugne and Sévérine Fetgo Betmbe and Thierry Noulamo},
keywords = {Not-first/not-last algorithm, Profile data structure, TimeTable data structure, Cumulative scheduling, Constraint programming, Horizontally elastic scheduling, RCPSP},
abstract = {The not-first/not-last rule is a pendant of the edge finding rule, generally embedded in the cumulative constraint during constraint-based scheduling. It is combined with other filtering rules for more pruning of the tree search. In this paper, the Profile data structure in which tasks are scheduled in a horizontally elastic way is used to strengthen the classic not-first/not-last rule. Potential not-first task intervals are selected using criteria (specified later in the paper), and the Profile data structure is applied to selected task intervals. We prove that this new rule subsumes the classic not-first rule. A quadratic filtering algorithm is proposed for the new rule, thus improving the complexity of the horizontally elastic not-first/not-last algorithm from O(n3) to O(n2). The fixed part of external tasks that overlap with the selected task intervals is considered during the computation of the earliest completion time of task intervals. This improvement increases the filtering power of the algorithm while remaining quadratic. Experimental results, on a well-known suite of benchmark instances of Resource-Constrained Project Scheduling Problems (RCPSPs), show that the propounded algorithms are competitive with the state-of-the-art not-first algorithms in terms of tree search and running time reduction.}
}
@article{CALDERON201860,
title = {Sunrise Hotels: An integrated managerial accounting teaching case},
journal = {Journal of Accounting Education},
volume = {44},
pages = {60-72},
year = {2018},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2018.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575117302439},
author = {Thomas Calderon and James W. Hesford and Nicolas Mangin and Mina Pizzini},
keywords = {Managerial accounting, Integrated learning, Case study, Teaching case},
abstract = {“Sunrise Hotels” consists of six, linked cases developed from a field study of a large hotel chain in North America. The cases are short, so they can be distributed and solved in less than a full class period, after a short lecture by the instructor. Students often see managerial topics as an unrelated collection of tools rather than as a coherent, integrated framework for decision-making and management control. Questions included with each short case guide students, and the integration developed across six cases in a single setting should help students view managerial accounting topics as inter-related tools for decision making and control.}
}
@article{NNAJI2019106672,
title = {Modelling and management of smart microgrid for rural electrification in sub-saharan Africa: The case of Nigeria},
journal = {The Electricity Journal},
volume = {32},
number = {10},
pages = {106672},
year = {2019},
issn = {1040-6190},
doi = {https://doi.org/10.1016/j.tej.2019.106672},
url = {https://www.sciencedirect.com/science/article/pii/S1040619019302775},
author = {Eunice C. Nnaji and Donald Adgidzi and Michael O. Dioha and Daniel R.E. Ewim and Zhongjie Huan},
keywords = {Energy access, Off-grid rural electrification, HOMER, Simulink, Nigeria},
abstract = {Access to electricity is still a challenge in many parts of sub-Saharan Africa. In Nigeria, over 70% of the rural dwellers do not have access to electricity. The purpose of this paper is to examine the potential of a smart microgrid for off-grid rural electrification in Nigeria. A combination of design thinking and model-based design methodology is employed to select a suitable microgrid configuration and to develop a smart microgrid model. A system consisting of a solar photovoltaic array, battery energy storage and a diesel generator is selected, and the model is developed in Simulink. Demand data from 10 rural communities in Nigeria are used to validate the performance of the model and the potential for demand management is considered. The use of energy efficient light bulbs is found to reduce the peak electricity demand of the case study communities by 42 to 76%. Combining the proposed system with the use of LED bulbs makes the system to have 56 to 81% less net present cost than a system with a diesel generator alone and incandescent light bulbs. The proposed smart microgrid is found to be more suitable for off-grid rural electrification in Nigeria than diesel generators which are currently used for off-grid electrification in Nigeria.}
}
@article{FURTADO2024100086,
title = {A task-oriented framework for generative AI in design},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100086},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000128},
author = {Lara Sucupira Furtado and Jorge Barbosa Soares and Vasco Furtado},
keywords = {Generative artificial intelligence, Product, Creative computing, Transformational Creativity},
abstract = {The intersection of Artificial Intelligence and Design disciplines such as Architecture, Urban Planning, Engineering and Product Design has been a longstanding pursuit, with Generative AI (GAI) ushering in a new era of possibilities. The research presented here explores how GAI can enhance creativity and assist Design practitioners with tasks to create products such as, but not limited to, renderings, concepts, construction techniques, materials, data analytics or maps. We apply a framework of combinational, exploratory and transformational creativity to organize how recent advancements in GAI can support each creative category. We propose a conceptual framework of GAI towards transformational creativity, and identify real-world examples to demonstrate GAI's impact, such as transforming sketches into detailed renders, facilitating real-time 3D model generation, predicting trends through analytics and creating images or reports via text prompts. Our work envisions a future where GAI becomes a real-time collaborator to complete certain automated tasks while liberating Designers to focus on transformational innovation.}
}
@article{SCHOEN2025102018,
title = {Improving the teaching and learning of statistics},
journal = {Learning and Instruction},
volume = {95},
pages = {102018},
year = {2025},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2024.102018},
url = {https://www.sciencedirect.com/science/article/pii/S0959475224001452},
author = {Robert C. Schoen and Christopher Rhoads and Alexandra Perez and Tim Jacobbe and Lanrong Li},
keywords = {Curriculum, Teacher professional development, Statistics education, Many-facet rasch, Hierarchical linear modeling},
abstract = {Structured Abstract
Background
Statistical literacy is more important now than ever. Mathematics teachers are often expected to teach statistics, but statistics and mathematics differ in important ways. The mathematics teaching workforce needs more opportunities to learn statistics and how to teach it accurately and effectively.
Aims
This study was designed to estimate the effects of an intervention. The intervention consisted of a combination of an inquiry-oriented curriculum replacement unit and teacher learning opportunities in statistics and probability. Primary outcomes of interest were instructional practice and student understanding of statistics and probability.
Sample
The study sample included seventh-grade teachers and their students (age 13) in a single, urban school district in the southeastern United States. There were 74 classrooms represented in the analytic sample for the instructional outcome and 2,283 students in the analytic sample for the student outcome.
Methods
Schools were randomly assigned to the treatment or control conditions with equal probability of assignment to condition. Treatment-condition teachers participated in four days of professional learning workshops focused on teaching a 20-day curriculum unit. The Instructional Quality Assessment was used to measure instructional practice. The Levels of Conceptual Understanding in Statistics assessment instrument was used to measure student learning outcomes. Data analysis used hierarchical linear modeling.
Results
Positive, statistically significant effects on both instructional practice (ES = .99) and student understanding of statistics (ES = .25) were found.
Conclusions
The study results indicate that the inquiry-oriented lessons in the curriculum—with the support of teacher-learning opportunities—can improve instruction and increase student learning in statistics.}
}
@article{PHAN2024,
title = {Precision synbiotics increase gut microbiome diversity and improve gastrointestinal symptoms in a pilot open-label study for autism spectrum disorder},
journal = {mSystems},
volume = {9},
number = {5},
year = {2024},
issn = {2379-5077},
doi = {https://doi.org/10.1128/msystems.00503-24},
url = {https://www.sciencedirect.com/science/article/pii/S2379507724001077},
author = {Joann Phan and Diana C. Calvo and Divya Nair and Suneer Jain and Thibaut Montagne and Summer Dietsche and Kelsey Blanchard and Shirin Treadwell and James Adams and Rosa Krajmalnik-Brown and Nicholas Chia},
keywords = {ASD, synbiotics, probiotics, prebiotics, gut microbiome, open-label, precision, supplements, metagenomics},
abstract = {ABSTRACT

The efficacy of prebiotics and probiotics (synbiotics when combined) to improve symptoms associated with autism spectrum disorder (ASD) has shown considerable inter-study variation, likely due to the complex, heterogeneous nature of the disorder and its associated behavioral, developmental, and gastrointestinal symptoms. Here, we present a precision synbiotic supplementation study in 296 children and adults diagnosed with ASD versus 123 age-matched neurotypical controls. One hundred seventy ASD participants completed the study. Baseline and post-synbiotic assessment of ASD and gastrointestinal (GI) symptoms and deep metagenomic sequencing were performed. Within the ASD cohort, there were significant differences in microbes between subpopulations based on the social responsiveness scale (SRS2) survey (Prevotella spp., Bacteroides, Fusicatenibacter, and others) and gluten and dairy-free diets (Bifidobacterium spp., Lactococcus, Streptococcus spp., and others). At the baseline, the ASD cohort maintained a lower taxonomic alpha diversity and significant differences in taxonomic composition, metabolic pathways, and gene families, with a greater proportion of potential pathogens, including Shigella, Klebsiella, and Clostridium, and lower proportions of beneficial microbes, including Faecalibacterium compared to controls. Following the 3-month synbiotic supplementation, the ASD cohort showed increased taxonomic alpha diversity, shifts in taxonomy and metabolic pathway potential, and improvements in some ASD-related symptoms, including a significant reduction in GI discomfort and overall improved language, comprehension, cognition, thinking, and speech. However, the open-label study design may include some placebo effects. In summary, we found that precision synbiotics modulated the gut microbiome and could be used as supplementation to improve gastrointestinal and ASD-related symptoms.
IMPORTANCE
Autism spectrum disorder (ASD) is prevalent in 1 out of 36 children in the United States and contributes to health, financial, and psychological burdens. Attempts to identify a gut microbiome signature of ASD have produced varied results. The limited pre-clinical and clinical population sizes have hampered the success of these trials. To understand the microbiome associated with ASD, we employed whole metagenomic shotgun sequencing to classify microbial composition and genetic functional potential. Despite being one of the most extensive ASD post-synbiotic assessment studies, the results highlight the complexity of performing such a case–control supplementation study in this population and the potential for a future therapeutic approach in ASD.
Autism spectrum disorder (ASD) is prevalent in 1 out of 36 children in the United States and contributes to health, financial, and psychological burdens. Attempts to identify a gut microbiome signature of ASD have produced varied results. The limited pre-clinical and clinical population sizes have hampered the success of these trials. To understand the microbiome associated with ASD, we employed whole metagenomic shotgun sequencing to classify microbial composition and genetic functional potential. Despite being one of the most extensive ASD post-synbiotic assessment studies, the results highlight the complexity of performing such a case–control supplementation study in this population and the potential for a future therapeutic approach in ASD.}
}
@article{ROSENBAUM2018510,
title = {Stress-related dysfunction of the right inferior frontal cortex in high ruminators: An fNIRS study},
journal = {NeuroImage: Clinical},
volume = {18},
pages = {510-517},
year = {2018},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2018.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S2213158218300561},
author = {David Rosenbaum and Mara Thomas and Paula Hilsendegen and Florian G. Metzger and Florian B. Haeussinger and Hans-Christoph Nuerk and Andreas J. Fallgatter and Vanessa Nieratschker and Ann-Christine Ehlis},
keywords = {Trier Social Stress Test (TSST), Functional near-infrared spectroscopy (fNIRS), Inferior frontal gyrus (IFG), Functional connectivity, Rumination, Cognitive control network (CCN)},
abstract = {Repetitive thinking styles such as rumination are considered to be a key factor in the development and maintenance of mental disorders. Different situational triggers (e.g., social stressors) have been shown to elicit rumination in subjects exhibiting such habitual thinking styles. At the same time, the process of rumination influences the adaption to stressful situations. The study at hand aims to investigate the effect of trait rumination on neuronal activation patterns during the Trier Social Stress Test (TSST) as well as the physiological and affective adaptation to this high-stress situation.
Methods
A sample of 23 high and 22 low ruminators underwent the TSST and two control conditions while their cortical hemodynamic reactions were measured with functional near-infrared spectroscopy (fNIRS). Additional behavioral, physiological and endocrinological measures of the stress response were assessed.
Results
Subjects showed a linear increase from non-stressful control conditions to the TSST in cortical activity of the cognitive control network (CCN) and dorsal attention network (DAN), comprising the bilateral dorsolateral prefrontal cortex (dlPFC), inferior frontal gyrus (IFG) and superior parietal cortex/somatosensory association cortex (SAC). During stress, high ruminators showed attenuated cortical activity in the right IFG, whereby deficits in IFG activation mediated group differences in post-stress state rumination and negative affect.
Conclusions
Aberrant activation of the CCN and DAN during social stress likely reflects deficits in inhibition and attention with corresponding negative emotional and cognitive consequences. The results shed light on possible neuronal underpinnings by which high trait rumination may act as a risk factor for the development of clinical syndromes.}
}
@article{PAVLOVA2024103631,
title = {A dual process model of spontaneous conscious thought},
journal = {Consciousness and Cognition},
volume = {118},
pages = {103631},
year = {2024},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2023.103631},
url = {https://www.sciencedirect.com/science/article/pii/S105381002300168X},
author = {Maria K. Pavlova},
keywords = {Automatic processing, Cognitive control, Executive failure, Involuntary attention, Mental effort, Mind wandering, Meta-awareness, Modality and interference in working memory, Process–occurrence framework, Spontaneous thought},
abstract = {In the present article, I review theory and evidence on the psychological mechanisms of mind wandering, paying special attention to its relation with executive control. I then suggest applying a dual-process framework (i.e., automatic vs. controlled processing) to mind wandering and goal-directed thought. I present theoretical arguments and empirical evidence in favor of the view that mind wandering is based on automatic processing, also considering its relation to the concept of working memory. After that, I outline three scenarios for an interplay between mind wandering and goal-directed thought during task performance (parallel automatic processing, off-task thought substituting on-task thought, and non-disruptive mind wandering during controlled processing) and address the ways in which the mind-wandering and focused-attention spells can terminate. Throughout the article, I formulate empirical predictions. In conclusion, I discuss how automatic and controlled processing may be balanced in human conscious cognition.}
}
@article{GAO2021107161,
title = {Optical waves/modes in a multicomponent inhomogeneous optical fiber via a three-coupled variable-coefficient nonlinear Schrödinger system},
journal = {Applied Mathematics Letters},
volume = {120},
pages = {107161},
year = {2021},
issn = {0893-9659},
doi = {https://doi.org/10.1016/j.aml.2021.107161},
url = {https://www.sciencedirect.com/science/article/pii/S089396592100080X},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Optical waves/modes, Multicomponent inhomogeneous optical fiber, Symbolic computation, Three-coupled variable-coefficient nonlinear Schrödinger system, Similarity reduction, Bäcklund transformation with analytic solutions},
abstract = {Recent progress in optical fibers is impressive, while nonlinear Schrödinger-type models are seen in fiber optics and other fields (such as ferromagnetism, plasma physics, Bose–Einstein condensation and oceanography). Hereby, our symbolic computation on a three-coupled variable-coefficient nonlinear Schrödinger system is performed, for the picosecond-pulse attenuation/amplification in a multicomponent inhomogeneous optical fiber with diverse polarizations/frequencies. For the slowly-varying envelopes of optical modes, we obtain a similarity reduction, an auto-Bäcklund transformation and some analytic solutions, which rely on the optical-fiber variable coefficients, i.e., the fiber loss/gain, nonlinearity and group velocity dispersion. Relevant variable-coefficient constraints are presented. Our results might be of some use in the construction of logic gates, optical computing, soliton switching, design of fiber directional couplers, quantum information processing, soliton amplification in the wavelength division multiplexing systems, solitonic studies in the all-optical devices and birefringence fiber systems.}
}
@article{SHAPIRO2007807,
title = {Bacteria are small but not stupid: cognition, natural genetic engineering and socio-bacteriology},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {38},
number = {4},
pages = {807-819},
year = {2007},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2007.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S1369848607000544},
author = {J.A. Shapiro},
keywords = {Computation, Sensing, Regulation, Cybernetic, Evolution},
abstract = {Forty years’ experience as a bacterial geneticist has taught me that bacteria possess many cognitive, computational and evolutionary capabilities unimaginable in the first six decades of the twentieth century. Analysis of cellular processes such as metabolism, regulation of protein synthesis, and DNA repair established that bacteria continually monitor their external and internal environments and compute functional outputs based on information provided by their sensory apparatus. Studies of genetic recombination, lysogeny, antibiotic resistance and my own work on transposable elements revealed multiple widespread bacterial systems for mobilizing and engineering DNA molecules. Examination of colony development and organization led me to appreciate how extensive multicellular collaboration is among the majority of bacterial species. Contemporary research in many laboratories on cell–cell signaling, symbiosis and pathogenesis show that bacteria utilise sophisticated mechanisms for intercellular communication and even have the ability to commandeer the basic cell biology of ‘higher’ plants and animals to meet their own needs. This remarkable series of observations requires us to revise basic ideas about biological information processing and recognise that even the smallest cells are sentient beings.}
}
@article{SPEER201099,
title = {Collegiate mathematics teaching: An unexamined practice},
journal = {The Journal of Mathematical Behavior},
volume = {29},
number = {2},
pages = {99-114},
year = {2010},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2010.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312310000052},
author = {Natasha M. Speer and John P. Smith and Aladar Horvath},
keywords = {Collegiate mathematics, Teaching practice},
abstract = {Though written accounts of collegiate mathematics teaching exist (e.g., mathematicians’ reflections and analyses of learning and teaching in innovative courses), research on collegiate teachers’ actual classroom teaching practice is virtually non-existent. We advance this claim based on a thorough review of peer-reviewed journals where scholarship on collegiate mathematics teaching is published. To frame this review, we distinguish between instructional activities and teaching practice and present six categories of published scholarship that consider collegiate teaching but are not descriptive empirical research on teaching practice. Empirical studies can reveal important differences among teachers’ thinking and actions, promote discussions of practice, and support learning about teaching. To support such research, we developed a preliminary framework of cognitively oriented dimensions of teaching practice based on our review of empirical research on pre-college and college teaching.}
}
@article{DIPAOLA2014212,
title = {Using a Contextual Focus Model for an Automatic Creativity Algorithm to Generate Art Work},
journal = {Procedia Computer Science},
volume = {41},
pages = {212-219},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.105},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015506},
author = {Steve DiPaola},
keywords = {Evolutionary Systems, Genetic Programming, Contextual Focus, Creativity, Computational Modelling},
abstract = {We sought to implement and determine whether incorporating cognitive based contextual focus into a genetic programming fitness function would play a crucial role in enabling the computer system to generate art that humans find “creative” (i.e. possessing qualities of novelty and aesthetic value typically ascribed to the output of a creative artistic process). We implemented contextual focus in the evolutionary art algorithm by giving the program the capacity to vary its level of fluidity and functional triggered dynamic control over different phases of the creative process. The domain of portrait painting was chosen because it requires both focused attention (analytical thought) to accomplish the primary goal of creating portrait sitter resemblance as well as defocused attention (associative thought) to creativity deviate from resemblance i.e., to meet the broad and often conflicting criteria of aesthetic art. Since judging creative art is subjective, rather than use quantitative analysis, a representative subset of the automatically produced art-work from this system was selected and submitted to many peer reviewed and commissioned art shows, thereby allowing it to be judged positively or negatively as creative by human art curators, reviewers and the art gallery going public.}
}
@article{OUYANG2023101227,
title = {Using an integrated discourse analysis approach to analyze a group's collaborative argumentation},
journal = {Thinking Skills and Creativity},
volume = {47},
pages = {101227},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101227},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122002280},
author = {Fan Ouyang and Zifan Tang and Mengting Cheng and Zixuan Chen},
keywords = {Collaborative argumentation, Collaborative learning, Knowledge construction, Discourse analysis, Informal learning},
abstract = {Collaborative argumentation is widely used in K-12 and higher education to foster students' argumentation skills, facilitate deep learning, and construct collective knowledge. Collaborative argumentation requires students to coordinate their social, cognitive, and metacognitive practices with peers through interactive discourses. Discourse analysis is a traditional analytic method that has been used to understand collaborative discourses. But most previous research has either integrated computational or statistical techniques to analyze frequencies of discourses or analyzed discourse from a qualitative perspective to demonstrate the microlevel, fine-grained attributes. There has been a lack of integrated discourse analysis method to holistically investigate and understand collaborative argumentation. To fill this gap, this case study used the scripted role strategy to support a group's collaborative argumentation and proposed an integrated discourse analysis approach to illustrate the temporal changes of the group's discourse moves, structures, and turn taking processes. The results showed that four participants had different discourse attributes. Based on the results, pedagogical and analytical implications are proposed to facilitate research and practice of collaborative argumentation.}
}
@article{LAU2017241,
title = {The many worlds hypothesis of dopamine prediction error: implications of a parallel circuit architecture in the basal ganglia},
journal = {Current Opinion in Neurobiology},
volume = {46},
pages = {241-247},
year = {2017},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2017.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959438817301587},
author = {Brian Lau and Tiago Monteiro and Joseph J Paton},
abstract = {Computational models of reinforcement learning (RL) strive to produce behavior that maximises reward, and thus allow software or robots to behave adaptively [1]. At the core of RL models is a learned mapping between ‘states’—situations or contexts that an agent might encounter in the world—and actions. A wealth of physiological and anatomical data suggests that the basal ganglia (BG) is important for learning these mappings [2, 3]. However, the computations performed by specific circuits are unclear. In this brief review, we highlight recent work concerning the anatomy and physiology of BG circuits that suggest refinements in our understanding of computations performed by the basal ganglia. We focus on one important component of basal ganglia circuitry, midbrain dopamine neurons, drawing attention to data that has been cast as supporting or departing from the RL framework that has inspired experiments in basal ganglia research over the past two decades. We suggest that the parallel circuit architecture of the BG might be expected to produce variability in the response properties of different dopamine neurons, and that variability in response profile may not reflect variable functions, but rather different arguments that serve as inputs to a common function: the computation of prediction error.}
}
@article{GOSWAMI2024111921,
title = {Real-time evaluation of object detection models across open world scenarios},
journal = {Applied Soft Computing},
volume = {163},
pages = {111921},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111921},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624006951},
author = {Puneet Goswami and Lakshita Aggarwal and Arun Kumar and Rahul Kanwar and Urvi Vasisht},
keywords = {Computer vision, Faster R-CNN, DETR, YOLO, Resnet 50, Resnet 101, Object detection, Model comparison, Evaluation metrices},
abstract = {Object detection models have been experiencing significant improvements over the years due to advancements in deep learning techniques, increased availability of large-scale annotated datasets, and computational resources. Different object detection models have varying levels of accuracy, speed, and robustness. With the increasing complexity and diversity of object detection models, it becomes a problem for researchers and practitioners to choose the most suitable model for their specific needs. This research paper outlines the escalating demand for robust comparison of object detection models in response to rapidly advancing technology. This evaluation helps in identifying the strengths and weaknesses of these models and selecting the most suitable one for a specific task. This highlights a significant challenge stemming from the lack of recent comparative studies on object detection models across various image qualities, object sizes, and training data sizes. The above challenges are tackled by a meticulous evaluation of three state-of-the-art object detection models: YOLO-v8, Faster R-CNN with ResNet 50 and 101 backbones, and End-to-End Object Detection Transformers (DETR) utilizing ResNet 50 and 101 backbones by employing a rigorous assessment framework encompassing mean Average Precision (mAP), accuracy, and inference speed. This study focuses on thoroughly examining how well the models perform across three different datasets: TACO, PlastOPol, and TACO 4.5. These datasets consist of open-world images captured in real-time from various locations. They include 1500, 2500, and 6500 images respectively, depicting real-world environments with varying lighting conditions and complex backgrounds. The results identify YOLOv8 as the superior model for high and medium-quality images, while Faster R-CNN performs better for low-quality images. However, DETR's accuracy falls short compared to other models. The paper fills a crucial gap in understanding model performance across varying image qualities and object sizes and helps in taking informed decisions in object detection systems.}
}