@article{XU2024167,
title = {Towards carbon neutrality in China: A systematic identification of China's sustainable land-use pathways across multiple scales},
journal = {Sustainable Production and Consumption},
volume = {44},
pages = {167-178},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S235255092300283X},
author = {Zhenci Xu},
keywords = {Carbon neutrality, Land use, Multi-scales, System thinking, China},
abstract = {Sustainable land use is crucial for achieving Carbon Neutrality goals, which requires a scientific identification of optimized pathways for land use patterns across multiple scales. Yet, current land use studies predominantly focus on single scales but lack system thinking and fail to establish complementary cross-regional carbon neutrality collaboration schemes. Applying life-cycle thinking to analyze land use sustainability and carbon neutrality potential at multiple scales could address this challenge. This study aims to present China's first multi-scale spatiotemporal optimization pathway for sustainable land use to improve carbon neutrality potential. It systematically integrates the complex spatial coupling relationships between land use intensity and efficiency. We integrate multi-scale sustainable land use pathways, spanning grid, basin, and administrative levels, and unveil significant variations in land use sustainability and carbon neutrality potential across China. Sixty-three percent of China's land is in low sustainability, and the overall carbon neutrality potential in China is relatively low, with regions accounting for <30 % facing more carbon neutrality missions. Implementing sequential and partitioned governance modes can effectively support China in achieving sustainable land use and advancing Carbon Neutrality goals. Our sustainable land use pathways for China provide valuable insights for systematically undertaking carbon neutrality actions across different scales.}
}
@article{SUPPES2004457,
title = {Semantic computations of truth based on associations already learned},
journal = {Journal of Applied Logic},
volume = {2},
number = {4},
pages = {457-467},
year = {2004},
note = {CMSRA},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2004.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1570868304000461},
author = {Patrick Suppes and Jean-Yves Béziau},
keywords = {Truth, Computaton, Empirical statements, Associative networks, Spreading activation},
abstract = {This article sets forth a detailed theoretical proposal of how the truth of ordinary empirical statements, often atomic in form, is computed. The method of computation draws on psychological concepts such as those of associative networks and spreading activation, rather that the concepts of philosophical or logical theories of truth. Axioms for a restricted class of cases are given, as well as some detailed examples.}
}
@article{WANG20098093,
title = {A computational narrative construction method with applications in organizational learning of social service organizations},
journal = {Expert Systems with Applications},
volume = {36},
number = {4},
pages = {8093-8102},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2008.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417408007495},
author = {W.M. Wang and C.F. Cheung and W.B. Lee and S.K. Kwok},
keywords = {Narrative construction, Knowledge management, Concept mapping, Knowledge-based systems, Computational, Reflective learning, Narrative simulation},
abstract = {Acquisition of knowledge must be interwoven with the process of applying it. However, traditional training methods which provide abstract knowledge have shown ineffective for gaining experience of the work. In order to solve this problem, more and more researchers have included narrative in simulation, which is known as narrative simulation. By providing the narratives, participants recognize the choices, decisions, and experience that lead to the consequences of those decisions. It has been proven that narrative simulation is very useful in facilitating in-depth learning and reflective learning. However, conventional methods of data collection and narrative construction for narrative simulation are labor intensive and time consuming. They make use of previous narratives manually and directly. They are inadequate to cope with the fast moving world where knowledge is changing rapidly. In order to provide a way for facilitating the construction of narrative simulation, a novel computational narrative construction method is proposed. By incorporating technologies of knowledge-based system (KBS), computational linguistics, and artificial intelligence (AI), the proposed method provides an efficient and effective way for collecting narratives and automating the construction of narratives. The method converts the unstructured narratives into a structural representation for abstraction and facilitating computing processing. Moreover, it constructs the narratives that combine multiple narratives into a single narrative by applying a forecasting algorithm. The proposed method was successfully implemented in early intervention in mental health care of a social service company in Hong Kong since the case records in that process have structural similarities to narrative. The accuracies of data conversion and predictive function were measured based on recall and precision and encouraging results were obtained. High recall and precision are achieved in the data conversion function, and high recall for the predictive function when new concepts are excluded. The results show that it is possible for converting multiple narratives into a single narrative automatically. Based on the approach, it helps to stimulate knowledge workers to explore new problem solving methods so as to increase the quality of their solutions.}
}
@article{USMANI20241044,
title = {The Digital Age: Exploring the Intersection of AI/CI and Human Cognition and Social Interactions},
journal = {Procedia Computer Science},
volume = {239},
pages = {1044-1052},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.268},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015114},
author = {Usman Ahmad Usmani and Ari Happonen and Junzo Watada},
keywords = {Artificial intelligence, Computational intelligence, Digitalization, Digital transformation, Human cognition, Social interaction, Industry 4.0, Digital capability, Social transformation, Human computer interaction},
abstract = {Although solutions based on artificial and computational intelligence have made life easier, the fast development of technology also raises questions about near future and log term human cognition and social interaction. Through a survey of the literature and qualitative analysis, our work examined current research on how the AI/CI affects human cognitive functions and social interactions. We discuss how AI and CI are influencing e.g. how we humans gather information, build relationships, and communicate with others, with and without the new frontline technologies. Additionally, proposals for future advances are discussed along with the ethical and societal ramifications these technologies have, could and might bring into our lives. We think that by developing a deeper knowledge of how AI/CI affects human cognition and social interaction, new contributions are made to a positive conversation and encourage a responsible approach to incorporating new technologies into our daily lives.}
}
@incollection{HOLCOMBE2005407,
title = {30 Computational modelling of creativity in abstract art},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {407-424},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80058-3},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800583},
author = {Mike Holcombe and Samantha Smith and Rowan Merewood and Andy Swingeford},
abstract = {Artistic creativity is studied through the construction of computational models of a number of well-known modern artists. In particular, the work of Piet Mondrian, M.C. Escher and Paul Klee are suitable vehicles for investigation since their work is accompanied by extensive writings describing the ideas and motivation behind their compositions. In particular, we have tried to abstract from their theories, rules that describe the construction process or the properties that their finished artefacts posses in order to create software programs that can articulate these rules. In this way, we are able to simulate either automatically or with user interaction, the process of creating works of art of a similar genre and satisfying the properties desired by the artist. Since the rules are bound to be considerably more complex than those currently exposed, we are looking to use machine-learning techniques to develop more sophisticated agents, which may behave more closely like the actual artist.}
}
@article{PAL20133944,
title = {Title Paper: Natural computing: A problem solving paradigm with granular information processing},
journal = {Applied Soft Computing},
volume = {13},
number = {9},
pages = {3944-3955},
year = {2013},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2013.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S1568494613002159},
author = {Sankar K. Pal and Saroj K. Meher},
keywords = {Natural computing, Granular computing, Soft computing, Hybrid model, Decision systems},
abstract = {Natural computing, inspired by biological course of action, is an interdisciplinary field that formalizes processes observed in living organisms to design computational methods for solving complex problems, or designing artificial systems with more natural behaviour. Based on the tasks abstracted from natural phenomena, such as brain modelling, self-organization, self-repetition, self evaluation, Darwinian survival, granulation and perception, nature serves as a source of inspiration for the development of computational tools or systems that are used for solving complex problems. Nature inspired main computing paradigms used for such development include artificial neural networks, fuzzy logic, rough sets, evolutionary algorithms, fractal geometry, DNA computing, artificial life and granular or perception-based computing. Information granulation in granular computing is an inherent characteristic of human thinking and reasoning process performed in everyday life. The present article provides an overview of the significance of natural computing with respect to the granulation-based information processing models, such as neural networks, fuzzy sets and rough sets, and their hybridization. We emphasize on the biological motivation, design principles, application areas, open research problems and challenging issues of these models.}
}
@article{WANG202428,
title = {Exploring the interplay between core and mood symptoms in schizophrenia: A network analysis},
journal = {Schizophrenia Research},
volume = {269},
pages = {28-35},
year = {2024},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2024.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0920996424001695},
author = {Yucheng Wang and Yixiao Xu and Peiyi Wu and Yang Zhou and Huanrui Zhang and Zijia Li and Yanqing Tang},
keywords = {Schizophrenia, Core symptoms, Mood symptoms, Network analysis, Symptom interactions},
abstract = {Background
Schizophrenia is a complex neuropsychiatric disorder characterized by positive symptoms, negative symptoms, cognitive deficits, and co-occurring mood symptoms. Network analysis offers a novel approach to investigate the intricate relationships between these symptom dimensions, potentially informing personalized treatment strategies.
Methods
A cross-sectional study was conducted from November 2019 to October 2021, involving 1285 inpatients with schizophrenia in Liaoning Province, China. Symptom severity was assessed using the Positive and Negative Syndrome Scale (PANSS), Hamilton Depression Rating Scale (HAMD-17), Hamilton Anxiety Rating Scale (HAMA-14), and Montreal Cognitive Assessment (MoCA). Network analysis was conducted to investigate the network structure, central symptoms, and bridge symptoms.
Results
The network analysis uncovered profound interconnectivity between core symptoms and the anxiety-depression community. Central symptoms, such as psychic anxiety, poor rapport, delusions, and attention, were identified as potential therapeutic targets. Bridge symptoms, including insomnia, depressed mood, anxiety-somatic, conceptual disorganization, and stereotyped thinking, emerged as key nodes facilitating interactions between symptom communities. The stability and reliability of the networks were confirmed through bootstrapping procedures.
Discussion
The findings highlight the complex interplay between schizophrenia symptoms, emphasizing the importance of targeting affective symptoms and cognitive impairment in treatment. The identification of central and bridge symptoms suggests potential pathways for personalized interventions aimed at disrupting self-reinforcing symptom cycles. The study underscores the need for a transdiagnostic, personalized approach to schizophrenia treatment.}
}
@article{PEREZRIVEROL2013134,
title = {Computational proteomics pitfalls and challenges: HavanaBioinfo 2012 Workshop report},
journal = {Journal of Proteomics},
volume = {87},
pages = {134-138},
year = {2013},
issn = {1874-3919},
doi = {https://doi.org/10.1016/j.jprot.2013.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S1874391913000493},
author = {Yasset Perez-Riverol and Henning Hermjakob and Oliver Kohlbacher and Lennart Martens and David Creasy and Jürgen Cox and Felipe Leprevost and Baozhen Paul Shan and Violeta I. Pérez-Nueno and Michal Blazejczyk and Marco Punta and Klemens Vierlinger and Pedro A. Valiente and Kalet Leon and Glay Chinea and Osmany Guirola and Ricardo Bringas and Gleysin Cabrera and Gerardo Guillen and Gabriel Padron and Luis Javier Gonzalez and Vladimir Besada},
keywords = {Bioinformatics workshop, Mass spectrometry, Course, Protein identification, Database searching, Proteomic repositories},
abstract = {The workshop “Bioinformatics for Biotechnology Applications (HavanaBioinfo 2012)”, held December 8–11, 2012 in Havana, aimed at exploring new bioinformatics tools and approaches for large-scale proteomics, genomics and chemoinformatics. Major conclusions of the workshop include the following: (i) development of new applications and bioinformatics tools for proteomic repository analysis is crucial; current proteomic repositories contain enough data (spectra/identifications) that can be used to increase the annotations in protein databases and to generate new tools for protein identification; (ii) spectral libraries, de novo sequencing and database search tools should be combined to increase the number of protein identifications; (iii) protein probabilities and FDR are not yet sufficiently mature; (iv) computational proteomics software needs to become more intuitive; and at the same time appropriate education and training should be provided to help in the efficient exchange of knowledge between mass spectrometrists and experimental biologists and bioinformaticians in order to increase their bioinformatics background, especially statistics knowledge.}
}
@incollection{YANG20161,
title = {Chapter 1 - Bio-inspired computation and its applications in image processing: an overview},
editor = {Xin-She Yang and João Paulo Papa},
booktitle = {Bio-Inspired Computation and Applications in Image Processing},
publisher = {Academic Press},
pages = {1-24},
year = {2016},
isbn = {978-0-12-804536-7},
doi = {https://doi.org/10.1016/B978-0-12-804536-7.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128045367000016},
author = {X.-S. Yang and J.P. Papa},
keywords = {algorithm, ant algorithm, artificial neural networks, bee algorithm, bat algorithm, bio-inspired computation, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, metaheuristics, swarm intelligence, support vector machine, signal and image processing},
abstract = {Almost all design problems in the sciences and engineering can be formulated as optimization problems, and many image processing problems can also be related to or formulated as optimization problems. These optimization problems can be solved by optimization techniques. However, these problems are often highly nonlinear and are subject to multiple nonlinear constraints, which makes them very challenging to solve. The further complication to these challenges is the stringent time requirements and high dimensionality, which means that traditional optimization techniques, such as gradient-based methods cannot deal with such kinds of problems well. Recent trends tend to use bio-inspired optimization techniques as a promising alternative, and it is usually combined with traditional methods, especially in the area of image processing. These bio-inspired computational methods are usually based on swarm intelligence and can be very effective in coping with nonlinearity in real-world problems. This chapter presents an overview of bio-inspired computation and its application in image processing, including some current trends and important issues, such as efficiency and time constraints.}
}
@article{AUSTIN2006544,
title = {Matrix and finite element stack machines for structural engineering computations with units},
journal = {Advances in Engineering Software},
volume = {37},
number = {8},
pages = {544-559},
year = {2006},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2005.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0965997805001833},
author = {Mark A. Austin},
keywords = {Stack machine, Matrix computations, Physical units, Scripting language design, Finite element analysis},
abstract = {Despite the well known benefits of physical units, matrices, and matrix algebra in engineering computations, most engineering analysis packages are essentially dimensionless. This paper describes the design and implementation of matrix and finite element stack machines for Aladdin, a new computational environment that embeds units inside matrix and finite element calculations. Functionality of the Aladdin stack machine is illustrated by working step by step through the setup and execution of three examples: (1) Parsing and stack machine execution for x=2in; (2) Deflection analysis of a cantilever beam, and (3) Rollup maneuver for a long cantilever beam.}
}
@article{GENT202336,
title = {Computing comes to life},
journal = {New Scientist},
volume = {258},
number = {3442},
pages = {36-39},
year = {2023},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(23)01054-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407923010540},
author = {Edd Gent},
abstract = {Nature is capable of astonishing feats of computation. Now, we are re-engineering molecules, cells and even whole organisms into living processors, says Edd Gent}
}
@incollection{VANCOUVER2020463,
title = {Chapter 12 - Perceptions of control theory in industrial-organizational psychology: disturbances and counter-disturbances},
editor = {Warren Mansell},
booktitle = {The Interdisciplinary Handbook of Perceptual Control Theory},
publisher = {Academic Press},
pages = {463-501},
year = {2020},
isbn = {978-0-12-818948-1},
doi = {https://doi.org/10.1016/B978-0-12-818948-1.00012-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128189481000125},
author = {Jeffrey B. Vancouver},
keywords = {Control theory, Self-regulation, Self-efficacy, Computational modeling},
abstract = {The history of perceptual control theory's growing influence in the field of Industrial-Organizational Psychology is described. This history began in the early 1980's and included mostly conceptual work that described how control theory concepts might be used to understand applied phenomena. Both conceptual and empirical work on control theory ideas continued throughout the 1990's despite a substantial backlash against the theory by prominent scholars in the field. However, it was conceptual and empirical work in the 21st century that defined its potential integrative value and its theoretical rigor. Moreover, research regarding self-efficacy demonstrated how informal theories of human behavior might be better understood from a control theory perspective. Much of the current work with perceptual control theory involves the construction and testing of computational models that represent the links among perceptual, learning, and thinking modes of self-regulation and control.}
}
@article{SAND2022100955,
title = {Three cases that demonstrate how students connect the domains of mathematics and computing},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100955},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100955},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000232},
author = {Odd Petter Sand and Elise Lockwood and Marcos D. Caballero and Knut Mørken},
keywords = {Computing, Modeling, Programming, Thinking and learning, Connections, Undergraduate students},
abstract = {This study uses actor-oriented transfer perspective to investigate different ways in which students make connections across the domains of mathematics and computing. We interview first-year students at the University of Oslo as they work with a set of tutorials that we designed to integrate knowledge from both domains. The cases we present here demonstrate four different types of cross-domain connections: (a) mathematically reproducing the work of a computer program, (b) cyclically improving a program to produce better output, (c) coupling math to output to justify program improvements and (d) coupling math to code to justify program design. We provide rich examples of the ways in which students make these connections and discuss affordances for mathematical learning in this context.}
}
@article{PEREZLOPEZ2024105162,
title = {Cartographic analysis as spatial determinant for climate change adaptation in the Hunter River Estuary, Australia},
journal = {Cities},
volume = {152},
pages = {105162},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105162},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003767},
author = {Irene {Perez Lopez} and Sandra Carrasco and Cesar {Mariscal Madrigal}},
keywords = {Ecological design, Estuary urbanism, Climate adaptation, Living infrastructures, Hunter River Australia},
abstract = {This paper explores the hydrological history of the Hunter River and Estuary (Newcastle, Australia), to identify pathways for incorporating climate-sensitive adaptation approaches into urban development and planning. The research method utilises mapping as a methodological discovery tools to visually articulate the correlation of pre-colonial hydrological landscapes, the transformation of the estuary over two centuries, the areas identified as at risk, and the opportunities for developing a climate-resilient estuary. This research aims to contribute to the redefinition of the discourse on the role of estuary planning for changing climate, focusing on four critical aspects: identify the impacts of urbanisation and industrialisation on ecosystems and its correlation with climate hazard at the estuary; visualise such transformations over time and space to identify critical spatial and climate factors threatening inhabitation; propose strategic spatial practices towards adaptation and resilience; and synthesising the options to foster reflective thinking and establish a correlation with novel policies, governance and practices. The study highlights that adopting new urbanism aligned with cultural and ecological principles can mitigate future climate impacts through re-naturalisation and urban adaptation to sea-level rise by focusing on proactive approaches to building resilient communities. This paper also acknowledges the need for site-specific adaptive design and planning strategies at multiple scales and governance levels.}
}
@article{TSAI202371,
title = {Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {71-95},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000180},
author = {Meng-Lin Tsai and Chong Wei Ong and Cheng-Liang Chen},
keywords = {Engineering education, Industry 4.0 skill, Programming in chemical engineering, Problem-solving, Large language models (LLMs), Chat-GPT},
abstract = {This study highlights the potential benefits of integrating Large Language Models (LLMs) into chemical engineering education. In this study, Chat-GPT, a user-friendly LLM, is used as a problem-solving tool. Chemical engineering education has traditionally focused on fundamental knowledge in the classroom with limited opportunities for hands-on problem-solving. To address this issue, our study proposes an LLMs-assisted problem-solving procedure. This approach promotes critical thinking, enhances problem-solving abilities, and facilitates a deeper understanding of core subjects. Furthermore, incorporating programming into chemical engineering education prepares students with vital Industry 4.0 skills for contemporary industrial practices. During our experimental lecture, we introduced a simple example of building a model to calculate steam turbine cycle efficiency, and assigned projects to students for exploring the possible use of LLMs in solving various aspect of chemical engineering problems. Although it received mixed feedback from students, it was found to be an accessible and practical tool for improving problem-solving efficiency. Analyzing the student projects, we identified five common difficulties and misconceptions and provided helpful suggestions for overcoming them. Our course has limitations regarding using advanced tools and addressing complex problems. We further provide two additional examples to better demonstrate how to integrate LLMs into core courses. We emphasize the importance of universities, professors, and students actively embracing and utilizing LLMs as tools for chemical engineering education. Students must develop critical thinking skills and a thorough understanding of the principles behind LLMs, taking responsibility for their use and creations. This study provides valuable insights for enhancing chemical engineering education's learning experience and outcomes by integrating LLMs.}
}
@article{MOSTAFA20118782,
title = {A neuro-computational intelligence analysis of the global consumer software piracy rates},
journal = {Expert Systems with Applications},
volume = {38},
number = {7},
pages = {8782-8803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2011.01.090},
url = {https://www.sciencedirect.com/science/article/pii/S0957417411001102},
author = {Mohamed M. Mostafa},
keywords = {Global software piracy, Ethical behavior, Neural networks, Bayesian regression, Evolutionary computation models},
abstract = {Software piracy represents a major damage to the moral fabric associated with the respect of intellectual property. The rate of software piracy appears to be increasing globally, suggesting that additional research that uses new approaches is necessary to evaluate the problem. The study remedies previous econometric and methodological shortcomings by applying Bayesian, robust and evolutionary computation robust regression algorithms to formally test empirical literature on software piracy. To gain further insights into software piracy at the global level, the study also uses five neuro-computational intelligence methodologies: multi-layer perceptron neural network (MLP), probabilistic neural network (PNN), radial basis function neural network (RBF), generalized regression neural network (GRNN) and Kohonen’s self-organizing maps (SOM) to classify, predict and cluster software piracy rates among 102 nations. At the empirical level, this research shows that software piracy is significantly affected by the wealth of nation as measured by gross domestic product (GDP), the nation’s expenditure on research and development and the nation’s judicial efficiency. At the methodological level, this research shows that neuro-computational models outperform traditional statistical techniques such as regression analysis, discriminant analysis and cluster analysis in predicting, classifying and clustering software piracy rates due to their robustness and flexibility of modeling algorithms.}
}
@article{KLEIN2014437,
title = {Computation and Visualization of Patch Geometries for the Design of Carbon Fiber Reinforced Parts at Early Design Stages},
journal = {Procedia CIRP},
volume = {21},
pages = {437-442},
year = {2014},
note = {24th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2014.03.133},
url = {https://www.sciencedirect.com/science/article/pii/S2212827114006738},
author = {Daniel Klein and Kaja Scheler and Sandro Wartzack},
keywords = {Lightweight design, Early design stages, Endless fibre reinforced composites},
abstract = {The market for carbon fibers is forecast to experience a double-digit growth over the next years. The reason for this development can be found in the special characteristics of Carbon Fiber Reinforced Plastics (CFRP) like high stiffness and strength at very low weight which make this composite an ideal material for lightweight design. However, the design of parts made of CFRP is a tightrope walk between costs, mechanical characteristics and manufacturability for product developers. On the one hand, the mechanical properties are highly dependent on the ideal fiber orientation within the part and the unique material characteristics can only be exploited with a suitable fiber orientation, but on the other hand, the ideal fiber orientation is often not manufacturable or the required manufacturing technique is too expensive. Therefore, a novel algorithm to support product developers in finding a manufacturable fiber orientation or patch layout which is as close as possible to the ideal fiber orientation is introduced. This algorithm computes and highlights areas with constant fiber orientation (=cluster) based upon the ideal fiber alignment from the CAIO method. With the help of the visualization of the clusters, product developers can be supported in the decision for the best patch placement and geometry as well as in choosing the best manufacturing technique. It is important to point out that the algorithm is intended for endless fiber reinforced parts only.}
}
@article{TESCH2001633,
title = {Applying optimal control theory for elements of quantum computation in molecular systems},
journal = {Chemical Physics Letters},
volume = {343},
number = {5},
pages = {633-641},
year = {2001},
issn = {0009-2614},
doi = {https://doi.org/10.1016/S0009-2614(01)00748-5},
url = {https://www.sciencedirect.com/science/article/pii/S0009261401007485},
author = {Carmen M. Tesch and Lukas Kurtz and Regina {de Vivie-Riedle}},
abstract = {Elements of quantum computation are implemented in a vibrationally excited molecule applying optimal control theory. The two different IR-active modes of acetylene are taken as a two-qubit-system. Optimal control theory is used to design laser pulses that allow transitions within each qubit separately. Calculations for initial state preparation and basic quantum gates are presented.}
}
@article{OLTETEANU201581,
title = {comRAT-C: A computational compound Remote Associates Test solver based on language data and its comparison to human performance},
journal = {Pattern Recognition Letters},
volume = {67},
pages = {81-90},
year = {2015},
note = {Cognitive Systems for Knowledge Discovery},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2015.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0167865515001609},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Computational creativity, Remote Associates Test, Cognitive systems, Knowledge base, Language corpus, Cognitive modeling},
abstract = {Discovering the processes and types of knowledge organization which are involved in the creative process is a challenge up to this date. Human creativity is usually measured by psychological tests, such as the Remote Associates Test (RAT). In this paper, an approach based on a specific type of knowledge organization and processes which enables automatic solving of RAT queries is implemented (comRAT) as a part of a more general cognitive theoretical framework for creative problem-solving (CreaCogs). This aims to study: (a) whether a convergence process can be used to solve such queries and (b) if frequency of appearance of the test items in language data may influence knowledge association or discovery in solving such problems. The comRAT uses a knowledge base of language data extracted from the Corpus of Contemporary American English. The results obtained are compared to results obtained in empirical tests with humans. In order to explain why some answers might be preferred over others, frequencies of appearance of the queries and solutions are analyzed. The difficulty encountered by humans when solving RAT queries is expressed in response times and percentage of participants solving the query, and a significant moderate correlation between human data on query difficulty and the data provided by this approach is obtained.}
}
@article{PROSPERETTI20031089,
title = {Appendix 3: Report of study group on computational physics},
journal = {International Journal of Multiphase Flow},
volume = {29},
number = {7},
pages = {1089-1099},
year = {2003},
issn = {0301-9322},
doi = {https://doi.org/10.1016/S0301-9322(03)00081-8},
url = {https://www.sciencedirect.com/science/article/pii/S0301932203000818},
author = {Andrea Prosperetti and Grétar Tryggvason},
keywords = {Computational multiphase flow, Direct numerical simulations, Numerical methods},
abstract = {The great improvement of algorithms and computing hardware in the last few years must be ranked as one of the most important turning points in the history of multiphase flow research. After a brief review of some of this recent progress, it is pointed out that, besides its application to solving actual problems, computational physics plays other key roles: (1) As a tool to develop and understand basic physics and as a guide toward asking more penetrating questions; (2) As an aid in closing the averaged equations; (3) As a means to learn to compute better. Roadblocks toward greater effectiveness are the huge complexity of many of the necessary computational tasks but also, at a more practical level, the transmission of “computational knowledge” from one researcher to another, much in the same way as experimentalists can rely on readily available equipment (e.g., lasers, etc.), without having to build each item themselves. The solution to this problem will require a cultural shift––from a “cottage industry” to a “big science” mentality––which can be aided by a different attitude on the part of the funding agencies. Great synergism can be achieved by a closer integration of the multiphase computational physics enterprise with both Applied Mathematics and Computer Science.}
}
@article{DAUCE20101,
title = {Computational neuroscience, from multiple levels to multi-level},
journal = {Journal of Physiology-Paris},
volume = {104},
number = {1},
pages = {1-4},
year = {2010},
note = {Computational Neuroscience, from Multiple Levels to Multi-level},
issn = {0928-4257},
doi = {https://doi.org/10.1016/j.jphysparis.2009.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0928425709000837},
author = {Emmanuel Daucé and Laurent Perrinet}
}
@article{DANOS200773,
title = {Distributed Measurement-based Quantum Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {170},
pages = {73-94},
year = {2007},
note = {Proceedings of the 3rd International Workshop on Quantum Programming Languages (QPL 2005)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2006.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1571066107000564},
author = {Vincent Danos and Ellie D'Hondt and Elham Kashefi and Prakash Panangaden},
keywords = {Formal language, quantum communication, quantum computing, semantics},
abstract = {We develop a formal model for distributed measurement-based quantum computations, adopting an agent-based view, such that computations are described locally where possible. Because the network quantum state is in general entangled, we need to model it as a global structure, reminiscent of global memory in classical agent systems. Local quantum computations are described as measurement patterns. Since measurement-based quantum computation is inherently distributed, this allows us to extend naturally several concepts of the measurement calculus [V. Danos, E. Kashefi and P. Panangaden, The measurement calculus (2004), arXiv:quant-ph/0412135], a formal model for such computations. Our goal is to define an assembly language, i.e. we assume that computations are well-defined and we do not concern ourselves with verification techniques. The operational semantics for systems of agents is given by a probabilistic transition system, and we define operational equivalence in a way that it corresponds to the notion of bisimilarity. With this in place, we prove that teleportation is bisimilar to a direct quantum channel, and this also within the context of larger networks.}
}
@article{CORDASCO201152,
title = {Efficient on-line algorithms for Euler diagram region computation},
journal = {Computational Geometry},
volume = {44},
number = {1},
pages = {52-68},
year = {2011},
issn = {0925-7721},
doi = {https://doi.org/10.1016/j.comgeo.2010.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925772110000581},
author = {Gennaro Cordasco and Rosario {De Chiara} and Andrew Fish},
keywords = {Euler diagrams, Region computation, Diagram generation},
abstract = {Euler diagrams are an accessible and effective visualisation of data involving simple set-theoretic relationships. Sets are represented by closed curves in the plane and often have wellformedness conditions placed on them in order to enhance comprehensibility. The theoretical underpinning for tool support has usually focussed on the problem of generating an Euler diagram from an abstract model. However, the problem of efficient computation of the abstract model from the concrete diagram has not been addressed before, despite this computation being a necessity for computer interpretations of user drawn diagrams. This may be used, together with automated manipulations of the abstract model, for purposes such as semantic information presentation or diagrammatic theorem proving. Furthermore, in interactive settings, the user may update diagrams “on-line” by adding and removing curves, for example, in which case a system requirement is the update of the abstract model (without the necessity of recomputation of the entire abstract model). We define the notion of marked Euler diagrams, together with a method for associating marked points on the diagram with regions in the plane. Utilising these, we provide on-line algorithms which quickly compute the abstract model of a weakly reducible wellformed Euler diagram (constructible as a sequence of additions or removals of curves, keeping a wellformed diagram at each step), and quickly updates both the set of curves in the plane as well as the abstract model according to the on-line operations. Efficiency is demonstrated by comparison with a common, naive algorithm. Furthermore, the methodology enables a straightforward implementation which has subsequently been realised as an application for the user classification domain.}
}
@article{BANDOPADHAYA2020100378,
title = {Integrated healthcare monitoring solutions for soldier using the internet of things with distributed computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {26},
pages = {100378},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2020.100378},
url = {https://www.sciencedirect.com/science/article/pii/S2210537919304081},
author = {Shuvabrata Bandopadhaya and Rajiv Dey and Ashok Suhag},
keywords = {Healthcare monitoring system, Internet of things (IoT), Distributed computing, Fuzzy classification, Partten recognistion, Long Range wide area network (LoRaWAN)},
abstract = {This paper has proposed an integrated healthcare monitoring solution for the soldiers deployed in adverse environmental conditions, using the internet of things (IoT) with distributed computing. For these soldiers, the health parameters of every individual need to be monitored on a real-time basis and subsequent analysis of the dataset to be made for initiating appropriate medical support with the lowest possible delay. In this paper, a three-layer service-oriented IoT architecture has been proposed where the computational functionalities are distributed among all the layers. The proposed distributed computing mechanism has implemented two levels of filtration of redundant information that belongs to safe soldiers. The first level of filtering is done at the end-node using the Fuzzy classification approach and the second level of filtering is done at the intermediate node using the time-series pattern analysis approach. This layer-wise filtration process results in a reduction in data flooding and computational burden on the cloud due to which system response time improves to suit emergency applications. A prototype has been developed to validate the effectiveness of the proposed solution.}
}
@article{PAPAIOANNOU2021e07984,
title = {Complexity analysis of the brain activity in Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD) due to cognitive loads/demands induced by Aristotle's type of syllogism/reasoning. A Power Spectral Density and multiscale entropy (MSE) analysis},
journal = {Heliyon},
volume = {7},
number = {9},
pages = {e07984},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e07984},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021020879},
author = {Anastasia G. Papaioannou and Eva Kalantzi and Christos C. Papageorgiou and Kalliopi Korombili and Anastasia Βokou and Artemios Pehlivanidis and Charalabos C. Papageorgiou and George Papaioannou},
keywords = {Multiscale entropy, Power Spectral Density, Aristotle's syllogism, ASD-ADHD, Systems of thinking I&II, Cognitive load},
abstract = {Objective
We aim to investigate whether EEG dynamics differ in adults with ASD (Autism Spectrum Disorders), ADHD (attention-deficit/hyperactivity disorder), compared with healthy subjects during the performance of an innovative cognitive task: Aristotle's valid and invalid syllogisms. We follow the Neuroanatomical differences type of criterion in assessing the results of our study in supporting or not the dual-process theory of Kahneman, 2011) (Systems I & II of thinking).
Method
We recorded EEGs from 14 scalp electrodes in 30 adults with ADHD, 30 with ASD and 24 healthy, normal subjects. The subjects were exposed in a set of innovative cognitive tasks (inducing varying cognitive loads), the Aristotle's four types of syllogism mentioned above. The multiscale entropy (MSE), a nonlinear information-theoretic measure or tool was computed to extract features that quantify the complexity of the EEG.
Results
The dynamics of the curves of the grand average of MSE values of the ADHD and ASD participants was significantly in higher levels for the majority of time scales, than the healthy subjects over a number of brain regions (electrodes locations), during the performance of both valid and invalid types of syllogism. This result is seemingly not in accordance of the broadly accepted ‘theory’ of complexity loss in ‘pathological’ subjects, but actually this is not the case as explained in the text. ADHD subjects are engaged in System II of thinking, for both Valid and Invalid syllogism, ASD and Control in System I for valid and invalid syllogism, respectively. A surprising and ‘provocative’ result of this paper, as shown in the next sections, is that the Complexity-variability of ASD and ADHD subjects, when they face Aristotle's types of syllogisms, is higher than that of the control subjects. An explanation is suggested as described in the text. Also, in the case of invalid type of Aristotelian syllogisms, the linguistic and visuo-spatial systems are both engaged ONLY in the temporal and occipital regions of the brain, respectively, of ADHD subjects. In the case of valid type, both above systems are engaged in the temporal and occipital regions of the brain, respectively, of both ASD and ADHD subjects, while in the control subjects only the visuo-spatial type is engaged (Goel et al., 2000; Knauff, 2007).
Conclusion
Based on the results of the analysis described in this work, the differences in the EEG complexity between the three groups of participants lead to the conclusion that cortical information processing is changed in ASD and ADHD adults, therefore their level of cortical activation may be insufficient to meet the peculiar cognitive demand of Aristotle's reasoning.
Significance
The present paper suggest that MSE, is a powerful and efficient nonlinear measure in detecting neural dysfunctions in adults with ASD and ADHD characteristics, when they are called on to perform in a very demanding as well as innovative set of cognitive tasks, that can be considered as a new diagnostic ‘benchmark’ in helping detecting more effectively such type of disorders. A linear measure alone, as the typical PSD, is not capable in making such a distinction. The work contributes in shedding light on the neural mechanisms of syllogism/reasoning of Aristotelian type, as well as toward understanding how humans reason logically and why ‘pathological’ subjects deviate from the norms of formal logic.}
}
@article{RICHARDSON2022100935,
title = {Extending the two-component model of delusion to substance use disorder etiology and recovery},
journal = {New Ideas in Psychology},
volume = {66},
pages = {100935},
year = {2022},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2022.100935},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X22000058},
author = {George B. Richardson and Nathan McGee},
keywords = {Brain disease model of addiction, Two-component model of delusion, Bayes Theorem, Belief, Substance use disorder},
abstract = {The brain disease model (BMDA) and psychosocial models of addiction attend to phenomena at different levels of biological organization, and evidence suggests neither is sufficient to explain substance use disorder (SUD). Here, we extend a Bayesian model of the emergence and persistence of delusions to SUD etiology and recovery, building upon efforts to link lower-level impacts of psychoactive compounds to higher-level phenomena such as attitudes, beliefs, and self-control. According to the resulting two-component model of SUD, psychoactive substances interact with genetic and environmental factors to produce delusions about the biological importance of substance use and its contexts by perturbating basic human affective systems. These delusions are most often revised or rejected based on individuals’ existing belief systems. But in some individuals, factors explaining the persistence of an array of delusions (e.g., lower levels of executive functioning) prevent the evaluation and revision system from rejecting or revising beliefs that attribute high salience to substance-related stimuli. This theory provides novel hypotheses regarding the potential roles of factors such as dichotomous thinking, positive illusions and self-deception, and denial or lack of awareness in SUD etiology and recovery. Furthermore, it provides an account of SUD that may result in less stigma than the BDMA.}
}
@incollection{MARINESCU20171,
title = {Chapter 1 - Complex Systems},
editor = {Dan C. Marinescu},
booktitle = {Complex Systems and Clouds},
publisher = {Elsevier},
address = {Boston},
pages = {1-32},
year = {2017},
series = {Computer Science Reviews and Trends},
isbn = {978-0-12-804041-6},
doi = {https://doi.org/10.1016/B978-0-12-804041-6.00001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128040416000013},
author = {Dan C. Marinescu},
keywords = {Complexity, Emergence, Phase transitions, Open systems, Nondeterminism, Self-similarity, Fractal geometry, Power Law distribution},
abstract = {After a brief review of the evolution of thinking about systems, consisting of an ensemble of components, the chapter analyzes the nondeterminism, nonlinearity, and phase transitions in complex systems. A range of topics pertinent to complexity, such as self-organization, self-organized criticality, power law distributions, computational irreducibility, and quantitative characterization of complexity are then covered. Cybernetics and the interdisciplinary nature of complexity conclude the chapter.}
}
@article{ASCENZI2020115295,
title = {Theoretical mathematics, polarized light microscopy and computational models in healthy and pathological bone},
journal = {Bone},
volume = {134},
pages = {115295},
year = {2020},
issn = {8756-3282},
doi = {https://doi.org/10.1016/j.bone.2020.115295},
url = {https://www.sciencedirect.com/science/article/pii/S8756328220300752},
author = {Maria-Grazia Ascenzi},
keywords = {Biomechanics, Lamella, Low-trauma fracture, Mathematics, Osteon, Pathology},
abstract = {The needs of everyday life, such as counting and measuring, are roots of theoretical mathematics. I believe these roots are why mathematical ideas ground research so amazingly well within many scientific fields. Initially trained as a theoretical mathematician and having collaborated with non-mathematicians in the field of bone research, I address the advantages and challenges of collaborations across fields of research among investigators trained in different disciplines. I report on the mathematical ideas that have guided my research on the mechanics of bone tissue. I explain how the mathematical ideas of local vs. global properties influence my research. Polarized light microscopy (PLM) is a tool that I use consistently, in association with other microscopy techniques, to investigate bone in its healthy state and in the presence of bone disease, in humans and in animal models. I review the results that I and investigators around the world have obtained with PLM. Applied to thin bone sections, PLM yields extinct (black) and bright (white) signals that are interpreted in terms of the orientation of collagen type I, by means of other microscopy techniques. Collagen type I is an elementary component of bone tissue. Its orientation is important for the mechanical function of bone. Images obtained by PLM at a specific bone site yield big data sets regarding collagen orientation. Multiple data sets in respect of multiple sites are often needed for research because the bone tissue differs by location in response to the distinct forces acting on it. Mathematics, defined by philosophers as the theory of patterns, offers the backdrop for pattern identification in the big data sets regarding collagen orientation. I also discuss the computational aspect of the research, pursuant to which the patterns identified are incorporated in simulations of mechanical behaviors of bone. These mathematical ideas serve to understand the role of collagen orientation in bone fracture risk.}
}
@article{MARCIALROMERO2008171,
title = {Sequential Real Number Computation and Recursive Relations},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {202},
pages = {171-189},
year = {2008},
note = {Proceedings of the Fourth International Conference on Computability and Complexity in Analysis (CCA 2007)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108001199},
author = {J. Raymundo Marcial-Romero and M. Andrew Moshier},
keywords = {exact real-number computation, sequential computation, recursive relations, semantics, non-determinism, PCF},
abstract = {In the first author's thesis [Marcial-Romero, J. R., “Semantics of a sequential language for exact real-number computation”, PhD thesis at the University of Birmingham, 2004)], a sequential language, LRT, for real number computation is investigated. The thesis includes a proof that all polynomials are programmable, but that work comes short of giving a complete characterization of the expressive power of the language even for first-order functions. The technical problem is that LRT is non-deterministic. So a natural characterization of its expressive power should be in terms of relations rather than functions. In [Brattka, V., Recursive characterization of computable real-valued functions and relations, Theoretical Computer Science 162 (1) (1996) 45–77], Brattka investigates a formalization of recursive relations in the style of Kleene's recursive functions on the natural numbers. This paper establishes the expressive power of LRTp, a variant of LRT, in terms of Brattka's recursive relations. Because Brattka already did the work of establishing the precise connection between his recursive relations and Type 2 Theory of Effectivity, we thus obtain a complete characterization of first-order definability in LRTp.}
}
@article{EDELMAN2007253,
title = {Behavioral and computational aspects of language and its acquisition},
journal = {Physics of Life Reviews},
volume = {4},
number = {4},
pages = {253-277},
year = {2007},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1571064507000255},
author = {Shimon Edelman and Heidi Waterfall},
keywords = {Computational cognitive linguistics, Psycholinguistics, Machine learning, Language acquisition},
abstract = {One of the greatest challenges facing the cognitive sciences is to explain what it means to know a language, and how the knowledge of language is acquired. The dominant approach to this challenge within linguistics has been to seek an efficient characterization of the wealth of documented structural properties of language in terms of a compact generative grammar—ideally, the minimal necessary set of innate, universal, exception-less, highly abstract rules that jointly generate all and only the observed phenomena and are common to all human languages. We review developmental, behavioral, and computational evidence that seems to favor an alternative view of language, according to which linguistic structures are generated by a large, open set of constructions of varying degrees of abstraction and complexity, which embody both form and meaning and are acquired through socially situated experience in a given language community, by probabilistic learning algorithms that resemble those at work in other cognitive modalities.}
}
@article{MENGOV20061636,
title = {Fast computation of a gated dipole field},
journal = {Neural Networks},
volume = {19},
number = {10},
pages = {1636-1647},
year = {2006},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2006.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608006001316},
author = {George Mengov and Kalin Georgiev and Stefan Pulov and Trifon Trifonov and Krassimir Atanassov},
keywords = {Gated dipole field, Adaptive resonance theory, Generalized net},
abstract = {We address the need to develop efficient algorithms for numerical simulation of models, based in part or entirely on adaptive resonance theory. We introduce modifications that speed up the computation of the gated dipole field (GDF) in the Exact ART neural network. The speed increase of our solution amounts to at least an order of magnitude for fields with more than 100 gated dipoles. We adopt a ‘divide and rule’ approach towards the original GDF differential equations by grouping them into three categories, and modify each category in a separate way. We decouple the slow-dynamics part — the neurotransmitters from the rest of system, solve their equations analytically, and adapt the solution to the remaining fast-dynamics processes. Part of the node activations are integrated by an unsophisticated numerical procedure switched on and off according to rules. The remaining activations are calculated at equilibrium. We implement this logic in a Generalized Net (GN) — a tool for parallel processes simulation which enables a fresh look at developing efficient models. Our software implementation of generalized nets appears to add little computational overhead.}
}
@article{MADHJA2020107068,
title = {Energy-aware tree network formation among computationally weak nodes},
journal = {Computer Networks},
volume = {168},
pages = {107068},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.107068},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619309533},
author = {Adelina Madhja and Sotiris Nikoletseas and Alexandros A. Voudouris},
keywords = {Wireless power transfer, Tree network formation, Energy balance},
abstract = {We study the fundamental problem of distributed network formation among mobile agents of limited computational power that aim to achieve energy balance by wirelessly transmitting and receiving energy in a peer-to-peer manner. Specifically, we design simple distributed protocols consisting of a small number of states and interaction rules for the formation of arbitrary and k-ary tree networks. Furthermore, we evaluate (theoretically and also using computer simulations) a plethora of energy redistribution protocols that exploit different levels of knowledge in order to achieve desired energy distributions among the agents which require that every agent has exactly or at least twice the energy of the agents of higher depth, according to the structure of the network. Our study shows that without using any knowledge about the network structure, such energy distributions cannot be achieved in a timely manner, meaning that there might be high energy loss during the redistribution process. On the other hand, only a few extra bits of information seem to be enough to guarantee quick convergence to energy distributions that satisfy particular properties, yielding low energy loss.}
}
@incollection{PRIETOMARTINEZ201919,
title = {Chapter 2 - Computational Drug Design Methods—Current and Future Perspectives},
editor = {Kunal Roy},
booktitle = {In Silico Drug Design},
publisher = {Academic Press},
pages = {19-44},
year = {2019},
isbn = {978-0-12-816125-8},
doi = {https://doi.org/10.1016/B978-0-12-816125-8.00002-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012816125800002X},
author = {Fernando D. Prieto-Martínez and Edgar López-López and K. {Eurídice Juárez-Mercado} and José L. Medina-Franco},
keywords = {Artificial intelligence, Big data, Chemical space, Chemoinformatics, Deep learning, Molecular modeling, Polypharmacology, SmART, Target fishing, Virtual screening},
abstract = {Computer-aided drug design (CADD) comprises a broad range of theoretical and computational approaches that are part of modern drug discovery. CADD methods have made key contributions to the development of drugs that are in clinical use or in clinical trials. Such methods have emerged and evolved along with experimental approaches used in drug design. In this chapter we discuss the major CADD methods and examples of recent applications to drugs that have advanced in clinical trials or that have been approved for clinical use. We also comment on representative trends in current drug discovery that are shaping the development of novel methods, such as computer-aided drug repurposing. Similarly we present emerging concepts and technologies in molecular modeling and chemoinformatics. Furthermore, this chapter discusses the authors’ point of view of the challenges of traditional and novel CADD methods to increase their positive impact in drug discovery.}
}
@article{WENG20072303,
title = {On developmental mental architectures},
journal = {Neurocomputing},
volume = {70},
number = {13},
pages = {2303-2323},
year = {2007},
note = {Selected papers from the 3rd International Conference on Development and Learning (ICDL 2004) Time series prediction competition: the CATS benchmark},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2006.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0925231206005194},
author = {Juyang Weng},
keywords = {Mental architecture, Agent architecture, Computational neural science, Cognitive development, Autonomous mental development, Developmental robots, Learning types, Developmental vision, Speech recognition, Language acquisition, Thinking, Reasoning, Autonomous planning},
abstract = {This paper presents a computational theory of developmental mental architectures for artificial and natural systems, motivated by neuroscience. The work is an attempt to approximately model biological mental architectures using mathematical tools. Six types of architecture are presented, beginning with the observation-driven Markov decision process as Type-1. From Type-1 to Type-6, the architecture progressively becomes more complete toward the necessary functions of autonomous mental development. Properties of each type are presented. Experiments are discussed with emphasis on their architectures.}
}
@article{LU2024,
title = {Methods for Calculating Building-Embodied Carbon Emissions for the Whole Design Process},
journal = {Fundamental Research},
year = {2024},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2022.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S266732582400092X},
author = {Mei Lu and Zhixing Luo and Yujie Cang and Nan Zhang and Liu Yang},
keywords = {Design process, embodied carbon emissions, calculation methods, conceptual design, scheme design, construction drawing design},
abstract = {Energy conservation and emissions reduction in the construction industry are important steps in achieving China's goals of peak carbon emissions by 2030 and carbon neutrality by 2060. The premise for building carbon emission (CE) reduction is to produce accurate CE calculations. Existing calculation methods for building CEs have many problems, such as complicated calculations, large data demands, time-consuming and laborious processes, weak design orientation of results, and poor feedback on emission reduction. At the same time, the calculation of CEs during the process of architectural design faces obstacles such as uncertainty of information, incomplete data, and difficulty in obtaining a bill of quantities based on design information. To resolve these obstacles, this study, based on a designer's vocabulary and thinking mode, describes the construction of a “design-oriented” calculation methods for building-embodied carbon emissions (ECEs). The prediction and assessment of the impact on the building environment during the architectural design process were helpful for identifying the key areas for carbon reduction, exploring potential emission reduction hotspots, and providing timely feedback for design optimization, which can have important theoretical value and practical significance in promoting the construction of low-carbon buildings.}
}
@article{HERBET2015413,
title = {Rethinking voxel-wise lesion-deficit analysis: A new challenge for computational neuropsychology},
journal = {Cortex},
volume = {64},
pages = {413-416},
year = {2015},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2014.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0010945214003517},
author = {Guillaume Herbet and Gilles Lafargue and Hugues Duffau}
}
@article{PAPAVLASOPOULOU2019415,
title = {Exploring children's learning experience in constructionism-based coding activities through design-based research},
journal = {Computers in Human Behavior},
volume = {99},
pages = {415-427},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219300184},
author = {Sofia Papavlasopoulou and Michail N. Giannakos and Letizia Jaccheri},
keywords = {Constructionism, Coding, Computational thinking, Engagement, Children, Design-based research},
abstract = {Over the last few years, the integration of coding activities for children in K-12 education has flourished. In addition, novel technological tools and programming environments have offered new opportunities and increased the need to design effective learning experiences. This paper presents a design-based research (DBR) approach conducted over two years, based on constructionism-based coding experiences for children, following the four stages of DBR. Three iterations (cycles) were designed and examined in total, with participants aged 8–17 years old, using mixed methods. Over the two years, we conducted workshops in which students used a block-based programming environment (i.e., Scratch) and collaboratively created a socially meaningful artifact (i.e., a game). The study identifies nine design principles that can help us to achieve higher engagement during the coding activity. Moreover, positive attitudes and high motivation were found to result in the better management of cognitive load. Our contribution lies in the theoretical grounding of the results in constructionism and the emerging design principles. In this way, we provide both theoretical and practical evidence of the value of constructionism-based coding activities.}
}
@article{SINGH2024483,
title = {How has the AI boom impacted algorithmic biology?},
journal = {Cell Systems},
volume = {15},
number = {6},
pages = {483-487},
year = {2024},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S2405471224001522},
author = {Mona Singh and Cenk Sahinalp and Jianyang Zeng and Wei Vivian Li and Carl Kingsford and Qiangfeng Zhang and Teresa Przytycka and Joshua Welch and Jian Ma and Bonnie Berger},
abstract = {This Voices piece will highlight the impact of artificial intelligence on algorithm development among computational biologists. How has worldwide focus on AI changed the path of research in computational biology? What is the impact on the algorithmic biology research community?}
}
@article{SCHWARTZ20192047,
title = {Biophysics and the Genomic Sciences},
journal = {Biophysical Journal},
volume = {117},
number = {11},
pages = {2047-2053},
year = {2019},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2019.07.038},
url = {https://www.sciencedirect.com/science/article/pii/S0006349519306277},
author = {David C. Schwartz},
abstract = {It is now rare to find biological, or genetic investigations that do not rely on the tools, data, and thinking drawn from the genomic sciences. Much of this revolution is powered by contemporary sequencing approaches that readily deliver large, genome-wide data sets that not only provide genetic insights but also uniquely report molecular outcomes from experiments that biophysicists are increasingly using for potentiating structural and mechanistic investigations. In this perspective, I describe a path of how biophysical thinking greatly contributed to this revolution in ways that parallel advancements in computer science through discussion of several key inventions, described as “foundational devices.” These discussions also point at the future of how biophysics and the genomic sciences may become more finely integrated for empowering new measurement paradigms for biological investigations.}
}
@article{XIA20025,
title = {Applications of computational fluid dynamics (cfd) in the food industry: a review},
journal = {Computers and Electronics in Agriculture},
volume = {34},
number = {1},
pages = {5-24},
year = {2002},
issn = {0168-1699},
doi = {https://doi.org/10.1016/S0168-1699(01)00177-6},
url = {https://www.sciencedirect.com/science/article/pii/S0168169901001776},
author = {Bin Xia and Da-Wen Sun},
keywords = {Computational fluid dynamics, , Food, Refrigeration, Cooling, Drying, Sterilisation, Mixing, Chilling, Modelling, Simulation},
abstract = {Computational fluid dynamics (cfd) is a simulation tool, which uses powerful computer and applied mathematics to model fluid flow situations for the prediction of heat, mass and momentum transfer and optimal design in industrial processes. It is only in recent years that cfd has been applied in the food processing industry. This paper reviews the application of cfd in food processing industries including drying, sterilisation, refrigeration and mixing. The advantages of using cfd are discussed and the future of cfd applications is also outlined.}
}
@article{WANG20073776,
title = {Maximum likelihood computation based on the Fisher scoring and Gauss–Newton quadratic approximations},
journal = {Computational Statistics & Data Analysis},
volume = {51},
number = {8},
pages = {3776-3787},
year = {2007},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2006.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S0167947306005147},
author = {Yong Wang},
keywords = {Maximum likelihood computation, Fisher scoring, Gauss–Newton method, Constrained optimization, Iteratively reweighted least-squares},
abstract = {The Fisher scoring and Gauss–Newton methods are two known methods for maximum likelihood computation. This paper provides a generalization for each method in a unified manner so that they can be used for some difficult maximum likelihood computation, when, for example, there exist constraints on the parameters. A generalized method does not use directly the Newton-type iteration formulas of these methods, but, instead, uses the corresponding quadratic functions transformed from them. It proceeds by repeatedly approximating the log-likelihood function with the quadratic functions in the neighborhoods of the current iterates and optimizing each quadratic function within the parameter space. It is shown that each quadratic function has a weighted linear regression formulation, which can be conveniently solved. This generalization also extends the applicability of the Fisher scoring method to situations when the expected Fisher information matrices are unavailable in closed form. Fast computation can generally be anticipated, owing to their small rates of convergence and a rapid solution of each linear regression problem. While the generalized Gauss–Newton method may sometimes suffer for the so-called large residual problem, the generalized Fisher scoring method has performed consistently well in the numerical experiments we conducted.}
}
@article{SUMAR20103980,
title = {Computational intelligence approach to PID controller design using the universal model},
journal = {Information Sciences},
volume = {180},
number = {20},
pages = {3980-3991},
year = {2010},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2010.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025510002872},
author = {Rodrigo Rodrigues Sumar and Antonio Augusto Rodrigues Coelho and Leandro dos Santos Coelho},
keywords = {PID control, Nonlinear systems, Fuzzy systems, Neural networks, Differential evolution, Optimization},
abstract = {Despite the popularity of PID (Proportional-Integral-Derivative) controllers, their tuning aspect continues to present challenges for researches and plant operators. Various control design methodologies have been proposed in the literature, such as auto-tuning, self-tuning, and pattern recognition. The main drawback of these methodologies in the industrial environment is the number of tuning parameters to be selected. In this paper, the design of a PID controller, based on the universal model of the plant, is derived, in which there is only one parameter to be tuned. This is an attractive feature from the viewpoint of plant operators. Fuzzy and neural approaches – bio-inspired methods in the field of computational intelligence – are used to design and assess the efficiency of the PID controller design based on differential evolution optimization in nonlinear plants. The numerical results presented herein indicate that the proposed bio-inspired design is effective for the nonlinear control of nonlinear plants.}
}
@incollection{TSATSE20212033,
title = {Reflections on the development of scenario and problem-based chemical engineering projects},
editor = {Metin Türkay and Rafiqul Gani},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {50},
pages = {2033-2038},
year = {2021},
booktitle = {31st European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-323-88506-5.50314-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323885065503144},
author = {A. Tsatse and E. Sorensen},
keywords = {problem-based learning, Scenarios, Process Systems Engineering},
abstract = { Abstract
This work reflects on the use of scenario- and problem-based learning as a way of conveying not only fundamental knowledge, but also to provide training in the use of computational Process Systems Engineering (PSE) tools applied to open-ended real world problems. The teaching framework also has a strong emphasis on the development of professional skills and to evaluate the recommended design solutions considering multiple perspectives such as economics, safety, environment and societal context. The framework is implemented through week-long group projects called Scenarios, taking place mainly in the first two years of study, and examples are given of different variations of Scenarios. This teaching approach has multiple benefits, including but not limited to, students’ understanding of PSE tools and the development of their critical engineering thinking.}
}
@article{MALDONADO2014177,
title = {Synchronicity among Biological and Computational Levels of an Organism: Quantum Biology and Complexity},
journal = {Procedia Computer Science},
volume = {36},
pages = {177-184},
year = {2014},
note = {Complex Adaptive Systems Philadelphia, PA November 3-5, 2014},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.09.076},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914013258},
author = {Carlos E. Maldonado and Nelson A. Gómez-Cruz},
keywords = {quantum biology, living systems, non-linear systems, complexity science, theory, health.},
abstract = {This paper argues that there is a synchronicity among biological and computational levels on an organism and provides arguments and proofs based on experimental research gathered in the literature. The leading thread is the interplay between quantum biology (QB) and complexity. As the paper asks whether QB does contribute to complexity science (CS), five arguments are provided: (i) Firstly a state-of-the art of QB and its relationship to CS is sketched out. Thereafter, the attention is directed to answering the question set out; (ii) Secondly, it digs into the understanding of life toward deeper levels of reality; (iii) It is shown that non-trivial quantum effects shed insightful lights on the information processing of and within living beings; (iv) Once the distinction is made between increasing levels of complexity and increasing levels of organization, the focus lies in the importance of QB for organization, and not so much for complexity as such; (v) The role of information rises at the center of all concerns, and the intertwining of complexity and information processing. At the end some conclusions are drawn.}
}
@article{POST1987339,
title = {Latest thinking on the Malpasset accident},
journal = {Engineering Geology},
volume = {24},
number = {1},
pages = {339-353},
year = {1987},
note = {Dam Failures},
issn = {0013-7952},
doi = {https://doi.org/10.1016/0013-7952(87)90071-8},
url = {https://www.sciencedirect.com/science/article/pii/0013795287900718},
author = {G. Post and D. Bonazzi}
}
@article{ROSEN20211,
title = {A word is worth a thousand pictures: A 20-year comparative analysis of aberrant abstraction in schizophrenia, affective psychosis, and non-psychotic depression},
journal = {Schizophrenia Research},
volume = {238},
pages = {1-9},
year = {2021},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421003674},
author = {Cherise Rosen and Martin Harrow and Liping Tong and Thomas H. Jobe and Helen Harrow},
keywords = {Abstraction, Concretism, Aberrant abstraction, Schizophrenia, Affective psychosis, Unipolar depression non-psychotic},
abstract = {Abstract thinking is a cognitive process that involves the assimilation of concepts reduced from diffuse sensory input, organized, and interpreted in a manner beyond the obvious. There are multiple facets by which abstraction is measured that include semantic, visual-spatial and social comprehension. This study examined the prevalence and course of abstract and concrete responses to semantic proverbs and aberrant abstraction (composite score of semantic, visual-spatial, and social comprehension) over 20 years in 352 participants diagnosed with schizophrenia, affective psychosis, and unipolar non-psychotic depression. We utilized linear models, two-way ANOVA and contrasts to compare groups and change over time. Linear models with Generalized Estimation Equation (GEE) to determine association. Our findings show that regardless of diagnosis, semantic proverb interpretation improves over time. Participants with schizophrenia give more concrete responses to proverbs when compared to affective psychosis and unipolar depressed without psychosis. We also show that the underlying structure of concretism encompasses increased conceptual overinclusion at index hospitalization and idiosyncratic associations at follow-up; whereas, abstract thinking overtime encompasses increased visual-spatial abstraction at index and rich associations with increased social comprehension scores at follow-up. Regardless of diagnosis, premorbid functioning, descriptive characteristics, and IQ were not associated with aberrant abstraction. Delusions are highly and positively related to aberrant abstraction scores, while hallucinations are mildly and positively related to this score. Lastly, our data point to the importance of examining the underlying interconnected structures of ‘established’ constructs vis-à-vis mixed methods to provide a description of the rich interior world that may not always map onto current quantitative measures.}
}
@article{ALONSO20092683,
title = {A method to generate computationally efficient reduced order models},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {198},
number = {33},
pages = {2683-2691},
year = {2009},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0045782509001376},
author = {D. Alonso and A. Velazquez and J.M. Vega},
keywords = {Reduced order model, Proper Orthogonal Decomposition, Incompressible nonisothermal flow},
abstract = {A new method is presented to generate reduced order models (ROMs) in Fluid Dynamics problems. The method is based on the expansion of the flow variables on a Proper Orthogonal Decomposition (POD) basis, calculated from a limited number of snapshots, which are obtained via Computational Fluid Dynamics (CFD). Then, the POD-mode amplitudes are calculated as minimizers of a properly defined overall residual of the equations and boundary conditions. The residual can be calculated using only a limited number of points in the flow field, which can be scattered either all over the whole computational domain or over a smaller projection window. This means that the process is both computationally efficient (reconstructed flow fields require less than 1% of the time needed to compute a full CFD solution) and flexible (the projection window can avoid regions of large localized CFD errors). Also, various definitions of the residual are briefly discussed, along with the number and distribution of snapshots, the number of retained modes, and the effect of CFD errors, to conclude that the method is numerically robust. This is because the results are largely insensitive to the definition of the residual, to CFD errors, and to the CFD method itself, which may contain artificial stabilizing terms. Thus, the method is amenable for practical engineering applications.}
}
@article{KERBER2012239,
title = {A worst-case bound for topology computation of algebraic curves},
journal = {Journal of Symbolic Computation},
volume = {47},
number = {3},
pages = {239-258},
year = {2012},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111001775},
author = {Michael Kerber and Michael Sagraloff},
keywords = {Topology computation, Algebraic curve, Amortized analysis, Complexity analysis},
abstract = {Computing the topology of an algebraic plane curve C means computing a combinatorial graph that is isotopic to C and thus represents its topology in R2. We prove that, for a polynomial of degree n with integer coefficients bounded by 2ρ, the topology of the induced curve can be computed with Õ(n8ρ(n+ρ)) bit operations (Õ indicates that we omit logarithmic factors). Our analysis improves the previous best known complexity bounds by a factor of n2. The improvement is based on new techniques to compute and refine isolating intervals for the real roots of polynomials, and on the consequent amortized analysis of the critical fibers of the algebraic curve.}
}
@article{METHLING2022100013,
title = {Heuristics in multi-criteria decision-making: The cost of fast and frugal decisions},
journal = {EURO Journal on Decision Processes},
volume = {10},
pages = {100013},
year = {2022},
issn = {2193-9438},
doi = {https://doi.org/10.1016/j.ejdp.2022.100013},
url = {https://www.sciencedirect.com/science/article/pii/S2193943822000024},
author = {Florian Methling and Sara J.M. Abdeen and Rüdiger {von Nitzsch}},
keywords = {MCDM, Decision support, Heuristics, Utility theory, Value-focused thinking},
abstract = {There has been an ongoing debate in research regarding the use of heuristics in decision-making. Advocators have succeeded in showing that applying heuristics not only reduces effort but can even be more accurate than analytical approaches under certain conditions. Others point out the biases and cognitive distortions inherent in disregarding information. Researchers have used both simulations and experiments to study how the use of heuristics affects the decision's outcome. However, a good decision is determined by the process and not a lucky outcome. It is a conscious reflection on the decision-maker's information and preferences. Therefore, a heuristic must be assessed by its ability to match a structured decision processing all available information. Thus, the question remains: how often does the reduction of information considered in heuristic decisions lead to a different recommended alternative? We applied different heuristics to a dataset of 945 real, personal decisions. We have found that by using heuristics instead of a fully developed decision structure, in 60.34% of cases, a different alternative would have been recommended to the decision-maker leading to a mean relative utility loss for the deviating decisions of 34.58%. This shows that a continuous effort to reflect on the weighing of objectives and alternatives leads to better decisions.}
}
@article{GUPTA2009481,
title = {Does phonological short-term memory causally determine vocabulary learning? Toward a computational resolution of the debate},
journal = {Journal of Memory and Language},
volume = {61},
number = {4},
pages = {481-502},
year = {2009},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2009.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X09000825},
author = {Prahlad Gupta and Jamie Tisdale},
keywords = {Nonword repetition, Vocabulary learning, Computational modeling, Phonological memory, Word learning, Short-term memory, Language},
abstract = {The relationship between nonword repetition ability and vocabulary size and vocabulary learning has been a topic of intense research interest and investigation over the last two decades, following the demonstration that nonword repetition accuracy is predictive of vocabulary size (Gathercole & Baddeley, 1989). However, the nature of this relationship is not well understood. One prominent account posits that phonological short-term memory (PSTM) is a causal determinant both of nonword repetition ability and of phonological vocabulary learning, with the observed correlation between the two reflecting the effect of this underlying third variable (e.g., Baddeley, Gathercole, & Papagno, 1998). An alternative account proposes the opposite causality: that it is phonological vocabulary size that causally determines nonword repetition ability (e.g., Snowling, Chiat, & Hulme, 1991). We present a theory of phonological vocabulary learning, instantiated as a computational model. The model offers a precise account of the construct of PSTM, of performance in the nonword repetition task, of novel word form learning, and of the relationship between all of these. We show through simulation not only that PSTM causally affects both nonword repetition accuracy and phonological vocabulary size, but also that phonological vocabulary size causally affects nonword repetition ability. The plausibility of the model is supported by the fact that its nonword repetition accuracy displays effects of phonotactic probability and of nonword length, which have been taken as evidence for causal effects on nonword repetition accuracy of phonological vocabulary knowledge and PSTM, respectively. Thus the model makes explicit how the causal links posited by the two theoretical perspectives are both valid, in the process reconciling the two perspectives, and indicating that an opposition between them is unnecessary.}
}
@article{FOLLI2022102458,
title = {Biases in belief reports},
journal = {Journal of Economic Psychology},
volume = {88},
pages = {102458},
year = {2022},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2021.102458},
url = {https://www.sciencedirect.com/science/article/pii/S016748702100088X},
author = {Dominik Folli and Irenaeus Wolff},
keywords = {Belief elicitation, Belief formation, Belief-action consistency, Framing effects, Projection, Consensus effect, Wishful thinking,  rationalization},
abstract = {Belief elicitation is important in many different fields of economic research. We show that how a researcher elicits such beliefs – in particular, whether the belief is about the participant’s opponent, an unrelated other, or the population of others – strongly affects the belief reports. We study the underlying processes and find a clear consensus effect. Yet, when matching the opponent’s action would lead to a low payoff and the researcher asks for the belief about this opponent, ex-post rationalization kicks in and beliefs are re-adjusted again. Hence, we recommend to ask about unrelated others or about the population in such cases, as ‘opponent beliefs’ are even more detached from the beliefs participants had when deciding about their actions in the corresponding game. We find no evidence of wishful thinking in any of the treatments.}
}
@article{SUTHAR202431,
title = {Practical exercises of computer-aided process synthesis for chemical engineering undergraduates},
journal = {Education for Chemical Engineers},
volume = {48},
pages = {31-43},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000071},
author = {Krunal J. Suthar and Aesha Mehta and Swapna Rekha Panda and Hitesh Panchal and Rakesh Sinha},
keywords = {computational tools, lifelong learning, laboratory learning, process synthesis},
abstract = {The study presents ten different exercises covering various computational tools. These exercises are practical applications presented to improve the understanding and skills of students in important concepts of chemical-aided process synthesis. A few exercises aim to build a foundation in computational techniques for chemical engineering undergraduates. The exercises are based on a spreadsheet that covers the design of regression analysis to find the optimum Antoine constants, array calculation for multicomponent distillation material balance, and the generation of a Gantt chart to plan and study the activities of batch processes. The other exercises included an introduction to process simulation, simulation, and reactor rating, and a simulation of multicomponent shortcut distillation. These exercises provide students with hands-on experience in utilizing process simulation software essential for analysing and optimizing chemical processes in real-world scenarios. The exercises also included the design of a heat exchanger network and solving a linear programming problem. An anonymous survey was collected from the cohort that had undergone the exercises, and the practical grades were compared with the batch that did not study the proposed exercises. Additionally, student feedback on practical exercises was collected. Based on the experience of the course coordinator and the collected feedback from participants, it was clear that the exercises helped students to inculcate critical thinking and self-learning abilities. An article essentially sheds light on the computer-aided practical exercises that enable chemical engineering graduates to engage in lifelong learning.}
}
@incollection{HUDEDAGADDI2017233,
title = {Chapter 7 - Quantum inspired computational intelligent techniques in image segmentation},
editor = {Siddhartha Bhattacharyya and Ujjwal Maulik and Paramartha Dutta},
booktitle = {Quantum Inspired Computational Intelligence},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {233-258},
year = {2017},
isbn = {978-0-12-804409-4},
doi = {https://doi.org/10.1016/B978-0-12-804409-4.00007-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128044094000073},
author = {D.P. Hudedagaddi and B.K. Tripathy},
keywords = {Quantum computing, Computing intelligence, Image segmentation, Evolutionary algorithms},
abstract = {Quantum computing (QC) is a new area of research which incorporates elements from mathematics, physics, and computing. Quantum computing has generated a growing interest among scientists, technologists, and industrialists. Over the past decade it provided a platform for research to people in the scientific, technical, and industrial fields. Quantum physics concepts have been used in developing the basics of QC. In QC, the parallel processing feature has reduced the algorithm complexities which are being used. This feature helped find solutions to several optimization problems and issues that were related to it. Quantum inspired intelligent computational methods have been used in several application areas. Image segmentation is one such area and the exploration of this feature in image segmentation is the primary focus of this chapter.}
}
@incollection{SEJNOWSKI20012460,
title = {Computational Neuroscience},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2460-2465},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/03419-7},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767034197},
author = {T.J. Sejnowski},
abstract = {The goal of computational neuroscience is to explain in computational terms how brains generate behaviors. Computational models of the brain explore how populations of highly interconnected neurons are formed during development and how they come to represent, process, store, act upon, and become altered by, information present in the environment. Techniques from computer science and mathematics are used to simulate and analyze these computational models and provide links between the widely ranging levels of investigation, from the molecular to the systems levels. Computational neuroscience is a relatively young discipline that is growing rapidly. Most of the models that have been developed thus far have been aimed at interpreting experimental data and providing a conceptual framework for the dynamic properties of neural systems. A more comprehensive theory of brain function should arise as we gain a broader understanding of the computational resources of nervous systems at all levels of organization.}
}
@article{SAMUELSSON2023100173,
title = {A shape of play to come: Exploring children's play and imaginaries with robots and AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100173},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100173},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000528},
author = {Robin Samuelsson},
keywords = {Early childhood, Robots, AI, Play, Playful learning, Sociotechnical imaginaries},
abstract = {We are rapidly moving into an era where AI and robots are part of everyday interactions in society and education, and there are immense discussions today about current and future technologies. Still, children are often not included in this discussion, while there is much to learn from current uses and children's understandings of AI and robotics. The study is based on a seven-month ethnographical work that details the implementation of a robot in two preschool groups of children aged 1–2 and 3–5 (n = 38). The study descriptively combines a framework for children's play analysis with explorative qualitative child interviews (n = 6) with the 3-5-year-olds to examine how children play with the robot and their thinking about a future with robots and AI. The results show how children's play with robots spans all of Hughes's (2011) sixteen play types and integrates robots into play in ways specific to child-robot interaction. The interviews indicate that children have well-formed knowledge about the current uses of robots and AI and elaborate imaginaries about a future with them, including critical boundaries toward robots and AI agents. The evidence shows emerging ways children relate to these. The potential of including children's actions and voices in the ongoing societal and educational debates on AI is discussed.}
}
@article{POPAT2019365,
title = {Learning to code or coding to learn? A systematic review},
journal = {Computers & Education},
volume = {128},
pages = {365-376},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0360131518302768},
author = {Shahira Popat and Louise Starkey},
keywords = {Coding, Programming, School, Computer, Outcome, Skills},
abstract = {The resurgence of computer programming in the school curriculum brings a promise of preparing students for the future that goes beyond just learning how to code. This study reviewed research to analyse educational outcomes for children learning to code at school. A systematic review was applied to identify relevant articles and a thematic analysis to synthesise the findings. Ten articles were included in the synthesis and an overarching model was developed which depicts the themes. The results demonstrate that although students are learning to code, a range of other educational outcomes can be learnt or practiced through the teaching of coding. These included mathematical problem-solving, critical thinking, social skills, self-management and academic skills. The review also identified the importance of instructional design for developing these educational outcomes through coding.}
}
@article{PALMERI2004378,
title = {Computational approaches to the development of perceptual expertise},
journal = {Trends in Cognitive Sciences},
volume = {8},
number = {8},
pages = {378-386},
year = {2004},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2004.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661304001603},
author = {Thomas J. Palmeri and Alan C-N. Wong and Isabel Gauthier},
abstract = {Dog experts, ornithologists, radiologists and other specialists are noted for their remarkable abilities at categorizing, identifying and recognizing objects within their domain of expertise. A complete understanding of the development of perceptual expertise requires a combination of thorough empirical research and carefully articulated computational theories that formalize specific hypotheses about the acquisition of expertise. A comprehensive computational theory of the development of perceptual expertise remains elusive, but we can look to existing computational models from the object-recognition, perceptual-categorization, automaticity and related literatures for possible starting points. Arguably, hypotheses about the development of perceptual expertise should first be explored within the context of existing computational models of visual object understanding before considering the creation of highly modularized adaptations for particular domains of perceptual expertise.}
}
@article{NUNES2020117761,
title = {Thinking the future of membranes: Perspectives for advanced and new membrane materials and manufacturing processes},
journal = {Journal of Membrane Science},
volume = {598},
pages = {117761},
year = {2020},
issn = {0376-7388},
doi = {https://doi.org/10.1016/j.memsci.2019.117761},
url = {https://www.sciencedirect.com/science/article/pii/S0376738819333113},
author = {Suzana P. Nunes and P. Zeynep Culfaz-Emecen and Guy Z. Ramon and Tymen Visser and Geert Henk Koops and Wanqin Jin and Mathias Ulbricht},
abstract = {The state-of-the-art of membrane technology is characterized by a number of mature applications such as sterile filtration, hemodialysis, water purification and gas separation, as well as many more niche applications of successful membrane-based separation and processing of fluid mixtures. The membrane industry is currently employing a portfolio of established materials, mostly standard polymers or inorganic materials (not originally developed for membranes), and easily scalable manufacturing processes such as phase inversion, interfacial polymerization and coating. Innovations in membranes and their manufacturing processes must meet the desired intrinsic properties that determine selectivity and flux, for specific applications. However, tunable and stable performance, as well as sustainability over the entire life cycle of membrane products are becoming increasingly important. Membrane manufacturers are progressively required to share the carbon footprint of their membrane modules with their customers. Environmental awareness among the world's population is a growing phenomenon and finds its reflection in product development and manufacturing processes. In membrane technology one can see initial steps in this direction with the replacement of hazardous solvents, the utilization of renewable materials for membrane production and the reuse of membrane modules. Other examples include increasing the stability of organic membrane polymers and lowering the cost of inorganic membranes. In a long-term perspective, many more developments in materials science will be required for making new, advanced membranes. These include “tools” such as self-assembly or micro- and nano-fabrication, and “building blocks”, e.g. tailored block copolymers or 1D, 2D and 3D materials. Such membranes must be fabricated in a simpler manner and be more versatile than existing ones. In this perspective paper, a vision of such LEGO®-like membranes with precisely adjustable properties will be illustrated with, where possible, examples that already demonstrate feasibility. These include the possibility to switch properties using an external stimulus, adapting a membrane's selectivity to a given separation, or providing the ability to assemble, disassemble and reassemble the membrane on a suitable support as scaffold, in situ, in place and on-demand. Overall, it is foreseen that the scope of future membrane applications will become much wider, based on improved existing membrane materials and manufacturing processes, as well as the combination of novel, tailor-made “building blocks” and “tools” for the fabrication of next-generation membranes tuned to specific applications.}
}
@article{TOUSSAINT20102,
title = {Computational geometric aspects of rhythm, melody, and voice-leading},
journal = {Computational Geometry},
volume = {43},
number = {1},
pages = {2-22},
year = {2010},
note = {Special Issue on the 14th Annual Fall Workshop},
issn = {0925-7721},
doi = {https://doi.org/10.1016/j.comgeo.2007.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S092577210900042X},
author = {Godfried Toussaint},
keywords = {Musical rhythm, Melody, Voice-leading, Evenness measures, Rhythm similarity, Sequence comparison, Necklaces, Convolution, Computational geometry, Music information retrieval, Algorithms, Computational music theory},
abstract = {Many problems concerning the theory and technology of rhythm, melody, and voice-leading are fundamentally geometric in nature. It is therefore not surprising that the field of computational geometry can contribute greatly to these problems. The interaction between computational geometry and music yields new insights into the theories of rhythm, melody, and voice-leading, as well as new problems for research in several areas, ranging from mathematics and computer science to music theory, music perception, and musicology. Recent results on the geometric and computational aspects of rhythm, melody, and voice-leading are reviewed, connections to established areas of computer science, mathematics, statistics, computational biology, and crystallography are pointed out, and new open problems are proposed.}
}
@article{SOTO2022100963,
title = {Undergraduates’ exploration of contour integration: What is Accumulated?},
journal = {The Journal of Mathematical Behavior},
volume = {66},
pages = {100963},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100963},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000311},
author = {Hortensia Soto and Michael Oehrtman},
keywords = {Complex functions, Contour integration, Emerging models},
abstract = {In this work we explored undergraduate students’ geometric and visual interpretations of the inscription for contour integrals, ∫Cfzdz, without them having any prior knowledge of integration of complex-valued functions. Our research participants drew from various sources of geometric and visual interpretations to productively investigate the components of contour integrals, which they conveyed with diagrams and gesture. Although this enabled significant progress, they were overwhelmed coordinating the multiple quantitative relationships and reverted to simplified interpretations such as summing values of z,fz, or ∆z. In other words, they were unable to maintain focus on what was accumulated. Our participants also engaged in the thinking real, doing complex phenomenon which sometimes provided productive feedback to assess their interpretations. We offer potential reasons for students’ struggles including various interpretations for integration of real-valued integration and the layering of inscriptions. We also provide potential instructional strategies based on the participants’ interpretations.}
}
@article{RIESENFELD20151054,
title = {Initiating a CAD renaissance: Multidisciplinary analysis driven design: Framework for a new generation of advanced computational design, engineering and manufacturing environments},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {284},
pages = {1054-1072},
year = {2015},
note = {Isogeometric Analysis Special Issue},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2014.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0045782514004502},
author = {Richard F. Riesenfeld and Robert Haimes and Elaine Cohen},
keywords = {Multidisciplinary analysis driven design, Integrated computational engineering, CAD/CAE/CAM/IGA},
abstract = {We present a critical analysis of the effectiveness of the current field of CAD, and discuss some of the forces that have taken it so far off course from its strikingly foresighted origins. Armed with the ensuing understanding of the operational forces that have taken CAD adrift, we conclude that the disparity between CAD’s mired state-of-the-art condition relative to more appropriate, inspired and achievable goals for CAD calls for more drastic measures. It is asserted that, well beyond the evolutionary progression of incremental steps characteristic of next version system releases, the field is overdue for developing a class of genuine design-centric, ab initio, CAD systems architectures effecting the original CAD vision through the powerful instruments of contemporary computing tools and technologies.}
}
@article{ANDERSON2015309,
title = {Reading visually embodied meaning from the brain: Visually grounded computational models decode visual-object mental imagery induced by written text},
journal = {NeuroImage},
volume = {120},
pages = {309-322},
year = {2015},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.06.093},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915006345},
author = {Andrew James Anderson and Elia Bruni and Alessandro Lopopolo and Massimo Poesio and Marco Baroni},
keywords = {Concept representation, Embodiment, Mental imagery, Perceptual simulation, Language, Multimodal semantic models, Representational similarity},
abstract = {Embodiment theory predicts that mental imagery of object words recruits neural circuits involved in object perception. The degree of visual imagery present in routine thought and how it is encoded in the brain is largely unknown. We test whether fMRI activity patterns elicited by participants reading objects' names include embodied visual-object representations, and whether we can decode the representations using novel computational image-based semantic models. We first apply the image models in conjunction with text-based semantic models to test predictions of visual-specificity of semantic representations in different brain regions. Representational similarity analysis confirms that fMRI structure within ventral-temporal and lateral-occipital regions correlates most strongly with the image models and conversely text models correlate better with posterior-parietal/lateral-temporal/inferior-frontal regions. We use an unsupervised decoding algorithm that exploits commonalities in representational similarity structure found within both image model and brain data sets to classify embodied visual representations with high accuracy (8/10) and then extend it to exploit model combinations to robustly decode different brain regions in parallel. By capturing latent visual-semantic structure our models provide a route into analyzing neural representations derived from past perceptual experience rather than stimulus-driven brain activity. Our results also verify the benefit of combining multimodal data to model human-like semantic representations.}
}
@article{BERGSTRA200855,
title = {Parallel Processes with Implicit Computational Capital},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {209},
pages = {55-81},
year = {2008},
note = {Proceedings of the LIX Colloquium on Emerging Trends in Concurrency Theory (LIX 2006)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108002193},
author = {J.A. Bergstra and C.A. Middelburg},
keywords = {Process algebra, Implicit computational capital, Preservation of computational money},
abstract = {We propose a process algebra which is concerned with processes that have an implicit computational capital. This process algebra is intended to be helpful when designing computer-based systems of which the behaviour is related to money handling. It goes along with the development that the behaviour of computer-based systems, organizations and persons is increasingly more related to money handling.}
}
@incollection{VALERIO201385,
title = {Chapter 6 - Computational Translation and Integration of Test Data to Meet Risk Assessment Goals},
editor = {Bruce A. Fowler},
booktitle = {Computational Toxicology},
publisher = {Academic Press},
address = {San Diego},
pages = {85-112},
year = {2013},
isbn = {978-0-12-396461-8},
doi = {https://doi.org/10.1016/B978-0-12-396461-8.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780123964618000087},
author = {Luis G. Valerio},
keywords = { toxicology,  methods, translational research, QSAR, computational toxicology, drug safety, safety assessment},
abstract = {The remarkable advances of high-performance computing to facilitate and increase efficiency in helping to resolve or support assessments on the toxic effects of chemicals on tissues and genomic material have led to development of novel in silico methods. These methods can support risk assessment via integration of study data that can be translated into meaningful predictive information. This chapter describes some methods in computational toxicology and how to integrate experimental data with computational assessments for supporting risk assessment.}
}
@article{VAMVOUDAKIS20226,
title = {Nonequilibrium dynamical games: A control systems perspective},
journal = {Annual Reviews in Control},
volume = {53},
pages = {6-18},
year = {2022},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2022.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1367578822000128},
author = {Kyriakos G. Vamvoudakis and Filippos Fotiadis and Aris Kanellopoulos and Nick-Marios T. Kokolakis},
abstract = {Dynamical games model interactions between agents that take place in ever-shifting environments. Due to the increasing penetration of autonomous systems to society, understanding and predicting the outcomes of these games has become crucial. In this work, we highlight the importance of nonequilibrium solutions to dynamical games through the lens of bounded rationality. We describe the principles of level-k thinking and cognitive hierarchy – concepts developed in the field of economics – via mathematical tools and formulation of control theory. We describe the main principles of bounded rationality for nonequilibrium differential games in both nonlinear non-zero-sum and linear zero-sum settings. The importance of those approaches is highlighted in problems of pursuit evasion between Unmanned Aerial Vehicles, while the core of the bounded rationality principles that we employ are extended to discrete stochastic dynamical games. The versatility of the proposed approach is complemented by rigorous mathematical guarantees that enable predictability of the games’ outcomes.}
}
@article{BAWDEN1984205,
title = {Systems thinking and practices in the education of agriculturalists},
journal = {Agricultural Systems},
volume = {13},
number = {4},
pages = {205-225},
year = {1984},
issn = {0308-521X},
doi = {https://doi.org/10.1016/0308-521X(84)90074-X},
url = {https://www.sciencedirect.com/science/article/pii/0308521X8490074X},
author = {Richard J. Bawden and Robert D. Macadam and Roger J. Packham and Ian Valentine},
abstract = {A systems approach has been taken to a review of agricultural education programmes and as the essential theme of resultant curricula at Hawkesbury Agricultural College in Australia. The systems thinking and practices which have guided, and been shaped by, the innovations are outlined, and the rationale and framework of the major programme are described. The subsequent emphasis has been placed on effective learning for agricultural managers and their technologist advisors. It is argued that problem solving and learning are essentially the same psychological processes and that taking a systems approach to investigating problem situations provides a more useful paradigm for learning about agriculture than reductionist, discipline-based approaches. Experiential learning and autonomy in learning are seen as consistent with this and are basic features of the programmes. A conceptual framework for problem solving that incorporates soft and hard systems and scientific reductionist methodologies has been developed. A contingency approach to situation improving is emerging as a less restrictive and more realistic alternative to a normative approach to problem solving.}
}
@article{ANDERSON201738,
title = {Isolating blocks as computational tools in the circular restricted three-body problem},
journal = {Physica D: Nonlinear Phenomena},
volume = {343},
pages = {38-50},
year = {2017},
issn = {0167-2789},
doi = {https://doi.org/10.1016/j.physd.2016.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167278916303013},
author = {Rodney L. Anderson and Robert W. Easton and Martin W. Lo},
keywords = {Circular restricted three-body problem, Isolating blocks, Invariant manifolds, Invariant 3-sphere},
abstract = {Isolating blocks may be used as computational tools to search for the invariant manifolds of orbits and hyperbolic invariant sets associated with libration points while also giving additional insight into the dynamics of the flow in these regions. We use isolating blocks to investigate the dynamics of objects entering the Earth–Moon system in the circular restricted three-body problem with energies close to the energy of the L2 libration point. Specifically, the stable and unstable manifolds of Lyapunov orbits and the hyperbolic invariant set around the libration points are obtained by numerically computing the way orbits exit from an isolating block in combination with a bisection method. Invariant spheres of solutions in the spatial problem may then be located using the resulting manifolds.}
}
@article{HUANG2006567,
title = {An integrated computational intelligence approach to product concept generation and evaluation},
journal = {Mechanism and Machine Theory},
volume = {41},
number = {5},
pages = {567-583},
year = {2006},
issn = {0094-114X},
doi = {https://doi.org/10.1016/j.mechmachtheory.2005.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0094114X05001333},
author = {Hong-Zhong Huang and Ruifeng Bo and Wei Chen},
keywords = {Conceptual design, Computational intelligence, Optimal concept, Genetic algorithm, Fuzzy neural network},
abstract = {Product concept generation and evaluation are two major activities for obtaining an optimal concept in conceptual design. In this paper, an integrated computational intelligence approach is proposed for dealing with these two aspects. A group of satisfactory concepts are generated first by using genetic algorithm and incorporating the information from knowledge base. Then concept evaluation and decision making are implemented using fuzzy neural network to obtain an optimal concept. Our procedure of using computational intelligence in conceptual design is described. The key issues in implementing the proposed approach are discussed, and finally the applicability of the proposed method is illustrated with an engineering example.}
}
@article{COLLINS2023101585,
title = {Generative linguistics: ‘Galilean style’},
journal = {Language Sciences},
volume = {100},
pages = {101585},
year = {2023},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2023.101585},
url = {https://www.sciencedirect.com/science/article/pii/S0388000123000505},
author = {John Collins},
keywords = {Chomsky, Centre-embedding, Competence/performance, Computation, Galilean style, Galileo},
abstract = {Generative linguistics is often claimed by Chomsky to have a 'Galilean style', which is intended to position linguistics as a science continuous with standard practise in the natural sciences. These claims, however, are more suggestive than explanatory. The paper will, first, explain just what a Galilean style is. It will then be argued that its application to two key notions in generative linguistics - the competence/performance distinction (with reference to centre-embedding) and the notion of computation - demands a departure from what we might expect of a Galilean style. In this sense, the epithet is misleading. It will also be shown, however, that the 'Galilean' label is appropriate once we factor in the difference between a science concerned with kinematics (the relations between objects in space and time) and one concerned with language.}
}
@article{ZENG2024123400,
title = {Research on the application of knowledge mapping and knowledge structure construction based on adaptive learning model},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123400},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123400},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424002653},
author = {Xiyin Zeng and Shouqiang Liu},
keywords = {Personalized learing, Pedagogy, Interactive learning environments, Applications},
abstract = {This project has developed a geometry learning software that integrates multiple computer technologies to address the challenges of deep analysis of knowledge points and establishing connections in learning software. The software combines Long Short-Term Memory (LSTM) and Residual Neural Network (ResNet101) to encode text and image features. A self-attention mechanism is used to fuse information from both modalities, enabling decoding of geometric models and classification of corresponding knowledge points.This project uses LSTM and ResNet101 models to extract text and visual features for problem-solving using the Multi Mode Thinking Chain (CoT) method. Classification labels are utilized to generate text responses for problem-solving ideas. Furthermore, a recommendation module is proposed, which combines knowledge tracking and neural collaborative filtering algorithms to capture student behavior and knowledge point vectors. Implicit factors representing students' mastery of different knowledge points are used as inputs in neural collaborative filtering for personalized recommendations. The results demonstrate improvements in accuracy using the ResNet + LSTM multimodal algorithm, achieving a 13 % increase compared to single-modal classification. The multimodal CoT approach also outperforms language models like GPT3.5 and VisualBert by 10 %. Additionally, the combined algorithm of knowledge tracking and neural collaborative filtering shows a 13.3 % higher F1 value compared to ordinary algorithms, confirming the superiority of the adopted method in this project.}
}
@article{RAHMAN201872,
title = {Hybrid bio-Inspired computational intelligence techniques for solving power system optimization problems: A comprehensive survey},
journal = {Applied Soft Computing},
volume = {69},
pages = {72-130},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618302424},
author = {Imran Rahman and Junita Mohamad-Saleh},
keywords = {Computational intelligence, Hybrid optimization, Optimization, Bio-inspired computation, Power system},
abstract = {Optimization problems of modern day power system are very challenging to resolve because of its design complexity, wide geographical dispersion and influence from many unpredictable factors. For that reason, it is essential to apply most effective optimization techniques by taking full benefits of simplified formulation and execution of a particular problem. This study presents a summary of significant hybrid bio-inspired computational intelligence (CI) techniques utilized for power system optimization. Authors have reviewed an extensive range of hybrid CI techniques and examined the motivations behind their improvements. Various applications of hybrid bio-inspired CI algorithms have been highlighted in this paper. In addition, few drawbacks regarding the hybrid CI algorithms are explained. Current trends in CI techniques from the past researches have also been discussed in the domain of power system optimization. Lastly, some future research directions are suggested for further advancement of hybrid techniques.}
}
@article{TURHAN20075237,
title = {Statistical and computational intelligence tools for the analyses of warp tension in different back-rest oscillations},
journal = {Information Sciences},
volume = {177},
number = {23},
pages = {5237-5252},
year = {2007},
note = {Including: Mathematics of Uncertainty},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507003246},
author = {Yıldıray Turhan and Sezai Tokat and Recep Eren},
keywords = {Neural networks, Radial basis function, Cross-validation, Data regression, Warp tension, Back-rest oscillation, Weft density},
abstract = {In this paper, experimental, computational intelligence based and statistical investigations of warp tensions in different back-rest oscillations are presented. Firstly, in the experimental stage, springs having different stiffnesses are used to obtain different back-rest oscillations. For each spring, fabrics are woven in different weft densities and the warp tensions are measured and saved during weaving process. Secondly, in the statistical investigation, the experimental data are analyzed by using linear multiple and quadratic multiple-regression models. Later, in the computational intelligence based investigation, the data obtained from the experimental study are analyzed by using artificial neural networks that are universal approximators which provide a massively parallel processing and decentralized computing. Specially, radial basis function neural network structure is chosen. In this structure, cross-validation technique is used in order to determine the number of radial basis functions. Finally, the results of regression analysis, the computational intelligence based analysis and experimental measurements are compared by using the coefficient of determination. From the results, it is shown that the computational intelligence based analysis indicates a better agreement with the experimental measurement than the statistical analysis.}
}
@article{GUARINO2022559,
title = {Optimism and pessimism in strategic interactions under ignorance},
journal = {Games and Economic Behavior},
volume = {136},
pages = {559-585},
year = {2022},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2022.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0899825622001506},
author = {Pierfrancesco Guarino and Gabriel Ziegler},
keywords = {Ignorance, Optimism/pessimism, Point/Wald Rationalizability, Interactive epistemology, Wishful thinking, Börgers dominance},
abstract = {We study players interacting under the veil of ignorance, who have—coarse—beliefs represented as subsets of opponents' actions. We analyze when these players follow max⁡min or max⁡max decision criteria, which we identify with pessimistic or optimistic attitudes, respectively. Explicitly formalizing these attitudes and how players reason interactively under ignorance, we characterize the behavioral implications related to common belief in these events: while optimism is related to Point Rationalizability, a new algorithm—Wald Rationalizability—captures pessimism. Our characterizations allow us to uncover novel results: (i) regarding optimism, we relate it to wishful thinking á la Yildiz (2007) and we prove that dropping the (implicit) “belief-implies-truth” assumption reverses an existence failure described therein; (ii) we shed light on the notion of rationality in ordinal games; (iii) we clarify the conceptual underpinnings behind a discontinuity in Rationalizability hinted in the analysis of Weinstein (2016).}
}
@article{HODGENS2021102149,
title = {Solving the puzzle of Fe homeostasis by integrating molecular, mathematical, and societal models},
journal = {Current Opinion in Plant Biology},
volume = {64},
pages = {102149},
year = {2021},
note = {Cell biology},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2021.102149},
url = {https://www.sciencedirect.com/science/article/pii/S1369526621001503},
author = {Charles Hodgens and Belinda S. Akpa and Terri A. Long},
keywords = {Iron homeostasis, Simulation-based inference (SBI), Inclusivity},
abstract = {To ensure optimal utilization and bioavailability, iron uptake, transport, subcellular localization, and assimilation are tightly regulated in plants. Herein, we examine recent advances in our understanding of cellular responses to Fe deficiency. We then use intracellular mechanisms of Fe homeostasis to discuss how formalizing cell biology knowledge via a mathematical model can advance discovery even when quantitative data is limited. Using simulation-based inference to identify plausible systems mechanisms that conform to known emergent phenotypes can yield novel, testable hypotheses to guide targeted experiments. However, this approach relies on the accurate encoding of domain-expert knowledge in exploratory mathematical models. We argue that this would be facilitated by fostering more “systems thinking” life scientists and that diversifying your research team may be a practical path to achieve that goal.}
}
@article{CHAUNCEY2023100182,
title = {A framework and exemplars for ethical and responsible use of AI Chatbot technology to support teaching and learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100182},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100182},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000619},
author = {Sarah A. Chauncey and H. Patricia McKenna},
keywords = {AI ethics, AI responsibility, AI-Rich learning environments, Cognitive flexibility, Critical thinking, Self-regulation},
abstract = {The aim of this paper is to investigate the ethical and responsible use of AI chatbots in education in support of critical thinking, cognitive flexibility and self-regulation in terms of their potential to enhance and motivate teaching and learning in contemporary education environments. AI chatbots such as ChatGPT by OpenAI appear to be improving in conversational and other capabilities and this paper explores such advances using version 4. Based on a review of the research literature, a conceptual framework is formulated for responsible use of AI chatbots in education supporting cognitive flexibility in AI-rich learning environments. The framework is then operationalized for use in this paper through the development of exemplars for math, english language arts (ELA), and studying with ChatGPT to close learning gaps in an effort to foster more ethical and responsible approaches to the design and development of AI chatbots for application and use in teaching and learning environments. This paper extends earlier foundational work on cognitive flexibility and AI chatbots as well as work on cognitive flexibility in support of creativity and innovation with AI chatbots in urban civic spaces.}
}
@article{HALLINAN2001506,
title = {Thinking Beyond the Fringe},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {12},
pages = {506-507},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01802-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300018027},
author = {Jennifer Hallinan},
keywords = {explicit models of memory, stochastic generative approach, evolution of the neural modularity, metarepresentation}
}
@article{PATAHUDDIN2022100988,
title = {Subtleties in spatial visualization maneuvers: Insights from numerical solutions},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100988},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100988},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000566},
author = {Sitti Maesuri Patahuddin and Ajay Ramful and Tom Lowrie and Ajeevsing Bholoa},
keywords = {Spatial visualization, Spatial reasoning, Mathematics, Geometry, Measurement, Pre-service teacher},
abstract = {This study aimed to identify the role and nature of spatial visualization in the problem solutions of pre-service teachers solving school-mathematics tasks requiring measurement reasoning. The nuances in the pre-service teachers’ strategies were examined for the role of spatial visualization in the solution process. The findings suggest that inadequacies in visualizing the spatial configurations of the tasks led to incorrect numerical solutions despite the presence of conceptual knowledge. Furthermore, the tendency to rely on formula-based approaches appeared to have suppressed the preliminary spatial processing of the configurations. Theoretically, the paper offers insights into the mechanism that may be involved in the solution of spatially-related mathematical tasks. The findings imply that pre-service teachers need to be sufficiently engaged in spatial reasoning activities.}
}
@article{CAI2023101087,
title = {Impact of prompts on students’ mathematical problem posing},
journal = {The Journal of Mathematical Behavior},
volume = {72},
pages = {101087},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101087},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000573},
author = {Jinfa Cai and Hua Ran and Stephen Hwang and Yue Ma and Jaepil Han and Faith Muirhead},
keywords = {Problem posing, Problem-posing prompt, Problem-posing processes, Task variables, Task characteristics, Teaching mathematics through problem posing, P-PBL},
abstract = {This study used three pairs of problem-posing tasks to examine the impact of different prompts on students’ problem posing. Two kinds of prompts were involved. The first asked students to pose 2–3 different mathematical problems without specifying other requirements for the problems, whereas the second kind of prompt did specify additional requirements. A total of 2124 students’ responses were analyzed to examine the impact of the prompts along multiple dimensions. In response to problem-posing prompts with more specific requirements, students tended to engage in more in-depth mathematical thinking and posed much more linguistically and semantically complex problems with more relationships or steps required to solve them. The findings from this study not only contribute to our understanding of problem-posing processes but also have direct implications for teaching mathematics through problem posing.}
}
@article{MURRAY202483,
title = {Brain mechanisms of rumination and negative self-referential processing in adolescent depression},
journal = {Journal of Affective Disorders},
volume = {366},
pages = {83-90},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.08.114},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724013466},
author = {Laura Murray and Nigel M. Jaffe and Anna O. Tierney and Kristina Pidvirny and Emma G. Balkind and Batool S. Abbasi and Miranda Brown and Christian A. Webb},
keywords = {Depression, Adolescence, Ecological momentary assessment, fMRI, Rumination, Self-referent encoding task},
abstract = {Background
Depression is linked to cognitive biases towards more negative and less positive self-relevant information. Rumination, perseverative negative thinking about the past and the self, may contribute to these biases.
Methods
159 adolescents (12–18 years), with a range of depression symptoms, completed the SRET during fMRI. Multiple regressions tested associations between conventional self-report and ecological momentary assessment (EMA) measured rumination, and neural and behavioral responses during a self-referent encoding task (SRET).
Results
Higher rumination (conventional self-report and EMA) was associated with more negative and fewer positive words endorsed and recalled. Higher self-reported (but not EMA) rumination was associated with higher accuracy in recognizing negative words and greater insula and dorsal anterior cingulate activity to negative versus positive words.
Limitations
The sample included mostly non-Hispanic White participants with household incomes above the national average, highlighting the need for replication in more diverse samples. Word endorsement discrepancies required fMRI analyses to model neural response to viewing negative versus positive words.
Conclusions
Adolescents with higher rumination endorsed and recalled more negative and fewer positive words and recognized more negative words during the SRET. Higher insula reactivity, a key region for modulating externally-oriented attention and internally-oriented self-referential processes, may contribute to links between rumination and negative memory biases. These findings provide insight into neurocognitive mechanisms underlying depression.}
}
@article{COSTA20055,
title = {Interactive Computation: Stepping Stone in the Pathway From Classical to Developmental Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {141},
number = {5},
pages = {5-31},
year = {2005},
note = {Proceedings of the Workshop on the Foundations of Interactive Computation (FInCo 2005)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2005.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S157106610505187X},
author = {Antônio Carlos da Rocha Costa and Graçaliz Pereira Dimuro},
keywords = {Interactive computation, developmental computation, domain theory, classical theory of computation},
abstract = {This paper reviews and extends previous work on the domain-theoretic notion of Machine Development. It summarizes the concept of Developmental Computation and shows how Interactive Computation can be understood as a stepping stone in the pathway from Classical to Developmental Computation. A critical appraisal is given of Classical Computation, showing in which ways its shortcomings tend to restrict the possible evolution of real computers, and how Interactive and Developmental Computation overcome such shortcomings. The idea that Developmental Computation is more encompassing than Interactive Computation is stressed. A formal framework for Developmental Computation is sketched, and the current frontier of the work on Developmental Computation is briefly exposed.}
}
@article{NOWROOZI201252,
title = {A general computational recognition primed decision model with multi-agent rescue simulation benchmark},
journal = {Information Sciences},
volume = {187},
pages = {52-71},
year = {2012},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2011.09.039},
url = {https://www.sciencedirect.com/science/article/pii/S0020025511005330},
author = {Alireza Nowroozi and Mohammad E. Shiri and Angeh Aslanian and Caro Lucas},
keywords = {Naturalistic decision making, Recognition primed decision model, Computational modeling, Disaster management, RoboCup, Multi-agent rescue simulation benchmark},
abstract = {Analytical decision making strategies rely on weighing pros and cons of multiple options in an unbounded rationality manner. Contrary to these strategies, recognition primed decision (RPD) model which is a primary naturalistic decision making (NDM) approach assumes that experienced and professional decision makers when encounter problems in real operating conditions are able to use their previous experiences and trainings in order to diagnose the problem, recall the appropriate solution, evaluate it mentally, and implement it to handle the problem in a satisficing manner. In this paper, a computational form of RPD, now called C-RPD, is presented. Unified Modeling Language was used as a modeling language to represent the proposed C-RPD model in order to make the implementation easy and obvious. To execute the model, RoboCup Rescue agent simulation environment, which is one of the best and the most famous complex and multi-agent large-scale environments, was selected. The environment simulates the incidence of fire and earthquakes in urban areas where it is the duty of the police forces, firefighters and ambulance teams to control the crisis. Firefighters of SOS team are first modeled and implemented by utilizing C-RPD and then the system is trained using an expert’s experience. There are two evaluations. To find out the convergence of different versions developed during experience adding, some of the developed versions are chosen and evaluated on seven maps. Results show performance improvements. The SOS team ranked first in an official world championship and three official open tournaments.}
}
@article{GOLDSTONE2005424,
title = {Computational models of collective behavior},
journal = {Trends in Cognitive Sciences},
volume = {9},
number = {9},
pages = {424-430},
year = {2005},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2005.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661305002147},
author = {Robert L. Goldstone and Marco A. Janssen},
abstract = {Computational models of human collective behavior offer promise in providing quantitative and empirically verifiable accounts of how individual decisions lead to the emergence of group-level organizations. Agent-based models (ABMs) describe interactions among individual agents and their environment, and provide a process-oriented alternative to descriptive mathematical models. Recent ABMs provide compelling accounts of group pattern formation, contagion and cooperation, and can be used to predict, manipulate and improve upon collective behavior. ABMs overcome an assumption that underlies much of cognitive science – that the individual is the crucial unit of cognition. The alternative advocated here is that individuals participate in collective organizations that they might not understand or even perceive, and that these organizations affect and are affected by individual behavior.}
}
@article{HASUO2017404,
title = {Semantics of higher-order quantum computation via geometry of interaction},
journal = {Annals of Pure and Applied Logic},
volume = {168},
number = {2},
pages = {404-469},
year = {2017},
note = {Eighth Games for Logic and Programming Languages Workshop (GaLoP)},
issn = {0168-0072},
doi = {https://doi.org/10.1016/j.apal.2016.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168007216301336},
author = {Ichiro Hasuo and Naohiko Hoshino},
keywords = {Higher-order computation, Quantum computation, Programming language, Geometry of interaction, Denotational semantics, Categorical semantics},
abstract = {While much of the current study on quantum computation employs low-level formalisms such as quantum circuits, several high-level languages/calculi have been recently proposed aiming at structured quantum programming. The current work contributes to the semantical study of such languages by providing interaction-based semantics of a functional quantum programming language; the latter is, much like Selinger and Valiron's, based on linear lambda calculus and equipped with features like the ! modality and recursion. The proposed denotational model is the first one that supports the full features of a quantum functional programming language; we prove adequacy of our semantics. The construction of our model is by a series of existing techniques taken from the semantics of classical computation as well as from process theory. The most notable among them is Girard's Geometry of Interaction (GoI), categorically formulated by Abramsky, Haghverdi and Scott. The mathematical genericity of these techniques—largely due to their categorical formulation—is exploited for our move from classical to quantum.}
}
@article{EVINS2013230,
title = {A review of computational optimisation methods applied to sustainable building design},
journal = {Renewable and Sustainable Energy Reviews},
volume = {22},
pages = {230-245},
year = {2013},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364032113000920},
author = {Ralph Evins},
keywords = {Review, Optimisation, Sustainable, Building, Design, Multi-objective},
abstract = {This paper presents a comprehensive review of all significant research applying computational optimisation to sustainable building design problems. A summary of common heuristic optimisation algorithms is given, covering direct search, evolutionary methods and other bio-inspired algorithms. The main summary table covers 74 works that focus on the application of these methods to different fields of sustainable building design. Key fields are reviewed in detail: envelope design, including constructions and form; configuration and control of building systems; renewable energy generation; and holistic optimisations of several areas simultaneously, with particular focus on residential and retrofit. Improvements to the way optimisation is applied are also covered, including platforms and frameworks, algorithmic comparisons and developments, use of meta-models and incorporation of uncertainty. Trends, including the rise of multi-objective optimisation, are analysed graphically. Likely future developments are discussed.}
}
@article{JAGER2014117,
title = {Thinking outside the channel: Timing pulse flows to benefit salmon via indirect pathways},
journal = {Ecological Modelling},
volume = {273},
pages = {117-127},
year = {2014},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013005437},
author = {Henriette I. Jager},
keywords = {Reservoir releases, Environmental flows, Natural flow paradigm, Optimization, Quantile model, Pulse flows},
abstract = {Using models to represent relationships between flow and fishes has important practical applications for managing reservoir releases. Attempts to model such relationships often neglect indirect mechanisms by which flow influences fish. For example, growth of salmon juveniles is measurably faster when flows inundate floodplain and promote higher production of invertebrate prey, but out-of-channel flows have not yet been incorporated into models. The QUANTUS model developed here represents indirect linkages between flow and freshwater survival, mediated by temperature and prey availability, for fall Chinook salmon (Oncorhynchus tshawytscha). Quantiles of spawning time and place were used to define cohorts of salmon in a regulated Central Valley, California river. Survival of these quantile-cohorts was simulated through incubation, juvenile growth, and eventual downstream migration. A genetic algorithm was used to optimize the seasonal timing of pulse flows. Simulated survival was highest for flow regimes that provided a modest, temperature-moderating pulse flow in early summer and, for wetter years, a second, larger pulse of over-bank flow in late winter. For many rivers of the Pacific coast that support fall Chinook salmon, the thermal window of opportunity for spawning and rearing is narrow. Optimized flows made the most of this window by providing access to accelerated juvenile growth and early survival in floodplain habitat, a result that should be verified with field experiments. Timing of optimized pulse flows differed in some respects from the region's natural hydrograph, dominated by spring runoff. This suggests that understanding the mechanisms by which flow influences fishes can be important when shaping flows in the changed context of a regulated river.}
}
@article{EMILYESTHERRANI2025107032,
title = {Alzheimer disease classification using optimal clustering based pre-trained SqueezeNet model},
journal = {Biomedical Signal Processing and Control},
volume = {100},
pages = {107032},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.107032},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424010905},
author = {K. {Emily Esther Rani} and S. Baulkani},
keywords = {Alzheimer disease, Optimal center, Clustering, Adaptive reptile search algorithm, Pre-trained squeezenet},
abstract = {Alzheimer’s disease (AD) is an irreversible neurological illness identified by deficits in thinking, behavior, and memory. Early detection and prevention of AD is a crucial and difficult task. DL (Deep Learning) has gained significant attention recently as a potential tool for early AD detection. However, traditional diagnostic methods such as cognitive tests and manual analysis of brain imaging are time consuming and prone to error. Hence, there is a need for an automated model which shows better classification performance. To tackle these issues, this study presents a system to improve AD recognition performance. Initially, the pre-processing and skull stripping processes are performed. Then, for segmenting the grey, whiter matters and Cerebrospinal Fluid (CSF), the optimal clustering process is carried out. Here, the optimal center of clusters is selected by the metaheuristic optimization Adaptive Reptile Search Algorithm-Clustering Approach (ARSA-CA) is utilized. The proposed ARSA is the integration of the optimization RSA and simulated annealing (SA). Finally, for classifying the different classes of AD, the DL approach pre-trained SqueezeNet is utilized. The experimentation is carried out on the ADNI and OASIS datasets and achieved better accuracies of 98.3% and 98.2% respectively. Thus, it is proved that the proposed model is suitable for identifying AD.}
}
@incollection{ISMAIL2018165,
title = {Chapter 6 - High-Throughput Screening of Phytochemicals: Application of Computational Methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {165-192},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000067},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High-throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening , Natural product prototypes, Drug discovery and development, , , },
abstract = {This chapter reviews the origin and evolution of high-throughput screening (HTS) through the experience of the authors, who have either consulted for and/or provided courses to various pharmaceutical companies. It focuses on the role of HTS in natural product (phytochemicals) drug screening and drug discovery. Application of computational methods in HTS for phytochemical is highlighted. Commonly encountered difficulties and solutions to some of the problems are discussed together with selected ‘how to’ protocols to ensure investigators can set up and productively use HTS in their own natural product research. Relevant failures and successes in identifying interesting natural products are also outlined.}
}
@article{KOOLSCHIJN2024101453,
title = {Resources, costs and long-term value: an integrative perspective on serotonin and meta-decision making},
journal = {Current Opinion in Behavioral Sciences},
volume = {60},
pages = {101453},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101453},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624001049},
author = {Renée S Koolschijn and Bertalan Polner and Julie M Hoomans and Roshan Cools and Eliana Vassena and Hanneke EM {den Ouden}},
abstract = {Serotonin has been associated with a wide range of neural computations and behaviours, yet an overarching function of this neurotransmitter has been hard to pinpoint. Here, we combine recent theories and findings on serotonin and propose a framework where serotonin integrates information on resource availability and state value to represent a cost–benefit trade-off at the neural level. Critically, this framework supports meta-decision making, that is, the flexible allocation of resources to decision-making. We highlight a computational and neural implementation of this framework, and through this novel, lens interpret empirical findings in the domains of controllability and persistence.}
}
@article{HAMED2018112,
title = {Quantitative modeling of gene networks of biological systems using fuzzy Petri nets and fuzzy sets},
journal = {Journal of King Saud University - Science},
volume = {30},
number = {1},
pages = {112-119},
year = {2018},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1018364716307819},
author = {Raed I. Hamed},
keywords = {FPNs, Fuzzy sets, Uncertain data, GRNs, Quantitative modeling},
abstract = {Quantitative demonstrating of organic frameworks has turned into an essential computational methodology in the configuration of novel and investigation of existing natural frameworks. Be that as it may, active information that portrays the framework's elements should be known keeping in mind the end goal to get pertinent results with the routine displaying strategies. This information is frequently robust or even difficult to get. Here, we exhibit a model of quantitative fuzzy rational demonstrating approach that can adapt to obscure motor information and hence deliver applicable results despite the fact that dynamic information is fragmented or just dubiously characterized. Besides, the methodology can be utilized as a part of the blend with the current cutting edge quantitative demonstrating strategies just in specific parts of the framework, i.e., where the data are absent. The contextual analysis of the methodology suggested in this paper is performed on the model of nine-quality genes. We propose a kind of FPN model in light of fuzzy sets to manage the quantitative modeling of biological systems. The tests of our model appear that the model is practical and entirely powerful for information impersonation and thinking of fuzzy expert frameworks.}
}
@incollection{GOODSON2010175,
title = {Chapter 10 - Using Computational Modeling to Understand Microtubule Dynamics: A Primer for Cell Biologists},
editor = {Leslie Wilson and John J. Correia},
series = {Methods in Cell Biology},
publisher = {Academic Press},
volume = {95},
pages = {175-188},
year = {2010},
booktitle = {Microtubules, in vitro},
issn = {0091-679X},
doi = {https://doi.org/10.1016/S0091-679X(10)95010-3},
url = {https://www.sciencedirect.com/science/article/pii/S0091679X10950103},
author = {Holly V. Goodson and Ivan V. Gregoretti},
abstract = {Experimental cell biology, biochemistry, and structural biology have provided a wealth of information about microtubule function and mechanism, but we are reaching a limit as to what can be understood from experiment alone. Standard biochemical approaches are not sufficient to make quantitative predictions about microtubule behavior, and they are limited in their ability to test existing conceptual models of microtubule mechanism. Because microtubules are so complex, achieving a deep understanding of microtubule behavior and mechanism will require the input of mathematical and computational modeling. However, this type of analysis can be daunting to the uninitiated. The purpose of this chapter is to provide a straightforward introduction to the various types of modeling and how they can be used to study microtubule function, dynamics, and mechanism.}
}
@article{SZUBA1998321,
title = {A molecular quasi-random model of computations applied to evaluate collective intelligence},
journal = {Future Generation Computer Systems},
volume = {14},
number = {5},
pages = {321-339},
year = {1998},
note = {Bio-inspired solutions to parallel processing problems},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(98)00037-5},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X98000375},
author = {Tadeusz Szuba},
keywords = {Collective intelligence, IQ measure, Social structure, PROLOG, Model of computations, Brownian movements},
abstract = {This paper presents a bio-inspired model of computations, the random PROLOG processor (RPP), used for analysis of collective intelligence (CI). In the RPP, clause_molecules (CMs) of facts, rules, goals, or higher-level logical structures enclosed by membranes move quasi-randomly in structured computational_PROLOG_space (CS). When CMs rendezvous, an inference process can occur iff the logical conditions are fulfilled. CI can be evaluated as follows: (1) the mapping is done of a given social structure into the RPP; (2) the beings and their behavior are translated into PROLOG expressions, carried by CMs; (3) the goal(s) of the social structure are translated into N-element inference (NEI); (4) the efficiency of the NEI is evaluated and given as the intelligence quotient of a social structure (IQS) projected onto NEI.}
}
@article{HAYASHI1999507,
title = {Numerical models of HDR geothermal reservoirs—a review of current thinking and progress},
journal = {Geothermics},
volume = {28},
number = {4},
pages = {507-518},
year = {1999},
issn = {0375-6505},
doi = {https://doi.org/10.1016/S0375-6505(99)00026-7},
url = {https://www.sciencedirect.com/science/article/pii/S0375650599000267},
author = {Kazuo Hayashi and Jonathan Willis-Richards and Robert J Hopkirk and Yuichi Niibori},
keywords = {Reservoir, Hot dry rock, HDR, Modelling, Numerical simulation},
abstract = {A brief review is presented of modelling and simulation of HDR geothermal reservoirs both for hydraulic fracturing/stimulation to create artificial/engineered geothermal reservoirs and for long-term heat extraction operations. Firstly, modelling of the governing factors is surveyed and coupling among mechanical, thermal, hydraulic and chemical effects is discussed. Next the structure and modelling of reservoirs are discussed. Finally, the features of a variety of simulation codes are summarized.}
}
@article{JACKSON20091397,
title = {There may be more to reaching than meets the eye: Re-thinking optic ataxia},
journal = {Neuropsychologia},
volume = {47},
number = {6},
pages = {1397-1408},
year = {2009},
note = {Perception and Action},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2009.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0028393209000475},
author = {Stephen R. Jackson and Roger Newport and Masud Husain and Jane E. Fowlie and Michael O’Donoghue and Nin Bajaj},
keywords = {Optic ataxia, Neuropsychology of action, Reaching},
abstract = {Optic ataxia (OA) is generally thought of as a disorder of visually guided reaching movements that cannot be explained by any simple deficit in visual or motor processing. In this paper we offer a new perspective on optic ataxia; we argue that the popular characterisation of this disorder is misleading and is unrepresentative of the pattern of reaching errors typically observed in OA patients. We begin our paper by reviewing recent neurophysiological, neuropsychological, and functional brain imaging studies that have led to the proposal that the medial parietal cortex in the vicinity of the parietal-occipital junction (POJ) – the key anatomical site associated with OA – represents reaching movements in eye-centred coordinates, and that this ability is impaired in optic ataxia. Our perspective stresses the importance of the POJ and superior parietal regions of the human PPC for representing reaching movements in both extrinsic (eye-centred) and intrinsic (postural) coordinates, and proposes that it is the ability to simultaneously represent multiple spatial locations that must be directly compared with one another that is impaired in non-foveal OA patients. In support of this idea we review recent fMRI and behavioural studies conducted by our group that have investigated the anatomical correlates of posturally guided movements, and the movements guided by postural cues in patients presenting with optic ataxia.}
}
@article{KEOGH2007249,
title = {Keeping the patient asleep and alive: Towards a computational cognitive model of disturbance management in anaesthesia},
journal = {Cognitive Systems Research},
volume = {8},
number = {4},
pages = {249-261},
year = {2007},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041707000034},
author = {K. Keogh and E.A. Sonenberg},
keywords = {Behavioural analysis, Computational cognitive modelling, Disturbance management},
abstract = {We have analysed rich, dynamic data about the behaviour of anaesthetists during the management of a simulated critical incident in the operating theatre. We use a paper based analysis and a partial implementation to further the development of a computational cognitive model for disturbance management in anaesthesia. We suggest that our data analysis pattern may be used for the analysis of behavioural data describing cognitive and observable events in other complex dynamic domains.}
}
@incollection{REIMERS2006119,
title = {[8] Bioconductor: An Open Source Framework for Bioinformatics and Computational Biology},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {411},
pages = {119-134},
year = {2006},
booktitle = {DNA Microarrays, Part B: Databases and Statistics},
issn = {0076-6879},
doi = {https://doi.org/10.1016/S0076-6879(06)11008-3},
url = {https://www.sciencedirect.com/science/article/pii/S0076687906110083},
author = {Mark Reimers and Vincent J. Carey},
abstract = {This chapter describes the Bioconductor project and details of its open source facilities for analysis of microarray and other high‐throughput biological experiments. Particular attention is paid to concepts of container and workflow design, connections of biological metadata to statistical analysis products, support for statistical quality assessment, and calibration of inference uncertainty measures when tens of thousands of simultaneous statistical tests are performed.}
}
@article{REYNANTE2024102287,
title = {Reducing the cognitive abstractness of climate change through an “engineering fiction” learning experience: A natural language processing study},
journal = {Journal of Environmental Psychology},
volume = {95},
pages = {102287},
year = {2024},
issn = {0272-4944},
doi = {https://doi.org/10.1016/j.jenvp.2024.102287},
url = {https://www.sciencedirect.com/science/article/pii/S0272494424000604},
author = {Brandon Reynante and Nicole M. Ardoin and Roy Pea},
keywords = {Artificial intelligence, Climate change education, Climate fiction},
abstract = {The lackluster societal response to the climate crisis is partially attributed to the abstractness of people's mental construals of climate change given its vast spatial and temporal dimensions, which fail to evoke urgency to act. Prior efforts to measure mental construal levels of climate change are inconsistent, insufficient, and labor-intensive. This study developed and implemented learning experiences for integrating engineering design and climate fiction writing to engage 48 high school students in concrete climate change thinking. A novel measure of cognitive abstractness overcomes previous methodological shortcomings by automatically quantifying the linguistic abstractness of participant-authored stories using natural language processing. Comparing participant stories written at the beginning and end of the intervention reveals a significant decrease in linguistic abstractness (Cohen's d = 1.01, p = 0.03). This study contributes to the nascent movement for greater use of narratives as data sources in environmental psychology research, which may uncover new insights into human behavior and decision making.}
}
@article{IOAKIMIDIS2017280,
title = {Caustics, pseudocaustics and the related illuminated and dark regions with the computational method of quantifier elimination},
journal = {Optics and Lasers in Engineering},
volume = {88},
pages = {280-300},
year = {2017},
issn = {0143-8166},
doi = {https://doi.org/10.1016/j.optlaseng.2016.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0143816616301348},
author = {Nikolaos I. Ioakimidis},
keywords = {Caustics, Pseudocaustics, Illuminated and dark regions, Cracks, Plates, Elasticity},
abstract = {The method of caustics is a powerful experimental method in elasticity and particularly in fracture mechanics for crack problems. The related method of pseudocaustics is also of interest. Here we apply the computational method of quantifier elimination implemented in the computer algebra system Mathematica in order to determine (i) the non-parametric equation and two properties of the caustic at a crack tip and especially (ii) the illuminated and the dark regions related to caustics and pseudocaustics in plane elasticity and plate problems. The present computations concern: (i) The derivation of the non-parametric equation of the classical caustic about a crack tip through the elimination of the parameter involved (here the polar angle) as well as two geometrical properties of this caustic. (ii) The derivation of the inequalities defining the illuminated region on the screen in the problem of an elastic half-plane loaded normally by a concentrated load with the boundary of this illuminated region related to some extent to the caustic formed. (iii) Similarly for the problem of a clamped circular plate under a uniform loading with respect to the caustic and the pseudocaustic formed. (iv) Analogously for the problem of an equilateral triangular plate loaded by uniformly distributed moments along its whole boundary, which defines the related pseudocaustic. (v) The determination of quantities of interest in mechanics from the obtained caustics or pseudocaustics. The kind of computations in the applications (ii) to (iv), i.e. the derivation of inequalities defining the illuminated region on the screen, seems to be completely new independently of the use here of the method of quantifier elimination. Additional applications are also possible, but some of them require the expansion of the present somewhat limited power of the quantifier elimination algorithms in Mathematica. This is expected to take place in the future.}
}
@article{KE201426,
title = {An implementation of design-based learning through creating educational computer games: A case study on mathematics learning during design and computing},
journal = {Computers & Education},
volume = {73},
pages = {26-39},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513003345},
author = {Fengfeng Ke},
keywords = {Learning by design, Game-based learning, Mathematical disposition, Thinking mathematically, Computer game making},
abstract = {This mixed-method case study examined the potential of computer-assisted, math game making activities in facilitating design-based math learning for school children. Sixty-four middle school children participated in Scratch-based, math game making activities. Data were collected via activity and conversation observation, artifact analysis, interviewing, and survey. The study findings indicated that participants developed significantly more positive dispositions toward mathematics after computer game making. The study also found that experience-driven game design processes helped to activate children's reflection on everyday mathematical experiences. Mathematical thinking and content experience were intertwined within the process of computer game authoring. On the other hand, children designers were involved in game-world and story crafting more than mathematical representation. And it was still challenging for them to perform computer game coding with abstract reasoning.}
}
@article{TOFFOLI20103,
title = {From Such Simple a Beginning: The Momentous Consequences of Physics' Microscopic Reversibility for Communication and Computation—and Almost Anything Else},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {253},
number = {6},
pages = {3-16},
year = {2010},
note = {Proceedings of the Workshop on Reversible Computation (RC 2009)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2010.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1571066110000150},
author = {Tommaso Toffoli},
keywords = {invertibility, irreversibility, computation, dynamics, thermodynamics, entropy, second law of thermodynamics},
abstract = {Darwin concludes The Origin of Species with a splendid one-phrase poem,From so simple a beginningendless forms most beautiful and most wonderfulhave been, and are being, evolved. Darwin's “simple beginning” may be identified, in today's terminology, with dissipation—evolution's basic fuel. All the rest is commentary—or, more precisely, corollary. One can aptly apply Darwin's phrase to another kind of “simple beginning,” from which as well “endless forms most beautiful and most wonderful have been, and are being, evolved.” What I have in mind is a concept that is apparently the very antithesis of dissipation, namely, physics' fundamental assumption of invertibility—or “microscopic reversibility.” To paraphrase Dobzhansky, no sensible step can be taken today in information, communication, and computer sciences, as well as in fundamental physics, except in the light of invertibility.}
}
@article{BAHLS2015104,
title = {LaTeXnics: The effect of specialized typesetting software on STEM students’ composition processes},
journal = {Computers and Composition},
volume = {37},
pages = {104-116},
year = {2015},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2015.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S8755461515000511},
author = {Patrick Bahls and Amanda Wray},
keywords = {Computer-Mediated communication, STEM writing, Writing process, LaTeX, Markup languages, Typesetting tools},
abstract = {Undergraduate science, technology, engineering, and mathematics (STEM) students are often trained to use technical typesetting software in order to produce authentic mathematical prose, though little research exists about how this writing technology impacts students’ thinking and computation process. Drawing upon survey and interview research conducted at two liberal arts institutions, the authors investigate student writing practices across several undergraduate mathematics courses that required the use of LaTeX (a common markup language allowing users to specify the appearance of text and its layout on the printed page). This article presents findings about how the use of LaTeX slowed down students’ writing process, encouraging greater revision and reflection as well as allowing students to identify errors in their work at more than one stage in the process. We also explore the affective learning outcomes of STEM students using typesetting software, including increased feelings of confidence and professionalization. This article seeks to contribute to the growing conversation about how STEM students transfer knowledge about writing across disciplines.}
}