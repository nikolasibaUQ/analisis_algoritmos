@article{RIBEIRO2011639,
title = {Re-thinking diagnosis for future automation systems: An analysis of current diagnostic practices and their applicability in emerging IT based production paradigms},
journal = {Computers in Industry},
volume = {62},
number = {7},
pages = {639-659},
year = {2011},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2011.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166361511000303},
author = {Luis Ribeiro and Jose Barata},
keywords = {Diagnosis, Reconfigurable manufacturing systems, Adaptive production systems},
abstract = {With the advent of the Internet and the progressive development and consolidation of a wide range of web standards and technologies as well as the advances in distributed artificial intelligence (DAI), namely the multi agent system concept, new opportunities have emerged for conceiving, modelling and enhancing shop floor's performance and response. Modern IT-supported production paradigms denote a common concept where the shop floor is a lively entity composed by interacting intelligent modules whose individual and collective function adapts and evolves ensuring the fitness and adequacy of the organization, owning the system, in tackling profitable but volatile business opportunities. The self-organizing and peer to peer nature of these systems renders a collective behaviour and dynamics that are fundamentally new. Conventional diagnostic methods and tools have not been designed targeting the envisioned systems therefore lack the required support. In this paper the emerging IT-based production paradigms are surveyed as well as the existing diagnostic methods whose adequacy is analysed. The resulting requirements and characteristics are exposed to stress the need for rethinking current diagnostic practices in future automation systems.}
}
@article{LONG201743,
title = {A framework for data-driven computational experiments of inter-organizational collaborations in supply chain networks},
journal = {Information Sciences},
volume = {399},
pages = {43-63},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517305807},
author = {Qingqi Long},
keywords = {Data-driven, Computational experiment, Inter-organizational collaboration, Supply chain network},
abstract = {Internet+ecosystems, big data applications, customers’ specific demands, and internal and external values integration of enterprises pose new challenges to inter-organizational collaborations in supply chain networks. To confront these challenges, this paper integrates computational experiment and data analysis, and proposes a methodology for data-driven computational experiments for inter-organizational collaborations in supply chain networks. It explores a paradigm shift to the development of data-driven computational experiments that supports decision making in the domain of inter-organizational collaborations. A basic principle for integrated solutions generation in the parallel worlds of virtual reality interaction is studied and the corresponding key issues in the paradigm are analyzed. To support the paradigm and solve key issues, a six-layered framework with four viewpoints for data-driven computational experiments is proposed. This framework systematically presents conceptual and technical solutions for data-driven computational experiments and decision support in the domain of inter-organizational collaborations in supply chain networks. The effectiveness of the framework is verified by theoretical analysis and a case study.}
}
@article{THOWYICK1998275,
title = {General information theory: Some macroscopic dynamics of the human thinking systems},
journal = {Information Processing & Management},
volume = {34},
number = {2},
pages = {275-290},
year = {1998},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(97)00069-1},
url = {https://www.sciencedirect.com/science/article/pii/S0306457397000691},
author = {Liang Thow-Yick},
abstract = {This study is an attempt to put in place the component of the general information theory that explains the macroscopic dynamics of the human thinking systems. The fundamental structure of such a theory must include the domains of external basic entity interactions, external basic entity and information-coded energy quantum transformations, and energy quantum and information-coded matter interactions. In this respect, a human thinking system is perceived to have at least a natural energy-matter subsystem and a human-created physical symbol subsystem. The artifacts of the human-created subsystem are the external basic physical entities, namely, data, information, knowledge, and wisdom. The intrinsic and interactive properties of these entities depict the characteristics of the physical symbol subsystem. Besides interacting among themselves, the external entities also interact with the natural entities, the information-coded energy quanta, according to certain rules and principles. Subsequently, the energy quanta interact with the information-coded matter structure. Such interactions occurring within the individual subsystems and between the two subsystems constitute the dynamics of the human thinking systems. In intelligent systems of this nature information can exist in physical, energy and matter forms, and the different forms are interconvertible. The interactions among these entities and the conversion of one form to another is made possible by the existence of an intelligence space in the human mind.}
}
@article{CHECIU2024127324,
title = {Reconstructing creative thoughts: Hopfield neural networks},
journal = {Neurocomputing},
volume = {575},
pages = {127324},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127324},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400095X},
author = {Denisa Checiu and Mathias Bode and Radwa Khalil},
keywords = {Creative Thinking, Hopfield Neural Network, Patterns, Memory, Associative Chains, Semantic Association},
abstract = {From a brain processing perspective, the perception of creative thinking is rooted in the underlying cognitive process, which facilitates exploring and cultivating novel avenues and problem-solving strategies. However, it is challenging to emulate the intricate complexity of how the human brain presents a novel way to uncover unique solutions. One potential approach to mitigating this complexity is incorporating creative cognition into the evolving artificial intelligence systems and associated neural models. Hopfield neural network (HNN) are commonly acknowledged as a simplified neural model, renowned for their biological plausibility to store and retrieve information, specifically patterns of neurons. Our findings suggest utilizing modern HNN to emulate creative thinking by making meaningful associations between seemingly disparate concepts. This semantic link is represented as a radio knob that can be set to determine whether the network solves problems creatively or shuts down; the threshold is a parameter. We used the term "first knob of creativity" to describe a certain pattern and utilized the "second knob of creativity" to aid in the examination of alternatives within the network. By manipulating the knobs, it is possible to selectively suppress specific patterns, facilitating the creative functioning of the HNN and identifying other patterns with which input can be linked.}
}
@article{HARRY20228413,
title = {Rational Computational Design of Systems Exhibiting Strong Halogen Bonding Involving Fluorine in Bicyclic Diamine Derivatives},
journal = {The Journal of Organic Chemistry},
volume = {87},
number = {13},
pages = {8413-8419},
year = {2022},
issn = {0022-3263},
doi = {https://doi.org/10.1021/acs.joc.2c00497},
url = {https://www.sciencedirect.com/science/article/pii/S0022326322023404},
author = {Stefan Andrew Harry and Srini Vemulapalli and Travis Dudding and Thomas Lectka},
abstract = {ABSTRACT
Perhaps the most controversial and rare aspect of the halogen bonding interaction is the potential of fluorine in compounds to serve as a halogen bond donor. In this note, we provide clear and convincing examples of hypothetical molecules in which fluorine is strongly halogen bonding in a metastable state. Of particular note is a polycyclic system inspired by Selectfluor, which has been controversially proposed to engage in halogen bonding.}
}
@article{ANANE20221103,
title = {Modular Robotic Prefabrication of Discrete Aggregations Driven by BIM and Computational Design},
journal = {Procedia Computer Science},
volume = {200},
pages = {1103-1112},
year = {2022},
note = {3rd International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.01.310},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922003192},
author = {Walid Anane and Ivanka Iordanova and Claudiane Ouellet-Plamondon},
keywords = {BIM, Computational Design, Robotic Fabrication, Discrete Architecture, Modular Construction},
abstract = {Discrete architecture is recognized as a computational design approach which uses computation to generate algorithmically combinable aggregations. It is therefore a promising innovation for increasing design process productivity through the adaptability of the aggregations it generates. In the built environment, discrete design is usually identified with the modular method. It is a construction process based on the aggregation of different modules assembled according to well-defined connections to ensure the building’s integrity and functionality. It involves off-site manufacturing, and hence a controlled environment ensuring more predictability over weathering and change. But like in conventional construction practices, the fragmentation of modular construction processes hinders its productivity. As a result, this construction approach requires adequate technologies and communication tools to improve collaboration and productivity. This paper aims to address these requirements by adopting a BIM-driven computational approach to design processes and a robotic approach to prefabrication processes. It proposes a modular construction framework for design and production, and presents the results through a study adopting BIM-driven discrete design and robotic manufacturing.}
}
@article{HEMMO201990,
title = {The physics of implementing logic: Landauer's principle and the multiple-computations theorem},
journal = {Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics},
volume = {68},
pages = {90-105},
year = {2019},
issn = {1355-2198},
doi = {https://doi.org/10.1016/j.shpsb.2019.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1355219819300048},
author = {Meir Hemmo and Orly Shenker},
keywords = {Entropy, Individuation of computation, Landauer's principle, Logical (ir)reversibility, Second law of thermodynamics},
abstract = {This paper makes a novel linkage between the multiple-computations theorem in philosophy of mind and Landauer's principle in physics. The multiple-computations theorem implies that certain physical systems implement simultaneously more than one computation. Landauer's principle implies that the physical implementation of “logically irreversible” functions is accompanied by minimal entropy increase. We show that the multiple-computations theorem is incompatible with, or at least challenges, the universal validity of Landauer's principle. To this end we provide accounts of both ideas in terms of low-level fundamental concepts in statistical mechanics, thus providing a deeper understanding of these ideas than their standard formulations given in the high-level terms of thermodynamics and cognitive science. Since Landauer's principle is pivotal in the attempts to derive the universal validity of the second law of thermodynamics in statistical mechanics, our result entails that the multiple-computations theorem has crucial implications with respect to the second law. Finally, our analysis contributes to the understanding of notions, such as “logical irreversibility,” “entropy increase,” “implementing a computation,” in terms of fundamental physics, and to resolving open questions in the literature of both fields, such as: what could it possibly mean that a certain physical process implements a certain computation.}
}
@article{MARTINEZ20001657,
title = {Systems thinking and functional modeling of batch process management using projects},
journal = {Computers & Chemical Engineering},
volume = {24},
number = {2},
pages = {1657-1663},
year = {2000},
issn = {0098-1354},
doi = {https://doi.org/10.1016/S0098-1354(00)00446-4},
url = {https://www.sciencedirect.com/science/article/pii/S0098135400004464},
author = {E.C. Martinez},
keywords = {Batch process management, Systems thinking, Functional modeling},
abstract = {Intense competition and rapid environmental changes are revealing severe limitations in the effectiveness of the hierarchical, stable and Tayloristic management system currently used by the vast majority of batch manufacturing industries. A project-oriented enterprise model of batch plants which results of integrating together systems thinking and functional modeling is proposed here. The latter refers to the set of intents and relationships between goals, functions and components (both physical and abstract) that comprise an analytical viewpoint of batch processes involving product recipes, equipment capabilities, constraints and human competencies (skills and knowledge). Complementarily, the systemic perspective accounts for the organizational setting (roles, objectives and actors), and provides an orthogonal view through the duality of whole-parts relationships and the ubiquitous concepts of boundary, emergence and hierarchy upon which the project-oriented enterprise model is built. A case study that comprises a dairy facility involving the production + 100 different fresh products using an order-driven management system will be presented. To support the prototype implementation of a plant information system using a hierarchy of project-based objects, a conceptual design has been developed. The implementation of the resulting enterprise model in Project 98™ will be discussed to highlight its easy and cheap implementation, and a number of advantages including: accumulation of information and knowledge, direct tracing of activities and cost analysis.}
}
@article{2024,
title = {Commentator Discussion: Autonomous Fontan pump: Computational feasibility study},
journal = {JTCVS Open},
year = {2024},
issn = {2666-2736},
doi = {https://doi.org/10.1016/j.xjon.2024.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S2666273624001906}
}
@article{RICHARDSON2021107607,
title = {TurboPy: A lightweight python framework for computational physics},
journal = {Computer Physics Communications},
volume = {258},
pages = {107607},
year = {2021},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2020.107607},
url = {https://www.sciencedirect.com/science/article/pii/S0010465520302897},
author = {A.S. Richardson and D.F. Gordon and S.B. Swanekamp and I.M. Rittersdorf and P.E. Adamson and O.S. Grannis and G.T. Morgan and A. Ostenfeld and K.L. Phlips and C.G. Sun and G. Tang and D.J. Watkins},
keywords = {Framework, Physics, Computational physics, Python, Dynamic factory pattern, Resource sharing},
abstract = {Computational physics problems often have a common set of aspects to them that any particular numerical code will have to address. Because these aspects are common to many problems, having a framework already designed and ready to use will not only speed the development of new codes, but also enhance compatibility between codes. Some of the most common aspects of computational physics problems are: a grid, a clock which tracks the flow of the simulation, and a set of models describing the dynamics of various quantities on the grid. Having a framework that could deal with these basic aspects of the simulation in a common way could provide great value to computational scientists by solving various numerical and class design issues that routinely arise. This paper describes the newly developed computational framework that we have built for rapidly prototyping new physics codes. This framework, called turboPy, is a lightweight physics modeling framework based on the design of the particle-in-cell code turboWAVE. It implements a class (called Simulation) which drives the simulation and manages communication between physics modules, a class (called PhysicsModule) which handles the details of the dynamics of the various parts of the problem, and some additional classes such as a Grid class and a Diagnostic class to handle various ancillary issues that commonly arise.
Program summary
Program Title: TurboPy CPC Library link to program files: http://dx.doi.org/10.17632/rznn6s5myw.1 Developer’s repository link: https://github.com/NRL-Plasma-Physics-Division/turbopy Licensing provisions: CC0 1.0 Programming language: Python Nature of problem: Many computation physics problems have a common set of aspects to them that are often addressed in a custom way in every different code, which leads to lengthy and redundant development and testing, as well as introducing roadblocks to interoperability. Solution method: Implement a set of python classes as a lightweight framework that deals with these common problems, so that development time on new computational physics codes is reduced, and interoperability and reusability are increased. References: A.S. Richardson et al., TurboPy: A lightweight computational physics framework. NRL-Plasma-Physics-Division/turbopy (v2020.08.05). doi:10.5281/zenodo.3973693}
}
@article{AKRAMI20124,
title = {Lateral thinking, from the Hopfield model to cortical dynamics},
journal = {Brain Research},
volume = {1434},
pages = {4-16},
year = {2012},
note = {Selected papers presented at the International Workshop on Neural Coding, Limassol, Cyprus, 29 October - 3 November 2010},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2011.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0006899311013151},
author = {Athena Akrami and Eleonora Russo and Alessandro Treves},
keywords = {Neural computation, Associative memory, Cortical dynamics, Modular network},
abstract = {Self-organizing attractor networks may comprise the building blocks for cortical dynamics, providing the basic operations of categorization, including analog-to-digital conversion, association and auto-association, which are then expressed as components of distinct cognitive functions depending on the contents of the neural codes in each region. To assess the viability of this scenario, we first review how a local cortical patch may be modeled as an attractor network, in which memory representations are not artificially stored as prescribed binary patterns of activity as in the Hopfield model, but self-organize as continuously graded patterns induced by afferent input. Recordings in macaques indicate that such cortical attractor networks may express retrieval dynamics over cognitively plausible rapid time scales, shorter than those dominated by neuronal fatigue. A cortical network encompassing many local attractor networks, and incorporating a realistic description of adaptation dynamics, may be captured by a Potts model. This network model has the capacity to engage long-range associations into sustained iterative attractor dynamics at a cortical scale, in what may be regarded as a mathematical model of spontaneous lateral thought. This article is part of a Special Issue entitled: Neural Coding.}
}
@article{ISMAILOVA202293,
title = {Lambda-calculus, combinators and applicative computational technologies},
journal = {Cognitive Systems Research},
volume = {76},
pages = {93-100},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000468},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {Lambda-calculus, Combinators, Compositional system, Cognitive activity},
abstract = {Applicative computing systems and technologies have taken a strong position in modern computing. In this paper, the basic applicative system, whether it is a lambda calculus or a system of combinators, is considered as a prototype concept system, using which it is possible to build individual systems that are practically significant for mathematics, computing, or programming. They are families of computational models that have both their own semantics and applied areas. This conceptualization/individualization technique is characteristic of the field of semantic studies. As it turns out, the applicative approach forms a metatheoretical framework that provides the basis for cognitive systems that consider abstract objects and interpret their properties and behavior in the environment of modern computing.}
}
@article{KONSTANTINIDOU2022104424,
title = {Teaching with technology: A large-scale, international, and multilevel study of the roles of teacher and school characteristics},
journal = {Computers & Education},
volume = {179},
pages = {104424},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104424},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521003018},
author = {Evi Konstantinidou and Ronny Scherer},
keywords = {Data science applications in education, Information literacy, Teaching/learning strategies, 21st century abilities},
abstract = {Providing high-quality instruction with technology has become more important than ever before. However, the instructional practices and the degree to which key skills, such as digital literacy and computational thinking, are emphasized in classrooms vary considerably between teachers, schools, and countries. The present study was aimed at explaining this variation in the frequency of teaching practices with technology and teachers' emphasis on developing students' computer and information literacy and computational thinking by key aspects of teacher motivation and expertise, school conditions and priorities, and countries' economy and innovation. Utilizing large-scale, representative data from the International Computer and Information Literacy Study (ICILS) 2018 (15,015 teachers in 1195 schools in eight countries), we performed multilevel structural equation modeling and regression trees and found that teacher motivation and collaboration were positively and consistently linked to teaching practices across countries. Besides, principals' expectations concerning the teaching with technology explained variation in Finnish and German schools. In three countries, teachers' professional development was related to their teaching practices. Finally, countries’ economic development and innovation explained variation in the teacher-level effects. Our study sheds new light on the possible factors related to teaching with technology and advances the field by taking a multilevel and international perspective on these factors.}
}
@article{GOVINDAN2019653,
title = {Computational decision framework for enhancing resilience of the energy, water and food nexus in risky environments},
journal = {Renewable and Sustainable Energy Reviews},
volume = {112},
pages = {653-668},
year = {2019},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2019.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364032119304083},
author = {Rajesh Govindan and Tareq Al-Ansari},
keywords = {Energy, water, and food nexus, Risk management, Artificial intelligence, Regime switching, Reinforcement learning},
abstract = {The energy, water and food (EWF) nexus modelling and analysis frameworks proposed recently have demonstrated their effectiveness in the assessment and quantification of synergies and trade-offs in the interlinkages between the three sectors. They largely rely on static, deterministic or equilibrium-based models that facilitate in making decisions for well-behaved and predictable resource systems over time. These frameworks, however, are partly limited in their functionality due to the fact that they do not consider the exposure of systems to the dynamic nature of extrinsic uncertainties and the associated risks in the nexus. Hence, there is a need for a sequential learning, planning and optimal control modelling framework which could help achieve adaptive systems under volatile conditions with the objective to maximise economic output and enhance their operational resilience. In this paper, the authors discuss the development of a novel computational framework which incorporates “algorithmic resilience thinking” to achieve adaptive and robust inter-networked systems. Here, the question of adaptive systems for EWF nexus resilience is posed as a reinforcement learning problem based on sequential decision-making called the Markov decision process (MDP). The authors further discuss a case study, considering weather volatility, its spatial impact on vegetation, and the consequent risks on the water-food nexus for outdoor agricultural operations in the State of Qatar. The application of the developed framework particularly demonstrates promise in providing the functionality to track and mitigate emerging risks that have the potential to cause unprecedented disruption in the operations of integrated natural resource systems. The outcome of this study has positive implications for the advancement and effectiveness of EWF nexus planning and risk management to avert resource shortages and price risks, socio-economic disruption, and cascading failures of critical infrastructures, particularly when the global supply chains are subjected to stresses and shocks, such as extreme weather conditions.}
}
@article{MOINGEON2022215,
title = {Artificial intelligence-enhanced drug design and development: Toward a computational precision medicine},
journal = {Drug Discovery Today},
volume = {27},
number = {1},
pages = {215-222},
year = {2022},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2021.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S1359644621003962},
author = {Philippe Moingeon and Mélaine Kuenemann and Mickaël Guedj},
keywords = {Artificial Intelligence, Big data, Computational precision medicine, Disease model, Drug discovery & development, Machine learning},
abstract = {Artificial Intelligence (AI) relies upon a convergence of technologies with further synergies with life science technologies to capture the value of massive multi-modal data in the form of predictive models supporting decision-making. AI and machine learning (ML) enhance drug design and development by improving our understanding of disease heterogeneity, identifying dysregulated molecular pathways and therapeutic targets, designing and optimizing drug candidates, as well as evaluating in silico clinical efficacy. By providing an unprecedented level of knowledge on both patient specificities and drug candidate properties, AI is fostering the emergence of a computational precision medicine allowing the design of therapies or preventive measures tailored to the singularities of individual patients in terms of their physiology, disease features, and exposure to environmental risks.}
}
@article{SCHORR2000209,
title = {Impact at the student level: a study of the effects of a teacher development intervention on students' mathematical thinking},
journal = {The Journal of Mathematical Behavior},
volume = {19},
number = {2},
pages = {209-231},
year = {2000},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(00)00045-6},
url = {https://www.sciencedirect.com/science/article/pii/S0732312300000456},
author = {Roberta Y Schorr},
keywords = {mathematics education, problem solving, teacher development},
abstract = {This research was conducted to study the impact on students of a long-term professional development intervention in mathematics for teachers in a low-wealth, urban school district. The emphasis in this assessment design was on obtaining a more accurate picture of student's problem-solving performance which challenged us to raise our expectations about student success from improved standardized test score data to an approach that focused on the way students think about mathematical tasks. The design used in this assessment provides a framework for considering teacher development and student assessment simultaneously. Results show that students taught by project teachers performed better in both classroom problem-solving activities and task-based interviews than students taught by nonproject teachers. In addition, there were major differences in the problem-solving behaviors of the two groups. Experimental students (students of project teachers) displayed greater mathematical confidence, and were more likely to see mathematics as a powerful way of thinking about the real world and approach mathematics as such.}
}
@article{KELLOGG2023255,
title = {Merging cultures and disciplines to create a drug discovery ecosystem at Virginia commonwealth university: Medicinal chemistry, structural biology, molecular and behavioral pharmacology and computational chemistry},
journal = {SLAS Discovery},
volume = {28},
number = {6},
pages = {255-269},
year = {2023},
note = {Emerging Drug Discovery Ecosystems},
issn = {2472-5552},
doi = {https://doi.org/10.1016/j.slasd.2023.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S2472555223000175},
author = {Glen E. Kellogg and Yana Cen and Malgorzata Dukat and Keith C. Ellis and Youzhong Guo and Jiong Li and Aaron E. May and Martin K. Safo and Shijun Zhang and Yan Zhang and Umesh R. Desai},
keywords = {Drug discovery ecosystem, Structure-based drug discovery, Quantitative structure-activity relationships, Computational glycomics, Drug Discrimination, Allosteric effectors of hemoglobin, G protein-coupled receptors, Experimental structural biology, High-throughput screening},
abstract = {The Department of Medicinal Chemistry, together with the Institute for Structural Biology, Drug Discovery and Development, at Virginia Commonwealth University (VCU) has evolved, organically with quite a bit of bootstrapping, into a unique drug discovery ecosystem in response to the environment and culture of the university and the wider research enterprise. Each faculty member that joined the department and/or institute added a layer of expertise, technology and most importantly, innovation, that fertilized numerous collaborations within the University and with outside partners. Despite moderate institutional support with respect to a typical drug discovery enterprise, the VCU drug discovery ecosystem has built and maintained an impressive array of facilities and instrumentation for drug synthesis, drug characterization, biomolecular structural analysis and biophysical analysis, and pharmacological studies. Altogether, this ecosystem has had major impacts on numerous therapeutic areas, such as neurology, psychiatry, drugs of abuse, cancer, sickle cell disease, coagulopathy, inflammation, aging disorders and others. Novel tools and strategies for drug discovery, design and development have been developed at VCU in the last five decades; e.g., fundamental rational structure-activity relationship (SAR)-based drug design, structure-based drug design, orthosteric and allosteric drug design, design of multi-functional agents towards polypharmacy outcomes, principles on designing glycosaminoglycans as drugs, and computational tools and algorithms for quantitative SAR (QSAR) and understanding the roles of water and the hydrophobic effect.}
}
@article{BUCCIARELLI2022100443,
title = {The causes of difficulty in children’s creation of informal programs},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100443},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100443},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921001185},
author = {Monica Bucciarelli and Robert Mackiewicz and Sangeet S. Khemlani and P.N. Johnson-Laird},
keywords = {Computational thinking, Deduction, Informal programs, Kinematic simulations, Recursion},
abstract = {We present a theory of the causes of difficulty in children’s creation of informal programs. Ten-year-old children are able to devise such programs to rearrange the order of the cars in trains on a simple railway track with a single siding. According to the theory, they rely on kinematic mental models that simulate the required sequence of steps, and we devised a computer program, mAbducer, which does so too in creating its own programs for such rearrangements. An experiment showed that a simple measure of the complexity of its programs, based on Kolmogorov complexity, predicts ten-year-olds’ difficulty in this task: the measure is the number of words in mAbducer’s programs for solving the rearrangement in a minimal number of moves. Complexity, in turn, reflects the structure of the required programs, which need loops of moves to be repeated, and often moves before and after such a loop. Children’s errors are predictable in both their location and nature. Our results therefore have implications for the assessment and pedagogy of computational thinking.}
}
@article{POEPPEL20221054,
title = {We don’t know how the brain stores anything, let alone words},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {12},
pages = {1054-1055},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002066},
author = {David Poeppel and William Idsardi},
abstract = {Cognitive, computational, and neurobiological approaches have made impressive advances in characterizing the operations that transform linguistic signals into meanings. But our understanding of how words and concepts are retained in the brain remains inadequate. How is the long-term storage of words, or in fact any representations, achieved? This puzzle requires new thinking to stimulate reinvestigation of the storage problem.}
}
@article{SMITH2012210,
title = {Losing our way with mapping: Thinking critically about marine spatial planning in Scotland},
journal = {Ocean & Coastal Management},
volume = {69},
pages = {210-216},
year = {2012},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2012.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0964569112002335},
author = {Glen Smith and Ruth E. Brennan},
abstract = {Marine spatial planning (MSP) is the dominant management tool for marine environments around the world and is an attempt to move beyond the sectoral governance of marine spaces. Scotland is no exception and MSP is central to its management plans. The interpretation and use of spatial data informs these plans and maps provide the backbone of the decision-making process. Whilst not refuting MSP as a governance tool, this paper examines more closely some of the inherent problems with representing marine environments spatially and how the practice of map-making inevitably interacts with social-ecological networks. Borrowing from critical cartography and Actor-Network Theory (ANT), four observations are made: 1) due to the necessary procedure of categorising and simplifying data, maps do not always accurately represent changeable marine environments and situations; 2) maps can produce reality as much as represent it; 3) mapping has become the point through which all actors and stakeholders must pass; 4) as they are obliged to pass through this point, the roles and definition of certain actors can change. This discussion of marine spatial planning in Scotland demonstrates what can be learnt from viewing marine spaces as a tightly coupled social-ecological environment.}
}
@article{MANISCALCO2005305,
title = {The Cradle of Thought: Exploring the Origins of Thinking.},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {44},
number = {3},
pages = {305},
year = {2005},
issn = {0890-8567},
doi = {https://doi.org/10.1097/00004583-200503000-00019},
url = {https://www.sciencedirect.com/science/article/pii/S0890856709614805},
author = {Joshua Maniscalco}
}
@article{PENG20231143,
title = {Design of Data Persistence for Network Resources Recommendation System Based on Hibernate Architecture},
journal = {Procedia Computer Science},
volume = {228},
pages = {1143-1151},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.149},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019804},
author = {Xia Peng and Jun Li and Yongchang Ren},
keywords = {Hibernate, "Python Programming", Network Resources, Recommendation System, Data Persistence},
abstract = {The Python language is more focused on problem solving, which is in line with the era of computational thinking, and the teaching of Python language course requires students to systematically master the basic concepts, programming ideas and programming techniques of Python, and have the idea of object-oriented software design technology. We have developed a recommended system of online resources for "Python Programming" course to solve the problem of students' access to resources and deepen the teaching reform of the Python Programming course. Data persistence is an important task in system development, and Hibernate is the most popular O/R Mapping framework. The data persistence design based on Hibernate solves the key technical problems in the development of the network resource recommendation system for the "Python Programming" course, and improves the efficiency and maintainability of the software system development.}
}
@article{LI2024127497,
title = {Fully automated diagnosis of thyroid nodule ultrasound using brain-inspired inference},
journal = {Neurocomputing},
volume = {582},
pages = {127497},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127497},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002686},
author = {Guanghui Li and Qinghua Huang and Chunying Liu and Guanying Wang and Lingli Guo and Ruonan Liu and Longzhong Liu},
keywords = {Brain-inspired inference, TI-RADS, Deep learning, Knowledge tensor, Thyroid ultrasound},
abstract = {The interpretability of artificial intelligence (AI) based medical diagnostic systems is crucial to make the diagnosis adequately convincible. Deep learning has been extensively investigated and utilized in the area of medical assistance diagnosis in recent decades due to its outstanding performance and objective prediction. However, a huge semantic chasm dividing clinicians and unexplainable deep models emerges. Here we design a brain-inspired inference framework from medical images to explainable features, then to the final diagnostic conclusions. The fast thinking module is responsible for recognizing medical features in ultrasound (US) images, and the slow-thinking module builds a model for inferring from medical features to diagnostic results by constructing a knowledge graph of medical features with tensor decomposition. The whole model infers through intuition and thinking like a human being, and gives the recognized medical image features while inferring the diagnosis, which greatly improves the interpretability of the model. We conducted studies on thyroid cancer diagnoses using US images. The American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS) characteristics are employed as medical features describing thyroid nodules. Our brain-inspired medical inference framework outperforms commonly used deep learning algorithms, with an AUC score of 0.963 (95% confidential interval (CI)=0.923–1.000) for thyroid US image diagnosis. Results indicate that our framework improves diagnostic objectivity and interpretability while providing performance that is better than deep models. Our proposed brain-inspired medical inference framework could improve the efficiency of diagnosis and our technique is performant, objective and interpretable.}
}
@article{DAVIS2023105580,
title = {Identifying social partners through indirect prosociality: A computational account},
journal = {Cognition},
volume = {240},
pages = {105580},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105580},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002147},
author = {Isaac Davis and Ryan Carlson and Yarrow Dunham and Julian Jara-Ettinger},
keywords = {Theory of mind, Social mindfulness, Computational modeling, Naive utility calculus},
abstract = {The ability to identify people who are prosocial, supportive, and mindful of others is critical for choosing social partners. While past work has emphasized the information value of direct social interactions (such as watching someone help or hinder others), social tendencies can also be inferred from indirect evidence, such as how an agent considers others when making personal choices. Here we present a computational model of this capacity, grounded in a Bayesian framework for action understanding. Across four experiments we show that this model captures how people infer social preferences based on how agents act when their choices indirectly impact others (Experiments 1a, 1b, & 1c), and how people infer what an agent knows about others from knowledge of that agent’s social preferences (Experiment 2). Critically, people’s patterns of inferences could not be explained by simpler alternatives. These findings illuminate how people can discern potential social partners from indirect evidence of their prosociality, thus deepening our understanding of partner detection, and social cognition more broadly.}
}
@article{CHANG201467,
title = {Understanding the paradigm shift to computational social science in the presence of big data},
journal = {Decision Support Systems},
volume = {63},
pages = {67-80},
year = {2014},
note = {1. Business Applications of Web of Things 2. Social Media Use in Decision Making},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167923613002212},
author = {Ray M. Chang and Robert J. Kauffman and YoungOk Kwon},
keywords = {Analytics, Big data, Computational social science, Data analytics, Interdisciplinary research, Managerial decision-making, Paradigm shift},
abstract = {The era of big data has created new opportunities for researchers to achieve high relevance and impact amid changes and transformations in how we study social science phenomena. With the emergence of new data collection technologies, advanced data mining and analytics support, there seems to be fundamental changes that are occurring with the research questions we can ask, and the research methods we can apply. The contexts include social networks and blogs, political discourse, corporate announcements, digital journalism, mobile telephony, home entertainment, online gaming, financial services, online shopping, social advertising, and social commerce. The changing costs of data collection and the new capabilities that researchers have to conduct research that leverages micro-level, meso-level and macro-level data suggest the possibility of a scientific paradigm shift toward computational social science. The new thinking related to empirical regularities analysis, experimental design, and longitudinal empirical research further suggests that these approaches can be tailored for rapid acquisition of big data sets. This will allow business analysts and researchers to achieve frequent, controlled and meaningful observations of real-world phenomena. We discuss how our philosophy of science should be changing in step with the times, and illustrate our perspective with comparisons between earlier and current research inquiry. We argue against the assertion that theory no longer matters and offer some new research directions.}
}
@article{KAO2023105008,
title = {Computational models of subjective feelings in psychiatry},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {145},
pages = {105008},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422004973},
author = {Chang-Hao Kao and Gloria W. Feng and Jihyun K. Hur and Huw Jarvis and Robb B. Rutledge},
keywords = {Computational psychiatry, Subjective feelings, Depression, Happiness, Reward prediction errors, Computational model, Decision making, Smartphone},
abstract = {Research in computational psychiatry is dominated by models of behavior. Subjective experience during behavioral tasks is not well understood, even though it should be relevant to understanding the symptoms of psychiatric disorders. Here, we bridge this gap and review recent progress in computational models for subjective feelings. For example, happiness reflects not how well people are doing, but whether they are doing better than expected. This dependence on recent reward prediction errors is intact in major depression, although depressive symptoms lower happiness during tasks. Uncertainty predicts subjective feelings of stress in volatile environments. Social prediction errors influence feelings of self-worth more in individuals with low self-esteem despite a reduced willingness to change beliefs due to social feedback. Measuring affective state during behavioral tasks provides a tool for understanding psychiatric symptoms that can be dissociable from behavior. When smartphone tasks are collected longitudinally, subjective feelings provide a potential means to bridge the gap between lab-based behavioral tasks and real-life behavior, emotion, and psychiatric symptoms.}
}
@article{DESAI2020893,
title = {Commentary: Flow Through Dynamic Thinking},
journal = {Seminars in Thoracic and Cardiovascular Surgery},
volume = {32},
number = {4},
pages = {893-894},
year = {2020},
issn = {1043-0679},
doi = {https://doi.org/10.1053/j.semtcvs.2020.06.051},
url = {https://www.sciencedirect.com/science/article/pii/S1043067920302458},
author = {Manan H. Desai and Aybala Tongut and Can Yerebakan}
}
@incollection{MAINZER2007115,
title = {The emergence of mind and brain: an evolutionary, computational, and philosophical approach},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {115-132},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68010-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680108},
author = {Klaus Mainzer},
keywords = {brain, mind, complex systems, nonlinear dynamics, self-organization, computational systems, artificial minds},
abstract = {Modern philosophy of mind cannot be understood without recent developments in computer science, artificial intelligence (AI), robotics, neuroscience, biology, linguistics, and psychology. Classical philosophy of formal languages as well as symbolic AI assume that all kinds of knowledge must explicitly be represented by formal or programming languages. This assumption is limited by recent insights into the biology of evolution and developmental psychology of the human organism. Most of our knowledge is implicit and unconscious. It is not formally represented, but embodied knowledge, which is learnt by doing and understood by bodily interacting with changing environments. That is true not only for low-level skills, but even for high-level domains of categorization, language, and abstract thinking. The embodied mind is considered an emergent capacity of the brain as a self-organizing complex system. Actually, self-organization has been a successful strategy of evolution to handle the increasing complexity of the world. Genetic programs are not sufficient and cannot prepare the organism for all kinds of complex situations in the future. Self-organization and emergence are fundamental concepts in the theory of complex dynamical systems. They are also applied in organic computing as a recent research field of computer science. Therefore, cognitive science, AI, and robotics try to model the embodied mind in an artificial evolution. The paper analyzes these approaches in the interdisciplinary framework of complex dynamical systems and discusses their philosophical impact.}
}
@article{PILEGGI2021115065,
title = {Knowledge interoperability and re-use in Empathy Mapping: an ontological approach},
journal = {Expert Systems with Applications},
volume = {180},
pages = {115065},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115065},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421005066},
author = {Salvatore F. Pileggi},
keywords = {Ontology, Data integration and re-use, Semantic interoperability, Semantic web, Data engineering, Knowledge engineering, Design thinking, Empathy mapping},
abstract = {Design Thinking is a human-centered approach extensively used across different domains that aims at problem solving, value creation for stakeholders and innovation by fostering creativity. The most characterising and critical step along the Design Thinking process is the empathy phase, in which stakeholder analysis is performed by looking at a given scenario from the perspective of different stakeholders. Such a methodology enables a systematic information gathering and organization that results in a deep understanding of actual problems, needs and expectations from the target stakeholders. The uniqueness of problems and the need for situation-specific data makes knowledge re-use not always practical, even within the most consolidated and experienced environments. In this paper we propose an ontological support to empathy mapping that aims to (i) establish an interoperable fine-grained data layer among the different data collected throughout the empathy mapping process, (ii) enable multi-scenario analysis underpinned by formal specifications and (iii) further empower the process through semantic enrichment and integration of insight from multiple sources and contexts. We believe this is the first step to design and properly integrate effective computational and AI-based functionalities along the creative design thinking process, as well as to enable in practice richer and more sophisticated approaches (e.g. through social networks).}
}
@article{WU2021106622,
title = {“Should’ve known better”: Counterfactual processing in disordered gambling},
journal = {Addictive Behaviors},
volume = {112},
pages = {106622},
year = {2021},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2020.106622},
url = {https://www.sciencedirect.com/science/article/pii/S0306460320307528},
author = {Yin Wu and Dawn Kennedy and Caylee-Britt Goshko and Luke Clark},
keywords = {Gambling disorder, Regret, Risk-taking, Counterfactual thinking, Affective sensitivity},
abstract = {Counterfactual thinking is a component of human decision-making that entails “if only” thinking about unselected choices and outcomes. It is associated with strong emotional responses of regret (when the obtained outcome is inferior to the counterfactual) and relief (vice versa). Counterfactual thinking may play a role in various cognitive phenomena in disordered gambling, such as the effects of near-misses. This study compared individuals with gambling disorder (n = 46) and healthy controls (n = 25) on a behavioural economic choice task that entailed choosing between two gambles, designed to measure counterfactual thinking. Participants provided affect ratings following both the obtained and the non-obtained outcomes. Choices were analyzed using a computational model that derived parameters reflecting sensitivity to expected value, risk variance, and anticipated regret. In the computational choice model, the group with gambling disorder showed increased sensitivity to anticipated regret, reduced sensitivity to expected value, and increased preference for high risk-variance gambles. On the affect ratings, the group with gambling disorder displayed blunted emotional sensitivity to obtained and counterfactual outcomes. Effect sizes of the group differences were modest. Participants with gambling disorder show wide-ranging alterations in decision-making processes and emotional reactivity to choice outcomes. Altered sensitivity to anticipatory regret in gambling disorder may contribute to the development of gambling-related cognitive distortions, and the influences of gambling marketing.}
}
@incollection{WALLER2005589,
title = {Bayesian Thinking in Spatial Statistics},
editor = {D.K. Dey and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {25},
pages = {589-622},
year = {2005},
booktitle = {Bayesian Thinking},
issn = {0169-7161},
doi = {https://doi.org/10.1016/S0169-7161(05)25020-4},
url = {https://www.sciencedirect.com/science/article/pii/S0169716105250204},
author = {Lance A. Waller},
abstract = {In the sections below we review basic motivations for spatial statistical analysis, review three general categories of data structure and associated inferential questions, and describe Bayesian methods for achieving inference. Our goal is to highlight similarities across spatial analytic methods, particularly with regards to how hierarchical probability structures often link approaches developed in one area of spatial analysis to components within other areas. By choosing to highlight similarities, we focus on general concepts in spatial inference, and often defer details of several interesting and current threads of development to the relevant literature. We conclude with a listing of some of these developing areas of interest and references for further reading.}
}
@article{GREEN20214139,
title = {Computational biology: Turing’s lessons in simplicity},
journal = {Biophysical Journal},
volume = {120},
number = {19},
pages = {4139-4141},
year = {2021},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2021.08.041},
url = {https://www.sciencedirect.com/science/article/pii/S000634952100727X},
author = {Jeremy B.A. Green},
abstract = {Biophysical modeling of development started with Alan Turing. His two-morphogen reaction-diffusion model was a radical but powerful simplification. Despite its apparent limitations, the model captured real developmental processes that only recently have been validated at the molecular level in many systems. The precision and robustness of reaction-diffusion patterning, despite boundary condition-dependence, remain active areas of investigation in developmental biology.}
}
@article{DECHENNE2022100932,
title = {A task to connect counting processes to lists of outcomes in combinatorics},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100932},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100932},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000936},
author = {Adaline {De Chenne} and Elise Lockwood},
keywords = {Combinatorics, Student thinking, Discrete mathematics, Computational setting},
abstract = {Research has shown that solving counting problems correctly can be difficult for students at all levels, and mathematics educators have sought to identify strategies and interventions to help students reason conceptually about combinatorial tasks. A set-oriented perspective (Lockwood, 2014) is a way of thinking about counting problems that emphasizes the importance of reasoning about the set of outcomes being counted. From a set-oriented perspective, one possible type of intervention is to have students focus on the sets of outcomes rather than formulas and expressions, and specifically to reason about the structure of the set of outcomes. Yet, reasoning about sets of outcomes is not sufficient for students to make connections between outcomes and counting processes. In this paper, we investigate tasks where students wrote computer code to enumerate the set of outcomes in a specific order by implementing listing processes, and they were then asked to determine a specific numbered outcome in their list by using the structure of their enumeration scheme. We clarify particular aspects of a set-oriented perspective that were productive for students, and we demonstrate that tasks that asked students to name a specific outcome in their list elicited meaningful connections between counting processes and sets of outcomes. Further, such tasks reinforce desirable mathematical practices such as leveraging structure and connecting representations.}
}
@article{WIGGINS202057,
title = {Response to commentaries on “Creativity, information, consciousness: The information dynamics of thinking”},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {57-61},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300634},
author = {Geraint A. Wiggins}
}
@article{NYBLOM201430,
title = {Making plans or “just thinking about the trip”? Understanding people’s travel planning in practice},
journal = {Journal of Transport Geography},
volume = {35},
pages = {30-39},
year = {2014},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2014.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0966692314000040},
author = {Åsa Nyblom},
keywords = {Travel planning, Travel information, Sustainable social practices, Practice theory},
abstract = {ICT solutions have been proposed as a means for changing environmentally unfavourable traffic behaviour by providing better, real-time and more accessible travel information. However, prevailing models of travel choice and travel behaviour tend to overemphasise the impact and importance of information and the individualistic perspective. The issue of choice and travel planning in everyday life situations, and how information is used and acted on in these processes, was examined in a qualitative study in Stockholm, Sweden. Practice Theory was used as the theoretical framework for the study. Interviews were supplemented with an explorative diary and photo assignment to bring unreflected choices and actions of planning travel to the conscious level. The results showed that travel planning involves the immediate situation where planning and decisions are made, but also aspirations, cognitive/time/material limitations, social norms and social relations that extend widely in time and space. Definitions of travel planning and travel information based on the situated practices of planning are suggested. In the muddle of everyday life, travel planning takes place in the brief moments where circumstances at different levels – time, place, the social realm - interact and are considered or directly acted upon. In the development of new ICT-based travel information services, the role of technology in changing normal practices should be considered.}
}
@article{CARDENASSAINZ2022100381,
title = {Integration and acceptance of Natural User Interfaces for interactive learning environments},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100381},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100381},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000817},
author = {Brandon Antonio Cárdenas-Sainz and María Lucia Barrón-Estrada and Ramón Zatarain-Cabada and José Mario Ríos-Félix},
keywords = {Natural user interfaces, Gesture recognition, Interactive learning environments, Computational thinking, Secondary education, Technology Acceptance Model},
abstract = {This study focuses on the design of interactive learning environments (ILE) enhanced with Natural User Interfaces (NUI) for educational applications. It presents a 3D virtual environment, namely THINKMOTION which enables students to practice computational thinking skills. THINKMOTION combines a visual programming interface for coding and creating 3D virtual scenes with physics simulations, with a gesture recognition system for interaction over virtual objects. The ILE integrates a NUI called Leap Motion Controller, which recognizes the users’ hand movements and gestures A questionnaire was designed in order to evaluate the perceptions toward experimental learning with students of public and private secondary schools. It applies Technology Acceptance Model (TAM) and enhanced with new constructs such as perceived enjoyment and interface style. Results from our study highlight that: (1) NUI technologies positively impacted enjoyment and perceived ease of use among ILE users; (2) The ease of use provided by NUIs improved the enjoyment of students; (3) The perceived enjoyment considerably increased the intention to use; (4) For public school students, NUI technology has a significant impact on their first impressions and overall interest, followed by a positive attitude toward using ILE; (5) Private school students who are more accustomed to and familiar with using natural interfaces presented a positive attitude and enjoyment when using the ILE.}
}
@article{BENZEEV1995341,
title = {The nature and origin of rational errors in arithmetic thinking: Induction from examples and prior knowledge},
journal = {Cognitive Science},
volume = {19},
number = {3},
pages = {341-376},
year = {1995},
issn = {0364-0213},
doi = {https://doi.org/10.1016/0364-0213(95)90022-5},
url = {https://www.sciencedirect.com/science/article/pii/0364021395900225},
author = {Talia Ben-Zeev},
abstract = {Students systematically and deliberately apply rule-based but erroneous algorithms to solving unfamiliar arithmetic problems. These algorithms result in erroneous solutions termed rational errors. Computationally, students' erroneous algorithms can be represented by perturbations or bugs in otherwise correct arithmetic algorithms (Brown & VanLehn, 1980; Langley & Ohilson, 1984; VanLehn, 1983, 1986, 1990; Young S O'Sheo, 1981). Bugs are useful for describing how rational errors occur but bugs are not sufficient for explaining their origin. A possible explanation for this is that rational errors are the result of incorrect induction from examples. This prediction is termed the “induction hypothesis” (VanLehn, 1986). The purpose of the present study was to: (a) expand on post formulations of the induction hypothesis, and (b) use a new methodology to test the induction hypothesis more carefully than has been done previously. The first step involved teaching participants a new number system called NewAbacus, a written modification of the abacus system. The second step consisted of dividing them into different groups, where each individual received an example of only one port of the NewAbacus addition algorithm. During the third and final step, participants were instructed to solve both familiar and unfamiliar types of addition problems in NewAbacus. The induction hypothesis was supported by using both empirical and computational investigations.}
}
@article{MOUAKHER201915,
title = {On the efficient stability computation for the selection of interesting formal concepts},
journal = {Information Sciences},
volume = {472},
pages = {15-34},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.08.056},
url = {https://www.sciencedirect.com/science/article/pii/S0020025518306741},
author = {A. Mouakher and S. {Ben Yahia}},
keywords = {Data mining, Pattern selection, Formal concept analysis, Formal concept, Interestingness measure, Stability measure, Minimal generator},
abstract = {The lattice theory under the framework of formal concept analysis has brought mathematical thinking to knowledge representation and discovery. In this respect, this mathematical framework offers a conceptual knowledge representation through the Galois lattice. This hierarchical conceptual structure has been beneficial within the task of knowledge discovery in databases. However, its effective use in large datasets is always limited by the overwhelming number of extracted formal concepts. To select interesting formal concepts, the stability measure can be of valuable help. The dedicated literature has highlighted non-scalable approaches to compute such a stability measure. In an effort to tackle this issue, we introduce the Dfsp algorithm dedicated to efficiently compute the quality measure of the stability of formal concepts. We also show that the stability computation is an instantiation of a larger issue: locating minimal generators given the closed pattern as a reference point. The guiding idea of the Dfsp algorithm is to maximize as far as possible the quantity of the useless search space through the swift localization of maximal non-generator cliques. The experiments performed demonstrate the efficiency of the Dfsp algorithm.}
}
@article{BANK2014540,
title = {Thinking too positive? Revisiting current methods of population genetic selection inference},
journal = {Trends in Genetics},
volume = {30},
number = {12},
pages = {540-546},
year = {2014},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2014.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168952514001589},
author = {Claudia Bank and Gregory B. Ewing and Anna Ferrer-Admettla and Matthieu Foll and Jeffrey D. Jensen},
keywords = {natural selection, background selection, population genetic inference, evolution, computational biology},
abstract = {In the age of next-generation sequencing, the availability of increasing amounts and improved quality of data at decreasing cost ought to allow for a better understanding of how natural selection is shaping the genome than ever before. However, alternative forces, such as demography and background selection (BGS), obscure the footprints of positive selection that we would like to identify. In this review, we illustrate recent developments in this area, and outline a roadmap for improved selection inference. We argue (i) that the development and obligatory use of advanced simulation tools is necessary for improved identification of selected loci, (ii) that genomic information from multiple time points will enhance the power of inference, and (iii) that results from experimental evolution should be utilized to better inform population genomic studies.}
}
@article{NOORIGOODARZI2023105449,
title = {Reverse vaccinology approaches to introduce promising immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae: Thinking outside the box in current prevention and treatment},
journal = {Infection, Genetics and Evolution},
volume = {112},
pages = {105449},
year = {2023},
issn = {1567-1348},
doi = {https://doi.org/10.1016/j.meegid.2023.105449},
url = {https://www.sciencedirect.com/science/article/pii/S1567134823000473},
author = {Narjes {Noori Goodarzi} and Soheila Ajdary and Mir Saeed Yekaninejad and Sepideh Fereshteh and Mohammad Reza Pourmand and Farzad Badmasti},
keywords = {Gonorrhea, Reverse vaccinology, Comparative genomics, Essential proteins, Immunogenic targets},
abstract = {Gonorrhea is an urgent antimicrobial resistance threat and its therapeutic options are continuously getting restricted. Moreover, no vaccine has been approved against it so far. Hence, the present study aimed to introduce novel immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae strains. In the first step, the core proteins of 79 complete genomes of N. gonorrhoeae were retrieved. Next, the surface-exposed proteins were evaluated from different aspects such as antigenicity, allergenicity, conservancy, and B-cell and T-cell epitopes to introduce promising immunogenic candidates. Then, the interactions with human Toll-like receptors (TLR-1, 2, and 4), and immunoreactivity to elicit humoral and cellular immune responses were simulated. On the other hand, to identify novel broad-spectrum drug targets, the cytoplasmic and essential proteins were detected. Then, the N. gonorrhoeae metabolome-specific proteins were compared to the drug targets of the DrugBank, and novel drug targets were retrieved. Finally, the protein data bank (PDB) file availability and prevalence among the ESKAPE group and common sexually transmitted infection (STI) agents were assessed. Our analyses resulted in the recognition of ten novel and putative immunogenic targets including murein transglycosylase A, PBP1A, Opa, NlpD, Azurin, MtrE, RmpM, LptD, NspA, and TamA. Moreover, four potential and broad-spectrum drug targets were identified including UMP kinase, GlyQ, HU family DNA-binding protein, and IF-1. Some of the shortlisted immunogenic and drug targets have confirmed roles in adhesion, immune evasion, and antibiotic resistance that can induce bactericidal antibodies. Other immunogenic and drug targets might be associated with the virulence of N. gonorrhoeae as well. Thus, further experimental studies and site-directed mutations are recommended to investigate the role of potential vaccine and drug targets in the pathogenesis of N. gonorrhoeae. It seems that the efforts for proposing novel vaccines and drug targets appear to be paving the way for a prevention-treatment strategy against this bacterium. Additionally, a combination of bactericidal monoclonal antibodies and antibiotics is a promising approach to curing N. gonorrhoeae.}
}
@incollection{CORICELLI2015153,
title = {Strategic Mentalizing: The Neural Correlates of Strategic Choice},
editor = {Arthur W. Toga},
booktitle = {Brain Mapping},
publisher = {Academic Press},
address = {Waltham},
pages = {153-157},
year = {2015},
isbn = {978-0-12-397316-0},
doi = {https://doi.org/10.1016/B978-0-12-397025-1.00171-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123970251001718},
author = {G. Coricelli},
keywords = {Belief learning, Beliefs, Game theory, Medial prefrontal cortex, Mentalizing, Neuroeconomics, Neuroimaging, Recursive thinking, Social cognitive neuroscience, Strategic thinking, Theory of mind},
abstract = {This article adopts a neuroeconomics perspective on the study of the neural computations of human social interaction. Reported findings support a cognitive hierarchy model of human brain and behavior, according to which people use different levels of strategic thinking that are associated with specific neural computations. A higher level is associated with recursive thinking, which is the realization that others can also produce any thought process that we produce, while low level reflects self-referential thinking. The medial prefrontal cortex clearly distinguishes high level versus low level of strategic thinking, thus encoding the complexity underlying human social behavior.}
}
@article{REDKO202371,
title = {Computational modeling of insight processes and artificial cognitive ontogeny},
journal = {Cognitive Systems Research},
volume = {78},
pages = {71-86},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001061},
author = {Vladimir G. Red'ko and Alexei V. Samsonovich and Valentin V. Klimov},
keywords = {Computational creativity, Insight, Dual process theory, Cognitive architectures, Symbol grounding, Socially emotional intelligence},
abstract = {Many approaches were proposed to model complex socially emotional behavior in virtual actors, such as intelligent tutors, creative assistants, or team partners. They still lack the ‘magic’ of human-level cognition: systems built for one paradigm appear clueless outside of its boundary. Natural cognitive systems, on the other hand, can adapt to unexpected environments and paradigms. To capture the robustness of natural cognitive development, a new approach is proposed here that enables the formation of new higher cognitive abilities in a model system, embedded in an unexpected environment. This is achieved based on the naturally developing grounding of innate abstract constructs (schemas). The mechanism producing this binding is that of creative insight. In this study, principles of insight processes borrowed from psychology are formalized and adapted for computer modeling. To do this, several examples of insight phenomena at different evolutionary levels and in different species are analyzed before the model is formulated based on the dual process theory, the signal model of insight, and the eBICA cognitive architecture framework. Results of its computer simulations prove the concept. One specific finding is that the accumulation of activation during the incubation period increases creative abilities of the system. It is argued that the proposed approach can explain a range of facts and mysteries associated with the human cognitive ontogeny and can provide the basis for a self-sustained evolution of future Artificial Intelligence.}
}
@article{MAGANA2016427,
title = {A case study of undergraduate engineering students' computational literacy and self-beliefs about computing in the context of authentic practices},
journal = {Computers in Human Behavior},
volume = {61},
pages = {427-442},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216301868},
author = {Alejandra J. Magana and Michael L. Falk and Camilo Vieira and Michael J. Reese},
keywords = {Computational literacy, Self-beliefs, Modeling and simulation practices, Anchored instruction},
abstract = {Engineering students, as compared to computing-related majors, are not traditionally introduced to computing in the context of authentic learning experiences, i.e., real-world applications within their discipline. This paper identifies the impact of computation delivered by authentic learning experiences in the form of anchored instruction on students' self-beliefs and their capacity to leverage computation to acquire disciplinary concepts in subsequent computationally-based engineering coursework. This case study included 130 students with different programing preparation (authentic or traditional), who were exposed to computational learning modules. Control-Value Theory of Achievement Emotions is the conceptual framework that guided the evaluation of this investigation. Measures included student self-beliefs such as control and value appraisals, and their relationship with academic performance. Results suggest that programming preparation presented in an authentic engineering context provides an important foundation that goes beyond increasing students' control self-beliefs. This preparation seems to effectively enable students to leverage computational practices for the purpose of acquiring disciplinary concepts. Implications for teaching relate to the integration of computation sooner, more often and within a disciplinary context in the undergraduate engineering curriculum. Implications for learning relate to fostering engineering computational literacy guided by anchored instruction to support disciplinary problem solving.}
}
@article{CHANDRASEGARAN2023101182,
title = {Constructing design activity in words: Exploring linguistic methods to analyse the design process},
journal = {Design Studies},
volume = {86},
pages = {101182},
year = {2023},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2023.101182},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X23000236},
author = {Senthil Chandrasegaran and Almila Akdag Salah and Peter Lloyd},
keywords = {design thinking, collaborative design, design activity, research methods, text analysis},
abstract = {Analysing transcripts of design activity typically involve either close reading or manual coding of data, which limits the amount of data that can be analysed. In contrast, we explore a machine-learning based linguistic analysis tool called Empath to identify patterns of reasoning in design talk. The data we use derives from the Design Thinking Research Symposium (DTRS) shared-data workshops which we analyse to look at two contrasting aspects of design talk: the expression of tentativeness, characterising designers' generative thinking; and the articulation of explanations, characterising their deductive or analytical thinking. We show, at the level of speech turns, how tentativeness and explanation relate to, and overlap, each other. Finally, we discuss the limitations of this ‘linguistic analysis at scale’ approach.}
}
@article{SERIES202466,
title = {Can computational models help elucidate the link between complex trauma and hallucinations?},
journal = {Schizophrenia Research},
volume = {265},
pages = {66-73},
year = {2024},
note = {Hallucinations: Neurobiology and Patient Experience},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423001834},
author = {Peggy Seriès and Emilie Veerapa and Renaud Jardri},
keywords = {Trauma, Voice hearing, Belief, Inference, Predictive coding, Bayesian models},
abstract = {Recently, a number of predictive coding models have been proposed to account for post-traumatic stress disorder (PTSD)'s symptomatology, including intrusions, flashbacks and hallucinations. These models were usually developed to account for traditional/type-1 PTSD. We here discuss whether these models also apply or can be translated to the case of complex/type-2 PTSD and childhood trauma (cPTSD). The distinction between PTSD and cPTSD is important because the disorders differ in terms of symptomatology and potential mechanisms, how they relate to developmental stages, but also in terms of illness trajectory and treatment. Models of complex trauma could give us insights on hallucinations in physiological/pathological conditions or more generally on the development of intrusive experiences across diagnostic classes.}
}
@article{PETERS2022104903,
title = {Towards characterizing the canonical computations generating phenomenal experience},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {142},
pages = {104903},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104903},
url = {https://www.sciencedirect.com/science/article/pii/S014976342200392X},
author = {Megan A.K. Peters},
keywords = {Metacognition, Consciousness, Computational modeling, Phenomenology, Qualia},
abstract = {Science and philosophy have long struggled with how to even begin studying the neural or computational basis of qualitative experience. Here I review psychological, neuroscience, and philosophical literature to reveal how perceptual metacognition possesses five unique properties that provide a powerful opportunity for studying the neural and computational correlates of subjective experience: (1) Metacognition leads to subjective experiences (we “feel” confident); (2) Metacognition is “about” internal representations, formalizing introspection; (3) Metacognitive computations are “recursive” (applying to meta-cognition and meta-meta-cognition), so we might discover “canonical computations” preserved across processing levels and implementations; (4) Metacognition is anchored to observable behavior; and (5) Metacognitive computations are unobservable yet hierarchically dependent, requiring development of sensitive, specific models. Given these properties, computational models of metacognition provide an empirically-tractable early step in characterizing the generative process that constructs qualitative experience. I also present practical ways to make progress in this vein, applying decades of developments in nearby fields to perceptual metacognition to reveal new and exciting insights about how the brain constructs subjective conscious experiences.}
}
@incollection{HASKELL2001205,
title = {Chapter 12 - The Harmonic Structure of Mind: Higher Level Everyday Transfer Thinking},
editor = {Robert E. Haskell},
booktitle = {Transfer of Learning},
publisher = {Academic Press},
address = {San Diego},
pages = {205-218},
year = {2001},
series = {Educational Psychology},
issn = {18716148},
doi = {https://doi.org/10.1016/B978-012330595-4/50013-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123305954500135},
author = {Robert E. Haskell},
abstract = {Publisher Summary
This chapter focuses on harmonic mind and its structure, and its importance in everyday transfer thinking. The harmonic structure of higher level transfer thinking helps to efficiently store, integrate, remember, process, and retrieve information. Such a structure becomes a memory or mnemonic device for learning. This form of analogical transfer is also seen in the basic structure of higher level mathematical thinking. Thus it appears that transfer ability and mathematical ability are integrally related on some fundamental neurological level. Although analogical transfer ability, which is manifested mathematically in abstract proportional forms, is characteristic of all good mathematicians, those not skilled in higher mathematics may nevertheless be good at transfer thinking.}
}
@article{BHATT2005424,
title = {Self-referential thinking and equilibrium as states of mind in games: fMRI evidence},
journal = {Games and Economic Behavior},
volume = {52},
number = {2},
pages = {424-459},
year = {2005},
note = {Special Issue on Neuroeconomics},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2005.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0899825605000308},
author = {Meghana Bhatt and Colin F. Camerer},
abstract = {Sixteen subjects' brain activity were scanned using fMRI as they made choices, expressed beliefs, and expressed iterated 2nd-order beliefs (what they think others believe they will do) in eight games. Cingulate cortex and prefrontal areas (active in “theory of mind” and social reasoning) are differentially activated in making choices versus expressing beliefs. Forming self-referential 2nd-order beliefs about what others think you will do seems to be a mixture of processes used to make choices and form beliefs. In equilibrium, there is little difference in neural activity across choice and belief tasks; there is a purely neural definition of equilibrium as a “state of mind.” “Strategic IQ,” actual earnings from choices and accurate beliefs, is negatively correlated with activity in the insula, suggesting poor strategic thinkers are too self-focused, and is positively correlated with ventral striatal activity (suggesting that high IQ subjects are spending more mental energy predicting rewards).}
}
@incollection{KASTURIRANGAN2007105,
title = {Thinking is believing},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {105-114},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68009-1},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680091},
author = {Rajesh Kasturirangan},
keywords = {thoughts, beliefs, stories, mathematical modeling},
abstract = {Philosophers as well lay people often think of beliefs as psychological states with dubious epistemic properties. Beliefs are conceptualized as unregulated conceptual structures, for the most part hypothetical and often fanciful or deluded. Thinking and reasoning on the other hand are seen as rational activities regulated by rules and governed by norms. Computational modeling of the mind has focused on rule-governed behavior, ultimately trying to reduce them to rules of logic. What if thinking is less like reasoning and more like believing? I argue that the classical model of thought as rational is mistaken and that thinking is fundamentally constituted by believing. This new approach forces us to re-evaluate classical epistemic concepts like “truth”, “justification” etc. Furthermore, if thinking is believing, then it is not clear how thoughts can be modeled computationally. We need new mathematical ideas to model thought, ideas that are quite different from traditional logic-based mathematical structures.}
}
@article{CUI2021412,
title = {Artificial intelligence and computational pathology},
journal = {Laboratory Investigation},
volume = {101},
number = {4},
pages = {412-422},
year = {2021},
issn = {0023-6837},
doi = {https://doi.org/10.1038/s41374-020-00514-0},
url = {https://www.sciencedirect.com/science/article/pii/S0023683722006468},
author = {Miao Cui and David Y. Zhang},
abstract = {Data processing and learning has become a spearhead for the advancement of medicine, with pathology and laboratory medicine has no exception. The incorporation of scientific research through clinical informatics, including genomics, proteomics, bioinformatics, and biostatistics, into clinical practice unlocks innovative approaches for patient care. Computational pathology is burgeoning subspecialty in pathology that promises a better-integrated solution to whole-slide images, multi-omics data, and clinical informatics. However, computational pathology faces several challenges, including the ability to integrate raw data from different sources, limitation of hardware processing capacity, and a lack of specific training programs, as well as issues on ethics and larger societal acceptable practices that are still solidifying. The establishment of the entire industry of computational pathology requires far-reaching changes of the three essential elements connecting patients and doctors: the local laboratory, the scan center, and the central cloud hub/portal for data processing and retrieval. Computational pathology, unlocked through information integration and advanced digital communication networks, has the potential to improve clinical workflow efficiency, diagnostic quality, and ultimately create personalized diagnosis and treatment plans for patients. This review describes clinical perspectives and discusses the statistical methods, clinical applications, potential obstacles, and future directions of computational pathology.}
}
@article{VUQUOC20231069,
title = {Deep Learning Applied to Computational Mechanics: A Comprehensive Review, State of the Art, and the Classics},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {137},
number = {2},
pages = {1069-1343},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.028130},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223002412},
author = {Loc Vu-Quoc and Alexander Humer},
keywords = {, breakthroughs, network architectures, backpropagation, stochastic optimization methods from classic to modern, recurrent neural networks, long short-term memory, gated recurrent unit, attention, transformer, kernel machines, Gaussian processes, libraries, Physics-Informed Neural Networks, state-of-the-art, history, limitations, challenges, , Finite-element matrix integration, improved Gauss quadrature, Multiscale geomechanics, fluid-filled porous media, Fluid mechanics, turbulence, proper orthogonal decomposition, , autoencoder, hyper-reduction using gappy data, control of large deformable beam},
abstract = {Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.}
}
@article{STUPURIENE2024104939,
title = {Teachers’ perceptions of the barriers and drivers for the integration of Informatics in primary education},
journal = {Computers & Education},
volume = {208},
pages = {104939},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002166},
author = {Gabrielė Stupurienė and Margarida Lucas and Pedro Bem-Haja},
keywords = {Primary education, Teacher professional development, Thematic analysis, Network analysis, Informatics education},
abstract = {A growing trend of integrating and teaching Informatics and Computational Thinking (CT) skills at primary education levels poses different challenges for teachers. Research demonstrates that it is challenging to introduce Informatics in schools without well-prepared teachers. In this paper, we examine Lithuanian teachers' perceptions of the barriers and drivers to integrate the renewed Informatics curricula in primary education and the relation between them. Fifteen semi-structured interviews were conducted with primary school teachers, and a mixed-methods approach was employed to analyze them. The results show that explicit guidelines for renewed curricula and motivation to learn Informatics are both identified as the main barriers and drivers for integrating Informatics. The study further highlights the critical role of resources, appropriate tools, and guidelines in facilitating the successful implementation of Informatics. The study provides knowledge that could, for instance, benefit teacher training programmes and help better understand how teachers can be better supported to meet current and future challenges.}
}
@article{CHAKRABORTY2021113486,
title = {Conformations and tautomerisation between (Z)-4-(hydroxyethyl) isochroman-1, 3-dione and and 4-acetyl-3-hydroxyisochroman-1-one: A computational study through Energy, electron Distribution, vibrational analysis and hardness profiles},
journal = {Computational and Theoretical Chemistry},
volume = {1206},
pages = {113486},
year = {2021},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2021.113486},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X21003443},
author = {Abhijit Chakraborty and Goutam Dey},
keywords = {, , (Z)-4-(hydroxyethyl) isochroman-1, 3-dione, , , },
abstract = {The saturated and unsaturated rings in the tautomers of (Z)-4-(hydroxyethyl) isochroman-1, 3-dione (EIC) and 4-acetyl-3-hydroxyisochroman-1-one (AOC) are found to be nonplanar. All the DFT and ab-initio computational methods with various basis sets identify EIC as the global minimum in S0. IRC and frequency computations locate the transition states (TS). AOC and TS are located about 3.5 ± 0.5 kcal/mole and 4.5 ± 0.8 kcal/mole higher in energy than EIC. The transition region is clearly marked with the evaluation of reaction force and force constants. CIS and TDDFT computations show inconsistent results. MHP is obeyed by the EIC tautomer, while MEP is obeyed by the TS structure. Frontier molecular orbitals confirms the S0 → S1 transition as π-π* in nature. The vibrational signatures in the tautomers corresponding to CO stretching modes and ring modes are identified. The earlier observed 1740 cm-1C = O stretching mode is computed to appear at 1763 cm−1 in EIC.}
}
@article{GOLDMAN201725,
title = {Computational training for the next generation of neuroscientists},
journal = {Current Opinion in Neurobiology},
volume = {46},
pages = {25-30},
year = {2017},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959438817301599},
author = {Mark S Goldman and Michale S Fee},
abstract = {Neuroscience research has become increasingly reliant upon quantitative and computational data analysis and modeling techniques. However, the vast majority of neuroscientists are still trained within the traditional biology curriculum, in which computational and quantitative approaches beyond elementary statistics may be given little emphasis. Here we provide the results of an informal poll of computational and other neuroscientists that sought to identify critical needs, areas for improvement, and educational resources for computational neuroscience training. Motivated by this survey, we suggest steps to facilitate quantitative and computational training for future neuroscientists.}
}
@article{STUMPF202158,
title = {Statistical and computational challenges for whole cell modelling},
journal = {Current Opinion in Systems Biology},
volume = {26},
pages = {58-63},
year = {2021},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2021.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2452310021000160},
author = {Michael P.H. Stumpf},
keywords = {Inference, Inverse problems, Synthetic biology, Reproducible modelling},
abstract = {Mathematical modelling of whole biological cells opens up new opportunities for fundamental and applied biology. In particular in the context of synthetic biology, it opens up the scope for rational engineering and design principles to be applied. But there are precious few such models available. Here I outline the challenges in the way of generating such whole cell models. The inference of parameters, the choice among competing models, and, first and foremost, the reliable construction of such models pose considerable challenges. Recent work in statistical inference, especially parameter estimation, and model selection, coupled to new computationally more efficient methods to simulate large (and stochastic) biochemical reaction systems will be pivotal for the generation of a new generation of whole cell models. But these need to be coupled to better ways of generating models de novo. I outline how this may be achieved, and why this is necessary.}
}
@article{MASEL2007216,
title = {A Bayesian model of quasi-magical thinking can explain observed cooperation in the public good game},
journal = {Journal of Economic Behavior & Organization},
volume = {64},
number = {2},
pages = {216-231},
year = {2007},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2005.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167268106000977},
author = {Joanna Masel},
keywords = {Conditional expected utility, Rationality},
abstract = {Models of learning, reciprocity and altruism cannot explain all aspects of observed contributions in the public good game. Here a new model is described in which players recognize a correlation between their own contribution and the likely contributions of other players. The correlation is calculated by treating a player's own conjectured contribution just like any other data point within a learning model. Although players recognize that this correlation is not causal, they nevertheless choose to maximize expected utility conditional on their own action rather than standard expected utility. Results from the model explain previously puzzling quantitative trends in the data.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{MOLLER2021103155,
title = {Computational models of the “active self” and its disturbances in schizophrenia},
journal = {Consciousness and Cognition},
volume = {93},
pages = {103155},
year = {2021},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2021.103155},
url = {https://www.sciencedirect.com/science/article/pii/S1053810021000817},
author = {Tim Julian Möller and Yasmin Kim Georgie and Guido Schillaci and Martin Voss and Verena Vanessa Hafner and Laura Kaltwasser},
keywords = {Schizophrenia, Self-disorders, Minimal self, Active self, Sense of agency, Sense of ownership, Computational psychiatry, Cognitive robotics, Developmental robotics, Predictive processing},
abstract = {The notion that self-disorders are at the root of the emergence of schizophrenia rather than a symptom of the disease, is getting more traction in the cognitive sciences. This is in line with philosophical approaches that consider an enactive self, constituted through action and interaction with the environment. We thereby analyze different definitions of the self and evaluate various computational theories lending to these ideas. Bayesian and predictive processing are promising approaches for computational modeling of the “active self”. We evaluate their implementation and challenges in computational psychiatry and cognitive developmental robotics. We describe how and why embodied robotic systems provide a valuable tool in psychiatry to assess, validate, and simulate mechanisms of self-disorders. Specifically, mechanisms involving sensorimotor learning, prediction, and self-other distinction, can be assessed with artificial agents. This link can provide essential insights to the formation of the self and new avenues in the treatment of psychiatric disorders.}
}
@article{KOCH1996193,
title = {Students' understanding of computation-related rational number skills},
journal = {The Journal of Mathematical Behavior},
volume = {15},
number = {2},
pages = {193-205},
year = {1996},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(96)90016-4},
url = {https://www.sciencedirect.com/science/article/pii/S0732312396900164},
author = {Laura Coffin Koch and Xiaoming Li},
abstract = {The purpose of this study was to investigate the differences between students' and instructors' perceptions of similarities among basic computation-related rational number skills. Multidimensional scaling was used to determine how the students organized their thinking about the computational problems. This was done by estimating the parameters and assessing the fit of various spatial distance models for proximity. Results indicate that college students enrolled in developmental mathematics do see some relationships among rational number computation skills, although not necessarily the ones seen by instructors.}
}
@article{YAO2023102216,
title = {Accelerating surface remeshing through GPU-based computation of the restricted tangent face},
journal = {Computer Aided Geometric Design},
volume = {104},
pages = {102216},
year = {2023},
issn = {0167-8396},
doi = {https://doi.org/10.1016/j.cagd.2023.102216},
url = {https://www.sciencedirect.com/science/article/pii/S0167839623000481},
author = {Yuyou Yao and Jingjing Liu and Wenming Wu and Gaofeng Zhang and Benzhu Xu and Liping Zheng},
keywords = {Restricted tangent face, Centroidal Voronoi tessellation, Parallel computation, GPU acceleration, Surface remeshing},
abstract = {High-quality mesh surfaces are crucial for geometric processing in a variety of applications. To generate these meshes, polyhedral remeshing techniques truncate Voronoi cells of the original surface and yield precise intersections, but the calculation is complicated. Some methods apply auxiliary points to construct Voronoi diagrams to simplify these techniques, thereby extracting co-planar facets to approximate the original surface. However, extracting these approximate facets from the constructed Voronoi diagram makes it inefficient and non-parallelizable. To this end, we propose an efficient GPU method for manifold surface remeshing, where the restricted tangent face (RTF) is utilized to approximate the original surface. By intersecting the pre-clipped Voronoi cell with the tangent plane, this method directly calculates the RTF of each point without any auxiliary points or traversing Voronoi cells. Moreover, to restrict the movement of points, we introduce a projection method based on the KNN strategy, where each point is projected onto the triangular facet in the original surface. Owing to the independence and non-interference of the RTF computation and projection of each point, our method is implemented in parallel on the GPU. Experimental results on various mesh surfaces demonstrate the superior performance of our method in the viability, effectiveness, and efficiency.}
}
@article{HOWLAND2015224,
title = {Learning to communicate computationally with Flip: A bi-modal programming language for game creation},
journal = {Computers & Education},
volume = {80},
pages = {224-240},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S036013151400195X},
author = {Kate Howland and Judith Good},
keywords = {Evaluation of CAL systems, Interactive learning environments, Programming and programming languages, Secondary education},
abstract = {Teaching basic computational concepts and skills to school children is currently a curricular focus in many countries. Running parallel to this trend are advances in programming environments and teaching methods which aim to make computer science more accessible, and more motivating. In this paper, we describe the design and evaluation of Flip, a programming language that aims to help 11–15 year olds develop computational skills through creating their own 3D role-playing games. Flip has two main components: 1) a visual language (based on an interlocking blocks design common to many current visual languages), and 2) a dynamically updating natural language version of the script under creation. This programming-language/natural-language pairing is a unique feature of Flip, designed to allow learners to draw upon their familiarity with natural language to “decode the code”. Flip aims to support young people in developing an understanding of computational concepts as well as the skills to use and communicate these concepts effectively. This paper investigates the extent to which Flip can be used by young people to create working scripts, and examines improvements in their expression of computational rules and concepts after using the tool. We provide an overview of the design and implementation of Flip before describing an evaluation study carried out with 12–13 year olds in a naturalistic setting. Over the course of 8 weeks, the majority of students were able to use Flip to write small programs to bring about interactive behaviours in the games they created. Furthermore, there was a significant improvement in their computational communication after using Flip (as measured by a pre/post-test). An additional finding was that girls wrote more, and more complex, scripts than did boys, and there was a trend for girls to show greater learning gains relative to the boys.}
}
@article{CASALS201981,
title = {Who and what can contribute to improve the statistical thinking in sports injury research? A humorous analogy between basketball and members of the multidisciplinary research team},
journal = {Apunts. Medicina de l'Esport},
volume = {54},
number = {203},
pages = {81-84},
year = {2019},
issn = {1886-6581},
doi = {https://doi.org/10.1016/j.apunts.2019.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1886658119300271},
author = {Marti Casals and Rasmus Oestergaard Nielsen}
}
@article{UPADHYAY20171055,
title = {Future Directions and a Roadmap in Digital Computational Humanities for a Data Driven Organization},
journal = {Procedia Computer Science},
volume = {122},
pages = {1055-1060},
year = {2017},
note = {5th International Conference on Information Technology and Quantitative Management, ITQM 2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.473},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917327266},
author = {Shalini Upadhyay and Nitin Upadhyay},
keywords = {Digital Humanities, Computational Humanities, Social-technical infrastructure, Data driven organization},
abstract = {The development in the computational artifacts, social media, and network infrastructure has provided a unique opportunity to scholars, academicians and researchers to enhance their understanding of the presence of “Humanities” in the digital spectrum. The current research work explores the continuum of “Digital Computational Humanities” and provides the future directions and a roadmap for its establishment, sustainability and usefulness for data driven organizations.}
}
@article{COTTAM2022104671,
title = {Chaos, complexity and computation in the evolution of biological systems},
journal = {Biosystems},
volume = {217},
pages = {104671},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104671},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000612},
author = {Ron Cottam and Roger Vounckx},
abstract = {Chaos, complexity and computation are especially important concepts with respect to both the Evolution of biological systems and the evolution of the Universe. We consider each of these five entities separately, and then view their combination in an overall consideration of both evolution and Evolution. The concept of computation can be directly derived from processes characteristic of the Evolution of biology or the evolution of the Universe, rather than presumed from our own mathematical ideas. We advocate the inclusion of meaning in science's deliberations, and support this by insisting that physically embodied abstractions should be considered part concrete in character. Combination of our initial five conceptual entities indicates that biological Evolution follows the same developmental criteria as the evolution of the Universe, albeit with an intermediate change in strategy. We conclude that evolutionarily derived computation is the prime driver of evolution/Evolutions' implications.}
}
@article{SHKLOVSKIYKORDI2022104653,
title = {Natural computation and its limits: Efim Liberman at the dawn of a new science},
journal = {Biosystems},
volume = {215-216},
pages = {104653},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104653},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000454},
author = {Nikita E. Shklovskiy-Kordi and Abir U. Igamberdiev},
keywords = {Efim Liberman, Quantum computation, Biological computation, Unity of science, Encoding, Genetic language, Natural algorithm, Molecular computer of the cell, Quantum regulator},
abstract = {Efim A. Liberman (1925–2011) can be considered as a founder of the new field of science that explores natural computation and its limits. He named it Chaimatics and suggested its generalization to the ultimate all-encompassing theory that unites biology, physics and mathematics. He made a number of experimental discoveries, including color coding in the retina, the participation mechanisms of Ca2+ ions in synaptic transmission, and the measurement of potential in the coupling membranes of mitochondria and chloroplasts. He also made a decisive contribution to the proof of the chemiosmotic hypothesis of oxidative phosphorylation. In a series of works started in 1972, Liberman developed the concept of the molecular computer of the cell, which includes the programs written on DNA and RNA nucleotide sequences and executed by enzymes playing the role of processing units whereas nucleotide sequences are interpreted as commands and addresses. In this framework, Liberman predicted RNA splicing before its discovery and suggested the role of processing of small informational molecules (later defined as small RNAs) in controlling biological processes. Efim Liberman defined the fundamental property of life as a molecular and quantum computational system and introduced the idea of quantum computing inside a cell for making decisions on complex control tasks described by equations of mathematical physics. He approached the brain as a net of molecular computers and created a model of neuron operation based on the transmission of hypersound signals via cytoskeleton where the molecular computational system encodes the digital output. In 1979 Liberman published a hypothesis of human self-consciousness associated with not a chemical, but with a physical quantum coherent system and named it “extremal quantum regulator”. We review here the contributions of Liberman in understanding the mechanisms of intracellular processing of information and his efforts to create an integrative theory of natural computation that aims to unite biology, physics and mathematics.}
}
@article{GUTIERREZBELTRAN2025103198,
title = {Mi Superpoder es la Programación: A tool for teaching programming to children and youth},
journal = {Science of Computer Programming},
volume = {240},
pages = {103198},
year = {2025},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2024.103198},
url = {https://www.sciencedirect.com/science/article/pii/S0167642324001217},
author = {Erika J. {Gutiérrez Beltrán} and Juan C. {Martínez Arias}},
keywords = {Programming for children, STEAM education, Digital educational tools, Game-based learning, Software engineering},
abstract = {Mi Superpoder es la Programación is a web tool designed to teach programming to children and young people. It focuses on developing logical thinking through interactive exercises that cover computer parts recognition, sequences, patterns, and flowcharts. The tool was developed to address the educational needs identified in the social project of the same name, where modern technologies and a serverless-based architecture were used to create an accessible and effective solution for teaching programming. Initial results indicate that students found the tool useful and demonstrated improvements in their understanding of computational logic. This analysis is framed within the global challenge of teaching programming to children and youth, demonstrating the potential of gamified tools across diverse educational contexts. Future plans include expanding the tool to incorporate more modules, allowing customization by teachers, and conducting broader evaluations in different educational environments.}
}
@article{WANG2021119,
title = {Computational pharmaceutics - A new paradigm of drug delivery},
journal = {Journal of Controlled Release},
volume = {338},
pages = {119-136},
year = {2021},
issn = {0168-3659},
doi = {https://doi.org/10.1016/j.jconrel.2021.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0168365921004363},
author = {Wei Wang and Zhuyifan Ye and Hanlu Gao and Defang Ouyang},
keywords = {Computational pharmaceutics, Artificial intelligence, Machine learning, Molecular modeling, Process simulation, Mathematical modeling, PBPK modeling},
abstract = {In recent decades pharmaceutics and drug delivery have become increasingly critical in the pharmaceutical industry due to longer time, higher cost, and less productivity of new molecular entities (NMEs). However, current formulation development still relies on traditional trial-and-error experiments, which are time-consuming, costly, and unpredictable. With the exponential growth of computing capability and algorithms, in recent ten years, a new discipline named “computational pharmaceutics” integrates with big data, artificial intelligence, and multi-scale modeling techniques into pharmaceutics, which offered great potential to shift the paradigm of drug delivery. Computational pharmaceutics can provide multi-scale lenses to pharmaceutical scientists, revealing physical, chemical, mathematical, and data-driven details ranging across pre-formulation studies, formulation screening, in vivo prediction in the human body, and precision medicine in the clinic. The present paper provides a comprehensive and detailed review in all areas of computational pharmaceutics and “Pharma 4.0”, including artificial intelligence and machine learning algorithms, molecular modeling, mathematical modeling, process simulation, and physiologically based pharmacokinetic (PBPK) modeling. We not only summarized the theories and progress of these technologies but also discussed the regulatory requirements, current challenges, and future perspectives in the area, such as talent training and a culture change in the future pharmaceutical industry.}
}
@article{ZECHMEISTER2023104889,
title = {Concurrent, computational design and modelling of structural, coreless-wound building components},
journal = {Automation in Construction},
volume = {151},
pages = {104889},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104889},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523001498},
author = {C. Zechmeister and M. {Gil Pérez} and J. Knippers and A. Menges},
keywords = {Coreless filament winding, Carbon fibre, Feedback-based computational design, Co-design, Computational modelling, Digital-physical workflow, Interdisciplinary design, Finite element analysis (FEA), Robotic fabrication},
abstract = {Coreless filament winding extends established industrial processes, enabling the fabrication of building parts with minimal formwork. Since the part's final geometry is unknown until completed, it creates uncertainties for design and engineering. Existing architectural design workflows are insufficient, and industrial software packages cannot capture the complexity of self-deforming fibres to model complex fibre layups. This research introduces a feedback-based computational method conceived as four development cycles to design and evaluate fibre layups of large-scale architectural building components, and a multi-scalar digital-physical design and evaluation toolset to model and evaluate them at multiple resolutions. The universal applicability of the developed methods is showcased by two different architectural fibre structures. The results show how the systematization of methods and toolset allow for increased design flexibility and deeper integration of interdisciplinary collaborators. They constitute an important step towards a consolidated co-design methodology and demonstrate the potential to simultaneously co-evolve design and evaluation methods.}
}
@article{FYFE201917,
title = {Mathematical thinking in children with developmental language disorder: The roles of pattern skills and verbal working memory},
journal = {Journal of Communication Disorders},
volume = {77},
pages = {17-30},
year = {2019},
issn = {0021-9924},
doi = {https://doi.org/10.1016/j.jcomdis.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0021992417300588},
author = {Emily R. Fyfe and Lauren Eisenband Matz and Kayla M. Hunt and Martha W. Alibali},
keywords = {Developmental language disorder (DLD), Patterning, Mathematics, Working memory},
abstract = {Previous research suggests that children with language disorders often have difficulties in mathematical tasks. In the current study, we investigated two relevant factors – working memory and pattern skills – that may underlie children’s poor mathematics performance. Children with developmental language disorder (DLD, n = 18, ages 6–13) and age-matched typically-developing children (n = 18) completed three math tasks that tapped calculation skill and knowledge of concepts. Children also completed a visual pattern extension task and a verbal working memory task. There were four key findings: (1) children with DLD exhibited poorer mathematical knowledge than typically-developing children, both in calculation and on key math concepts, (2) children with DLD performed similarly to typically-developing children on the visual pattern extension task, (3) children with DLD had lower verbal working memory scores than typically-developing children, and these differences in working memory accounted in part for their poorer calculation performance, and (4) children’s pattern extension scores predicted their arithmetic calculation scores, but not their concept scores.}
}
@article{OCAK2023100146,
title = {An AI-enhanced pattern recognition approach to temporal and spatial analysis of children's embodied interactions},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100146},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100146},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000255},
author = {Ceren Ocak and Theodore J. Kopcha and Raunak Dey},
keywords = {Computational thinking (CT), Multimodality, Embodied interactions, Artificial Intelligence (AI), Machine learning},
abstract = {Multimodal video analysis is a complex and time-consuming process for a researcher; it entails capturing, watching, and re-watching video data to identify which segments best inform or address the questions that drive the research. Modern AI applications can alleviate the challenges that arise during the fine-grained analysis of learners' multimodal interactions captured through video. In this study, we present a supervised approach to training a deep neural network to analyze children's computational thinking (CT) captured through multimodal video data. The approach first uses a set of images extracted from video data to train the AI to map them to labels generated using a priori theory. Confusion matrices were used to establish the performance of the AI by comparing AI predictions to human analysis on a validation set of data. The findings suggested that the AI classified several aspects of children's CT in a way that was highly consistent with human analysis, demonstrating how the AI could serve as an additional team member during multimodal analysis. Implications for using AI to ease the challenges of multimodal analysis of video data are discussed.}
}
@article{CSIZMADIA2024108765,
title = {Exploring the role of working memory gate opening process in creativity: An ERP study using the reference-back paradigm},
journal = {Biological Psychology},
volume = {187},
pages = {108765},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108765},
url = {https://www.sciencedirect.com/science/article/pii/S0301051124000243},
author = {Petra Csizmadia and Boglárka Nagy and Lili Kővári and Zsófia Anna Gaál},
keywords = {Divergent/convergent thinking, Working memory, Reference-back paradigm, Gate opening, ERP},
abstract = {We investigated the relationship between the gate opening process of working memory and an individual's proficiency in divergent (DT) and convergent thinking (CT) using the reference-back paradigm. Event-related potentials and reaction times were measured across groups with varying DT (N = 40, 27.35 ± 5.05 years) and CT levels (N = 40, 27.88 ± 4.95 years). Based on the role of striatal dopamine in supporting cognitive flexibility, which facilitates DT, and considering the significance of phasic dopamine activity as the gate opening signal originating from the basal ganglia, we assumed that the gate opening process may contribute differently to DT and CT. Despite the absence of behavioural differences in gate opening costs, distinct neural patterns emerged. In the early time windows (P1, N1), gate opening effects were detected in both DT and CT groups, with a notable interaction influenced by the level of DT, resulting in significant effects within the lower DT group. The P2 component showed a gate opening effect only in the higher DT group. In the P3 time window, the process unfolded comparably in all groups. Our results suggest that groups with different levels of convergent thinking (based on Matrix reasoning) and those with lower DT (based on Creativity Index) tend to select and activate the prefrontal cortex representation containing the required task information at an earlier stage, compared to those with better DT. This could be beneficial especially in the early phase of idea generation, as more elements become available to create associations and original ideas.}
}
@incollection{DOMINOWSKI19941,
title = {CHAPTER 1 - History of Research on Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {1-35},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500074},
author = {Roger L. Dominowski and Lyle E. Bourne},
abstract = {Publisher Summary
The two problems that characterize the modern psychology of thinking are mental representation and mental computation. Throughout the history of psychology, there has been an agreement that the essential features of a problem are that an organism has a goal but lacks a clear or well-learned route to the goal. Thus the emphasis in research on problem solving has been on response discovery—how the organism arrives at an effective, goal-attaining behavior. There have often been controversies over the role of learning or past experiences in problem solving. This chapter illustrates the conflict between emphases on learning and emphases on perception as central components of problem solving. Because a problem solver must find a solution, it might seem inevitable that an essential activity tries different approaches makes errors until the right approach is found. Earlier in problem-solving research, trial and error became associated with the view that acquiring a solution was a gradual, undirected process that did not involve perception or comprehension of problem requirements or structure.}
}
@article{HANI2023102968,
title = {Computational intelligence modeling of nanomedicine preparation using advanced processing: Solubility of fludrocortisone acetate in supercritical carbon dioxide},
journal = {Case Studies in Thermal Engineering},
volume = {45},
pages = {102968},
year = {2023},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.102968},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23002745},
author = {Umme Hani and Zainab {Ali Bu sinnah} and Ahmad J. Obaidullah and Bader Huwaimel and Muteb Alanazi and Tareq {Nafea Alharby} and Ahmed A. Lahiq and Abdullah {Ali Alshehri}},
keywords = {Nanomedicine, Multilayer perceptron, Support vector machine, Multi linear regression, Drug solubility},
abstract = {The method of green technology which is based on supercritical solvent has been studied in this work for analysis of nanomedicine preparation of solid dosage oral medications. Given that the poor drug solubility in aqueous media is a big challenge in pharmaceutical industry, nanomedicines would help improve the drug solubility in aqueous media. The solubility of fludrocortisone acetate in supercritical carbon dioxide is modelled in this research using various machine learning methods because it is a crucial aspect of the expansion of the pharmaceutical business. For this purpose, the accessible data have two input features: a pressure range of 120–300 (bar) and a temperature range of 308–338 (K). MLP, v-SVR and MLR are the basic models used in this research, but not their raw versions. They are improved for modeling drug solubility and coupled with the grey wolf optimization (GWO) in order to optimize the models. The models optimized by GWO showed acceptable results, but among these models, MLP regression has shown better results when coupled with this optimization algorithm. This model has the RMSE error rate of 2.98 × 10−2 and its R2 score is 0.9797 in correlating the solubility data of the medicine.}
}
@article{GILL1995349,
title = {Bridging second-grade children's thinking and mathematical recording},
journal = {The Journal of Mathematical Behavior},
volume = {14},
number = {3},
pages = {349-362},
year = {1995},
issn = {0732-3123},
doi = {https://doi.org/10.1016/0732-3123(95)90016-0},
url = {https://www.sciencedirect.com/science/article/pii/0732312395900160},
author = {Alice J. Gill and Arlene Thompson},
abstract = {The focus of this article is how what students do and say to solve a problem may be recorded to mirror the student's actions or thoughts rather than portraying a common algorithm that is not connected to the student's thinking. It illustrates the multiple strategies used by a second-grade class that has solved a problem with three addends and how the teacher tries to faithfully map their thinking into the system of mathematical notation. Emphasis is placed on the step-by-step linking of action, thought, and symbol that must occur. The AFT Thinking Mathematics program that the teacher is using is briefly described as well as how the teacher developed number sense and a culture in which student thinking is respected. The article stresses that teachers need professional development experiences that help them understand how children best learn mathematics to be able to effectively address the needs of a class of heterogeneous learners and open doors to greater achievement.}
}
@article{LIU2006267,
title = {New tectonics: a preliminary framework involving classic and digital thinking},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {267-307},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X05000852},
author = {Yu-Tung Liu and Chor-Kheng Lim},
keywords = {tectonics, design technology, design process, computer aided design, design theory},
abstract = {The digital tectonic studies noticed the dramatic change of traditional architectural construction in association with digital technology. A more systematic framework of new tectonics combining digital and classic elements and processes is needed to explore the digital theory in the architecture field. The first step of this case-study research is to determine both the analytical factors of classic tectonics and the digital cases. The next step discusses emergent digital factors of tectonics. The third step applies the four new factors to the tectonic processes of five digital projects by well-known architects who have actual building experience in both predigital and digital works. Some phenomena of digital tectonics have emerged to reveal the dynamic factors of motion, information, generation and fabrication. In a preliminary framework of new tectonics, seven classic and four digital factors form a whole and interact with each other.}
}
@article{ZENGAFFINEN2023100159,
title = {“Computational analysis on verbal fluency reveals heterogeneity in subjective language interests and brain structure”},
journal = {Neuroimage: Reports},
volume = {3},
number = {1},
pages = {100159},
year = {2023},
issn = {2666-9560},
doi = {https://doi.org/10.1016/j.ynirp.2023.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666956023000041},
author = {Francilia Zengaffinen and Antje Stahnke and Stephan Furger and Roland Wiest and Thomas Dierks and Werner Strik and Yosuke Morishima},
keywords = {Language, SyNoPsis, Computational analysis, LSA, VBM, Healthy cohort, Psychosis},
abstract = {Language is an essential higher cognitive function in humans and is often affected by psychiatric and neurological disorders. Objective measures like the verbal fluency test are often used to determine language dysfunction. Recent applications of computational approaches broaden insights into language-related functions. In addition, individuals diagnosed with a psychiatric or neurological disorder also often report subjective difficulties in language-related functions. Therefore, we investigated the association between objective and subjective measures of language functioning, on the one hand, and inter-individual structural variations in language-related brain areas, on the other hand. We performed a Latent Semantic analysis (LSA) on a semantic verbal fluency task in 101 healthy adult participants. To investigate if these objective measures are associated with a subjective one, we examined assessed subjective natural tendency of interest in language-related activity with a study-specific questionnaire. Lastly, a voxel-based brain morphometry (VBM) was conducted to reveal associations between objective (LSA) measures and structural changes in language-related brain areas. We found a positive correlation between the LSA measure cosine similarity and the subjective interest in language. Furthermore, we found that higher cosine similarity corresponds to higher gray matter volume in the right cerebellum. The results suggest that people with higher interests in language access semantic knowledge in a more organized way exhibited by higher cosine similarity and have larger gray matter volume in the right cerebellum, when compared to people with lower interests. In conclusion, we demonstrate that there is inter-individual diverseness of accessing the semantic knowledge space and that it is associated with subjective language interests as well as structural differences in the right cerebellum.}
}
@article{BANERJEE2017227,
title = {A computational model for the endogenous arousal of thoughts through Z*-numbers},
journal = {Information Sciences},
volume = {405},
pages = {227-258},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517306321},
author = {Romi Banerjee and Sankar K. Pal},
keywords = {Artificial general intelligence, Attention dynamics, Man-machine interaction, Multimodal integration, Perception of meaning, Self-aware systems},
abstract = {Natural language provides a rich combinatorial mechanism for encoding meanings - a finite set of words can express an unbounded number of thoughts. Framed in 2015 to extend the purpose of Zadeh's Z-numbers, a Z*-number is a perceptual symbol of the meaning of a natural language expression and consequently mentalese – or internal speech. This article, through decomposition of the Z*-macro-parameters into its atomic constituents, presents a model for the endogenous arousal of thoughts during empathetic, bespoke comprehension of the real-world. Based on Minsky's Society of Mind, the framework is founded on the assimilation of multimodal experiences, a sense of ‘unified self’ and its derivatives (choice, interest, curiosity, etc.), objective and subjective components of knowledge, commonsense, and attention dynamics over a real-world scenario. The model attempts emulation of slow and fast thinking, instinctive reactions, learning, deliberation, reflection and self-conscious decisions. The design has been validated against human responses, and aims to contribute to the development of autonomous artificial systems for man-machine symbiosis.}
}
@article{CASALI2022105,
title = {Role of Anion in Determining the Stereoselectivity of Mg-Ph-BOX-Catalyzed Diels–Alder Reactions: A Computational Study},
journal = {Organometallics},
volume = {41},
number = {2},
pages = {105-114},
year = {2022},
issn = {0276-7333},
doi = {https://doi.org/10.1021/acs.organomet.1c00550},
url = {https://www.sciencedirect.com/science/article/pii/S0276733322004502},
author = {Emanuele Casali and Giuseppe Faita and Lucio Toma},
abstract = {ABSTRACT
In the realm of enantioselective Diels–Alder reactions, a role of primary importance is held by Mg-BOX catalysis. The main features of both catalysts and ligand in directing the stereoselective outcome have been extensively studied in several papers mainly through 1H NMR and X-ray diffraction (XRD) techniques. However, over the years, no computational studies have been reported to support the models proposed to rationalize the observed stereoselectivity for the reaction between 3-acryloyl-1,3-oxazolidin-2-one and cyclopentadiene catalyzed by the BOX ligand (R,R)-(+)-2,2′-isopropylidenebis­(4-phenyl-2-oxazoline) and Mg­(II) salts. To approach the problem, we performed a density functional theory (DFT) computational study, aiming to locate the preferred transitions states deriving from these proposed models, but we only found a correspondence in selectivities for the reaction catalyzed by Mg­(OTf)2, where the model suggests an octahedral complex with the two triflate anions coordinating magnesium. For the other cases [i.e., Mg­(ClO4)2, Mg­(ClO4)2·2H2O, and MgI2·I2], the commonly accepted tetrahedral or octahedral models suggest no involvement of the perchlorate or iodide anions, but the corresponding calculations did not reproduce the experimental selectivities. Only when we considered also in these cases coordination complexes involving their presence, the observed selectivities were reproduced, thus opening new insights to better understand the role and the action of the counterion to determine the stereochemical outcome of these reactions.}
}
@article{SCHWAB2021104536,
title = {Thinking outside the box: The cross-border effect of tax cuts on R&D},
journal = {Journal of Public Economics},
volume = {204},
pages = {104536},
year = {2021},
issn = {0047-2727},
doi = {https://doi.org/10.1016/j.jpubeco.2021.104536},
url = {https://www.sciencedirect.com/science/article/pii/S0047272721001729},
author = {Thomas Schwab and Maximilian Todtenhaupt},
keywords = {Taxation, Cross-border, Innovation, Multinational corporations},
abstract = {We analyze how a reduction of the tax rate on corporate income from intellectual property (IP) in one country, known as a patent box regime, affects corporate R&D activity in other countries. Combining data on patents and multinational corporation networks, we show that the cross-border effect of tax policy changes depends on whether co-location of the IP and the underlying R&D activity is required. Patent boxes without such a requirement increase patent output in other countries. Patent boxes with such a requirement reduce patent output abroad but only when relocation costs for R&D activity are small.}
}
@incollection{KOROMINA202221,
title = {2.03 - Pharmacogenomics in the Era of “Big Data” and Advanced Computational Approaches},
editor = {Terry Kenakin},
booktitle = {Comprehensive Pharmacology},
publisher = {Elsevier},
address = {Oxford},
pages = {21-26},
year = {2022},
isbn = {978-0-12-820876-2},
doi = {https://doi.org/10.1016/B978-0-12-820472-6.00114-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204726001146},
author = {Maria Koromina and George P. Patrinos},
keywords = {GWAS, Large-scale genomics studies, NGS, PGx, Rare variants, Text-mining},
abstract = {Undoubtedly, next generation sequencing (NGS) technologies have led to the production of a voluminous amount of data, which can be exploited towards the delineation and identification of novel pharmacogenomics (PGx) associations. Herein, we describe how NGS and genome-wide association (GWA) technologies have changed the landscape of the pharmacogenomics field, whilst proceeding with thorough details on the contribution of rare pharmacogenomics variants to the heritability of drug response trait. Moreover, we summarize some state-of-the-art text mining techniques which if harnessed properly can lead to a plethora of PGx retrieved associations. Overall, we conclude by stating that there is often a knowledge gap between (clinical) pharmacologists and researchers who exploit (pharmaco)genomics big data by using advanced computing methods. To overcome the limited number of advanced computational, statistical and mathematical methods and protocols, we propose a broad implementation and standardization of NGS techniques that should be explored by the PGx community.}
}
@article{MADSEN2022103671,
title = {Soft City Sensing: A turn to computational humanities in data-driven urbanism},
journal = {Cities},
volume = {126},
pages = {103671},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103671},
url = {https://www.sciencedirect.com/science/article/pii/S026427512200110X},
author = {Anders Koed Madsen and Anders Grundtvig and Sofie Thorsen},
keywords = {Soft City Sensing, Urban studies, Big data, Social web, Digital city, Computational humanities},
abstract = {Data-driven urbanism is often entangled with the smart city and practiced in a way that prioritizes control over physical objects and downplays the human and political aspects of data. We label this approach ‘hard city sensing’ (HCS) and we argue that the rise of the ‘digital city’ offers the empirical foundation for more humanistic approaches. Driven by the ambition to untangle data-driven urbanism from HCS, this paper reviews two decades of scholarship that has used digital traces as an empirical ground for understanding urban phenomena. The review identifies four distinct ways of working with digital traces of which three pave the way for new ways of problematizing the city. Instead of abandoning the idea of data-driven urbanism, we propose the framework of 'soft city sensing' (SCS) as way to re-engage with it with inspiration from these pioneering works. However, this requires a willingness to revisit central epistemological commitments that currently serve as standards for how to “properly” do data projects. We therefore urge qualitative urban scholars to ponder the possibilities of furthering their urban interest by ‘thinking with algorithms’ while retaining their interpretative ambitions just as we identify a need for urban decion-makers to expand their criteria for what serves as valid data inputs to urban planning.}
}
@article{ASCIONE2021110533,
title = {The design of safe classrooms of educational buildings for facing contagions and transmission of diseases: A novel approach combining audits, calibrated energy models, building performance (BPS) and computational fluid dynamic (CFD) simulations},
journal = {Energy and Buildings},
volume = {230},
pages = {110533},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110533},
url = {https://www.sciencedirect.com/science/article/pii/S0378778820323483},
author = {Fabrizio Ascione and Rosa Francesca {De Masi} and Margherita Mastellone and Giuseppe Peter Vanoli},
keywords = {Educational buildings, Energy models, Calibration, Indoor air quality, COVID-19, HVAC systems, Mechanical ventilation, Healthy indoor spaces, BES building performance simulation, CFD computational fluid dynamics},
abstract = {The proposed investigation is aimed at providing useful suggestions and guidelines for the renovation of educational buildings, in order to do University classrooms safe and sustainable indoor places, with respect to the 2020 SARS-CoV-2 global pandemic. Classrooms and common spaces have to be thought again, for a new “in-presence” life, after the recent worldwide emergency following the spring 2020 pandemic diffusion of COVID-19. In this paper, starting from a real case study, and thus the architectural and technological refurbishment of an Italian University building (Campobasso, South Italy, cold climate), with the aims of improving the classrooms’ quality and safety, a comprehensive approach for the retrofit design is proposed. By taking into account the necessary come back to classrooms starting, hopefully, from the next months (Autumn 2020), experimental studies (monitoring and investigations of the current energy performances) are followed by the coupling of different numerical methods of investigations, and thus building performance simulations, under transient conditions of heat transfer, and computational fluid dynamics studies, to evidence criticalities and potentialities to designers involved in the re-thinking of indoor spaces hosting multiple persons, with quite high occupancy patterns. Both energy impacts, in terms of monthly and annual increase of energy demands due to higher mechanical ventilation, and indoor distribution of microclimatic parameters (i.e., temperature, airspeed, age of air) are here investigated, by proposing new scenarios and evidencing the usefulness of HVAC systems, equipment (e.g., sensible heat recovery, without flows’ contamination) and suitability of some strategies for the air distribution systems (ceiling squared and linear slot diffusers) compared to traditional ones.}
}
@article{GEPSHTEIN2021221,
title = {Thinking Outside the Lineup Box: Eyewitness Identification by Perceptual Scaling},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {10},
number = {2},
pages = {221-224},
year = {2021},
issn = {2211-3681},
doi = {https://doi.org/10.1016/j.jarmac.2021.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211368121000310},
author = {Sergei Gepshtein and Thomas D. Albright}
}
@article{RAJU2022,
title = {Computational evaluation of the effect of femoral component curvature on the mechanical response of the UHMWPE tibial insert in total knee replacement implants},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2022.12.224},
url = {https://www.sciencedirect.com/science/article/pii/S2214785322075964},
author = {Vaishakh Raju and Poornesh Kumar Koorata},
keywords = {Femoral component, Knee implant, Total knee replacement, Tibial insert, UHMWPE},
abstract = {Total knee replacement (TKR) surgery is done on individuals with end-stage osteoarthritis to restore knee function and alleviate joint discomfort. There have been recent developments in the design of customized implants based on patient-specific data obtained from MRI scans and subsequent image processing techniques. Here curvature of the femoral component plays an important role in effective implant design. Therefore, the objective here is to investigate the influence of this curvature of the femoral component on the mechanical response of the bearing component. A 3D finite element knee implant model with a circular and an elliptical femoral component is developed and investigated for gait kinetics and kinematics. Responses such as contact pressure, stresses, strains, and wear produced on the tibial insert are estimated throughout the gait cycle. These findings suggest that the elliptical femoral component generates less contact pressure on the tibial insert than its circular counterpart. It is also inferred that too much variation in this curvature is not recommended as it may affect the patient's comfort level. In addition, the wear of the tibial insert is computed based on the contact pressure created by both knee implant models. Our study suggests an optimum value for the curvature and the comfort level of the patients over the existing knee implant designs.}
}
@article{JAYBONK1998261,
title = {Alternative instructional strategies for creative and critical thinking in the accounting curriculum},
journal = {Journal of Accounting Education},
volume = {16},
number = {2},
pages = {261-293},
year = {1998},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(98)00012-8},
url = {https://www.sciencedirect.com/science/article/pii/S0748575198000128},
author = {Curtis {Jay Bonk} and G {Stevenson Smith}},
abstract = {In the midst of numerous accounting reform reports declaring that the memorization of accounting facts will no longer suffice, global economies have increased the pressure on universities to develop higher-order thinking skill curricula. This paper suggests that a consultative model of teaching can meet these challenges. From this framework, learning environments can be reshaped to support both the creative and critical thinking skills demanded by workplaces of the 21st century. In contrast to the passive reception of knowledge of teacher-centered classrooms, this style of teaching promotes active, student-centered learning. Importantly, a myriad of critical and creative thinking techniques, activities, and examples are detailed for developing accounting curricula in accordance with these views. Peripheral issues related to assessing higher-order thinking as well as cooperative grouping also are considered.}
}
@article{FENG2025100831,
title = {Construction of teaching game evaluation model based on ISSA-BPNN},
journal = {Entertainment Computing},
volume = {52},
pages = {100831},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100831},
url = {https://www.sciencedirect.com/science/article/pii/S187595212400199X},
author = {Bibo Feng and Lingli Zhang and Jing Yin and Rong Wang},
keywords = {Sparrow search algorithm, Back propagation neural network, Teaching games, Evaluating indicator},
abstract = {Teaching games are an effective teaching organization activity. In response to the evaluation and prediction problem of teaching games, a teaching game evaluation model based on improved sparrow search algorithm and back propagation neural network was studied and constructed. Firstly, a situational teaching game was designed and an evaluation index system was constructed. Then, a teaching game evaluation prediction model based on the improved method was established. Finally, the expert consultation method is adopted to collect opinions from experts in the field of education and construct an evaluation index system for teaching games. And based on the evaluation index system of teaching games, evaluate students’ mathematical thinking ability before and after experiencing teaching games to verify the application effect of teaching games. The scenario based teaching game designed in this study has a certain effect on improving students’ mathematical thinking ability. Students’ mathematical thinking has significantly improved (P<0.05), and the teaching effect is the same for students of different genders (P>0.1). The improved sparrow search algorithm has a faster convergence rate than other algorithms, and tends to be stable when iteration is about 100 when solving the single peak benchmark function. When solving the multimodal benchmark test function, it tends to stabilize when iteration is around 20. The teaching game evaluation prediction price model based on the improved method shows a trend of first increasing and then decreasing with hidden units increasing. When the hidden unit is 16, the area index under model curve is the highest, around 0.962, and its prediction accuracy is relatively high. In summary, the model constructed in this study is applicating good in teaching game evaluation prediction, and can promote education industry developing.}
}
@article{SCHAUERTE2023801,
title = {The managerial relevance of marketing science: Properties and genesis},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {4},
pages = {801-822},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000472},
author = {Nico Schauerte and Maren Becker and Monika Imschloss and Julian R.K. Wichmann and Werner J. Reinartz},
keywords = {Managerial relevance, Research–practice gap, Research properties and genesis, Marketing science value chain, Computational grounded theory},
abstract = {Part of marketing academia’s mandate is to generate findings that improve management practice. Managerial relevance plays a key role in this mandate as it describes a research project’s potential to influence managerial decision-making and thinking. Therefore, it is crucial to understand what makes research managerially relevant and to uncover success factors in the genesis of such research. This study addresses these issues through a qualitative analysis of 65 depth interviews with senior editors of business transfer journals, marketing managers, and academic researchers. The authors carve out distinct, multidimensional properties that determine managerial relevance. From specific configurations of these properties, four archetypical relevance types emerge: (1) problem-solving, (2) explicating, (3) consolidating, and (4) forward-thinking relevance. Finally, the authors develop a unifying framework and identify success factors for generating highly relevant research. Based on these insights, they suggest concrete courses of action for academics who seek to increase the managerial relevance of their research.}
}
@article{KRAUSE2001432,
title = {Entropy reduction in human mathematical thinking: A microstate study of EEG oscillations},
journal = {NeuroImage},
volume = {13},
number = {6, Supplement },
pages = {432},
year = {2001},
note = {Originally published as Volume 13, Number 6, Part 2},
issn = {1053-8119},
doi = {https://doi.org/10.1016/S1053-8119(01)91775-6},
url = {https://www.sciencedirect.com/science/article/pii/S1053811901917756},
author = {Werner Krause and Barbara Schack and Gundula Seidel and Frank Heinrich and Ursula Krause}
}
@article{SCHWABE201360,
title = {Stress and multiple memory systems: from ‘thinking’ to ‘doing’},
journal = {Trends in Cognitive Sciences},
volume = {17},
number = {2},
pages = {60-68},
year = {2013},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661312002811},
author = {Lars Schwabe and Oliver T. Wolf},
abstract = {Although it has been known for decades that stress influences memory performance, it was only recently shown that stress may alter the contribution of multiple, anatomically and functionally distinct memory systems to behavior. Here, we review recent animal and human studies demonstrating that stress promotes a shift from flexible ‘cognitive’ to rather rigid ‘habit’ memory systems and discuss, based on recent neuroimaging data in humans, the underlying brain mechanisms. We argue that, despite being generally adaptive, this stress-induced shift towards ‘habit’ memory may, in vulnerable individuals, be a risk factor for psychopathology.}
}
@article{DEGELDER2021744,
title = {A computational neuroethology perspective on body and expression perception},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {9},
pages = {744-756},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321001479},
author = {Beatrice {de Gelder} and Marta {Poyo Solanas}},
keywords = {body, emotion, movement, ethology, computational features},
abstract = {Survival prompts organisms to prepare adaptive behavior in response to environmental and social threat. However, what are the specific features of the appearance of a conspecific that trigger such adaptive behaviors? For social species, the prime candidates for triggering defense systems are the visual features of the face and the body. We propose a novel approach for studying the ability of the brain to gather survival-relevant information from seeing conspecific body features. Specifically, we propose that behaviorally relevant information from bodies and body expressions is coded at the levels of midlevel features in the brain. These levels are relatively independent from higher-order cognitive and conscious perception of bodies and emotions. Instead, our approach is embedded in an ethological framework and mobilizes computational models for feature discovery.}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@article{MARENKO2015110,
title = {When making becomes divination: Uncertainty and contingency in computational glitch-events},
journal = {Design Studies},
volume = {41},
pages = {110-125},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000587},
author = {Betti Marenko},
keywords = {philosophy of design, computational models, digital design, design processes, uncertainty},
abstract = {This article investigates those aspects of computation that concern uncertainty, contingency and indeterminacy. Starting from a critique of current dominant models of computation, and drawing on the philosophical notions of the virtual and the event, uncertainty, contingency and indeterminacy are proposed as virtualities that express the ongoing differentiation of digital matter. On these grounds, the glitch is reframed as an event capable of revealing the potential of the digital in processes of computational making. Ideas concerning the incomputable and non-human intelligence of the algorithm underpin this argument. Finally, it is proposed that intuitive and uncognitive modes of apprehending digital making operate as forms of divination that capture the unprogrammed unfolding of matter.}
}
@article{OXMAN2002135,
title = {The thinking eye: visual re-cognition in design emergence},
journal = {Design Studies},
volume = {23},
number = {2},
pages = {135-164},
year = {2002},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(01)00026-6},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X01000266},
author = {Rivka Oxman},
keywords = {perception, design cognition, visual reasoning, emergence, creativity},
abstract = {Emergence has been widely recognized as a significant phenomenon of visual reasoning in design. Despite its centrality as a cognitive phenomenon, research in emergence currently lacks a comprehensive theoretical foundation. A broadened view of design emergence that adds to the perceptual phenomenon of shape emergence in reflecting the way the design domains are conceptualized is proposed. An expanded theory of emergence in which visual cognition plays an important role is presented. Beginning with an attempt to broaden the perceptual perspectives of shape emergence, the process of cognitive emergence is defined. The duality of related perceptual and cognitive components provides a working basis for conceptualizing visual emergence in design. Antithetical to the idea of accidental emergence, it is proposed that emergence is guided and anticipated. We claim that it is the re-cognition of visual shapes and images in design that enables emergence. This kind of guidance function in emergence is termed ‘anticipated emergence’. We demonstrate how high-level domain knowledge of visual forms can be accommodated as cognitive content, and how this can contribute to establishing a cognitive basis for emergence. An empirical experiment from the domain of architecture is presented.}
}
@incollection{DIETRICH19943,
title = {CHAPTER 1 - Thinking Computers and The Problem of Intentionality},
editor = {Eric Dietrich},
booktitle = {Thinking Computers and Virtual Persons},
publisher = {Academic Press},
pages = {3-34},
year = {1994},
isbn = {978-0-12-215495-9},
doi = {https://doi.org/10.1016/B978-0-12-215495-9.50006-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780122154959500065},
author = {Eric Dietrich},
abstract = {Publisher Summary
This chapter is an attempt to clear the names of artificial intelligence (AI) and computational cognitive science. These two related disciplines have been accused of a conceptual error so profound that their very existence is jeopardized. Sometimes, however, philosophers successfully arrest and lock up the guilty. The best example of this, ironically, is in psychology. Artificial intelligence and computational cognitive science are both committed to the claim that computers can think. The former is committed to the claim that human-made computers can think, while computational cognitive science is committed to the view that naturally occurring computers, brains, think. AI is the field dedicated to building intelligent computers. AI ultimately wants a machine that could solve very difficult, novel problems like proving Fermat's last theorem, correcting the greenhouse effect, or figuring out the fundamental structure of space-time. Historically, AI is associated with computer science, but the compleat AI researcher frequently knows a fair amount of psychology, linguistics, neuroscience, mathematics, and possibly some other discipline.}
}
@article{CAVAZZA2014422,
title = {Ways of thinking about the incinerator: A typology of citizens’ mindsets},
journal = {The Social Science Journal},
volume = {51},
number = {3},
pages = {422-430},
year = {2014},
issn = {0362-3319},
doi = {https://doi.org/10.1016/j.soscij.2013.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0362331913001705},
author = {Nicoletta Cavazza and Sandro Rubichi},
keywords = {Attitude, Social representations, Waste disposal, Trust, Self-efficacy},
abstract = {This paper considers the social representation of an incinerator plant operating for more than 30 years in a medium-sized city in Italy. A survey was carried out with a representative sample of an Italian town, a community that was not generally hostile to it. On the basis of self-efficacy and trust in institutions, and by applying cluster analyses, we obtain evidence for four distinct groups labelled as Fatalists, Collaboratives, Activists, and Delegants. The four groups express systematic variations in social representation. We discuss the theoretical and practical impacts of these results.}
}
@article{HADAS2024101549,
title = {Using large language models to evaluate alternative uses task flexibility score},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101549},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101549},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000877},
author = {Eran Hadas and Arnon Hershkovitz},
keywords = {Creativity, Divergent thinking, Alternative uses task, Flexibility, Large language models},
abstract = {In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.}
}
@article{MCDONOUGH2002211,
title = {Understanding, assessing and developing children's mathematical thinking: the power of a one-to-one interview for preservice teachers in providing insights into appropriate pedagogical practices},
journal = {International Journal of Educational Research},
volume = {37},
number = {2},
pages = {211-226},
year = {2002},
issn = {0883-0355},
doi = {https://doi.org/10.1016/S0883-0355(02)00061-7},
url = {https://www.sciencedirect.com/science/article/pii/S0883035502000617},
author = {Andrea McDonough and Barbara Clarke and Doug M. Clarke},
keywords = {Preservice teacher education, Mathematics education, One-to-one interview, Children, Questioning, Listening, Reflection},
abstract = {At Australian Catholic University and Monash University, preservice mathematics teachers are required to conduct and analyse one-to-one mathematics assessment interviews with primary-aged children. The assessment tool is drawn from the Early Numeracy Research Project, where it was used with over 11,000 children in Victorian schools. The interview assesses content from Number, Measurement and Geometry, in an interactive, hands-on format, with children's responses and strategies determining the path through the interview protocol. Follow-up discussion in class enabled preservice teachers to explore appropriate pedagogies that build upon what had been learned from the interviews. The research described in this chapter sought to investigate the effectiveness of this process. Interviews and written questionnaires were the data sources. Analysis of the data suggested that teachers were more aware of the kinds of strategies that children use including their variety and relative level of sophistication, and that the interview and subsequent discussion stimulated preservice teachers to reflect upon appropriate classroom experiences for young mathematics learners.}
}
@incollection{ISMAIL2024219,
title = {Chapter 7 - High throughput screening of phytochemicals: Application of computational methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {219-253},
year = {2024},
isbn = {978-0-443-16102-5},
doi = {https://doi.org/10.1016/B978-0-443-16102-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161025000080},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening /, Natural product prototypes, Drug discovery and development, Machine learning, , , },
abstract = {This chapter examines the history and development of high-throughput screening (HTS) using the knowledge and expertise of the writers, who have worked as consultants or trainers for several pharmaceutical companies. It focuses on the function of HTS in drug development and screening for natural products (phytochemicals). It emphasizes the use of computational tools in HTS for phytochemicals. To guarantee that researchers can set up and effectively use HTS in their natural product research, common problems and solutions are covered along with a few ‘how to’ protocols. Also described are pertinent failures and accomplishments in finding intriguing natural products.}
}
@article{OMER2024100308,
title = {Computational studies of a series of closely related acenaphthopyrazine derivative},
journal = {Results in Surfaces and Interfaces},
volume = {17},
pages = {100308},
year = {2024},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2666845924001284},
author = {Rebaz Anwar Omer and Rebaz Obaid Kareem and Yousif Hussein Azeez and Lana Omer Ahmed and Damir A. Safin and karukh Ali Babakr},
keywords = {Gaussian software, DFT, NLO, Thermal properties, Monte Carlo simulations},
abstract = {The novelty of the study is in the use of quantum computing analysis of acenaphthopyrazine derivatives using Density Functional Theory (DFT) with the B3LYP/6-31G(d,p) basis set. The research focused on intramolecular charge transfer (ICT) and its influence on non-linear optical (NLO) properties. The NLO analysis revealed that the protonated forms of these compounds exhibit higher dipole moments, indicating their potential for NLO applications. Natural Bond Orbital (NBO) analysis identified molecule 5 as having the highest E(2) value of 509.41 kcal/mol, signifying strong electron donation from nitrogen to hydrogen atoms. The study also evaluated the thermal properties, showing that the Gibbs free energy remained positive across a wide temperature range, suggesting that none of the compounds are spontaneously formed in either neutral or protonated states. Additionally, Monte Carlo simulations indicated favorable adsorption energies for these derivatives on the Fe (110) surface, with compound 5 demonstrating the most significant inhibitory potential. We conduced of that, lower negative adsorption energy (−216.729) compound 1 are confirm with highest energy gap (3.396 eV), and smaller refractive index, and electrical conductivityof compound 1 indicates a small metal-inhibitor molecule interaction, as well as are agreement with Monte Carlo simulation for adsorption on Fe (110) non protonated case.}
}
@incollection{DAWES200112082,
title = {Probabilistic Thinking},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {12082-12089},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00431-9},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767004319},
author = {R.M. Dawes},
abstract = {While games of chance have been played for thousands of years, and while experienced players often had good intuitive ideas of the relative frequencies of various outcomes, the concept of probability as referring to the ratio of favorable outcomes to total outcomes of a ‘fair’ gambling device emerged only 500 or so years ago in Western societies. That allowed evaluation of new games not yet played and later led to a more abstract conception of probability as a measure satisfying certain conditions (‘axioms’). Only in the past 150 years or so has probability had a major role in science and only in the last 50 years or so in everyday life—as for example in evaluating medical outcomes or technological risks or manufacturer liability. Thus, especially in attempting to assess probability in everyday situations, our intuitions are often deficient—more so than those concerning quantity, space, and time. The major problem is not, however, one of making random errors in probability judgments but of making systematic ones that result from a number of well-known and research systematic cognitive biases and heuristics, which are described in this article. These systematic departures from rational assessment do not imply that coherent and accurate probabilistic thinking is (anywhere near) impossible, but that when departures from coherence and accuracy occur, they tend to follow a predictable pattern.}
}