@article{MOHAMED2022152376,
title = {The Search for Efficient and Stable Metal-Organic Frameworks for Photocatalysis: Atmospheric Fixation of Nitrogen},
journal = {Applied Surface Science},
volume = {583},
pages = {152376},
year = {2022},
issn = {0169-4332},
doi = {https://doi.org/10.1016/j.apsusc.2021.152376},
url = {https://www.sciencedirect.com/science/article/pii/S0169433221033948},
author = {Amro M.O. Mohamed and Yusuf Bicer},
keywords = {Computational screening, Electronic properties, Green ammonia, Life cycle assessment, Molecular simulation, Photoactivity, Solar energy},
abstract = {Recent research targets the low-pressure synthesis of ammonia via a light-initiated catalytic process. Despite the importance of materials selection for photocatalysis, computational efforts to guide candidate materials’ nomination ahead of experiments are lacking. The purpose of this study is to employ computational screening, using density functional theory and molecular simulations, to select and evaluate metal–organic frameworks (MOFs) as nitrogen fixation photocatalysts and further deduce correlations for the prediction of MOFs’ electronic properties. First, MOFs with appropriate electronic and structural properties are identified. The top candidates have been examined from the perspective of adsorption, diffusion, and mechanical and chemical stability properties. Four MOFs, Fe2Cl2(BBTA), Fe2(mDOBDC), Zn2(mDOBDC), and Ni-BTP, have been selected based on their band edges, while only Fe2Cl2(BBTA) MOF exhibited a bandgap less than 3 eV. Fe2(mDOBDC) exhibited the highest shear modulus of approximately 31 GPa. In addition, a life cycle assessment of the four MOFs showed that Ni-BTP has the lowest environmental impact. A set of 48 MOFs’ combinations are proposed for heterojunction application to enhance charge carriers’ separation. Intriguingly, we demonstrated the predictability of MOF’s bandgap and edges from MOF’s organic linker bandgap and metal node type (oxidation state and corresponding electronic configuration) for MOF families.}
}
@article{2024100676,
title = {Erratum regarding missing declaration of competing interest statements in previously published articles},
journal = {International Journal of Child-Computer Interaction},
volume = {41},
pages = {100676},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100676},
url = {https://www.sciencedirect.com/science/article/pii/S221286892400045X}
}
@incollection{FREUND20151,
title = {Chapter 1 - Introduction},
editor = {Jack Freund and Jack Jones},
booktitle = {Measuring and Managing Information Risk},
publisher = {Butterworth-Heinemann},
address = {Boston},
pages = {1-11},
year = {2015},
isbn = {978-0-12-420231-3},
doi = {https://doi.org/10.1016/B978-0-12-420231-3.00001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124202313000014},
author = {Jack Freund and Jack Jones},
keywords = {Analysis, Assessment, Assumptions, Bald tire, Risk, Threat, Vulnerability},
abstract = {This chapter makes the case for the need for quantitative risk management. It begins with the Bald Tire thought experiment to help make the case for a need to articulate assumptions, discuss terminology, and makes plain the factors of risk that we care about modeling and how to communicate them effectively to management. This section also discusses the difference between risk assessment and risk analysis, and details the deficiencies in current approaches that treat the two the same. Lastly, the chapter spells out the progression of topics for the remainder of the book and offers some words of advice on how thinking about risk will impact your ability to make better decisions in all aspects of your life.}
}
@article{2024100677,
title = {Erratum regarding missing Declaration of Competing Interest statements in previously published articles},
journal = {International Journal of Child-Computer Interaction},
volume = {41},
pages = {100677},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100677},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000461}
}
@article{SPEISER2012463,
title = {Why is paper-and-pencil multiplication difficult for many people?},
journal = {The Journal of Mathematical Behavior},
volume = {31},
number = {4},
pages = {463-475},
year = {2012},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2012.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312312000338},
author = {Robert Speiser and Matthew H. Schneps and Amanda Heffner-Wong and Jaimie L. Miller and Gerhard Sonnert},
keywords = {Representations, Spatial schemas, Working memory, Attention, Multiplication, Algorithms},
abstract = {In school, at least in the US, we were taught to multiply by hand according to a standard algorithm. Most people find that algorithm difficult to use, and many children fail to learn it. We propose a new way to make sense of this difficulty: to treat explicit computation as perceptually supported physical and mental action. Based on recent work in neuroscience, we trace the flow of arithmetic information to emphasize demands on visual working memory and attention. We predict that algorithms that make moderate demands on memory and attention will work better than others that make stronger demands. We suggest that the judicious use of spatial schemas can reduce such cognitive demands. Experimental evidence from children in an inner-city school supports this claim. Our work suggests new ways to think about instruction. The goal should be to minimize demands that present obstacles and maximize instead what human eyes, bodies, and brains do well.}
}
@article{CHONG2024103352,
title = {Integrable approximations of dispersive shock waves of the granular chain},
journal = {Wave Motion},
volume = {130},
pages = {103352},
year = {2024},
issn = {0165-2125},
doi = {https://doi.org/10.1016/j.wavemoti.2024.103352},
url = {https://www.sciencedirect.com/science/article/pii/S0165212524000829},
author = {Christopher Chong and Ari Geisler and Panayotis G. Kevrekidis and Gino Biondini},
abstract = {In the present work we revisit the shock wave dynamics in a granular chain with precompression. By approximating the model by an α-Fermi–Pasta–Ulam–Tsingou chain, we leverage the connection of the latter in the strain variable formulation to two separate integrable models, one continuum, namely the KdV equation, and one discrete, namely the Toda lattice. We bring to bear the Whitham modulation theory analysis of such integrable systems and the analytical approximation of their dispersive shock waves in order to provide, through the lens of the reductive connection to the granular crystal, an approximation to the shock wave of the granular problem. A detailed numerical comparison of the original granular chain and its approximate integrable-system-based dispersive shocks proves very favorable in a wide parametric range. The gradual deviations between (approximate) theory and numerical computation, as amplitude parameters of the solution increase are quantified and discussed.}
}
@article{HURST2024105918,
title = {Continuous and discrete proportion elicit different cognitive strategies},
journal = {Cognition},
volume = {252},
pages = {105918},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105918},
url = {https://www.sciencedirect.com/science/article/pii/S001002772400204X},
author = {Michelle A. Hurst and Steven T. Piantadosi},
keywords = {Proportion, Strategy, Bayesian analysis, Model comparison},
abstract = {Despite proportional information being ubiquitous, there is not a standard account of proportional reasoning. Part of the difficulty is that there are several apparent contradictions: in some contexts, proportion is easy and privileged, while in others it is difficult and ignored. One possibility is that although we see similarities across tasks requiring proportional reasoning, people approach them with different strategies. We test this hypothesis by implementing strategies computationally and quantitatively comparing them with Bayesian tools, using data from continuous (e.g., pie chart) and discrete (e.g., dots) stimuli and preschoolers, 2nd and 5th graders, and adults. Overall, people's comparisons of highly regular and continuous proportion are better fit by proportion strategy models, but comparisons of discrete proportion are better fit by a numerator comparison model. These systematic differences in strategies suggest that there is not a single, simple explanation for behavior in terms of success or failure, but rather a variety of possible strategies that may be chosen in different contexts.}
}
@article{HAO201630,
title = {Reflection enhances creativity: Beneficial effects of idea evaluation on idea generation},
journal = {Brain and Cognition},
volume = {103},
pages = {30-37},
year = {2016},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278262616300057},
author = {Ning Hao and Yixuan Ku and Meigui Liu and Yi Hu and Mark Bodner and Roland H. Grabner and Andreas Fink},
keywords = {Idea evaluation, Idea generation, Creativity, Alpha, EEG},
abstract = {The present study aimed to explore the neural correlates underlying the effects of idea evaluation on idea generation in creative thinking. Participants were required to generate original uses of conventional objects (alternative uses task) during EEG recording. A reflection task (mentally evaluating the generated ideas) or a distraction task (object characteristics task) was inserted into the course of idea generation. Behavioral results revealed that participants generated ideas with higher originality after evaluating the generated ideas than after performing the distraction task. The EEG results revealed that idea evaluation was accompanied with upper alpha (10–13Hz) synchronization, most prominent at frontal cortical sites. Moreover, upper alpha activity in frontal cortices during idea generation was enhanced after idea evaluation. These findings indicate that idea evaluation may elicit a state of heightened internal attention or top-down activity that facilitates efficient retrieval and integration of internal memory representations.}
}
@article{KUGURAKOVA2015112,
title = {Anthropomorphic Artificial Social Agent with Simulated Emotions and its Implementation},
journal = {Procedia Computer Science},
volume = {71},
pages = {112-118},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.217},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036789},
author = {Vlada Kugurakova and Maxim Talanov and Nadir Manakhov and Denis Ivanov},
keywords = {intelligent agents, visualization, emotional artificial intelligence, neuromodulators, visual speech synthesis, expressive and controllable speech synthesis},
abstract = {In this paper we describe an emotional human-machine interface as an anthropomorphic social agent able to exhibit simulated emotions and react to emotional stimuli. We propose a neurobiologically inspired agent implementation that is based on mechanics of chemical and physiological processes within human brain. Implementation of model features simulation of neuromodulators such as dopamine, serotonin, and noradrenaline. Demonstration of emotions is achieved via combining aforementioned neuromodulators in different proportions. The Lovheim cube of emotions is used for this purpose. Topic of “uncanny valley” phenomenon and its effect on human-machine interactions is also mentioned. In conclusion of this paper we have proposed realistic computation model allowing us to visualize agents mimics in sync with his speech, and have made a working prototype of aforementioned model.}
}
@incollection{DORST200723,
title = {2 - Spanning oriented subspaces},
editor = {Leo Dorst and Daniel Fontijne and Stephen Mann},
booktitle = {Geometric Algebra for Computer Science},
publisher = {Morgan Kaufmann},
address = {Burlington},
pages = {23-64},
year = {2007},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-369465-2},
doi = {https://doi.org/10.1016/B978-012369465-2/50005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123694652500050},
author = {Leo Dorst and Daniel Fontijne and Stephen Mann},
abstract = {Publisher Summary
This chapter shows that a vector space is much more than merely a space of vectors, and that it is straightforward and useful to extend it computationally. The crucial idea here is to make the subspaces of vector space explicit elements of computation. To build the algebra of subspaces, the familiar lines and planes are revisited through the origin. This chapter investigates their geometrical properties carefully and formalizes those by the aid of a new algebraic outer product, which algebraically builds subspaces from vectors. The structure it produces is considered for the Grassmann space of subspaces of a vector space Rn, and defines many terms to describe its features. Throughout this chapter, it considers a real n-dimensional vector space Rn, but has no need for a metric; additionally, it only treats its homogeneous subspaces (i.e., subspaces containing the origin). The chapter starts with an n-dimensional vector space. However, the definition of a vector space in linear algebra is more general than what is needed in this book, being defined over arbitrary fields of scalars. To develop thinking about subspaces, the homogeneous subspaces of a 3-D space are considered.}
}
@article{STEVENS2022108887,
title = {Hyper-differential sensitivity analysis for inverse problems governed by ODEs with application to COVID-19 modeling},
journal = {Mathematical Biosciences},
volume = {351},
pages = {108887},
year = {2022},
issn = {0025-5564},
doi = {https://doi.org/10.1016/j.mbs.2022.108887},
url = {https://www.sciencedirect.com/science/article/pii/S0025556422000827},
author = {Mason Stevens and Isaac Sunseri and Alen Alexanderian},
keywords = {Inverse problems, Sensitivity analysis, Uncertainty quantification, Design of experiments, Computational epidemiology},
abstract = {We consider inverse problems governed by systems of ordinary differential equations (ODEs) that contain uncertain parameters in addition to the parameters being estimated. In such problems, which are common in applications, it is important to understand the sensitivity of the solution of the inverse problem to the uncertain model parameters. It is also of interest to understand the sensitivity of the inverse problem solution to different types of measurements or parameters describing the experimental setup. Hyper-differential sensitivity analysis (HDSA) is a sensitivity analysis approach that provides tools for such tasks. We extend existing HDSA methods by developing methods for quantifying the uncertainty in the estimated parameters. Specifically, we propose a linear approximation to the solution of the inverse problem that allows efficiently approximating the statistical properties of the estimated parameters. We also explore the use of this linear model for approximate global sensitivity analysis. As a driving application, we consider an inverse problem governed by a COVID–19 model. We present comprehensive computational studies that examine the sensitivity of this inverse problem to several uncertain model parameters and different types of measurement data. Our results also demonstrate the effectiveness of the linear approximation model for uncertainty quantification in inverse problems and for parameter screening.}
}
@article{20152,
title = {Positive Gradients},
journal = {Cell Systems},
volume = {1},
number = {1},
pages = {2-3},
year = {2015},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2015.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405471215000137},
abstract = {The new associate vice chancellor of computational heath sciences at the University of California San Diego reflects on the coming era of big data in medicine.}
}
@article{PENG2024100093,
title = {Memristor-based spiking neural networks: cooperative development of neural network architecture/algorithms and memristors},
journal = {Chip},
volume = {3},
number = {2},
pages = {100093},
year = {2024},
issn = {2709-4723},
doi = {https://doi.org/10.1016/j.chip.2024.100093},
url = {https://www.sciencedirect.com/science/article/pii/S270947232400011X},
author = {Huihui Peng and Lin Gan and Xin Guo},
keywords = {Spike neural networks, Hardware, Memristor, Algorithm, Cooperative development},
abstract = {Inspired by the structure and principles of the human brain, spike neural networks (SNNs) appear as the latest generation of artificial neural networks, attracting significant and universal attention due to their remarkable low-energy transmission by pulse and powerful capability for large-scale parallel computation. Current research on artificial neural networks gradually change from software simulation into hardware implementation. However, such a process is fraught with challenges. In particular, memristors are highly anticipated hardware candidates owing to their fast-programming speed, low power consumption, and compatibility with the complementary metal–oxide semiconductor (CMOS) technology. In this review, we start from the basic principles of SNNs, and then introduced memristor-based technologies for hardware implementation of SNNs, and further discuss the feasibility of integrating customized algorithm optimization to promote efficient and energy-saving SNN hardware systems. Finally, based on the existing memristor technology, we summarize the current problems and challenges in this field.}
}
@incollection{SHAH2017251,
title = {Chapter Seven - What Makes Everyday Scientific Reasoning So Challenging?},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {66},
pages = {251-299},
year = {2017},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2016.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079742116300214},
author = {Priti Shah and Audrey Michal and Amira Ibrahim and Rebecca Rhodes and Fernando Rodriguez},
keywords = {ANCOVA, Anecdotes, Causality bias, Decision making, Heuristic vs. analytic thinking, Science education, Scientific reasoning, Selection bias, Statistical validity},
abstract = {Informed citizens are expected to use science-based evidence to make decisions about health, behavior and public policy. To do so, they must judge whether the evidence is consistent with the claims presented (theory-evidence coordination). Unfortunately, most individuals make numerous errors in theory-evidence coordination. In this chapter, we provide an overview of research on science evidence evaluation, drawing from research in cognitive and developmental psychology, science and statistics education, decision sciences, political science and science communication. Given the breadth of this research area, we highlight some influential studies and reviews across these different topics. This body of research provides several clues about: (1) why science evidence evaluation is challenging, (2) the influence of the content and context of the evidence and (3) how the characteristics of the individual examining the evidence impact the quality of the evaluations. Finally, we suggest some possible directions for empirical research on improving evidence evaluation and point to the responsibility of scientists, especially social and behavioral scientists, in communicating their findings to the public. Overall, our goal is to give readers an interdisciplinary view of science evidence evaluation research and to integrate research from different scientific communities that address similar questions.}
}
@incollection{SEDIG2005239,
title = {17 A descriptive framework for designing interaction for visual abstractions},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {239-254},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80045-5},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800455},
author = {K. Sedig and J. Morey},
abstract = {This chapter propses a descriptive framework for categorisation and characterisation of the different forms of interaction with visual abstractions (VAs). Abstract visual representations play an important role in assisting human reasoning, thinking, and understanding processes. There are different forms of designing interaction with these representations. The goal of this chapter is to provide a descriptive framework to guide the designers and evaluators of cognitive tools to determine the appropriate forms of interaction that can facilitate the understanding of abstract concepts, patterns, structures and processes. The framework is described and substantiated using a number of VAs that represent and communicate mathematical ideas.}
}
@article{RUFFO2023100531,
title = {Studying fake news spreading, polarisation dynamics, and manipulation by bots: A tale of networks and language},
journal = {Computer Science Review},
volume = {47},
pages = {100531},
year = {2023},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2022.100531},
url = {https://www.sciencedirect.com/science/article/pii/S157401372200065X},
author = {Giancarlo Ruffo and Alfonso Semeraro and Anastasia Giachanou and Paolo Rosso},
keywords = {Disinformation, Network analysis, Natural language processing, Opinion dynamics, Fake news spreading, Social bots},
abstract = {With the explosive growth of online social media, the ancient problem of information disorders interfering with news diffusion has surfaced with a renewed intensity threatening our democracies, public health, and news outlets’ credibility. Therefore, thousands of scientific papers have been published in a relatively short period, making researchers of different disciplines struggle with an information overload problem. The aim of this survey is threefold: (1) we present the results of a network-based analysis of the existing multidisciplinary literature to support the search for relevant trends and central publications; (2) we describe the main results and necessary background to attack the problem under a computational perspective; (3) we review selected contributions using network science as a unifying framework and computational linguistics as the tool to make sense of the shared content. Despite scholars working on computational linguistics and networks traditionally belong to different scientific communities, we expect that those interested in the area of fake news should be aware of crucial aspects of both disciplines.}
}
@incollection{BOSE2006649,
title = {Chapter 10 - Fuzzy Logic and Applications},
editor = {Bimal K. Bose},
booktitle = {Power Electronics And Motor Drives},
publisher = {Academic Press},
address = {Burlington},
pages = {649-729},
year = {2006},
isbn = {978-0-12-088405-6},
doi = {https://doi.org/10.1016/B978-012088405-6/50012-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780120884056500121},
author = {Bimal K. Bose},
abstract = {Publisher Summary
The chapter deals with the description of Fussy Logic (FL) principles and its application in power electronics and motor-drive systems. The FL is a discipline under Artificial Intelligence (AI). AI is basically computer emulation of human thinking (called computational intelligence). The goal of AI is to mimic human intelligence. AI also includes expert systems (ESs), artificial neural networks (ANNs), or neural networks (NNWs), and genetic algorithms (GAs). All of the main areas in AI, except ES, are defined as soft computing. The concept of FL and its characteristics emerge from Zadeh's theory propounded in 1965. Any FL application uses a knowledge base that consists of multivalued membership functions (MFs) describing the fuzzy variables and the rule table consisting of “IF… THEN… statements.” The knowledge base is developed on the basis of the behavioral nature of the system. The trial-and-error approach of FL algorithms may be time consuming, but user-friendly computer programs (such as the MATLAB-based Fuzzy Logic Toolbox) help speed the process. The applications of FL principles, include speed control of induction motor vector drives, efficiency optimization of induction motor vector drives by flux programming; and wind generation systems, linearization of the transfer characteristics of thyristor converters at discontinuous conduction, induction motor stator resistance estimations, estimation of distorted waveforms and MRAC slip gain tuning control of vector drives.}
}
@article{ABONDIO202237,
title = {Single Cell Multiomic Approaches to Disentangle T Cell Heterogeneity},
journal = {Immunology Letters},
volume = {246},
pages = {37-51},
year = {2022},
issn = {0165-2478},
doi = {https://doi.org/10.1016/j.imlet.2022.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0165247822000669},
author = {Paolo Abondio and Carlo {De Intinis} and João Lídio {da Silva Gonçalves Vianez Júnior} and Luigia Pace},
keywords = {T cells, scRNA-seq, Analysis pipeline, Pseudotime, TCR},
abstract = {Single-cell multi-omics is a rapidly evolving field, thanks to a fast technological improvement and the growing accuracy of dedicated computational tools for data analysis. Its importance is highlighted by the possibility to distinguish apparently identical cells based on their pattern of gene expression. In this review, the mostly used methodological pipelines for single-cell analysis, as well as the advantages and potential limitations of several analytical steps, are presented and discussed, with specific sections focusing on crucial parts of this procedure, their bioinformatic tools, as well as their advantages and potential drawbacks. The current bioinformatic approaches for T-cell receptor (TCR) reconstruction are also introduced, as well as a comparison of single-cell sequencing technologies. Critical points that may introduce analytical biases and potential inaccuracies in data interpretation are also highlighted.}
}
@article{FAN2020248,
title = {From Brain Science to Artificial Intelligence},
journal = {Engineering},
volume = {6},
number = {3},
pages = {248-252},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920300035},
author = {Jingtao Fan and Lu Fang and Jiamin Wu and Yuchen Guo and Qionghai Dai},
keywords = {Artificial intelligence, Brain science},
abstract = {Reviewing the history of the development of artificial intelligence (AI) clearly reveals that brain science has resulted in breakthroughs in AI, such as deep learning. At present, although the developmental trend in AI and its applications has surpassed expectations, an insurmountable gap remains between AI and human intelligence. It is urgent to establish a bridge between brain science and AI research, including a link from brain science to AI, and a connection from knowing the brain to simulating the brain. The first steps toward this goal are to explore the secrets of brain science by studying new brain-imaging technology; to establish a dynamic connection diagram of the brain; and to integrate neuroscience experiments with theory, models, and statistics. Based on these steps, a new generation of AI theory and methods can be studied, and a subversive model and working mode from machine perception and learning to machine thinking and decision-making can be established. This article discusses the opportunities and challenges of adapting brain science to AI.}
}
@article{DUFVA201917,
title = {Grasping the future of the digital society},
journal = {Futures},
volume = {107},
pages = {17-28},
year = {2019},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302252},
author = {Tomi Dufva and Mikko Dufva},
keywords = {Digitalisation, Digital society, Experiential foresight, Craft education, Art education, Artistic research, Embodied learning, Critical theory},
abstract = {Society is increasingly digitalised and connected, with computers and algorithms mediating much of people’s daily activity in one way or another. The degree of digitalisation and its consequences are challenging to understand because most people lack first-hand experience of what digitalisation actually feels like. Digitalisation is abstract and difficult to grasp, which leads to a detached sense of the digital surroundings. In this paper, we argue that in order to grasp the nature and future of a digitalised society, an embodied understanding of digitalisation is needed. Such an understanding should utilise ways of knowing other than rational thinking, challenge existing narratives and move from preparing for the future to exploring novelty. We focus on the importance of a broader understanding of digitalisation within the field of education and discuss how a more diverse view is essential to empower people to take part in a digitalised society. We use the concept of ‘digi-grasping’ to analyse awareness and involvement in the digital world. By digi-grasping we mean active sense-making and existing in a world that consists of both a digital and a physical world. We argue that through ‘grasping’ the digital world it is possible to create an ethical and aesthetic attachment to society. Digi-grasping can empower people to understand and question the choices and motivations behind current digital structures and create new structures. It is thus an important approach to shaping the futures of digital society. We illustrate the concept with examples representing different modes of being and doing at the interface of the digital and physical.}
}
@article{AGRAWAL20241,
title = {A systematic review on metaheuristic approaches for autonomous path planning of unmanned aerial vehicles},
journal = {Drone Systems and Applications},
volume = {12},
pages = {1-28},
year = {2024},
issn = {2564-4939},
doi = {https://doi.org/10.1139/dsa-2023-0093},
url = {https://www.sciencedirect.com/science/article/pii/S2564493924000158},
author = {Sameer Agrawal and Bhumeshwar K. Patle and Sudarshan Sanap},
keywords = {artificial intelligence, path planning, metaheuristic algorithms, UAV, mobile robot navigation},
abstract = {In the path planning of UAVs, autonomous decision-making and control are challenging tasks in the uncertain 3D environment consisting of static and dynamic obstacles. Hence, the selection of appropriate path-planning approaches is essential. In the proposed work, we have considered the meta-heuristic approaches only for an in-depth review. Metaheuristic approaches have been remarkably known for solving complex problems, optimal solutions, and lesser computational complexity compared to deterministic approaches that produce an inefficient solution. An in-depth review has been made by considering the approaches used for path planning, their advantages, disadvantages, applications, the type of time domain (offline or online), type of environment (simulation or real time), hybridization with other approaches, single or multiple UAV system, and obstacle handled (static or dynamic). It is observed that current meta-heuristic methods face constraints like inadequate convergence rates, entrapment in local optima, and complex operations, necessitating continuous development of novel approaches. Implementation of path-planning approaches are very much limited to simulation study over experimental analysis. Hybrid algorithms emerge as a potential solution for tackling these hurdles and optimizing UAV navigation, particularly in dynamic environments involving multiple UAVs. The paper highlights key research gaps, trends, along with prospects in the field of research.}
}
@article{LI2021711,
title = {Prediction of BLEVE blast loading using CFD and artificial neural network},
journal = {Process Safety and Environmental Protection},
volume = {149},
pages = {711-723},
year = {2021},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2021.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0957582021001324},
author = {Jingde Li and Qilin Li and Hong Hao and Ling Li},
keywords = {ANN, BLEVE, Blast wave, Peak pressure, CFD, Neural networks},
abstract = {Boiling Liquid Expanding Vapour Explosions (BLEVEs) are extreme explosions driven by nonlinear physical processes associated with explosively expanded vapour and flashed liquid. Blast loading generated from BLEVEs may severely harm structures and people. Prediction of such strong explosions is not currently feasible using simple tools. Physics-based Computational Fluid Dynamics (CFD) methods are commonly utilized to predict the blast loading of BLEVE by going through many empirical formulas that map input variables to the target progressively. The calculation is often time-consuming, and it is therefore impractical to apply these methods to predict explosion loads from BLEVE in normal design analysis. Thinking of the composition of empirical relations in CFD models as a complex and nonlinear function, it is necessary to find an approximation of this function that can be efficiently calculated. The Artificial Neural Network (ANN) is a data-driven computational model that is capable of approximating any functions by learning from training data. Once properly trained, ANN can produce accurate predictions even for unseen inputs. This article presents the development of an ANN model to predict blast loading of BLEVEs in an open environment. A rigorous validation process is presented for the design of ANN structure, and the selected ANN is trained using validated simulation data from CFD models. Extensive evaluation of the network predictive performance is conducted, and it shows that the developed ANN can reproduce the result of CFD models effectively and efficiently, not only on simulation data but also on real experimental data. The prediction of ANN has a percentage error around 6 % and R2 value over 0.99 with the result of CFD simulated data. It speeds up the processing time from hours to seconds and only increases the error from 26.3 %–27.6 %, compared to the CFD simulations of real experimental data. Therefore, the developed ANN model can be potentially applied in the process engineering to generate a large number of reliable data for safety and risk assessment of BLEVEs in a more efficient way.}
}
@article{BERTO2024101278,
title = {A motivational-based learning model for mobile robots},
journal = {Cognitive Systems Research},
volume = {88},
pages = {101278},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101278},
url = {https://www.sciencedirect.com/science/article/pii/S138904172400072X},
author = {Letícia Berto and Paula Costa and Alexandre Simões and Ricardo Gudwin and Esther Colombini},
keywords = {Motivation, Action selection and planning, Models of internal states, Internal reinforces},
abstract = {Humans have needs motivating their behavior according to intensity and context. However, we also create preferences associated with each action’s perceived pleasure, which is susceptible to changes over time. This makes decision-making more complex, requiring learning to balance needs and preferences according to the context. To understand how this process works and enable the development of robots with a motivational-based learning model, we computationally model a motivation theory proposed by Hull. In this model, the agent (an abstraction of a mobile robot) is motivated to keep itself in a state of homeostasis. We introduced hedonic dimensions to explore the impact of preferences on decision-making and employed reinforcement learning to train our motivated-based agents. In our experiments, we deploy three agents with distinct energy decay rates, simulating different metabolic rates, within two diverse environments. We investigate the influence of these conditions on their strategies, movement patterns, and overall behavior. The findings reveal that agents excel at learning more effective strategies when the environment allows for choices that align with their metabolic requirements. Furthermore, we observe that incorporating pleasure as a component of the motivational mechanism affects behavior learning, particularly for agents with regular metabolisms depending on the environment. Our study also unveils that, when confronted with survival challenges, agents prioritize immediate needs over pleasure and equilibrium. These insights shed light on how robotic agents can adapt and make informed decisions in demanding scenarios, demonstrating the intricate interplay between motivation, pleasure, and environmental context in autonomous systems.}
}
@article{DEVGUN2022143,
title = {Pre-cath Laboratory Planning for Left Atrial Appendage Occlusion – Optional or Essential?},
journal = {Interventional Cardiology Clinics},
volume = {11},
number = {2},
pages = {143-152},
year = {2022},
note = {Left Atrial Appendage Occlusion},
issn = {2211-7458},
doi = {https://doi.org/10.1016/j.iccl.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2211745821001073},
author = {Jasneet Devgun and Tom {De Potter} and Davide Fabbricatore and Dee Dee Wang},
keywords = {Left atrial appendage occlusion, Left atrial appendage, Atrial fibrillation, Cardiac CT, 3D printing, Imaging, Structural heart disease}
}
@article{RUSSELL2018114,
title = {Leveraging complexity for ecosystemic innovation},
journal = {Technological Forecasting and Social Change},
volume = {136},
pages = {114-131},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517316475},
author = {Martha G. Russell and Nataliya V. Smorodinskaya},
keywords = {Business network, Collaboration, Complexity, Innovation ecosystem, Innovation cluster, Global economy, Non-linearity},
abstract = {This paper looks at innovation ecosystems through the lens of complexity science, considering them as open non-linear entities that are characterized by changing multi-faceted motivations of networked actors, high receptivity to feedback, and persistent structural transformations. In the context of the growing organizational complexity of economies, driven by their adaptation to high uncertainty, and the central role of collaboration, we differentiate the innovation capacity of various types of business networks by the complexity of their internal interactions, thus identifying the place of innovation ecosystems in the world of business networks, as well as the place of innovation clusters among other innovation ecosystems. We observe how innovation ecosystems have been viewed in four different research streams: management literature; the inter-firm and business network stream of economic and sociological literature; the innovation policy and competitiveness agenda in economic literature; and the dichotomy of localized and economy-wide innovation ecosystems in policy studies (in economic literature, evolutionary geography, and regional research). We then describe generic properties of innovation ecosystems in terms of complexity science, viewing them as complex adaptive systems, paying special attention to the complexity of innovation clusters. We compare complexity thinking of modern economies, deriving from their emerging ecosystem design, with traditional thinking conceived for industrial era, drawing insights for a better transition to innovation-led growth. We conclude with a summary of key findings, practical and policy implications and recommendations for further study.}
}
@article{GUO2023100246,
title = {Function approximation reinforcement learning of energy management with the fuzzy REINFORCE for fuel cell hybrid electric vehicles},
journal = {Energy and AI},
volume = {13},
pages = {100246},
year = {2023},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2023.100246},
url = {https://www.sciencedirect.com/science/article/pii/S2666546823000186},
author = {Liang Guo and Zhongliang Li and Rachid Outbib and Fei Gao},
keywords = {Energy management strategy, Fuel cell hybrid electric vehicle, Reinforcement learning, Fuzzy inference system, Fuzzy policy gradient, Hardware-in-loop},
abstract = {In the paper, a novel self-learning energy management strategy (EMS) is proposed for fuel cell hybrid electric vehicles (FCHEV) to achieve the hydrogen saving and maintain the battery operation. In the EMS, it is proposed to approximate the EMS policy function with fuzzy inference system (FIS) and learn the policy parameters through policy gradient reinforcement learning (PGRL). Thus, a so-called Fuzzy REINFORCE algorithm is first proposed and studied for EMS problem in the paper. Fuzzy REINFORCE is a model-free method that the EMS agent can learn itself through interactions with environment, which makes it independent of model accuracy, prior knowledge, and expert experience. Meanwhile, to stabilize the training process, a fuzzy baseline function is adopted to approximate the value function based on FIS without affecting the policy gradient direction. Moreover, the drawbacks of traditional reinforcement learning such as high computation burden, long convergence time, can also be overcome. The effectiveness of the proposed methods were verified by Hardware-in-Loop experiments. The adaptability of the proposed method to the changes of driving conditions and system states is also verified.}
}
@article{WOLFENGAGEN2016347,
title = {Evolutionary Domains for Varying Individuals},
journal = {Procedia Computer Science},
volume = {88},
pages = {347-352},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.447},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317033},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov and Viacheslav V. Navrotskiy and Sergey I. Kukalev and Alexander A. Zuev and Polina V. Belyatskaya},
keywords = {computational model, variable domains, individual migration, tangled individuals},
abstract = {The domains ranged by the variables using Web-resources can vary with a time. This is possible even in a runtime of Web-application giving rise to various vulnerabilities and bugs. This paper focuses at the problem mentioned as the individual migration in a problem domain. There is a lack of computational models which operate in an environment of variable domains and the contribution is to develop such a model. The advance is in establishing the mechanism for driving the dynamics of the sets and individuals. As a consequence, the behavior of the variables in query logical expression becomes predictable suppressing the possible semantic instability.}
}
@article{EKLUND201716,
title = {Two approaches to System-of-Systems from Lative Logic point of view},
journal = {Procedia Computer Science},
volume = {119},
pages = {16-21},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.155},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323657},
author = {Patrik Eklund and Jari Kortelainen},
keywords = {Category theory, computational science, lative logic, System-of-Systems},
abstract = {The paper presents two approaches to model System-of-Systems on lative logic point of view. Lative logic is a general framework to construct building blocks of logic using Category Theory as its metalanguage. This approach reveals avenues to describe System-of-Systems themselves, and to model information and processes they posess, using some reasonable modelling languages in a computational manner, thus, touching foundations of computational science. After presenting some preliminary notes, the paper explains the main steps to construct lative logics, and then give two approaches to System-of-System modelling. Finally, the paper presents a survey to some applications.}
}
@incollection{HARITASHYA20221,
title = {4.01 - The Development, History and Future of Cryospheric Geomorphology},
editor = {John (Jack) F. Shroder},
booktitle = {Treatise on Geomorphology (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {1-19},
year = {2022},
isbn = {978-0-12-818235-2},
doi = {https://doi.org/10.1016/B978-0-12-818234-5.00181-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128182345001814},
author = {Umesh K. Haritashya and Jon Harbor and Hugh French},
keywords = {Cold regions geomorphology, Cryosphere, Geocryology, Glacial geomorphology, Glaciology, Permafrost, Process geomorphology, Quaternary science},
abstract = {The cryosphere is a broadly defined term associated with areas where water is in solid form. Thus, cryospheric geomorphology, in theory, should include polar and mountain regions, the arctic, ice, sea ice, glaciers, rock glaciers, snow, permafrost, ice shelves and icebergs, karst-glacial interactions, and even planetary cryosphere. No book can completely justify including all these areas/topics. In this treatise on geomorphology, the focus is primarily on conventional and applied glacial geomorphology and periglacial geomorphology with a rich history and promising future. Glacial geomorphology, for example, rose to prominence in debate surrounding the theory of Ice Ages. Detailed descriptions and novel measurements of processes and landforms and now high-end computing facilities led to sophisticated process-form modeling. Current emphases include interactions between glacial and other processes in development of mountain belts, natural hazards, hydrological interplay, and responses to climate change. Periglacial geomorphology begins with Walery von Lozinski and the IGS Spitzbergen excursion, 1910–11, followed by it becoming a descriptive branch of European-dominated climatic geomorphology with a growing emphasis on quantitative studies by the 1960s. More recently, the emergence of geocryology, cold-regions engineering, and sophisticated Quaternary studies is dominating many aspects of basic and applied periglacial geomorphology. The advent of high-resolution satellite and drone images, digital elevation models, and machine learning and large-scale data computational techniques are now leading the discovery process for cryospheric geomorphology.}
}
@article{KELLER2006357,
title = {A practical view of ‘druggability’},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {4},
pages = {357-361},
year = {2006},
note = {Next-generation therapeutics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2006.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S1367593106000834},
author = {Thomas H Keller and Arkadius Pichota and Zheng Yin},
abstract = {The introduction of Lipinski's ‘Rule of Five’ has initiated a profound shift in the thinking paradigm of medicinal chemists. Understanding the difference between biologically active small molecules and drugs became a priority in the drug discovery process, and the importance of addressing pharmacokinetic properties early during lead optimization is a clear result. These concepts of ‘drug-likeness’ and ‘druggability’ have been extended to proteins and genes for target identification and selection. How should these concepts be integrated practically into the drug discovery process? This review summarizes the recent advances in the field and examines the usefulness of ‘the rules of the game’ in practice from a medicinal chemist's standpoint.}
}
@article{LAI202333,
title = {Impact of social cognitive propensity on the processing of nontransparent sentential meaning},
journal = {Journal of Pragmatics},
volume = {205},
pages = {33-62},
year = {2023},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2022.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0378216622003010},
author = {Yao-Ying Lai and Huei-ling Lai},
keywords = {Nontransparent meaning, Meaning contextualization, Combinatorial semantic processing, Individual differences, Social cognition, Autism-spectrum quotient},
abstract = {This study investigates the influence of individual social-cognitive propensity in the processing of nontransparent sentential meaning, exemplified by the morpho-syntactically unsupported iterative meaning in “The frog hopped for five minutes.” Results of our speeded questionnaire in Mandarin Chinese showed that social cognitive propensity of typically-developed individuals, indexed by autistic-like traits, significantly correlated with online response times (RTs) of naturalness rating, while the effect was absent in offline rating scores. Individuals with higher autistic-like traits (i.e., lower social skills) took longer to process sentences with nontransparent meaning for making judgments. We argue that the computation of these sentences involves meaning contextualization—construing a coherent conceptual representation by integrating multiple lexical representations and evaluating sentential-discourse context. Such context-dependent meaning processing requires sufficient context sensitivity, which varies across individuals in association with social cognitive propensity. The pattern is captured by the Dual-Process Approach to information processing and social cognition: individuals with higher autistic-like traits are prone to deliberative reasoning with lower contextual sensitivity. This cognitive bias leads to greater cost when the full comprehension demands meaning contextualization, and therefore longer RTs in evaluating appropriate interpretations. The findings show that individual variability in social cognitive propensity modulates the online computation of nontransparent sentential meaning.}
}
@article{DOU2021103147,
title = {Enhancing higher-order eigenmodes of AFM using bridge/cantilever coupled system},
journal = {Micron},
volume = {150},
pages = {103147},
year = {2021},
issn = {0968-4328},
doi = {https://doi.org/10.1016/j.micron.2021.103147},
url = {https://www.sciencedirect.com/science/article/pii/S0968432821001384},
author = {Zhipeng Dou and Jianqiang Qian and Yingzi Li and Rui Lin and Tingwei Wang and Jianhai Wang and Peng Cheng and Zeyu Xu},
keywords = {Atomic force microscopy, Multi-frequency, Transfer function, Higher-order eigenmodes, Finite element simulation},
abstract = {The wide application of multi-frequency atomic force microscopy (AFM) places higher demands on the higher-order modes response of the cantilever. The response of the higher modes however is generally weaker than that of the fundamental mode in air. Researchers have proposed many methods, most of which involve cantilever modification, to enhance higher-order eigenmodes response. These previous results are proved to be effective, but the microfabrication is expensive. In this article, we propose a novel model based on bridge/cantilever coupled system to enhance the higher-order modes response of AFM cantilever. The segmented beam model provides a new thinking to explain the appearance of undesired peaks in mode analysis of cantilever. Through theoretical analysis and simulation, we find that higher resonance modes are enhanced by tuning the bridge to match the high resonances of the single clamped cantilever. The length, thickness of the coupled system and the location of excitation can affect the enhancement. In summary, this model provides a new way to improve higher mode response for multi-frequency and other high bandwidth applications of AFM.}
}
@article{SELVARAJ2022100471,
title = {Capture Based Trust Dependence framework for authorized node identification in mobile agent systems},
journal = {Measurement: Sensors},
volume = {24},
pages = {100471},
year = {2022},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100471},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422001052},
author = {Priyanka Selvaraj and Vijay Bhanu Srinivasan},
keywords = {Capture based, Dependence framework mobile agents, Network performance, Trust identification},
abstract = {A mobile agent is a self-learning machine entity that uses the system infrastructure to keep running in another remote zone, check and compile the results, interact with various locations and return to his home site after completing the relegated activities. Mobile Agent-based solutions for the testing community have grown in popularity and are now used in a variety of fields, including boardroom management, electronic commerce, renewable energy and power management. Addition to these applications, Broadband Interactive Sensors, network performance improvement, disseminated knowledge mining, multimedia, human monitoring, surveillance, affective computing, weather and environment, e-learning and semantic web administrations are only a few of the topics covered. In an extremely non trusty environment, focus should be taken to shield the portable operator from acquiring altered. Existing works on mobile agent frameworks with very surprising instruments does not offer complete security. In this paper a capture based trust dependence framework is proposed for identification of authorized or trust nodes inside mobile agents systems. Here we consider the mobile adhoc networks for computational analysis of network performance using network simulator. The framework provides efficient results in identification of authorized nodes.}
}
@article{FROWNFELTERLOHRKE201768,
title = {Teaching good Excel design and skills: A three spreadsheet assignment project},
journal = {Journal of Accounting Education},
volume = {39},
pages = {68-83},
year = {2017},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575115300403},
author = {Cynthia {Frownfelter- Lohrke}},
keywords = {Excel, Spreadsheets, Spreadsheet design, Active learning, Project-based learning},
abstract = {Over sixty percent of AIS courses cover Excel because it is an important tool for accounting students to learn and master. Although spreadsheet programs like Excel provide powerful analytical tools for business, in practice, they are often created and used by people with minimal programming experience. Consequently, users can often develop spreadsheets containing critical errors, which, in turn, can cause significant losses for their businesses. Errors can be reduced, however, by learning and employing good spreadsheet design techniques. Good spreadsheet design also makes it easier to update and continue to use a spreadsheet over time. This paper describes a method for teaching spreadsheet design where students complete three spreadsheet assignments in an iterative and repetitive process. By the time students have completed these assignments, they will have acquired good spreadsheet design skills and improved their basic Excel skills.}
}
@article{NAKAMURA20091639,
title = {A shift of mind – Introducing a concept creation model},
journal = {Information Sciences},
volume = {179},
number = {11},
pages = {1639-1646},
year = {2009},
note = {Including Special Issue on Chance Discovery},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508004933},
author = {Jun Nakamura and Yukio Ohsawa},
keywords = {Creativity, Concept, Ambiguity and constraint},
abstract = {The ability to construct concepts is indispensable to both individual and evolutionary development. Our model involves the use of ambiguous stimuli to facilitate decision-making by promoting analogical reasoning. Toward this end, we have developed Web-based exercises in word categorization for the purpose of engaging participants in analogical reasoning that contributes to the integration of words and leads to the construction of new concepts. 12 graduate students and 20 junior high school students were presented with ambiguous information for the purpose of comparison between the senior and the junior students. We hypothesized that the senior students tend to behave with more insight rather than junior students with less activation of thought process. Our results suggested that the presentation of the ambiguous stimuli were associated with unique thought processes, which are consistent with approaches to word categorization that reflect either the experience of insight or the operation of a trial and error strategy, depending on the junior or the senior students. We showed that the senior students tend to be more like insight into categorization design, while the junior as rather try and error behavior, in consideration of needed time and actions in analogical thinking.}
}
@article{KE2024111909,
title = {Improving the transferability of adversarial examples through neighborhood attribution},
journal = {Knowledge-Based Systems},
volume = {296},
pages = {111909},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111909},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124005434},
author = {Wuping Ke and Desheng Zheng and Xiaoyu Li and Yuanhang He and Tianyu Li and Fan Min},
keywords = {Adversarial examples, Computer vision, Neural networks, AI security},
abstract = {Adversarial examples, which add carefully planned perturbations to images, pose a serious threat to neural network applications. Transferable adversarial attacks, in which adversarial examples generated on the source model can successfully attack the target model, provide a realistic and undetectable method. Existing transfer-based attacks tend to improve the transferability of adversarial examples by destroying their intrinsic features. They destabilized features differentially by assessing their importance, thus rendering the model incapable of inference. However, the existing methods generate feature-importance assessments that are overly dependent on the source model, leading to inaccurate importance guidance and insufficient feature destruction. In this paper, we propose neighborhood expectancy attribution attacks (NEAA) that accurately guide the destruction of deep features, leading to highly transferable adversarial examples. First, we design a highly versatile attribution tool called neighborhood attribution to represent the importance of features that attribute highly similar results to various source models. Specifically, we discard the imputation of a single baseline and adopt the imputed expectation of a baseline within the neighborhood of the image. Subsequently, we generalize the neighborhood attribution to the middle layer of the model and simplify the computation by assuming linear independence. Finally, the attribution result guides the attack to destroy the intrinsic features of the image and obtain highly transferable adversarial examples. Numerous experiments demonstrate the effectiveness of the proposed method. Code is available at Github: https://github.com/KWPCCC/NEAA.}
}
@incollection{BERNARD20221,
title = {Chapter One - Understanding cerebellar function through network perspectives: A review of resting-state connectivity of the cerebellum},
editor = {Kara D. Federmeier},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {76},
pages = {1-49},
year = {2022},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2022.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079742122000019},
author = {Jessica A. Bernard},
keywords = {Cerebellum, Resting-state connectivity, Cognition, Internal models},
abstract = {The human cerebellum, though relatively small in total volume, makes up for it in its neuronal density and immense computational power. As we seek to understand complex higher order human behavior, it is critical to consider how this structure may contribute to these domains. While historically conceptualized as a motor structure, likely in large part due to the overt motor deficits often experienced by those with cerebellar damage, it is now known to play a critical role in cognition. In the last decade in particular there has been a great deal of growth in the literature in this regard (though these ideas have been percolating since the 1980s). The development of resting-state functional connectivity magnetic resonance imaging (fcMRI) also resulted in a boom of literature seeking to clarify cerebellar interactions with the cortex. In this chapter, cerebellar anatomy and function are reviewed, with a particular focus on how fcMRI has impacted our understanding of the human cerebellum and what this has meant for our accounts of cerebellar processing (that is, the underlying computations). This work has broadened our appreciation of the cerebellum's networks linked to higher order processing, and resulted in thought provoking findings with respect to the functional organization of the cerebellum that may in the future impact our understanding of how the “little brain” helps the cortex produce nuanced and complicated human behavior.}
}
@article{NAKHLE2024100411,
title = {Shrinking the giants: Paving the way for TinyAI},
journal = {Device},
volume = {2},
number = {8},
pages = {100411},
year = {2024},
issn = {2666-9986},
doi = {https://doi.org/10.1016/j.device.2024.100411},
url = {https://www.sciencedirect.com/science/article/pii/S2666998624002473},
author = {Farid Nakhle},
keywords = {accelerated models, compressed models, miniaturized intelligence, tiny artificial intelligence, tiny machine learning},
abstract = {Summary
In the current era of technological advancement, the quest for more efficient and accessible artificial intelligence (AI) is driving the investigation of the predictive potential of small architecture-based, compressed, and accelerated AI models (TinyAI) and the benefits of running those on small-scale digital edge computing devices. This perspective delves into the expanding world of TinyAI, envisioning a future in which powerful machine intelligence can be encapsulated within pocket-sized devices, and discusses the technological challenges and opportunities associated with it. In addition, some of the myriad applications and benefits that can arise from their deployment will be discussed.}
}
@article{TUPPURAINEN2024108835,
title = {Conceptual design of furfural extraction, oxidative upgrading and product recovery: COSMO-RS-based process-level solvent screening},
journal = {Computers & Chemical Engineering},
volume = {191},
pages = {108835},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108835},
url = {https://www.sciencedirect.com/science/article/pii/S0098135424002539},
author = {Ville Tuppurainen and Lorenz Fleitmann and Jani Kangas and Kai Leonhard and Juha Tanskanen},
keywords = {Furfural oxidation, Hydrogen peroxide, Conceptual process design, COSMO-RS predictive thermodynamics, Solvent screening},
abstract = {Liquid phase oxidation of furfural using hydrogen peroxide offers a promising route for bio-based C4 furanones and diacids; however, only dilute water-based process designs have been previously suggested that have limited techno-economic potential. In this study, a conceptual process design is presented, where aqueous furfural is extracted using an organic solvent, coupled with peroxide oxidation and product recovery in the presence of the solvent. To address the problem of solvent selection, the COSMO-RS-based solvent screening framework is applied, where quantum mechanics-based thermodynamics are utilized in pinch-based process models. About 2500 solvent candidates were identified as feasible. Focusing on a set of 400 solvent candidates revealed energy consumption values (Qreb,tot/ṁprod recov) between approximately 2 MWh/tonne and 33 MWh/tonne, signifying the potential of the solvent-based process in outperforming the reference aqueous process (49.4 MWh/tonne). The study provides potential solvent candidates and future directions to consider in more costly computational and experimental efforts.}
}
@article{FORTESCUE197967,
title = {Why the ‘language of thought’ is not a language: Some inconsistencies of the computational analogy of thought},
journal = {Journal of Pragmatics},
volume = {3},
number = {1},
pages = {67-80},
year = {1979},
issn = {0378-2166},
doi = {https://doi.org/10.1016/0378-2166(79)90006-7},
url = {https://www.sciencedirect.com/science/article/pii/0378216679900067},
author = {Michael Fortescue}
}
@article{MOHANAN2024100997,
title = {Integrating Ayurveda and modern mainstream medicine},
journal = {Journal of Ayurveda and Integrative Medicine},
volume = {15},
number = {5},
pages = {100997},
year = {2024},
issn = {0975-9476},
doi = {https://doi.org/10.1016/j.jaim.2024.100997},
url = {https://www.sciencedirect.com/science/article/pii/S0975947624001128},
author = {K.P. Mohanan},
abstract = {This article is an attempt to understand the challenge of integrating the education provided by BAMS programs and MBBS programs, in order to initiate the process of integrating research and practice in Ayurveda and Modern Mainstream Medicine. The specific issues discussed in the article are framed within the broader context of the challenge of integrating any two bodies of knowledge, theories, or knowledge systems in education and research.}
}
@incollection{AI2019853,
title = {Study on the formation of chemical wave patterns for the Belousov–Zhabotinsky reaction system},
editor = {Anton A. Kiss and Edwin Zondervan and Richard Lakerveld and Leyla Özkan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {46},
pages = {853-858},
year = {2019},
booktitle = {29th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818634-3.50143-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186343501430},
author = {Jiali Ai and Wei Sun and Chi Zhai},
keywords = {far-from thermodynamic equilibrium, instabilities, reaction-diffusion system, Hopf bifurcation},
abstract = {The Belousov–Zhabotinsky (BZ) reaction system is famous because it can generate self-organized patterns, also known as “chemical waves”. Pattern formation out of an initially homogeneous system is seemingly violating the 2nd-law of thermodynamics (order is produced out of disorder), while in fact, the BZ reaction is an open, far-from thermodynamic equilibrium system, where instability is the cause of morphogenesis and Hopf bifurcation of the reaction kinetics can generate self-oscillatory state trajectories. In this paper, the evolution of the BZ reaction in a two dimensional diffusion system is studied by the numerical computation methods, for the purpose of reconstructing the chemical wave patterns. The similarity of the chemical waves to many complex systems in biology, ecology and engineering makes current study potentially significant. With the study of the pattern formation, we hope provide some thoughts on complex system theory, thermodynamics of the self-oscillatory reaction system, and numerical computation methods on complex patterns, etc.}
}
@article{YANG201616,
title = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
journal = {Global Environmental Change},
volume = {37},
pages = {16-30},
year = {2016},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016300036},
author = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
keywords = {The Yarlung Tsangpo River, The Jamuna River, Water resources systems analysis, Transboundary water management, Ex post scenario analysis},
abstract = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower projects, upstream water diversions and possible climate changes introduce concerns among riparian countries about future water supply for energy and food production in the basin. This study presents a new hydro-economic water system model of the basin coupled with ex post scenario analysis under the “nexus thinking” concept to identify and illustrate where development paths are in conflict. Results indicate that the ability of future development to remain free of conflict hinges mostly on the amount of precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future temperature and the unknown amount of upstream water diversion combine to strongly influence future water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries unable to secure enough water to produce their desired energy and food. Future climate projected by General Circulation Models suggest a warmer and wetter climate condition in the region, which is associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The methodology presented here is expected to be generally useful for diagnosing the conditions that may cause water resources development goals to not be achieved due to either changes in climate or water use among competing users.}
}
@article{MASHAL201366,
title = {Enhanced left frontal involvement during novel metaphor comprehension in schizophrenia: Evidence from functional neuroimaging},
journal = {Brain and Language},
volume = {124},
number = {1},
pages = {66-74},
year = {2013},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2012.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X12002155},
author = {N. Mashal and T. Vishne and N. Laor and D. Titone},
keywords = {Schizophrenia, Novel metaphors, Lateralization, Language, fMRI},
abstract = {The neural basis involved in novel metaphor comprehension in schizophrenia is relatively unknown. Fourteen people with schizophrenia and fourteen controls were scanned while they silently read novel metaphors, conventional metaphors, literal expressions, and meaningless word-pairs. People with schizophrenia showed reduced comprehension of both novel and conventional metaphors. Furthermore, while controls showed enhanced brain activation in right inferior frontal gyrus (IFG) for novel metaphors versus meaningless word-pairs, people with schizophrenia showed an over-activation of left IFG and middle frontal gyrus (MFG). Direct comparison between the groups revealed greater activation in left precuneus for both novel metaphors and literal expressions vs. baseline for individuals with schizophrenia. Direct comparison for novel metaphors vs. literal expressions also revealed increased activation for individuals with schizophrenia in left MFG. These results suggest that the inefficient processing of novel metaphors in schizophrenia involves compensatory recruitment of additional brain regions that include the left MFG and left precuneus.}
}
@article{KECECI2021100386,
title = {A mixed integer programming formulation for Smashed Sums puzzle: Generating and solving problem instances},
journal = {Entertainment Computing},
volume = {36},
pages = {100386},
year = {2021},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2020.100386},
url = {https://www.sciencedirect.com/science/article/pii/S187595212030094X},
author = {Barış Keçeci},
keywords = {Smashed Sums, Sudoku, Mathematical formulation},
abstract = {Playing mind games and puzzles has 2500 years of known history. Puzzles and games constitute a research domain that is attracting the interest of scientists from numerous disciplines such as artificial and computational intelligence, neural networks etc. All types of puzzles and games contain their own logic and mathematics. Able to know the science behind them and modelling the logic that a person uses to solve them would shed light to some decisional concepts. This is particularly true from the perspective of computational intelligence. In this paper a logic-based puzzle game called Smashed Sums is considered. The binary integer linear programming formulation is proposed to use in solving and generating the puzzles. Illustrative examples are given to show the validity of the formulation. Some experimental computations are conducted to analyze the puzzle and its complexity. And several open problems are concluded for the further researches.}
}
@article{LEVENSPIEL20024691,
title = {Modeling in chemical engineering},
journal = {Chemical Engineering Science},
volume = {57},
number = {22},
pages = {4691-4696},
year = {2002},
note = {Festschrift in Honour of Dr Winn van Swaaij},
issn = {0009-2509},
doi = {https://doi.org/10.1016/S0009-2509(02)00280-4},
url = {https://www.sciencedirect.com/science/article/pii/S0009250902002804},
author = {Octave Levenspiel},
abstract = {In its 90 year life what has chemical engineering (ChE) contributed to society? Firstly, we have invented and developed processes to create new materials, more gently and more efficiently, so as to make life easier for all. Secondly, ChE has changed our accepted concepts and our ways of thinking in science and technology. Here modeling stands out as the primary development. Let us consider this.}
}
@article{GUO202377,
title = {Notes on the improvement of concept-cognitive learning accuracy},
journal = {International Journal of Approximate Reasoning},
volume = {156},
pages = {77-96},
year = {2023},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2023.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X23000294},
author = {Keyi Guo and Jinhai Li and Xiao Zhang},
keywords = {Granular computing, Rough set, Concept lattice, Concept-cognitive learning, Learning accuracy},
abstract = {The concept-cognitive learning (CCL) process is the specific implementation step of simulating the human brain to learn concepts, and the CCL model is its core carrier. Different CCL models constructed by different cognitive minds will produce different concept learning results. The existing CCL model based on sufficient and necessary granule approximations regards the human's approximation idea in the face of inconsistent information as a logical criterion, and aims at finding the closest concept pair of the clue as concept learning results with a certain learning accuracy. However, the existing CCL method based on sufficient and necessary granule approximations cannot guarantee that the clue must be between its lower approximation and upper approximation, which causes the fact that the learning accuracy may not effectively measure the consistency of concept learning results. What is more, although the computational process obeys logical cognitive condition, the concept learning results may not conform to the actual situation, such as the case of merely generating full concepts and empty concepts. For the first problem, we improve the learning accuracy of the existing CCL method, propose a new CCL method with learning accuracy under hybrid lattice structure, and develop CCL algorithms for the cases of objects and attributes as clues. Moreover, experiments show the effectiveness of the proposed CCL method with learning accuracy under hybrid lattice structure. For the second problem, we put forward a CCL method based on non-logical associative mechanism to handle the unreasonable situation where the concept learning results are full concepts and empty concepts. Finally, two associative CCL algorithms are explored, and experiments are conducted to show their effectiveness.}
}
@incollection{ILLES2015735,
title = {Chapter 45 - Advances in Ethics for the Neuroscience Agenda},
editor = {Michael J. Zigmond and Lewis P. Rowland and Joseph T. Coyle},
booktitle = {Neurobiology of Brain Disorders},
publisher = {Academic Press},
address = {San Diego},
pages = {735-747},
year = {2015},
isbn = {978-0-12-398270-4},
doi = {https://doi.org/10.1016/B978-0-12-398270-4.00045-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123982704000458},
author = {Judy Illes and Peter B. Reiner},
keywords = {animal model, biomedical science, data sharing, ethics, health, incidental finding, neuroscience, public policy, science communication},
abstract = {Critical thinking about ethics in neuroscience can be a powerful force in enabling research and translating results meaningfully for society. This chapter provides four examples of such an empowered approach to neuroscience. The authors discuss how upfront consideration of the societal implications of advances in neuroscience can shape the use of animal models. They situate ethical thinking in this era of big science and big data, reflecting on strategies for sharing databases while protecting contributors and users. They highlight how collaboration among neuroscientists, ethicists, and others can produce positive measures to resolve the problem of incidental discoveries in brain imaging research, as one example of debates on incidental findings more broadly. The mandate of neuroscience research as public service and ethical imperative is addressed by describing opportunities for neuroscientists to engage with societal issues emerging from their research, and how this deepens the discourse and adds value to the research enterprise.}
}
@article{OH2015e6,
title = {The effects of simulation-based learning using standardized patients in nursing students: A meta-analysis},
journal = {Nurse Education Today},
volume = {35},
number = {5},
pages = {e6-e15},
year = {2015},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2015.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0260691715000507},
author = {Pok-Ja Oh and Kyeong Deok Jeon and Myung Suk Koh},
keywords = {Students, Nursing, Patient simulation, Meta-analysis},
abstract = {Summary
Purpose
The aim of this study was to evaluate the effect of simulation-based learning using standardized patients (SPs) on cognitive, affective, and psychomotor domain outcomes of learning in nursing students.
Methods
MEDLINE via PubMed, Cochrane Library CENTRAL, EMBASE, CINAHL, and several Korean electronic databases (to June 2014) were searched. The RevMan 5.3 program of the Cochrane library was used for data analysis.
Results
A meta-analysis was conducted of 18 controlled trials (4 randomized and 14 non-randomized designs), with a total of 1326 nursing students. Overall, simulation-based learning using SPs appeared to have beneficial effects on the cognitive, affective, and psychomotor domains of learning. In subgroup analysis, use of SPs showed significant effects on knowledge acquisition (d=0.38, p=.05, I2=42%), communication skill (d=1.86, p<.001, I2=15%), self-efficacy (d=0.61, p<.001, I2=6%), learning motivation (d=0.77, p<.001, I2=0%) and clinical competence (d=0.72, p<.001, I2=0%). Treatment effects on critical thinking (p=.75) and learning satisfaction (p=.43) were not significant.
Conclusion
The findings of the current study suggest that simulation-based learning using SPs might have a positive impact on self efficacy and learning motivation that affects knowledge and clinical skill acquisition. Therefore, these findings demonstrate that, if integrated appropriately, an SP educational approach can be used in academic settings as an active learning methodology.}
}
@article{MAKINDE2020368,
title = {An approach to estimate the back order penalty cost of a manufacturing company},
journal = {Procedia Manufacturing},
volume = {43},
pages = {368-374},
year = {2020},
note = {Sustainable Manufacturing - Hand in Hand to Sustainability on Globe: Proceedings of the 17th Global Conference on Sustainable Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.02.175},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920307551},
author = {Olasumbo Makinde and Thomas Munyai},
keywords = {Backorder cost, Economic Order Quantity, Customer disappointment index, Inventory Models},
abstract = {The classical inventory models solely rely on accurate estimate of the back order cost, with a view to establish economic order quantity (EOQ) that must be placed by a customer. Recognizing and quantifying the adverse effects of loss of customer goodwill owing to the inability of a raw material or product supplier organisation to meet customer demands should not only focus on direct penalty cost computation, but should also incorporate change in customers’ future demand owing to this backordering phenomenon. A lot of classical and mathematical approaches focused on the computation of the back order penalty cost coefficient; which gives an organisation a clue of the customer disappointment index, and not the estimated back order cost required for EOQ computation. In light of this, this paper proposes an approach that could be utilized to accurately compute the back order penalty cost of an organisation. The approach considers: (i) the number of times backordering phenomenon have occurred in an organisation, (ii) the decision a customer takes when backordering occur once or couple of times during the ordering phases of an organisation and (iii) myriads of penalties that a customer bestow on a raw material or product supplier organisation for backordering its order, to establish the backorder cost of this organisation. The approach proposed in this study serve as a useful information to suppliers in ascertaining the raw material backorder cost based on their customer responses to backordering, with a view to ensure sustainable raw material supply.}
}
@article{GONZALEZ2024446,
title = {BOIS: Bayesian Optimization of Interconnected Systems},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {14},
pages = {446-451},
year = {2024},
note = {12th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.377},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324011364},
author = {Leonardo D. González and Victor M. Zavala},
keywords = {Bayesian optimization, grey-box modeling, composite functions},
abstract = {Bayesian optimization (BO) has proven to be an effective paradigm for the global optimization of expensive-to-sample systems. One of the main advantages of BO is its use of Gaussian processes (GPs) to characterize model uncertainty which can be leveraged to guide the learning and search processes. However, BO typically treats systems as black-boxes and this limits the ability to exploit structural knowledge (e.g., physics and sparse interconnections). Composite functions of the form f(x,y(x)), wherein GP modeling is shifted from the performance function f to an intermediate function y, offer an avenue for exploiting structural knowledge. However, the use of composite functions in a BO framework is complicated by the need to generate a probability density for f from the Gaussian density of y calculated by the GP (e.g., when f is nonlinear it is not possible to obtain a closed-form expression). Previous work has handled this issue using sampling techniques; these are easy to implement and flexible but are computationally intensive. In this work, we introduce a new paradigm which allows for the efficient use of composite functions in BO; this uses adaptive linearizations of f to obtain closed-form expressions for the statistical moments of the composite function. We show that this simple approach (which we call BOIS) enables the exploitation of structural knowledge, such as that arising in interconnected systems as well as systems that embed multiple GP models and combinations of physics and GP models. Using a chemical process optimization case study, we benchmark the effectiveness of BOIS against standard BO and sampling approaches. Our results indicate that BOIS achieves performance gains and accurately captures the statistics of composite functions.}
}
@article{BECK2017110,
title = {Can bootstrapping explain concept learning?},
journal = {Cognition},
volume = {158},
pages = {110-121},
year = {2017},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2016.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0010027716302578},
author = {Jacob Beck},
keywords = {Bootstrapping, Concept learning, Susan Carey, Concepts, Computational constraints},
abstract = {Susan Carey’s account of Quinean bootstrapping has been heavily criticized. While it purports to explain how important new concepts are learned, many commentators complain that it is unclear just what bootstrapping is supposed to be or how it is supposed to work. Others allege that bootstrapping falls prey to the circularity challenge: it cannot explain how new concepts are learned without presupposing that learners already have those very concepts. Drawing on discussions of concept learning from the philosophical literature, this article develops a detailed interpretation of bootstrapping that can answer the circularity challenge. The key to this interpretation is the recognition of computational constraints, both internal and external to the mind, which can endow empty symbols with new conceptual roles and thus new contents.}
}
@article{SANDERS2023107790,
title = {Methodological innovations to strengthen evidence-based serious illness communication},
journal = {Patient Education and Counseling},
volume = {114},
pages = {107790},
year = {2023},
issn = {0738-3991},
doi = {https://doi.org/10.1016/j.pec.2023.107790},
url = {https://www.sciencedirect.com/science/article/pii/S0738399123001702},
author = {Justin J. Sanders and Danielle Blanch-Hartigan and Jonathan Ericson and Elise Tarbi and Donna Rizzo and Robert Gramling and Liesbeth {van Vliet}},
keywords = {Communication, Palliative care, Methodology},
abstract = {Background/Objective
A growing population of those affected by serious illness, prognostic uncertainty, patient diversity, and healthcare digitalization pose challenges for the future of serious illness communication. Yet, there is paucity of evidence to support serious illness communication behaviors among clinicians. Herein, we propose three methodological innovations to advance the basic science of serious illness communication.
Results
First, advanced computation techniques – e.g. machine-learning techniques and natural language processing – offer the possibility to measure the characteristics and complex patterns of audible serious illness communication in large datasets. Second, immersive technologies – e.g., virtual- and augmented reality – allow for experimentally manipulating and testing the effects of specific communication strategies, and interactional and environmental aspects of serious illness communication. Third, digital-health technologies – e.g., shared notes and videoconferences – can be used to unobtrusively observe and manipulate communication, and compare in-person to digitally-mediated communication elements and effects. Immersive and digital health technologies allow integration of physiological measurement (e.g. synchrony or gaze) that may advance our understanding of patient experience.
Conclusion/practice implications
New technologies and measurement approaches, while imperfect, will help advance our understanding of the epidemiology and quality of serious illness communication in an evolving healthcare environment.}
}
@article{ENE20141110,
title = {Open Loop Reverse Supply Chain Network Design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {109},
pages = {1110-1115},
year = {2014},
note = {2nd World Conference on Business, Economics and Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.12.596},
url = {https://www.sciencedirect.com/science/article/pii/S187704281305235X},
author = {Seval Ene and Nursel Öztürk},
keywords = {Supply chain management, open loop system, product recovery, network design, mathematical programming},
abstract = {Reverse supply chain management is a significant issue for sustainable economy, product recovery and green thinking. The purpose of this study is to contribute product recovery management by designing open loop reverse supply chain network. The main difference between open loop and closed loop reverse supply chain is in returning of used products. In a closed loop reverse supply chain, used products are generally returned to original producers. But in an open loop reverse supply chain, used products are not returned to original producers, outsider firms recover them. This paper presents a mathematical model for multi stage and multi period reverse supply chain network, which maximizes total profit of the network. The proposed model determines facility locations and material flows between stages in each period. Numerical experiments showed the applicability and efficiency of the model.}
}
@article{KOWALCZUK2020103562,
title = {Interpretation and modeling of emotions in the management of autonomous robots using a control paradigm based on a scheduling variable},
journal = {Engineering Applications of Artificial Intelligence},
volume = {91},
pages = {103562},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103562},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620300518},
author = {Zdzisław Kowalczuk and Michał Czubenko and Tomasz Merta},
keywords = {Emotions, Decision-making systems, Cognitive modeling, Human mind, Computational models, Fuzzy approach, Intelligent systems, Autonomous agents},
abstract = {The paper presents a technical introduction to psychological theories of emotions. It highlights a usable idea implemented in a number of recently developed computational systems of emotions, and the hypothesis that emotion can play the role of a scheduling variable in controlling autonomous robots. In the main part of this study, we outline our own computational system of emotion – xEmotion – designed as a key structural element in the developed target device, being an Intelligent System of Decision-making (ISD) for autonomous and robotic units. The ISD system has a cognitive architecture based on the principles of human psychology. The main purpose of building such a system is to prepare a framework for autonomous units used in system engineering (Kowalczuk and Czubenko, 2011; Czubenko et al., 2015). In particular, ISD is based on the concepts of cognitive psychology (in information processing) and motivation theory, which includes the system of needs (for decision-making). The xEmotion subsystem, however, focuses on modeling an alternative approach based on emotion. The xEmotion implementation covers aspects of somatic, appraisal and evolutionary theories of emotions using fuzzy sets. In this article, we also illustrate the core emotional behavior of the ISD system using simulation. The first application is a user interface for identifying emotions and predicting human behavior. The second is an eSailor simulation, which illustrates the possible behavior of the xEmotion subsystem. The last is an xDriver simulation experiment, which is to prove the validity of the concept of using emotion-based systems, according to the SVC principle. In summary, we also discuss other possible applications of the xEmotion system.}
}
@article{LI20232,
title = {Adult acquired flatfoot deformity: an update in classification},
journal = {Orthopaedics and Trauma},
volume = {37},
number = {1},
pages = {2-10},
year = {2023},
issn = {1877-1327},
doi = {https://doi.org/10.1016/j.mporth.2022.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S187713272200121X},
author = {James Li and Chandra Pasapula and Vivekanandan Dhukaram},
keywords = {AAFD, adult acquired flatfoot deformity, classification, flatfoot},
abstract = {Adult acquired flatfoot deformity (AAFD) involves a complex spectrum of pathologies, arising primarily from failure of static restrains, leading to collapse of the medial longitudinal arch and further subsequent deformities in the foot. The landmark paper and classification by Johnson et al. proposed that pathology in the posterior tibial tendon (PTT) was key in the development of AAFD. Since then, the understanding of AAFD has evolved and advanced. Multiple structures aside from the PTT, such as the spring ligament, plantar fascia and deltoid ligament, have been identified to play a similarly key role in disease development and progression. Classification systems have also evolved to incorporate this new understanding. These include modifications to Johnson's classification (Myerson, Bluman) as well as new systems which aim to incorporate modern thinking, capture the wide spectrum of presentations or utilize modern advancements in imaging modalities. Current classification systems continue to aid understanding and management of AAFD, despite their increasing complexity. Future classifications should aim to provide a succinct way to describe and understand AAFD, as well as guiding prognosis and management.}
}
@incollection{VOIRONCANICIO202185,
title = {Chapter 4 - Methods and tools in geoprospective},
editor = {Emmanuel Garbolino and Christine Voiron-Canicio},
booktitle = {Ecosystem and Territorial Resilience},
publisher = {Elsevier},
pages = {85-122},
year = {2021},
isbn = {978-0-12-818215-4},
doi = {https://doi.org/10.1016/B978-0-12-818215-4.00004-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128182154000043},
author = {Christine Voiron-Canicio and Emmanuel Garbolino and Giovanni Fusco and Jean-Christophe Loubier},
keywords = {Geoprospective approach, simulations, modeling, uncertainty, land change, decision-making tool, uncertain causal model, geovizualization, graphic modeling, 3D simulation},
abstract = {This chapter illustrates the diversity of methods and tools available for developing a geoprospective approach, and, through them, the variety of ways to introduce the spatial dimension in scenarios, simulations, and collective thinking. A number of methods, such as modeling, are not specific to geoprospective. The perspective adopted is to shine the light on what their use in geoprospective entails: the specific constraints and the new questions raised relating to the weight of past evolutions, to the unforeseen, to uncertainty. In addition to the models of the land use and cover change (LUCC) type and companion modeling, this chapter gives much importance to the following new approaches which are hitherto hardly used in geoprospective: scenarios integrating various territorial scales, modeling of the decision-making process coupled with prospective spatial modeling, geoprospective based on causal probabilistic models, graphic modeling, prospective choremes, immersive and 3D simulation in landscapes of the future.}
}
@article{CRISTOFARO2020344,
title = {“I feel and think, therefore I am”: An Affect-Cognitive Theory of management decisions},
journal = {European Management Journal},
volume = {38},
number = {2},
pages = {344-355},
year = {2020},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263237319301094},
author = {Matteo Cristofaro},
keywords = {Sensemaking, Decision making, Socially situated cognition, Affect, Cognition, Rationality, Behavioral strategy},
abstract = {I propose an Affect-Cognitive Theory to comprehensively understand how decisions occur in organizations. To this aim, I first review the assumptions of sensemaking and decision-making streams of research, especially the influence of bounded rationality, affective states and their relationships with cognition; then, I integrate them on the common basis of socially situated cognition. This new theory emphasizes the role of affective states in determining/being determined by cognition and its errors, pointing out decision makers’ affect as the result of multi-level adaptations to the physical and social environment. Management decisions are path dependent but not immutable; they, indeed, bank on the predominant feeling resulting from the modifying interactions and regulations of decision makers with their physical and social environment. Here, decision makers are proposed as “emotional cognizers” overcoming the thinking-feeling dichotomy that has often featured in the study of management decisions. This theory is beneficial for behavioral strategy, offering the needed assumptions to intertwine human cognition, emotions, and social behavior.}
}
@article{CHANG2023109277,
title = {Location and timestamp-based chip contour detection using LWMG-YOLOv5},
journal = {Computers & Industrial Engineering},
volume = {180},
pages = {109277},
year = {2023},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2023.109277},
url = {https://www.sciencedirect.com/science/article/pii/S0360835223003017},
author = {Bao Rong Chang and Hsiu-Fen Tsai and Chia-Wei Hsieh},
keywords = {Chip contour detection, Real-time image recognition, LWMG-YOLOv5 model, Ghost convolution, Attention mechanism, and Minimizing production costs},
abstract = {In the fab, semiconductor manufacturers often use deep learning approaches for chip contour detection to shorten automated optical inspection to minimize the loss of production costs and lower power consumption in chip contour detection for realizing energy-efficient computing. However, YOLOv5 and GSEH-YOLOv5 models have sacrificed their accuracy to improve the operational speed. MobileNetv3-YOLOv5 model can enhance the accuracy but lacks high-speed operation. Therefore, this study presents a light version of MobileNetv3-YOLOv5 model with ghost convolution, abbreviated LWMG-YOLOv5, to speed up chip contour detection because this architecture can reduce the number of model parameters and computational burden at the same time. As a result, the proposed approach can outperform the other methods by getting a 3.62% speed-up in chip contour detection to gain a better manufacturing advantage in increasing the chip yields by 1.7% and reducing the loss of production costs by 1.83% significantly.}
}
@article{CHRISTAKOU2014302,
title = {Present simple and continuous: Emergence of self-regulation and contextual sophistication in adolescent decision-making},
journal = {Neuropsychologia},
volume = {65},
pages = {302-312},
year = {2014},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0028393214003133},
author = {Anastasia Christakou},
keywords = {Decision-making, Adolescence, Self-regulation, Corticostriatal circuits},
abstract = {Sophisticated, intentional decision-making is a hallmark of mature, self-aware behaviour. Although neural, psychological, interpersonal, and socioeconomic elements that contribute to such adaptive, foresighted behaviour mature and/or change throughout the life-span, here we concentrate on relevant maturational processes that take place during adolescence, a period of disproportionate developmental opportunity and risk. A brief, eclectic overview is presented of recent evidence, new challenges, and current thinking on the fundamental mechanisms that mature throughout adolescence to support adaptive, self-controlled decision-making. This is followed by a proposal for the putative contribution of frontostriatal mechanisms to the moment-to-moment assembly of evaluative heuristics that mediate increased decision-making sophistication, promoting the maturation of self-regulated behaviour through adolescence and young adulthood.}
}
@article{CHEN2021107754,
title = {2D multi-area coverage path planning using L-SHADE in simulated ocean survey},
journal = {Applied Soft Computing},
volume = {112},
pages = {107754},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107754},
url = {https://www.sciencedirect.com/science/article/pii/S156849462100675X},
author = {Guanzhong Chen and Yue Shen and Yixiao Zhang and Wenfeng Zhang and Dianrui Wang and Bo He},
keywords = {L-SHADE, Multi-area, Coverage path planning, Sub-area path planning, Mutation process},
abstract = {Ocean environmental surveys typically involve multi-area coverage path planning tasks. The most important problem is improving the coverage efficiency of the task. A new path planning method based on Successful History-Based Adaptive Differential Evolution variants with Linear population size reduction(L-SHADE) is presented to solve this problem. The method comprises two parts: the part of sub area coverage path planning and the part of finding the optimized sequence of sub area start points. The key idea is establishing the relationship between the starting point of each sub area and the optimized multi-area path. We implement the method through numbering the possible starting point of sub area path and proposing a computing formula. In addition, the results of L-SHADE mutation process are optimized which make L-SHADE possible to apply in multi-area coverage path planning. This method avoids area discretization and exponential growth of computational quantities, and it is suitable for complex areas as well as multi-area. The simulation results with MATLAB showed the improvement of coverage path planning task execution efficiency. Compared with the method thinking of the sub area as the center of it, our method reduced the multi-area coverage path length by 4%–7%. From the simulations and analysis, we concluded that the method is able to improve the efficiency and stability of multi-area coverage path planning.}
}
@article{TSAI2017997,
title = {An empirical study on the incorporation of APP and progressive reasoning teaching materials for improving technical creativity amongst students in the subject of automatic control},
journal = {Computers in Human Behavior},
volume = {75},
pages = {997-1007},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216307117},
author = {Hsieh–Chih Tsai and Min Jou and JingYing Wang and Chun-Chiang Huang},
keywords = {APP, Progressive reasoning, Technical creativity, Scientific reasoning},
abstract = {This study reformed teaching materials for automatic control, a mandatory course for engineering students, and designed a set of digital teaching materials based upon progressive reasoning with hand-mind combinations. The teaching materials were mainly delivered via a hands-on APP. The authors conducted an empirical study as well as pre-tests and post-tests for a total of 118 sophomore students majoring in engineering at two Universities. Outcomes found that the progressive reasoning teaching materials designed for this course were helpful in improving student creativity and scientific reasoning. Significant improvements were also achieved in product design, technical methods, and technological ideas aspects of technological creativity and every scientific reasoning skill, with the exception of proportional reasoning. Results also identified strong correlation between technical creativity and scientific reasoning. This relationship may be further investigated in follow-up studies. This study also proposed recommendations for coordinating designs of digital teaching materials in other engineering courses with the development of student thinking.}
}
@article{NEUDERT2024100092,
journal = {Journal of Responsible Technology},
volume = {20},
pages = {100092},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000180},
author = {Philipp Neudert and Mareike Smolka and Britta Acksel and Yana Boeva}
}
@article{BROER2022115131,
title = {The Googlization of Health: Invasiveness and corporate responsibility in media discourses on Facebook's algorithmic programme for suicide prevention},
journal = {Social Science & Medicine},
volume = {306},
pages = {115131},
year = {2022},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2022.115131},
url = {https://www.sciencedirect.com/science/article/pii/S0277953622004373},
author = {Tineke Broer},
keywords = {Suicide prevention, Facebook, Content moderation, Privacy, Googlization of health},
abstract = {Big tech companies increasingly play a role in the domain of health. Also called the “Googlization of Health”, this phenomenon is often studied by drawing on the notion of ‘hostile worlds’, where market values and common goods are incommensurable. Yet, the ‘hostile worlds’ theory is not uncontested; scholars for instance argue that the justifications of big tech companies are important analytical considerations as well. Building on this literature, in this paper I report on a case study of Facebook employing AI for suicide prevention, moving beyond Facebook's justifications only to study the ways in which media commentators and their audiences discussed Facebook's programme and the values they saw as being at stake. In the results, I show how invasiveness was, in different ways and forms, a main theme in thinking about Facebook using AI to do suicide prevention. Commentators and readers alike discussed how: 1) Facebook takes corporate responsibility with this initiative, or alternatively Facebook only has commercial interests and uses the notion of ‘public good’ to transgress spheres and sectors even further, thus being invasive; 2) Facebook's AI suicide prevention programme is invasive in relation to privacy and privacy laws, or, instead, people give up their privacy willingly in exchange for entertainment; 3) The programme undermines, rather than enhances, safety; 4) Suicide prevention in itself is already invasive. These different forms of invasiveness, I argue in the conclusion, also imply responsibility for different actors, from AI itself to Facebook through to medical professionals. Moreover, they show what values are at stake in, and transformed through, Facebook's AI suicide prevention programme, going beyond the frames of privacy and surveillance capitalism.}
}
@article{AYERS201861,
title = {A first step toward a practice-based theory of pedagogical content knowledge in secondary economics},
journal = {The Journal of Social Studies Research},
volume = {42},
number = {1},
pages = {61-79},
year = {2018},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X17300177},
author = {Cheryl A. Ayers},
keywords = {Secondary economic education, Pedagogical content knowledge, Horizon content knowledge, Specialized content knowledge, Knowledge of content and teaching, Knowledge of content and students},
abstract = {The purpose of this qualitative case study was to gain an in-depth understanding of how three award-winning secondary economics teachers demonstrated their pedagogical content knowledge (PCK), specifically horizon content knowledge, specialized content knowledge, knowledge of content and teaching, and knowledge of content and students. The teachers consistently connected economic content to other grades, subjects, and economic concepts and skills. Economic content was also regularly used to prepare students for citizenship, including casting more informed votes and understanding current events. However, authentic discussions, including ones about controversial issues, were mostly lacking. An emphasis was placed on developing students’ economic reasoning skills, including real-world applications of the economic way of thinking and decision-making models. Additionally, active learning instructional practices were frequently incorporated, and economic content was almost always related to students’ interests and experiences. A detailed description of a first step toward a practice-based theory of PCK in secondary economics concludes the article.}
}
@incollection{COBB200685,
title = {Constructivism},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {85-87},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/01593-5},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542015935},
author = {T. Cobb},
keywords = {constructivism, constructivist, educational reform, language technologies, learner-as-linguist, objectivism, second language acquisition},
abstract = {Constructivism, the notion that knowledge must be assembled from pieces rather than assimilated whole, has been a principal learning theory in psychology for about 20 years and in psycholinguistics for 10. The theory is now making a strong entry into educational thinking, but in language education it is less in evidence. That is because applied linguists have always been constructivists, implicitly, and have already confronted some of the implementation problems facing constructivism in mathematics or science education. Nevertheless, a more explicit understanding of the constructivist approach is useful within language education, particularly in providing a framework for exploiting information technologies.}
}
@article{ZHAO2021270,
title = {Learnable Heterogeneous Convolution: Learning both topology and strength},
journal = {Neural Networks},
volume = {141},
pages = {270-280},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S089360802100126X},
author = {Rongzhen Zhao and Zhenzhi Wu and Qikun Zhang},
keywords = {Convolution neural network, Efficiency & performance, Learning topology & strength, Fine-grained but structural, Hardware acceleration},
abstract = {Existing convolution techniques in artificial neural networks suffer from huge computation complexity, while the biological neural network works in a much more powerful yet efficient way. Inspired by the biological plasticity of dendritic topology and synaptic strength, our method, Learnable Heterogeneous Convolution, realizes joint learning of kernel shape and weights, which unifies existing handcrafted convolution techniques in a data-driven way. A model based on our method can converge with structural sparse weights and then be accelerated by devices of high parallelism. In the experiments, our method either reduces VGG16/19 and ResNet34/50 computation by nearly 5× on CIFAR10 and 2× on ImageNet without harming the performance, where the weights are compressed by 10× and 4× respectively; or improves the accuracy by up to 1.0% on CIFAR10 and 0.5% on ImageNet with slightly higher efficiency. The code will be available on www.github.com/Genera1Z/LearnableHeterogeneousConvolution.}
}
@article{GU2024110161,
title = {A Bayesian decision network–based pre-disaster mitigation model for earthquake-induced cascading events to balance costs and benefits on a limited budget},
journal = {Computers & Industrial Engineering},
volume = {191},
pages = {110161},
year = {2024},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2024.110161},
url = {https://www.sciencedirect.com/science/article/pii/S0360835224002821},
author = {Wenjing Gu and Jiangnan Qiu and Jilei Hu and Xiaowei Tang},
keywords = {Earthquake-induced cascading disasters, Pre-disaster mitigation, Bayesian decision network, Cost–benefit analyses, Limited budgets},
abstract = {Cascading disasters induced by earthquakes amplify the severity of the initial impact on environment. Although decisionmakers may face uncertainty, an effective mitigation strategy is critical in environmental management. We propose an earthquake-induced cascading disaster mitigation–Bayesian decision network (ECDM-BDN) model to assess pre-disaster mitigating strategies under limited budgets from the perspective of systematic thinking. This model graphically represents the complex relationship among various variables in a seismic hazard system and resistance system based on disaster system theory. It can predict the triggering of cascading events through probabilistic reasoning and identify the key variable accountable for the range of outputs observed through sensitivity analysis. In addition, cost–benefit analyses are carried out by combining Bayesian decision network utility nodes and dynamic programming to obtain a balance between costs and benefits in the context of limited budgets. An earthquake-induced liquefaction served as a case study to demonstrate the proposed model’s effectiveness. Experimental results indicate that the ECDM-BDN model can balance the costs and effects of each pre-disaster mitigating strategy as well as select the optimal one according to the utility value. The proposed model can perform a “white-box” decision-making process, which is expected to guide earthquake-induced cascading event pre-disaster mitigation in cases of limited budgets.}
}
@article{DRANKO2021738,
title = {Structural Analysis of Large-Scale Socio-Technical Systems Based on the Concept of Influence},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {738-743},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.540},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321019789},
author = {O.I. Dranko and Yu.G. Rykov and A.A. Karandeev},
keywords = {Complex systems, Cognitive maps, Influence, Structural analysis, Russian Federation economics structure},
abstract = {The paper is devoted to studying the stability of complex systems, which include diversified and heterogeneous elements. In order to analyze the stability of such systems, it is proposed to develop the process of dynamic determination of the main factors. For this purpose, this paper uses a variant of cognitive modeling based on the concept of “influence”. The proposed approach implies, in a sense, a broader view of the concept of the “fuzzy cognitive map” introduced by B. Kosko. “Influence” does not mean “causality”, allows a broader interpretation range, and is calculated in a special way that makes it possible to prove rigorous theorems. A complex system is represented as a digraph, and the selection of the main factors is proposed to be based on the concept of “influence”, which is introduced as follows. All nodes of the graph are assigned an abstract property “significance”, which allows you to compare heterogeneous factors, and a particular computational procedure is introduced that allows this “significance” to be calculated. The “influence” of factors on each other is defined as a mathematically formalized response in accordance with the introduced computational procedure of the “significance” of the studied factor to the variation in the “significance” of input factors. For example, the analysis of the sustainability of a large-scale model of the Russian economy in terms of the strength of the “influence” is provided.}
}
@article{BROOKS2013947,
title = {The Primate Cerebellum Selectively Encodes Unexpected Self-Motion},
journal = {Current Biology},
volume = {23},
number = {11},
pages = {947-955},
year = {2013},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2013.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0960982213004375},
author = {Jessica X. Brooks and Kathleen E. Cullen},
abstract = {Summary
Background
The ability to distinguish sensory signals that register unexpected events (exafference) from those generated by voluntary actions (reafference) during self-motion is essential for accurate perception and behavior. The cerebellum is most commonly considered in relation to its contributions to the fine tuning of motor commands and sensorimotor calibration required for motor learning. During unexpected motion, however, the sensory prediction errors that drive motor learning potentially provide a neural basis for the computation underlying the distinction between reafference and exafference.
Results
Recording from monkeys during voluntary and applied self-motion, we demonstrate that individual cerebellar output neurons encode an explicit and selective representation of unexpected self-motion by means of an elegant computation that cancels the reafferent sensory effects of self-generated movements. During voluntary self-motion, the sensory responses of neurons that robustly encode unexpected movement are canceled. Neurons with vestibular and proprioceptive responses to applied head and body movements are unresponsive when the same motion is self-generated. When sensory reafference and exafference are experienced simultaneously, individual neurons provide a precise estimate of the detailed time course of exafference.
Conclusions
These results provide an explicit solution to the longstanding problem of understanding mechanisms by which the brain anticipates the sensory consequences of our voluntary actions. Specifically, by revealing a striking computation of a sensory prediction error signal that effectively distinguishes between the sensory consequences of self-generated and externally produced actions, our findings overturn the conventional thinking that the sensory errors coded by the cerebellum principally contribute to the fine tuning of motor activity required for motor learning.}
}
@article{WIERZBICKI2007610,
title = {Modelling as a way of organising knowledge},
journal = {European Journal of Operational Research},
volume = {176},
number = {1},
pages = {610-635},
year = {2007},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2005.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0377221705007010},
author = {Andrzej P. Wierzbicki},
keywords = {OR in research and development, Knowledge-based systems, Mathematical modelling, Knowledge management, Hard and soft systems approaches, Tacit knowledge and intuition, Epistemology},
abstract = {The paper is motivated by the need of to address a new the old topic of operational research and hard (but also soft) systems science: what is the role of mathematical modelling, how does it relate to knowledge, to creativity, to human concerns? Such a need arises because of the great change observed today, of informational revolution, of transition towards knowledge-based economy, towards networked organization of our social and economic life. During last 50years operational research, mathematical modelling and computerised techniques of model analysis and optimisation contributed essentially to the change of perception of contemporary world, characteristic for the current informational revolution indicating the change of civilisation eras. These contributions have been noted during these years inside operational research, but analysed mostly from so-called soft systems thinking perspective. Main contributions to the actual formation of the new era, however, came from the hard systems research, in particular, as we shall show, from mathematical modelling in applications to the development of technological systems. The new civilisation era of information and knowledge-based economy started around 1980. It is a long duration historical era, characterised by a new way of understanding the world. This understanding is systemic and chaotic; in particular, it assumes the emergence of qualitatively new properties of complex systems on higher layers of complexity, which cannot be reduced to the properties of system components. On this background, it is necessary to reflect a new on the theory of knowledge. The paper presents a discussion of the concept of knowledge from several perspectives, such as the perspective of operational research, of systems science, of mathematical modelling, of knowledge-based economy, of knowledge engineering and knowledge management, of interactive model-based decision support. The human-centred development of informational technology necessitates a re-appraisal of soft systems approaches; their values and limitations are discussed. Additionally, a rational theory of intuition is recalled to show its relation with the concept of tacit knowledge, of knowledge creation and with harmonious approaches to knowledge characterising Far East philosophy as well as Japanese approaches to knowledge management and creation. Epistemological conclusions from the rational theory of intuition are discussed, including a new concept of micro-theories of knowledge creation and the concept of Creative Space.}
}
@article{VANDENENDE2022107201,
title = {A review of mathematical modeling of addiction regarding both (neuro-) psychological processes and the social contagion perspectives},
journal = {Addictive Behaviors},
volume = {127},
pages = {107201},
year = {2022},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2021.107201},
url = {https://www.sciencedirect.com/science/article/pii/S0306460321003865},
author = {Maarten W.J. {van den Ende} and Sacha Epskamp and Michael H. Lees and Han L.J. {van der Maas} and Reinout W. Wiers and Peter M.A. Sloot},
keywords = {Computational modeling, Addiction, Dynamical systems, Agent-based modeling, Formal theories, Review},
abstract = {Addiction is a complex biopsychosocial phenomenon, impacted by biological predispositions, psychological processes, and the social environment. Using mathematical and computational models that allow for surrogative reasoning may be a promising avenue for gaining a deeper understanding of this complex behavior. This paper reviews and classifies a selection of formal models of addiction focusing on the intra- and inter-individual dynamics, i.e., (neuro) psychological models and social models. We find that these modeling approaches to addiction are too disjoint and argue that in order to unravel the complexities of biopsychosocial processes of addiction, models should integrate intra- and inter-individual factors.}
}
@incollection{GULATI1991173,
title = {Neurocomputing Formalisms for Computational Learning and Machine Intelligence},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {33},
pages = {173-245},
year = {1991},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60167-9},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808601679},
author = {S. Gulati and J. Barhen and S.S. Iyengar},
abstract = {Publisher Summary
The chapter discusses the capabilities of neural-network learning that is central to the deeper question of its feasibility to artificial intelligence. It focuses on machine learning in the context of neural networks from the standpoints of computational complexity and algorithms information theory, and on the emerging area of learning theory in the context of dynamic systems. Engineered intelligent systems behave with remarkable rigidity when compared with, their biological counterparts, especially in their ability to recognize objects or speech, to manipulate and adapt in an unstructured environment, and to learn from past experience. A major reason for this limited technical success in emulating some of the more fundamental aspects of human intelligence lies in the differences between the organization and structuring of knowledge, and the dynamics of biological neuronal circuitry and its emulation using the symbolic-processing paradigm. The chapter rederives a theoretical framework for neural learning of nonlinear mappings, wherein both the topology of the network and synaptic interconnection strengths are evolved adaptively. The proposed methodology exploits a new class of mathematical constructs, terminal attractors, which provide unique information-processing capabilities to artificial neural systems. Terminal attractor representations are used not only to ensure infinite local stability of the encoded information, but also to provide a qualitative as well as quantitative change in the nature of the learning process. The chapter also draws from mathematical constructs in sensitivity theory for nonlinear systems to illustrate the notion of forward and adjoint-operators. The formalism exploits the concept of adjoint-operators to enable a fast global computation of the network's response to perturbations in all system parameters. This formalism eliminates the heuristic overtones of the proposed framework.}
}
@article{COIERA2007S98,
title = {Putting the technical back into socio-technical systems research},
journal = {International Journal of Medical Informatics},
volume = {76},
pages = {S98-S103},
year = {2007},
note = {Information Technology in Health Care: Sociotechnical Approaches},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2006.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S1386505606001481},
author = {Enrico Coiera},
keywords = {Human–computer interaction, Information system design, Information system evaluation, Socio-technical systems},
abstract = {Socio-technical systems (STS) analysis has provided us with a powerful framework with which to analyse the reasons behind the poor acceptability, uptake and performance of many information or communication technology systems (ICT). However, for the contribution of STS thinking to be more than simply a means of critiquing current practices and ICT systems, it needs to also contribute to the process of developing new and more effective ICT systems. Specifically, we need to develop a formal design language for translating our insights about the socio-technical nature of work, into design specifications that result in better interventions in the work place. We need to get ‘technical’ about what we mean and about what we want from a design, and we need to work alongside technologists to shape technology, as well as the processes, organisations and cultures within which they will be embedded. Indeed the process of design itself can be seen as a socio-technical one, and understanding the decision to design itself may allow us one day to stop designing for people, and create STS that sustainably design themselves.}
}
@article{CORBETT2020e03250,
title = {Connectivism and leadership: harnessing a learning theory for the digital age to redefine leadership in the twenty-first century},
journal = {Heliyon},
volume = {6},
number = {1},
pages = {e03250},
year = {2020},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2020.e03250},
url = {https://www.sciencedirect.com/science/article/pii/S2405844020300955},
author = {Frederique Corbett and Elio Spinello},
keywords = {Connectivism, Learning, Education, Learning theory, Leadership, Computer science, Human-centered computing, Information systems, Network (computer science)},
abstract = {This manuscript provides a literature review of connectivism. It presents evidence and thinking in which connectivism, a new learning theory which has typically been used for online learning, is applied to leadership, with a provocative discussion on the yet unexplored opportunities to use connectivism to redefine leadership in the twenty-first century. The paper aims to bridge the gap between the contributions of digital learning in education and the field of leadership theory and development. It seeks to apply the critical tenets of connectivism in education and learning to leadership theory and to stimulate a debate on new forms of leadership.}
}
@incollection{BURK2023457,
title = {Chapter 24 - Analytics architectures for the 21st century},
editor = {Gary D. Miner and Linda A. Miner and Scott Burk and Mitchell Goldstein and Robert Nisbet and Nephi Walton and Thomas Hill},
booktitle = {Practical Data Analytics for Innovation in Medicine (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {457-472},
year = {2023},
isbn = {978-0-323-95274-3},
doi = {https://doi.org/10.1016/B978-0-323-95274-3.00017-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323952743000178},
author = {Scott Burk},
keywords = {Data literacy, center of excellence, culture, data architecture, APIS, microservices, streaming data, data stores, data virtualization, 5v’s of data, master data, reference data, metadata, data governance, data management, exploratory data analysis, data prep, feature engineering, model selection, model evaluation, model deployment, model monitoring, model Ops},
abstract = {Artificial Intelligence (AI) and analytics efforts are too often just extensions or isolated additions to medical practice and research. It could be an extension of research efforts, part of a medical degree curriculum or residency program to extend scholarly pursuits. It could be hospital systems wishing to gain operation efficiency and control. It could be physician groups-of-practice trying to mitigate risk or improve financial performance. While isolated efforts may provide some benefit, leaders understand that exceptional results require a paradigm shift in thinking and the infrastructure to support the new technologies and innovation. In this chapter, we present three pillars that lay the foundation for success in medical research and results in the 21st century. Successful participants will have designed and implemented the following architectures.}
}
@article{GALLISTEL201287,
title = {On rationalism and optimality: Responses to the Miller and Nevin Commentaries},
journal = {Behavioural Processes},
volume = {90},
number = {1},
pages = {87-88},
year = {2012},
note = {Society for the Quantitative Analyses of Behavior: Extinction},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2012.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0376635712000514},
author = {C.R. Gallistel},
keywords = {Rationalism, Optimality, Information theory, Contingency, Cue competition, Assignment of credit},
abstract = {Modern materialist rationalism is the doctrine that principles governing behaviorally important aspects of the world have become implicit in the structure of purpose-specific information-processing mechanisms through evolution by natural selection. These principles are mostly, but not entirely mathematical. Because the evolutionary process tends to optimize, the computations performed by these mechanisms tend to approximate the optimal computation. This doctrine does not imply that animals always make rational and/or optimal choices.}
}
@article{MONTANARO2024,
title = {Computable species descriptions and nanopublications: applying ontology-based technologies to dung beetles (Coleoptera, Scarabaeinae)},
journal = {Biodiversity Data Journal},
volume = {12},
year = {2024},
issn = {1314-2836},
doi = {https://doi.org/10.3897/BDJ.12.e121562},
url = {https://www.sciencedirect.com/science/article/pii/S1314283624001660},
author = {Giulio Montanaro and James P. Balhoff and Jennifer C. Girón and Max Söderholm and Sergei Tarasov},
keywords = {Phenoscript, taxonomy, semantic data, phenotypic traits, characters, morphology,   , microCT},
abstract = {Background
Taxonomy has long struggled with analysing vast amounts of phenotypic data due to computational and accessibility challenges. Ontology-based technologies provide a framework for modelling semantic phenotypes that are understandable by computers and compliant with FAIR principles. In this paper, we explore the use of Phenoscript, an emerging language designed for creating semantic phenotypes, to produce computable species descriptions. Our case study centers on the application of this approach to dung beetles (Coleoptera, Scarabaeinae).
New information
We illustrate the effectiveness of Phenoscript for creating semantic phenotypes. We also demonstrate the ability of the Phenospy python package to automatically translate Phenoscript descriptions into natural language (NL), which eliminates the need for writing traditional NL descriptions. We introduce a computational pipeline that streamlines the generation of semantic descriptions and their conversion to NL. To demonstrate the power of the semantic approach, we apply simple semantic queries to the generated phenotypic descriptions. This paper addresses the current challenges in crafting semantic species descriptions and outlines the path towards future improvements. Furthermore, we discuss the promising integration of semantic phenotypes and nanopublications, as emerging methods for sharing scientific information. Overall, our study highlights the pivotal role of ontology-based technologies in modernising taxonomy and aligning it with the evolving landscape of big data analysis and FAIR principles.}
}
@article{TRAN2019284,
title = {Creating material data for thermoset injection molding simulation process},
journal = {Polymer Testing},
volume = {73},
pages = {284-292},
year = {2019},
issn = {0142-9418},
doi = {https://doi.org/10.1016/j.polymertesting.2018.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S0142941818316295},
author = {Ngoc Tu Tran and Michael Gehde},
keywords = {Thermoset injection molding, Reactive viscosity and cure kinetics model, Thermoset material data, Reactive injection molding simulation, Wall slip boundary condition},
abstract = {Thermoset material data for reactive injection molding simulation process is found in limited sources and seldom available from data bank of simulation tools because of complication not only in rheological and thermal properties measurement but also in writing optimization algorithm to model rheological and thermal mathematical equations. In this paper, rheological and thermal properties of thermoset injection molding compounds were successfully measured. In addition, a numerical method was developed to create material data of thermoset injection molding compounds, which was directly imported into a simulation tool, namely, Moldex3D to investigate its application in thermoset injection molding simulation process. Furthermore, a strong slip phenomenon on the interface between thermoset melt and wall surface which was investigated and detected during injection molding experiments was taken into account in the filling simulation process. The computation was found to be in good agreement with the experimental results, indicating that the new generated material data is reasonable and the influence of wall slip on the mold filling characterization of thermoset injection compounds during simulation process is not ignorable.}
}
@article{COWLEY2021101364,
title = {Reading: skilled linguistic action},
journal = {Language Sciences},
volume = {84},
pages = {101364},
year = {2021},
note = {A Dialogue between Distributed Language and Reading Disciplines},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2021.101364},
url = {https://www.sciencedirect.com/science/article/pii/S0388000121000103},
author = {Stephen J. Cowley},
keywords = {Reading, Distributed language, Embodied cognitive science, Languaging, Literacy, Radical embodied cognitive science},
abstract = {The paper links critique of ‘inner process’ to a perspective that treats language as activity that is accomplished by living beings. The view traces reading to human ways of coordinating with ‘the seen’. Having contrasted this distributed view with organism-first alternatives, I use a case study of reports to sketch how readers engage with written materials to both select details and project an imagined ‘source’ (e.g. a meaning, author or intention). Far from using inner process (‘decoding’) readers coordinate with a field of patternings. Where skilled, they use recollecting to link looking, silent thinking, expectations and strategic moves. Using judgements, they transform what they observe by setting off experience. I thus build on Wittgenstein's critique of inner process while also endorsing Trybulec’s (2019) radicalization of his view. To avoid treating the sense of ‘written words’ as subjective, the material aspect of patternings is taken to index outward criteria (roughly, standards of judgement). In seeking to replace theories that presuppose ‘text’, I stress how patternings invite directed sensorimotor activity by an intelligent person. Indeed, since persons learn to see wordings (or take a language stance) arrangements of patternings act as marks, ‘symbols’ and aggregations that set off recollection, judgements and iterated action. Skilled readers can use re-reading, the already read etc. to modulate ways of attending. Readers link the said, hints, recollections and ways of actualizing movements to grant reading experience a specific sense. By considering how outer criteria are evoked, reading is traced back to skilled linguistic action.}
}
@article{KASALICA20212157,
title = {APE in the Wild: Automated Exploration of Proteomics Workflows in the bio.tools Registry},
journal = {Journal of Proteome Research},
volume = {20},
number = {4},
pages = {2157-2165},
year = {2021},
issn = {1535-3907},
doi = {https://doi.org/10.1021/acs.jproteome.0c00983},
url = {https://www.sciencedirect.com/science/article/pii/S1535390721002031},
author = {Vedran Kasalica and Veit Schwämmle and Magnus Palmblad and Jon Ison and Anna-Lena Lamprecht},
keywords = {proteomics, scientific workflows, computational pipelines, workflow exploration, automated workflow composition, semantic tool annotation},
abstract = {The bio.tools registry is a main catalogue of computational tools in the life sciences. More than 17 000 tools have been registered by the international bioinformatics community. The bio.tools metadata schema includes semantic annotations of tool functions, that is, formal descriptions of tools’ data types, formats, and operations with terms from the EDAM bioinformatics ontology. Such annotations enable the automated composition of tools into multistep pipelines or workflows. In this Technical Note, we revisit a previous case study on the automated composition of proteomics workflows. We use the same four workflow scenarios but instead of using a small set of tools with carefully handcrafted annotations, we explore workflows directly on bio.tools. We use the Automated Pipeline Explorer (APE), a reimplementation and extension of the workflow composition method previously used. Moving “into the wild” opens up an unprecedented wealth of tools and a huge number of alternative workflows. Automated composition tools can be used to explore this space of possibilities systematically. Inevitably, the mixed quality of semantic annotations in bio.tools leads to unintended or erroneous tool combinations. However, our results also show that additional control mechanisms (tool filters, configuration options, and workflow constraints) can effectively guide the exploration toward smaller sets of more meaningful workflows.
}
}
@incollection{GIOVANNONE202441,
title = {Chapter Two - Further steps towards a mechanistic functionalist framework for understanding individual differences in language and cognition},
editor = {Kara D. Federmeier},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {81},
pages = {41-73},
year = {2024},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2024.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0079742124000380},
author = {Nikole Giovannone and Joseph C. Toscano},
keywords = {Individual differences, Cognition, Language processing, Computational modeling, Mechanistic functionalism},
abstract = {Despite a growing focus on individual differences in cognitive psychology, research in this area is complicated by several issues related to how such differences are defined and measured. These challenges create a significant roadblock for the field. To combat this issue, we argue that the next critical step for language and cognitive science is careful and thorough investigation of the specific mechanisms that drive individual differences. In this chapter, our goal is to extend the process-based mechanistic functional normativist framework and to provide a test case for how researchers can leverage computational modeling to investigate individual differences in cognitive mechanisms (using pattern learning in the serial reaction time task as an example). By shifting our focus to characterizing the mechanisms that drive individual differences in language and cognition, the field stands to advance both theoretical frameworks and methodological approaches for studying these processes.}
}
@article{COCHAND2023847,
title = {Systems Anesthesiology: Systems of Care Delivery and Optimization in the Operating Room},
journal = {Anesthesiology Clinics},
volume = {41},
number = {4},
pages = {847-861},
year = {2023},
note = {Perioperative Safety Culture},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2023.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S1932227523000460},
author = {Laure Cochand and Mark G. Filipovic and Markus Huber and Markus M. Luedi and Richard D. Urman and Corina Bello},
keywords = {Systems anesthesiology, Perioperative care, Leadership, Operations management}
}
@incollection{SUKHAI2017249,
title = {22 - Simulation learning},
editor = {Mahadeo A. Sukhai and Chelsea E. Mohler},
booktitle = {Creating a Culture of Accessibility in the Sciences},
publisher = {Academic Press},
pages = {249-255},
year = {2017},
isbn = {978-0-12-804037-9},
doi = {https://doi.org/10.1016/B978-0-12-804037-9.00022-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012804037900022X},
author = {Mahadeo A. Sukhai and Chelsea E. Mohler},
keywords = {Simulation learning, accommodation, teaching tool, computer technology, application of best practices},
abstract = {Simulation learning can be a valuable tool deployed in support of the learning of students with disabilities in the sciences. In thinking about simulation learning, we must consider two scenarios: (1) When simulation learning will benefit a student with a disability, because other accommodation methods are not appropriate or feasible; and, (2) When simulation learning is applied to all students, where accessibility considerations of the simulation must be taken into account for students with disabilities in the class. In this chapter, we will review the application of both scenarios for simulation learning to students with disabilities in the sciences.}
}
@article{CHANDRASEGARAN2013204,
title = {The evolution, challenges, and future of knowledge representation in product design systems},
journal = {Computer-Aided Design},
volume = {45},
number = {2},
pages = {204-228},
year = {2013},
note = {Solid and Physical Modeling 2012},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2012.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010448512001741},
author = {Senthil K. Chandrasegaran and Karthik Ramani and Ram D. Sriram and Imré Horváth and Alain Bernard and Ramy F. Harik and Wei Gao},
keywords = {Knowledge representation, Knowledge capture, Knowledge management, Product design, Computational tools, Ontology, Systems engineering, Design rationale, Multidisciplinary modeling, Virtual reality, Collaborative engineering, Simulation},
abstract = {Product design is a highly involved, often ill-defined, complex and iterative process, and the needs and specifications of the required artifact get more refined only as the design process moves toward its goal. An effective computer support tool that helps the designer make better-informed decisions requires efficient knowledge representation schemes. In today’s world, there is a virtual explosion in the amount of raw data available to the designer, and knowledge representation is critical in order to sift through this data and make sense of it. In addition, the need to stay competitive has shrunk product development time through the use of simultaneous and collaborative design processes, which depend on effective transfer of knowledge between teams. Finally, the awareness that decisions made early in the design process have a higher impact in terms of energy, cost, and sustainability, has resulted in the need to project knowledge typically required in the later stages of design to the earlier stages. Research in design rationale systems, product families, systems engineering, and ontology engineering has sought to capture knowledge from earlier product design decisions, from the breakdown of product functions and associated physical features, and from customer requirements and feedback reports. VR (Virtual reality) systems and multidisciplinary modeling have enabled the simulation of scenarios in the manufacture, assembly, and use of the product. This has helped capture vital knowledge from these stages of the product life and use it in design validation and testing. While there have been considerable and significant developments in knowledge capture and representation in product design, it is useful to sometimes review our position in the area, study the evolution of research in product design, and from past and current trends, try and foresee future developments. The goal of this paper is thus to review both our understanding of the field and the support tools that exist for the purpose, and identify the trends and possible directions research can evolve in the future.}
}
@article{BUESODEBARRIO2025101019,
title = {Executable contracts for Elixir},
journal = {Journal of Logical and Algebraic Methods in Programming},
volume = {142},
pages = {101019},
year = {2025},
issn = {2352-2208},
doi = {https://doi.org/10.1016/j.jlamp.2024.101019},
url = {https://www.sciencedirect.com/science/article/pii/S2352220824000737},
author = {Luis Eduardo {Bueso de Barrio} and Lars-Åke Fredlund and Ángel Herranz and Julio Mariño and Clara {Benac Earle}},
abstract = {This article presents the design of a library for attaching and checking executable contracts to code written in the Elixir programming language. In addition to classical contract constructs such as preconditions and postconditions, the library allows specifying exceptional behaviour (i.e., which exceptions are thrown and under which conditions), detecting non-termination issues in recursive functions by specifying a strictly decreasing order in function arguments, and associating timers with function calls to detect slow computations. The library also focuses on language-specific features, enabling the association of contracts with the reception of messages sent by processes and the attachment of constraints to variable names (useful due to variable shadowing in Elixir). Moreover, stateful contracts (i.e., with a model state) permit specifying the behaviour of stateful APIs whose operations can be linearized. Using the stateful contracts, a monitor can be employed to check that the observed state can be explained in terms of possible linearizations.}
}
@article{JOHANNESJOSEFIJEN202173,
title = {An adaptive temporal-causal network model to analyse extinction of communication over time},
journal = {Cognitive Systems Research},
volume = {68},
pages = {73-83},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S1389041721000231},
author = {Lucas {Johannes José Fijen} and Julio {Joaquín López González} and Jan Treur},
keywords = {Extinction of communication, Network modeling, Adaptive network, Social simulation},
abstract = {The persistence of information communicated between humans is difficult to measure as it is affected by many features. This paper presents an approach to computationally model the cognitive processes of information sharing to describe persistence or extinction of communication in Twitter over time. The adaptive mental network model explains, for example, how an individual can experience information overflow on a topic, and how this affects the sharing of information. Parameter tuning by Simulated Annealing is used to identify characteristics of the network model that fit to empirical data from Twitter. The data collected is related to the independentism in Catalunya, Spain, which is considered a global issue with repercussion in Europe.}
}
@incollection{LINSTER2020650,
title = {3.33 - Modeling of Olfactory Processing☆},
editor = {Bernd Fritzsch},
booktitle = {The Senses: A Comprehensive Reference (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {650-660},
year = {2020},
isbn = {978-0-12-805409-3},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.24153-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245241539},
author = {Christiane Linster and Thomas A. Cleland},
keywords = {Bulbar neurons, Filtering and contrast enhancement, Odorant molecules, Odorant receptors, Olfactory bulb, Pattern of activation},
abstract = {Synopsis
We here review how computational models of olfactory system have guided our understanding of olfactory processing. We discuss how the neural mechanisms underlying functionalities such as contrast enhancement, filtering and associative memory processes have been elucidated by computational models at different levels of detail. We provide an overall view of current theories of olfactory processing.}
}
@article{RANJBARI2023124,
title = {Waste management beyond the COVID-19 pandemic: Bibliometric and text mining analyses},
journal = {Gondwana Research},
volume = {114},
pages = {124-137},
year = {2023},
note = {Special Issue on Environmental impacts of COVID-19 pandemic},
issn = {1342-937X},
doi = {https://doi.org/10.1016/j.gr.2021.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S1342937X22000272},
author = {Meisam Ranjbari and Zahra {Shams Esfandabadi} and Sneha Gautam and Alberto Ferraris and Simone Domenico Scagnelli},
keywords = {COVID-19, Plastic waste, Healthcare waste, Municipal solid waste, Wastewater, Personal protective equipment},
abstract = {The outbreak of the COVID-19 pandemic has significantly increased the demand for personal protective equipment, in particular face masks, thus leading to a huge amount of healthcare waste generated worldwide. Consequently, such an unprecedented amount of newly emerged waste has posed significant challenges to practitioners, policy-makers, and municipal authorities involved in waste management (WM) systems. This research aims at mapping the COVID-19-related scientific production to date in the field of WM. In this vein, the performance indicators of the target literature were analyzed and discussed through conducting a bibliometric analysis. The conceptual structure of COVID-19-related WM research, including seven main research themes, were uncovered and visualized through a text mining analysis as follows: (1) household and food waste, (2) personnel safety and training for waste handling, (3) sustainability and circular economy, (4) personal protective equipment and plastic waste, (5) healthcare waste management practices, (6) wastewater management, and (7) COVID-19 transmission through infectious waste. Finally, a research agenda for WM practices and activities in the post-COVID-19 era was proposed, focusing on the following three identified research gaps: (i) developing a systemic framework to properly manage the pandemic crisis implications for WM practices as a whole, following a systems thinking approach, (ii) building a circular economy model encompassing all activities from the design stage to the implementation stage, and (iii) proposing incentives to effectively involve informal sectors and local capacity in decentralizing municipal waste management, with a specific focus on developing and less-developed countries.}
}
@article{LIU2024102118,
title = {Personalized fuzzy semantic model of PHFLTS: Application to linguistic group decision making},
journal = {Information Fusion},
volume = {103},
pages = {102118},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102118},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004347},
author = {Yaya Liu and Lina Zhu and Rosa M. Rodríguez and Luis Martínez},
keywords = {Computing with words, Linguistic group decision making, Proportional hesitant fuzzy linguistic term set, Personalized individual semantic},
abstract = {The proportional hesitant fuzzy linguistic term set (PHFLTS) has been effectively employed in analyzing the group’s hesitancy in linguistic group decision making (LGDM). The application of PHFLTS assists in capturing the individual’s hesitancy across diverse time periods. It is acknowledged that a single word could potentially convey various meanings to different decision makers, such differences can be proficiently managed by utilizing personalized individual semantic (PIS) models. Previous approaches for calculating PIS failed to incorporate the individual’s updating preference information over time, which increases the risk that the computation of PIS is affected by random factors in a specific moment. In our current research, individual linguistic preference gathered over a time period are leveraged to form the PHFLTS. Additionally, a consistency driven optimization model based on PHFLTS is formulated to obtain PIS of linguistic terms. Subsequently, a fuzzy representation model termed as the fuzzy envelope of PHFLTS is introduced to facilitate the computation with words processes, integrating PHFLTS in LGDM. The practicality and legitimacy of these proposed models are evaluated through a comparative analysis. Lastly, these proposed models are tested and applied in a dedicated case study to further prove their usefulness and efficacy.}
}
@article{JI2023126734,
title = {Experimental and numerical investigation on a radiative cooling driving thermoelectric generator system},
journal = {Energy},
volume = {268},
pages = {126734},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.126734},
url = {https://www.sciencedirect.com/science/article/pii/S0360544223001287},
author = {Yishuang Ji and Song Lv},
keywords = {Radiative cooling, Thermoelectric generator, Hybrid system, Thermal-electrical properties, Numerical analysis},
abstract = {Thermoelectric (TE) technology and radiative sky cooling (RSC) technology have proven to be a promising and green way to harvest energy from the environment. Combining RSC technology with Thermoelectric generator (TEG) device for passive power generation at night is meaningful and remains a challenge. Here, a radiative sky cooling driving thermoelectric generator (RSC-TE) system integrated by a doped modified TiO2/PMMA radiative cooling film, a commercial TEG, and an aluminum heat sink is developed, with a simple structure, low cost and high efficiency. The thermal-electrical performance of the RSC-TE system was evaluated through a consecutive nighttime experiment. Experimental results show that the temperature of the cold side of the TEG in contact with the radiative cooler is 2.7–4.2 °C lower than the ambient temperature, and the temperature difference between the hot and cold sides of TEG is 2.3–3.2 °C. The temperature difference at 00:00 can reach 2.5 °C, which corresponds to an open circuit voltage of 87 mV. Furthermore, a 3D model has been established by COMSOL software to investigate the effects of different environmental parameters and component-related parameters on system performance, which has guiding significance for the improvement and optimization of the experimental setup. This study can provide a new thinking and some practical guidelines for the design and application of the RSC-TE system.}
}
@article{GOMOLLONBEL20245056,
title = {Connecting chemical worlds for a sustainable future},
journal = {Chemical Science},
volume = {15},
number = {14},
pages = {5056-5060},
year = {2024},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc06815c},
url = {https://www.sciencedirect.com/science/article/pii/S2041652024004267},
author = {Fernando Gomollón-Bel and Javier García-Martínez},
abstract = {Chemistry plays a central role in science and is the basis of one of the major, more impactful, and diverse industries. However, to address the most pressing global challenges, we must learn to create connections in an effective and meaningful way, with other disciplines, industries, and society at large. Here, we present the IUPAC Top Ten Emerging Technologies in Chemistry as an example of an initiative that highlights the value of the most promising advances in chemistry and contributes to creating connections to accelerate sustainable solutions for our society and our planet.}
}
@article{CLAPIN2002231,
title = {Content and cognitive science},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {231-242},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00004-6},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000046},
author = {Hugh Clapin},
keywords = {Symbols, Classical, Cognitive science, Tacit representation, Architectural content, Computation},
abstract = {The computer model of the mind has informed and guided debate in the cognitive sciences for over 40 years, and gives pride of place to symbols. In this paper I investigate the nature of computational symbols and show that even in the parade cases of symbolic computation, symbols are not doing all the semantic and computational work. This analysis has important consequences for the scope of cognitive science, particularly with regard to what constitutes its domain: cognition.}
}
@article{WOLFENGAGEN2020276,
title = {Capturing information processes with variable domains},
journal = {Procedia Computer Science},
volume = {169},
pages = {276-283},
year = {2020},
note = {Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.177},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303008},
author = {Viacheslav Wolfengagen and Larisa Ismailova and Sergey Kosikov},
keywords = {semantic information processing, computational model, variable domains},
abstract = {An approach to the construction of a computational model in which information processes are presented in the framework of theories without types, and they, in turn, are considered as special parts of typed theories, is proposed. Similar mixing was used in model studies for lambda-calculus. In contrast to them, in the present work, information processes correspond to parameterized metadata objects, which are variable domain constructs. Transformations of variable domains correspond to the spread of the process. Directional transformation provides the generation of metadata targets in the form of parameterized concepts. This simulates the evolving of the process, which allows the interpretation of the hidden time factor. The emerging model is purely process-based and provides a conceptual framework. The possibility of coding this framework with a system of interdependent lambda-terms is shown.}
}
@article{SAVILLE201577,
title = {Application of information and communication technology and data sharing management scheme for the coastal fishery using real-time fishery information},
journal = {Ocean & Coastal Management},
volume = {106},
pages = {77-86},
year = {2015},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2015.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0964569115000289},
author = {Ramadhona Saville and Katsumori Hatanaka and Minoru Sano and Masaaki Wada},
keywords = {Catchable stock index, Self-management support, Real-time data sharing, Cloud computing, ICT, Swept area method, Sea cucumber},
abstract = {In this paper, we propose an automatic computation and data sharing scheme to support management system in coastal fishery using real-time fishery information through information and communication technology (ICT). In Japan, several species of fisheries commodity have not been specified in Total Allowable Catch policy, causing a lot of confusion on fishery cooperatives and fishermen on how to set the catch limit. To deal with the problem, in the previous study, we developed catchable stock index, a method to estimate a certain extent of resource via the swept area method. However, as the calculation of the index was computed on a GIS software manually, it was very time consuming, costly and unable to give an immediate evaluation of the fishing operation. This study aims to support management system in a coastal fishery through the development of automatic catchable stock index algorithm. In this study, ICT was utilized to obtain and transmit the real-time data sharing of fishery information as well as to distribute the computation results to the fishermen and fishery cooperative. The data used were vessels' trajectories and catch records, which included the start/end time and catch amount of each fishing operation. The catchable stock index was automatically computed in an originally developed cloud computing service. We have conducted the test run of the present method in sea cucumber dredge-net fishery on the coast of Rumoi City, Hokkaido, Japan. Data were collected from the entire vessels in Rumoi (16 vessels) during the 2012 and 2013 fishing seasons. The results were returned to the fishermen via the Internet each day during the fishing season, therefore, fishermen were able to immediately evaluate their catch. The estimated catchable stock index for the 2012 and 2013 seasons was 85.5 tons and 92.3 tons, respectively. By referring to the present system, fishermen voluntarily stopped the 2012 and 2013 fishing season several weeks earlier than their initial schedule to avoid overfishing. Moreover, in the previous study, the spacing of the grid has been decided empirically, but in this study, the adequate grid size could be evaluated due to the fast computation through ratio of the area of a grid cell to the total dredged area. In light of the evidence, the present automatic algorithm provided useful information for supporting the self-management of this coastal fishery.}
}
@article{DIMARTINO2023138293,
title = {A comprehensive classification of food–energy–water nexus optimization studies: State of the art},
journal = {Journal of Cleaner Production},
volume = {420},
pages = {138293},
year = {2023},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2023.138293},
url = {https://www.sciencedirect.com/science/article/pii/S0959652623024514},
author = {Marcello {Di Martino} and Patrick Linke and Efstratios N. Pistikopoulos},
keywords = {Food–energy–water nexus, Resource supply systems, Process systems engineering, Optimization, Sustainability},
abstract = {To tackle the globally increasing discrepancy between food, energy and water demands and resource availability sustainably, resource supply system models have to incorporate the inter-dependencies and -connectivities to other supply systems. This leads naturally to a food–energy–water nexus (FEWN) approach. The FEWN can be interpreted as the study of the connections between the food, energy and water resource systems, emphasizing how decision-making influences the synergies, conflicts and trade-offs among the various sectors. In recent years, modeling and optimization of FEWN systems has been receiving an increasing interest in the open literature, however, with limited emphasis on how decisions of the FEWN are derived. In this review, FEWN optimization studies are analyzed with focus on the employed objectives, optimization and solution strategies, as well as the selected sub-systems and their corresponding spatial and temporal scales to uncover in detail how decision-making is facilitated. More specifically, FEWN optimization studies are classified according to their modeling and solution strategies. Based on this classification it is uncovered that (i) the decision-making itself has not yet been investigated in detail in FEWN literature, (ii) the incorporation of all aspects of the FEWN is still a challenge, (iii) the interconnection between FEWN systems and society has to be further investigated, and (iv) the implications of uncertainty for the resiliency, robustness and security of process systems is not yet well defined. Additionally, a generic FEWN resource-task network formulation is introduced to illustrate the similarities across the various resource supply sectors. Special interest is placed on how synergies are identified and competition be avoided among resource systems. It is shown that the selected spatial scale as well as the utilized modeling and optimization strategies significantly influence the synergy level of obtained solutions. Furthermore, it is derived that the energy transition has to incorporate FEWN systems thinking for sustainable solution generation. Overall, this review summarizes the different applications and implications of process systems engineering concepts to FEWN systems.}
}
@article{ALLISON2018147,
title = {Dilemmas of modelling and decision-making in environmental research},
journal = {Environmental Modelling & Software},
volume = {99},
pages = {147-155},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217300749},
author = {Andrew E.F. Allison and Mark E. Dickson and Karen T. Fisher and Simon F. Thrush},
keywords = {Wicked problems, Agent-based modelling, Post-normal science, Social-ecological systems, Shallow coastal systems},
abstract = {Multiple dilemmas confound social-ecological modelling. This review paper focuses on two: a modeller's dilemma associated with determining appropriate levels of model simplification, and a dilemma of decision-making relating to the use of models that were never designed to predict. We analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling. Simplified inter- and trans-disciplinary models have the potential to identify directions of system change, challenge thinking in disciplinary silos, and ultimately confront the dilemmas of social-ecological modelling.}
}
@article{CHAFEE2022R346,
title = {Prefrontal cortex},
journal = {Current Biology},
volume = {32},
number = {8},
pages = {R346-R351},
year = {2022},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2022.02.071},
url = {https://www.sciencedirect.com/science/article/pii/S0960982222003414},
author = {Matthew V. Chafee and Sarah R. Heilbronner},
abstract = {Summary
The prefrontal cortex is a well-studied but, in terms of understanding what it is for, deeply divisive part of the brain located at the front of the head. Perhaps the least controversial feature of the prefrontal cortex is its complexity. The prefrontal cortex is anatomically, functionally, and computationally complex. It is anatomically complex, containing a number of subregions each sending and receiving projections to a unique set of other cortical and subcortical areas. This interconnectivity presents a serious challenge to efforts to localize function to prefrontal cortex, because it can seem as though information flows everywhere all at once in prefrontal networks. Perhaps as a result, prefrontal cortex is also computationally complex: working memory, abstraction, sensory attention, value-based decision making, planning, and motor control are all functions that have been attributed to the prefrontal cortex. This diversity of functions is likely to reflect the diversity of brain regions that prefrontal cortex communicates with while carrying out the computations it performs to influence behavior.}
}
@article{LI20241035,
title = {Current status and construction scheme of smart geothermal field technology},
journal = {Petroleum Exploration and Development},
volume = {51},
number = {4},
pages = {1035-1048},
year = {2024},
issn = {1876-3804},
doi = {https://doi.org/10.1016/S1876-3804(24)60523-9},
url = {https://www.sciencedirect.com/science/article/pii/S1876380424605239},
author = {Gensheng LI and Xianzhi SONG and Yu SHI and Gaosheng WANG and Zhongwei HUANG},
keywords = {smart geothermal field, intelligent development of geothermal reservoirs, application scenario, intelligent characterization, intelligent simulation, intelligent optimization control, smart management},
abstract = {To address the key problems in the application of intelligent technology in geothermal development, smart application scenarios for geothermal development are constructed. The research status and existing challenges of intelligent technology in each scenario are analyzed, and the construction scheme of smart geothermal field system is proposed. The smart geothermal field is an organic integration of geothermal development engineering and advanced technologies such as the artificial intelligence. At present, the technology of smart geothermal field is still in the exploratory stage. It has been tested for application in scenarios such as intelligent characterization of geothermal reservoirs, dynamic intelligent simulation of geothermal reservoirs, intelligent optimization of development schemes and smart management of geothermal development. However, it still faces many problems, including the high computational cost, difficult real-time response, multiple solutions and strong model dependence, difficult real-time optimization of dynamic multi-constraints, and deep integration of multi-source data. The construction scheme of smart geothermal field system is proposed, which consists of modules including the full database, intelligent characterization, intelligent simulation and intelligent optimization control. The connection between modules is established through the data transmission and the model interaction. In the next stage, it is necessary to focus on the basic theories and key technologies in each module of the smart geothermal field system, to accelerate the lifecycle intelligent transformation of the geothermal development and utilization, and to promote the intelligent, stable, long-term, optimal and safe production of geothermal resources.}
}
@incollection{BARTO199135,
title = {On the Computational Economics of Reinforcement Learning},
editor = {David S. Touretzky and Jeffrey L. Elman and Terrence J. Sejnowski and Geoffrey E. Hinton},
booktitle = {Connectionist Models},
publisher = {Morgan Kaufmann},
pages = {35-44},
year = {1991},
isbn = {978-1-4832-1448-1},
doi = {https://doi.org/10.1016/B978-1-4832-1448-1.50010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978148321448150010X},
author = {Andrew G. Barto and Satinder Pal Singh},
abstract = {Following terminology used in adaptive control, we distinguish between indirect learning methods, which learn explicit models of the dynamic structure of the system to be controlled, and direct learning methods, which do not. We compare an existing indirect method, which uses a conventional dynamic programming algorithm, with a closely related direct reinforcement learning method by applying both methods to an infinite horizon Markov decision problem with unknown state-transition probabilities. The simulations show that although the direct method requires much less space and dramatically less computation per control action, its learning ability in this task is superior to, or compares favorably with, that of the more complex indirect method. Although these results do not address how the methods’ performances compare as problems become more difficult, they suggest that given a fixed amount of computational power available per control action, it may be better to use a direct reinforcement learning method augmented with indirect techniques than to devote all available resources to a computationally costly indirect method. Comprehensive answers to the questions raised by this study depend on many factors making up the economic context of the computation.}
}