@article{CAMARENA2020122574,
title = {Artificial intelligence in the design of the transitions to sustainable food systems},
journal = {Journal of Cleaner Production},
volume = {271},
pages = {122574},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.122574},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620326214},
author = {Stéphanie Camaréna},
keywords = {Artificial intelligence, Design ethics, Transdisciplinary research, Design for sustainability, Sustainable food systems, Systems thinking},
abstract = {Food systems and our ability to secure food and nutrition for current and future generations is challenged by population growth, climate change, resource depletion and pollution. The current agricultural and supply chain systems are one of the main contributors to the issues. Transformational, not incremental change is needed to transition to sustainable food systems capable of feeding close to 10 billion people in less than 30 years. Artificial intelligence (AI) is pervading all parts of food systems in ways that indicate transformative system changes are possible. Designers, as mediators between people, technology and the environment have a responsibility to recognise and reflect on ways AI could bring the change needed to move to sustainable food systems. This literature review is situated at the intersection of Food systems, Design, Artificial Intelligence and Sustainability. The transdisciplinary approach reveals what exists across the disciplines, what can be done with AI to transition to sustainable food systems, how Design proposes to approach the change, and which ethical or philosophical considerations start to emerge. The discussion reflects on AI as a potential leverage point to bring changes in the system and on the designer's role in establishing the human-technology-environmental relationships. Further research and recommendations are provided.}
}
@article{CARNEY2004135,
title = {Denis Noble discusses his career in computational biology},
journal = {Drug Discovery Today: BIOSILICO},
volume = {2},
number = {4},
pages = {135-137},
year = {2004},
issn = {1741-8364},
doi = {https://doi.org/10.1016/S1741-8364(04)02414-X},
url = {https://www.sciencedirect.com/science/article/pii/S174183640402414X},
author = {Stephen Carney},
keywords = {Interview, computer modeling, grid computing, cardiac electrophysiology, whole organ models, arrhythmia},
abstract = {Denis Noble was born in 1936 and obtained a BSc and PhD from University College London. He is one of the pioneers of computational biology related to cardiac cell electrophysiology and its incorporation into the first detailed biophysical models of the whole organ. He has made many major contributions to this work spanning from his groundbreaking work in 1960, showing that in heart, contrary to the situation in nerve, the first effect of membrane depolarisation is to greatly reduce potassium conductance, which in turn is greatly dependent on plasma potassium levels. His work over the last forty years has culminated in a highly successful virtual model of the heart, which has allowed theoretical interpretation of cardiac arrhythmias and the development of antiarrhythmic drugs. Professor Noble was made a fellow of the Royal Society in 1979, one of the highlights of his many awards. He is in great demand as a presenter of plenary lectures at many august meetings. In addition to his abilities as a computational biologist, Professor Noble is an accomplished linguist and has given lectures in French and Italian, and has significant abilities in Japanese, Korean and even Maori.}
}
@article{LAZARO2021111384,
title = {Policy and governance dynamics in the water-energy-food-land nexus of biofuels: Proposing a qualitative analysis model},
journal = {Renewable and Sustainable Energy Reviews},
volume = {149},
pages = {111384},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111384},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121006699},
author = {Lira Luz Benites Lazaro and Leandro Luiz Giatti and Celio Bermann and Angelica Giarolla and Jean Ometto},
keywords = {Water–energy–food nexus, Nexus thinking, Governance, Policy, Biofuels, Nexus methodology, Nexus method, Innovation},
abstract = {The production of biofuels is inextricably linked with the water-energy-food-land (WEFL) nexus. Understanding these linkages is necessary to formulate effective policies that can influence positive outcomes and contribute to the realization of long-term economic, environmental, and social goals. The use of biofuels can help achieve the United Nation's Sustainable Development Goals (SDGs) and implement the Paris Agreement on climate change. However, the biofuels sector must account for its interdependencies and trade-offs with other sectors. In this study, we formulate a qualitative analytical model that goes beyond the three water-energy-food nexus components by incorporating other elements, such as policy, innovation, governance, and labor to examine their effect as influencing factors and to understand how synergies, trade-offs, and long-overlooked interlinkages between sectors and among existing policies and institutions can become visible. This qualitative model was applied to the case of ethanol in Brazil, for which a large corpus was constructed from the scientific literature, documents and sustainability reports from sugarcane ethanol companies. We used a supervised latent Dirichlet allocation (sLDA) algorithm along with co-occurrence and network analyses. The results demonstrate this approach can be used to evaluate the interfaces between science, policy, and businesses within the WEFL-biofuels nexus. This is done by identifying how best to integrate the development of policies, governance, and stakeholder actions to support cost-effective decisions for optimal resource management and regulatory processes while enabling better integration of scientific insight and policy-making. We also identified how these four influencing factors are of vital importance within the nexus and, if properly addressed, can contribute to more holistic nexus thinking management.}
}
@article{ROHLFS2025128701,
title = {Generalization in neural networks: A broad survey},
journal = {Neurocomputing},
volume = {611},
pages = {128701},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128701},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224014723},
author = {Chris Rohlfs},
keywords = {Literature review, Deep learning, Overfitting, Causality, Domain generalization, Transfer learning, Foundation models, Multimodal, Semantic knowledge, Abstraction, Biologically-inspired},
abstract = {This paper reviews concepts, modeling approaches, and recent findings along a spectrum of different levels of abstraction of neural network models including generalization across (1) Samples, (2) Distributions, (3) Domains, (4) Tasks, (5) Modalities, and (6) Scopes. Strategies for (1) sample generalization from training to test data are discussed, with suggestive evidence presented that, at least for the ImageNet dataset, popular classification models show substantial overfitting. An empirical example and perspectives from statistics highlight how models’ (2) distribution generalization can benefit from consideration of causal relationships and counterfactual scenarios. Transfer learning approaches and results for (3) domain generalization are summarized, as is the wealth of domain generalization benchmark datasets available. Recent breakthroughs surveyed in (4) task generalization include few-shot meta-learning approaches and the emergence of transformer-based foundation models such as those used for language processing. Studies performing (5) modality generalization are reviewed, including those that integrate image and text data and that apply a biologically-inspired network across olfactory, visual, and auditory modalities. Higher-level (6) scope generalization results are surveyed, including graph-based approaches to represent symbolic knowledge in networks and attribution strategies for improving networks’ explainability. Additionally, concepts from neuroscience are discussed on the modular architecture of brains and the steps by which dopamine-driven conditioning leads to abstract thinking.}
}
@article{MARENDA20232152,
title = {Sliding pendulum isolators without secretes},
journal = {Procedia Structural Integrity},
volume = {44},
pages = {2152-2157},
year = {2023},
note = {XIX ANIDIS Conference, Seismic Engineering in Italy},
issn = {2452-3216},
doi = {https://doi.org/10.1016/j.prostr.2023.01.275},
url = {https://www.sciencedirect.com/science/article/pii/S2452321623002846},
author = {Ivan Marenda and Agostino Marioni and Marco Banfi and Roberto Dalpedri},
keywords = {friction coefficient, pendulum device, contact, isolation system},
abstract = {Over the last decades, anti-seismic devices have gained increasing interest in the civil engineering field. The introduction of the base isolation system has led to a new concept in the construction panorama in terms of human life safety, a new way of thinking on new constructions, improvement and retrofitting on existent structures. Therefore, rubber and friction isolators have been deeply investigated to hence performances and predict dynamic behaviour during an earthquake. While the response of the former is characterised by the composition of the elastomeric compound, the latter features special materials able to dissipate energy by moving on smooth surfaces. This paper focuses on friction pendulum devices and addresses its attention on the behaviour of sliding materials. It is well-known that stick-slip phenomenon occurs when friction excitation is present and, in the anti-seismic field is important to reduce it and have a well-representative mathematical law able to describe it. Therefore, Hirun International after performing several treatments of the sliding materials has set up a special processing to guarantee a stable response of the HI-M material used on pendulum devices. The paper, after a brief presentation of the special sliding material, shows a comparison between the material with and without the treatment in terms of the force-displacement law. The paper also analyses in detail the cinematic behaviour of the sliding pendulum with one or two main sliding surfaces, with and without central articulation and determines the stress distribution in the sliding surfaces for the different cases.}
}
@article{WEBB2008360,
title = {The role of teacher instructional practices in student collaboration},
journal = {Contemporary Educational Psychology},
volume = {33},
number = {3},
pages = {360-381},
year = {2008},
note = {Collaborative Discourse, Argumentation, and Learning},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2008.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X0800026X},
author = {Noreen M. Webb and Megan L. Franke and Marsha Ing and Angela Chan and Tondra De and Deanna Freund and Dan Battey},
keywords = {Instructional practices, Student collaboration},
abstract = {Prior research on collaborative learning identifies student behaviors that significantly predict student achievement, such as giving explanations of one’s thinking. Less often studied is the role of teachers’ instructional practices in collaboration among students. This article investigates the extent to which teachers engage in practices that support students’ explanations of their thinking, and how these teacher practices might be related to the nature of explanations that students give when asked by the teacher to collaborate with each other. The teachers observed here, all of whom received specific instruction in eliciting the details of student thinking, varied significantly in the extent to which they asked students to elaborate on their suggestions. This variation corresponded to variation across classrooms in the nature and extent of student explanations during collaborative conversations and to differences in student achievement.}
}
@incollection{MAURYA2010175,
title = {Chapter 8 - Computational Challenges in Systems Biology},
editor = {Edison T. Liu and Douglas A. Lauffenburger},
booktitle = {Systems Biomedicine},
publisher = {Academic Press},
address = {San Diego},
pages = {175-223},
year = {2010},
isbn = {978-0-12-372550-9},
doi = {https://doi.org/10.1016/B978-0-12-372550-9.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123725509000080},
author = {Mano Ram Maurya and Shankar Subramaniam},
abstract = {Publisher Summary
This chapter examines the challenges and some of the recent advances in computational systems biology. Research in computational systems biology has moved beyond interaction networks based simply on clustering and correlation. There are two paradigms in computational systems biology: the iterative cycle of biochemical model—mathematical model—computational model, and integration of novel data and legacy knowledge to develop context-specific biochemical, mathematical, and computational models. Challenges in building biochemical models include the complexity of proteomic states and interactions, integration of diverse data to infer biochemical interactions, and the temporal state of biochemical models. Challenges in building mathematical models include incorporating statistical/probabilistic information into analytical models, using qualitative constraints in mathematical models, and incomplete knowledge and coarse-graining. Challenges in computational modeling include the absence of knowledge about model parameters such as rate constants, local versus global concentrations of species and multiple scales of distance and time, and variation among different cell types and subpopulation variability, or variability among biological repeats. Advanced research in coarse graining will pave the way for progress in the development of multiscale multidomain modeling that can connect fundamental research in network biology to clinical research.}
}
@article{AKTAYEVA2022285,
title = {Aesthetic education: the process of teaching mathematics with the open-source software},
journal = {Transportation Research Procedia},
volume = {63},
pages = {285-293},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522002708},
author = {Alena Aktayeva and Elena Zubareva and Aibek Dautov and Kymbat Saginbayeva and Rozamgul Niyazova and Sergey Khan and Aigerim Shonasheva},
keywords = {Aesthetic education, mathematical education, software, computer programs},
abstract = {In the article one of leading aims of educating mathematics is examined is aesthetic education of student facilities of mathematics. Presentation of aesthetic beauty at her decisions possibility of students is investigated, specifying them on the decision of one problem in several ways that assists the detailed consideration of idea of aesthetic education, through Open-source Software. The technical capabilities and elegant ease of use of systems Open-source Software provides a seamless, integrated and constantly expanding system that covers the breadth and depth of mathematical computing, and is available seamlessly through any web browser along with all modern systems used in the educational process. The article will describe understanding of beauty the decision of a problem; methods of decisions that are accompanied by the use make possible a uniquely flexible and convenient approach to charting and information visualization in a mathematical calculate. Such sort of activity assists aesthetic education, allowing to develop a culture and logical thinking, forming at students a different choice, grace of decision of problems.}
}
@article{IWASE20211,
title = {Towards a Noncompliant Pedagogy of the Image: Reading Negentropic Bifurcatory Potentials in Video Images},
journal = {Video Journal of Education and Pedagogy},
volume = {6},
number = {2021},
pages = {1-27},
year = {2021},
issn = {2364-4583},
doi = {https://doi.org/10.1163/23644583-bja10020},
url = {https://www.sciencedirect.com/science/article/pii/S236445832300023X},
author = {Masayuki Iwase and Joff P. N. Bradley},
keywords = {urban film-making, critique, metamodelization, global mnemotechnical system, proletarianized knowledge, mnemonic control, artificial and living engines, machinic enslavement, negentropic bifurcation, Deleuze, Heidegger, Virilio, time-image, lectosign, spiritual automation, zooming-in/out, autistic milieus, diffractive becoming, radical pedagogy},
abstract = {The authors explore the noncompliant pedagogy of the image based on their video Autopoietic Veering: Schizo Socius of Tokyo and Vancouver (2021). It is not the kind of trendy modelized video abstract or kinetic presentation eagerly promoted by international publishers; it is a cross-cultural collaborative work intended to generate affirmative temporal ruptures of entropic habitual modes of seeing, memorizing, and thinking of human and nonhuman life in the cities of Tokyo (Japan) and Vancouver (Canada). The authors elucidate Stiegler’s (2015b) concept of a “global mnemotechnical system” that stores and produces human memories in vast digital archives and databases (tertiary retentions) through “mnemonic control” (Parisi & Goodman, 2011). The authors repurpose video images to interrupt and recontrol human perception and memories as “living engines” (Lazzarato, 2006). They foreground the philosophical work of Deleuze, Heidegger, and Virilio to rethink and revive the creative act of “critique” (Foucault, 1997) through “metamodelization” (Guattari, 1995; Manning, 2020); therefore, they plug these apparently incommensurable modes of thinking into their readings of the video’s images. They read the images as “time-images” and focus on their five dimensions that possibly activate “spiritual automation” (Deleuze, 1989), which they assess as “negentropic bifurcatory” potentials (Bradley & Kennedy, 2019).}
}
@article{ARCHAMBAULT2024102865,
title = {Ethical dimensions of algorithmic literacy for college students: Case studies and cross-disciplinary connections},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {3},
pages = {102865},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102865},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000260},
author = {Susan Gardner Archambault and Shalini Ramachandran and Elisa Acosta and Sheree Fu},
keywords = {Algorithmic literacy, Information literacy, Algorithmic bias, AI ethics, Algorithmic fairness, Computer science education},
abstract = {This article addresses three key questions related to the ethical facets of algorithmic literacy. First, it synthesizes existing literature to identify six core ethical components, including bias, privacy, transparency, accountability, accuracy, and non-maleficence. Second, a crosswalk maps the intersections of these principles across the Association of College and Research Libraries' Framework for Information Literacy for Higher Education and the Association of Computing Machinery's Code of Ethics and Professional Conduct and Joint Statement on Principles for Responsible Algorithmic Systems. This analysis reveals significant overlap on issues like unfairness and transparency, helping prioritize topics for instruction. Finally, case studies showcase pedagogical strategies for teaching ethical considerations, informed by the crosswalk. Workshops for diverse undergraduates and computer science students employed reallife instances of algorithmic bias to prompt reflection on unintended harm, contestability, and responsible development. Pre-post surveys indicated expanded critical perspectives after the interventions. By systematically examining shared values and testing instructional approaches, this study provides practical tools to shape ethical thinking on algorithms. It also demonstrates promising practices for responsibly advancing algorithmic literacy across disciplines. Ultimately, fostering interdisciplinary awareness and multipronged educational initiatives can empower students to question algorithmic authority and biases.}
}
@article{OZER20114514,
title = {An application of fuzzy information granulation in the emerging area of online sports},
journal = {Expert Systems with Applications},
volume = {38},
number = {4},
pages = {4514-4521},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.09.125},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410010821},
author = {Muammer Ozer},
keywords = {Information granulation, Fuzzy granulation, Application, Online business},
abstract = {Abstract
One of the major computational challenges that online businesses face today is to make sense of huge amount of information. Granular computing has emerged as an important conceptual and computational paradigm of information processing. As an emerging field of study, it has been suggested that granular computing at philosophical level concerns with structural thinking and at the application level concerns with structured problem solving. It has been further suggested that fuzzy information granulation, as a special case of granular computing, is likely to play an important role in the evolution of fuzzy logic and may eventually have a far-reaching impact on its applications. Responding to the calls for future studies dealing with the applications of fuzzy information granulation, this paper presents an application of the theory of fuzzy information granulation in an emerging and important area where there has not yet been any application, showing how online sports services can make sense of huge amount of data in a structured way and how they can structure their decisions. The empirical results show that despite the huge amount of data that needs to be processed, fuzzy information granulation can help online sports services make sense of it and identify meaningful granules for easier decision making.}
}
@article{CHATURVEDI2005694,
title = {Agent-based simulation for computational experimentation: Developing an artificial labor market},
journal = {European Journal of Operational Research},
volume = {166},
number = {3},
pages = {694-716},
year = {2005},
note = {Advances in Complex Systems Modeling},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2004.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0377221704004102},
author = {Alok Chaturvedi and Shailendra Mehta and Daniel Dolk and Rick Ayer},
keywords = {Artificial intelligence, Decision support systems, Simulation, Modelling systems and languages, Economics},
abstract = {This paper discusses the creation of an artificial labor market (ALM) as an agent-based simulation model. We trace the development of the ALM by adapting the traditional simulation life cycle into two main parts: the model phase and the simulation phase. In the modeling phase of the life cycle, we focus upon agent representation and specification within the virtual world. In the simulation phase, we discuss the use of scenario planning as the experimentation vehicle. Throughout, we use military recruit market as an example to illustrate the methodology. The benefits of the ALM are (1) it provides a virtual world for continuous computational experimentation, (2) it supports market segmentation by allowing “drilldowns” to finer and finer levels of granularity, and (3) when connected via a common OLAP interface to a “real world” counterpart, it facilitates a tightly integrated, persistent, “sense and respond” decision support functionality.}
}
@article{SU2024108233,
title = {Musical protein: Mapping the time sequence of music onto the spatial architecture of proteins},
journal = {Computer Methods and Programs in Biomedicine},
volume = {252},
pages = {108233},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108233},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724002281},
author = {Jun Su and Peng Zhou},
keywords = {Musical protein, Life of music, Bioinformatics, Stave, Note, Piano, Conversion of music to protein},
abstract = {Background and objective
Music, the ubiquitous language across human cultures, is traditionally considered as a form of art but has been linked to biomolecules in recent years. However, previous efforts have only been addressed on sonification of nucleic acids and proteins to produce so-called life music, the soundscape from the basic building blocks of life. In this study, we attempted to, for the first time, conduct a reverse operation of this process, i.e. conversion of music to protein (CoMtP).
Methods
A novel notion termed musical protein (MP) –– the protein defined by music –– was proposed and, on this basis, we described a computational strategy to map the time sequence of music onto the spatial architecture of proteins, which considered that each note in the stave of a music (target) can be simply characterized by two acoustical quantities and that each residue in the primary sequence of a protein (hit) was represented by amino acid descriptors.
Results
A simulated annealing (SA) algorithm was applied to iteratively generate the best matched MP hit for a music target and structural bioinformatics was then used to model spatial advanced structure for the resulting MP. We also demonstrated that some small MPs derived from music segments may have potential biological functions, which, for example, can serve as antimicrobial peptides (AMPs) to inhibit clinical bacterial strains with moderate or high antibacterial potency.
Conclusions
This work may benefit many aspects; for example, it would open a door for the hearing-impaired persons to ‘listen’ music in a biological vision and could be a mean of exposing students to the concepts of biomolecules at an earlier age through the use of auditory characteristics. The CoMtP would also facilitate the rational design of proteins with biological and medicinal significance.}
}
@article{SHEFFIELD20221149,
title = {Belief Updating and Paranoia in Individuals With Schizophrenia},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {7},
number = {11},
pages = {1149-1157},
year = {2022},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2022.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S2451902222000799},
author = {Julia M. Sheffield and Praveen Suthaharan and Pantelis Leptourgos and Philip R. Corlett},
keywords = {Belief updating, Computational psychiatry, Delusions, Paranoia, Volatility, Worry},
abstract = {Background
Persecutory delusions are among the most common delusions in schizophrenia and represent the extreme end of the paranoia continuum. Paranoia is accompanied by significant worry and distress. Identifying cognitive mechanisms underlying paranoia is critical for advancing treatment. We hypothesized that aberrant belief updating, which is related to paranoia in human and animal models, would also contribute to persecutory beliefs in individuals with schizophrenia.
Methods
Belief updating was assessed in 42 participants with schizophrenia and 44 healthy control participants using a 3-option probabilistic reversal learning task. Hierarchical Gaussian Filter was used to estimate computational parameters of belief updating. Paranoia was measured using the Positive and Negative Syndrome Scale and the revised Green et al. Paranoid Thoughts Scale. Unusual thought content was measured with the Psychosis Symptom Rating Scale and the Peters et al. Delusions Inventory. Worry was measured using the Dunn Worry Questionnaire.
Results
Paranoia was significantly associated with elevated win-switch rate and prior beliefs about volatility both in schizophrenia and across the whole sample. These relationships were specific to paranoia and did not extend to unusual thought content or measures of anxiety. We observed a significant indirect effect of paranoia on the relationship between prior beliefs about volatility and worry.
Conclusions
This work provides evidence that relationships between belief updating parameters and paranoia extend to schizophrenia, may be specific to persecutory beliefs, and contribute to theoretical models implicating worry in the maintenance of persecutory delusions.}
}
@article{SVOZIL2005845,
title = {Computational universes},
journal = {Chaos, Solitons & Fractals},
volume = {25},
number = {4},
pages = {845-859},
year = {2005},
note = {TRANSFINITE PHYSICS Treading the Path of Cantor and Einstein A collection of papers in honour of the Egyptian Engineering Scientist},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2004.11.055},
url = {https://www.sciencedirect.com/science/article/pii/S0960077904007830},
author = {Karl Svozil},
abstract = {Suspicions that the world might be some sort of a machine or algorithm existing “in the mind” of some symbolic number cruncher have lingered from antiquity. Although popular at times, the most radical forms of this idea never reached mainstream. Modern developments in physics and computer science have lent support to the thesis, but empirical evidence is needed before it can begin to replace our contemporary world view.}
}
@incollection{KENDRICK2008685,
title = {Chapter 17 The Supporting Role of Molecular Modelling and Computational Chemistry in Polymer Analysis},
editor = {John M. Chalmers and Robert J. Meier},
series = {Comprehensive Analytical Chemistry},
publisher = {Elsevier},
volume = {53},
pages = {685-734},
year = {2008},
booktitle = {Molecular Characterization and Analysis of Polymers},
issn = {0166-526X},
doi = {https://doi.org/10.1016/S0166-526X(08)00417-0},
url = {https://www.sciencedirect.com/science/article/pii/S0166526X08004170},
author = {John Kendrick},
abstract = {Publisher Summary
Molecular modeling covers a wide range of techniques and the calculation of an even wider range of properties. Although for polymers, the possibility of treating a polymer chain quantum mechanically is formidable, it is clear that the modeling approach allows calculations on monomers, dimmers, and oligomers to guide the interpretation of many spectroscopic observations with great success. For those systems, where longer times scales and larger size scales are important, molecular mechanics and molecular dynamics methods are available, but the issue of the force field and the approximations that it introduces remain significant. The key to the change in attitude to modeling and its role have to lie in the availability of mature algorithms with well-known and well-understood properties. The density functional theory method in quantum mechanics has introduced a new era in applications of quantum mechanical methods.}
}
@article{SONI2024100016,
title = {Advancements in MXene-based electrocatalysts for hydrogen evolution reaction processes: A comprehensive review},
journal = {Journal of Alloys and Compounds Communications},
volume = {3},
pages = {100016},
year = {2024},
issn = {2950-2845},
doi = {https://doi.org/10.1016/j.jacomc.2024.100016},
url = {https://www.sciencedirect.com/science/article/pii/S295028452400016X},
author = {Kunjal Soni and Rakesh Kumar Ameta},
keywords = {MXenes, 2D materials, Two-electron transfer process, Hydrogen evolution process, Electrocatalysts},
abstract = {MXenes are a newly emerging family of two-dimensional (2D) materials that include carbonitrides, nitrides, and carbides of transition metals. They have attracted much interest from scientists and researchers due to their potential use in electrocatalysts, where a two-electron transfer process is applied. Their remarkable properties, such as strong chemical and structural stability, high electrical conductivity, and large active surface area, make them effective for their potential in advanced hydrogen evolution reactions (HER). This thorough analysis starts by carefully outlining the forward-thinking advances in MXene synthesis and development. It then explores the theoretical and empirical aspects of MXene-based HER electrocatalysts. This review paper presents methods for improving the HER catalytic activity of MXene, including terminal modification, metal-atom doping, and the creation of various nanostructures to increase the density of active sites. The study clarifies current issues and new opportunities and provides a valuable framework for the future development of effective MXene-based electrocatalysts for HERs.}
}
@article{THAKIRABED20232293,
title = {The computation intelligent system of role of parental leadership in organizational familiarity in Iraqi Airways employees},
journal = {Materials Today: Proceedings},
volume = {80},
pages = {2293-2301},
year = {2023},
note = {SI:5 NANO 2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.06.318},
url = {https://www.sciencedirect.com/science/article/pii/S221478532104709X},
author = {Marwan {Thakir Abed}},
keywords = {Parental leadership, Organizational familiarity, Empowerment, Iraqi Airways},
abstract = {The research aimed to know the effect of parental leadership represented by (benevolent leadership, moral leadership, and authoritarian leadership) found in the research sample, in the organizational familiarity (employee morale, empowerment, and objective merit), the research relied on the questionnaire as a key instrument to collect the necessary data to meet its goal. As (60) forms were distributed to find the level of availability of parental leadership and organizational harmony, while (56) forms were retrieved. A set of statistical methods were used, represented by normal distribution, stability factor (Alpha Kronbach), reliability, arithmetic mean, standard deviation, and coefficient Simple correlation Pearson, multiple regression coefficient. The results showed that there is a positive correlation and effect relationship with statistically significant between parental leadership with its dimensions (benevolent leadership, moral leadership, authoritarian leadership) and organizational affiliation with its dimensions (employee morale, empowerment, and merit's Objectivity), and the research showed a direct impact relationship between parental leadership and the organizational affiliation of the studied sample. Accordingly, the research concluded that the study sample should pay attention to the nature and type of empowering workers in order to give them freedom and independence in making decisions regarding the tasks assigned to them.}
}
@article{HOYTE2006S348,
title = {Computational model of levator ani muscle stretch during vaginal delivery},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S348},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)84382-4},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006843824},
author = {L. Hoyte and P. Krysl and G. Chukkapalli and A. Majumdar and D.J. Choi and A. Trivedi and S.K. Warfield and M.S. Damaser}
}
@article{MACHADO2023101290,
title = {A multiple criteria framework to assess learning methodologies},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101290},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000603},
author = {Rafaela Heloisa Carvalho Machado and Samuel Vieira Conceição and Renata Pelissari and Sarah Ben Amor and Thiago Lombardi Resende},
keywords = {Active learning methodologies, Skills, Multiple criteria decision making, MCDA, MCDM},
abstract = {New job skills required by the professional market have been causing significant changes in the learning process of undergraduate students. Different learning methodologies can be adopted to assist in the development of those skills, and the process of choosing the most suitable learning methodology for each situation may be complex, involving multiple and conflicting criteria. In order to support the choice of learning methodologies for the development of the “4C skills”, i.e, collaboration, communication, creativity and critical thinking, we propose a new framework based on the multiple criteria decision-making approach PROMETHEE II (Preference Ranking Organization Method for Enrichment of Evaluations), considering as criteria the “4C skills”, student motivation, level of learning, student comfort, decision-making capacity and time required for class preparation. Passive methods and active learning methodologies such as Guided Reciprocal Peer Questioning (GRPQ), Think-Pair-Share (TPS), and Problem Based Learning (PBL) are compared. Each methodology was applied to three groups of students of Industrial Engineering of a Brazilian University, totaling 138 students. As a result, PBL obtained the best assessment in the three groups, followed by GRPQ. The proposed framework validates the assessment of learning methodologies, providing a structure and guideline for its replication in other educational institutions.}
}
@article{CRILLY2021309,
title = {The Evolution of “Co-evolution” (Part I): Problem Solving, Problem Finding, and Their Interaction in Design and Other Creative Practices},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {309-332},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000915},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Design history, Interdisciplinarity},
abstract = {One of the most influential descriptions of design activity emphasizes how problems and solutions “co-evolve.” This concept has somehow escaped critical review and cross-disciplinary comparison, resulting in a fragmented approach to the subject. Reviewing the published literature on design co-evolution reveals that the term is used to refer to a range of distinct concepts, and the study of co-evolution has generated a number of elaborations and alternatives. Reviewing the broader literature in design and other disciplines further reveals that discussions of design co-evolution are disconnected from the history of relevant concepts in design research, and disconnected from a range of relevant concepts in other disciplines that describe creative work. Here I examine what the different concepts of design co-evolution are, how they have been modified and what they are related to. This leads to questioning the distinction between problems and solutions, defining them in relative terms, and drawing a connection between design co-evolution and design fixation.}
}
@article{WANG20231225,
title = {Parameterization Design of 3D Fractal Images in Packaging Design Based on Genetic Algorithm},
journal = {Procedia Computer Science},
volume = {228},
pages = {1225-1232},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.104},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301935X},
author = {Jinxia Wang},
keywords = {Genetic Algorithm, Packaging Design, 3D Fractal Image, NSGA - II},
abstract = {Packaging design, as an important element in product appearance, can directly affect customers' sensory perception of the product. Many universities even offer packaging design majors, which mainly use natural science and aesthetic knowledge to promote product sales. However, many old brands remain complacent and their packaging design still adopts traditional thinking, which to some extent affects their sales. Therefore, this article decided to use genetic algorithms as a tool to parameterize the 3D fractal images in packaging design, aiming to create more creative and eye-catching packaging designs. At the end of this article, an experiment was conducted on two branches of a certain brand. Branch 1 tried out the new design provided in this article, while Branch 2 continued to use the original design. After Branch 1 fully adopted the design, sales skyrocketed, from the original daily sales of 50-60 units to 70-85 units. Branch 2 remained unchanged, with a sharp contrast.}
}
@article{ZHAO2024109027,
title = {Towards the definition of spatial granules},
journal = {Fuzzy Sets and Systems},
volume = {490},
pages = {109027},
year = {2024},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2024.109027},
url = {https://www.sciencedirect.com/science/article/pii/S0165011424001738},
author = {Liquan Zhao and Yiyu Yao},
keywords = {Granularity, Fineness, Subsethood, Coarse-fine relation, Quotient join, Quotient meet, Granular space, Spatial granular computing},
abstract = {Three basic issues of granular computing are construction or definition of granules, measures of granules, and computation or reasoning with granules. This paper reviews the main theories of granular computing and introduces the definition of spatial granules. A granule is composed of one or more atomic granules. The rationality of this definition is explained from the four aspects: simplicity, applicability, measurability and visualization. A one-to-one correspondence is established between the granules and the points in the unit hypercube, and the coarsening and refining of the granules are the descending and ascending dimensions of the points, respectively. The weak fuzzy tolerance relation and weak fuzzy equivalence relation are defined so as to study on all fuzzy binary relations. The notion of layer granularity/fineness is introduced and each granule can be easily denoted by two numbers, which can be used to pre-process macro knowledge space and greatly improve the search speed. This paper also discusses the main properties of granules including the necessary and sufficient conditions of coarse-fine relation and the main principles of granular space.}
}
@article{CHISCI1995487,
title = {Fast Computation of Stabilizing Predictive Control Laws},
journal = {IFAC Proceedings Volumes},
volume = {28},
number = {5},
pages = {487-493},
year = {1995},
note = {3rd IFAC/IFIP Workshop on Algorithms and Architectures for Real-Time Control 1995 (AARTC'95), Ostend, Belgium, 31 May-2 June 1995},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)47270-3},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017472703},
author = {L. Chisci and A. Garulli and G. Zappa},
keywords = {Predictive control, linear quadratic regulators, control algorithms, fast parallel algorithms, fast Kalman algorithms, computational methods, adaptive control},
abstract = {A fast algorithm for Linear Quadratic(LQ) control with linear equality constraints is derived and exploited for stabilizing predictive control synthesis. The algorithm requires only O(Nn) computations for an nth order plant and N-steps prediction horizon, and possesses a remarkable numerical accuracy.}
}
@article{PIAW20114019,
title = {Establishing a Brain Styles Test: The YBRAINS Test},
journal = {Procedia - Social and Behavioral Sciences},
volume = {15},
pages = {4019-4027},
year = {2011},
note = {3rd World Conference on Educational Sciences - 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.04.407},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811009530},
author = {Chua Yan Piaw},
keywords = {Brain style, thinking and learning, YBRAINS, validity and reliability},
abstract = {Teaching with knowledge of students’ thinking and learning styles increases its effectiveness. The YBRAINS test is developed to help school teachers to understand the thinking and learning readiness levels of their students in the process of providing effective teaching and learning activities. The test was established based on theories and brain experiment research evidences. This article reports the rationale of establishing the test and its validity and reliability.}
}
@article{JOHNSON200033,
title = {Thinking ahead: the case for motor imagery in prospective judgements of prehension},
journal = {Cognition},
volume = {74},
number = {1},
pages = {33-70},
year = {2000},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(99)00063-3},
url = {https://www.sciencedirect.com/science/article/pii/S0010027799000633},
author = {Scott H Johnson},
keywords = {Motor imagery, Prospective judgements, Prehension},
abstract = {How similar are judgements concerning how we expect to perform an action, to how we actually behave? The veracity of such prospective action judgements, and the mechanisms by which they are computed, was explored in a series of tasks that involved either grasping (MC conditions) or thinking about grasping (PJ conditions) a dowel presented in various orientations. PJs concerning limits of comfortable hand supination and pronation when turning a dowel in the picture plane were highly consistent with values obtained during actual hand rotation (Exp. 1). The same was true for judgements regarding the level of awkwardness involved in adopting a prescribed grip (e.g. overhand with right hand) for dowels in various picture plane orientations (Exp. 2). When allowed to select the most natural grip (overhand versus underhand) or hand (left versus right) for engaging dowels in these orientations, subjects preferred virtually identical responses in both PJ and MC conditions. In both instances, they consistently chose the least awkward response options. As would be expected for actual movements, PJs involving awkward hand postures had longer response times (RTs), and were less accurate. Likewise, latencies for both grip and hand judgements tended to increase as a function of the angular distance between the current positions of subjects’ hands, and the orientation of the chosen posture. Together, these findings are consistent with a the hypothesis that PJs involve mentally simulated actions, or motor imagery. These results suggest that motor imagery does not depend on the existence of a completed premotor plan (Jeannerod, 1994), but may instead be involved in the planning process itself. A provisional model for the involvement of imagery in motor planning is outlined, as are a set of criteria for evaluating claims of the involvement of motor imagery in problem solving.}
}
@article{DENEF20071096,
title = {Computational complexity of the landscape: Part I},
journal = {Annals of Physics},
volume = {322},
number = {5},
pages = {1096-1142},
year = {2007},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2006.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0003491606001382},
author = {Frederik Denef and Michael R. Douglas},
abstract = {We study the computational complexity of the physical problem of finding vacua of string theory which agree with data, such as the cosmological constant, and show that such problems are typically NP hard. In particular, we prove that in the Bousso–Polchinski model, the problem is NP complete. We discuss the issues this raises and the possibility that, even if we were to find compelling evidence that some vacuum of string theory describes our universe, we might never be able to find that vacuum explicitly. In a companion paper, we apply this point of view to the question of how early cosmology might select a vacuum.}
}
@article{LEE2021100737,
title = {Turbulent boundary layer trailing-edge noise: Theory, computation, experiment, and application},
journal = {Progress in Aerospace Sciences},
volume = {126},
pages = {100737},
year = {2021},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2021.100737},
url = {https://www.sciencedirect.com/science/article/pii/S0376042121000427},
author = {Seongkyu Lee and Lorna Ayton and Franck Bertagnolio and Stephane Moreau and Tze Pei Chong and Phillip Joseph},
keywords = {Trailing-edge noise, Aeroacoustics, Turbulent boundary layer},
abstract = {When the pressure fluctuations caused by turbulence vorticity in the boundary layer are scattered by a sharp trailing edge, acoustic energy is generated and propagated to the far field. This trailing edge noise is emitted from aircraft wings, turbomachinery blades, wind turbine blades, helicopter blades, etc. Being dominant at high frequencies, this trailing-edge noise is a key element that annoys human hearing. This article covers virtually the entire landscape of modern research into trailing-edge noise including theoretical developments, numerical simulations, wind tunnel experiments, and applications of trailing-edge noise. The theoretical approach includes Green’s function formulations, Wiener–Hopf methods that solve the mixed boundary-value problem, Howe’s and Amiet’s models that relate the wall pressure spectrum to acoustic radiation. Recent analytical developments for poroelasticity and serrations are also included. We discuss a hierarchy of numerical approaches that range from semi-empirical schemes that estimate the wall pressure spectrum using mean-flow and turbulence statistics to high-fidelity unsteady flow simulations such as Large Eddy Simulation (LES) or Direct Numerical Simulation (DNS) that resolve the sound generation and scattering process based on the first-principles flow physics. Wind tunnel experimental research that provided benchmark data for numerical simulations and unravel flow physics is reviewed. In each theoretical, numerical, and experimental approach, noise control methods for mitigating trailing-edge noise are discussed. Finally, highlights of practical applications of trailing-edge noise prediction and reduction to wind turbine noise, fan noise, and rotorcraft noise are given. The current challenges in each approach are summarized with a look toward the future developments. The review could be useful as a primer for new researchers or as a reference point to the state of the art for experienced professionals.}
}
@article{ALTARABICHI2023118528,
title = {Fast Genetic Algorithm for feature selection — A qualitative approximation approach},
journal = {Expert Systems with Applications},
volume = {211},
pages = {118528},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118528},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422016049},
author = {Mohammed Ghaith Altarabichi and Sławomir Nowaczyk and Sepideh Pashami and Peyman Sheikholharam Mashhadi},
keywords = {Feature selection, Evolutionary computation, Genetic Algorithm, Particle Swarm Intelligence, Fitness approximation, Meta-model, Optimization},
abstract = {Evolutionary Algorithms (EAs) are often challenging to apply in real-world settings since evolutionary computations involve a large number of evaluations of a typically expensive fitness function. For example, an evaluation could involve training a new machine learning model. An approximation (also known as meta-model or a surrogate) of the true function can be used in such applications to alleviate the computation cost. In this paper, we propose a two-stage surrogate-assisted evolutionary approach to address the computational issues arising from using Genetic Algorithm (GA) for feature selection in a wrapper setting for large datasets. We define “Approximation Usefulness” to capture the necessary conditions to ensure correctness of the EA computations when an approximation is used. Based on this definition, we propose a procedure to construct a lightweight qualitative meta-model by the active selection of data instances. We then use a meta-model to carry out the feature selection task. We apply this procedure to the GA-based algorithm CHC (Cross generational elitist selection, Heterogeneous recombination and Cataclysmic mutation) to create a Qualitative approXimations variant, CHCQX. We show that CHCQX converges faster to feature subset solutions of significantly higher accuracy (as compared to CHC), particularly for large datasets with over 100K instances. We also demonstrate the applicability of the thinking behind our approach more broadly to Swarm Intelligence (SI), another branch of the Evolutionary Computation (EC) paradigm with results of PSOQX, a qualitative approximation adaptation of the Particle Swarm Optimization (PSO) method. A GitHub repository with the complete implementation is available.22https://github.com/Ghaith81/Fast-Genetic-Algorithm-For-Feature-Selection.}
}
@article{MILLER1993205,
title = {Educational tools for computational modelling},
journal = {Computers & Education},
volume = {21},
number = {3},
pages = {205-261},
year = {1993},
issn = {0360-1315},
doi = {https://doi.org/10.1016/0360-1315(93)90019-F},
url = {https://www.sciencedirect.com/science/article/pii/036013159390019F},
author = {Rob Miller and Jon Ogborn and Jonathan Briggs and Derek Brough and Joan Bliss and Richard Boohan and Tim Brosnan and Harvey Mellar and Babis Sakonidis},
abstract = {The paper reports both a theoretical analysis and a comparison of educational tools for computational modelling, and describes three prototype tools developed in the Programme for use in empirical studies of children reasoning with the aid of computational tools, together with an outline of the result obtained by using the tools with children.}
}
@article{JIANG2024109208,
title = {Surrogate-based Shape Optimization Design for the Stable Descent of Mars Parachutes},
journal = {Aerospace Science and Technology},
volume = {150},
pages = {109208},
year = {2024},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2024.109208},
url = {https://www.sciencedirect.com/science/article/pii/S1270963824003390},
author = {Lulu Jiang and Guanhua Chen and Xiaopeng Xue and Xin Pan and Gang Chen},
keywords = {Supersonic Parachute, Mars atmosphere, Aerodynamic Optimization, Shape design, Wide Speed Range},
abstract = {The crucial role that the supersonic parachute plays in space exploration missions has been widely recognized, as it directly impacts the safe landing of probes. However, parachute models with optimization on different aerodynamic performances often involve design conflicts with each other. Additionally, the parachute design focusing on a single point cannot fully adapt to different speed ranges during stable descent. This complexity makes it challenging to use traditional shape design methods, which rely on empirical knowledge, to address these coupled design issues. Faced with the design challenges of Mars parachutes, this study, inspired by aircraft aerodynamic optimization principles, establishes a shape design method specifically for the stable descent phase of Mars parachutes. The method combines numerical simulation and surrogate-based optimization strategies, aiming to enhance the overall performance during stable descent and meet various demands of different exploration missions. Meanwhile, by providing a rapid estimate of the shape during the design phase, the method significantly improves computational efficiency. The optimal models effectively balance comprehensive performance in the supersonic-transonic-subsonic speed domain by conducting shape optimization research on the disk-gap-band parachute using the surrogate-based optimization strategy. Also, it exhibits better deceleration and stability across the entire speed range compared to the base model, even when deviating from the design Mach number. Importantly, the advantages of canopy-only optimization for drag performance extend to the capsule-canopy two-body system, enhancing the drag performance of the canopy in the two-body system. This strategic approach reduces the transient calculation time for the two-body system, further improving computational efficiency. The method provides a practical and forward-thinking solution for the design of Mars parachutes.}
}
@article{ZHANG2025111031,
title = {Constrained multi-scale dense connections for biomedical image segmentation},
journal = {Pattern Recognition},
volume = {158},
pages = {111031},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.111031},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324007829},
author = {Jiawei Zhang and Yanchun Zhang and Hailong Qiu and Tianchen Wang and Xiaomeng Li and Shanfeng Zhu and Meiping Huang and Jian Zhuang and Yiyu Shi and Xiaowei Xu},
keywords = {Multi-scale dense connections, Image segmentation, Network architecture search, Feature fusion},
abstract = {Multi-scale dense connection has been widely used in the biomedical image community to enhance the segmentation performance. In this way, features from all or most scales are aggregated or iteratively fused. However, by analyzing the details, we discover that some connections involving distant scales may not contribute to, or even harm, the performance, while they always introduce a noticeable increase in computational cost. In this paper, we propose constrained multi-scale dense connections (CMDC) for biomedical image segmentation. In contrast to current general lightweight approaches, we first introduce two methods, a naive method and a network architecture search (NAS)-based method, to remove redundant connections and verify the optimal connection configuration, thereby improving overall efficiency and accuracy. The results demonstrate that the two approaches obtain a similar optimal configuration in which most features at the adjacent scales are connected. Then, we applied the optimal configuration to various backbone networks to build constrained multi-scale dense networks (CMD-Net). Experimental results evaluated on eight image segmentation datasets covering biomedical images and natural images demonstrate the effectiveness of CMD-Net across a variety of backbone networks (FCN, U-Net, DeepLabV3, SegNet, FCNsa, ConvUNeXt) with a much lower increase in computational cost. Furthermore, CMD-Net achieves state-of-the-art performance on four publicly available datasets. We believe that the CMDC method can offer valuable insight for ways to engage in dense connectivity at multiple scales within communities. The source code has been made available at https://github.com/JerRuy/CMD-Net.}
}
@article{NUNEZV2024101173,
title = {Recommendation system using bio-inspired algorithms for urban orchards},
journal = {Internet of Things},
volume = {26},
pages = {101173},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101173},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524001148},
author = {Juan M. {Núñez V.} and Juan M. Corchado and Diana M. Giraldo and Sara Rodríguez-González and Fernando {De la Prieta}},
keywords = {Internet of Things, Bio-inspired algorithms, Urban orchards, Lettuce crops, Social design},
abstract = {According to the Food and Agriculture Organization of the United Nations (FAO), climate change is exponentially affecting agricultural production worldwide, with food prices expected to increase by up to 90 percent by 2030 and hunger and malnutrition rates to rise by 2050. This paper presents the development of a platform based on the Internet of Things (IoT) for monitoring urban gardens as a strategy to mitigate hunger, promote food sovereignty and circular economy in areas of food shortage. To this end, an Internet of Things (IoT) architecture is proposed and implemented that involves a social design layer that allows an effective transfer of knowledge to communities and a recommendation system based on evolutionary computation to optimize and maximize the productivity of urban orchards, and thus contribute to the 2030 agenda of the Sustainable Development Goals (SDGs). Finally, three experiments in urban gardens are shown to validate evolutionary computation and artificial intelligence models, such as multiple linear regression, genetic algorithms, ant colony algorithms and spatial estimation and inference algorithms such as the Kriging algorithm. The productivity of urban lettuce orchards is increased between 25 and 45%.}
}
@article{ZILLES20101072,
title = {The computational complexity of avoiding spurious states in state space abstraction},
journal = {Artificial Intelligence},
volume = {174},
number = {14},
pages = {1072-1092},
year = {2010},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2010.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370210000950},
author = {Sandra Zilles and Robert C. Holte},
keywords = {Abstraction, Heuristic search, Planning},
abstract = {Abstraction is a powerful technique for speeding up planning and search. A problem that can arise in using abstraction is the generation of abstract states, called spurious states, from which the goal state is reachable in the abstract space but for which there is no corresponding state in the original space from which the goal state can be reached. Spurious states can be harmful, in practice, because they can create artificial shortcuts in the abstract space that slow down planning and search, and they can greatly increase the memory needed to store heuristic information derived from the abstract space (e.g., pattern databases). This paper analyzes the computational complexity of creating abstractions that do not contain spurious states. We define a property—the downward path preserving property (DPP)—that formally captures the notion that an abstraction does not result in spurious states. We then analyze the computational complexity of (i) testing the downward path preserving property for a given state space and abstraction and of (ii) determining whether this property is achievable at all for a given state space. The strong hardness results shown carry over to typical description languages for planning problems, including sas+ and propositional strips. On the positive side, we identify and illustrate formal conditions under which finding downward path preserving abstractions is provably tractable.}
}
@article{SELBY20001491,
title = {Computational Aspects of Complex Securities},
journal = {Journal of Economic Dynamics and Control},
volume = {24},
number = {11},
pages = {1491-1497},
year = {2000},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(99)00084-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188999000846},
author = {Michaël J.P Selby}
}
@article{ATALLAH2022B2,
title = {Society for Maternal-Fetal Medicine Special Statement: Cognitive bias and medical error in obstetrics—challenges and opportunities},
journal = {American Journal of Obstetrics and Gynecology},
volume = {227},
number = {2},
pages = {B2-B10},
year = {2022},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2022.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0002937822003143},
author = {Fouad Atallah and Rebecca F. Hamm and Christina M. Davidson and C. Andrew Combs},
keywords = {decision-making, diagnostic error, disparities, implicit bias, inequity, medical error, racism},
abstract = {The processes of diagnosis and management involve clinical decision-making. However, decision-making is often affected by cognitive biases that can lead to medical errors. This statement presents a framework of clinical thinking and decision-making and shows how these processes can be bias-prone. We review examples of cognitive bias in obstetrics and introduce debiasing tools and strategies. When an adverse event or near miss is reviewed, the concept of a cognitive autopsy—a root cause analysis of medical decision-making and the potential influence of cognitive biases—is promoted as part of the review process. Finally, areas for future research on cognitive bias in obstetrics are suggested.}
}
@article{ELLIOT201878,
title = {A Proposal to Integrate System Dynamics and Carbon Metabolism for Urban Planning},
journal = {Procedia CIRP},
volume = {69},
pages = {78-82},
year = {2018},
note = {25th CIRP Life Cycle Engineering (LCE) Conference, 30 April – 2 May 2018, Copenhagen, Denmark},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2017.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212827117307618},
author = {Thomas Elliot and Benedetto Rugani and Javier Babí Almenar and Samuel Niza},
keywords = {Life-cycle thinking, system dynamics, urban metabolism, urban planning},
abstract = {Coupling of life-cycle thinking with urban metabolism (UM) has the potential to improve sustainable urban planning. Current urban metabolism models are largely ‘black-box’ methods which do not reveal the non-linearity of feedback loops and complex internal dynamics of urban systems. The integration of system dynamics (SD) with UM based on a life-cycle thinking approach can provide built environment professionals (e.g. town planners, civil engineers, architects) with a ‘transparent-box’ solution for assessing the potential of urban projects, plans, and their implementation. This paper describes the development of a method that integrates input-output (IO) table flows with SD modelling to improve the completeness of UM assessments. This modelling framework can also allow for a ‘nested’ multi-region assessment which takes into account sustainability burdens consequent to urban system changes occurring elsewhere in the national and/or global economy. Pros and cons of this proposal are showcased by the illustration of a model for Lisbon.}
}
@article{TEO2024102655,
title = {Age-appropriate adaptation of creativity tasks for infants aged 12–24 months},
journal = {MethodsX},
volume = {12},
pages = {102655},
year = {2024},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2024.102655},
url = {https://www.sciencedirect.com/science/article/pii/S2215016124001092},
author = {Ling Zheng Teo and Victoria Leong},
keywords = {Precursors of creativity, Infancy, Measurements of creativity},
abstract = {Creativity is an important skill that relates to innovation, problem-solving and artistic achievement. However, relatively little is known about the early development of creative potential in very young children, in part due to a paucity of tasks suitable for use during infancy. Current measures of creativity in early childhood include the Unusual Box Test, Torrance's Thinking Creatively in Action and Movement (TCAM) task and the Toca Kitchen Monsters task. These tasks are designed for children aged above 12, 36 and 18 months respectively, but very few measures of creativity can be used for infants aged below 2. Accordingly, here we report age-appropriate adaptations of TCAM and Toca Kitchen Monsters tasks for infants as young as 12 to 24 months. Considerations taken into account include (1) infants’ cognitive capacities (i.e., attention span, language comprehension skills, motor skills, and approach to play), and (2) practicality of the stimuli, including suitability for use amid the COVID-19 pandemic. The modified creativity battery for infants includes three tasks: Music Play, Object Play and Exploratory Play tasks. The task protocols elaborated in this paper are intended to facilitate studies on the early development of creativity in infants aged between 12 and 24 months. Primary highlights include:•Age-appropriate adaptation of creativity tasks for use with infants aged between 12 and 24 months.•Consideration of infants’ cognitive capacities and stimulus practicality.•Innovative use of movement as expression of infants’ creative behaviour.}
}
@article{KUMAR20101805,
title = {A generalized computational approach to stability of static equilibria of nonlinearly elastic rods in the presence of constraints},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {199},
number = {25},
pages = {1805-1815},
year = {2010},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2010.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045782510000654},
author = {Ajeet Kumar and Timothy J. Healey},
keywords = {Stability, Elasticity, Rods, Constraints},
abstract = {We present a generalized approach to stability of static equilibria of nonlinearly elastic rods, subjected to general loading, boundary conditions and constraints (of both point-wise and integral type), based upon the linearized dynamics stability criterion. Discretization of the governing equations leads to a non-standard (singular) generalized eigenvalue problem. A new efficient sparse-matrix-friendly algorithm is presented to determine its few left-most eigenvalues, which, in turn, yield stability/instability information. For conservative problems, the eigenvalue problem arising from the linearized dynamics stability criterion is also shown to be equivalent to that arising in the determination of constrained local minima of the potential energy. We illustrate the method with several examples. A novel variational formulation for extensible and unshearable rods is also proposed within the context of one of the example problems.}
}
@article{PAN2025125506,
title = {CISL-PD: A deep learning framework of clinical intervention strategies for Parkinson’s disease based on directional counterfactual Dual GANs},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125506},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125506},
url = {https://www.sciencedirect.com/science/article/pii/S095741742402373X},
author = {Changrong Pan and Yu Tian and Lingyan Ma and Tianshu Zhou and Shuyu Ouyang and Jingsong Li},
keywords = {Parkinson’s disease, Intervention strategies, Counterfactual generation, Generative Adversarial Network},
abstract = {Parkinson’s disease (PD) is a prevalent chronic neurodegenerative disorder characterized by both motor and non-motor symptoms. The significant heterogeneity among PD patients poses a major challenge for treatment interventions. Current clinical interventions for PD primarily target motor symptoms, often neglecting non-motor symptoms, which can lead to unnecessary complications in non-motor symptoms while treating motor symptoms. Therefore, it is crucial to provide comprehensive and precise intervention strategies that encompass both symptom types. To address this issue, we develop a deep learning framework of clinical intervention strategies for PD (CISL-PD) based on counterfactual thinking. This framework introduces Directional Counterfactual Dual Generative Adversarial Networks (DCD-GANs), which apply various counterfactual constraints to longitudinal data to generate practical and plausible counterfactual instances aligned with clinical reality. By analyzing these counterfactual instances and their differences from the original instances, we explore PD intervention strategies with duration-specific fine regulation of multidimensional features. Experiments conducted on 374 PD patients from the Parkinson’s Progression Markers Initiative (PPMI) demonstrate that the counterfactual instances generated by DCD-GANs surpass other state-of-the-art models in terms of similarity (0.307 ± 0.246), sparsity (0.513 ± 0.161), smoothness (0.238 ± 0.135), and trend consistency (0.100 ± 0.089). From these generated counterfactual instances, we develop three clinically feasible intervention strategies that address both motor and non-motor symptoms and identify corresponding patterns of PD with distinct progression differences. Validation on an independent cohort of 351 patients from the National Institute of Neurological Disorders and Stroke Parkinson’s Disease Biomarkers Program (PDBP) confirmed the framework’s robustness and generalizability. By offering precise, multidimensional intervention strategies that can address both motor and non-motor symptoms, the CISL-PD framework has the potential to enhance patient outcomes, reduce complications, improve overall quality of life, and guide clinical decision-making.}
}
@article{ZHANG2024100667,
title = {Research on the application value of Multimedia-Based virtual reality technology in drama education activities},
journal = {Entertainment Computing},
volume = {50},
pages = {100667},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100667},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124000351},
author = {Bingyu Zhang and Wenwen Jiang},
keywords = {Multimedia, Virtual reality, Academic technology, Drama education, and ANOVA},
abstract = {The research and moral use of academic technology focuses on developing, implementing, and overseeing the use of suitable technical resources and procedures to enhance learning and achievement. Multimedia has found its position in some form as an educational technology platform in the contemporary environment of academic universities. The use of virtual reality software as an intellectual tool and learning provider allows students to perform cognitive rehabilitation of preexisting information frameworks. People are paying more and more attention to how preschoolers' holistic skills develop as education reform progresses. Drama education is incorporated into the school curriculum to enhance young children's artistic, intellectual, and linguistic skills. Therefore, this study aims to examine the potential of multimedia-based virtual reality technology (MVRT) in drama education. The participants in this study were students from different universities in China. Students were exposed to multimedia-based virtual reality technology, and its efficacy was assessed using a statistical analytic approach called Analysis of variance (ANOVA). Drama understanding rate, educational improvement ratio, teaching quality rate, student achievement ratio, computation time, and parental support rate are among the performance metrics used to assess performance. Multimedia-based virtual reality technology (MVRT) for drama education showed outstanding success, with a 98% improvement ratio in educational outcomes and higher teaching quality. Students exhibited improved performance, supported by solid parental approval, demonstrating the effectiveness of MVRT in enhancing educational experiences.}
}
@article{NOROOZI2019295,
title = {Multidisciplinary innovations and technologies for facilitation of self-regulated learning},
journal = {Computers in Human Behavior},
volume = {100},
pages = {295-297},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302638},
author = {Omid Noroozi and Sanna Järvelä and Paul A. Kirschner},
abstract = {Technology-enhanced learning environments provide ample opportunities for learners to self-regulate their learning processes and activities for achieving the intended learning outcomes in various disciplines from soft to hard sciences and from humanities to the natural and social sciences. This special issue discusses the emerging technological advancements and cutting-edge research on self-regulated learning dealing with different cognitive, motivational, emotional, and social processes of learning both at the individual and group levels. Specifically, it discusses how to optimally use advanced technologies to facilitate learners’ self-regulated learning for achieving their own individual learning needs and goals. In this special issue, seven researchers/research teams from the fields of collaborative learning, computational thinking, educational psychology, and learning analytics presented contributions to self-regulated learning with the goal of stimulating cross-border discussion in the field.}
}
@article{GALLISTEL201266,
title = {Extinction from a rationalist perspective},
journal = {Behavioural Processes},
volume = {90},
number = {1},
pages = {66-80},
year = {2012},
note = {Society for the Quantitative Analyses of Behavior: Extinction},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2012.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0376635712000447},
author = {C.R. Gallistel},
keywords = {Acquisition, Extinction, Partial reinforcement, Spontaneous recovery, Renewal, Reinstatement, Resurgence, Information theory, Bayesian inference},
abstract = {The merging of the computational theory of mind and evolutionary thinking leads to a kind of rationalism, in which enduring truths about the world have become implicit in the computations that enable the brain to cope with the experienced world. The dead reckoning computation, for example, is implemented within the brains of animals as one of the mechanisms that enables them to learn where they are (Gallistel, 1990, Gallistel, 1995). It integrates a velocity signal with respect to a time signal. Thus, the manner in which position and velocity relate to one another in the world is reflected in the manner in which signals representing those variables are processed in the brain. I use principles of information theory and Bayesian inference to derive from other simple principles explanations for: (1) the failure of partial reinforcement to increase reinforcements to acquisition; (2) the partial reinforcement extinction effect; (3) spontaneous recovery; (4) renewal; (5) reinstatement; (6) resurgence (aka facilitated reacquisition). Like the principle underlying dead-reckoning, these principles are grounded in analytic considerations. They are the kind of enduring truths about the world that are likely to have shaped the brain's computations.}
}
@article{BAKEEVA2022676,
title = {Increasing the student talking time parameter under the digitalization in transport engineering learning},
journal = {Transportation Research Procedia},
volume = {63},
pages = {676-685},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.062},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522003179},
author = {L Bakeeva and L Brylevskaya and L Gonchar and E Pastukhova and Y Romanova and O Skepko},
keywords = {Digitalization of education, transport engineering, student talking time, study-train-explain methodology},
abstract = {The most recent information technologies have become an integral part of modern life. As the study shows, along with the obvious benefits, their use can lead to negative consequences, namely the loss of communication and soft skills, changes in the ability to absorb information, decreased motivation to acquire new knowledge among the younger age group. The authors propose a new methodology for organizing the educational process Study-Train-Explain. The aim of the method is to increase the Student Talking Time parameter to develop the skills of mathematical data analysis, systematic and analytical thinking to master the methods of description and construction of mathematical model of the phenomenon or process. These competencies are extremely in demand in the professional field related to the organization of transportation and operation of transport-technological machines and complexes under the conditions of digitalization of global processes. The article presents an algorithm and the results of the experimental training process carried out by the authors according to the specified methodology.}
}
@article{AGRE19951,
title = {Computational research on interaction and agency},
journal = {Artificial Intelligence},
volume = {72},
number = {1},
pages = {1-52},
year = {1995},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0004370294000545},
author = {Philip E. Agre},
abstract = {Recent research in artificial intelligence has developed computational theories of agents' involvements in their environments. Although inspired by a great diversity of formalisms and architectures, these research projects are unified by a common concern: using principled characterizations of agents' interactions with their environments to guide analysis of living agents and design of artificial ones. This article offers a conceptual framework for such theories, surveys several other fields of research that hold the potential for dialogue with these new computational projects, and summarizes the principal contributions of the articles in this special double volume. It also briefly describes a case study in these ideas—a computer program called Toast that acts as a short-order breakfast cook. Because its designers have discovered useful structures in the world it inhabits, Toast can employ an extremely simple mechanism to decide what to do next.}
}
@article{NAJJAR19991907,
title = {Advances in the dataflow computational model},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {1907-1929},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00070-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000708},
author = {Walid A Najjar and Edward A Lee and Guang R Gao},
keywords = {Computational models, Dataflow, Multithreaded computer architecture, von Neumann computer, Dataflow history, Memory models},
abstract = {The dataflow program graph execution model, or dataflow for short, is an alternative to the stored-program (von Neumann) execution model. Because it relies on a graph representation of programs, the strengths of the dataflow model are very much the complements of those of the stored-program one. In the last thirty or so years since it was proposed, the dataflow model of computation has been used and developed in very many areas of computing research: from programming languages to processor design, and from signal processing to reconfigurable computing. This paper is a review of the current state-of-the-art in the applications of the dataflow model of computation. It focuses on three areas: multithreaded computing, signal processing and reconfigurable computing.}
}
@article{SNODGRASS20161,
title = {Instructional supports for students with disabilities in K-5 computing: Findings from a cross-case analysis},
journal = {Computers & Education},
volume = {100},
pages = {1-17},
year = {2016},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131516300999},
author = {Melinda R. Snodgrass and Maya Israel and George C. Reese},
keywords = {Universal design for learning, Students with disabilities, Pedagogy, Supports},
abstract = {As computer programming and computational thinking (CT) become more integrated into K-12 instruction, content teachers and special educators need to understand how to provide instructional supports to a wide range of learners, including students with disabilities. This cross-case analysis study examined the supports that two students with disabilities, who were initially disengaged during computing activities, received during computing instruction. Data revealed that students' support needs during computing activities were not CT-specific. Rather, supports specific to these students' needs that were successful in other educational areas were also successful and sufficient in CT. Although additional studies would need to be conducted to ascertain the transferability of these findings to other contexts and students, our results contribute evidence that students with disabilities can and should participate in CT and be provided with the supports they need, just as in all other areas of the curriculum. We present a framework for evaluating student engagement to identify student-specific supports and, when needed, refine the emerging K-12 CT pedagogy to facilitate full participation of all students. We then offer a list of four implications for practice based on the findings.}
}
@incollection{CHORAFAS2004141,
title = {7 - Five models by the Basel Committee for computation of operational risk},
editor = {Dimitris N. Chorafas},
booktitle = {Operational Risk Control with Basel II},
publisher = {Butterworth-Heinemann},
address = {Oxford},
pages = {141-162},
year = {2004},
isbn = {978-0-7506-5909-3},
doi = {https://doi.org/10.1016/B978-075065909-3.50009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780750659093500098},
author = {Dimitris N. Chorafas},
abstract = {Publisher Summary
This chapter analyzes the four methods of capital allocation for operational risk by the Basel Committee on Banking Supervision: (1) the basic indicator approach, (2) standard approach, (3) internal measurement approach, and (4) loss distribution approach. The chapter also explains why the internal measurement approach and loss distribution approach require leadership in databasing and datamining. The chapter depicts these four methods for computation of operational risk charges on a double scale: expected amount of capital allocation and complexity. Valid solutions take account of different perspectives and definitions of operational risk. The way operational risk is managed is affected by the manner in it is viewed, added with how the board and CEO come to grips with operational risk, the skills and tools at the regulators' disposal, and the resolve to put the risk under lock and key. This is the reason why Basel II wants banks to put aside capital for operational risk control.}
}
@article{LOPEZBRAU2023105524,
title = {People can use the placement of objects to infer communicative goals},
journal = {Cognition},
volume = {239},
pages = {105524},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105524},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001580},
author = {Michael Lopez-Brau and Julian Jara-Ettinger},
keywords = {Computational modeling, Social objects, Theory of Mind},
abstract = {Beyond words and gestures, people have a remarkable capacity to communicate indirectly through everyday objects: A hat on a chair can mean it is occupied, rope hanging across an entrance can mean we should not cross, and objects placed in a closed box can imply they are not ours to take. How do people generate and interpret the communicative meaning of objects? We hypothesized that this capacity is supported by social goal inference, where observers recover what social goal explains an object being placed in a particular location. To test this idea, we study a category of common ad-hoc communicative objects where a small cost is used to signal avoidance. Using computational modeling, we first show that goal inference from indirect physical evidence can give rise to the ability to use object placement to communicate. We then show that people from the U.S. and the Tsimane’—a farming-foraging group native to the Bolivian Amazon—can infer the communicative meaning of object placement in the absence of a pre-existing convention, and that people’s inferences are quantitatively predicted by our model. Finally, we show evidence that people can store and retrieve this meaning for use in subsequent encounters, revealing a potential mechanism for how ad-hoc communicative objects become quickly conventionalized. Our model helps shed light on how humans use their ability to interpret other people’s behavior to embed social meaning into the physical world.}
}
@article{FRITSCH2024100297,
title = {Teaching advanced topics in econometrics using introductory textbooks: The case of dynamic panel data methods},
journal = {International Review of Economics Education},
volume = {47},
pages = {100297},
year = {2024},
issn = {1477-3880},
doi = {https://doi.org/10.1016/j.iree.2024.100297},
url = {https://www.sciencedirect.com/science/article/pii/S147738802400015X},
author = {Markus Fritsch and Andrew Adrian Yu Pua and Joachim Schnurbus},
keywords = {Teaching econometrics, instrumental variables, linear dynamic panel data methods, cigarette demand, lagged variables},
abstract = {We show how to use the introductory econometrics textbook by Stock and Watson (2019) as a starting point for teaching and studying dynamic panel data methods. The materials are intended for undergraduate students taking their second econometrics course, undergraduate students in seminar-type courses, independent study courses, capstone, or thesis projects, and beginning graduate students in a research methods course. First, we distill the methodological core necessary to understand dynamic panel data methods. Second, we design an empirical and a theoretical case study to highlight the capabilities, downsides, and hazards of the method. The empirical case study is based on the cigarette demand example in Stock and Watson (2019) and illustrates that economic and methodological issues are interrelated. The theoretical case study shows how to evaluate current empirical practices from a theoretical standpoint. We designed both case studies to boost students’ confidence in working with technical material and to provide instructors with more opportunities to let students develop econometric thinking and to actively communicate with applied economists. Although we focus on Stock and Watson (2019) and the statistical software R, we also show how to modify the material for use with another introductory textbook by Wooldridge (2020) and Stata, and highlight some possible further pathways for instructors and students to reuse and extend our materials.}
}
@incollection{BALAKRISHNAN202131,
title = {Chapter 2 - Computational intelligence in healthcare and biosignal processing},
editor = {Janmenjoy Nayak and Bighnaraj Naik and Danilo Pelusi and Asit Kumar Das},
booktitle = {Handbook of Computational Intelligence in Biomedical Engineering and Healthcare},
publisher = {Academic Press},
pages = {31-64},
year = {2021},
isbn = {978-0-12-822260-7},
doi = {https://doi.org/10.1016/B978-0-12-822260-7.00015-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222607000157},
author = {Nagaraj Balakrishnan and Valentina E. Balas and Arunkumar Rajendran},
keywords = {ANN, Clustering, Data classification, Data mining, Deep clustering networks, Deep learning},
abstract = {In this new era, technological advancement toward the mission of a better tomorrow is reaching its limit because the exploration of the advanced possibilities of Artificial Intelligence is bounded with certain limitations. The application of analyzing various features of biosignal processing is key in the fields of medicine and healthcare. Biosignals such as Electroencephalogram (EEG), Electrocardiogram (ECG), Electromyography (EMG), Electrooculography (EOG), Galvanic Skin Response(GSR), and Magnetoencephalography (MEG) is already giving deep insight into the human body toward the identification of diverse nature and disorders. In recent years, the research toward analyzing biosignal gained interest among many researchers. The primary limitation for the algorithms to analyze these signals for more possibilities of insight is its uncertainty. Even though the algorithms of Artificial Intelligence have the capabilities to unravel the mysteries, it is bounded with specific difficulties. The machine learning algorithms designed to manage uncertain data but lacks accuracy due to many factors. Also, complete supervision is needed in a training process that involves the extraction and selection of adequate features for the training. The deep learning method (a subset of machine learning) comes into the picture due to one of these facts. This, indeed, as a supervised learning method, needs a massive volume of data to train to reach the accuracy goal. The deep learning algorithm plays a significant role in today's Artificial Intelligence–based applications. However, this platform needs many requirements, such as (a) high computational power like graphical processing units (GPU); (b) similar to machine learning methods, a massive labeled dataset for supervised learning; (c) adequate parameter selection to avoid overfitting or underfitting. To overcome the problems highlighted, the strategy of adopting the behaviors of unsupervised learning (performed by the clustering algorithm) in the deep learning methodology is needed. To achieve the goal, two-phase operations were processed, such as (1) transformation of the data elements into a latent feature space (Z) is processed through a nonlinear mapping of deep learning networks; (2) clustering the latent feature space to k-clusters, and simultaneously, the clustering loss is fed to the deep learning network for the next iteration of operation concerning the objective function convergence analyzed by the Kullback–Leibler divergence. Various strategies of enhancing the nature of deep learning methods and clustering methodologies for an unsupervised learning process are addressed in this chapter.}
}
@article{CASTRO2006811,
title = {Patient-Specific Computational Modeling of Cerebral Aneurysms With Multiple Avenues of Flow From 3D Rotational Angiography Images},
journal = {Academic Radiology},
volume = {13},
number = {7},
pages = {811-821},
year = {2006},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2006.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1076633206001826},
author = {Marcelo A. Castro and Christopher M. Putman and Juan R. Cebral},
abstract = {Rationale and Objectives
Previous studies of aneurysm flow dynamics based on three-dimensional (3D) rotational angiography (RA) images were limited to aneurysms with a single route of blood inflow. However, aneurysms of the circle of Willis frequently involve locations with more than one source of inflow, such as aneurysms of the anterior communicating artery. The highest resolution images of cerebral vessels are from RA images, but this technique is limited to visualizing only one route of inflow at a time, leaving a significant limitation in the application of 3DRA image sets for clinical studies of patient-specific computational fluid dynamics (CFD) simulations. In this report, subject-specific models of cerebral aneurysms with multiple avenues of flow are constructed from RA images by using a novel combination of image coregistration and surface merging techniques.
Materials and Methods
RA images are obtained by means of contrast injection in each vessel that provides inflow to the aneurysm. Anatomic models are constructed independently of each of these vascular trees and fused together into a single model. The model is used to construct a finite element grid for CFD simulations of hemodynamics.
Results
Three examples of patient-specific models are presented: an anterior communicating artery aneurysm, a basilar tip aneurysm, and a model of an entire circle of Willis with five coincident aneurysms. The method is evaluated with a numeric phantom of an aneurysm in the anterior communicating artery.
Conclusion
These examples show that this new technique can be used to create merged network numeric models for CFD modeling. Furthermore, intra-aneurysmal flow patterns are influenced strongly by merging of the two inflow streams. This effect decreases as distance from the merging streams increases.}
}
@article{SINGH2012185,
title = {Towards an integrated generative design framework},
journal = {Design Studies},
volume = {33},
number = {2},
pages = {185-207},
year = {2012},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2011.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X11000391},
author = {Vishal Singh and Ning Gu},
keywords = {generative design, architectural design, digital design, design cognition, reflective practise},
abstract = {Design creativity techniques encourage divergent thinking. But how well do the existing generative design techniques support this requirement? How can these general techniques be augmented for supporting design exploration and creativity? This paper investigates these questions through a review of five different generative design techniques used in architectural design that includes cellular automata, genetic algorithms, L-systems, shape grammars, and swarm intelligence. Based on the literature on design cognition and the recent theoretical works on digital design thinking, this paper proposes the need for an integrated generative design framework to enhance design exploration support for human designers. Potential challenges and strategies towards developing such an integrated framework are discussed.}
}
@incollection{RZESZEWSKI2024219,
title = {Chapter 10 - Augmented reality content and relations of power in smart spaces},
editor = {Zhihan Lyu},
booktitle = {Smart Spaces},
publisher = {Academic Press},
pages = {219-234},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-13462-3},
doi = {https://doi.org/10.1016/B978-0-443-13462-3.00008-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044313462300008X},
author = {Michal Rzeszewski and Leighton Evans},
keywords = {Augmented reality, Smart space, Agency of place, Power relations},
abstract = {This chapter’s main aim is to interrogate how augmented reality (AR) content can change the relations of power within a place and transform the perception of place from being a material background for social interactions into a living agent that can have its own agency. We use the concept of sociotechnical imaginary and thematic analysis of AR-related media content to explore main narrations in the current discourse on AR and smart urban spaces. We identify two dominant themes: “smart information in place” and “subversion of meaning” that combine two ways of thinking about relation between place and AR. In the first one, AR acts not as an augmentation of place, but as a reducer of the experience of place down to seeing the world as information and data for the achievement of efficiencies in late capitalism. In the second one, AR can be seen as transcending the traditional constellations of power relations that shape places and spaces of modern cities, skewing them toward nonhuman actors, of which AR may be the most visible and influential. Through the visible differentiation of users, alteration of perception and the forcing of presence and behavior, AR is a technology that makes visible the systems and processes of control and mediation of space and place. As such, the smart space itself will become visible through the presence, use, and functioning of AR in a manner that has not been the case previously. We posit, therefore, that AR can be seen as a physical manifestation of the agency of place. This position can have consequences for the practical development of smart spaces and for theoretical consideration of the human-technology interaction in urban space in its material and digital dimensions.}
}
@article{ALIABADI2000243,
title = {Stabilized-finite-element/interface-capturing technique for parallel computation of unsteady flows with interfaces},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {3},
pages = {243-261},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00200-0},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500002000},
author = {Shahrouz Aliabadi and Tayfun E. Tezduyar},
abstract = {We present the stabilized-finite-element/interface-capturing (SFE/IC) method developed for parallel computation of unsteady flow problems with two-fluid interfaces and free surfaces. The SFE/IC method involves stabilized formulations, an interface-sharpening technique, and the enforcement of global mass conservation for each fluid. The SFE/IC method has been efficiently implemented on the CRAY T3E parallel supercomputer. A number of 2D test problems are presented to demonstrate how the SFE/IC method works and the accuracy it attains. We also show how the SFE/IC method can be very effectively applied to 3D simulation of challenging flow problems, such as two-fluid interfaces in a centrifuge tube and operational stability of a partially filled tanker truck driving over a bump.}
}
@article{ZHONG2016423,
title = {The impact of social factors on pair programming in a primary school},
journal = {Computers in Human Behavior},
volume = {64},
pages = {423-431},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305064},
author = {Baichang Zhong and Qiyun Wang and Jie Chen},
keywords = {Primary education, Pair programming, Social factors, Gender, Partnership},
abstract = {Pair programming (PP) is a usefulness approach to fostering computational thinking (CT) for young students. However, there are many factors to impact the effectiveness of PP. Among all factors, the social factors are often ignored by researchers. Therefore, this study aimed to explore the impact of two social factors (gender and partnership) on PP in a primary school setting. To that end, we conducted PP experiments in four classes from the sixth grade in a Chinese primary school. The research results indicated: (a) there was no significant difference on compatibility among the gender pairs, but a significant difference among partnership pairs; (b) there was no significant difference on programming achievement and confidence among different pairs, and girls became more productive and confidence in PP; and (c) PP tightened up the partnership within pairs. These findings suggest that teachers should take partnership into account as an important factor in PP or other collaborative learning, and adopt PP as an effective approach to decrease the gender gap in programming courses, and make students socialize.}
}
@incollection{YANG20151,
title = {Chapter 1 - Bio-Inspired Computation and Optimization: An Overview},
editor = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
booktitle = {Bio-Inspired Computation in Telecommunications},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {1-21},
year = {2015},
isbn = {978-0-12-801538-4},
doi = {https://doi.org/10.1016/B978-0-12-801538-4.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012801538400001X},
author = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
keywords = {Algorithm, Ant algorithm, Bee algorithm, Bat algorithm, Bio-inspired computation, Cuckoo search, Firefly algorithm, Harmony search, Particle swarm optimization, Metaheuristics, Swarm intelligence, Telecommunications},
abstract = {All design problems in telecommunications can be formulated as optimization problems, and thus may be tackled by some optimization techniques. However, these problems can be extremely challenging due to the stringent time requirements, complex constraints, and a high number of design parameters. Solution methods tend to use conventional methods such as Lagrangian duality and fractional programming in combination with numerical solvers, while new trends tend to use evolutionary algorithms and swarm intelligence. This chapter provides a summary review of the bio-inspired optimization algorithms and their applications in telecommunications. We also discuss key issues in optimization and some active topics for further research.}
}
@article{NORTON2006600,
title = {Computational fluid dynamics (CFD) – an effective and efficient design and analysis tool for the food industry: A review},
journal = {Trends in Food Science & Technology},
volume = {17},
number = {11},
pages = {600-620},
year = {2006},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2006.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0924224406001981},
author = {Tomás Norton and Da-Wen Sun},
abstract = {Computational fluid dynamics (CFD) is a powerful numerical tool that is becoming widely used to simulate many processes in the food industry. Recent progression in computing efficacy coupled with reduced costs of CFD software packages has advanced CFD as a viable technique to provide effective and efficient design solutions. This paper discusses the fundamentals involved in developing a CFD solution. It also provides a state-of-the-art review on various CFD applications in the food industry such as ventilation, drying, sterilisation, refrigeration, cold display and storage, and mixing and elucidates the physical models most commonly used in these applications. The challenges faced by modellers using CFD in the food industry are also discussed.}
}
@article{FARRELL20175597,
title = {N‐Aryl‐9,10‐phenanthreneimines as Scaffolds for Exploring Noncovalent Interactions: A Structural and Computational Study},
journal = {European Journal of Organic Chemistry},
volume = {2017},
number = {37},
pages = {5597-5609},
year = {2017},
issn = {1434-193X},
doi = {https://doi.org/10.1002/ejoc.201700884},
url = {https://www.sciencedirect.com/science/article/pii/S1434193X22035940},
author = {David Farrell and Samuel J. Kingston and Dmitry Tungulin and Stefano Nuzzo and Brendan Twamley and James A. Platts and Robert J. Baker},
keywords = {Stacking interactions, Noncovalent interactions, Density functional calculations},
abstract = {A series of 10‐[(4‐halo‐2,6‐diisopropylphenyl)imino]phenanthren‐9‐ones and derivatives of the phenanthrene‐9,10‐dione ligand have been synthesised and structurally characterised to explore two types of noncovalent interactions, namely the influence of the steric bulk upon the resulting C–H···π and π‐stacking interactions and halogen bonding. Selected noncovalent interactions have additionally been analysed by DFT and AIM techniques. No halogen bonding has been observed in these systems, but X lone pair···π, C–H···O=C and C–H···π interactions are the prevalent ones in the halogenated systems. Removal of the steric bulk in N‐(2,4,6‐trimethylphenyl)‐9,10‐iminophenanthrenequinone affords different noncovalent interactions, but the C–H···O=C hydrogen bonds are observed. Surprisingly, in N‐(2,6‐dimethylphenyl)‐9,10‐iminophenanthrenequinone and N‐(phenyl)‐9,10‐iminophenanthrenequinone these C–H···O=C hydrogen bonds are not observed. However, they are observed in the related 2,6‐di‐tert‐butylphenanthrene‐9,10‐dione. The π‐interactions in dimers extracted from the crystal structures have been analysed by DFT and AIM. Spectroscopic investigations are also presented and these show only small perturbations to the O=C–C=N fragment.}
}
@article{JAUK2012219,
title = {Tackling creativity at its roots: Evidence for different patterns of EEG alpha activity related to convergent and divergent modes of task processing},
journal = {International Journal of Psychophysiology},
volume = {84},
number = {2},
pages = {219-225},
year = {2012},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2012.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167876012000748},
author = {Emanuel Jauk and Mathias Benedek and Aljoscha C. Neubauer},
keywords = {EEG, Creativity, Alpha synchronization, Divergent thinking, Convergent thinking},
abstract = {The distinction between convergent and divergent cognitive processes given by Guilford (1956) had a strong influence on the empirical research on creative thinking. Neuroscientific studies typically find higher event-related synchronization in the EEG alpha rhythm for individuals engaged in creative ideation tasks compared to intelligence-related tasks. This study examined, whether these neurophysiological effects can also be found when both cognitive processing modes (convergent vs. divergent) are assessed by means of the same task employing a simple variation of instruction. A sample of 55 participants performed the alternate uses task as well as a more basic word association task while EEG was recorded. On a trial-by-trial basis, participants were either instructed to find a most common solution (convergent condition) or a most uncommon solution (divergent condition). The answers given in the divergent condition were in both tasks significantly more original than those in the convergent condition. Moreover, divergent processing was found to involve higher task-related EEG alpha power than convergent processing in both the alternate uses task and the word association task. EEG alpha synchronization can hence explicitly be associated with divergent cognitive processing rather than with general task characteristics of creative ideation tasks. Further results point to a differential involvement of frontal and parietal cortical areas by individuals of lower versus higher trait creativity.}
}
@article{BULLEN2022101933,
title = {Patterns of math and reading achievement in children and adolescents with autism spectrum disorder},
journal = {Research in Autism Spectrum Disorders},
volume = {92},
pages = {101933},
year = {2022},
issn = {1750-9467},
doi = {https://doi.org/10.1016/j.rasd.2022.101933},
url = {https://www.sciencedirect.com/science/article/pii/S1750946722000204},
author = {Jennifer C. Bullen and Matthew C. Zajic and Nancy McIntyre and Emily Solari and Peter Mundy},
keywords = {Autism spectrum disorder, Academic achievement, Hierarchical cluster analysis, Math achievement, Reading fluency},
abstract = {Background
There has been an increase of autistic students without intellectual disabilities (autisticWoID) placed in general education settings (Hussar et al., 2020), but there is a lack of understanding of how to best support classroom learning for these children. Previous research has pointed to subgroups of autisticWoID children who display difficulty with mathematics and reading achievement (Chen et al., 2018; Estes et al., 2011; Jones et al., 2009; Wei et al., 2015). Research has primarily focused on symptomatology and communication factors related to learning in subgroups of autistic children. The current study sought to expand upon this research by assessing the validity of these previous studies and by investigating the specific contribution of domain-general cognitive abilities to differences in these subgroups.
Method
Seventy-eight autisticWoID individuals (M = 11.34 years, SD = 2.14) completed measures of mathematics and reading achievement, IQ, working memory, inferential thinking, and Theory of Mind (ToM). A hierarchical cluster analysis was performed on the math and reading measures.
Results
The analysis revealed two unique achievement groups: one group that performed lower than expected on math and reading achievement and a second group that performed higher than expected. Groups differed significantly on IQ and working memory and were distinguished by performance on reading fluency. Groups did not differ on ToM, inferential thinking, or symptomatology.
Conclusion
These findings describe a group of autisticWoID individuals that may be more likely to experience difficulty learning, which should be accounted for in general education settings.}
}
@article{BECKER2003164,
title = {A computational model of the role of dopamine and psychotropic drugs in modulating motivated action},
journal = {Schizophrenia Research},
volume = {60},
number = {1, Supplement },
pages = {164},
year = {2003},
note = {Abstracts of the IXth International Congress on Schizophrenia Research},
issn = {0920-9964},
doi = {https://doi.org/10.1016/S0920-9964(03)81019-8},
url = {https://www.sciencedirect.com/science/article/pii/S0920996403810198},
author = {S. Becker and A. Chan and P. Fletcher and A. Smith and S. Kapur}
}
@article{OBERKAMPF2002209,
title = {Verification and validation in computational fluid dynamics},
journal = {Progress in Aerospace Sciences},
volume = {38},
number = {3},
pages = {209-272},
year = {2002},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(02)00005-2},
url = {https://www.sciencedirect.com/science/article/pii/S0376042102000052},
author = {William L. Oberkampf and Timothy G. Trucano},
abstract = {Verification and validation (V&V) are the primary means to assess accuracy and reliability in computational simulations. This paper presents an extensive review of the literature in V&V in computational fluid dynamics (CFD), discusses methods and procedures for assessing V&V, and develops a number of extensions to existing ideas. The review of the development of V&V terminology and methodology points out the contributions from members of the operations research, statistics, and CFD communities. Fundamental issues in V&V are addressed, such as code verification versus solution verification, model validation versus solution validation, the distinction between error and uncertainty, conceptual sources of error and uncertainty, and the relationship between validation and prediction. The fundamental strategy of verification is the identification and quantification of errors in the computational model and its solution. In verification activities, the accuracy of a computational solution is primarily measured relative to two types of highly accurate solutions: analytical solutions and highly accurate numerical solutions. Methods for determining the accuracy of numerical solutions are presented and the importance of software testing during verification activities is emphasized. The fundamental strategy of validation is to assess how accurately the computational results compare with the experimental data, with quantified error and uncertainty estimates for both. This strategy employs a hierarchical methodology that segregates and simplifies the physical and coupling phenomena involved in the complex engineering system of interest. A hypersonic cruise missile is used as an example of how this hierarchical structure is formulated. The discussion of validation assessment also encompasses a number of other important topics. A set of guidelines is proposed for designing and conducting validation experiments, supported by an explanation of how validation experiments are different from traditional experiments and testing. A description is given of a relatively new procedure for estimating experimental uncertainty that has proven more effective at estimating random and correlated bias errors in wind-tunnel experiments than traditional methods. Consistent with the authors’ contention that nondeterministic simulations are needed in many validation comparisons, a three-step statistical approach is offered for incorporating experimental uncertainties into the computational analysis. The discussion of validation assessment ends with the topic of validation metrics, where two sample problems are used to demonstrate how such metrics should be constructed. In the spirit of advancing the state of the art in V&V, the paper concludes with recommendations of topics for future research and with suggestions for needed changes in the implementation of V&V in production and commercial software.}
}
@article{KIM20141,
title = {Studying children's tactile problem-solving in a digital environment},
journal = {Thinking Skills and Creativity},
volume = {12},
pages = {1-13},
year = {2014},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1871187113000734},
author = {Mi Jeong Kim and Myung Eun Cho},
keywords = {Children's problem solving, Tactile interaction, Cognitive perspectives, Empirical study, Protocol analysis},
abstract = {Given that modern children have grown up with numerous digital interactive devices it is essential to understand how the digital environment might affect children's cognitive development. As an extension of previous studies, this research investigates the cognitive effects of tactile interaction on children's problem solving. In order to explore the cognitive development of children with respect to tactile interaction, we compared furniture arrangements by elementary school students of 3D blocks and pencils. A protocol analysis was adopted for examining the ways in which children used the two different tools. The results of this study show that tactile interaction supports children's problem solving. This research implies that children in early education need to experience a wide range of digital devices utilizing rich sensorial dimensions as such devices stimulate divergent thinking, affecting cognitive developmental trajectories.}
}
@article{BRIMKOV20071631,
title = {Digital hyperplane recognition in arbitrary fixed dimension within an algebraic computation model},
journal = {Image and Vision Computing},
volume = {25},
number = {10},
pages = {1631-1643},
year = {2007},
note = {Discrete Geometry for Computer Imagery 2005},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2006.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0262885606002988},
author = {Valentin E. Brimkov and Stefan Dantchev},
keywords = {Digital hyperplane, Digital plane recognition, Integer programming, Euclidean algorithm},
abstract = {In this paper we present an algorithm for the integer linear programming (ILP) problem within an algebraic model of computation and use it to solve the following digital plane segment recognition problem: Given a set of points M={p1,p2,…,pm}⊆Rn, decide whether M is a portion of a digital hyperplane and, if so, determine its analytical representation. In our setting p1, p2, …,pm may be arbitrary points (possibly, with rational and/or irrational coefficients) and the dimension n may be any arbitrary fixed integer. We reduce this last problem to an ILP to which our general integer programming algorithm applies. It performs O(mlogD) arithmetic operations, where D is a bound on the norm of the domain elements. For the special case of problem dimension two, we propose an elementary algorithm that takes advantage of the specific geometry of the problem and appears to be optimal. It implies an efficient algorithm for digital line segment recognition.}
}
@article{KESIC2024101072,
title = {Complexity and biocomplexity: Overview of some historical aspects and philosophical basis},
journal = {Ecological Complexity},
volume = {57},
pages = {101072},
year = {2024},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2023.101072},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X23000442},
author = {Srdjan Kesić},
keywords = {Cybernetics, General systems theory, Complexity, Modeling, Biocomplexity, Emergence, Autopoiesis},
abstract = {Complexity has radically changed human understanding of the world environment and continues challenging our best scientific theories. In a rapidly changing research landscape, historical and philosophical insights into Complexity can heighten awareness of the proper theoretical perspectives scientists should adopt to advance the study of biocomplexity, including ecological complexity. The present work aims to deepen this awareness and disclose how researchers should generally approach, scientifically and philosophically, the question of what Complexity is, which is of great importance not only to the scientific community but also far beyond. First, this article reviews some critical historical turning points that led to Complexity. Second, the paper discusses philosophical-scientific approaches to the emergence as one of the most critical features of complex systems. The critical ideas behind attempts to understand the generators of complexity in nature are then presented, focusing on the living world. Finally, the review focuses on understanding the ecosystem- and organism-oriented perspectives of biocomplexity. We conclude that the genuine problem of the origin of complexity theory and biocomplexity will continue to inspire generations of researchers to search for new, more comprehensive mathematical and computational frameworks to explain biological hierarchies in order to further advance the scientific understanding of life.}
}
@article{TABATABAEI2018133,
title = {With a little help from my friends: A computational model for the role of social support in mood regulation},
journal = {Cognitive Systems Research},
volume = {47},
pages = {133-146},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2017.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716302030},
author = {Seyed Amin Tabatabaei and Altaf Hussain Abro and Michel Klein},
keywords = {Social support, Stress buffering, Human ambient agent, Perceived support, Social network characteristics},
abstract = {The growing interest in the role of social support in mental and physical health has led to the development of several intelligent systems that aim to use social mechanisms to simulate healthy behaviour. In this paper a computational model of a human agent is presented which describes the effect of social support on mood. According to the literature, social support can either refer to the social resources that individuals perceive to be available or to the support that is actually provided in problematic situations. The proposed model distinguishes between both roles of social support. The role of social network characteristics has been taken into account, as an individual can perceive or receive social support through his/her social network. In addition, the number of connections (friends), strength of ties (relationships), social isolation and social integration have been studied. Simulation experiments have been done to analyze the effect of the different types of support in different scenarios and also to analyze the role of various social network characteristics on the mood level. It is shown that support can help to reduce the induced stress and thus can contribute to healthy mood regulation and prevention of depression. The presented model provides a basis for an intelligent support system for people with mood regulation problems that take the social network of people into account.}
}
@article{WU2019104407,
title = {A review of performance assessment methods for construction and demolition waste management},
journal = {Resources, Conservation and Recycling},
volume = {150},
pages = {104407},
year = {2019},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2019.104407},
url = {https://www.sciencedirect.com/science/article/pii/S0921344919303027},
author = {Huanyu Wu and Jian Zuo and Hongping Yuan and George Zillante and Jiayuan Wang},
keywords = {Construction and demolition waste, Waste management, Performance assessment methods, System thinking, Life cycle assessment},
abstract = {Significant efforts have been devoted to assessing construction and demolition waste management (CDWM). However, there is little knowledge to understand the utilisation of the developed models for assessing CDWM performance, thus limiting the comparison and generalization of recognized methods and tools. By reviewing the prior published literature, this study assesses the current research methods, in particular, data collection. It also reviews the range of critical indicators for CDWM performance assessment considered by the literature and put forwards a new framework for better assessing CDWM performance. The proposed framework summarises the system boundary, research scale and performance assessment aspects documented by previous studies, and further integrate an integrated framework with procedures for better assessing CDWM performance. The literature review found that while some studies adopt a system thinking and life cycle thinking to assess CDWM performance, other research they adopt a sustainability based model to finalize CDWM performance assessment. The results also demonstrate that compared with environmental and economic aspects, the social aspect has attracted less attention. Social factors, however are crucial in CDWM. The findings about current performance assessment practices in CDWM and the proposed procedures are possible to implement for researchers and practitioners to develop sound CDWM approaches.}
}
@article{CAO2024102160,
title = {Self-assembly of peptides: The acceleration by molecular dynamics simulations and machine learning},
journal = {Nano Today},
volume = {55},
pages = {102160},
year = {2024},
issn = {1748-0132},
doi = {https://doi.org/10.1016/j.nantod.2024.102160},
url = {https://www.sciencedirect.com/science/article/pii/S174801322400015X},
author = {Nana Cao and Kang Huang and Jianjun Xie and Hui Wang and Xinghua Shi},
keywords = {Peptides, Self-assembly, Molecular dynamics, Machine learning},
abstract = {Peptides, biopolymeric compounds connected by peptide bonds, have garnered significant attention in recent years as their potential wide applications in fields such as drug delivery, tissue engineering, and antibiotics. Peptides exhibit excellent biocompatibility and stability due to their structural similarities to many bioactive substances found in human bodies. The self-assembly of peptides has piqued considerable interest with groundbreaking advancements achieved in experimental research. However, it is still a big challenge to establish comprehensive theoretical model to accurately describe the behavior of peptide self-assembly. Current peptide self-assembly designs primarily rely on experimental outcomes and general rules, which is inefficient and susceptible to human errors. In recent years, thanks to rapid advancements in computer techniques and theoretical methods, computational research has become a vital tool in complementing experimental research with rapid development witted in this field. This review delves into the description of peptide self-assembly, covering relevant sequences, structures, morphologies, rules, and application areas. It places particular emphasis on the recent progress in computational methods such as molecular dynamics (MD) simulations and machine learning (ML) techniques in the study. Finally, we provide a perspective on the application of computational methods to expedite exploration in the realm of multi-peptide self-assembly.}
}
@article{HAMMIA2024517,
title = {Enhancing Real-time Simultaneous Localization and Mapping with FPGA-based EKF-SLAM's Hardware Architecture},
journal = {Procedia Computer Science},
volume = {236},
pages = {517-526},
year = {2024},
note = {International Symposium on Green Technologies and Applications (ISGTA’2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.061},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924010779},
author = {Slama Hammia and Anas Hatim and Abdelilah Haijoub},
keywords = {EKF-SLAM, Simultaneous Localization and Mapping, Green Technologies, FPGA},
abstract = {Simultaneous Localization and Mapping enable a mobile robot that is exploring an uncharted environment to localize itself and calculate its path within the map. In the context of green technologies and applications, there is a growing need for efficient SLAM solutions that not only provide accurate localization and mapping but also minimize power consumption. EKF-SLAM is a SLAM solution based on the Extended Kalman Filter, it is well known In the domain of robotics for its ability to handle non-linear models, its ability to handle noise related to the sensors, and its extremely high degree of precision. To guarantee real-time performance, the EKF-SLAM implementation requires a high-performance hardware architecture. In light of this challenge, researchers are thinking about using parallel processing platforms like FPGAs, which can provide the required level of performance and meet strict constraints on physics, computing capacity, and electrical power. This study describes a hardware architecture's implementation design for EKF-SLAM on an FPGA platform. The entire design is built on the Cyclone 2 FPGA, which has a maximum speed of 114 MHz and 18577 LUTs, creating a highly efficient hardware architecture.}
}
@incollection{KRAAK2020141,
title = {Geovisualization},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {141-151},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10552-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105529},
author = {Menno-Jan Kraak},
keywords = {Alternative visualization, Cartography, Cognition, Coordinated multiple views, Geocomputation, Geovisualization, Information visualization, Interfaces, Maps, Representation, Spatiotemporal data, Usability, Visual analytics, Visual exploration, Visual representation, Visual thinking},
abstract = {Due to technological developments and societal needs cartography, scientific visualization, image analysis and remote sensing, information visualization, exploratory data analysis, visual analytics, and GIScience have undergone fundamental changes in recent years. Interactivity and dynamics allow not only maps and diagrams to present known facts but also to analyze and explore unknown data. The environment in which the maps and diagrams are used has also changed and often includes coordinated multiple views display via the Internet. Such environments allow for simultaneous alternative views of the data and stimulate visual thinking, resulting in geovisualization.}
}
@article{BAYRAKTARSARI2024110835,
title = {Architectural spatial layout design for hospitals: A review},
journal = {Journal of Building Engineering},
volume = {97},
pages = {110835},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.110835},
url = {https://www.sciencedirect.com/science/article/pii/S2352710224024033},
author = {Aysegul Ozlem {Bayraktar Sari} and Wassim Jabi},
keywords = {Architectural spatial layout design, Hospital spatial layout design, Computational design, Facility layout planning, Machine learning (ML) driven layout design, Systematic review},
abstract = {The design of hospital spatial layouts is a critical aspect of healthcare architecture, directly influencing patient outcomes, staff efficiency, and the overall quality of care. A well-designed hospital layout is essential for ensuring smooth operations, minimizing errors, and improving both patient and staff experiences. This paper reviews the significant advances in the field, particularly focusing on the transition from traditional design methods to the integration of computational techniques and machine learning (ML) in hospital layout planning. Despite these technological advancements, there remains a notable gap in the full adoption and optimization of these methods to effectively address the inherent complexities of healthcare environments. This review identifies that while computational methods and machine learning-driven approaches have brought precision and innovation to hospital design, the challenge lies in balancing these technologies with the expertise and insights of human designers. Moreover, the need for interdisciplinary collaboration between architects, healthcare professionals, and engineers is emphasized as crucial for the successful implementation of advanced design strategies. Insights from this review highlight the potential of future research to bridge the existing gaps, proposing directions for the continuous integration of technology in hospital layout design.}
}
@article{LI2023104935,
title = {Development of a distributed MR-IoT method for operations and maintenance of underground pipeline network},
journal = {Tunnelling and Underground Space Technology},
volume = {133},
pages = {104935},
year = {2023},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2022.104935},
url = {https://www.sciencedirect.com/science/article/pii/S0886779822005764},
author = {Wei Li and Zhoujing Ye and Yajian Wang and Hailu Yang and Songli Yang and Zhenlong Gong and Linbing Wang},
keywords = {Underground Pipeline Network, Mixed Reality, IoT Cloud Platform, Data Communication, Operation and Maintenance},
abstract = {The underground pipeline network (UPN) is an essential infrastructure and plays an irreplaceable role in national defense and urban activities. The complexity of structural environment and management makes its operation and maintenance difficult. To solve this problem, a distributed mixed reality (MR) and internet of things (IoT) system is developed through game thinking. Firstly, digital models are created based on design drawings and real-world environments, and then an MR system for the UPN is built by the game engine and the OpenXR platform. Secondly, an IoT cloud platform is built to connect with the MR system based on the API sets and cloud services; the data communication between sensors and MR devices is linked with the Socket method, and the data filtering model is constructed by the Kalman algorithm to realize the information exchange between the field workers and the backend managers. Finally, the National Center for Materials Service Safety at the University of Science and Technology Beijing (NCMS_USTB) is used as the experimental site to test this system, and its underground sewage and rainwater pipeline network are used to simulate the key problems in the operation and maintenance. The effect of the application shows that there is potential technical complementarity between the MR and IoT, and the distributed MR-IoT approach can be used as a new technical reference for the operation and maintenance of the UPN.}
}
@article{VALLESPERIS2024102448,
title = {Digital citizenship at school: Democracy, pragmatism and RRI},
journal = {Technology in Society},
volume = {76},
pages = {102448},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102448},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002531},
author = {Núria Vallès-Peris and Miquel Domènech},
keywords = {Science and technology studies, Digital citizenship, Responsible research and innovation, Democracy, Pragmatism},
abstract = {This paper presents a strategy for fostering digital citizenship at school that transcends the mere use of digital devices or instructional methods focused solely on their use. The core premise of this proposal rests on the need for an ethical-political debate concerning digitization in education. In addition, it emphasizes the need to cultivate a form of digital literacy that blends science and technology with the humanities, and erases the traditional boundaries between making and thinking. The proposed approach encapsulates two primary concerns: firstly, it asserts that digital literacy serves as a foundation for meaningful participation in digital societies; secondly, it underscores the importance of democratizing digital technologies by incorporating the perspectives, needs, and concerns of children. Drawing inspiration from the theories of pragmatism and responsible research and innovation (RRI), we present a conceptual framework for digital citizenship. To operationalize this approach, we adapt John Dewey's pragmatic model of inquiry as a method that can be applied within the school setting. This pragmatic methodology serves as a conduit for developing hands-on experience geared towards developing digital citizenship. The practical implementation of this methodology is illustrated through an actualized experience with 10- and 11-year-old children in a public primary school, regarding the issue of care robots. This paper advocates for a symbiotic relationship between theoretical understanding and practical application, and puts forward a concrete proposal for the integration of digital citizenship in schools in the form of a four-phase procedural model, based on the creation of what we term ‘the encounter’ between the educational community and the research and development community.}
}
@article{RUSSWINKEL2011336,
title = {Predicting temporal errors in complex task environments: A computational and experimental approach},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {336-354},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000143},
author = {Nele Russwinkel and Leon Urbas and Manfred Thüring},
keywords = {Cognitive modelling, Time perception, Working memory, Expectations, Surprise, ACT-R},
abstract = {Management in complex environments requires knowledge about temporal contingencies. Expectations about durations enable us to prepare for important events in good time, but also to detect irregularities. Unfortunately, time perception is not invariant. Situational aspects as well as features of the task at hand may dramatically change our sense of time. Particularly under varying workload conditions, temporal distortions may lead to performance errors. A valid and reliable model of time perception must account for these characteristics. Based on the cognitive architecture ACT-R (Anderson et al., 2004), we developed a computational model in line with this requirement. Specific emphasis was placed on mechanisms of coordinative working memory which seem to influence time encoding and perception. The model’s assumptions were tested in three steps. First, the model was applied to account for time distortions ‘a posteriori’. Effects of varying working memory demands reported by Dutke (2005) were replicated and explained by simulations of the model. Second, the model was used for predicting effects ‘a priori’. Augmenting Dutke’s (2005) approach by switching between different degrees of memory demands, predictions of time distortions were derived from the model. These predictions were compared with experimental data. Central assumptions of the model were supported, but there were also some deviations that the model had not captured. Based on the conclusions from the results of the experiment, a second a priori testing addressed temporal expectations in a complex task using a micro-world scenario. The results support the interpretation of the previous experiment and provide new insights for modelling time perception. In summary, our results indicate that coordinative working memory – in contrast to general attention – causes differences in timing performance. This characteristic is captured by our approach. The model we propose heavily relies on mechanisms of working memory and can be applied to explain effects for different time intervals, under a variety of experimental conditions and in different task environments.}
}
@article{SUJAN2023105994,
title = {Operationalising FRAM in Healthcare: A critical reflection on practice},
journal = {Safety Science},
volume = {158},
pages = {105994},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2022.105994},
url = {https://www.sciencedirect.com/science/article/pii/S0925753522003332},
author = {M. Sujan and L. Pickup and M.S. {de Vos} and R. Patriarca and L. Konwinski and A. Ross and P. McCulloch},
keywords = {Patient Safety, FRAM, Resilience Engineering, System Safety},
abstract = {Resilience Engineering principles are becoming increasingly popular in healthcare to improve patient safety. FRAM is the best-known Resilience Engineering method with several examples of its application in healthcare available. However, the guidance on how to apply FRAM leaves gaps, and this can be a potential barrier to its adoption and potentially lead to misuse and disappointing results. The article provides a self-reflective analysis of FRAM use cases to provide further methodological guidance for successful application of FRAM to improve patient safety. Five FRAM use cases in a range of healthcare settings are described in a structured way including critical reflection by the original authors of those studies. Individual reflections are synthesised through group discussion to identify lessons for the operationalisation of FRAM in healthcare. Four themes are developed: (1) core characteristics of a FRAM study, (2) flexibility regarding the underlying epistemological paradigm, (3) diversity with respect to the development of interventions, and (4) model complexity. FRAM is a systems analysis method that offers considerable flexibility to accommodate different epistemological positions, ranging from realism to phenomenology. We refer to these as computational FRAM and reflexive FRAM, respectively. Practitioners need to be clear about their analysis aims and their analysis position. Further guidance is needed to support practitioners to tell a convincing and meaningful “system story” through the lens of FRAM.}
}
@article{FALLOON2019138,
title = {Using simulations to teach young students science concepts: An Experiential Learning theoretical analysis},
journal = {Computers & Education},
volume = {135},
pages = {138-159},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S036013151930051X},
author = {Garry Falloon},
keywords = {Simulations, Young students, Electricity, Circuits, Experiential learning},
abstract = {Early research investigated young students' understandings of science concepts using physical equipment, but technological advances now mean there are new options to introduce these ideas, through devices such as iPads and simulations. However, research investigating the use of simulations in early years' science learning is limited. This study applied revisions of Kolb's Experiential Learning theoretical model to determine if age-indicated science simulations were effective for teaching 5 year olds simple circuit building procedures and electricity concepts, and the function of circuit components. It also explored whether their engagement with the simulations provided worthwhile opportunities to exercise higher order capabilities such as reflective thinking and abstraction – skills oftencited in literature as valuable outcomes from older student and adult use of simulations. Findings indicate students developed a solid base of procedural knowledge about constructing different circuits, and functional knowledge about circuit components they applied to different circuit designs. The emergence of tentative, generalised theories about current and the effects of different circuit designs on the performance of resistors - linked to the exercise of reflective and descriptive thinking, were also noted in many students. However, examples were found of some simulations appearing to foster common misconceptions, such as current being ‘consumed’ by resistors – indicating teachers need to be highly vigilant and work closely with students, to ensure accurate understandings are developed. Overall, with appropriate teacher support and careful selection and review, the study concludes simulations can be effective for introducing young students to simple physical science concepts, and for providing them with opportunities to engage in higher order thinking processes.}
}
@article{OLCAYSOYOKTEN2022111606,
title = {When knowledge is blinding: The dangers of being certain about the future during uncertain societal events},
journal = {Personality and Individual Differences},
volume = {195},
pages = {111606},
year = {2022},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2022.111606},
url = {https://www.sciencedirect.com/science/article/pii/S0191886922001106},
author = {Irmak {Olcaysoy Okten} and Anton Gollwitzer and Gabriele Oettingen},
keywords = {Subjective certainty, Future thinking, COVID-19, Elections, Information seeking, Uncertainty},
abstract = {Past research has independently examined the concepts of certainty and future thought. Here we combine these concepts by examining the cognitive and behavioral outcomes of certainty about the future during periods of societal uncertainty. Three studies (N = 1218) examined future certainty, defined as feeling certain about some future event or outcome, during two major societal events of uncertainty—the COVID-19 pandemic and the 2020 U.S. Presidential Election. In Study 1, certainty about positive or negative futures of COVID-19 (e.g., the pandemic will end soon; the pandemic will never end) predicted poorer information seeking—ignorance of medical experts, adherence to conspiratorial thinking, and lower objective knowledgeability about COVID-19. Building on these findings, in Study 2, future certainty predicted antisocial health behaviors, including failing to social distance. Study 3 extended these findings to the political domain—the 2020 Presidential Election. Future certainty that one's preferred candidate would win the election predicted poor information seeking and antisocial behaviors in terms of claiming that the election was rigged, endorsing violence if one's candidate lost, and, among Trump supporters, identifying with Capitol insurrectionists. These findings suggest that future certainty is linked to intellectual blindness and antisocial behaviors during important periods of societal uncertainty.}
}
@article{ZHAO2023100891,
title = {Meet the authors: Yuxuan Zhao, Enmeng Lu, and Yi Zeng},
journal = {Patterns},
volume = {4},
number = {12},
pages = {100891},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100891},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923002933},
author = {Yuxuan Zhao and Enmeng Lu and Yi Zeng},
abstract = {Yuxuan Zhao, associate professor, Enmeng Lu, research engineer, and Yi Zeng, professor and lab director, have proposed a brain-inspired bodily self-perception model based on biological findings on monkeys and humans. This model can reproduce various rubber hand illusion (RHI) experiments, which helps reveal the RHI’s computational and biological mechanisms. They talk about their view of data science and research plans for brain-inspired robot self-modeling and ethical robots.}
}
@article{POHL201654,
title = {Using lag-sequential analysis for understanding interaction sequences in visualizations},
journal = {International Journal of Human-Computer Studies},
volume = {96},
pages = {54-66},
year = {2016},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916300829},
author = {Margit Pohl and Günter Wallner and Simone Kriglstein},
keywords = {Interaction sequences, Lag-sequential analysis, Visualization, Log files, Thinking aloud},
abstract = {The investigation of how users make sense of the data provided by information systems is very important for human computer interaction. In this context, understanding the interaction processes of users plays an important role. The analysis of interaction sequences, for example, can provide a deeper understanding about how users solve problems. In this paper we present an analysis of sequences of interactions within a visualization system and compare the results to previous research. We used log file analysis and thinking aloud as methods. There is some indication based on log file analysis that there are interaction patterns which can be generalized. Thinking aloud indicates that some cognitive processes occur together with a higher probability than others.}
}
@incollection{ZIMMERMAN2005255,
title = {VIII - Development of Theory with Computation},
editor = {M. Olivucci},
series = {Theoretical and Computational Chemistry},
publisher = {Elsevier},
volume = {16},
pages = {255-278},
year = {2005},
booktitle = {Computational Photochemistry},
issn = {1380-7323},
doi = {https://doi.org/10.1016/S1380-7323(05)80025-1},
url = {https://www.sciencedirect.com/science/article/pii/S1380732305800251},
author = {Howard E. Zimmerman}
}
@article{JIANG2024102530,
title = {Product innovation design approach driven by implicit relationship completion via patent knowledge graph},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102530},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102530},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001782},
author = {Shaofei Jiang and Jingwei Yang and Jing Xie and Xuesong Xu and Yubo Dou and Liting Jing},
keywords = {Product innovation design, Patent text, Knowledge graph, RFSB ontology model, Implicit relationship completion},
abstract = {Product innovation design process involves a great deal of discrete engineering knowledge, limiting the ability of designers to quickly utilize this knowledge to support design innovation. Nowadays, innovation design based on knowledge graphs has enhanced the ability to explore design knowledge, improving the efficiency of knowledge retrieval. Previous studies have focused on mining more design knowledge to enrich the knowledge graph overlooks the implicit relationships with potential value among design knowledge, wasting design resources. To address these issues, an approach for product innovation design based on implicit knowledge relationship completion in the patent knowledge graph is proposed, which explores the implicit relationships between design knowledge to provide new knowledge satisfying design preferences and enhance the innovativeness of solutions. First, a requirements-function-structure-benefit (RFSB) knowledge ontology is constructed and extracted from the benefit knowledge of patents to build the knowledge graph. Second, an implicit relationship completion model based on the similarity of function or benefit entities explores the implicit relationships, replacing structure entities directly connected to similar function or benefit entities to generate new relationships and outputs novel ideas. Third, a scheme improvement process based on the co-occurrence frequency of requirement and structure knowledge supplements neglected design preferences. Final, a pipeline inspection robot case study is further employed to verify the proposed approach, and a patent knowledge graph assisted design solution prototype system is developed to assist in the utilization of innovative design knowledge. Evaluation results show the significant design potential of the proposed approach in inspiring innovative thinking and knowledge reuse.}
}
@article{MASON2020103898,
title = {Development and analysis of the Elementary Student Coding Attitudes Survey},
journal = {Computers & Education},
volume = {153},
pages = {103898},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103898},
url = {https://www.sciencedirect.com/science/article/pii/S036013152030097X},
author = {Stacie L. Mason and Peter J. Rich},
keywords = {Elementary education, Computational thinking, Coding, Attitude scale, Instrument validation},
abstract = {There is an increasing emphasis on teaching young learners to code; yet, there are few tools designed to measure the effect of learning to code on children. The purpose of this study was to develop and validate a tool to assess changes in young learners' attitudes toward coding: the Elementary Student Coding Attitudes Survey (ESCAS). We validated the scale using Confirmatory Factory Analysis and Structural Equation Modeling with responses from over 6000 4th-6th grade students (aged 9–12 years). Survey validation revealed a scale consisting of five constructs that comprise young learners' attitudes toward coding: social value, coding confidence, coding interest, perception of coders, and coding utility. In our analysis, students' grade level, ethnicity, gender, coding frequency, coding experience, and math interest influenced social value, which in turn influenced coding interest, perception of coders, and coding utility. Students' math confidence, coding frequency, coding experience, ethnicity, and coding interest predicted their coding confidence. Among observable variables, coding frequency and math interest had the greatest influence on social value, which substantially influenced all other factors. We discuss how this tool can help those who teach coding to young children to better measure and understand the variables that may influence young learners’ attitudes toward coding over time.}
}
@article{SUI2001529,
title = {Terrae Incognitae and Limits of Computation: Whither GIScience?},
journal = {Computers, Environment and Urban Systems},
volume = {25},
number = {6},
pages = {529-533},
year = {2001},
issn = {0198-9715},
doi = {https://doi.org/10.1016/S0198-9715(01)00027-8},
url = {https://www.sciencedirect.com/science/article/pii/S0198971501000278},
author = {Daniel Sui}
}
@article{HICKOK2011407,
title = {Sensorimotor Integration in Speech Processing: Computational Basis and Neural Organization},
journal = {Neuron},
volume = {69},
number = {3},
pages = {407-422},
year = {2011},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2011.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627311000675},
author = {Gregory Hickok and John Houde and Feng Rong},
abstract = {Sensorimotor integration is an active domain of speech research and is characterized by two main ideas, that the auditory system is critically involved in speech production and that the motor system is critically involved in speech perception. Despite the complementarity of these ideas, there is little crosstalk between these literatures. We propose an integrative model of the speech-related “dorsal stream” in which sensorimotor interaction primarily supports speech production, in the form of a state feedback control architecture. A critical component of this control system is forward sensory prediction, which affords a natural mechanism for limited motor influence on perception, as recent perceptual research has suggested. Evidence shows that this influence is modulatory but not necessary for speech perception. The neuroanatomy of the proposed circuit is discussed as well as some probable clinical correlates including conduction aphasia, stuttering, and aspects of schizophrenia.}
}
@article{CROOKS2014344,
title = {Defining and measuring conceptual knowledge in mathematics},
journal = {Developmental Review},
volume = {34},
number = {4},
pages = {344-377},
year = {2014},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2014.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0273229714000380},
author = {Noelle M. Crooks and Martha W. Alibali},
keywords = {Mathematical thinking, Conceptual knowledge, Equivalence, Cardinality, Inversion},
abstract = {A long tradition of research on mathematical thinking has focused on procedural knowledge, or knowledge of how to solve problems and enact procedures. In recent years, however, there has been a shift toward focusing, not only on solving problems, but also on conceptual knowledge. In the current work, we reviewed (1) how conceptual knowledge is defined in the mathematical thinking literature, and (2) how conceptual knowledge is defined, operationalized, and measured in three mathematical domains: equivalence, cardinality, and inversion. We uncovered three general issues. First, few investigators provide explicit definitions of conceptual knowledge. Second, the definitions that are provided are often vague or poorly operationalized. Finally, the tasks used to measure conceptual knowledge do not always align with theoretical claims about mathematical understanding. Together, these three issues make it challenging to understand the development of conceptual knowledge, its relationship to procedural knowledge, and how it can best be taught to students. In light of these issues, we propose a general framework that divides conceptual knowledge into two facets: knowledge of general principles and knowledge of the principles underlying procedures.}
}
@article{TALWAR2021102341,
title = {Has financial attitude impacted the trading activity of retail investors during the COVID-19 pandemic?},
journal = {Journal of Retailing and Consumer Services},
volume = {58},
pages = {102341},
year = {2021},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2020.102341},
url = {https://www.sciencedirect.com/science/article/pii/S0969698920313497},
author = {Manish Talwar and Shalini Talwar and Puneet Kaur and Naliniprava Tripathy and Amandeep Dhir},
keywords = {Artificial neural network, COVID-19, Financial behavior, Financial attitude, Financial anxiety, Pandemic},
abstract = {Financial attitude influences the financial behavior of retail investors. Although the extant research has acknowledged and examined this relationship, the measures of financial attitude and behavior still vary widely and are generally posed as a series of questions rather than statements. In addition to this, there is insufficient knowledge regarding retail investors' behavior in the face of a health crisis, such as the current COVID-19 pandemic. This study addresses these gaps in the prior literature by examining the relative influence of six dimensions of financial attitude, namely, financial anxiety, optimism, financial security, deliberative thinking, interest in financial issues, and needs for precautionary savings, on the trading activity of retail investors during the pandemic. Data were collected from 404 respondents and analyzed using the artificial neural network (ANN) method. The results revealed that all six dimensions had a positive influence on trading activity, with interest in financial issues exerting the strongest influence, followed by deliberative thinking. The study thus contributes important inferences for researchers and managers.}
}
@article{WOLFE197853,
title = {The rise of network thinking in anthropology},
journal = {Social Networks},
volume = {1},
number = {1},
pages = {53-64},
year = {1978},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(78)90012-6},
url = {https://www.sciencedirect.com/science/article/pii/0378873378900126},
author = {Alvin W. Wolfe},
abstract = {The encyclopedic inventory of the first half of the twentieth century, “Anthropology Today”, published in 1953, gave little inkling that within a few decades developing trends in social theory, in field experience, in electronic data processing, and in mathematics would combine to bring to prominence a distinctive theoretical approach using a quite formal network model for social systems. Now, sophisticated mathematics and computer programming permit sophisticated network models — networks seen as sets of links, networks seen as generated structures, and networks seen as flow processes. Although network thinking has shown a dramatic rise from the “Anthropology Today” of 1953 to the current anthropology of 1978, it is predicted to soar in the next quarter century, much of the weighty burden of network analysis having been lifted from us by ever more rapid electronic data processing.}
}
@article{MENGOV2014232,
title = {Person-by-person prediction of intuitive economic choice},
journal = {Neural Networks},
volume = {60},
pages = {232-245},
year = {2014},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014002123},
author = {George Mengov},
keywords = {Decision making, Economic choice, Experimental economics, Gated dipole, Intuitive thinking, Differential equations},
abstract = {Decision making is an interdisciplinary field, which is explored with methods spanning from economic experiments to brain scanning. Its dominant paradigms such as utility theory, prospect theory, and the modern dual-process theories all resort to formal algebraic models or non-mathematical postulates, and remain purely phenomenological. An approach introduced by Grossberg deployed differential equations describing neural networks and bridged the gap between decision science and the psychology of cognitive–emotional interactions. However, the limits within which neural models can explain data from real people’s actions are virtually untested and remain unknown. Here we show that a model built around a recurrent gated dipole can successfully forecast individual economic choices in a complex laboratory experiment. Unlike classical statistical and econometric techniques or machine learning algorithms, our method calibrates the equations for each individual separately, and carries out prediction person-by-person. It predicted very well the behaviour of 15%–20% of the participants in the experiment–half of them extremely well–and was overall useful for two thirds of all 211 subjects. The model succeeded with people who were guided by gut feelings and failed with those who had sophisticated strategies. One hypothesis is that this neural network is the biological substrate of the cognitive system for primitive–intuitive thinking, and so we believe that we have a model of how people choose economic options by a simple form of intuition. We anticipate our study to be useful for further studies of human intuitive thinking as well as for analyses of economic systems populated by heterogeneous agents.}
}
@article{HU2015287,
title = {A new face recognition method based on image decomposition for single sample per person problem},
journal = {Neurocomputing},
volume = {160},
pages = {287-299},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.02.032},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215001812},
author = {Changhui Hu and Mengjun Ye and Saiping Ji and Weili Zeng and Xiaobo Lu},
keywords = {Face recognition, Single sample per person problem, Lower-upper decomposition algorithm, Reverse thinking approach based on experimental analysis},
abstract = {The image decomposition based method is one of the efficient and important face recognition solutions for the single sample per person problem. The low image decomposition performance and the unconvincing reconstruction of the approximation image are the two main limitations of the previous methods. In this paper, a new single sample face recognition method based on lower-upper (LU) decomposition algorithm is proposed. The procedure of the proposed method is as following. First, the single sample and its transpose are decomposed to two sets of basis images by using the LU decomposition algorithm, which is more efficient than the image decomposition algorithms of the previous works. Two approximation images are reconstructed from the two basis image sets by the reverse thinking approach based on experimental analysis. Then, the fisher linear discriminant analysis (FLDA) algorithm is used to evaluate the optimal projection space by using the new training set consisting of the single sample and its two approximation images for each person. Finally, the nearest neighbor classifier based on Euclidean distance is adopted as the final classification. We make two main contributions: one is that we propose to decompose the single sample and its transpose using the efficient LU decomposition algorithm, and reorder each basis image set according to the basis image energy; the other is that we present a reverse thinking approach based on experimental analysis to reconstruct the approximation image. The performance of the proposed method is verified using four public face databases, namely FERET, AR, ORL and Yale B. The experimental results indicate that the proposed method is efficient and outperforms several state-of-the-art approaches which are proposed to address the single sample per person problem.}
}
@article{TUZUN202085,
title = {Introduction to systems engineering and sustainability PART I: Student-centred learning for chemical and biological engineers},
journal = {Education for Chemical Engineers},
volume = {31},
pages = {85-93},
year = {2020},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2020.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1749772820300269},
author = {U. Tuzun},
keywords = {Systems engineering & sustainability, Active learning, Formative assessment},
abstract = {Student-Centred Active Learning of Systems Engineering and Sustainability requires challenging metacognitive integration of high-level evaluation skills combined with discipline-based core knowledge. This two-part series aims to demonstrate the basic principles, methodology and specific examples of active learning with formative assessment implemented to achieve improved student academic performance. In this part I of the two-part series, firstly, a detailed description is introduced of the cognitive learning methodology which makes use of student-centered recognition, analysis and synthesis for decision-making when there is no entirely right or wrong decision. The concept of “decision situation” is described which combines several surrounding and contingency elements to arrive at a demonstration of the holistic decision-making through systems analysis. A Holistic thinking approach is further developed using a systems learning methodology that combines normative with descriptive analyses to arrive at a cognitive mode model of judgement and choice. Sustainability modelling using the three-gateway systems approach is introduced and compared with the multi-layered view of chemical and biochemical engineering education and research; see Gani et al. (2020). Holistic thinking strategy is applied most recently to integrating, backcasting and eco-design for the circular economy (CE); see Mendoza et al. (2017). A student-centred learning approach is advocated that makes use of these principles and enables the systematic embedding of sustainability modeling in industrial and economic activities whose success rely substantively on decision-making. Finally, the relative importance is evaluated using classroom data available with specific engineering topics of the didactic “rule-based” methods of knowledge transfer in contrast with the experiential accumulation of practical information amassed through social interactions in a co-operative learning environment that relies on sustained improvement through active communication and feedback between the teacher/instructor and the student/learner; see Stephan et al. (2017) and Shallcross and Alpay (2018).}
}
@article{XU2025121541,
title = {Adaptive sequential three-way decisions for dynamic time warping},
journal = {Information Sciences},
volume = {690},
pages = {121541},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121541},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524014555},
author = {Jianfeng Xu and Ruihua Wang and Yuanjian Zhang and Weiping Ding},
keywords = {Time-series data, Sequential three-way decisions, Dynamic time warping, Uncertainty},
abstract = {Dynamic time warping (DTW) algorithm is widely used in diversified applications due to its excellent anti-deformation and anti-interference in measuring time-series based similarity. However, the high time complexity of DTW restrains the applicability of real-time case. The existing DTW acceleration studies suffer from a loss of accuracy. How to accelerate computation while maintaining satisfying computational accuracy remains challenging. Motivated by sequential three-way decisions, this paper develops a novel model with adaptive sequential three-way decisions for dynamic time warping (AS3-DTW). Firstly, we systematically summarize distance differences under the context of adjacent tripartite search spaces for DTW, and propose five patterns of granularity adjustments of the search spaces. Furthermore, we present the corresponding calculation method of DTW adjacent tripartite search spaces distances difference. Finally, we construct a novel dynamism on adaptively adjusting time warping by combining sequence-based multi-granularity with sequential three-way decisions. Experimental results show that AS3-DTW effectively achieves promising trade-off between computational speed and accuracy on multiple UCR datasets when compared with the state-of-the-art algorithms.}
}
@article{FERNANDEZFONTECHA2022101067,
title = {Examining the relations between semantic memory structure and creativity in second language},
journal = {Thinking Skills and Creativity},
volume = {45},
pages = {101067},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101067},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000700},
author = {Almudena Fernández-Fontecha and Yoed N. Kenett},
keywords = {Creativity, Semantic network, L2, Bilingualism, Semantic fluency},
abstract = {Creativity is related to a higher flexible semantic memory structure, which could explain greater fluency of ideas. Extensive research has identified a positive connection between creativity and bi-/multilingualism mainly in contexts where two languages or more concur in daily communicative interactions. Yet, creativity has received scant attention in regard to L2 (second or foreign language) acquisition that mainly takes place in classroom situations. The scarce research points to a positive relationship between creativity and L2 fluency – understood as the number of words produced. We apply computational network science analysis and Forward Flow methods to examine lexical organization patterns of a low creativity (LC) and high creativity (HC) group of 12th grade Spanish English as a Foreign Language (EFL) learners. The participants completed two fluency tasks, where they generated animal names in their L2, and also L1 – used here as a control measure. EFL proficiency was controlled. Our analyses revealed that the HC individuals were more fluent in L1 and L2, generated more remote responses, and exhibited a more flexible and efficiently structured semantic memory in both languages, with a greater effect of creativity in L2. Contrary to previous research, the L2 semantic memory network exhibited a less random organization. Differences in the L2 learning conditions are adduced as likely causes of this result.}
}
@incollection{YETURU20233,
title = {Chapter 1 - Object-oriented basis of artificial intelligence methodologies},
editor = {Steven G. Krantz and Arni S.R. {Srinivasa Rao} and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {49},
pages = {3-46},
year = {2023},
booktitle = {Artificial Intelligence},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169716123000251},
author = {Kalidas Yeturu},
keywords = {Object oriented, Vector representation, Induction, Deduction, Machine learning, Artificial intelligence},
abstract = {If O2 is for I, then what is O2 for AI? What is oxygen for humans is what is object-oriented thinking for artificial intelligent systems. Much the same way as humans need O2 knowingly or unknowingly, the first step in designing an AI system requires the application of object-oriented principles either explicitly or implicitly. The basis of the definition of state in AI is a description of the concept of interest as an object with properties. The idea of an object extends beyond typical noun forms that describe elements of the real world. The verb forms are included as well with -able suffixes such as runnable, serializable, and executable. In the software world, the first step in modeling a business requirement is the identification of objects of interest and defining their properties and interactions. For instance, in the case of web services, a service is an object; in the case of database systems, a table or a transaction is an object; or in the case of large-scale integration, electronic components are objects. The concept of an object extends beyond the software realm and into the mathematical world in an implicit form. Functional analysis is an old topic in mathematics where each function is an object indeed. The concept of space in mathematics relates closely to the possible value ranges of all attributes of an object. Mathematical operators are the same as methods of objects. It is day-to-day practical life in any modern operating system software dealing with process objects and applications such as Python scripts involving function objects. In this chapter, the application of object-oriented thinking to convert a business requirement to a machine learning (ML) formulation is presented with examples. The five steps of supervised ML formulation based on vector representations of input and output, mapping function, loss function, and data set are clarified. The scope and limitation of ML formulation as against general AI methodology are discussed to demystify popular myths. This chapter also reveals the secret behind the success of deep learning methodology as automatic differentiation involving function objects.}
}
@article{BROSSEAU2003373,
title = {Computational electromagnetics and the rational design of new dielectric heterostructures},
journal = {Progress in Materials Science},
volume = {48},
number = {5},
pages = {373-456},
year = {2003},
issn = {0079-6425},
doi = {https://doi.org/10.1016/S0079-6425(02)00013-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079642502000130},
author = {C. Brosseau and A. Beroual},
abstract = {Dielectric properties of heterogeneous materials for various condensed-matter systems have been gaining world-wide attention over the past 50 or so years in the design (or engineering) of materials structures for desired properties and functional purposes. These applications range from cable and current limiters to sensors. These multiscale systems lead to challenging problems of connecting micro- or meso-structural features to macroscopic materials response, i.e. permittivity, conductivity. This article first reviews progress made at that time of the underlying physics of dielectric heterostructures and points out the missing elements that have led to a resurgence of interest in these and related materials. Recent advances in computational electromagnetics provide unparalleled control over morphology in this class of materials to produce a seemingly unlimited number of exquisitely structured materials endowed with tailored electromagnetic, and other physical properties. In the text to follow, we illustrate how an ab initio computational technique can be used to accurately characterize structure–dielectric property relationships of periodic heterostructures in the quasistatic limit. More specifically, we have carried out two-dimensional (2D) and three-dimensional (3D) numerical studies of two-component materials in which equal-sized inclusions, with shape and orientation and possibly fused together, are fixed in a periodic square (2D) or cubic (3D) array. Boundary-integral equations (BIE) are derived from Green's theorem and are solved for the local field with appropriate periodicity conditions on a unit cell of the structures using the field calculation package PHI3D. A number of illustrative examples shows how this computational technique can provide very accurate predictions for the complex effective permittivity of translationally-invariant heterostructures. The performance of the method is also compared with those of other computational and analytical techniques. We comment on how this computational method helps identify some important characteristics for rationalizing and predicting the structure of composite materials in terms of the nature, size, shape and orientation of their constituents.}
}
@article{WOLFF2024893,
title = {The mediodorsal thalamus in executive control},
journal = {Neuron},
volume = {112},
number = {6},
pages = {893-908},
year = {2024},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324000023},
author = {Mathieu Wolff and Michael M. Halassa},
keywords = {thalamus, mediodorsal, prefrontal cortex, cognition, cognitive flexibility, computation, neural architectures},
abstract = {Summary
Executive control, the ability to organize thoughts and action plans in real time, is a defining feature of higher cognition. Classical theories have emphasized cortical contributions to this process, but recent studies have reinvigorated interest in the role of the thalamus. Although it is well established that local thalamic damage diminishes cognitive capacity, such observations have been difficult to inform functional models. Recent progress in experimental techniques is beginning to enrich our understanding of the anatomical, physiological, and computational substrates underlying thalamic engagement in executive control. In this review, we discuss this progress and particularly focus on the mediodorsal thalamus, which regulates the activity within and across frontal cortical areas. We end with a synthesis that highlights frontal thalamocortical interactions in cognitive computations and discusses its functional implications in normal and pathological conditions.}
}
@incollection{CAMERON200789,
title = {Designing Computational Clusters for Performance and Power},
editor = {Marvin V. Zelkowitz},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {69},
pages = {89-153},
year = {2007},
booktitle = {Architectural Issues},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(06)69002-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065245806690025},
author = {Kirk W. Cameron and Rong Ge and Xizhou Feng},
abstract = {Power consumption in computational clusters has reached critical levels. High-end cluster performance improves exponentially while the power consumed and heat dissipated increase operational costs and failure rates. Yet, the demand for more powerful machines continues to grow. In this chapter, we motivate the need to reconsider the traditional performance-at-any-cost cluster design approach. We propose designs where power and performance are considered critical constraints. We describe power-aware and low power techniques to reduce the power profiles of parallel applications and mitigate the impact on performance.}
}
@article{DRAGGIOTIS1998157,
title = {On the computation of multigluon amplitudes},
journal = {Physics Letters B},
volume = {439},
number = {1},
pages = {157-164},
year = {1998},
issn = {0370-2693},
doi = {https://doi.org/10.1016/S0370-2693(98)01015-6},
url = {https://www.sciencedirect.com/science/article/pii/S0370269398010156},
author = {Petros Draggiotis and Ronald H.P. Kleiss and Costas G. Papadopoulos},
abstract = {A computational algorithm based on recursive equations is developed in order to estimate multigluon production processes at high energy hadron colliders. The partonic reactions gg→(n−2)g with n≤9 are studied and comparisons with known approximations are presented.}
}
@article{HARDING2024295,
title = {A new predictive coding model for a more comprehensive account of delusions},
journal = {The Lancet Psychiatry},
volume = {11},
number = {4},
pages = {295-302},
year = {2024},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(23)00411-X},
url = {https://www.sciencedirect.com/science/article/pii/S221503662300411X},
author = {Jessica Niamh Harding and Noham Wolpe and Stefan Peter Brugger and Victor Navarro and Christoph Teufel and Paul Charles Fletcher},
abstract = {Summary
Attempts to understand psychosis—the experience of profoundly altered perceptions and beliefs—raise questions about how the brain models the world. Standard predictive coding approaches suggest that it does so by minimising mismatches between incoming sensory evidence and predictions. By adjusting predictions, we converge iteratively on a best guess of the nature of the reality. Recent arguments have shown that a modified version of this framework—hybrid predictive coding—provides a better model of how healthy agents make inferences about external reality. We suggest that this more comprehensive model gives us a richer understanding of psychosis compared with standard predictive coding accounts. In this Personal View, we briefly describe the hybrid predictive coding model and show how it offers a more comprehensive account of the phenomenology of delusions, thereby providing a potentially powerful new framework for computational psychiatric approaches to psychosis. We also make suggestions for future work that could be important in formalising this novel perspective.}
}
@incollection{YANG20133,
title = {1 - Swarm Intelligence and Bio-Inspired Computation: An Overview},
editor = {Xin-She Yang and Zhihua Cui and Renbin Xiao and Amir Hossein Gandomi and Mehmet Karamanoglu},
booktitle = {Swarm Intelligence and Bio-Inspired Computation},
publisher = {Elsevier},
address = {Oxford},
pages = {3-23},
year = {2013},
isbn = {978-0-12-405163-8},
doi = {https://doi.org/10.1016/B978-0-12-405163-8.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124051638000016},
author = {Xin-She Yang and Mehmet Karamanoglu},
keywords = {Algorithm, ant algorithm, bee algorithm, bat algorithm, bio-inspired, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, swarm intelligence, metaheuristics},
abstract = {Swarm intelligence (SI) and bio-inspired computing in general have attracted great interest in almost every area of science, engineering, and industry over the last two decades. In this chapter, we provide an overview of some of the most widely used bio-inspired algorithms, especially those based on SI such as cuckoo search, firefly algorithm, and particle swarm optimization. We also analyze the essence of algorithms and their connections to self-organization. Furthermore, we highlight the main challenging issues associated with these metaheuristic algorithms with in-depth discussions. Finally, we provide some key, open problems that need to be addressed in the next decade.}
}