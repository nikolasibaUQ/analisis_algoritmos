@incollection{DELLANGELO2022299,
title = {13 - Computational chemistry and the study and design of catalysts},
editor = {Liliana Mammino},
booktitle = {Green Chemistry and Computational Chemistry},
publisher = {Elsevier},
pages = {299-332},
year = {2022},
series = {Advances in Green and Sustainable Chemistry},
isbn = {978-0-12-819879-7},
doi = {https://doi.org/10.1016/B978-0-12-819879-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198797000106},
author = {David Dell’Angelo},
keywords = {CO capture, conversion and utilization, Energy storage, Free energy techniques, Metal-organic frameworks (MOFs), Nanohazard simulations, Photocatalysis technologies, Roles of catalysis in green chemistry, Simulation methods in molecular modelling, Solvent effects on chemical reactivity, Zeolites and catalysis},
abstract = {Several theoretical and computational chemistry works may yield results that prove useful for a better understanding of phenomena relevant to green chemistry, or may specifically focus on addressing green chemistry issues. This chapter presents an overview of results of this type, considering their various application areas. At the same time, it devotes particular attention to the roles that computationally obtained information may play for an efficient design of catalysts and for a better understanding of catalytic processes. This particular attention is motivated by the fundamental roles of catalysis in the design of ‘greener’ processes, where ‘greener’ may refer to a variety of aspects, such as the use of safer reactants and products, the use of benign solvents, the increase in energy efficiency and other features that make a process more environmentally friendly.}
}
@article{CAMERON2017131,
title = {Lateral thinking – Interocular symmetry and asymmetry in neurovascular patterning, in health and disease},
journal = {Progress in Retinal and Eye Research},
volume = {59},
pages = {131-157},
year = {2017},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S135094621630091X},
author = {James R. Cameron and Roly D. Megaw and Andrew J. Tatham and Sarah McGrory and Thomas J. MacGillivray and Fergus N. Doubal and Joanna M. Wardlaw and Emanuele Trucco and Siddharthan Chandran and Baljean Dhillon},
keywords = {Interocular symmetry, Asymmetry, Retina, Retinal imaging, Retinal vasculature, Patterning},
abstract = {No biological system or structure is likely to be perfectly symmetrical, or have identical right and left forms. This review explores the evidence for eye and visual pathway asymmetry, in health and in disease, and attempts to provide guidance for those studying the structure and function of the visual system, where recognition of symmetry or asymmetry may be essential. The principal question with regards to asymmetry is not ‘are the eyes the same?’, for some degree of asymmetry is pervasive, but ‘when are they importantly different?’. Knowing if right and left eyes are ‘importantly different’ could have significant consequences for deciding whether right or left eyes are included in an analysis or for examining the association between a phenotype and ocular parameter. The presence of significant asymmetry would also have important implications for the design of normative databases of retinal and optic nerve metrics. In this review, we highlight not only the universal presence of asymmetry, but provide evidence that some elements of the visual system are inherently more asymmetric than others, pointing to the need for improved normative data to explain sources of asymmetry and their impact on determining associations with genetic, environmental or health-related factors and ultimately in clinical practice.}
}
@article{YERION20151967,
title = {An Introductory Course in the Computational Modeling of Nature},
journal = {Procedia Computer Science},
volume = {51},
pages = {1967-1976},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.461},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012697},
author = {Kathie A. Yerion},
keywords = {Modeling, Agent-based, System-dynamics},
abstract = {This introductory course in computational modeling of nature contains the development of three kinds of models of phenomena in nature -- agent-based models and simple finite difference models using the environment of the NetLogo language and complex finite difference models using the language of C++. No prior programming experience is assumed. The natural phenomena modeled include some standard ones (e.g. ants following pheromone trails, the interaction of sheep and wolves) and some non-standard ones (the creation of the world, 3 dogs playing games, and formation of stripes and spots in the skins of animals). The emphasis of the course is on the modeling process. A distinguishing feature is that students are able to compare and critique these models.}
}
@article{LIU20111907,
title = {The effect of simulation games on the learning of computational problem solving},
journal = {Computers & Education},
volume = {57},
number = {3},
pages = {1907-1918},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511000832},
author = {Chen-Chung Liu and Yuan-Bang Cheng and Chia-Wen Huang},
keywords = {Game-based learning, Problem solving, Simulation, Flow experience},
abstract = {Simulation games are now increasingly applied to many subject domains as they allow students to engage in discovery processes, and may facilitate a flow learning experience. However, the relationship between learning experiences and problem solving strategies in simulation games still remains unclear in the literature. This study, thus, analyzed the feedback and problem solving behaviors of 117 students in a simulation game, designed to assist them to learn computational problem solving. It was found that students when learning computational problem solving with the game were more likely to perceive a flow learning experience than in traditional lectures. The students’ intrinsic motivation was also enhanced when they learned with the simulation game. In particular, the results of the study found a close association between the students’ learning experience states and their problem solving strategies. The students who perceived a flow experience state frequently applied trial-and-error, learning-by-example, and analytical reasoning strategies to learn the computational problem solving skills. However, a certain portion of students who experienced states of boredom and anxiety did not demonstrate in-depth problem solving strategies. For instance, the students who felt anxious in the simulation game did not apply the learning-by-example strategy as frequently as those in the flow state. In addition, the students who felt bored in the simulation game only learned to solve the problem at a superficial level.}
}
@article{GISSEL201661,
title = {A case of fixed asset accounting: Initial and subsequent measurement},
journal = {Journal of Accounting Education},
volume = {37},
pages = {61-66},
year = {2016},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575116300422},
author = {Jodi L. Gissel},
keywords = {Fixed asset acquisition, Depreciation, Interest capitalization, Nonmonetary exchange, Impairment, IFRS},
abstract = {This instructional case integrates multiple accounting concepts relating to fixed asset acquisition and subsequent measurement. You must apply accounting knowledge, professional judgment, and critical thinking skills to evaluate fixed assets and make recommendations. You must also analyze differences between fixed asset accounting under US generally accepted accounting principles and IFRS. As a student, you generally understand basic application of asset cost computation that simply recognizes the amount of cash paid for acquiring the asset. However, determining asset cost becomes challenging when you encounter more complex situations. You must consider initial measurement issues relating to a land purchase (demolition of existing building and a special assessment expenditure), interest capitalization for a self-constructed building, a nonmonetary asset exchange, and an asset retirement obligation. The case also considers subsequent measurement issues in terms of depreciation (straight-line and accelerated methods), replacement of an asset component, and impairment. The case structure is flexible and the teaching notes include alternatives for using scaled-down versions.}
}
@article{HAWTHORNE2022100931,
title = {Reconceptualizing a mathematical domain on the basis of student reasoning: Considering teachers’ perspectives about integers},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100931},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100931},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000924},
author = {Casey Hawthorne and Randolph A. Philipp and Lisa L. Lamb and Jessica P. Bishop and Ian Whitacre and Bonnie P. Schappelle},
keywords = {Integers, Student thinking, Mathematical knowledge for teaching},
abstract = {Integers have historically been approached as a system of rules. However, to teach any mathematical domain for understanding, teachers must conceptualize it as comprised of more than procedures. Using as a lens the four types of integer reasoning identified by Bishop et al. (2014a, 2014b), we interviewed 7th-grade teachers to investigate their own integer reasoning and how this corresponds to their approaches to teaching integers and to their interpretations of students’ reasoning. The teachers not only correctly solved integer tasks but also most reasoned using more than rules, demonstrating a flexibility of strategies. Additionally, although they attempted to introduce integers in meaningful ways, most teachers viewed teaching integers as helping their students apply procedures, an orientation that constrained their understanding of students’ integer reasoning. Results indicate that teachers possess productive conceptual resources but need a structure to leverage their understandings to teach integers as more than a set of rules.}
}
@article{LETONSAARI2017131,
title = {Modeling computational algorithms using nonlinear storytelling methods of computer game design},
journal = {Procedia Computer Science},
volume = {119},
pages = {131-138},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.169},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323797},
author = {Mika Letonsaari and Jukka Selin},
keywords = {Twine, visual programming, rapid prototyping, algorithm design, digital storytelling},
abstract = {Computational algorithms can be described in many methods and implemented in many languages. Here we present an approach using storytelling methods of computer game design in modeling some finite-state machine algorithms and applications requiring user interaction. An open source software Twine is used for the task. Interactive nonlinear stories created with Twine are applications that can be executed in a web browser. Storytelling approach provides an easy-to-understand view on computational algorithms allowing communication with people with no computer science education. It also allows rapid prototyping and testing in mixed background work teams.}
}
@incollection{IACOBONI2000523,
title = {17 - Mapping Human Cognition: Thinking, Numerical Abilities, Theory of Mind, Consciousness},
editor = {Arthur W. Toga and John C. Mazziotta},
booktitle = {Brain Mapping: The Systems},
publisher = {Academic Press},
address = {San Diego},
pages = {523-534},
year = {2000},
isbn = {978-0-12-692545-6},
doi = {https://doi.org/10.1016/B978-012692545-6/50019-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780126925456500192},
author = {Marco Iacoboni},
abstract = {Publisher Summary
This chapter discusses the mapping the brain activity associated with complex cognitive functions—problem solving, reasoning, numerical processing, and consciousness. One of the most widely used tasks in brain mapping studies of problem solving is the Raven's progressive matrices. The role of frontoparietal circuits in numerical cognition has been confirmed by a positron emission tomography (PET) investigation of number multiplication and number comparison, in which bilateral frontoparietal networks are activated during both tasks. Various other regions are also found activated in this investigation, in which an exploratory, hypotheses-generating approach determined relatively “liberal” statistical thresholds. The consciousness of action is an important component of consciousness. However, the most common approach to the study of consciousness and its neural counterpart in cognitive neuroscience is via perception and visual awareness. A variety of brain mapping techniques, from PET and functional magnetic resonance imaging to electrical scalp recording, have been already used in investigations directly addressing visual awareness in normal subjects and patients with neurological disorders. A paradigm that is extremely suitable for the examination of conscious perception is binocular rivalry. A different mapping approach to the study of conscious perception is the mapping of temporal neural events.}
}
@article{SHENGLAI20124318,
title = {Study on Simulation Modeling and Approximate Synchronous Computation Technology for the Active Structural Stiffness Design},
journal = {Procedia Engineering},
volume = {29},
pages = {4318-4324},
year = {2012},
note = {2012 International Workshop on Information and Electronics Engineering},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.01.664},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812006741},
author = {Xia Shenglai and He Jingwu and Chu Hongyu and Yang Xuan},
keywords = {active structural stiffness design (ASSD), stiffness criterion, simulation modeling, computation analysis, section stiffness},
abstract = {In the past, structure design mainly adopted strength criterion. At the same time, many problems occurred due to structural stiffness deficiency. In order to resolve many practical problems resulted from structural stiffness in aircraft structure, and draw out structural potential better, the design idea of active structural stiffness, namely, the method of active structural stiffness design (ASSD) is put forward at the beginning of the structure design. For ASSD, there are three key factors should be considered, that is, stiffness criterion, simulation modeling and computation analysis. In this paper, stiffness criterion, which is important at the preliminary stage of structural design, will be researched; Simulation modeling adopts parametric modeling technology; computation analysis is based on engineering beam theory, which is compiled and embedded into CATIA to compute structural stiffness. Using simulation modeling and computation analysis technologies, ASSD can be achieved quickly and conveniently.}
}
@article{EDELMAN201791,
title = {Language and other complex behaviors: Unifying characteristics, computational models, neural mechanisms},
journal = {Language Sciences},
volume = {62},
pages = {91-123},
year = {2017},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117300128},
author = {Shimon Edelman},
abstract = {Similar to other complex behaviors, language is dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions or thoughts in others and self (Edelman, 2017b). An analysis of the functional characteristics shared by complex sequential behaviors suggests that they all present a common overarching computational problem: dynamically controlled constrained navigation in concrete or abstract situation spaces. With this conceptual framework in mind, I compare and contrast computational models of language and evaluate their potential for explaining linguistic behavior and for elucidating the brain mechanisms that support it.}
}
@article{FIGLIOLIA2020102968,
title = {An FPGA multiprocessor architecture for Bayesian online change point detection using stochastic computation},
journal = {Microprocessors and Microsystems},
volume = {74},
pages = {102968},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102968},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119304727},
author = {Tomas Figliolia and Andreas G. Andreou},
keywords = {Changepoint analysis, Changepoint detection, Image segmentation, Bayesian inference, On-line algorithm, Stochastic processing, Precision on demand, ASIC, VHDL, Probabilistic event representation},
abstract = {In this paper we report on an event-based stochastic architecture for the Adams/McKay Bayesian Online Change Point Detection algorithm (BOCPD) [1]. In the stochastic computational structures, probabilities are represented natively as stochastic events and computation is carried out directly with these probabilities and not probability density functions. A fully programmable BOCPD processor is synthesized in VHDL. The BOCPD algorithm with on-line learning, to perform foreground/background image segmentation with online learning. Running on a single Kintex 7 FPGA (Opal Kelly XEM7350-K410T) the architecture is capable of real-time processing a 160 × 120 pixels image, at 10 frames per second.}
}
@article{THIRUNAVUKARASU2022106020,
title = {Towards computational solutions for precision medicine based big data healthcare system using deep learning models: A review},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106020},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007429},
author = {Ramkumar Thirunavukarasu and George Priya Doss C and Gnanasambandan R and Mohanraj Gopikrishnan and Venketesh Palanisamy},
keywords = {Personalized medicine, Precision medicine, Artificial intelligence, Deep learning, Healthcare big data},
abstract = {The emergence of large-scale human genome projects, advances in DNA sequencing technologies, and the massive volume of electronic medical records [EMR] shift the transformation of healthcare research into the next paradigm, namely ‘Precision Medicine.’ This new clinical system model uses patients' genomic profiles and disparate healthcare data sources to a greater extent and provides personalized deliverables. As an advanced analytical technique, deep learning models significantly impact precision medicine because they can process voluminous amounts of diversified data with improved accuracy. Two salient features of deep learning models, namely processing a massive volume of multi-model data at multiple levels of abstraction and the ability to identify inherent features from the input data on their own, attract the implication of deep learning techniques in precision medicine research. The proposed review highlights the importance of deep learning-based analytical models in handling diversified and disparate big data sources of precision medicine. To augment further, state-of-the-art precision medicine research based on the taxonomy of deep learning models has been reviewed along with their research outcomes. The diversified data inputs used in research attempts, their applications, benchmarking data repositories, and usage of various evaluation measures for accuracy estimations are highlighted in this review. This review also brings out some promising analytical avenues of precision medicine research that give directions for future exploration.}
}
@article{REN201310351,
title = {Challenges in the assignment of relative and absolute configurations of complex molecules: computation can resolve conflicts between theory and experiment},
journal = {Tetrahedron},
volume = {69},
number = {48},
pages = {10351-10356},
year = {2013},
issn = {0040-4020},
doi = {https://doi.org/10.1016/j.tet.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S004040201301538X},
author = {Jie Ren and Guo-You Li and Lan Shen and Guo-Lin Zhang and Laurance A. Nafie and Hua-Jie Zhu},
keywords = {Absolute configuration reassignment, DFT, Chiroptical spectroscopy, Transition state, X-ray},
abstract = {The configuration of (−)-brevianamides was assigned as (2S,13S) based on X-ray structure analysis and hydrolysis experiments. However, our theoretical investigation of its chiroptical properties strongly implied that the correct configuration should be (2R,13R). The reasons for the incorrect earlier assignment are analyzed by calculations of conversion energy barriers among different intermediates, starting materials and final products. This study demonstrates that conflicting theoretical and, experimental results suggest that it is premature to assign the configuration of a natural product.}
}
@article{FEHER201498,
title = {Computational approaches to mapping allosteric pathways},
journal = {Current Opinion in Structural Biology},
volume = {25},
pages = {98-103},
year = {2014},
note = {Theory and simulation / Macromolecular machines},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2014.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X14000190},
author = {Victoria A Feher and Jacob D Durrant and Adam T {Van Wart} and Rommie E Amaro},
abstract = {Allosteric signaling occurs when chemical and/or physical changes at an allosteric site alter the activity of a primary orthosteric site often many Ångströms distant. A number of recently developed computational techniques, including dynamical network analysis, novel topological and molecular dynamics methods, and hybrids of these methods, are useful for elucidating allosteric signaling pathways at the atomistic level. No single method prevails as best to identify allosteric signal propagation path(s), rather each has particular strengths in characterizing signals that occur over specific timescale ranges and magnitudes of conformational fluctuation. With continued improvement in accuracy and predictive power, these computational techniques aim to become useful drug discovery tools that will allow researchers to identify allostery critical residues for subsequent pharmacological targeting.}
}
@article{THABTAH2018112,
title = {A new computational intelligence approach to detect autistic features for autism screening},
journal = {International Journal of Medical Informatics},
volume = {117},
pages = {112-124},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618300546},
author = {Fadi Thabtah and Firuz Kamalov and Khairan Rajab},
keywords = {Accuracy, Autism Spectrum Disorder, Behaviour science, Classifiers, Computational intelligence, Data mining, Feature analysis, Machine learning, Sensitivity, Specificity},
abstract = {Autism Spectrum Disorder (ASD) is one of the fastest growing developmental disability diagnosis. General practitioners (GPs) and family physicians are typically the first point of contact for patients or family members concerned with ASD traits observed in themselves or their family member. Unfortunately, some families and adult patients are unaware of ASD traits that may be exhibited and as a result do not seek out necessary diagnostic services or contact their GP. Therefore, providing a quick, accessible, and simple tool utilizing items related to ASD to these families may increase the likelihood they will seek professional assessment and is vital to the early detection and treatment of ASD. This study aims at identifying fewer, albeit influential, features in common ASD screening methods in order to achieve efficient screening as demands on evaluating the items’ influences on ASD within existing tools is urgent. To achieve this aim, a computational intelligence method called Variable Analysis (Va) is proposed that considers feature-to-class correlations and reduces feature-to-feature correlations. The results of the Va have been verified using two machine learning algorithms by deriving automated classification systems with respect to specificity, sensitivity, positive predictive values (PPVs), negative predictive values (NPVs), and predictive accuracy. Experimental results using cases and controls related to items in three common screening methods, along with features related to individuals, have been analysed and compared with results obtained from other common filtering methods. The results exhibited that Va was able to derive fewer numbers of features from adult, adolescent, and child screening methods yet maintained competitive predictive accuracy, sensitivity, and specificity rates.}
}
@article{TANG2024103266,
title = {A causal counterfactual graph neural network for arising-from-chair abnormality detection in parkinsonians},
journal = {Medical Image Analysis},
volume = {97},
pages = {103266},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103266},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001919},
author = {Xinlu Tang and Rui Guo and Chencheng Zhang and Xiaohua Qian},
keywords = {Parkinson's disease, Arising-from-chair, Graph neural network, Causal inference, Counterfactual thinking},
abstract = {The arising-from-chair task assessment is a key aspect of the evaluation of movement disorders in Parkinson's disease (PD). However, common scale-based clinical assessment methods are highly subjective and dependent on the neurologist's expertise. Alternate automated methods for arising-from-chair assessment can be established based on quantitative susceptibility mapping (QSM) images with multiple-instance learning. However, performance stability for such methods can be typically undermined by the presence of irrelevant or spuriously-relevant features that mask the intrinsic causal features. Therefore, we propose a QSM-based arising-from-chair assessment method using a causal graph-neural-network framework, where counterfactual and debiasing strategies are developed and integrated into this framework for capturing causal features. Specifically, the counterfactual strategy is proposed to suppress irrelevant features caused by background noise, by producing incorrect predictions when dropping causal parts. The debiasing strategy is proposed to suppress spuriously relevant features caused by the sampling bias and it comprises a resampling guidance scheme for selecting stable instances and a causal invariance constraint for improving stability under various interferences. The results of extensive experiments demonstrated the superiority of the proposed method in detecting arising-from-chair abnormalities. Its clinical feasibility was further confirmed by the coincidence between the selected causal features and those reported in earlier medical studies. Additionally, the proposed method was extensible for another motion task of leg agility. Overall, this study provides a potential tool for automated arising-from-chair assessment in PD patients, and also introduces causal counterfactual thinking in medical image analysis. Our source code is publicly available at https://github.com/SJTUBME-QianLab/CFGNN-PDarising.}
}
@article{MARTIN2000195,
title = {What do animals do all day?: The division of labor, class bodies, and totemic thinking in the popular imagination},
journal = {Poetics},
volume = {27},
number = {2},
pages = {195-231},
year = {2000},
issn = {0304-422X},
doi = {https://doi.org/10.1016/S0304-422X(99)00025-X},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X9900025X},
author = {John Levi Martin},
keywords = {Animals, Totemism, Class body, Busytown, Symbolic domination, Division of labor},
abstract = {This article uses relatively new methods of the analysis of qualitative data to investigate the socio-logical relation between animal species and occupation in the popular imagination, specifically in the world of children's literature, in order to test a claim that the class habitus that naturalizes the division of labor, erasing the contingent nature of class domination, does not simply arise via the internalization of objective social divisions into a subjective social vision, but rather begins with the application of a totemic logic which maps differences between people onto differences between animals, thereby exaggerating and naturalizing them. Children are evidently instructed in the reality of class bodies and the logic of social structure before they have any first-hand acquaintance with these social processes; indeed, by working the embodied relations of class domination into the role play and role learning of the pre-school years, we make it difficult for them to have any unmediated first-hand experience that would militate against these habitual distinctions.}
}
@article{SADEGHIPOUR2012213,
title = {Gesture processing as grounded motor cognition: Towards a computational model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {32},
pages = {213-223},
year = {2012},
note = {The 4th International Conference of Cognitive Science},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S187704281200033X},
author = {Amir Sadeghipour and Stefan Kopp},
keywords = {Motor Cognition, embodiment, grounded cognition, gestures, social interaction, computational model, embodied conversational agents},
abstract = {In this paper, we present an approach to treat and model the processing (i.e. recognition and production) of communicative gestures as grounded motor cognition. We first review cognitive theories and neuropsychological studies on human motor cognition. On this basis, we propose a computational framework that connects the sensorimotor processing of hand gestures in representational structures of meaning (visuospatial imagery), other modalities (language), and communicative intentions. We present an implementation that enables an embodied virtual agent to engage in gesture-based interaction with a human user.}
}
@incollection{CARETTE202215,
title = {Chapter Two - Embracing the laws of physics: Three reversible models of computation},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {126},
pages = {15-63},
year = {2022},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000838},
author = {Jacques Carette and Roshan P. James and Amr Sabry},
keywords = {Reversible programming, Reversible Boolean circuits, Monoidal categories, Type isomorphisms, Commutative semirings, Homotopy-type theory, Quantum circuits, Permutations},
abstract = {Our main models of computation (the Turing Machine and the RAM) and most modern computer architectures make fundamental assumptions about which primitive operations are realizable on a physical computing device. The consensus is that these primitive operations include logical operations like conjunction, disjunction and negation, as well as reading and writing to a large collection of memory locations. This perspective conforms to a macro-level view of physics and indeed these operations are realizable using macro-level devices involving thousands of electrons. This point of view is however incompatible with computation realized using quantum devices or analyzed using elementary thermodynamics as both these fundamental physical theories imply that information is a conserved quantity of physical processes and hence of primitive computational operations. Our aim is to redevelop foundational computational models in a way that embraces the principle of conservation of information. We first define what information is and what its conservation means in a computational setting. We emphasize the idea that computations must be reversible transformations on data. One can think of data as modeled using topological spaces and programs as modeled by reversible deformations of these spaces. We then illustrate this idea using three notions of data and their associated reversible computational models. The first instance only assumes unstructured finite data, i.e., discrete topological spaces. The corresponding notion of reversible computation is that of permutations. We show how this simple model subsumes conventional computations on finite sets. We then consider a modern structured notion of data based on the Curry–Howard correspondence between logic and type theory. We develop the corresponding notion of reversible deformations using a sound and complete programming language for witnessing type isomorphisms and proof terms for commutative semirings. We then “move up a level” to examine spaces that treat programs as data, which is a crucial notion for any universal model of computation. To derive the corresponding notion of reversible programs between programs, i.e., reversible program equivalences, we look at the “higher dimensional” analog to commutative semirings: symmetric rig groupoids. The coherence laws for these groupoids turn out to be exactly the sound and complete reversible program equivalences we seek. We conclude with some possible generalizations inspired by homotopy type theory and survey several open directions for further research.}
}
@article{LIU20121773,
title = {ACE - A Model Centered REU Program Standing on the Three Legs of CSE: Analysis, Computation and Experiment},
journal = {Procedia Computer Science},
volume = {9},
pages = {1773-1782},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.195},
url = {https://www.sciencedirect.com/science/article/pii/S187705091200316X},
author = {Hong P. Liu and Andrei Ludu},
keywords = {CSE Education, REU, Project-Oriented Pedagogy},
abstract = {Enhancing REU (research experience for undergraduates) has become a popular strategy for many selective universities to enhance quality of undergraduate education and recruit gifted new students. The university that the authors are affiliated has set REU as one of the major outcomes for our QEP (quality enhancement program) for next 5 years. This paper presents a model centered REU program entitled as ACE standing for Analysis, Computation and Experiment. As a work in progress, the program is planned to run for the next 5 years and to serve for 20-30 undergraduate students who are gifted in mathematics and computing annually. ACE is to use interdisciplinary research projects, the guided exploration based on sound pedagogical practice and the top niche analogical and virtual dual lab facility bring measurable impacts to over a hundred of gifted undergraduates.}
}
@incollection{2009339,
title = {Appendix A - Thinking in MATLAB},
editor = {Pascal Wallisch and Michael Lusignan and Marc Benayoun and Tanya I. Baker and Adam S. Dickey and Nicholas G. Hatsopoulos},
booktitle = {Matlab for Neuroscientists},
publisher = {Academic Press},
address = {London},
pages = {339-344},
year = {2009},
isbn = {978-0-12-374551-4},
doi = {https://doi.org/10.1016/B978-0-12-374551-4.00034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123745514000348}
}
@article{KNIGHT20151,
title = {Computational making},
journal = {Design Studies},
volume = {41},
pages = {1-7},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000721},
author = {Terry Knight and Theodora Vardouli}
}
@article{CHI20111937,
title = {Teaching Computing to STEM Students via Visualization Tools},
journal = {Procedia Computer Science},
volume = {4},
pages = {1937-1943},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.211},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911002699},
author = {Hongmei Chi and Harsh Jain},
keywords = {Visualization, ChemSketch, ParaView, Computation ;STEM education},
abstract = {Information technology is evolving fast and steady over the years providing more and more tools for society to use. There is an increasing need and implementation of computation in the conduct of modern scientific research and experimentation. Computational thinking has been scarcely understood by STEM undergraduates if their majors are not computer sciences. We explore computation projects into existing courses via visualization computational tools to increase the number of STEM students who graduate with discipline specific computational skills. The goal of this paper was to report our efforts for increasing the number of students with experience using computation in science. Discipline specific tools were chosen and implemented in the respective courses, for example Chemsketch in chemistry. Hands-on labs were designed to familiarize instructors and students so it can be helpful to smooth the learning curve in STEM undergraduate students}
}
@article{SAID2015396,
title = {Exploiting Computational Intelligence Paradigms in e-Technologies and Activities},
journal = {Procedia Computer Science},
volume = {65},
pages = {396-405},
year = {2015},
note = {International Conference on Communications, management, and Information technology (ICCMIT'2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.09.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915029312},
author = {Hanaa M. Said and Abdel-Badeeh M. Salem},
keywords = {Machine Learning, Intelligent Data Analysis, E- Technologies government, Neural Networks, Fuzzy Logic, Genetic algorithm, Case based reasoning, SVM, Swarm intelligence, computational intelligence;},
abstract = {Computational intelligence (CI) has emerged as a powerful paradigm in e-Science, providing the researchers an immense volume of intelligent computing techniques and algorithms. CI provides knowledge engineers to develop a robust techniques and intelligent tools for e-government applications and tasks. This paper presents a comparative analysis of some techniques used in e-activities and e-government systems. The study includes the following paradigms; artificial neural networks, fuzzy logic, genetic algorithms, case-based reasoning, support vector machines, and swarm intelligence. Additionally, this study found that such paradigms offer many business benefits and advantages; e.g. (a) the ability to acquire, represent, manage and structure the knowledge in the domain under study, (b) the ability to optimize resources, (c) the ability to perform efficient performance, and (d) the ability to conduct planning, budgeting, and forecasting.}
}
@incollection{RAMOS2018720,
title = {8.36 - Bioinformatics and Computational Biology in Toxicology: Gateways for Precision Medicine☆},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {720-728},
year = {2018},
isbn = {978-0-08-100601-6},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99176-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383991761},
author = {K.S. Ramos and M. Martin and I.N. Ramos and G.A. Rempala},
keywords = {Bioinformatics, Computational biology, Precision medicine, Systems biology},
abstract = {The National Center for Biotechnology Information (NCBI) defines bioinformatics as “… the field of science in which biology, computer science, and information technology merge to form a single discipline”. As such, the field of bioinformatics includes computer scientists who develop algorithms for sequence analysis, biostatisticians who develop and implement methods of analyses for large clinical datasets, mathematicians or physical scientists who develop models to describe the interactions of genes, proteins, and small molecules within cells, and all those engaged in the development of software and databases for manipulation, storage, and retrieval of information in support of their research. This chapter focuses on how computational biology has been enabled by molecular informatics to provide the basis for in silico studies that facilitate the collection, organization, and analysis of datasets that explain biological phenomena and that help to drive biological discovery with applications in precision medicine.}
}
@article{ZENDEHROUH2015112,
title = {A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task},
journal = {Neural Networks},
volume = {71},
pages = {112-123},
year = {2015},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608015001604},
author = {Sareh Zendehrouh},
keywords = {Cognitive control, Reinforcement learning, Goal-directed behavior, Dual system theory, Cost function, Probabilistic learning task},
abstract = {Recent work on decision-making field offers an account of dual-system theory for decision-making process. This theory holds that this process is conducted by two main controllers: a goal-directed system and a habitual system. In the reinforcement learning (RL) domain, the habitual behaviors are connected with model-free methods, in which appropriate actions are learned through trial-and-error experiences. However, goal-directed behaviors are associated with model-based methods of RL, in which actions are selected using a model of the environment. Studies on cognitive control also suggest that during processes like decision-making, some cortical and subcortical structures work in concert to monitor the consequences of decisions and to adjust control according to current task demands. Here a computational model is presented based on dual system theory and cognitive control perspective of decision-making. The proposed model is used to simulate human performance on a variant of probabilistic learning task. The basic proposal is that the brain implements a dual controller, while an accompanying monitoring system detects some kinds of conflict including a hypothetical cost-conflict one. The simulation results address existing theories about two event-related potentials, namely error related negativity (ERN) and feedback related negativity (FRN), and explore the best account of them. Based on the results, some testable predictions are also presented.}
}
@article{VARNER2017170,
title = {Computational models of airway branching morphogenesis},
journal = {Seminars in Cell & Developmental Biology},
volume = {67},
pages = {170-176},
year = {2017},
note = {Extracellular Vesicles Cellular Mechanisms of Morphogenesis},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2016.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952116301653},
author = {Victor D. Varner and Celeste M. Nelson},
keywords = {Quantitative models, Morphodynamics, Mechanobiology, Turing patterns},
abstract = {The bronchial network of the mammalian lung consists of millions of dichotomous branches arranged in a highly complex, space-filling tree. Recent computational models of branching morphogenesis in the lung have helped uncover the biological mechanisms that construct this ramified architecture. In this review, we focus on three different theoretical approaches – geometric modeling, reaction-diffusion modeling, and continuum mechanical modeling – and discuss how, taken together, these models have identified the geometric principles necessary to build an efficient bronchial network, as well as the patterning mechanisms that specify airway geometry in the developing embryo. We emphasize models that are integrated with biological experiments and suggest how recent progress in computational modeling has advanced our understanding of airway branching morphogenesis.}
}
@article{LEE2023101274,
title = {Storytelling as a learning tool in creative education: A case study in an architecture design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101274},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101274},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000445},
author = {Keunhye Lee and Eunki Kang and Eun Joo Park},
keywords = {Storytelling, Creative thinking, Architecture design studio, Creative education, Communicative representation},
abstract = {This paper investigates the significant aspects of storytelling, when used as a pedagogical method to enhance students critical and creative thinking and communicative technique, by applying it to first-year students in the architecture design studio. Creativity is a substantial part of architectural education as it improves students’ design processes in innovative ways. This paper considers how the architecture design studio can form a creative design solution that can be learned and developed by learner-centred activity; it concentrates on aspects of storytelling, which many scholars have begun to discuss its significance in creative education. Thus, this paper aims to develop a creative learning strategy for use in the architecture design studio and suggest a new learning method by engaging storytelling in the design process. This paper starts with discussions about storytelling and its usages in the architecture design studio, referring to several theorists and educators, particularly focusing on McDrury and Alterio (2003); it helps to create a framework and develop a curriculum for the architecture design studio. The overall results suggest that using storytelling as a learning method in an architecture design studio is important in contextualising and articulating design work, from ideas to analysis, visualisation and expression, in a coherent context. It helps students gain better design skills and a greater understanding of the design process across the disciplines of the design studio, improving students creative thinking during the unique design process.}
}
@article{WANG2003457,
title = {Thinking as saying: shuo (‘say’) in Taiwan Mandarin conversation and BBS talk},
journal = {Language Sciences},
volume = {25},
number = {5},
pages = {457-488},
year = {2003},
issn = {0388-0001},
doi = {https://doi.org/10.1016/S0388-0001(03)00020-2},
url = {https://www.sciencedirect.com/science/article/pii/S0388000103000202},
author = {Yu-Fang Wang and Aya Katz and Chih-Hua Chen},
keywords = {Grammaticalization, Metaphor, Propositional, Textual, Expressive},
abstract = {The research reported here is an attempt to explore the functions of shuo ‘say’ in informal Chinese speech and writing. We further probe into the grammaticalization of shuo, discussing how the various lexical, grammatical and discourse functions have come into being, with reference to the general tendencies of semantic change proposed by Traugott [(1982). In: Lehmann and Malkiel (Eds.) Perspectives on Historical Linguistics. Benjamins, Amsterdam. pp. 245–272; (1989) Language 65(1), 31–55] and Traugott and König [In: Traugott and Heine (Eds.), Approaches to Grammaticalization, Vol. I. John Benjamins, Philadelphia. pp. 189–218], and the metaphor MIND-AS-BODY proposed by Sweetser [(1990). From Etymology to Pragmatics. Cambridge University Press, Cambridge]. The corpus used in this study contains two sets of data: non-face-to-face talk on BBS (the Electronic Bulletin Board System) and face-to-face daily conversation, mainly produced by young people in Taiwan. Our data indicate that shuo, in addition to acting as a complementizer as discussed by S. Huang [On the (almost perfect) identify of speech and thought: Evidence from Chinese dialects. (1982). Paper presented at Fourteenth International Conference on Sino-Tibetan Languages and Linguistics] and Cheng [(1997). In: Cheng (Ed.), Taiwanese and Mandarin Structures and Their Developmental Trends in Taiwan II: Contacts between Taiwanese and Mandarin and Restructuring of their Synonyms. Yuan-Liou Publishing Co. Taipei. pp. 105–131], can also occur in an utterance-initial position, functioning as a marker of hearsay, and in an utterance-final position, as a marker of counterexpectation or as an intensifier. On the whole, the data suggest that the initial and final shuo's are innovations serving an expressive function. In particular, the lexeme shuo is moving from the propositional level to the expressive level; i.e., it is evolving from a verb meaning ‘say’ that prefaces an utterance conveying information into a discourse marker that encodes the attitude of the speaker toward the proposition.}
}
@article{SU2022100049,
title = {Artificial intelligence in early childhood education: A scoping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100049},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000042},
author = {Jiahong Su and Weipeng Yang},
keywords = {Artificial intelligence, Early childhood education, Teaching and learning, Machine learning, Computer science},
abstract = {Artificial intelligence (AI) tools are increasingly being used in the field of early childhood education (ECE) to enhance learning and development among young children. Previous proof-of-concept studies have demonstrated that AI can effectively improve teaching and learning in ECE; however, there is a scarcity of knowledge about how these studies are conducted and how AI is used across these studies. We conducted this scoping review to evaluate, synthesize and display the latest literature on AI in ECE. This review analyzed 17 eligible studies conducted in different countries from 1995 to 2021. Although few studies on this critical issue have been found, the existing references provide up-to-date insights into different aspects (knowledge, tools, activities, and impacts) of AI for children. Most studies have shown that AI has significantly improved children's concepts regarding AI, machine learning, computer science, and robotics and other skills such as creativity, emotion control, collaborative inquiry, literacy skills, and computational thinking. Future directions are also discussed for researching AI in ECE.}
}
@article{MARSIK2021108,
title = {Introducing ⦇ λ ⦈, a λ-calculus for effectful computation},
journal = {Theoretical Computer Science},
volume = {869},
pages = {108-155},
year = {2021},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2021.02.038},
url = {https://www.sciencedirect.com/science/article/pii/S0304397521001225},
author = {Jirka Maršík and Maxime Amblard and Philippe {de Groote}},
keywords = {Side effects, Monads, -calculus, Handlers, CRS, IDTS},
abstract = {We present ⦇λ⦈, a calculus with special constructions for dealing with effects and handlers. This is an extension of the simply-typed λ-calculus (STLC). We enrich STLC with a type for representing effectful computations alongside with operations to create and process values of this type. The calculus is motivated by natural language modelling, and especially semantic representation. Traditionally, the meaning of a sentence is calculated using λ-terms, but some semantic phenomena need more flexibility. In this article we introduce the calculus and show that the calculus respects the laws of algebraic structures and it enjoys strong normalisation. To do so, confluence is proven using the Combinatory Reduction Systems (CRSs) of Klop and termination using the Inductive Data Type Systems (IDTSs) of Blanqui.}
}
@article{QUINLAN2007413,
title = {Re-thinking stages of cognitive development: An appraisal of connectionist models of the balance scale task},
journal = {Cognition},
volume = {103},
number = {3},
pages = {413-459},
year = {2007},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2006.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010027706000552},
author = {Philip T. Quinlan and Han L.J. {van der Maas} and Brenda R.J. Jansen and Olaf Booij and Mark Rendell},
keywords = {Connectionist models, Balance scale task, Latent class analysis},
abstract = {The present paper re-appraises connectionist attempts to explain how human cognitive development appears to progress through a series of sequential stages. Models of performance on the Piagetian balance scale task are the focus of attention. Limitations of these models are discussed and replications and extensions to the work are provided via the Cascade-Correlation algorithm. An application of multi-group latent class analysis for examining performance of the networks is described and these results reveal fundamental functional characteristics of the networks. Evidence is provided that strongly suggests that the networks are unable to acquire a mastery of torque and, although they do recover certain rules of operation that humans do, they also show a propensity to acquire rules never previously seen.}
}
@article{DIAZ2021247,
title = {Evaluating Aspects of Usability in Video Game-Based Programming Learning Platforms},
journal = {Procedia Computer Science},
volume = {181},
pages = {247-254},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921001812},
author = {Jaime Díaz and Jeferson Arango López and Samuel Sepúlveda and Gabriel Mauricio {Ramírez Villegas} and Danay Ahumada and Fernando Moreira},
keywords = {Human-Computer Interaction, Usability, Video-games, Training, Computer Programming},
abstract = {Teaching computer programming is an important topic. Due to Science and Technology initiatives, these topics are considered in different training cycles. For higher education, students must cultivate fundamental concepts for the development of software applications, which not only contribute to the knowledge of programming languages but also to opening guidelines for computational thinking. However, selecting a proper tool can be complex. Especially for the diversity of alternatives on the web. Further, not all of them meet basic usability requirements. In this study, we present a set of platforms that seek to develop programming skills based on video games. The search consisted of 4 stages: (i) definition of the research questions, (ii) scope review, (iii) execution of search and (iv) platform selection. Finally, we employ a usability heuristic evaluation for a novice programming system to determine best practices.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{DALLACHIARA201669,
title = {A first-order epistemic quantum computational semantics with relativistic-like epistemic effects},
journal = {Fuzzy Sets and Systems},
volume = {298},
pages = {69-90},
year = {2016},
note = {Special Issue on Graded Logical Approaches and Their Applications},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415004145},
author = {Maria Luisa {Dalla Chiara} and Roberto Giuntini and Roberto Leporini and Giuseppe Sergioli},
keywords = {Quantum computation, Quantum computational logics, Epistemic operators},
abstract = {Quantum computation has suggested new forms of quantum logic, called quantum computational logics. In these logics well-formed formulas are supposed to denote pieces of quantum information: possible pure states of quantum systems that can store the information in question. At the same time, the logical connectives are interpreted as quantum logical gates: unitary operators that process quantum information in a reversible way, giving rise to quantum circuits. Quantum computational logics have been mainly studied as sentential logics (whose alphabet consists of atomic sentences and of logical connectives). In this article we propose a semantic characterization for a first-order epistemic quantum computational logic, whose language can express sentences like “Alice knows that everybody knows that she is pretty”. One can prove that (unlike the case of logical connectives) both quantifiers and epistemic operators cannot be generally represented as (reversible) quantum logical gates. The “act of knowing” and the use of universal (or existential) assertions seem to involve some irreversible “theoretic jumps”, which are similar to quantum measurements. Since all epistemic agents are characterized by specific epistemic domains (which contain all pieces of information accessible to them), the unrealistic phenomenon of logical omniscience is here avoided: knowing a given sentence does not imply knowing all its logical consequences.}
}
@article{HEINZLE201621,
title = {Computational models of eye movements and their application to schizophrenia},
journal = {Current Opinion in Behavioral Sciences},
volume = {11},
pages = {21-29},
year = {2016},
note = {Computational modeling},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2016.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154616300754},
author = {Jakob Heinzle and Eduardo A Aponte and Klaas Enno Stephan},
abstract = {Patients with neuropsychiatric disorders, in particular schizophrenia, show a variety of eye movement abnormalities that putatively reflect alterations of perceptual inference, learning and cognitive control. While these abnormalities are consistently found at the group level, a particularly difficult and important challenge is to translate these findings into clinically useful tests for single patients. In this paper, we argue that generative models of eye movement data, which allow for inferring individual computational and physiological mechanisms, could contribute to filling this gap. We present a selective overview of eye movement paradigms with clinical relevance for schizophrenia and review existing computational approaches that rest on (or could be turned into) generative models. We conclude by outlining desirable clinical applications at the individual subject level and discuss the necessary validation studies.}
}
@article{MURANO2020577,
title = {Model-checking graded computation-tree logic with finite path semantics},
journal = {Theoretical Computer Science},
volume = {806},
pages = {577-586},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519305651},
author = {Aniello Murano and Mimmo Parente and Sasha Rubin and Loredana Sorrentino},
keywords = {Computation tree logic, Model checking, Finite paths},
abstract = {This paper introduces Graded Computation Tree Logic with finite path semantics (GCTLf⁎, for short), a variant of Computation Tree Logic CTL⁎, in which path quantifiers are interpreted over finite paths and can count the number of such paths. State formulas of GCTLf⁎ are interpreted over Kripke structures. The syntax of GCTLf⁎ has path quantifiers of the form E≥gψ which express that there are at least g many distinct finite paths that satisfy ψ. After defining and justifying the logic GCTLf⁎, we solve its model checking problem and establish that its computational complexity is PSPACE-complete. Moreover, we investigate GCTLf⁎ under the imperfect information setting. Precisely, we introduce GCTLKf⁎, an epistemic extension of GCTLf⁎ and prove that the model checking problem also in this case is PSPACE-complete.}
}
@article{KOTAGODAHETTI2024118926,
title = {Life cycle-based multi-objective model for optimal gaseous fuel generation and portfolio allocation in gas grids: A strategic decarbonization},
journal = {Energy Conversion and Management},
volume = {319},
pages = {118926},
year = {2024},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2024.118926},
url = {https://www.sciencedirect.com/science/article/pii/S0196890424008677},
author = {Ravihari Kotagodahetti and Kasun Hewage and Ezzeddin Bakhtavar and Rehan Sadiq},
keywords = {Biomethane, Hydrogen, Environmental impacts, Economic impacts, Life cycle thinking, Multi-objective optimization},
abstract = {Biomethane and hydrogen are acknowledged as transformative opportunities for decarbonizing the conventional gas grid. Essential to this transformation is the modeling of the gaseous fuel supply chain, particularly with hydrogen and biomethane, offering crucial insights for decision-makers. This study introduces a life cycle thinking-based multi-objective optimization model for the integrated design of biomethane and hydrogen gaseous fuel supply chain networks. The model determines optimal resource allocation for the production of the two fuels, integrating them into the conventional gas network. Moreover, it allocates conventional natural gas, biomethane, and hydrogen optimally across building, industry, and transport sectors, considering the life cycle environmental and economic performance of fuel integration paths. Objective functions include minimization of life cycle emissions and levelized cost of energy while maximizing revenue from fuel sales. Integrating life cycle assessment and cost analysis tools, the optimization model quantifies emissions and life cycle costs for biomethane and hydrogen paths. Results identify Pareto-optimal fuel production paths and portfolios, revealing that integrating the alternative fuels into the current gas grid can significantly reduce emissions (up to 250 tonCO2eq/year) and generate substantial carbon tax savings (up to $16,250/year). This model is useful for gaseous fuel industry stakeholders, offering a comprehensive view of supply chain costs and detailed insights into emission benefits when integrating alternative fuels into existing gas networks.}
}
@article{BOTANA2016115,
title = {Some issues on the automatic computation of plane envelopes in interactive environments},
journal = {Mathematics and Computers in Simulation},
volume = {125},
pages = {115-125},
year = {2016},
note = {8th Workshop STRUCTURAL DYNAMICAL SYSTEMS: Computational Aspects; Edited by Nicoletta Del Buono, Roberto Garrappa and Giulia Spaletta and Nonstandard Applications of Computer Algebra (ACA’2013); Edited by Francisco Botana, Antonio Hernando, Eugenio Roanes-Lozano and Michael J. Wester},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414001529},
author = {Francisco Botana and Tomas Recio},
keywords = {Envelope, Dynamic Geometry, Automatic computation, GröbnerCover algorithm},
abstract = {This paper addresses some concerns, and describes some proposals, on the ellusive concept of envelope of an algebraic family of varieties, and on its automatic computation. We describe how to use the recently developed Gröbner Cover algorithm to study envelopes of families of algebraic curves, and we give a protocol towards its implementation in dynamic geometry environments. The proposal is illustrated through some examples. A beta version of GeoGebra is used to highlight new envelope abilities in interactive environments, and limitations of our approach are discussed, since the computations are performed in an algebraically closed field.}
}
@article{SLOOT2010131,
title = {The cross-disciplinary road to true computational science},
journal = {Journal of Computational Science},
volume = {1},
number = {3},
pages = {131},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000451},
author = {Peter M.A. Sloot}
}
@article{IGNATOWSKI2014264,
title = {Wishful thinking or effective threat? Tightening bank resolution regimes and bank risk-taking},
journal = {Journal of Financial Stability},
volume = {15},
pages = {264-281},
year = {2014},
issn = {1572-3089},
doi = {https://doi.org/10.1016/j.jfs.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1572308914000485},
author = {Magdalena Ignatowski and Josef Korte},
keywords = {Bank resolution, Orderly Liquidation Authority, FDIC, Bank behavior, Risk-taking},
abstract = {We propose a framework for testing the effects of changes in bank resolution regimes on bank behavior. By exploiting the differential relevance of recent changes in U.S. bank resolution (i.e., the introduction of the Orderly Liquidation Authority, OLA) for different types of banks, we are able to simulate a quasi-natural experiment using a difference-in-difference framework. We find that banks that are more affected by the introduction of the OLA (1) significantly decrease their overall risk-taking and (2) shift their loan origination toward lower risk, indicating the general effectiveness of the regime change. This effect, however, does (3) not hold for the largest and most systemically important banks. Hence, the introduction of the OLA in the U.S. alone does not appear to have solved the too-big-to-fail problem and might need to be complemented with other measures to limit financial institutions’ risk-taking.}
}
@article{LONG201960,
title = {The mammalian kinetochore–microtubule interface: robust mechanics and computation with many microtubules},
journal = {Current Opinion in Cell Biology},
volume = {60},
pages = {60-67},
year = {2019},
note = {Cell Dynamics},
issn = {0955-0674},
doi = {https://doi.org/10.1016/j.ceb.2019.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0955067419300250},
author = {Alexandra F Long and Jonathan Kuhn and Sophie Dumont},
abstract = {The kinetochore drives chromosome segregation at cell division. It acts as a physical link between chromosomes and dynamic microtubules, and as a signaling hub detecting and processing microtubule attachments to control anaphase onset. The mammalian kinetochore is a large macromolecular machine that forms a dynamic interface with the many microtubules that it binds. While we know most of the kinetochore’s component parts, how they work together to give rise to its robust functions remains poorly understood. Here we highlight recent findings that shed light on this question, driven by an expanding physical and molecular toolkit. We present emerging principles that underlie the kinetochore’s robust microtubule grip, such as redundancy, specialization, and dynamicity, and present signal processing principles that connect this microtubule grip to robust computation. Throughout, we identify open questions, and define simple engineering concepts that provide insight into kinetochore function.}
}
@article{COX2005104,
title = {Metacognition in computation: A selected research review},
journal = {Artificial Intelligence},
volume = {169},
number = {2},
pages = {104-141},
year = {2005},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2005.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370205001530},
author = {Michael T. Cox},
keywords = {Cognitive monitoring, Computational introspection, Limited rationality, Metacognition, Meta-explanation, Metaknowledge, Meta-level architecture, Metareasoning, Self-reference, Reflection},
abstract = {Various disciplines have examined the many phenomena of metacognition and have produced numerous results, both positive and negative. I discuss some of these aspects of cognition about cognition and the results concerning them from the point of view of the psychologist and the computer scientist, and I attempt to place them in the context of computational theories. I examine metacognition with respect to both problem solving (e.g., planning) and to comprehension (e.g., story understanding) processes of cognition.}
}
@incollection{JIAO202081,
title = {Chapter 3 - Theoretical basis of natural computation},
editor = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
booktitle = {Brain and Nature-Inspired Learning Computation and Recognition},
publisher = {Elsevier},
pages = {81-95},
year = {2020},
isbn = {978-0-12-819795-0},
doi = {https://doi.org/10.1016/B978-0-12-819795-0.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128197950000037},
author = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
keywords = {Artificial immune system, Evolutionary algorithms, Multiobjective optimization, Theoretical basis},
abstract = {Enlightened by nature, the natural computing method has the ability of self-adaptation, self-organization, and self-learning, and can solve complex problems which are difficult to be solved by traditional computing methods. Natural computing is not only a new hotspot in artificial intelligence research, but also a new thinking in the development of artificial intelligence. It is also a new achievement in the transformation of methodology. Its research results include evolutionary algorithms, artificial immune system, multiobjective optimization, and so on. Natural computing can solve many complex problems which are difficult to be solved by traditional computing methods. It has good application prospects in solving large-scale complex optimization problems, intelligent control, computer network security, and other fields.}
}
@article{WHITE1985287,
title = {Thinking about learning about thinking: An interview with Seymour Papert},
journal = {New Ideas in Psychology},
volume = {3},
number = {3},
pages = {287-292},
year = {1985},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(85)90025-X},
url = {https://www.sciencedirect.com/science/article/pii/0732118X8590025X},
author = {Barbara Y. White}
}
@incollection{SEJNOWSKI200919,
title = {Computational Methods},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {19-22},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.01396-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469013966},
author = {T.J. Sejnowski},
keywords = {Brain theory, Computational models, Mathematical analysis},
abstract = {Computational neuroscience is a relatively recent approach to understanding how nervous systems develop and interact with a changing and uncertain world. Computational models can be used to interpret experimental data in new ways, to confirm and extend existing hypotheses, and to generate new hypotheses for the function of neural systems. These hypotheses provide links between levels of description, from the molecular level to the systems level. Hypotheses that are tested and validated provide a conceptual framework that can lead to more abstract theories. The ultimate aim of theoretical and computational neuroscience is to provide linking principles from neural mechanisms to behavior.}
}
@article{YANG20111230,
title = {Computational optimization, modelling and simulation: Recent advances and overview},
journal = {Procedia Computer Science},
volume = {4},
pages = {1230-1233},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911001906},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming increasingly important in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. This second workshop on Computational Optimization, Modelling and Simulation (COMS 2011) at ICCS 2011 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{RUSCH2020107488,
title = {Theory of mind and decision science: Towards a typology of tasks and computational models},
journal = {Neuropsychologia},
volume = {146},
pages = {107488},
year = {2020},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2020.107488},
url = {https://www.sciencedirect.com/science/article/pii/S0028393220301597},
author = {Tessa Rusch and Saurabh Steixner-Kumar and Prashant Doshi and Michael Spezio and Jan Gläscher},
keywords = {Theory of mind, Computational modeling, Decision making, Interactivity, Uncertainty},
abstract = {The ability to form a Theory of Mind (ToM), i.e., to theorize about others’ mental states to explain and predict behavior in relation to attributed intentional states, constitutes a hallmark of human cognition. These abilities are multi-faceted and include a variety of different cognitive sub-functions. Here, we focus on decision processes in social contexts and review a number of experimental and computational modeling approaches in this field. We provide an overview of experimental accounts and formal computational models with respect to two dimensions: interactivity and uncertainty. Thereby, we aim at capturing the nuances of ToM functions in the context of social decision processes. We suggest there to be an increase in ToM engagement and multiplexing as social cognitive decision-making tasks become more interactive and uncertain. We propose that representing others as intentional and goal directed agents who perform consequential actions is elicited only at the edges of these two dimensions. Further, we argue that computational models of valuation and beliefs follow these dimensions to best allow researchers to effectively model sophisticated ToM-processes. Finally, we relate this typology to neuroimaging findings in neurotypical (NT) humans, studies of persons with autism spectrum (AS), and studies of nonhuman primates.}
}
@article{GARCIANUNES2020102607,
title = {A computational tool for weak signals classification – Detecting threats and opportunities on politics in the cases of the United States and Brazilian presidential elections},
journal = {Futures},
volume = {123},
pages = {102607},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102607},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300999},
author = {Pedro Ivo Garcia-Nunes and Pedro Artico Rodrigues and Kaulitz Guimarães Oliveira and Ana Estela Antunes {da Silva}},
keywords = {Conceptual systems, Opportunities, Threats, Weak signals},
abstract = {The literature on weak signals (WS) has been fruitful in recent years and this specific type of information has attracted the attention of several disciplines, notably the futures studies. However, most of these studies still focus on conceptual discussions, terminology, or the proposal for frameworks that do not take advantage of the evolution of information and communication technologies. In this paper, authors discussed the lack of tools to computationally support WS handling. In response to this lack, a computational tool was developed considering a previously published method for WS classification based on conceptual systems. This tool was applied and evaluated in experimental cases about surprising events that occurred in politics in recent years, considering traditional metrics of information retrieval. Experiments illustrate that organizations can create several conceptual systems to represent different scenarios and types of knowledge; after all, results showed that the tool can operate according to different artifacts of knowledge representation. This capacity is useful to mitigate the effects of the surveillance filter though the evidence does not directly confirm its usefulness for the monitoring activities. Furthermore, the tool provides a list of threats, opportunities and unlabeled WS that can trigger other steps of sensemaking about these signals.}
}
@article{FILOMENA201914,
title = {A computational approach to ‘The Image of the City’},
journal = {Cities},
volume = {89},
pages = {14-25},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118309776},
author = {Gabriele Filomena and Judith A. Verstegen and Ed Manley},
keywords = {Image of the City, Cognitive maps, Kevin Lynch, Street network, GIScience},
abstract = {In The Image of the City Lynch describes how individuals perceive and recall features in urban spaces. The most distinctive elements in the urban landscape - categorised in paths, nodes, edges, districts and landmarks - give shape to individuals' mental representation of the city. Lynch’s approach has stimulated research into spatial cognition, urban design and artificial intelligence, and it still represents an essential pillar in the analysis of urban dynamics. Nevertheless, an explicit link between The Image of the City and GIScience has not been completely explored yet. In this paper, a computational approach to The Image of the City is proposed. Different perspectives in spatial cognition and GIS research are integrated to obtain a complete Image of the City, in which the most salient elements are shared by a large part of citizens. Nodes, paths and districts were identified through network science techniques. Methods drawn from the information approach to The Image of the City are used to detect landmarks, integrating the complexity of points of reference in their visual, structural and semantic components, as conceptualised by Lynch and successive research. The methods were applied to the central area of Boston and built using freely available spatial datasets. Results were compared to Lynch’s maps to evaluate the methodology: besides a considerable discrepancy with regard to landmarks, a good correspondence for paths, nodes, edges and districts was found.}
}
@article{RAZ2024101598,
title = {Open and closed-ended problem solving in humans and AI: The influence of question asking complexity},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101598},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101598},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001366},
author = {Tuval Raz and Roni Reiter-Palmon and Yoed N. Kenett},
keywords = {Question asking, Problem-solving, AI, Creativity},
abstract = {Question-asking, an underexplored aspect of creativity, is integral to creative problem-solving and information-seeking. Previous research reveals that lower creativity correlates with asking simpler, closed questions, while higher creativity correlates with complex, open-ended inquiries. The present study explores the relation between question asking complexity and problem-solving tasks involving open- and close-ended thinking and how these abilities generalize and compare to AI. In Study 1, participants (N = 89) completed the alternative questions task (AQT), a close-ended riddles task (Stumpers), and the alternate uses task (AUT), a creativity measure. Our results show AQT question complexity wasn't correlated with stumpers performance, although it correlated with AUT originality (r = .3). In Study 2, participants (N = 100) completed the AQT, AUT, and open-ended creative problem-solving (CPS) task. CPS responses were evaluated for originality and quality. A positive correlation was observed between CPS quality and AQT complexity (r = .29) and originality (r = .34). In study 3, AI agents (N = 100) completed the AQT, AUT, stumpers, and CPS tasks. Like humans, AI's AQT originality and complexity were related with open, but not closed problem-solving. AI questions were also significantly more creative and complex, it solved more stumpers and gave higher quality CPS solutions. Surprisingly, human and AI CPS originality didn't differ. We find significant links between question complexity and open—but not closed-ended—problem-solving in humans, which generalize to AI. Our results highlight the significance of complex and creative question-asking in everyday life and as an integral part of our problem-solving toolkit.}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{BUKOWSKI202116,
title = {Computational medicine, present and the future: obstetrics and gynecology perspective},
journal = {American Journal of Obstetrics and Gynecology},
volume = {224},
number = {1},
pages = {16-34},
year = {2021},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2020.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0002937820308851},
author = {Radek Bukowski and Karl Schulz and Kelly Gaither and Keri K. Stephens and Dave Semeraro and Justin Drake and Gordon Smith and Craig Cordola and Thaleia Zariphopoulou and Thomas J.R. Hughes and Christopher Zarins and Dimitri Kusnezov and Donna Howard and Tinsley Oden},
keywords = {computation, data, data-driven models, machine learning, modeling, physics-based models, theory-based models, uncertainty},
abstract = {Medicine is, in its essence, decision making under uncertainty; the decisions are made about tests to be performed and treatments to be administered. Traditionally, the uncertainty in decision making was handled using expertise collected by individual providers and, more recently, systematic appraisal of research in the form of evidence-based medicine. The traditional approach has been used successfully in medicine for a very long time. However, it has substantial limitations because of the complexity of the system of the human body and healthcare. The complex systems are a network of highly coupled components intensely interacting with each other. These interactions give those systems redundancy and thus robustness to failure and, at the same time, equifinality, that is, many different causative pathways leading to the same outcome. The equifinality of the complex systems of the human body and healthcare system demand the individualization of medical care, medicine, and medical decision making. Computational models excel in modeling complex systems and, consequently, enabling individualization of medical decision making and medicine. Computational models are theory- or knowledge-based models, data-driven models, or models that combine both approaches. Data are essential, although to a different degree, for computational models to successfully represent complex systems. The individualized decision making, made possible by the computational modeling of complex systems, has the potential to revolutionize the entire spectrum of medicine from individual patient care to policymaking. This approach allows applying tests and treatments to individuals who receive a net benefit from them, for whom benefits outweigh the risk, rather than treating all individuals in a population because, on average, the population benefits. Thus, the computational modeling–enabled individualization of medical decision making has the potential to both improve health outcomes and decrease the costs of healthcare.}
}
@article{KARA2015526,
title = {A Critical Look at the Digital Technologies in Architectural Education: When, where, and how?},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {526-530},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.506},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815005431},
author = {Levent Kara},
keywords = {architectural pedagogy, architectural design, digital architecture, CAD, CAM, computational design, architectural design studio, architectural drawing, architectural modeling, architectural thinking, architectural geometry},
abstract = {In the past decade, architectural education has seen an increasing amount of digital technologies being involved in the design studio curricula. Following the trends in the profession, these various technologies of computer aided drafting, enumerating, modeling, and analysis became not only key pedagogical nodes in the design studio, but also started to shape the overall curricular structure of architectural education as they also needed to be implemented as support courses in order to compensate the learning curves and the number of software available to architects. These digital technologies range from one end of simple drafting, conventional three dimensional modeling, and more sophisticated animation of buildings with a computer, to the other end of inventing new tectonic and spatial geometries using parametric computations. In this context, it will be unrealistic to argue against teaching and using digital technologies in architectural education. When one thinks how the profession has evolved in the past decade, it is necessary to embrace these tools in the architectural curriculum. However, a discussion that has not been clearly resolved is when, where, and how these digital tools are thought and used in the architectural education. My paper argues that the conventional tools of hand drawing, physical modeling, and hand making should be embraced in the foundational levels, and the digital tools should be introduced after developing a certain set of skills of one-to-one physical making where a sense of tectonic resolution, scale, and spatial experience is cultivated as a basis of architectural thinking with digital tools. In what follows, I will discuss this viewpoint through examples from architectural design studio education in the United States and in Turkey.}
}
@article{PRADO2019727,
title = {Towards an Extensible Architecture for Ideation},
journal = {Procedia Computer Science},
volume = {159},
pages = {727-735},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.228},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919314140},
author = {Hércules A. do Prado and Elaine Coutinho Marcial and Aluizio Haendchen Filho and Edilson Ferneda and Roseane Salvio},
keywords = {design thinking, ideation, debates, sentiment analysis, foresight, Studies of Future},
abstract = {Ideation is an important activity of Design Thinking, a process that may benefit from different levels of automation in its activities. Preceded by Immersion and Analysis activities, Ideation can be enhanced by computational approaches like debate synthesis and mediation, sentiment analysis, and so on. In this paper an architecture for an extensible platform for ideation is addressed. Initially, it comprises a set of components to cope with those functionalities. The extensibility of this platform is in the sense that it shall allow the inclusion of new components like creation of domain ontologies for integration of different studies in the same domain. The general purpose of this platform is to support the creation of ideas by (i) constructing consensus among specialists and (ii) managing dissents in order to keep in track of marginal ideas that can become dominant ones as the discussion advances. It can be applied to many fields, like innovation, Studies of Future, definition of complex diagnoses, etc. Actually, this proposal came up from an experience with a study of future in which some experts had tried to envision trends for some years ahead in order to propose strategic actions for reaching a desired status for Brazil as a successful, fair, and inclusive country. The proposal includes an open and interactive computational environment to enable (i) structuring debates in threads of discussion; (ii) the gathering of ideas about topics of interest; (iii) the debate on the ideas put forward in order to identify the most relevant ones; (iv) synthesis of a debate (anytime summarization); (v) identification of the prevailing sentiments in a debate; and (vi) identification of variables relevant for the sake of the debate target.}
}
@article{CADDY1996219,
title = {Regime shifts and paradigm changes: is there still a place for equilibrium thinking?},
journal = {Fisheries Research},
volume = {25},
number = {3},
pages = {219-230},
year = {1996},
issn = {0165-7836},
doi = {https://doi.org/10.1016/0165-7836(95)00443-2},
url = {https://www.sciencedirect.com/science/article/pii/0165783695004432},
author = {J.F. Caddy}
}
@article{TRYK2023101372,
title = {The electrochemistry of platinum-group and noble metals as it relates to fuel cells and water electrolysis: Vibrational spectroscopic and computational insights},
journal = {Current Opinion in Electrochemistry},
volume = {41},
pages = {101372},
year = {2023},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2023.101372},
url = {https://www.sciencedirect.com/science/article/pii/S2451910323001655},
author = {Donald A. Tryk and Akiyoshi Kuzume},
abstract = {The intrinsic electrochemistry of platinum and other platinum-group metals and noble metals has been under intense investigation for over forty years but is still not fully understood. Various in situ spectroscopic techniques, particularly vibrational spectroscopies, have provided and continue to provide many insights, but challenges remain. The intrinsic electrochemistry is capable of being elucidated through the combination of electrochemistry, vibrational spectroscopy and theory and is then further able to clarify the catalytic reactions involved in H2–O2 fuel cells and water electrolysis.}
}
@article{JARMAN2022225,
title = {Critical measurement issues in the assessment of social media influence on body image},
journal = {Body Image},
volume = {40},
pages = {225-236},
year = {2022},
issn = {1740-1445},
doi = {https://doi.org/10.1016/j.bodyim.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1740144521001583},
author = {Hannah K. Jarman and Siân A. McLean and Scott Griffiths and Samantha J. Teague and Rachel F. Rodgers and Susan J. Paxton and Emma Austen and Emily Harris and Trevor Steward and Adrian Shatte and Long {Khanh-Dao Le} and Tarique Anwar and Cathrine Mihalopoulos and Alexandra G. Parker and Zali Yager and Matthew Fuller-Tyszkiewicz},
keywords = {Social media, Body image, Qualitative, Survey, Experimental, Momentary assessment, Web scraping, Computational modelling, Measurement, Assessment},
abstract = {Progress towards understanding how social media impacts body image hinges on the use of appropriate measurement tools and methodologies. This review provides an overview of common (qualitative, self-report survey, lab-based experiments) and emerging (momentary assessment, computational) methodological approaches to the exploration of the impact of social media on body image. The potential of these methodologies is detailed, with examples illustrating current use as well as opportunities for expansion. A key theme from our review is that each methodology has provided insights for the body image research field, yet is insufficient in isolation to fully capture the nuance and complexity of social media experiences. Thus, in consideration of gaps in methodology, we emphasise the need for big picture thinking that leverages and combines the strengths of each of these methodologies to yield a more comprehensive, nuanced, and robust picture of the positive and negative impacts of social media.}
}
@article{DEICHMANN2024105260,
title = {Contrasting philosophical and scientific views in the long history of studying the generation of form in development},
journal = {BioSystems},
volume = {242},
pages = {105260},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105260},
url = {https://www.sciencedirect.com/science/article/pii/S030326472400145X},
author = {Ute Deichmann},
keywords = {Genomic causality, Developmental gene regulatory networks, Physical-chemical selforganization in form generation, Preformation versus epigenesis, Morphogenesis, Stochastic fluctuations, Eric Davidson, Aristotle},
abstract = {Focusing on the opposing ways of thinking of philosophers and scientists to explain the generation of form in biological development, I show that today's controversies over explanations of early development bear fundamental similarities to the dichotomy of preformation theory versus epigenesis in Greek antiquity. They are related to the acceptance or rejection of the idea of a physical form of what today would be called information for the generating of the embryo as a necessary pre-requisite for specific development and heredity. As a recent example, I scrutinize the dichotomy of genomic causality versus self-organization in 20th and 21st century theories of the generation of form. On the one hand, the generation of patterns and form, as well as the constant outcome in development, are proposed to be causally related to something that is "preformed" in the germ cells, the nucleus of germ cells, or the genome. On the other hand, it is proposed that there is no pre-existing form or information, and development is seen as a process where genuinely new characters emerge from formless matter, either by immaterial "forces of life," or by physical-chemical processes of self-organization. I also argue that these different ways of thinking and the research practices associated with them are not equivalent, and maintain that it is impossible to explain the generation of form and constant outcome of development without the assumption of the transmission of pre-existing information in the form of DNA sequences in the genome. Only in this framework of "preformed" information can "epigenesis" in the form of physical and chemical processes of self-organization play an important role.}
}
@article{DENHAAN2011175,
title = {Computational suite of models with heterogeneous agents II: Multi-country real business cycle models},
journal = {Journal of Economic Dynamics and Control},
volume = {35},
number = {2},
pages = {175-177},
year = {2011},
note = {Computational Suite of Models with Heterogeneous Agents II: Multi-Country Real Business Cycle Models},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165188910002149},
author = {Wouter J. {Den Haan} and Kenneth L. Judd and Michel Juillard},
keywords = {Numerical solutions, Simulations, Approximations},
abstract = {This paper describes the second model considered in the computational suite project that compares the performance of different numerical algorithms. It is a multi-country model in which countries face different productivity shocks. Solving such models is a challenging numerical problem unless the number of countries is small. The solutions are functions of a large set of arguments and the functional forms are unknown. Moreover, the solution procedures have to deal with high-dimensional integration problems.}
}
@article{ALI20201425,
title = {Re-thinking adaptive immunity in the beetles: Evolutionary and functional trajectories of lncRNAs},
journal = {Genomics},
volume = {112},
number = {2},
pages = {1425-1436},
year = {2020},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2019.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0888754319302034},
author = {Ali Ali and Hesham M. {Abd El Halim}},
keywords = {Immune memory, Priming, , Macrophage},
abstract = {Unlike vertebrate animals, invertebrates lack lymphocytes and therefore have historically been believed not to develop immune memory. A few studies have reported evidence of immune priming in insects; however, these studies lack the molecular mechanism and proposed it might be different among taxa. Since lncRNAs are known to regulate the immune response, we identified 10,120 lncRNAs in Tribolium castaneum genome-wide followed by transcriptome analysis of primed and unprimed larvae of different infectious status. A shift in lncRNA expression between Btt primed larvae and other treatment groups provides evidence of immune memory response. A few “priming” lncRNAs (n = 9) were uniquely regulated in Btt primed larvae. Evidence suggests these lncRNAs are likely controlling immune priming in Tribolium by regulating expression of genes involved in proteasomal machinery, Notch system, zinc metabolism, and methyltransferase activity, which are necessary to modulate phagocytosis. Our results support a conserved immune priming mechanism in a macrophage-dependent manner.}
}
@article{TRAYLOR2024110895,
title = {Model-based experiments as epistemic evidence in paleoecology},
journal = {Ecological Modelling},
volume = {498},
pages = {110895},
year = {2024},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2024.110895},
url = {https://www.sciencedirect.com/science/article/pii/S0304380024002837},
author = {Wolfgang Traylor},
keywords = {Epistemology, Bayesian, Preregistration, Blinding, Uncertainty analysis},
abstract = {Where ordinary experiments are impossible and observational data scarce and indirect—particularly in paleoecosystems—computational experiments are often our only means to learn about reality. There are good arguments to count such model-based predictions as evidence, testing hypotheses and updating our beliefs about the world. However, the epistemic weight of computational experiments depends on an adequate model representation of the target system, transparency about predictive uncertainty, and the avoidance of confirmation bias. I argue that mechanistic models are particularly suited for paleoecological predictions but that iterative uncertainty analyses should guide their development. Using a Bayesian framework I propose preregistration and blinded analysis as tools to strengthen the epistemic value of computational experiments. Here, a preregistration marks the boundary between exploratory model development, which establishes credence in the model, and predictive model application, which tests hypotheses. As good modeling practice I suggest clarifying epistemic goals at the outset of a project and accordingly choose methods to maximize the epistemic weight of the computational experiment.}
}
@article{YANG20101297,
title = {Computational optimization, modelling and simulation–a paradigm shift},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {1297-1300},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001456},
author = {Xin-She Yang and Slawomir Koziel},
keywords = {Algorithm, Black-box modelling, Computational optimization, Derivative-free method, Optimization algorithm, Modelling, Nonlinear optimization, Surragate-based optimization, Simulation},
abstract = {Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry}
}
@article{TRASMUNDI2024101615,
title = {Dialogical cognition},
journal = {Language Sciences},
volume = {103},
pages = {101615},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101615},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000044},
author = {Sarah Bro Trasmundi and Sune Vork Steffensen},
keywords = {Per Linell, Dialogical cognition, Distributed cognition, Cognitive ethnography, Distributed language},
abstract = {In this article we review Per Linell's work within the last five decades that led to his dialogism framework, which he defines as a general epistemology of language, cognition and communication. We critically discuss how his contribution on the one hand, altered and qualified existent models within language, communication and cognitive science, because dialogism removed language and cognition from their abstract and mental seat in the brain, and embedded them instead in situational contexts and embodied interaction. In that sense, his dialogism successfully replaced monological assumptions about the mind, action and thinking with more contextual and temporally distributed ones. On the other hand, we also question why Linell has not pursued a more rigorous empirical program for studying human cognition, when he did establish a theoretical apparatus for approaching cognition from a dialogical starting point. In going through Linell's arguments over the past five decades we suggest that this absence of an empirical program is due to his humanistic roots which both have sensitised him to appreciating the contingencies and dynamics of human sense making and cognition, and have impeded him from buying into a necessary condition for pursuing a cognitive analysis, even if he conceptually and methodologically accepts a distributed view on cognition. The outcome of this discussion leads to an empirical-based cognitive analysis of a medical interaction. Altogether, the purpose of this article is to show how Linell's conceptual framework can be put to use in ways that make a dialogical cognitive science achievable.}
}
@article{COTTAM2024105343,
title = {Intelligence: Natural, artificial, or what?},
journal = {BioSystems},
volume = {246},
pages = {105343},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002284},
author = {Ron Cottam and Roger Vounckx},
abstract = {We consider the competing attributes of natural intelligence (NI) and artificial intelligence (AI). Attention is paid to conceptual, theoretical, stylistic and structural aspects of both, and non-human intelligence. Intelligence is related to information processing and current views of physical structuring. Means of distinguishing between NI and AI are noted, and neural and digital structures are described. Pribram's bi-computational neural networks are introduced, and high-level Pribram computation is discussed. We describe the hierarchical Aquarium scheme, along with an AI implementation, and conclude with a proposition for future quantum-based artificial intelligence.}
}
@article{GONDOCS2024102769,
title = {AI in medical diagnosis: AI prediction & human judgment},
journal = {Artificial Intelligence in Medicine},
volume = {149},
pages = {102769},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000113},
author = {Dóra Göndöcs and Viktor Dörfler},
keywords = {Medical diagnosis, Melanoma, Human-computer interaction, Augmented intelligence, Explainability, Responsible AI},
abstract = {AI has long been regarded as a panacea for decision-making and many other aspects of knowledge work; as something that will help humans get rid of their shortcomings. We believe that AI can be a useful asset to support decision-makers, but not that it should replace decision-makers. Decision-making uses algorithmic analysis, but it is not solely algorithmic analysis; it also involves other factors, many of which are very human, such as creativity, intuition, emotions, feelings, and value judgments. We have conducted semi-structured open-ended research interviews with 17 dermatologists to understand what they expect from an AI application to deliver to medical diagnosis. We have found four aggregate dimensions along which the thinking of dermatologists can be described: the ways in which our participants chose to interact with AI, responsibility, ‘explainability’, and the new way of thinking (mindset) needed for working with AI. We believe that our findings will help physicians who might consider using AI in their diagnosis to understand how to use AI beneficially. It will also be useful for AI vendors in improving their understanding of how medics want to use AI in diagnosis. Further research will be needed to examine if our findings have relevance in the wider medical field and beyond.}
}
@article{LEE2023121253,
title = {Artificial intelligence enabled energy-efficient heating, ventilation and air conditioning system: Design, analysis and necessary hardware upgrades},
journal = {Applied Thermal Engineering},
volume = {235},
pages = {121253},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2023.121253},
url = {https://www.sciencedirect.com/science/article/pii/S1359431123012826},
author = {Dasheng Lee and Shang-Tse Lee},
keywords = {Artificial intelligence (AI), Heating, ventilation and air conditioning (HVAC), Energy saving, Design thinking, Hardware upgrade},
abstract = {Literature search across different databases showed that the application of artificial intelligence (AI) in heating, ventilation and air conditioning (HVAC) equipment has been extensively studied. On the commercial front, Internet search suggested that numerous AI-equipped HVAC products have been launched. These products apply AI in very different ways, and their energy-saving effects are also different. Such divergence and uncertain energy-saving effects may hinder AI application. To overcome this difference and accelerate the development of AI applications, the present study proposed a double diamond preferred reporting items for systematic reviews and meta-analysis (PRISMA) method—an analysis method that combined literature review with design thinking. Through a process of divergence-convergence-re-divergence, this study described how to design AI functions for energy-efficient HVAC systems, taking into account more than 1,700 research papers it had reviewed. However, there was a limitation on the part re-divergence. Because the vast majority of research papers only published results of successful AI applications, no cases of failed applications were available for review, making it impossible to re-think profoundly. Instead, this study collected raw data from 88 research papers and used these data to analyze the effectiveness and ineffectiveness of AI in depth. It was concluded that AI application must be accompanied by necessary hardware improvements to achieve effective energy savings. AI-enabled energy-saving effects for chillers, air-handing units, heating systems, and air conditioners, as well as corresponding hardware upgrades, were discussed.}
}
@article{AILON2020234,
title = {Paraunitary matrices, entropy, algebraic condition number and Fourier computation},
journal = {Theoretical Computer Science},
volume = {814},
pages = {234-248},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520300797},
author = {Nir Ailon},
keywords = {Fourier transform, Lower bounds, Complexity, Linear algebraic computation},
abstract = {The Fourier Transform is one of the most important linear transformations used in science and engineering. Cooley and Tukey's Fast Fourier Transform (FFT) from 1964 is a method for computing this transformation in time O(nlog⁡n). From a lower bound perspective, relatively little is known. Ailon shows in 2013 an Ω(nlog⁡n) bound for computing the normalized Fourier Transform assuming only unitary operations on two coordinates are allowed at each step, and no extra memory is allowed. In 2014, Ailon then improved the result to show that, in a κ-well conditioned computation, Fourier computation can be sped up by no more than O(κ). The main conjecture is that Ailon's result can be exponentially improved, in the sense that κ-well condition cannot admit ω(log⁡κ) speedup. The main result here is that ‘algebraic’ κ-well condition cannot admit ω(κ) speedup. One equivalent definition of algebraic condition number is related to the degree of polynomials naturally arising as the computation evolves. Using the maximum modulus theorem from complex analysis, we show that algebraic condition number upper bounds standard condition number, and equals it in certain cases. Algebraic condition number is an interesting measure of numerical computation stability in its own right, and provides a novel computational lens. Moreover, based on evidence from other recent related work, we believe that the approach of algebraic condition number has a good chance of establishing an algebraic version of the main conjecture.}
}
@article{TOIVONEN202052,
title = {Computational creativity beyond machine learning},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {52-53},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300373},
author = {Hannu Toivonen}
}
@incollection{WARD2018,
title = {Analogy☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21889-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245218890},
author = {Thomas B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling, Laboratory study, In vivo study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo, neuroscience and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{FRISTON2014148,
title = {Computational psychiatry: the brain as a phantastic organ},
journal = {The Lancet Psychiatry},
volume = {1},
number = {2},
pages = {148-158},
year = {2014},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(14)70275-5},
url = {https://www.sciencedirect.com/science/article/pii/S2215036614702755},
author = {Karl J Friston and Klaas Enno Stephan and Read Montague and Raymond J Dolan},
abstract = {Summary
In this Review, we discuss advances in computational neuroscience that relate to psychiatry. We review computational psychiatry in terms of the ambitions of investigators, emerging domains of application, and future work. Our focus is on theoretical formulations of brain function that put subjective beliefs and behaviour within formal (computational) frameworks—frameworks that can be grounded in neurophysiology down to the level of synaptic mechanisms. Understanding the principles that underlie the brain's functional architecture might be essential for an informed phenotyping of psychopathology in terms of its pathophysiological underpinnings. We focus on active (Bayesian) inference and predictive coding. Specifically, we show how basic principles of neuronal computation can be used to explain psychopathology, ranging from impoverished theory of mind in autism to abnormalities of smooth pursuit eye movements in schizophrenia.}
}
@article{CUI2022104203,
title = {Pore-network modeling of flow in shale nanopores: Network structure, flow principles, and computational algorithms},
journal = {Earth-Science Reviews},
volume = {234},
pages = {104203},
year = {2022},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0012825222002872},
author = {Ronghao Cui and S. Majid Hassanizadeh and Shuyu Sun},
keywords = {Pore-network modeling, Shale rock, Nanoporous media, Flow theory, Thermodynamics},
abstract = {Hydrocarbons in subsurface nanoporous media, such as shale, are promising energy resources to compensate for the shortage of conventional reservoirs. Pore-network modeling serves as a valuable tool for simulating microscale fluid transport and elucidating flow physics in porous media. However, traditional pore-network models have failed to capture features of spatial structure and fluid flow in unconventional shale rock. This work presents a critical review of pore-network modeling of single-phase and two-phase flow in shale rock. Pore-network modeling advances of shale are reviewed based on three major parts: network morphology and geometries, flow principles in nanocapillaries, and pore-network computational algorithms. First, based on key geological features of shale rock, we analyze network topology, multiscale network, pore geometries, and network representativeness of shale pore-network models. Then, we discuss four important aspects that may influence flow principles of fluids in nanocapillaries: gas and liquid slippage, sorption and diffusion behavior, hydrocarbon thermodynamics, and the presence of water. Finally, we present pore-network modeling methods used for flow simulations in shale rock, including quasi-static and dynamic algorithms. We hope that this review could shed light on fundamentals of pore-network modeling of shale rock.}
}
@incollection{HUDLICKA2017383,
title = {Chapter 16 - Computational Modeling of Cognition–Emotion Interactions: Theoretical and Practical Relevance for Behavioral Healthcare},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {383-436},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00016-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000161},
author = {Eva Hudlicka},
keywords = {emotion–cognition modeling, modeling mechanism of therapeutic action, computational models of affective disorders and psychopathology, therapeutic games, behavioral healthcare technology, transdiagnostic model},
abstract = {Recent years have witnessed an increasing interest in developing computational models of emotion and emotion–cognition interaction, within the emerging area of computational affective science. At the same time, emotion theorists and clinical psychologists have begun to recognize the importance of moving beyond descriptive characterizations of psychopathology, and identifying the underlying mechanisms that mediate both the etiology of affective disorders, and their treatment: the transdiagnostic approach to psychopathology. Computational models of cognition–emotion interactions have the potential to facilitate more accurate assessment and diagnosis of affective disorders, and to provide a basis for more efficient and targeted approaches to their treatment, through an improved understanding of the underlying mechanisms. This chapter discusses the state-of-the-art in modeling emotion–cognition interaction and the relevance of these models for understanding the mechanisms mediating psychopathology and therapeutic action. The discussion is limited to symbolic models and theories defined at the psychological, versus neural, level. The chapter also outlines how these models can support the development of serious therapeutic games, to enhance assessment and treatment methods in behavioral healthcare.}
}
@article{ROSSITER202473,
title = {A MATLAB virtual laboratory to support learning of auto-tuning PID approaches},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {7},
pages = {73-78},
year = {2024},
note = {4th IFAC Conference on Advances in Proportional-Integral-Derivate Control PID 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324007250},
author = {J.A. Rossiter and A. Visioli and S. Dormido and R. Bars},
keywords = {Control101 toolbox, PID compensation, virtual laboratories, independent learning},
abstract = {This paper presents a small number of MATLAB APPs and livescript files designed to help students both understand and implement PID tuning. The paper presents the thinking behind the use of MATLAB and the topic itself before then describing the proposed resources in detail. The resources split into files with detailed mathematical and coding background students can use for self-study and assignments, and a virtual laboratory which is more intuitive and interactive and useful for familiarisation with core concepts. The files were recently added to the control101 toolbox (Rossiter, 2023).}
}
@article{MITTAL1994253,
title = {Massively parallel finite element computation of incompressible flows involving fluid-body interactions},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {112},
number = {1},
pages = {253-282},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)90029-9},
url = {https://www.sciencedirect.com/science/article/pii/0045782594900299},
author = {S. Mittal and T.E. Tezduyar},
abstract = {We describe our massively parallel finite element computations of unsteady incompressible flows involving fluid-body interactions. These computations are based on the Deforming-Spatial-Domain/Stabilized-Space-Time (DSD/SST) finite element formulation. Unsteady flows past a stationary NACA 0012 airfoil are computed for Reynolds numbers 1000, 5000 and 100 000. Significantly different flow patterns are observed for these three cases. The method is then applied to computation of the dynamics of an airfoil falling in a viscous fluid under the influence of gravity. It is observed that the location of the center of gravity of the airfoil plays an important role in determining its pitch stability. Computations are reported also for simulation of the dynamics of a two-dimensional ‘projectile’ that has a certain initial velocity. Specially designed mesh moving schemes are employed to eliminate the need for remeshing. All these computations were carried out on the Thinking Machines CM-200 and CM-5 supercomputers, with major speed-ups compared to traditional supercomputers. The implicit equation systems arising from the finite element discretizations of these large-scale problems are solved iteratively by using the GMRES update technique with diagonal preconditioners. The finite element formulations and their parallel implementations assume unstructured meshes.}
}
@article{DELGADO2019133,
title = {Computational methods for Gene Regulatory Networks reconstruction and analysis: A review},
journal = {Artificial Intelligence in Medicine},
volume = {95},
pages = {133-145},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0933365718303865},
author = {Fernando M. Delgado and Francisco Gómez-Vela},
keywords = {Gene Network, Systems biology, Networks validation, Gene Regulatory Network, Gene Network inference},
abstract = {In the recent years, the vast amount of genetic information generated by new-generation approaches, have led to the need of new data handling methods. The integrative analysis of diverse-nature gene information could provide a much-sought overview to study complex biological systems and processes. In this sense, Gene Regulatory Networks (GRN) arise as an increasingly-promising tool for the modelling and analysis of biological processes. This review is an attempt to summarize the state of the art in the field of GRNs. Essential points in the field are addressed, thereof: (a) the type of data used for network generation, (b) machine learning methods and tools used for network generation, (c) model optimization and (d) computational approaches used for network validation. This survey is intended to provide an overview of the subject for readers to improve their knowledge in the field of GRN for future research.}
}
@article{COHEN1981285,
title = {The power of parallel thinking},
journal = {Journal of Economic Behavior & Organization},
volume = {2},
number = {4},
pages = {285-306},
year = {1981},
issn = {0167-2681},
doi = {https://doi.org/10.1016/0167-2681(81)90011-1},
url = {https://www.sciencedirect.com/science/article/pii/0167268181900111},
author = {Michael D. Cohen},
abstract = {A small computer model demonstrates that an appropriate organization of boundedly rational individuals can find optimal policies in an environment that is overwhelmingly complex for unorganized decision makers. The model is also used to identify conditions under which optimal — or even good — policies are not found. The demonstrated adaptive power of the model is interpreted in light of recent developments in the theory of computational complexity that place new stress on powerful methods of search, and of new models from computer science which markedly advance search effectiveness by harnessing parallel structures of information processing.}
}
@article{DUGGAN2024101426,
title = {ChatGPT performance on radiation technologist and therapist entry to practice exams},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {55},
number = {4},
pages = {101426},
year = {2024},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S193986542400122X},
author = {Ryan Duggan and Kaitlyn M. Tsuruda},
keywords = {Radiography, Radiotherapy, Nuclear Medicine, Magnetic Resonance Imaging, AI (Artificial Intelligence), Natural Language Processing, Teaching, Educational Measurement},
abstract = {Background
The aim of this study was to describe the proficiency of ChatGPT (GPT-4) on certification style exams from the Canadian Association of Medical Radiation Technologists (CAMRT), and describe its performance across multiple exam attempts.
Methods
ChatGPT was prompted with questions from CAMRT practice exams in the disciplines of radiological technology, magnetic resonance (MRI), nuclear medicine and radiation therapy (87-98 questions each). ChatGPT attempted each exam five times. Exam performance was evaluated using descriptive statistics, stratified by discipline and question type (knowledge, application, critical thinking). Light's Kappa was used to assess agreement in answers across attempts.
Results
Using a passing grade of 65 %, ChatGPT passed the radiological technology exam only once (20 %), MRI all five times (100 %), nuclear medicine three times (60 %), and radiation therapy all five times (100 %). ChatGPT's performance was best on knowledge questions across all disciplines except radiation therapy. It performed worst on critical thinking questions. Agreement in ChatGPT's responses across attempts was substantial within the disciplines of radiological technology, MRI, and nuclear medicine, and almost perfect for radiation therapy.
Conclusion
ChatGPT (GPT-4) was able to pass certification style exams for radiation technologists and therapists, but its performance varied between disciplines. The algorithm demonstrated substantial to almost perfect agreement in the responses it provided across multiple exam attempts. Future research evaluating ChatGPT's performance on standardized tests should consider using repeated measures.
Résumé
Contexte
L'objectif de cette étude était de décrire la compétence du ChatGPT (GPT-4) dans les examens d'agrément de l'Association canadienne des technologues en radiation médicale (ACTRM), et de décrire sa performance à travers plusieurs tentatives d'examen.
Méthodes
ChatGPT a été invité à répondre à des questions provenant des examens pratiques de l'ACTRM dans les disciplines de la technologie de radiologie, de la résonance magnétique (IRM), de la médecine nucléaire et de la radiothérapie (87-98 questions pour chaque discipline). ChatGPT a tenté chaque examen cinq fois. La performance à l'examen a été évaluée à l'aide de statistiques descriptives, stratifiées par discipline et par type de question (connaissances, application, réflexion critique). Le Kappa de Light a été utilisé pour évaluer la concordance des réponses entre les tentatives.
Résultats
En utilisant une note de passage de 65 %, ChatGPT a réussi l'examen de technologie de radiologie une seule fois (20 %), l'IRM les cinq fois (100 %), la médecine nucléaire trois fois (60 %), et la radiothérapie les cinq fois (100 %). Les performances de ChatGPT ont été les meilleures pour les questions de connaissances dans toutes les disciplines, à l'exception de la radiothérapie. Il a été le moins performant pour les questions de réflexion critique. La concordance des réponses du ChatGPT entre les tentatives était substantielle dans les disciplines de la technologie de radiologie, de l'IRM et de la médecine nucléaire, et presque parfaite pour la radiothérapie.
Conclusion
ChatGPT (GPT-4) a été capable de réussir les examens d'agrément pour les technologues en radiation médicale et les radiothérapeutes, mais ses performances ont varié selon les disciplines. L'algorithme a démontré une concordance substantielle à presque parfaite dans les réponses qu'il a fournies à travers de multiples tentatives d'examen. Les futures recherches évaluant les performances de ChatGPT sur des tests standardisés devraient envisager l'utilisation de mesures répétées.}
}
@article{COWARD2014164,
title = {Brain Computational Primitives},
journal = {Procedia Computer Science},
volume = {41},
pages = {164-175},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015452},
author = {L. Andrew Coward},
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.}
}
@article{SUN2009124,
title = {Theoretical status of computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {10},
number = {2},
pages = {124-140},
year = {2009},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000429},
author = {Ron Sun},
keywords = {Cognitive modeling, Cognitive architecture, Theory, Simulation, Validation},
abstract = {This article explores the view that computational models of cognition may constitute valid theories of cognition, often in the full sense of the term “theory”. In this discussion, this article examines various (existent or possible) positions on this issue and argues in favor of the view above. It also connects this issue with a number of other relevant issues, such as the general relationship between theory and data, the validation of models, and the practical benefits of computational modeling. All the discussions point to the position that computational cognitive models can be true theories of cognition.}
}
@article{BAKER2023238,
title = {13Ccarbene nuclear magnetic resonance chemical shift analysis confirms CeIVC double bonding in cerium(iv)–diphosphonioalkylidene complexes††Electronic supplementary information (ESI) available: Computational details. See DOI: https://doi.org/10.1039/d3sc04449a},
journal = {Chemical Science},
volume = {15},
number = {1},
pages = {238-249},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc04449a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023058364},
author = {Cameron F. Baker and John A. Seed and Ralph W. Adams and Daniel Lee and Stephen T. Liddle},
abstract = {Diphosphonioalkylidene dianions have emerged as highly effective ligands for lanthanide and actinide ions, and the resulting formal metal–carbon double bonds have challenged and developed conventional thinking about f-element bond multiplicity and covalency. However, f-element–diphosphonioalkylidene complexes can be represented by several resonance forms that render their metal–carbon double bond status unclear. Here, we report an experimentally-validated 13C Nuclear Magnetic Resonance computational assessment of two cerium(iv)–diphosphonioalkylidene complexes, [Ce(BIPMTMS)(ODipp)2] (, BIPMTMS = {C(PPh2NSiMe3)2}2−; Dipp = 2,6-diisopropylphenyl) and [Ce(BIPMTMS)2] (). Decomposing the experimental alkylidene chemical shifts into their corresponding calculated shielding (σ) tensor components verifies that these complexes exhibit CeC double bonds. Strong magnetic coupling of CeC σ/π* and π/σ* orbitals produces strongly deshielded σ11 values, a characteristic hallmark of alkylidenes, and the largest 13C chemical shift tensor spans of any alkylidene complex to date (, 801 ppm; , 810 ppm). In contrast, the phosphonium-substituent shielding contributions are much smaller than the CeC σ- and π-bond components. This study confirms significant Ce 4f-orbital contributions to the CeC bonding, provides further support for a previously proposed inverse-trans-influence in , and reveals variance in the 4f spin–orbit contributions that relate to the alkylidene hybridisation. This work thus confirms the metal–carbon double bond credentials of f-element–diphosphonioalkylidenes, providing quantified benchmarks for understanding diphosphonioalkylidene bonding generally.}
}
@article{BEYTIA2022101732,
title = {Towards a Digital Reflexive Sociology: Using Wikipedia's Biographical Repository as a Reflexive Tool},
journal = {Poetics},
volume = {95},
pages = {101732},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101732},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001140},
author = {Pablo Beytía and Hans-Peter Müller},
keywords = {Reflexive sociology, digital sociology, sociology of knowledge, computational social science, digital methods},
abstract = {We propose the development of 'digital reflexive sociology', understood as the use of digital methods and Big Data to reflect on the social and historical circumstances of sociologists and sociological thinking. To show this approach's potential, we employ Wikipedia as a ‘reflexive tool’, i.e., an external artefact of self-observation that can help sociologists to notice conventions, biases, and blind spots within their discipline. We analyse the collective patterns of the 500 most notable sociologists on Wikipedia, performing structural, network, and text analyses of their biographies. Our exploration reveals patterns in their historical frequency, gender composition, geographical concentration, birth-death mobility, centrality degree, biographical clustering, and proximity between countries, also stressing institutions, events, places, and relevant dates from a biographical point of view. Linking these patterns in a diachronic way, we distinguish five generations of sociologists recorded on Wikipedia and emphasise the high historical concentration of the discipline in geographical areas, gender, and schools of thought. Drawing on these results, we discuss the potential of using digital repositories and methods to enhance reflexivity within sociology.}
}
@article{MURRAY2018777,
title = {Biophysical Modeling of Large-Scale Brain Dynamics and Applications for Computational Psychiatry},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {3},
number = {9},
pages = {777-787},
year = {2018},
note = {Computational Methods and Modeling in Psychiatry},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902218301782},
author = {John D. Murray and Murat Demirtaş and Alan Anticevic},
keywords = {Computational model, Functional connectivity, Neuroimaging, Resting-state, Schizophrenia, Transcriptomics},
abstract = {Noninvasive neuroimaging has revolutionized the study of the organization of the human brain and how its structure and function are altered in psychiatric disorders. A critical explanatory gap lies in our mechanistic understanding of how systems-level neuroimaging biomarkers emerge from underlying synaptic-level perturbations associated with a disease state. We describe an emerging computational psychiatry approach leveraging biophysically based computational models of large-scale brain dynamics and their potential integration with clinical and pharmacological neuroimaging. In particular, we focus on neural circuit models, which describe how patterns of functional connectivity observed in resting-state functional magnetic resonance imaging emerge from neural dynamics shaped by inter-areal interactions through underlying structural connectivity defining long-range projections. We highlight the importance of local circuit physiological dynamics, in combination with structural connectivity, in shaping the emergent functional connectivity. Furthermore, heterogeneity of local circuit properties across brain areas, which impacts large-scale dynamics, may be critical for modeling whole-brain phenomena and alterations in psychiatric disorders and pharmacological manipulation. Finally, we discuss important directions for future model development and biophysical extensions, which will expand their utility to link clinical neuroimaging to neurobiological mechanisms.}
}
@article{LIU2017168,
title = {A landmark-based data-driven approach on 2.5D facial attractiveness computation},
journal = {Neurocomputing},
volume = {238},
pages = {168-178},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217301248},
author = {Shu Liu and Yang-Yu Fan and Zhe Guo and Ashok Samal and Afan Ali},
keywords = {Facial attractiveness computation, 2.5 D, Geometric features, Data-driven, BJUT-3D},
abstract = {Investigating the nature and components of face attractiveness from a computational view has become an emerging topic in facial analysis research. In this paper, a multi-view (frontal and profile view, 2.5D) facial attractiveness computational model is developed to explore how face geometry affects its attractiveness. A landmark-based, data-driven method is introduced to construct a huge dimension of three kinds of geometric facial measurements, including ratios, angles, and inclinations. An incremental feature selection algorithm is proposed to systematically select the most discriminative subset of geometric features, which are finally mapped to an attractiveness score through the application of support vector regression (SVR). On a dataset of 360 facial images pre-processed from BJUT-3D Face Database and an attractiveness score dataset collected from human raters, we show that the computational model performs well with low statistic error (MSE=0.4969) and good predictability (R2=0.5756).}
}
@incollection{GOMEZPEROSANZ2019906,
title = {Computational Immunogenetics},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {906-930},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20452-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338204524},
author = {Marta {Gómez Perosanz} and Giulia Russo and Jose Luis {Sanchez-Trincado Lopez} and Marzio Pennisi and Pedro A. Reche and Adrian Shepherd and Francesco Pappalardo},
keywords = {Agent based modelling, Antibody modelling, Bioinformatics for immune system modelling, Crystallography, Epitopes prediction, Immune system modelling, Immune system pathways, Immunotherapies, In silico trials, Molecular and cellular modelling, Multi-scale modelling, ODE modelling, Petri nets, T and B cells, Vaccines},
abstract = {Computational immunogenetics encompasses the use and application of bioinformatics methods, mathematical models and statistical techniques for the study of immune system function. The considerable heterogeneity of the immune system requires systems approaches to be used to model such a complexity and to respond to questions posed by biomedical audience to help them solve biomedical questions. Computational approaches are increasingly vital to understand the implications of the wealth of gene expression and epigenomics data being gathered from immune cells, and dozens of immune databases play a vital role in organizing the vast quantities of experimental data generated by modern high-throughput technologies. Multi-scale methodologies are increasingly being used to characterise the interplay between the molecular, cellular and organism levels of the immune system. Finally, computational immunology is making an important contribution to an emerging field of computational biomedicine: in silico clinical trials.}
}
@article{FARAZI2024103661,
title = {Planning electric vertical takeoff and landing aircraft (eVTOL)-based package delivery with community noise impact considerations},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103661},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103661},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002527},
author = {Nahid Parvez Farazi and Bo Zou},
keywords = {Advanced air mobility (AAM), eVTOL, Package delivery, Community noise impact, Bi-objective integer programming model, Tailored solution algorithm},
abstract = {The rapid development of Advanced Air Mobility (AAM) in recent years suggests a promise to use electric vertical takeoff and landing aircraft (eVTOLs) for package delivery in metro areas. While eVTOL manufacturers and logistics service providers are actively developing prototype eVTOLs and exploring their potentials for moving freight, a system thinking about the suitability and ways to operate an eVTOL-based package delivery system remains scarce. A key aspect of the system thinking is the noise impact of eVTOL operations on surrounding communities. In this study, we provide an operation planning framework that aims to prepare AAM to be both economically efficient and community friendly for package delivery. We first develop a method to quantify the community noise impact of an eVTOL operation, using a “population exposure” measure which is based on the level of sound generated and accounts for both the number of people impacted and duration of the impact. Then, a bi-objective integer programming model is formulated which simultaneously optimizes total shipping cost and community noise impact of eVTOL operations. The optimization takes into consideration operational constraints including maximum distance for local delivery, latest package departure time from the warehouse, and eVTOL fleet size and carrying capacity. A tailored solution algorithm which augments non-dominated sorting genetic algorithm 2 (NSGA2) with compact solution representation, guided generation of initial population of solutions, and customized local search heuristics is devised. The model and the algorithm are implemented in a case study in the Chicago metro area. Numerical results reveal the trade-off between the minimization of shipping cost and community noise impact. Several operational insights about eVTOL-based package delivery are obtained. The computational efficiency and effectiveness of the proposed solution algorithm are also demonstrated in comparison with alternative solution methods.}
}
@incollection{ERICSSON199437,
title = {CHAPTER 2 - Contemporary Approaches to the Study of Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {37-79},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50008-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500086},
author = {K. Anders Ericsson and Reid Hastie},
abstract = {Publisher Summary
This chapter discusses the contemporary approaches to the study of thinking and problem solving. The modal approach to create a comprehensive theory of thinking strives to identify simple conditions under which a given type of thinking can be reliably reproduced. Following the successful example of experimenters in many of the natural sciences, the goal of this approach is to discover general laws and invariant constraints in well-defined tasks that do not require access to complex knowledge and experience. The most popular alternative approach to the study of thinking starts by examining performance in everyday life and identifying stable and reproducible phenomena. Of particular interest is expert performance, because it offers the highest levels of performance and also the largest stable individual differences in performance when compared with that of beginners. An understanding of thinking is incomplete unless it provides an account of how the elements of adult thought—such as concepts, representations, and skills—are acquired. Research on learning and skill acquisition on the whole range of activities ranging from performance on simple laboratory tasks to complex life-long efforts to attain expert performance shows that effective learning is not an automatic consequence of extended experience.}
}
@article{MASELLI20235395,
title = {Computational analysis of five neurodegenerative diseases reveals shared and specific genetic loci},
journal = {Computational and Structural Biotechnology Journal},
volume = {21},
pages = {5395-5407},
year = {2023},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023003835},
author = {Francesca Maselli and Salvatore D’Antona and Mattia Utichi and Matteo Arnaudi and Isabella Castiglioni and Danilo Porro and Elena Papaleo and Paolo Gandellini and Claudia Cava},
keywords = {Neurodegenerative diseases, Bioinformatics, GWAS, SNPs},
abstract = {Neurodegenerative diseases (ND) are heterogeneous disorders of the central nervous system that share a chronic and selective process of neuronal cell death. A computational approach to investigate shared genetic and specific loci was applied to 5 different ND: Amyotrophic lateral sclerosis (ALS), Alzheimer's disease (AD), Parkinson's disease (PD), Multiple sclerosis (MS), and Lewy body dementia (LBD). The datasets were analyzed separately, and then we compared the obtained results. For this purpose, we applied a genetic correlation analysis to genome-wide association datasets and revealed different genetic correlations with several human traits and diseases. In addition, a clumping analysis was carried out to identify SNPs genetically associated with each disease. We found 27 SNPs in AD, 6 SNPs in ALS, 10 SNPs in PD, 17 SNPs in MS, and 3 SNPs in LBD. Most of them are located in non-coding regions, with the exception of 5 SNPs on which a protein structure and stability prediction was performed to verify their impact on disease. Furthermore, an analysis of the differentially expressed miRNAs of the 5 examined pathologies was performed to reveal regulatory mechanisms that could involve genes associated with selected SNPs. In conclusion, the results obtained constitute an important step toward the discovery of diagnostic biomarkers and a better understanding of the diseases.}
}
@article{MANCHES2020105859,
title = {Identifying embodied metaphors for computing education},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105859},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S074756321830623X},
author = {Andrew Manches and Peter E. McKenna and Gnanathusharan Rajendran and Judy Robertson},
keywords = {Embodied cognition, Gesture, Metaphor, Computing education, Computational thinking, Representation},
abstract = {Computing education is increasing in global importance, with calls for greater understanding of conceptual development that can inform pedagogy. Here, we report a study investigating elementary computing concepts through the lens of Embodied Cognition. Sixteen students (9 female) studying university-level computing were asked to explain their understanding of computing concepts (without materials) in individually video-recorded sessions. We analysed the gestures generated for three elementary concepts: algorithms, loops, and conditional statements. In total, 368 representational gestures were identified across 48 (16 × 3) explanations, thereby providing evidence that offline thinking in this domain is embodied. Our analysis of representational gestures showed that participants drew upon two overarching embodied metaphors in their explanations: 1) Computing Constructs as Physical Objects, in which participants simulated manipulating physical objects (e.g., pinching) when referring to range of computing constructs, and 2) Computing Processes as Motion along a Path, whereby participants moved their hands along one of three body-based axes when referring to temporal sequences. We contrast our findings to similar research in mathematics and discuss implications for computing pedagogy – namely the role of gesture in the classroom and technologies that can exploit embodied metaphors.}
}
@article{LEVIN2019125,
title = {Planarian regeneration as a model of anatomical homeostasis: Recent progress in biophysical and computational approaches},
journal = {Seminars in Cell & Developmental Biology},
volume = {87},
pages = {125-144},
year = {2019},
note = {Planarian regeneration},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952117301970},
author = {Michael Levin and Alexis M. Pietak and Johanna Bischof},
keywords = {Planaria, Dugesia japonica, Regeneration, Patterning, Morphostasis},
abstract = {Planarian behavior, physiology, and pattern control offer profound lessons for regenerative medicine, evolutionary biology, morphogenetic engineering, robotics, and unconventional computation. Despite recent advances in the molecular genetics of stem cell differentiation, this model organism’s remarkable anatomical homeostasis provokes us with truly fundamental puzzles about the origin of large-scale shape and its relationship to the genome. In this review article, we first highlight several deep mysteries about planarian regeneration in the context of the current paradigm in this field. We then review recent progress in understanding of the physiological control of an endogenous, bioelectric pattern memory that guides regeneration, and how modulating this memory can permanently alter the flatworm’s target morphology. Finally, we focus on computational approaches that complement reductive pathway analysis with synthetic, systems-level understanding of morphological decision-making. We analyze existing models of planarian pattern control and highlight recent successes and remaining knowledge gaps in this interdisciplinary frontier field.}
}
@article{VANDENBOS201842,
title = {Computational neuroscience across the lifespan: Promises and pitfalls},
journal = {Developmental Cognitive Neuroscience},
volume = {33},
pages = {42-53},
year = {2018},
note = {Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1878929317301068},
author = {Wouter {van den Bos} and Rasmus Bruckner and Matthew R. Nassar and Rui Mata and Ben Eppinger},
keywords = {Computational neuroscience, Reinforcement learning, Risk-taking, Decision-making, Brain development, Identification, Strategies},
abstract = {In recent years, the application of computational modeling in studies on age-related changes in decision making and learning has gained in popularity. One advantage of computational models is that they provide access to latent variables that cannot be directly observed from behavior. In combination with experimental manipulations, these latent variables can help to test hypotheses about age-related changes in behavioral and neurobiological measures at a level of specificity that is not achievable with descriptive analysis approaches alone. This level of specificity can in turn be beneficial to establish the identity of the corresponding behavioral and neurobiological mechanisms. In this paper, we will illustrate applications of computational methods using examples of lifespan research on risk taking, strategy selection and reinforcement learning. We will elaborate on problems that can occur when computational neuroscience methods are applied to data of different age groups. Finally, we will discuss potential targets for future applications and outline general shortcomings of computational neuroscience methods for research on human lifespan development.}
}
@article{DROSATOS2014170,
title = {Privacy-preserving computation of participatory noise maps in the cloud},
journal = {Journal of Systems and Software},
volume = {92},
pages = {170-183},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000430},
author = {George Drosatos and Pavlos S. Efraimidis and Ioannis N. Athanasiadis and Matthias Stevens and Ellie D’Hondt},
keywords = {Privacy-preserving computation, Cloud computing, Participatory sensing},
abstract = {This paper presents a privacy-preserving system for participatory sensing, which relies on cryptographic techniques and distributed computations in the cloud. Each individual user is represented by a personal software agent, deployed in the cloud, where it collaborates on distributed computations without loss of privacy, including with respect to the cloud service providers. We present a generic system architecture involving a cryptographic protocol based on a homomorphic encryption scheme for aggregating sensing data into maps, and demonstrate security in the Honest-But-Curious model both for the users and the cloud service providers. We validate our system in the context of NoiseTube, a participatory sensing framework for noise pollution, presenting experiments with real and artificially generated data sets, and a demo on a heterogeneous set of commercial cloud providers. To the best of our knowledge our system is the first operational privacy-preserving system for participatory sensing. While our validation pertains to the noise domain, the approach used is applicable in any crowd-sourcing application relying on location-based contributions of citizens where maps are produced by aggregating data – also beyond the domain of environmental monitoring.}
}
@article{SLOOT2012439,
title = {Young Russian researchers take up challenges in the computational sciences},
journal = {Journal of Computational Science},
volume = {3},
number = {6},
pages = {439-440},
year = {2012},
note = {Next Generation Computational Scientists: Russian Federation},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2012.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877750312000981},
author = {Peter M.A. Sloot and Alexander V. Boukhanovsky}
}
@article{CAMACHOLIE202435,
title = {Development of basic thermodynamics workshops integrating a cubic equations of state simulator and MATLAB Grader courses},
journal = {Education for Chemical Engineers},
volume = {49},
pages = {35-54},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000228},
author = {Mariola Camacho-Lie and Rodrigo Alberto Hernández-Ochoa and Adriana Palacios},
keywords = {Teaching of thermodynamics, Digital tools in education, Deep learning, Constructive Alignment, Preparation for Future Learning, Productive Failure},
abstract = {This paper describes the development of EoS Simulator, a cubic equations of state simulator created in the MATLAB R2022b App Designer platform, which aims to be a practical digital tool for chemical engineering students that facilitates the solution, analysis, and critical thinking about thermodynamic problems. In the simulator, numerical algorithms were implemented based on a theoretical framework, such as fugacity test, bracketing methods, and the calculation of residual properties. EoS Simulator can estimate two-phase envelopes, isobars, isotherms, and surfaces related to PTVHS properties. MATLAB Grader courses were proposed to test student learning using the software in two different workshops. The evaluation was based on the achievement of tasks related to intended learning outcomes. Survey responses about the simulator and learning environment were collected, concluding that most students improved their skills in understanding thermodynamics phenomena, but some improvements are necessary for future versions of the software and online courses.}
}
@incollection{OREILLY2019317,
title = {Chapter 17 - Computational models of motivated frontal function},
editor = {Mark D'Esposito and Jordan H. Grafman},
series = {Handbook of Clinical Neurology},
publisher = {Elsevier},
volume = {163},
pages = {317-332},
year = {2019},
booktitle = {The Frontal Lobes},
issn = {0072-9752},
doi = {https://doi.org/10.1016/B978-0-12-804281-6.00017-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042816000173},
author = {Randall C. O’Reilly and Jacob Russin and Seth A. Herd},
keywords = {Computational models, Frontal cortex, Basal ganglia, Goal-directed, Motivation, Working memory, Reinforcement learning},
abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex). Computational models of goal-directed action selection at multiple different levels of analysis provide insight into the nature of learning and processing in these areas and the relative contributions of the frontal cortex versus the BG. The most common neurologic disorders implicate these areas, and understanding their precise function and modes of dysfunction can contribute to the new field of computational psychiatry, within the broader field of computational neuroscience.}
}
@article{ALEXANDROV20151685,
title = {Computational Science Research Methods for Science Education at PG Level},
journal = {Procedia Computer Science},
volume = {51},
pages = {1685-1693},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.305},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915011138},
author = {Nia Alexandrov and Vassil Alexandrov},
keywords = {Computational Science Research Methods, Postgraduate Education, Science Subjects},
abstract = {The role of Computational Science research methods teaching to science students at PG level is to enhance their research profile developing their abilities to investigate complex problems, analyze the resulting data and use adequately HPC environments and tools for computation and visualization. The paper analyses the current state and proposes a program that encompasses mathematical modelling, data science, advanced algorithms development, parallel programming and visualization tools. It also gives examples of specific scientific domains with explicitly taught and embedded Computational Science subjects.}
}
@article{GARDNER201582,
title = {A new Canadian interdisciplinary Ph.D. in computational sciences},
journal = {Journal of Computational Science},
volume = {9},
pages = {82-87},
year = {2015},
note = {Computational Science at the Gates of Nature},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000666},
author = {William B. Gardner and Gary Grewal and Deborah Stacey and David A. Calvert and Stefan C. Kremer and Fangju Wang},
keywords = {Interdisciplinary, Computational science, Computer science, Postgraduate studies},
abstract = {In response to growing demands of society for experts trained in computational skills applied to various domains, the School of Computer Science at the University of Guelph is creating a new approach to doctoral studies called an interdisciplinary Ph.D. in computational sciences. The program is designed to appeal to candidates with strong backgrounds in either computer science or an application discipline who are not necessarily seeking a traditional academic career. Thesis based, it features minimal course requirements and short duration, with the student’s research directed by co-advisors from computer science and the application discipline. The degree program’s rationale and special characteristics are described. Related programs in Ontario and reception of this innovative proposal at the institutional level are discussed.}
}
@article{JOLLY20171,
title = {Computational systems biology of epithelial-hybrid-mesenchymal transitions},
journal = {Current Opinion in Systems Biology},
volume = {3},
pages = {1-6},
year = {2017},
note = {• Mathematical modelling • Mathematical modelling, Dynamics of brain activity at the systems level • Clinical and translational systems biology},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2017.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2452310016300191},
author = {Mohit Kumar Jolly and Herbert Levine},
keywords = {Metastasis, Epithelial–mesenchymal plasticity, Hybrid epithelial/mesenchymal, Cancer stem cells, Computational modeling},
abstract = {Metastasis accounts for more than 90% of cancer-related deaths, and is fueled by fine-tuned transitions among many cellular phenotypes. Transitions among epithelial (strong cell–cell adhesion, no or little migration), mesenchymal (no cell–cell adhesion, high migration), and hybrid epithelial/mesenchymal (both cell–cell adhesion and cell migration) phenotypes are considered to be a hallmark of metastasis. Recent years have witnessed rapid progress in mapping the regulatory networks underlying these transitions. This progress has enabled the capability to develop computational systems biology models to characterize how various intracellular and extracellular signals can drive these transitions. Here, we discuss how different mathematical models have contributed to elucidating the underlying principles of these transitions and guided further experiments to address key unanswered questions concerning metastasis.}
}
@article{WANG20152603,
title = {Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring},
journal = {Procedia Computer Science},
volume = {51},
pages = {2603-2612},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.368},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501176X},
author = {Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson},
keywords = {Bayesian Computational Sensor Networks, Uncertainty, Structural Health Monitoring, Cloud Computing},
abstract = {The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments.}
}
@incollection{WEIKUM200220,
title = {Chapter 4 - Self-tuning Database Technology and Information Services: From Wishful Thinking to Viable Engineering},
editor = {Philip A. Bernstein and Yannis E. Ioannidis and Raghu Ramakrishnan and Dimitris Papadias},
booktitle = {VLDB '02: Proceedings of the 28th International Conference on Very Large Databases},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {20-31},
year = {2002},
isbn = {978-1-55860-869-6},
doi = {https://doi.org/10.1016/B978-155860869-6/50011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608696500111},
author = {Gerhard Weikum and Axel Moenkeberg and Christof Hasse and Peter Zabback},
abstract = {Publisher Summary
The COMFORT project was started in 1990, and it was then expected that automatic tuning could be achieved with a few simple principles. While the feedback control loop framework provides useful guidance, the difficult problems are in the details of the various tuning issues. For robust solutions, workload statistics and mathematical models are key assets, and for viable engineering, these must be carefully designed to ensure acceptable overhead. The field, in general, has made significant progress towards self-tuning database technology, but there is no breakthrough. The biggest challenges that the research community should address as high-priority problems are the interactions of different system components and their tuning knobs, and the interference between different workload classes. For tackling this complexity, it is believed that a drastic simplification of today's overly complex system architectures is overdue. If one is able to build individually self-tuning components, the composition of these building blocks into higher-level e-services with service-quality guarantees seems feasible only with sufficiently simple component interfaces and radical minimization of cross talk.}
}