@article{SANKARANARAYANAN20151,
title = {Genome-based, mechanism-driven computational modeling of risks of ionizing radiation: The next frontier in genetic risk estimation?},
journal = {Mutation Research/Reviews in Mutation Research},
volume = {764},
pages = {1-15},
year = {2015},
issn = {1383-5742},
doi = {https://doi.org/10.1016/j.mrrev.2014.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S138357421400091X},
author = {K. Sankaranarayanan and H. Nikjoo},
keywords = {Radiation risk, DNA damage, DNA repair, Biophysical models},
abstract = {Research activity in the field of estimation of genetic risks of ionizing radiation to human populations started in the late 1940s and now appears to be passing through a plateau phase. This paper provides a background to the concepts, findings and methods of risk estimation that guided the field through the period of its growth to the beginning of the 21st century. It draws attention to several key facts: (a) thus far, genetic risk estimates have been made indirectly using mutation data collected in mouse radiation studies; (b) important uncertainties and unsolved problems remain, one notable example being that we still do not know the sensitivity of human female germ cells to radiation-induced mutations; and (c) the concept that dominated the field thus far, namely, that radiation exposures to germ cells can result in single gene diseases in the descendants of those exposed has been replaced by the concept that radiation exposure can cause DNA deletions, often involving more than one gene. Genetic risk estimation now encompasses work devoted to studies on DNA deletions induced in human germ cells, their expected frequencies, and phenotypes and associated clinical consequences in the progeny. We argue that the time is ripe to embark on a human genome-based, mechanism-driven, computational modeling of genetic risks of ionizing radiation, and we present a provisional framework for catalyzing research in the field in the 21st century.}
}
@article{ANDRADE2017111,
title = {Exact posterior computation in non-conjugate Gaussian location-scale parameters models},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {53},
pages = {111-129},
year = {2017},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2017.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S100757041730151X},
author = {J.A.A. Andrade and P.N. Rathie},
keywords = {Bayesian computation, Exact posterior distribution, Non-conjugate models, Special functions, H-function},
abstract = {In Bayesian analysis the class of conjugate models allows to obtain exact posterior distributions, however this class quite restrictive in the sense that it involves only a few distributions. In fact, most of the practical applications involves non-conjugate models, thus approximate methods, such as the MCMC algorithms, are required. Although these methods can deal with quite complex structures, some practical problems can make their applications quite time demanding, for example, when we use heavy-tailed distributions, convergence may be difficult, also the Metropolis-Hastings algorithm can become very slow, in addition to the extra work inevitably required on choosing efficient candidate generator distributions. In this work, we draw attention to the special functions as a tools for Bayesian computation, we propose an alternative method for obtaining the posterior distribution in Gaussian non-conjugate models in an exact form. We use complex integration methods based on the H-function in order to obtain the posterior distribution and some of its posterior quantities in an explicit computable form. Two examples are provided in order to illustrate the theory.}
}
@article{HUANG2022209,
title = {A Framework for Collaborative Artificial Intelligence in Marketing},
journal = {Journal of Retailing},
volume = {98},
number = {2},
pages = {209-223},
year = {2022},
issn = {0022-4359},
doi = {https://doi.org/10.1016/j.jretai.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022435921000142},
author = {Ming-Hui Huang and Roland T. Rust},
keywords = {Artificial intelligence, Collaborative AI, Collaborative intelligence, Augmentation, Replacement},
abstract = {We develop a conceptual framework for collaborative artificial intelligence (AI) in marketing, providing systematic guidance for how human marketers and consumers can team up with AI, which has profound implications for retailing, which is the interface between marketers and consumers. Drawing from the multiple intelligences view that AI advances from mechanical, to thinking, to feeling intelligence (based on how difficult for AI to mimic human intelligences), the framework posits that collaboration between AI and HI (human marketers and consumers) can be achieved by 1) recognizing the respective strengths of AI and HI, 2) having lower-level AI augmenting higher-level HI, and 3) moving HI to a higher intelligence level when AI automates the lower level. Implications for marketers, consumers, and researchers are derived. Marketers should optimize the mix and timing of AI-HI marketing team, consumers should understand the complementarity between AI and HI strengths for informed consumption decisions, and researchers can investigate innovative approaches to and boundary conditions of collaborative intelligence.}
}
@article{RUBENSTEIN2022101030,
title = {Exploring creativity's complex relationship with learning in early elementary students},
journal = {Thinking Skills and Creativity},
volume = {44},
pages = {101030},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101030},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000335},
author = {Lisa DaVia Rubenstein and Jenna Thomas and W. Holmes Finch and Lisa M. Ridgley},
keywords = {Creativity, Learning, Early elementary, Academic achievement, Kindergarten},
abstract = {The purpose of this study was to examine the relationship between learning and creativity in early elementary students using both static and growth achievement scores in reading and mathematics. Participants were kindergarten and first grade students from the Midwestern United States. Initial correlations demonstrated significant positive relationships between students’ performance on the Torrance Test of Creative Thinking –Figural (TTCT-F) and static academic achievement scores in both reading and mathematics, but that same relationship did not exist with academic growth scores. Specifically, when academic growth was examined further using Generalized Additive Models (GAMs), a complex picture emerged, such that grade level (i.e., kindergarten v. first grade) and subscale type (e.g., Fluency v. Originality) influenced the significance and nature of the relationship (i.e., linear v. nonlinear). In general, as students increased in creativity performance, they demonstrated less academic growth. Future work should explore the underlying mechanisms explaining these relationships to better help students leverage their creative abilities for positive academic gains in the classroom setting.}
}
@article{HADIMOGAVI2024100027,
title = {ChatGPT in education: A blessing or a curse? A qualitative study exploring early adopters’ utilization and perceptions},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100027},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100027},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000270},
author = {Reza {Hadi Mogavi} and Chao Deng and Justin {Juho Kim} and Pengyuan Zhou and Young {D. Kwon} and Ahmed {Hosny Saleh Metwally} and Ahmed Tlili and Simone Bassanelli and Antonio Bucchiarone and Sujit Gujar and Lennart E. Nacke and Pan Hui},
keywords = {Artificial intelligence (AI), Generative AI, ChatGPT, Education, Human-computer interaction (HCI),, Early adopters, Social media, Qualitative research},
abstract = {To foster the development of pedagogically potent and ethically sound AI-integrated learning landscapes, it is pivotal to critically explore the perceptions and experiences of the users immersed in these contexts. In this study, we perform a thorough qualitative content analysis across four key social media platforms. Our goal is to understand the user experience (UX) and views of early adopters of ChatGPT across different educational sectors. The results of our research show that ChatGPT is most commonly used in the domains of higher education, K-12 education, and practical skills training. In social media dialogues, the topics most frequently associated with ChatGPT are productivity, efficiency, and ethics. Early adopters' attitudes towards ChatGPT are multifaceted. On one hand, some users view it as a transformative tool capable of amplifying student self-efficacy and learning motivation. On the other hand, there is a degree of apprehension among concerned users. They worry about a potential overdependence on the AI system, which they fear might encourage superficial learning habits and erode students’ social and critical thinking skills. This dichotomy of opinions underscores the complexity of Human-AI Interaction in educational contexts. Our investigation adds depth to this ongoing discourse, providing crowd-sourced insights for educators and learners who are considering incorporating ChatGPT or similar generative AI tools into their pedagogical strategies.}
}
@article{YOUSIF201880,
title = {Fuzzy logic computational model for performance evaluation of Sudanese Universities and academic staff},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {30},
number = {1},
pages = {80-119},
year = {2018},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1319157816300556},
author = {Mohamed Khalid Yousif and Adnan Shaout},
keywords = {Evaluation criteria, Performance evaluation, Sudanese universities, Survey design, Fuzzy computational model, Consistency checking},
abstract = {The excellence of a Sudanese universities and academic staff member can be effectively classified by systematic and objective design criteria, which participates in developing the learning outcomes in Sudan. In the first phase of this study, we reviewed the literatures, determined and defined the suitable quantitative and qualitative criteria and then designed & exploited pairwise comparison and evaluation forms through a survey to get experts opinions/preference on the evaluation criteria that are used to measure the universities and academic staff performance. This paper presents a fuzzy logic computational model based on this survey to measure and classify the performance of Sudanese universities and academic staff, which includes computation of criteria weights and overall evaluation of Sudanese universities and academic staff using AHP and TOPSIS techniques.}
}
@incollection{LUCHINI2023195,
title = {Chapter 13 - Brain networks of creative cognition},
editor = {Roni Reiter-Palmon and Sam Hunter},
booktitle = {Handbook of Organizational Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {195-207},
year = {2023},
isbn = {978-0-323-91840-4},
doi = {https://doi.org/10.1016/B978-0-323-91840-4.00021-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323918404000219},
author = {Simone Luchini and Roger E. Beaty},
keywords = {Creativity, Default network, Divergent thinking, Executive control network, Functional connectivity, Network neuroscience},
abstract = {In recent years there has been an increasing interest in the role of brain networks supporting creative thinking. This chapter provides a summary of the literature on the network neuroscience of creativity, providing a twofold argument by separately detailing research in domain-general and domain-specific creativity. The first section will concern two main lines of research on domain-general creativity: (1) the neurocognitive mechanisms of creative cognition (how brain networks map onto specific cognitive processes involved in creative thinking), and (2) the individual differences in brain network connectivity and creative ability (how brain networks relate to differences in creative abilities). The second section, on domain-specific creativity, will then consider three domains of artistic creativity: (1) music improvisation, (2) figural creativity, and (3) literary creativity. Throughout this chapter we discuss common themes and shared findings between domain-general and domain-specific creativity. We will then conclude by outlining some of the limitations in the literature and by providing some directions for future research.}
}
@article{ARJMANDI202350,
title = {Embedding computer programming into a chemical engineering course: The impact on experiential learning},
journal = {Education for Chemical Engineers},
volume = {43},
pages = {50-57},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000064},
author = {Mohammadreza Arjmandi and Meng Wai Woo and Cody Mankelow and Thomas Loho and Kaveh Shahbaz and Amar Auckaili and Ashvin Thambyah},
keywords = {Engineering education, Qualitative study, Programming with MATLAB, Problem-based learning, Student experience},
abstract = {The need for autonomous engineering graduates who demonstrate hands-on skills has increased in the industry. Computer programming helps engineering students solve real-world problems systematically and accurately by applying governing physical and mathematical models into a format that a computer can read and execute. This study describes the pedagogical approach of incorporating programming workshops and assessments into a second-year chemical engineering course. The impact of this intervention on experiential learning amongst the students was then evaluated by analysing the feedback provided by voluntary participants during several focus group sessions. The feedback gave further insight into teaching pedagogy with respect to Kolb's experiential learning cycle. It was found the programming background of an individual clearly affects the phase of the learning cycle they predominantly experience during the workshops. Furthermore, programming background affected an individual's critical thinking while approaching an engineering problem. Constructive feedback provided by the student participants offered an invaluable opportunity for the teaching team to reflect on what went well and the areas for improvement in future iterations. The findings of this study can advance knowledge around design and implementation of a programming module within an engineering course.}
}
@article{KONDINSKI20226397,
title = {Composition-driven archetype dynamics in polyoxovanadates††Electronic supplementary information (ESI) available. CCDC 2128841 and 2130016. For ESI and crystallographic data in CIF or other electronic format see https://doi.org/10.1039/d2sc01004f},
journal = {Chemical Science},
volume = {13},
number = {21},
pages = {6397-6412},
year = {2022},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d2sc01004f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023011690},
author = {Aleksandar Kondinski and Maren Rasmussen and Sebastian Mangelsen and Nicole Pienack and Viktor Simjanoski and Christian Näther and Daniel L. Stares and Christoph A. Schalley and Wolfgang Bensch},
abstract = {ABSTRACT
Molecular metal oxides often adopt common structural frameworks (i.e. archetypes), many of them boasting impressive structural robustness and stability. However, the ability to adapt and to undergo transformations between different structural archetypes is a desirable material design feature offering applicability in different environments. Using systems thinking approach that integrates synthetic, analytical and computational techniques, we explore the transformations governing the chemistry of polyoxovanadates (POVs) constructed of arsenate and vanadate building units. The water-soluble salt of the low nuclearity polyanion [V6As8O26]4− can be effectively used for the synthesis of the larger spherical (i.e. kegginoidal) mixed-valent [V12As8O40]4− precipitate, while the novel [V10As12O40]8− POVs having tubular cyclic structures are another, well soluble product. Surprisingly, in contrast to the common observation that high-nuclearity polyoxometalate (POM) clusters are fragmented to form smaller moieties in solution, the low nuclearity [V6As8O26]4− anion is in situ transformed into the higher nuclearity cluster anions. The obtained products support a conceptually new model that is outlined in this article and that describes a continuous evolution between spherical and cyclic POV assemblies. This new model represents a milestone on the way to rational and designable POV self-assemblies.}
}
@article{VALLEETOURANGEAU2020100812,
title = {Mapping systemic resources in problem solving},
journal = {New Ideas in Psychology},
volume = {59},
pages = {100812},
year = {2020},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2020.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X17300272},
author = {Frédéric Vallée-Tourangeau and Gaëlle Vallée-Tourangeau},
abstract = {In the wild, thinking demonstrably uses interactive processes that draw on a wide range of external resources, spanning multiple time scales. As Malafouris (2015, p. 361) puts it, “cognition is not a within property; it is an in-between process”. Interactive processes configure extended systems within which each human agent is embedded. Yet much research on higher cognition, such as problem solving, reflects an implicit but deep commitment to methodological individualism that casts the agent as the ontological locus of cognition, and largely dictates the nature of the research enterprise. Thus, tasks to measure capacities and gauge reasoning performance are designed in a manner that reduces or eliminates the possibility of interacting with the problem presentation; if thinking takes place in the head, there is no need or reason to engineer procedures wherein agents can interact with the task's physical constituents. Conversely, a methodological interactivism forces one to acknowledge the participative yet not all-encompassing role of capacities such as working memory and thinking dispositions; it also encourages the granular mapping of the cognitive ecosystem from which new ideas emerge. To adopt an interactivist perspective is thus to focus on the cognitive resources of the extended system inviting a careful description of how these resources are dynamically configured over time and space to promote the development of new ideas in problem solving. In turn, a systemic perspective encourages the development of interventions that promote cognitive performance through the optimisation of systemic rather than individualist cognitive resources.}
}
@article{CHEN20121,
title = {Varieties of agents in agent-based computational economics: A historical and an interdisciplinary perspective},
journal = {Journal of Economic Dynamics and Control},
volume = {36},
number = {1},
pages = {1-25},
year = {2012},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2011.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0165188911001692},
author = {Shu-Heng Chen},
keywords = {Cellular automata, Autonomous agents, Tournaments, Genetic algorithms, Genetic programming, Cognitive capacity},
abstract = {In this paper, we trace four origins of agent-based computational economics (ACE), namely, the markets origin, the cellular-automata origin, the tournaments origin, and the experiments origin. Along with this trace, we examine how these origins have motivated different concepts and designs of agents in ACE, which starts from the early work on simple programmed agents, randomly behaving agents, zero-intelligence agents, human-written programmed agents, autonomous agents, and empirically calibrated agents, and extends to the newly developing cognitive agents, psychological agents, and culturally sensitive agents. The review also shows that the intellectual ideas underlying these varieties of agents cross several disciplines, which may be considered as a part of a general attempt to study humans (and their behavior) with an integrated interdisciplinary foundation.}
}
@article{KUMAR20224712,
title = {Efficient computational stochastic framework for performance optimization of E-waste management plant},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {8, Part A},
pages = {4712-4728},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822001677},
author = {Naveen Kumar and Deepak Sinwar and Monika Saini and Dinesh Kumar Saini and Ashish Kumar and Manjit Kaur and Dilbag Singh and Heung-No Lee},
keywords = {E-waste management plant, Availability, Maintainability, Genetic Algorithm, Differential Evolution, Particle Swarm Optimization, Markov Birth-Death Process},
abstract = {Purpose
Reliability and maintainability are the key system effectiveness measures in process and manufacturing industries, and treatment plants, especially in E-waste management plants. The present work is proposed with a motto to develop a stochastic framework for the e-waste management plant to optimize its availability integrated with reliability, availability, maintainability, and dependability (RAMD) measures and Markovian analysis to estimate the steady-state availability of the E-waste management plant. In the analysis an effort is also made to identify the best performing algorithm for availability optimization of the e-waste plant.
Methodology
A stochastic model for a particular plant is developed and its availability is optimized using various metaheuristic approaches like a genetic algorithm (GA), particle swarm optimization (PSO), and differential evolutions (DE). The most sensitive component is identified using RAMD methodology while the effect of deviation in various failure and repair rates are observed by the proposed model. The failure and repair rates follow an exponential distribution. All time-dependent random variables are statistically independent.
Originality/Novelties
A novel stochastic model is presented for an e-waste management plant and optimum availability is obtained using metaheuristic approaches. The proposed methodology is not so far discussed in the reliability analysis of process industries.
Findings
The numerical results of the proposed model compared to identify the most efficient algorithm. It is observed that genetic algorithm provides the maximum value (0.92330969) of availability at a population size 2500 after 500 iterations. PSO algorithm attained the maximum value (0.99996744) of availability just after 50 iterations and 100 population size. So, its rate of convergence is faster than GA. The optimum value of availability is 0.99997 using differential evolution after 500 iterations and population size of more than 1000. These findings are very beneficial for system designers.
Practical Implications
The proposed methodology can be utilized to find the reliability measures of other process industries.}
}
@article{HONG2006255,
title = {Bruno Buchberger — A life devoted to symbolic computation},
journal = {Journal of Symbolic Computation},
volume = {41},
number = {3},
pages = {255-258},
year = {2006},
note = {Logic, Mathematics and Computer Science: Interactions in honor of Bruno Buchberger (60th birthday)},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2005.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717105001306},
author = {Hoon Hong and Deepak Kapur and Peter Paule and Franz Winkler and  {Faculty of RISC-Linz}}
}
@article{SILAGHI20121303,
title = {A time-constrained SLA negotiation strategy in competitive computational grids},
journal = {Future Generation Computer Systems},
volume = {28},
number = {8},
pages = {1303-1315},
year = {2012},
note = {Including Special sections SS: Trusting Software Behavior and SS: Economics of Computing Services},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X11002251},
author = {Gheorghe Cosmin Silaghi and Liviu Dan Şerban and Cristian Marius Litan},
keywords = {SLA negotiation, Intelligent strategies, Bayesian learning, Time constraints},
abstract = {Automated and intelligent negotiation solutions for reaching service level agreements (SLA) represent a hot research topic in computational grids. Previous work regarding SLA negotiation in grids focuses on devising bargaining models where service providers and consumers can meet and exchange SLA offers and counteroffers. Recent developments in agent research introduce strategies based on opponent learning for contract negotiation. In this paper we design a generic framework for strategical negotiation of service level values under time constraints and exemplify the usage of our framework by extending the Bayesian learning agent to cope with the limited duration of a negotiation session. We prove that opponent learning strategies are worth for consideration in open competitive computational grids, leading towards an optimal allocation of resources and fair satisfaction of participants.}
}
@article{RUPESH20213320,
title = {Computational investigation of heat transfer on the surface of engine cylinder with fins of different shapes and materials},
journal = {Materials Today: Proceedings},
volume = {46},
pages = {3320-3326},
year = {2021},
note = {International Conference on Materials, Manufacturing and Mechanical Engineering for Sustainable Developments-2020 (ICMSD 2020)},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.11.471},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320391355},
author = {P.L. Rupesh and K. Raja and N.V. {Sai Deepak Raj} and M. {Pruthviraj Bharmal} and Pandey {Aditya Ramjatan}},
keywords = {Two stroke engine, Fin, Circular fin, Tapered fin, Silumin, Thermal Conductivity},
abstract = {In everyday life the use of vehicles has expanded immensely for some ventures and house hold applications, likewise the running time of engine cycle is exceptionally long. Thus because of the consistent running enormous measure of heat is produced. At the point when this heat isn't appropriately disseminated, the engine gets more fragile very soon and life of the engine declines because of the heat development. To build the life of the engine, heat dispersal is expanded by giving fins at external of engine chamber. The shape of the fins and the material used for the fin increases its heat dissipation capacity and in turn increases the cooling of the engine for proper functioning. The present work focuses on the design of fins of circular and tapered shapes for a 2-stroke engine. The temperature distribution and the heat dissipation along the fin surface of two shapes has been observed by a steady state thermal analysis. Alusil and Silumin has been selected as the fin materials and a computational evaluation has also been done using FEM. A better shape of the fin along with a suitable material has been selected based on the results observed by FEM and on comparison with the existing shape and material of the fin.}
}
@article{LOHSE2012236,
title = {Thinking about muscles: The neuromuscular effects of attentional focus on accuracy and fatigue},
journal = {Acta Psychologica},
volume = {140},
number = {3},
pages = {236-245},
year = {2012},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2012.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001691812000807},
author = {Keith R. Lohse and David E. Sherwood},
keywords = {Attention, Force production, Motor control, Fatigue},
abstract = {Although the effects of attention on movement execution are well documented behaviorally, much less research has been done on the neurophysiological changes that underlie attentional focus effects. This study presents two experiments exploring effects of attention during an isometric plantar-flexion task using surface electromyography (sEMG). Participants' attention was directed either externally (towards the force plate they were pushing against) or internally (towards their own leg, specifically the agonist muscle). Experiment 1 tested the effects of attention on accuracy and efficiency of force produced at three target forces (30, 60, and 100% of the maximum voluntary contraction; MVC). An internal focus of attention reduced the accuracy of force being produced and increased cocontraction of the antagonist muscle. Error on a given trial was positively correlated with the magnitude of cocontraction on that trial. Experiment 2 tested the effects of attention on muscular fatigue at 30, 60 and 100%MVC. An internal focus of attention led to less efficient intermuscular coordination, especially early in the contraction. These results suggest that an internal focus of attention disrupts efficient motor control in force production resulting in increased cocontraction, which potentially explains other neuromechanical findings (e.g. reduced functional variability with an internal focus).}
}
@incollection{DIBBLE20061511,
title = {Chapter 31 Computational Laboratories for Spatial Agent-Based Models},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1511-1548},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02031-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020319},
author = {Catherine Dibble},
keywords = {agent-based simulation, computational laboratory, computational social science, computational economics, spatial economics, spatial social science, spatial networks, small-world networks, scale-free networks, synthetic landscape, inference},
abstract = {An agent-based model is a virtual world comprising distributed heterogeneous agents who interact over time. In a spatial agent-based model the agents are situated in a spatial environment and are typically assumed to be able to move in various ways across this environment. Some kinds of social or organizational systems may also be modeled as spatial environments, where agents move from one group or department to another and where communications or mobility among groups may be structured according to implicit or explicit channels or transactions costs. This chapter focuses on the potential usefulness of computational laboratories for spatial agent-based modeling. Speaking broadly, a computational laboratory is any computational framework permitting the exploration of the behaviors of complex systems through systematic and replicable simulation experiments. By that definition, most of the research discussed in this handbook would be considered to be work with computational laboratories. A narrower definition of computational laboratory (or comp lab for short) refers specifically to specialized software tools to support the full range of agent-based modeling and complementary tasks. These tasks include model development, model evaluation through controlled experimentation, and both the descriptive and normative analysis of model outcomes. The objective of this chapter is to explore how comp lab tools and activities facilitate the systematic exploration of spatial agent-based models embodying complex social processes critical for social welfare. Examples include the spatial and temporal coordination of human activities, the diffusion of new ideas or of infectious diseases, and the emergence and ecological dynamics of innovative ideas or of deadly new diseases.}
}
@article{WELLS1998269,
title = {Turing's analysis of computation and theories of cognitive architecture},
journal = {Cognitive Science},
volume = {22},
number = {3},
pages = {269-294},
year = {1998},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(99)80041-X},
url = {https://www.sciencedirect.com/science/article/pii/S036402139980041X},
author = {A.J. Wells},
abstract = {Turing's analysis of computation is a fundamental part of the background of cognitive science. In this paper it is argued that a re-interpretation of Turing's work is required to underpin theorizing about cognitive architecture. It is claimed that the symbol systems view of the mind, which is the conventional way of understanding how Turing's work impacts on cognitive science, is deeply flawed. There is an alternative interpretation that is more faithful to Turing's original insights, avoids the criticisms made of the symbol systems approach and is compatible with the growing interest in agent-environment interaction. It is argued that this interpretation should form the basis for theories of cognitive architecture.}
}
@article{GOLDSMITH198815,
title = {Idiots savants — Thinking about remembering: A response to White},
journal = {New Ideas in Psychology},
volume = {6},
number = {1},
pages = {15-23},
year = {1988},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(88)90020-7},
url = {https://www.sciencedirect.com/science/article/pii/0732118X88900207},
author = {Lynn T. Goldsmith and David Henry Feldman}
}
@article{SIMMONS2012311,
title = {Bats use a neuronally implemented computational acoustic model to form sonar images},
journal = {Current Opinion in Neurobiology},
volume = {22},
number = {2},
pages = {311-319},
year = {2012},
note = {Neuroethology},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2012.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959438812000293},
author = {James A Simmons},
abstract = {This paper reexamines neurophysiological results from echolocating big brown bats to propose a new perspective on FM biosonar processing in the auditory system. Individual auditory neurons are frequency-tuned and respond to brief, 2–10ms FM sweeps with an average of one spike per sound to register their tuned frequencies, to detect echo arrival, or to register a local null in the echo spectrum. When initiated by the broadcast, these responses comprise a cascade of single spikes distributed across time in neurons tuned to different frequencies that persists for 30–50ms, long after the sound has ended. Their progress mirrors the broadcast's propagation away from the bat and the return of echoes for distances out to 5–8m. Each returning echo evokes a similar pattern of single spikes that coincide with ongoing responses to the broadcast to register the target's distance and shape. The hypothesis advanced here is that this flow of responses over time acts as an internal model of sonar acoustics that the bat executes using neuronal computations distributed across many neurons to accumulate a dynamic image of the bat's surroundings.}
}
@article{OXMAN1999105,
title = {Educating the designerly thinker},
journal = {Design Studies},
volume = {20},
number = {2},
pages = {105-122},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00029-5},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000295},
author = {Rivka Oxman},
keywords = {design education, design cognition, design knowledge, conceptual design, computational models},
abstract = {This paper presents a hypothesis about design education that is framed within and derived from cognitive theories of learning. The relevance of design thinking and cognitive approaches to the development of pedagogical approaches in design education is presented and discussed. A conceptual model for design education that emphasizes the acquisition of explicit knowledge of design is proposed. The acquisition of knowledge is achieved through the explication of cognitive structures and strategies of design thinking. The explication process is constructed by exploiting a representational formalism, and a computational medium which supports both the learning process as well as the potential re-use of this knowledge. Finally, an argument is presented that the measure of learning, generally equated with the evaluation of the product of designing, can instead be based upon evaluating learning increments of acquired knowledge.}
}
@article{VAZQUEZ2017550,
title = {Price computation in electricity auctions with complex rules: An analysis of investment signals},
journal = {Energy Policy},
volume = {105},
pages = {550-561},
year = {2017},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0301421517300770},
author = {Carlos Vazquez and Michelle Hallack and Miguel Vazquez},
keywords = {Electricity auctions, Investment signals, Side payments, Integer decisions, Marginal cost},
abstract = {This paper discusses the problem of defining marginal costs when integer variables are present, in the context of short-term power auctions. Most of the proposals for price computation existing in the literature are concerned with short-term competitive equilibrium (generators should not be willing to change the dispatch assigned to them by the auctioneer), which implies operational-cost recovery for all of the generators accepted in the auction. However, this is in general not enough to choose between the different pricing schemes. We propose to include an additional criterion in order to discriminate among different pricing schemes: prices have to be also signals for generation expansion. Using this condition, we arrive to a single solution to the problem of defining prices, where they are computed as the shadow prices of the balance equations in a linear version of the unit commitment problem. Importantly, not every linearization of the unit commitment is valid; we develop the conditions for this linear model to provide adequate investment signals. Compared to other proposals in the literature, our results provide a strong motivation for the pricing scheme and a simple method for price computation.}
}
@article{TIBURU201836,
title = {Investigating the Conformation of S100β Protein Under Physiological Parameters Using Computational Modeling: A Clue for Rational Drug Design},
journal = {The Open Biomedical Engineering Journal},
volume = {12},
pages = {36-50},
year = {2018},
issn = {1874-1207},
doi = {https://doi.org/10.2174/1874120701812010036},
url = {https://www.sciencedirect.com/science/article/pii/S1874120718000036},
author = {Elvis K. Tiburu and Ibrahim Issah and Mabel Darko and Robert E. Armah-Sekum and Stephen O. A. Gyampo and Nadia K. Amoateng and Samuel K. Kwofie and Gordon Awandare},
keywords = {S100β Protein, Molecular Dynamics, Cofactors, Energy Minimization, Physiological Parameters, Alzheimer's},
abstract = {Background
Physiochemical factors such as temperature, pH and cofactors are well known parameters that confer conformational changes in a protein structure. With S100β protein being a metal binding brain-specific receptor for both extracellular and intracellular functions, a change in conformation due to the above-mentioned factors, can compromise their cellular functions and therefore result in several pathological conditions such as Alzheimer’s disease, Ischemic stroke, as well as Myocardial Infarction.
Objective
The studies conducted sought to elucidate the effect of these physiological factors on the conformational dynamics of S100β protein using computational modeling approaches.
Method
Temperature-dependent and protein-cofactor complexes molecular dynamics simulations were conducted by varying the temperature from 100 to 400K using GROMACS 5.0.3. Additionally, the conformational dynamics of the protein was studied by varying the pH at 5.0, 7.4 and 9.0 using Ambertools17. This was done by preparing the protein molecule, solvating and minimizing its energy level as well as heating it to the required temperature, equilibrating and simulating under desired conditions (NVT and NPT ensembles).
Results
The results show that the protein misfolds as a function of increasing temperature with alpha helical content at 100K and 400K being 57.8% and 43.3%, respectively. However, the binding sites of the protein were not appreciably affected by temperature variations. The protein displayed high conformational instability in acidic medium (pH ~5.0). The binding sites of Ca2+, Mg2+ and Zn2+ were identified and each exhibited different groupings of the secondary structural elements (binding motifs). The secondary structure analysis revealed different conformational changes with the characteristic appearance of two beta hairpins in the presence of Zn2+and Mg2+.
Conclusion
High temperatures, different cofactors and acidic pH confer conformational changes to the S100β structure and these results may indicate the design of novel drugs against the protein.}
}
@article{GIANNOPULU2022e09017,
title = {Synchronised neural signature of creative mental imagery in reality and augmented reality},
journal = {Heliyon},
volume = {8},
number = {3},
pages = {e09017},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09017},
url = {https://www.sciencedirect.com/science/article/pii/S240584402200305X},
author = {I. Giannopulu and G. Brotto and T.J. Lee and A. Frangos and D. To},
keywords = {Creativity, Synchronisation, Mental imagery, Real environment, Augmented reality, Complexity},
abstract = {Creativity, transforming imaginative thinking into reality, is a mental imagery simulation in essence. It can be incorporeal, concerns sophisticated and/or substantial thinking, and involves objects. In the present study, a mental imagery task consisting of creating a scene using familiar (FA) or abstract (AB) physical or virtual objects in real (RMI) and augmented reality (VMI) environments, and an execution task involving effectively creating a scene in augmented reality (VE), were utilised. The beta and gamma neural oscillations of healthy participants were recorded via a 32 channel wireless 10/20 international EGG system. In real and augmented environments and for both the mental imagery and execution tasks, the participants displayed a similar cortico-cortical neural signature essentially based on synchronous vs asynchronous beta and gamma oscillatory activities between anterior (i.e. frontal) and posterior (i.e. parietal, occipito-parietal and occipito-temporal) areas bilaterally. The findings revealed a transient synchronised neural architecture that appears to be consistent with the hypothesis according to which, creativity, because of its inherent complexity, cannot be confined to a single brain area but engages various interconnected networks.}
}
@article{YAMAGUCHI2023427,
title = {Equitable STEM+CS learning experiences for girls of color: nurturing an independent learning approach via a learning ecosystem},
journal = {Journal for Multicultural Education},
volume = {17},
number = {4},
pages = {427-442},
year = {2023},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-01-2023-0004},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X23000368},
author = {Ryoko Yamaguchi and Veronica {Hankerson Madrigal} and Cyntrica N. Eaton and Jamika D. Burge},
keywords = {Black girls, Computer science, Computational thinking, Dependent learning, Equity, Independent learning, Learning behaviors, Learning ecosystem, Middle school girls, STEM, STEM+CS},
abstract = {Purpose
There is a critical need to understand how to attract Black girls and other girls of color to the science, technology, engineering, math, and computer science (STEM+CS) field. This study aims to look at the design and implementation of a CS learning ecosystem that supports girls of color in acquiring critical CS skills starting in middle school.
Design/methodology/approach
This mixed-method case study included 53 girls, between the ages of 11 and 13, in four US middle schools. Study methods included the analysis of a pre-program student survey, longitudinal interviews and focus groups, weekly observations and computing artifacts.
Findings
Program participants were interested in CS, were confident in their ability to learn CS, had prior coding and CS experience and had parents and teachers who encouraged them to learn CS. But some students showed dependent learning behaviors while engaging in CS activities. These included relying on instructors and being reticent to make mistakes–behaviors that limit learning. The CS learning ecosystem supported students as they shifted from applying dependent learning approaches to applying independent learning approaches. Instructors sustained a growth mindset and supported productive struggle as students learned CS skills.
Originality/value
A CS learning system supported equitable learning experiences and helped students develop independent learning behaviors that led to deeper engagement in CS.}
}
@article{KALPOKIENE2023102197,
title = {Creative encounters of a posthuman kind – anthropocentric law, artificial intelligence, and art},
journal = {Technology in Society},
volume = {72},
pages = {102197},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102197},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23000027},
author = {Julija Kalpokiene and Ignas Kalpokas},
keywords = {Anthropocentrism, Artificial intelligence, Creativity, Copyright},
abstract = {Artificial Intelligence (AI) is becoming an increasingly transformative force in human life. Crucially, its impact is already extending beyond automation of routine tasks and encroaching on creativity – a domain once seen as exclusively human. Hence, this article first surveys the discriminatory and exploitative underpinnings of the anthropocentric thinking that lies beyond attempts at sidelining the creative capacities of AI. Next, four different approaches to creativity and art are analyzed, ultimately conceptualizing art-ness as externally ascribed. Ultimately, the article moves to one way of such ascription – copyrightability – demonstrating the anthropocentric thinking behind attempts to both deny and award copyright protection to AI-generated content. Moreover, it transpires that human authors are under threat whichever of such strategies ends up dominant.}
}
@article{AMEMIYA2024105836,
title = {Children use disagreement to infer what happened},
journal = {Cognition},
volume = {250},
pages = {105836},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724001227},
author = {Jamie Amemiya and Gail D. Heyman and Tobias Gerstenberg},
keywords = {Disagreement, Inference, Prediction, Theory of mind, Ambiguous speech},
abstract = {In a rapidly changing and diverse world, the ability to reason about conflicting perspectives is critical for effective communication, collaboration, and critical thinking. The current pre-registered experiments with children ages 7 to 11 years investigated the developmental foundations of this ability through a novel social reasoning paradigm and a computational approach. In the inference task, children were asked to figure out what happened based on whether two speakers agreed or disagreed in their interpretation. In the prediction task, children were provided information about what happened and asked to predict whether two speakers will agree or disagree. Together, these experiments assessed children's understanding that disagreement often results from ambiguity about what happened, and that ambiguity about what happened is often predictive of disagreement. Experiment 1 (N = 52) showed that children are more likely to infer that an ambiguous utterance occurred after learning that people disagreed (versus agreed) about what happened and found that these inferences become stronger with age. Experiment 2 (N = 110) similarly found age-related change in children's inferences and also showed that children could reason in the forward direction, predicting that an ambiguous utterance would lead to disagreement. A computational model indicated that although children's ability to predict when disagreements might arise may be critical for making the reverse inferences, it did not fully account for age-related change.}
}
@article{EGRINAGY2008135,
title = {Algebraic properties of automata associated to Petri nets and applications to computation in biological systems},
journal = {Biosystems},
volume = {94},
number = {1},
pages = {135-144},
year = {2008},
note = {Seventh International Workshop on Information Processing in Cells and Tissues},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2008.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0303264708001366},
author = {Attila Egri-Nagy and Chrystopher L. Nehaniv},
keywords = {Algebraic automata theory, Petri nets, Krohn-Rhodes theorem, Algebraic biology},
abstract = {Biochemical and genetic regulatory networks are often modeled by Petri nets. We study the algebraic structure of the computations carried out by Petri nets from the viewpoint of algebraic automata theory. Petri nets comprise a formalized graphical modeling language, often used to describe computation occurring within biochemical and genetic regulatory networks, but the semantics may be interpreted in different ways in the realm of automata. Therefore, there are several different ways to turn a Petri net into a state-transition automaton. Here, we systematically investigate different conversion methods and describe cases where they may yield radically different algebraic structures. We focus on the existence of group components of the corresponding transformation semigroups, as these reflect symmetries of the computation occurring within the biological system under study. Results are illustrated by applications to the Petri net modelling of intermediary metabolism. Petri nets with inhibition are shown to be computationally rich, regardless of the particular interpretation method. Along these lines we provide a mathematical argument suggesting a reason for the apparent all-pervasiveness of inhibitory connections in living systems.}
}
@article{KENNEDY198538,
title = {Thinking of opening your own business? Be prepared!},
journal = {Business Horizons},
volume = {28},
number = {5},
pages = {38-42},
year = {1985},
issn = {0007-6813},
doi = {https://doi.org/10.1016/0007-6813(85)90066-7},
url = {https://www.sciencedirect.com/science/article/pii/0007681385900667},
author = {Carson R. Kennedy},
abstract = {The good news is that new businesses are booming. The bad news is that many are going bust. Careful preparation prior to opening your own business is the best way to forestall failure.}
}
@article{BLACKBURNE2025105969,
title = {Communicated priors tune the perception of control},
journal = {Cognition},
volume = {254},
pages = {105969},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105969},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724002555},
author = {George Blackburne and Chris D. Frith and Daniel Yon},
keywords = {Agency, Control, Expectation, Prediction, Communication},
abstract = {Action allows us to shape the world around us. But to act effectively we need to accurately sense what we can and cannot control. Classic theories across cognitive science suppose that this ‘sense of agency’ is constructed from the sensorimotor signals we experience as we interact with our surroundings. But these sensorimotor signals are inherently ambiguous, and can provide us with a distorted picture of what we can and cannot influence. Here we investigate one way that agents like us might overcome the inherent ambiguity of these signals: by combining noisy sensorimotor evidence with prior beliefs about control acquired through explicit communication with others. Using novel tools to measure and model control decisions, we find that explicit beliefs about the controllability of the environment alter both the sensitivity and bias of agentic choices; meaning that we are both better at detecting and more biased to feel control when we are told to expect it. These seemingly paradoxical effects on agentic choices can be captured by a computational model where expecting to be in control exaggerates the sensitivity or ‘gain’ of the mechanisms we use to detect our influence over our surroundings – making us increasingly sensitised to both true and illusory signs of agency. In combination, these results reveal a cognitive and computational mechanism that allows public communication about what we can and cannot influence to reshape our private sense of control.}
}
@article{BATISTA2003189,
title = {A Computational Basis to Object?},
journal = {Neuron},
volume = {37},
number = {2},
pages = {189-190},
year = {2003},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(03)00029-1},
url = {https://www.sciencedirect.com/science/article/pii/S0896627303000291},
author = {Aaron P. Batista},
abstract = {To use an object, we must be able to perceive the spatial relationship between the object's parts. The accepted view of how the brain coherently encodes an object is that some neurons in the frontal cortex employ an object-centered coordinate frame. A new computational model challenges this view, using the rich conceptual framework of neural basis functions.}
}
@article{YAO2018107,
title = {Three-way decision and granular computing},
journal = {International Journal of Approximate Reasoning},
volume = {103},
pages = {107-123},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18302809},
author = {Yiyu Yao},
keywords = {Three-way decision, Three-way computing, Granular computing in threes, Thinking in threes, Magical number three},
abstract = {Based on results from cognitive science, this paper examines the two fields of three-way decision and granular computing, as well as their interplay. The ideas from one field shed new light on the other field. The integration of the two gives rise to three-way granular computing, that is, thinking, problem solving, and information processing in threes. We discuss a wide sense of three-way decision and propose a trisecting–acting–outcome (TAO) model. We explain fundamental notions of granular computing based on the philosophy of three-way decision as thinking in threes. We discuss a model of three-way granular computing by making use of two particular types of granular structures represented, respectively, by three granules and three levels. We use examples across different disciplines to demonstrate the values of the two types. Our investigation suggests that, in many situations, the power of granular computing is indeed the power of three-way decision, i.e., thinking in threes.}
}
@article{PLATZ2024e4563,
title = {Dichlorocarbene: From Jack Hine to Robert Moss},
journal = {Journal of Physical Organic Chemistry},
volume = {37},
number = {1},
pages = {e4563},
year = {2024},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4563},
url = {https://www.sciencedirect.com/science/article/pii/S089432302300259X},
author = {Matthew S. Platz},
keywords = {carbene, dichlorocarbene, Jack Hine, Robert Moss},
abstract = {A select history of dichlorocarbene chemistry between 1950 and 2010 will be presented. This is not a comprehensive review; rather, it is a personal perspective on the contributions of two respected colleagues, the reactive intermediate that spanned their research efforts, and their important contributions to organic synthesis and mechanistic thinking.}
}
@article{VIGNONCLEMENTEL20103,
title = {A primer on computational simulation in congenital heart disease for the clinician},
journal = {Progress in Pediatric Cardiology},
volume = {30},
number = {1},
pages = {3-13},
year = {2010},
note = {Proceedings of the 1st International Conference on Computational Simulation in Congenital Heart Disease},
issn = {1058-9813},
doi = {https://doi.org/10.1016/j.ppedcard.2010.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1058981310000767},
author = {Irene E. Vignon-Clementel and Alison L. Marsden and Jeffrey A. Feinstein},
keywords = {Hemodynamics, Computer modeling, Boundary conditions, Clinical data, Congenital heart disease},
abstract = {Interest in the application of engineering methods to problems in congenital heart disease has gained increased popularity over the past decade. The use of computational simulation to examine common clinical problems including single ventricle physiology and the associated surgical approaches, the effects of pacemaker implantation on vascular occlusion, or delineation of the biomechanical effects of implanted medical devices is now routinely appearing in clinical journals within all pediatric cardiovascular subspecialties. In practice, such collaboration can only work if both communities understand each other's methods and their limitations. This paper is intended to facilitate this communication by presenting in the context of congenital heart disease (CHD) the main steps involved in performing computational simulation—from the selection of an appropriate clinical question/problem to understanding the computational results, and all of the “black boxes” in between. We examine the current state of the art and areas in need of continued development. For example, medical image-based model-building software has been developed based on numerous different methods. However, none of them can be used to construct a model with a simple “click of a button.” The creation of a faithful, representative anatomic model, especially in pediatric subjects, often requires skilled manual intervention. In addition, information from a second imaging modality is often required to facilitate this process. We describe the technical aspects of model building, provide a definition of some of the most commonly used terms and techniques (e.g. meshes, mesh convergence, Navier-Stokes equations, and boundary conditions), and the assumptions used in running the simulations. Particular attention is paid to the assignment of boundary conditions as this point is of critical importance in the current areas of research within the realm of congenital heart disease. Finally, examples are provided demonstrating how computer simulations can provide an opportunity to “acquire” data currently unobtainable by other modalities, with essentially no risk to patients. To illustrate these points, novel simulation examples of virtual Fontan conversion (from preoperative data to predicted postoperative state) and outcomes of different surgical designs are presented. The need for validation of the currently employed techniques and predicted results are required and the methods remain in their infancy. While the daily application of these technologies to patient-specific clinical scenarios likely remains years away, the ever increasing interest in this area among both clinicians and engineers makes its eventual use far more likely than ever before and, some could argue, only a matter of [computing] time.}
}
@article{MANALU2023641,
title = {Developing Nusantara Mobile Application to Support Local Tourism in Indonesia},
journal = {Procedia Computer Science},
volume = {227},
pages = {641-650},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.568},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923017350},
author = {Daniella Oktalina Manalu and Yudhistya Ayu Kusumawati and Cuk Tho},
keywords = {mobile application, tourism, local tourism},
abstract = {Tourism is a very important sector and has a major influence on development and national income. Moreover, Indonesia has thousands of tourist destinations that are very beautiful and interesting to visit, both for Indonesians and foreigners. It's just that, there are still many local tours, such as tourist villages, which are still not well known by most people. In fact, there are many cultures, customs, places of recreation, or characteristics of an area that need to be seen and introduced to outsiders, even to Indonesians themselves. Therefore, this study aims to explain the problems that occur in the field of tourism, as well as provide solutions in the form of tourism applications that aim to help promote local Indonesian tourism, as well as make it easy for travel enthusiasts to organize their travel plans. The process of making this travel application is also carried out through various research and interviews with potential users and IT people in order to produce an attractive and effective application. This study uses the design thinking method. Researchers collected data sources from literature studies and surveys through questionnaires, where the results of the data obtained from the questionnaires were numerical or quantitative. The aim is to determine the level of public interest in tourism, as well as determine the level of potential users of this tourism application. That way, the goals of this application will be achieved and effective in helping solve tourism problems.}
}
@article{WANG2013226,
title = {A Computational Knowledge Elicitation and Sharing System for mental health case management of the social service industry},
journal = {Computers in Industry},
volume = {64},
number = {3},
pages = {226-234},
year = {2013},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2012.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361512001777},
author = {W.M. Wang and C.F. Cheung},
keywords = {Narratives, Knowledge management, Concept mapping, Knowledge-based system, Natural language processing},
abstract = {Narrative data provide rich information and knowledge to the workers. However, existing systems mainly served as a workflow system, a reporting system, or a database system for storing this kind of information. The massive amount of unstructured narrative data makes it extremely difficult to be shared and reused. Actual knowledge sharing and reuse among the workers is still limited. This paper presents a Computational Knowledge Elicitation and Sharing System which attempts to elicit knowledge from individuals as well as a team and converts it into a structured format and shared among the team. The proposed system accomplishes several current technologies in knowledge-based system, artificial intelligence and natural language processing, which converts the narrative knowledge of knowledge workers into a concept mapping representation. With a sufficient number of narratives, patterns are revealed and an aggregate concept map for all participating members is produced. It converts the unstructured text into a more structured format which helps to summarize and share the knowledge that can be taken in handling different case management issues. Such integration is considered to be novel. A prototype system has been implemented based on the method successfully in the mental healthcare of a social service organization for handling their case management issues. An experiment has been carried out for measuring the accuracy for converting the unstructured data into the structured format. The theoretical results are found to agree well with the experimental results.}
}
@article{RUSSO2020745,
title = {Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit Distinct Geometries, Compatible with Different Classes of Computation},
journal = {Neuron},
volume = {107},
number = {4},
pages = {745-758.e6},
year = {2020},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2020.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0896627320303664},
author = {Abigail A. Russo and Ramin Khajeh and Sean R. Bittner and Sean M. Perkins and John P. Cunningham and L.F. Abbott and Mark M. Churchland},
keywords = {supplementary motor area, motor control, motor cortex, population coding, recurrent neural network, neural dynamics, neural computation, population geometry},
abstract = {Summary
The supplementary motor area (SMA) is believed to contribute to higher order aspects of motor control. We considered a key higher order role: tracking progress throughout an action. We propose that doing so requires population activity to display low "trajectory divergence": situations with different future motor outputs should be distinct, even when present motor output is identical. We examined neural activity in SMA and primary motor cortex (M1) as monkeys cycled various distances through a virtual environment. SMA exhibited multiple response features that were absent in M1. At the single-neuron level, these included ramping firing rates and cycle-specific responses. At the population level, they included a helical population-trajectory geometry with shifts in the occupied subspace as movement unfolded. These diverse features all served to reduce trajectory divergence, which was much lower in SMA versus M1. Analogous population-trajectory geometry, also with low divergence, naturally arose in networks trained to internally guide multi-cycle movement.}
}
@article{SNAIDER201259,
title = {Time production and representation in a conceptual and computational cognitive model},
journal = {Cognitive Systems Research},
volume = {13},
number = {1},
pages = {59-71},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041710000781},
author = {Javier Snaider and Ryan McCall and Stan Franklin},
keywords = {Time, Time perception, Cognitive architecture, Event, Duration},
abstract = {Time perception and inferences there from are of critical importance to many autonomous agents. But time is not perceived directly by any sensory organ. We argue that time is constructed by cognitive processes. Here we present a model for time perception that concentrates on succession and duration, and that generates these concepts and others, such as continuity, immediate present duration, and lengths of time. These concepts are grounded through the perceptual process itself. We also address event representation, event hierarchy and expectations, as issues intimately related with time. The LIDA cognitive model is used to illustrate these ideas.}
}
@article{DYER2021101055,
title = {Uncertainty and disciplinary difference: Mapping attitudes towards uncertainty across discipline boundaries},
journal = {Design Studies},
volume = {77},
pages = {101055},
year = {2021},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2021.101055},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X21000661},
author = {Loren Dyer and Jacqueline Power and Andrew Steen and Louise Wallis and Aidan Davison},
keywords = {design processes, design thinking, epistemology, interdisciplinarity, uncertainty},
abstract = {This article investigates the different ways that uncertainty is understood and approached across design disciplines. Structural attitudes toward uncertainty are assessed in design thinking literature before other possible ways of viewing uncertainty in the design process are introduced. Uncertainty is then presented as a source of epistemological difference between design disciplines, and this difference is explicated through a project that uses literature survey and analytical diagramming to map differences between discipline attitudes to uncertainty. Our review identifies uncertainty as a prevalent source of discipline difference with the goal of better describing barriers, and effective responses to them, in inter- and trans-disciplinary design agendas.}
}
@incollection{MADIAJAGAN20191,
title = {Chapter 1 - Parallel Computing, Graphics Processing Unit (GPU) and New Hardware for Deep Learning in Computational Intelligence Research},
editor = {Arun Kumar Sangaiah},
booktitle = {Deep Learning and Parallel Computing Environment for Bioengineering Systems},
publisher = {Academic Press},
pages = {1-15},
year = {2019},
isbn = {978-0-12-816718-2},
doi = {https://doi.org/10.1016/B978-0-12-816718-2.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128167182000087},
author = {M. Madiajagan and S. Sridhar Raj},
keywords = {Deep learning, Parallelization, Graphics processing unit, Hardware architecture, Memory optimization, Computational intelligence},
abstract = {Graphics processing unit (GPU) is an electronic circuit which manipulates and modifies the memory for better image output. Deep learning involves huge amounts of matrix multiplications and other operations which can be massively parallelized and thus sped up on GPUs. A single GPU might have thousands of cores while a CPU usually has no more than 12 cores. GPU's practical applicability is affected by two issues: long training time and limited GPU memory, which is greatly influenced as the neural network size grows. In order to overcome these issues, this chapter presents various technologies in distributed parallel processing which improve the training time and optimize the memory, and hardware engine architectures will be explored for data size reduction. The GPUs generally used for deep learning are limited in memory size compared to CPUs, so even the latest Tesla GPU has only 16 GB of memory. Therefore, GPU memory cannot be increased to that extent easily, so networks must be designed to fit within the available memory. This could be a factor limiting progress, overcoming which would be highly beneficiary to the computational intelligence area.}
}
@article{ZBOINSKA2019675,
title = {Influence of a hybrid digital toolset on the creative behaviors of designers in early-stage design},
journal = {Journal of Computational Design and Engineering},
volume = {6},
number = {4},
pages = {675-692},
year = {2019},
issn = {2288-4300},
doi = {https://doi.org/10.1016/j.jcde.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S228843001830174X},
author = {Malgorzata A. Zboinska},
keywords = {Early-stage design, Digital design, Computational design, Architectural design, Hybrid digital design systems, Intelligent human-machine integration},
abstract = {The purpose of this research was to investigate how diversification of the repertoire of digital design techniques affects the creative behaviors of designers in the early design phases. The principal results of practice-based pilot experiments on the subject indicate three key properties of the hybrid digital tooling strategy. The strategy features intelligent human-machine integration, facilitating three different types of synergies between the designer and the digital media: human-dominated, machine-dominated, and a balanced human-machine collaboration. This strategy also boosts the cognitive behaviors of the designer by triggering divergent, transformative and convergent design activities and allowing for work on various abstraction levels. In addition, the strategy stimulates the explorative behaviors of the designer by encouraging the production of and interaction with a wide range of design representations, including physical and digital, dynamic and static objects. Thus, working with a broader range of digital modeling techniques can positively influence the creativity of designers in the early conception stages.}
}
@article{ROTH2023101278,
title = {Reset and restoration. The looming conservative turn of management theory: An extension of Foss et al.},
journal = {Scandinavian Journal of Management},
volume = {39},
number = {3},
pages = {101278},
year = {2023},
issn = {0956-5221},
doi = {https://doi.org/10.1016/j.scaman.2023.101278},
url = {https://www.sciencedirect.com/science/article/pii/S0956522123000192},
author = {Steffen Roth},
keywords = {The Great Reset, Management theory, Cronyism, Stratification, Conservatism, Restorism},
abstract = {This article is a reply to Foss et al.’s (2022) contribution to the special issue of the Scandinavian Journal of Management on The Great Reset of management and organization theory. In their article, the authors make a strong case that “reset thinking” geared towards a more “sustainable” redesign of the global economy promotes extensive state interventionism and cronyism capitalism, and therefore reject the idea of a need for “a fundamental rethink of existing management theory”. Whereas I do agree with the authors on most points, I am less convinced that “existing management theory” will suffice to address the problem of “reset thinking”. In this article, I demonstrate that the economy-bias of existing theories is a gateway for “reset thinking” geared towards an allegedly necessary re-/socialisation of management and organisation. A research agenda on cronyism must therefore be complemented by one on privilege and hierarchy not only as undesirable side-effects of cronyism, but also as desired outcomes of advocacy for specific minorities or missions. As self-identifications with group interests or calls for missions have become popular in management theory, I conclude that this new appetite for privilege might undermine not only the higher ideals of many management theorists, but also the foundations of modern society.}
}
@article{MANNI2016260,
title = {Numerical study of airfoil stall cells using a very wide computational domain},
journal = {Computers & Fluids},
volume = {140},
pages = {260-269},
year = {2016},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2016.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0045793016302894},
author = {Luca Manni and Takafumi Nishino and Pierre-Luc Delafin},
keywords = {Flow separation, 2D/3D transition, High aspect ratio wing, Unsteady RANS, Delayed DES},
abstract = {The formation of stall cells over a NACA 0012 airfoil at a Reynolds number of one million has been investigated numerically, using unsteady Reynolds-averaged Navier–Stokes (URANS) and delayed detached-eddy simulation (DDES) approaches. The simulations are performed with a very wide computational domain (10 chord length) to minimize the influence of spanwise periodic boundary conditions. For the URANS simulations, four different spanwise mesh resolutions are tested to determine the minimum resolution required to capture the formation of stall cells. Both URANS and DDES results show a sudden decrease in lift and increase in drag between 16° and 17° angle of attack, accompanied by a significant change of separated flow patterns. Stall cell structures are observed clearly in the URANS solutions between 17° and 19° with a spanwise spacing of about 1.4 to 1.8 chord length, which agrees well with a theoretical prediction based on the slope of the lift curve in this angle-of-attack range. The DDES results show much more complex flow patterns over the airfoil at these high angles of attack, although the spectral analysis of wall shear stress suggests the existence of flow structures having a similar spanwise length scale to the stall cells.}
}
@incollection{NAGURNEY1996335,
title = {Chapter 7 Parallel computation},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {1},
pages = {335-404},
year = {1996},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(96)01009-X},
url = {https://www.sciencedirect.com/science/article/pii/S157400219601009X},
author = {Anna Nagurney},
abstract = {Publisher Summary
Parallel computation represents not only a new mode of computation, but, a new intellectual paradigm. This chapter provides an overview of the technology of parallel computation in terms of hardware and programming languages; presents some of the fundamental classes of problems encountered in economics and the associated numerical methodologies for their solution; discusses the state-of-the-art computational techniques and focuses on parallel techniques and contrasts them with serial techniques for illumination and instructive purposes; and presents applications of the classes of problems and associated numerical methods to econometrics, microeconomics, macroeconomics, and finance. The emergence of computation as a basic scientific methodology in economics has given access to solutions of fundamental problems that pure analysis, observation, or experimentation could not have achieved. Parallel computation represents the wave of the future. It is considered to be cheaper and faster than serial computing and the only approach to faster computation currently foreseeable. Parallel computation is appealing, hence, for the economies of scale that are possible, for the potentially faster solution of large-scale problems, and also for the possibilities that it presents for imitating adjustment or tatonnement processes.}
}
@article{SCHMID2022,
title = {Mendelian or Multifactorial? Current Undergraduate Genetics Assessments Focus on Genes and Rarely Include the Environment},
journal = {Journal of Microbiology & Biology Education},
volume = {23},
number = {3},
year = {2022},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00093-22},
url = {https://www.sciencedirect.com/science/article/pii/S1935787722000302},
author = {Kelly M. Schmid and Dennis Lee and Monica Weindling and Awais Syed and Stephanie-Louise Yacoba Agyemang and Brian Donovan and Gregory Radick and Michelle K. Smith and L. Kate Wright},
keywords = {assessment, curriculum, environment, genes, genetics, undergraduate},
abstract = {Undergraduate genetics courses have historically focused on simple genetic models, rather than taking a more multifactorial approach where students explore how traits are influenced by a combination of genes, the environment, and gene-by-environment interactions. While a focus on simple genetic models can provide straightforward examples to promote student learning, they do not match the current scientific understanding and can result in deterministic thinking among students.
ABSTRACT
Undergraduate genetics courses have historically focused on simple genetic models, rather than taking a more multifactorial approach where students explore how traits are influenced by a combination of genes, the environment, and gene-by-environment interactions. While a focus on simple genetic models can provide straightforward examples to promote student learning, they do not match the current scientific understanding and can result in deterministic thinking among students. In addition, undergraduates are often interested in complex human traits that are influenced by the environment, and national curriculum standards include learning objectives that focus on multifactorial concepts. This research aims to discover to what extent multifactorial genetics is currently being assessed in undergraduate genetics courses. To address this, we analyzed over 1,000 assessment questions from a commonly used undergraduate genetics textbook; published concept assessments; and open-source, peer-reviewed curriculum materials. Our findings show that current genetics assessment questions overwhelmingly emphasize the impact of genes on phenotypes and that the effect of the environment is rarely addressed. These results indicate a need for the inclusion of more multifactorial genetics concepts, and we suggest ways to introduce them into undergraduate courses.}
}
@article{DEBER200449,
title = {Medical savings accounts in a universal system: wishful thinking meets evidence},
journal = {Health Policy},
volume = {70},
number = {1},
pages = {49-66},
year = {2004},
issn = {0168-8510},
doi = {https://doi.org/10.1016/j.healthpol.2004.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168851004000119},
author = {Raisa B Deber and Evelyn L Forget and Leslie L Roos},
keywords = {Medical savings accounts, Canada, Health care financing, Distribution of expenditures},
abstract = {Medical savings accounts (MSAs) and similar approaches based on flowing reimbursements through individuals/consumers rather than providers are unsuited for systems with universal coverage. Data from Manitoba, Canada reveal that, because expenditures for physician and hospital services are highly skewed in all age groups, MSAs would substantially increase both public expenditures and out-of-pocket costs for the most ill. The empirical distribution of health expenditures limits the potential impact of many current ‘demand-based’ approaches to cost control. Because most of the population is relatively healthy and uses few hospital and physician services, inducing the general population to spend less will not yield substantial savings.}
}
@article{SAIDI20091467,
title = {PLR-based heuristic for backup path computation in MPLS networks},
journal = {Computer Networks},
volume = {53},
number = {9},
pages = {1467-1479},
year = {2009},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2009.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389128609000292},
author = {Mohand Yazid Saidi and Bernard Cousin and Jean-Louis {Le Roux}},
keywords = {Recovery, Local protection, Backup LSP, Failure risk, SRLG, MPLS, Bandwidth sharing, Path computation, Network},
abstract = {To ensure service continuity in networks, local protection pre-configuring the backup paths is preferred to global protection. Under the practical hypothesis of single physical failures in the network, the backup paths which protect against different logical failure risks (node, link and shared risk link group (SRLG)) cannot be active at the same time. Thus, sharing bandwidth between such backup paths is crucial to increase the bandwidth availability. In this article, we focus on the optimal on-line distributed computation of the bandwidth-guaranteed backup paths in MPLS networks. As the requests for connection establishment and release arrive dynamically without knowledge of future arrivals, we choose to use the on-line mode to avoid LSP reconfigurations. We also selected a distributed computation to offer scalability and decrease the LSP setup time. Finally, the optimization of bandwidth utilization can be achieved thanks to the flexibility of the path choice offered by MPLS and to the bandwidth sharing. For a good bandwidth sharing, the backup path computation entities (BPCEs) require the knowledge and maintenance of a great quantity of bandwidth information (e.g. non aggregated link information or per path information) which is undesirable in distributed environments. To get around this problem, we propose here a PLR (point of local repair)-based heuristic (PLRH) which aggregates and noticeably decreases the size of the bandwidth information advertised in the network while offering a high bandwidth sharing. PLRH permits an efficient computation of backup paths. It is scalable, easy to be deployed and balances equitably computations on the network nodes. Simulations show that with the transmission of a small quantity of aggregated information per link, the ratio of rejected backup paths is low and close to the optimum.}
}
@article{MILOVANOVIC2021101044,
title = {Characterization of concept generation for engineering design through temporal brain network analysis},
journal = {Design Studies},
volume = {76},
pages = {101044},
year = {2021},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2021.101044},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X21000557},
author = {Julie Milovanovic and Mo Hu and Tripp Shealy and John Gero},
keywords = {design cognition, design process, problem solving, conceptual design, design neurocognition},
abstract = {This research explores the effect of the structuredness of design concept generation techniques on temporal network neurocognition. Engineering graduate students (n = 30) completed three concept generation tasks using techniques with different levels of structuredness: brainstorming, morphological analysis, and TRIZ. Students’ brain activation in their prefrontal cortex (PFC) was measured using functional near-infrared spectroscopy (fNIRS). The temporal dynamic of central regions in brain networks were compared between tasks. Central regions facilitate functional interaction and imply information flow through the brain. A consistent central region appears in the medial PFC. Consistent network connections occurred across both hemispheres suggesting a concurrent dual processing of divergent and convergent thinking. This study offers novel insights into the underlying neurophysiological mechanism when using these concept generation techniques.}
}
@article{BALAHUR20141,
title = {Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications},
journal = {Computer Speech & Language},
volume = {28},
number = {1},
pages = {1-6},
year = {2014},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2013.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885230813000697},
author = {Alexandra Balahur and Rada Mihalcea and Andrés Montoyo},
keywords = {Subjectivity analysis, Sentiment analysis, Multilingual resources, Social Media mining, Chat analysis},
abstract = {Recent years have witnessed a surge of interest in computational methods for affect, ranging from opinion mining, to subjectivity detection, to sentiment and emotion analysis. This article presents a brief overview of the latest trends in the field and describes the manner in which the articles contained in the special issue contribute to the advancement of the area. Finally, we comment on the current challenges and envisaged developments of the subjectivity and sentiment analysis fields, as well as their application to other Natural Language Processing tasks and related domains.}
}
@article{KUO2010307,
title = {Conceptual study of micro-tab device in airframe noise reduction: (I) 2D computation},
journal = {Aerospace Science and Technology},
volume = {14},
number = {5},
pages = {307-315},
year = {2010},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1270963810000210},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift device, Micro-tab, Airframe noise},
abstract = {A two-dimensional numerical study was performed to investigate the acoustic effects of micro-tab device on airframe noise reduction. As the noise generated by leading-edge slat and trailing-edge flap rise with their increased deflection angles, it is possible to mitigate such high-lift noise by using reduced settings without sacrificing the aerodynamic performance during approach. In this paper, micro-tab device attached to the pressure side of the flap surface is envisioned as a mean to achieve this goal. Hybrid method involving Computational Fluid Dynamics and acoustic analogy was used to predict the far-field noise spectrum. Results illustrate that the micro-tab device with reduced deflection angles of the high-lift settings provides lower noise signature at far-field positions, comparing to the baseline configuration, while the aerodynamic performance is maintained. In addition, two parametric studies which investigated the effects of micro-tab location and micro-tab height on acoustic spectra were also included.}
}
@article{CORBIN2023100645,
title = {A comparison of linguistic patterns between individuals with current major depressive disorder, past major depressive disorder, and controls in a virtual, psychiatric research interview},
journal = {Journal of Affective Disorders Reports},
volume = {14},
pages = {100645},
year = {2023},
issn = {2666-9153},
doi = {https://doi.org/10.1016/j.jadr.2023.100645},
url = {https://www.sciencedirect.com/science/article/pii/S266691532300183X},
author = {Lisette Corbin and Emily Griner and Salman Seyedi and Zifan Jiang and Kailey Roberts and Mina Boazak and Ali {Bahrami Rad} and Gari D. Clifford and Robert O. Cotes},
keywords = {Depression, LIWC, Psychiatric interview, Computational linguistics},
abstract = {Major Depressive Disorder (MDD) is a leading health burden worldwide. Previous research has demonstrated that linguistic analysis of depressed individuals’ written and oral speech has potential as a diagnostic and monitoring biomarker. We sought to determine if the semantic content of speech differs between individuals with current MDD, past MDD, and controls. We recruited 53 volunteers for a simulated telehealth psychiatric intake interview. The sample included 14 individuals with current MDD, 21 with past MDD, and 18controls, all confirmed using a semi-structured diagnostic interview. The manually-transcribed interview transcripts were analyzed utilizing the LIWC-22 dictionary and statistical tests were applied to identify differences in the linguistic patterns between each clinical categorization. When comparing depressed subjects (either current or past) versus controls, significant differences were found for emotional tone, total function words, auxiliary verbs, negative tone, negative emotion, anxiety, sadness, attention, and visual. Individuals with past MDD only differed from those with current MDD in use of analytical thinking and auxiliary verbs. These results indicate that LIWC categories could differentiate current or past depressed subjects from controls, but fewer differences emerged when comparing current and past MDD. Further prospective studies with larger sample sizes are needed to confirm these findings.}
}
@article{LONG201855,
title = {Data-driven decision making for supply chain networks with agent-based computational experiment},
journal = {Knowledge-Based Systems},
volume = {141},
pages = {55-66},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117305294},
author = {Qingqi Long},
keywords = {Data-driven decision making, Supply chain network, Business analytics, Data-granularity model, Four-dimensional-flow model, Agent-based computational experiment},
abstract = {The complicated micro structures, macro emergences and dynamic evolutions in a supply chain network pose challenges to decision making for solving operational problems for the network's performance improvement. Most of these problems are complicated since various factors and their complicated relationships are involved. Success of this decision making relies on efficient business analytics based on the comprehensive and multi-dimensional data related to the static attributes and dynamic operations of the network. To confront the challenges, this paper proposes to explore a methodology of data-driven decision making for supply chain networks. In this methodology, a data-granularity model of a supply chain network is developed to standardize the data form for decision making. A four-dimensional-flow model of a supply chain network is proposed to satisfy the data requirements for decision making that are defined in the data-granularity model. Agent-based computational experiment is employed to support the generation of a comprehensive operational dataset of a supply chain network and to verify the solutions generated in decision making. Integrating these models, a data-driven decision-making framework for supply chain networks is proposed. In the framework, a new decision-making mode of “problem definition - business analytics - solution verification - parameter adjustment” is proposed. Oriented towards domain knowledge in supply chain networks, two approaches of business analytics—mapping analysis and correlation analysis—are presented. Finally, a case of a five-echelon manufacturing supply chain network is studied with the methodology. The findings indicate that the proposed methodology, models and framework are effective in supporting the data-centric decision making for solving complicated operational problems in supply chain networks and provide the networks’ managers or member enterprises with an effective tool to generate unbiased and efficient decisions for the networks’ performance improvement.}
}
@incollection{HOUQUN2016155,
title = {Chapter 8 - Research on parallel computation of high arch dam structure seismic motion response},
editor = {Chen Houqun and Wu Shengxin and Dang Faning},
booktitle = {Seismic Safety of High Arch Dams},
publisher = {Academic Press},
address = {Oxford},
pages = {155-205},
year = {2016},
isbn = {978-0-12-803628-0},
doi = {https://doi.org/10.1016/B978-0-12-803628-0.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128036280000082},
author = {Chen Houqun and Wu Shengxin and Dang Faning},
keywords = {seismic response analysis, high arch dam, high-performance parallel computation, component technique, technique of automatically generating programs, FEPG and PFEPG computation programs},
abstract = {The storage capacity and the computation time of dynamic analysis for seismic responses of high concrete arch dam systems are enormous. As a matter of course, the use of high-performance parallel computation for seismic analysis of high-concrete dams must be enforced. The significance and current situation of parallel computation for hydraulic structures using finite element method are briefly described. However, the more difficult task is to develop a parallel program. The EFPG is a finite element program generator using finite element language developed by Chinese Professor Liang Guoping in 1990. The program generated by FEPG can be automatically transformed to corresponding parallel program through the program PFEPG. The parallel computational program by means of FEPG and PFEPG applied in this stage to dynamic analysis for seismic responses of high concrete arch dam system is outlined. The strategy of FEPG is based on component technique and the technique of automatically generating programs. According to the characteristics of domain decomposition method, a finite element program can generally be decomposed to six modules as preprocess partition, start, bft, solv, E, and U programs, in which the subroutines of E and U component are generated by the system based on the scripts VDE or PDE of the partial differential equation describing the physical fields and the corresponding computational algorithms (NFE), other else components are fixed and provided by the FEPG Library. The structures and modules as well as the working operation of FEPG and PFEPG are briefly introduced. The parallel program developed for seismic response analysis of high arch dam by using the FEPG and PFEPG, including the corresponding treatments of dynamic explicit computation process, dynamic contact problem, artificial transmitting, and spring-viscous boundaries, are examined in slight details. The procedure of seismic analysis of arch dam includes three loading cases accomplished successively as follows:1.In case 1, the dam elements were treated as dead elements with zero degree of freedom for nodes, and only the dead load of the foundation rock is considered in the analysis. At the end of calculation, the initial normal compressive force along the contact planes was modified by adding the calculated contact force. All other states of the foundation were recovered to that before loading.2.In case 2, the dead load of dam and other static actions including water pressure, silt pressure, and temperature applied to the dam as well as the seepage pressure in the foundation are considered.3.In case 3, a three-component seismic input is applied to the base of the artificial transmitting boundaries in form of displacement ground motion, or to the spring-viscous boundaries with free field input including boundary stresses, velocities and displacements. In this loading case, the rate effect for dynamic strength and modulus of elasticity are considered.}
}
@article{MA2024103893,
title = {Secure outsourced decryption for FHE-based privacy-preserving cloud computing},
journal = {Journal of Information Security and Applications},
volume = {86},
pages = {103893},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103893},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624001959},
author = {Xirong Ma and Chuan Li and Yuchang Hu and Yunting Tao and Yali Jiang and Yanbin Li and Fanyu Kong and Chunpeng Ge},
keywords = {Privacy-preserving computation, Outsourced computing, Homomorphic encryption},
abstract = {The demand for processing vast volumes of data has surged dramatically due to the advancement of machine learning technology. Large-scale data processing necessitates substantial computational resources, prompting individuals and enterprises to turn to cloud services. Accompanying this trend is a growing concern regarding data leakage and misuse. Homomorphic encryption (HE) is one solution for safeguarding data privacy, enabling encrypted data to be processed securely in the cloud. However, the encryption and decryption routines of some HE schemes require considerable computational resources, presenting non-trivial work for clients. In this paper, we propose an outsourced decryption protocol for the prevailing RLWE-based fully homomorphic encryption schemes. The protocol splits the original decryption into two routines, with the computationally intensive part executed remotely by the cloud. Its security relies on an invariant of the NTRU-search problem with a newly designed blinding key distribution. Cryptographic analyses are conducted to configure protocol parameters across varying security levels. Our experiments demonstrate that the proposed protocol achieves up to a 67% acceleration in the client-side computation, accompanied by a 50% reduction in space usage.}
}
@article{RONEZRA2021100896,
title = {Engaging a third-grade student with autism spectrum disorder in an error finding activity},
journal = {The Journal of Mathematical Behavior},
volume = {63},
pages = {100896},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100896},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000572},
author = {Maya Ron-Ezra and Esther S. Levenson},
keywords = {Autism spectrum disorder, Two-digit addition, Error analysis, Mathematical explanations},
abstract = {This paper describes a case study of one mainstreamed third grade student with autism spectrum disorder (ASD) and his ability to explain his solutions for two-digit addition problems, and find and explain the mistake when presented with incorrectly solved addition problems. The study is presented as a counterexample to deficit views of ASD, views that focus on lack of communication skills, not being able to see someone else’s point of view, and poor executive functions. Each encounter with the student is analyzed in two ways, first analyzing his mathematical knowledge, and then analyzing obstacles the student faces that are associated with ASD. Some obstacles are overcome by the student on his own and others are overcome with the help of the researcher, who responds to the student’s thinking, and supports his endeavor to engage with a challenging activity.}
}
@article{KISS2020106823,
title = {Process systems engineering developments in Europe from an industrial and academic perspective},
journal = {Computers & Chemical Engineering},
volume = {138},
pages = {106823},
year = {2020},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2020.106823},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420303069},
author = {Anton A. Kiss and Johan Grievink},
keywords = {Process systems engineering, Industry, Education, Research, Interface, Perspectives},
abstract = {Process Systems Engineering (PSE) is a discipline that deals with decision-making, at all levels and scales, by understanding any complex process system using a holistic view and a systems thinking framework. A closely related discipline (considered usually a part of PSE) is the Computer Aided Process Engineering (CAPE) which is a complementary field that focuses on developing methods and providing solution through systematic computer aided techniques for problems related to the design, control and operation of chemical systems. Nowadays, the ‘PSE’ term suffers from a branding issue to the point that PSE no longer gets the recognition that it deserves. In chemical engineering education the integrative systems frame for process design, control and operations is virtually absent. Its application potential in process industry lags relative to academic research progress and results. This work aims to provide an informative industrial and academic perspective on PSE (focused on the European region), arguing that the ‘systems thinking’ and ‘systems problem solving’ have to be given priority over just applications of computational problem solving methods. A multi-level view of the PSE field is provided within the academic and industrial context, and enhancements for PSE are suggested at their industrial and academic interfaces to create win-win situations.}
}
@article{HAMALAINEN2024100050,
title = {Generating policy alternatives for decision making: A process model, behavioural issues, and an experiment},
journal = {EURO Journal on Decision Processes},
volume = {12},
pages = {100050},
year = {2024},
issn = {2193-9438},
doi = {https://doi.org/10.1016/j.ejdp.2024.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2193943824000062},
author = {Raimo P. Hämäläinen and Tuomas J. Lahtinen and Kai Virtanen},
keywords = {Policy decision, Generation of policy alternatives, Portfolio decision analysis, Path dependence, Cognitive biases and heuristics},
abstract = {The generation of alternative policies is essential in complex decision tasks with multiple interests and stakeholders. A diverse set of policies is typically desirable to cover the range of options and objectives. Decision modelling literature has often assumed that clearly defined decision alternatives are readily available. This is not a realistic assumption in practice. We present a structured process model for the generation of policy alternatives in settings that include non-quantifiable elements and where portfolio optimisation approaches are not applicable. Behavioural issues and path dependence as well as heuristics and biases which can occur during the process are discussed. The behavioural experiment compares policy alternatives obtained by using two different portfolio generation techniques. The results of the experiment demonstrate that path dependence can occur in policy generation. We report thinking patterns of subjects which relate to biases and heuristics.}
}
@article{TARIM2011563,
title = {An efficient computational method for a stochastic dynamic lot-sizing problem under service-level constraints},
journal = {European Journal of Operational Research},
volume = {215},
number = {3},
pages = {563-571},
year = {2011},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711005637},
author = {S. Armagan Tarim and Mustafa K. Dogˇru and Ulaş Özen and Roberto Rossi},
keywords = {Inventory, Relaxation, Stochastic non-stationary demand, Mixed integer programming, Service level, Static–dynamic uncertainty},
abstract = {We provide an efficient computational approach to solve the mixed integer programming (MIP) model developed by Tarim and Kingsman [8] for solving a stochastic lot-sizing problem with service level constraints under the static–dynamic uncertainty strategy. The effectiveness of the proposed method hinges on three novelties: (i) the proposed relaxation is computationally efficient and provides an optimal solution most of the time, (ii) if the relaxation produces an infeasible solution, then this solution yields a tight lower bound for the optimal cost, and (iii) it can be modified easily to obtain a feasible solution, which yields an upper bound. In case of infeasibility, the relaxation approach is implemented at each node of the search tree in a branch-and-bound procedure to efficiently search for an optimal solution. Extensive numerical tests show that our method dominates the MIP solution approach and can handle real-life size problems in trivial time.}
}
@article{ALPUENTE20153,
title = {Exploring conditional rewriting logic computations},
journal = {Journal of Symbolic Computation},
volume = {69},
pages = {3-39},
year = {2015},
note = {Symbolic Computation in Software Science},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2014.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0747717114000960},
author = {M. Alpuente and D. Ballis and F. Frechina and J. Sapiña},
keywords = {Rewriting logic, Trace exploration, Maude, Conditional rewrite theories},
abstract = {Trace exploration is concerned with techniques that allow computation traces to be dynamically searched for specific contents. Depending on whether the exploration is carried backward or forward, trace exploration techniques allow provenance tracking or impact tracking to be done. The aim of provenance tracking is to show how (parts of) a program output depends on (parts of) its input and to help estimate which input data need to be modified to accomplish a change in the outcome. The aim of impact tracking is to identify the scope and potential consequences of changing the program input. Rewriting Logic (RWL) is a logic of change that supplements (an extension of) the equational logic by adding rewrite rules that are used to describe (nondeterministic) transitions between states. In this paper, we present a rich and highly dynamic, parameterized technique for the forward inspection of RWL computations that allows the nondeterministic execution of a given conditional rewrite theory to be followed up in different ways. With this technique, an analyst can browse, slice, filter, or search the traces as they come to life during the program execution. The navigation of the trace is driven by a user-defined, inspection criterion that specifies the required exploration mode. By selecting different inspection criteria, one can automatically derive a family of practical algorithms such as program steppers and more sophisticated dynamic trace slicers that compute summaries of the computation tree, thereby facilitating the dynamic detection of control and data dependencies across the tree. Our methodology, which is implemented in the Anima graphical tool, allows users to evaluate the effects of a given statement or instruction in isolation, track input change impact, and gain insight into program behavior (or misbehavior).}
}
@article{CSILLERY2010410,
title = {Approximate Bayesian Computation (ABC) in practice},
journal = {Trends in Ecology & Evolution},
volume = {25},
number = {7},
pages = {410-418},
year = {2010},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169534710000662},
author = {Katalin Csilléry and Michael G.B. Blum and Oscar E. Gaggiotti and Olivier François},
abstract = {Understanding the forces that influence natural variation within and among populations has been a major objective of evolutionary biologists for decades. Motivated by the growth in computational power and data complexity, modern approaches to this question make intensive use of simulation methods. Approximate Bayesian Computation (ABC) is one of these methods. Here we review the foundations of ABC, its recent algorithmic developments, and its applications in evolutionary biology and ecology. We argue that the use of ABC should incorporate all aspects of Bayesian data analysis: formulation, fitting, and improvement of a model. ABC can be a powerful tool to make inferences with complex models if these principles are carefully applied.}
}
@article{SCHERER2020106349,
title = {A meta-analysis of teaching and learning computer programming: Effective instructional approaches and conditions},
journal = {Computers in Human Behavior},
volume = {109},
pages = {106349},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106349},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220301023},
author = {Ronny Scherer and Fazilat Siddiq and Bárbara {Sánchez Viveros}},
keywords = {Computational thinking, Computer programming, Intervention studies, Multilevel meta-analysis, Scratch programming},
abstract = {This meta-analysis maps the evidence on the effectiveness of instructional approaches and conditions for learning computer programming under three study conditions: (a) Studies focusing on the effectiveness of programming interventions per se, (b) studies focusing on the effectiveness of visualization and physicality, and (c) studies focusing on the effectiveness of dominant instructional approaches. Utilizing the data from 139 interventions and 375 effect sizes, we found (a) a strong effect of learning computer programming per se (Hedges’ g‾ = 0.81, 95% CI [0.42, 1.21]), (b) moderate to large effect sizes of visualization (g‾ = 0.44, 95% CI [0.29, 0.58]) and physicality interventions (g‾ = 0.72, 95% CI [0.23, 1.21]), and (c) moderate to large effect sizes for studies focusing on dominant instructional approaches (g‾s = 0.49–1.02). Moderator analyses indicated that the effect sizes differed only marginally between the instructional approaches and conditions—however, collaboration in metacognition instruction, problem solving instruction outside of regular lessons, short-term interventions focusing on physicality, and interventions focusing on visualization through Scratch were especially effective. Our meta-analysis synthesizes the existing research evidence on the effectiveness of computer programming instruction and, ultimately, provides references with which the effects of future studies could be compared.}
}
@article{ARLE2014642,
title = {Mechanism of Dorsal Column Stimulation to Treat Neuropathic but not Nociceptive Pain: Analysis With a Computational Model},
journal = {Neuromodulation: Technology at the Neural Interface},
volume = {17},
number = {7},
pages = {642-655},
year = {2014},
issn = {1094-7159},
doi = {https://doi.org/10.1111/ner.12178},
url = {https://www.sciencedirect.com/science/article/pii/S1094715914601410},
author = {Jeffrey E. Arle and Kristen W. Carlson and Longzhi Mei and Nicolae Iftimia and Jay L. Shils},
keywords = {Chronic pain, dorsal column stimulation, gate control theory of pain, neural circuitry modeling, neuromodulation mechanism, neuropathic pain, spinal cord stimulation},
abstract = {Objective:
Stimulation of axons within the dorsal columns of the human spinal cord has become a widely used therapy to treat refractory neuropathic pain. The mechanisms have yet to be fully elucidated and may even be contrary to standard “gate control theory.” Our hypothesis is that a computational model provides a plausible description of the mechanism by which dorsal column stimulation (DCS) inhibits wide dynamic range (WDR) cell output in a neuropathic model but not in a nociceptive pain model.
Materials and Methods:
We created a computational model of the human spinal cord involving approximately 360,000 individual neurons and dendritic processing of some 60 million synapses—the most elaborate dynamic computational model of the human spinal cord to date. Neuropathic and nociceptive “pain” signals were created by activating topographically isolated regions of excitatory interneurons and high-threshold nociceptive fiber inputs, driving analogous regions of WDR neurons. Dorsal column fiber activity was then added at clinically relevant levels (e.g., Aβ firing rate between 0 and 110 Hz by using a 210-μsec pulse width, 50–150 Hz frequency, at 1–3 V amplitude).
Results:
Analysis of the nociceptive pain, neuropathic pain, and modulated circuits shows that, in contradiction to gate control theory, 1) nociceptive and neuropathic pain signaling must be distinct, and 2) DCS neuromodulation predominantly affects the neuropathic signal only, inhibiting centrally sensitized pathological neuron groups and ultimately the WDR pain transmission cells.
Conclusion:
We offer a different set of necessary premises than gate control theory to explain neuropathic pain inhibition and the relative lack of nociceptive pain inhibition by using retrograde DCS. Hypotheses regarding not only the pain relief mechanisms of DCS were made but also regarding the circuitry of pain itself, both nociceptive and neuropathic. These hypotheses and further use of the model may lead to novel stimulation paradigms.}
}
@article{JI20074338,
title = {A fuzzy logic-based computational recognition-primed decision model},
journal = {Information Sciences},
volume = {177},
number = {20},
pages = {4338-4353},
year = {2007},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507001193},
author = {Yanqing Ji and R. Michael Massanari and Joel Ager and John Yen and Richard E. Miller and Hao Ying},
keywords = {Medical decision-making, Naturalistic decision-making, Recognition-primed decision model, Computational recognition-primed decision model, Experience-based reasoning, Adverse drug reactions, Fuzzy logic, Similarity measure},
abstract = {The recognition-primed decision (RPD) model is a primary naturalistic decision-making approach which seeks to explicitly recognize how human decision makers handle complex tasks and environment based on their experience. Motivated by the need for quantitative computer modeling and simulation of human decision processes in various application domains, including medicine, we have developed a general-purpose computational fuzzy RPD model that utilizes fuzzy sets, fuzzy rules, and fuzzy reasoning to represent, interpret, and compute imprecise and subjective information in every aspect of the model. Experiences acquired by solicitation with experts are stored in experience knowledge bases. New local and global similarity measures have been developed to identify the experience that is most applicable to the current situation in a specific decision-making context. Furthermore, an action evaluation strategy has been developed to select the workable course of action. The proposed fuzzy RPD model has been preliminarily validated by using it to calculate the extent of causality between a drug (Cisapride, withdrawn by the FDA from the market in 2000) and some of its adverse effects for 100 hypothetical patients. The simulated patients were created based on the profiles of over 1000 actual patients treated with the drug at our medical center before its withdrawal. The model validity was demonstrated by comparing the decisions made by the proposed model and those by two independent internists. The levels of agreement were established by the weighted Kappa statistic and the results suggested good to excellent agreement.}
}
@article{DORKO2023101036,
title = {Is it a function? Generalizing from single- to multivariable settings},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101036},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101036},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000068},
author = {Allison Dorko},
keywords = {Actor-oriented transfer, Generalization, Multivariable calculus, Functions of two variables, Multivariable functions},
abstract = {Generalizing is a hallmark of mathematical thinking. The term ‘generalization’ is used to mean both the process of generalizing and the product of that process. This paper reports on five calculus students’ generalizing activity and what they generalized about multivariable functions. The study makes two contributions. The first is a fine-grained, actor-oriented characterization of the ways undergraduates generalized. This adds to knowledge in two areas: the use of the actor-oriented perspective and generalization in advanced mathematics. The second contribution is the products of students’ generalizing: what they generalized about what it means for a multivariable relation to represent a function). This adds to the literature about student reasoning regarding multivariable topics by characterizing the powerful ways of reasoning students possess pre-instruction.}
}
@article{XUE2024100156,
title = {Conceptual frameworks for the integration of genetic and social epidemiology in complex diseases},
journal = {Global Epidemiology},
volume = {8},
pages = {100156},
year = {2024},
issn = {2590-1133},
doi = {https://doi.org/10.1016/j.gloepi.2024.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2590113324000221},
author = {Diane Xue and Anjum Hajat and Alison E. Fohner},
abstract = {Uncovering the root causes of complex diseases requires complex approaches, yet many studies continue to isolate the effects of genetic and social determinants of disease. Epidemiologic efforts that under-utilize genetic epidemiology methods and findings may lead to incomplete understanding of disease. Meanwhile, genetic epidemiology studies are often conducted without consideration of social and environmental context, limiting the public health impact of genomic discoveries. This divide endures despite shared goals and increases in interdisciplinary data due to a lack of shared theoretical frameworks and differing language. Here, we demonstrate that bridging epidemiological divides does not require entirely new ways of thinking. Existing social epidemiology frameworks including Ecosocial theory and Fundamental Cause Theory, can both be extended to incorporate principles from genetic epidemiology. We show that genetic epidemiology can strengthen, rather than detract from, efforts to understand the impact of social determinants of health. In addition to presenting theoretical synergies, we offer practical examples of how genetics can improve the public health impact of epidemiology studies across the field. Ultimately, we aim to provide a guiding framework for trainees and established epidemiologists to think about diseases and complex systems and foster more fruitful collaboration between genetic and traditional epidemiological disciplines.}
}
@article{AGGARWAL2023110458,
title = {Quantum healthcare computing using precision based granular approach},
journal = {Applied Soft Computing},
volume = {144},
pages = {110458},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110458},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623004763},
author = {Lakshita Aggarwal and Shelly Sachdeva and Puneet Goswami},
keywords = {Quantum computing, Qubits, Healthcare, Diagnosis, Classical computing, Precision},
abstract = {Previously, doctors interpreted diseases and their outcomes according to their experience in diagnosis. However, with the rapid increase in technology and population, the task of examining the patient becomes cumbersome and sometimes human efforts produce inconsistent results. Several research is being done for healthcare in terms of improving visualization and accuracy by using machine learning models. The current research targets to explore quantum computing as a different way of processing information compared to classical computer systems such as the use of quantum bits (qubits) along with superposition and entanglement for extending the computation capabilities at an unprecedented level of thinking in the healthcare domain. Quantum computing systems provide exponential benefits in terms of high-speed processing, faster and easier diagnostic assistance, unimaginable reduction in processing throughput, and many more. An extensive comparative analysis of existing approaches has been made which benchmarks the need for quantum healthcare computing. The objective of this work is to interpret whether Quantum computers prove to be more trusted when it comes to patient diagnosis, and faster analysis leading to cost optimization. In order to accelerate patient diagnosis, different approaches have been presented. The authors have proposed a precision-based granular approach for patient diagnosis that incorporates diagnosing the disease with enhanced precision and granularity. It involves reporting symptoms by the patient, encountering by healthcare expert on multiple factors, precise examination, granular health status (understanding past and present medical history), followed by a precise intervention by understanding biomolecular simulations. The algorithm has been presented to describe the flow process for patient diagnosis modeling using quantum computing. It involves qubits initialization, pairing the values, assigning probabilistic values, cross-validation, and quantum circuit formation. Precision-based granular approach has been implemented for a scenario (consisting of medical parameters such as oxygen and heart rate level, with the functionality of diagnosing oxygen level and heart range which lies as either normal or not normal (high/low)). Precision-based granular approach deals specifically with the individual ‘biomolecular simulation by understanding variations in the individual body whereas the umbrella-based approach does not deal with specifically to individual mechanisms. Granular level of encounter is not possible in umbrella-based treatment. Python Jupyter notebook and IBM Composer tool is used for the implementation of results. Bloch sphere and computational state graph are obtained as an output for better visualization and understanding. Falcon r5.11H processor is used with the version of 1.0.24 of IBM Composer to simulate the experiment. The methodology using precision based granular approach provides timely encounter of disease along with umbrella diagnosis and precise treatment. The time is taken and frequency of qubits have been presented with promising results. The diagnosis process and optimizing cost efficiency can aid in an early detection of the disease.}
}
@article{GANUTHULA2016216,
title = {Rationality and the reflective mind: A case for typical performance measure of cognitive ability},
journal = {Learning and Individual Differences},
volume = {49},
pages = {216-223},
year = {2016},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2016.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1041608016301029},
author = {Venkat Ram Reddy Ganuthula and Lata Dyaram},
keywords = {Typical performance measure of cognitive ability, Thinking dispositions, Rationality, Tripartite model of mind},
abstract = {Intelligence and cognitive abilities often denoted good thinking. However, critics of intelligence tests have long pointed out that the failures of rational judgments and decision-making imperfectly correlate with intelligence. Reviewing the work of Keith Stanovich and his colleagues, paper highlights the role of individual differences in judgment and decision-making. Paper presents a case for typical performance measure of cognitive ability besides thinking dispositions to explain variations in rational thought. Specifically, we examine and model the relationship between need for cognition (a measure of thinking dispositions), absorptive capacity (typical performance measure of intelligence) and normative decision-making tasks.}
}
@article{CARROLL1999111,
title = {Invented Computational Procedures of Students in a Standards-Based Curriculum},
journal = {The Journal of Mathematical Behavior},
volume = {18},
number = {2},
pages = {111-121},
year = {1999},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(99)00024-3},
url = {https://www.sciencedirect.com/science/article/pii/S0732312399000243},
author = {William M. Carroll},
abstract = {Fourth graders who had been in a standards-based elementary curriculum since kindergarten were individually interviewed and administered a whole-class test that probed their knowledge of facts and multidigit computation. Standard algorithms are not taught as part of the curriculum, which instead emphasizes student-invented procedures and discussions of solution methods. Of interest were the types of student-invented procedures that were used as well as their computational accuracy. Students used several procedures that involved sophisticated mental calculation strategies, such as decomposing numbers or adding from left to right. Many students also used the standard written algorithms. Both invented and standard algorithms used by the students were highly accurate, although invented procedures often indicated better mental flexibility and awareness of place value. On the written test, students' computational abilities were above national normative levels.}
}
@article{BOTTEGONI201223,
title = {The role of fragment-based and computational methods in polypharmacology},
journal = {Drug Discovery Today},
volume = {17},
number = {1},
pages = {23-34},
year = {2012},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1359644611002534},
author = {Giovanni Bottegoni and Angelo D. Favia and Maurizio Recanatini and Andrea Cavalli},
abstract = {Polypharmacology-based strategies are gaining increased attention as a novel approach to obtaining potentially innovative medicines for multifactorial diseases. However, some within the pharmaceutical community have resisted these strategies because they can be resource-hungry in the early stages of the drug discovery process. Here, we report on fragment-based and computational methods that might accelerate and optimize the discovery of multitarget drugs. In particular, we illustrate that fragment-based approaches can be particularly suited for polypharmacology, owing to the inherent promiscuous nature of fragments. In parallel, we explain how computer-assisted protocols can provide invaluable insights into how to unveil compounds theoretically able to bind to more than one protein. Furthermore, several pragmatic aspects related to the use of these approaches are covered, thus offering the reader practical insights on multitarget-oriented drug discovery projects.}
}
@article{BAR202135,
title = {Wanted: Architecture for changing minds: A comment on “The growth of cognition: Free energy minimization and the embryogenesis of cortical computation”},
journal = {Physics of Life Reviews},
volume = {36},
pages = {35-36},
year = {2021},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300683},
author = {Moshe Bar}
}
@article{LEOPOLD2024102913,
title = {The big mixup: Neural representation during natural modes of primate visual behavior},
journal = {Current Opinion in Neurobiology},
volume = {88},
pages = {102913},
year = {2024},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S0959438824000758},
author = {David A. Leopold},
abstract = {The primate brain has evolved specialized visual capacities to navigate complex physical and social environments. Researchers studying cortical circuits underlying these capacities have traditionally favored the use of simplified tasks and brief stimulus presentations in order to isolate cognitive variables with tight experimental control. As a result, operational theories about visual brain function have come to emphasize feature detection, hierarchical stimulus encoding, top-down task modulation, and functional segregation in distinct cortical areas. Recently, however, experimental paradigms combining natural behavior with electrophysiological recordings have begun to offer a distinctly different portrait of how the brain takes in and analyzes its visual surroundings. The present article reviews recent work in this area, highlighting some of the more surprising findings in domains of social vision and spatial navigation along with shifts in thinking that have begun to emanate from this approach.}
}
@article{CRAWFORD202180,
title = {Efficient mechanisms for level-k bilateral trading},
journal = {Games and Economic Behavior},
volume = {127},
pages = {80-101},
year = {2021},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2021.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0899825621000282},
author = {Vincent P. Crawford},
keywords = {Mechanism design, Bilateral trading, Level- thinking, Behavioral game theory},
abstract = {This paper revisits Myerson and Satterthwaite's (1983) classic analysis of mechanism design for bilateral trading, replacing equilibrium with a level-k model of strategic thinking and focusing on direct mechanisms. The revelation principle fails for level-k models, so restricting attention to direct mechanisms and imposing incentive-compatibility are not without loss of generality. If, however, only direct, level-k-incentive-compatible mechanisms are feasible and traders' levels are observable, Myerson and Satterthwaite's characterization of mechanisms that maximize traders' total surplus subject to incentive constraints generalizes qualitatively to level-k models. If only direct, level-k-incentive-compatible mechanisms are feasible but traders' levels are not observable, generically a particular posted-price mechanism maximizes traders' total expected surplus subject to incentive constraints. If direct, non-level-k-incentive-compatible mechanisms are feasible and traders best respond to them, total expected surplus-maximizing mechanisms may take completely different forms.}
}
@article{KARTHIK2024106286,
title = {Improving brain tumor treatment with better imaging and real-time therapy using quantum dots},
journal = {Biomedical Signal Processing and Control},
volume = {95},
pages = {106286},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106286},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424003446},
author = {A. Karthik and S. {Shiek Aalam} and M. Sivakumar and M.V. {Rama Sundari} and J. {Dafni Rose} and Muniyandy Elangovan and A. Rajaram},
keywords = {NIR- quantum dots, Magnetic resonance imaging, Radiotherapy, Brain Tumor},
abstract = {Recent advancements in medical imaging and therapeutic technologies have propelled innovative strategies in brain tumor treatment. This study introduces a comprehensive methodology merging Quantum Dots (QDs) and Real-Time Imaging-Guided Therapeutics (RIGT) to refine the precision of brain tumor radiotherapy. Focusing on the synthesis of near-infrared quantum dots (NIR-QDs), the study emphasizes the critical role of meticulous surface functionalization in achieving biocompatibility and stability. The methodology integrates 3D brain MRI images into the ingeniously devised Real-Time Imaging-Guided Therapeutics (RIGT) system, facilitating precise tumor localization and adaptive treatment protocol adjustments. Novel hybrid architecture is introduced for real-time MRI data analysis, enabling intricate tumor segmentation, feature extraction, localization, and synthetic image generation. This fusion of technologies, empowered by artificial intelligence, equips healthcare professionals with comprehensive insights into tumor intricacies and potential treatment outcomes. The proposed methodology's transformative objective seeks to redefine brain tumor treatment by seamlessly integrating advanced imaging modalities, cutting-edge nanotechnology, and AI-driven precision therapeutics. It envisions establishing a new paradigm in brain tumor treatment, promising heightened efficacy and minimized risks for patients. The study's numerical findings showcase the AI-powered image analysis capabilities of the Hybrid CNN-GAN network. Demonstrating superior performance in tumor segmentation, the results exhibit an Intersection over Union (IoU) of 0.89, Dice Coefficient of 0.95, F1-score of 0.94, and Structural Similarity Index (SSI) of 0.91. Additionally, computational efficiency is evident, with a short processing time of 65 ms and balanced CPU and GPU usage at 80 % and 90 %, respectively. In summary, this study presents an innovative methodology for brain tumor treatment, underpinned by exceptional numerical results validating its efficacy and computational efficiency.}
}
@article{BOND200481,
title = {A computational model for the primate neocortex based on its functional architecture},
journal = {Journal of Theoretical Biology},
volume = {227},
number = {1},
pages = {81-102},
year = {2004},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2003.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022519303003825},
author = {Alan H Bond},
keywords = {Brain architecture, Perception-action hierarchy, Computational model, Logic programming, Primate social behavior},
abstract = {Experimental evidence has shown that the primate neocortex consists in the main of a set of cortical regions which form a perception hierarchy, an action hierarchy and connections between them. By using a computer science analysis, we develop a computational architecture for the brain in which each cortical region is represented by a computational module with processing and storage abilities. Modules are interconnected according to the connectivity of the corresponding cortical regions. We develop computational principles for designing such a hierarchical and parallel computing system. We demonstrate this approach by proposing a causal functioning model of the brain. We report on results obtained with an implementation of this model. We conclude with a brief discussion of some consequences and predictions of our work.}
}
@article{WEBB2010903,
title = {Troubleshooting assessment: an authentic problem solving activity for it education},
journal = {Procedia - Social and Behavioral Sciences},
volume = {9},
pages = {903-907},
year = {2010},
note = {World Conference on Learning, Teaching and Administration Papers},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.256},
url = {https://www.sciencedirect.com/science/article/pii/S187704281002361X},
author = {David C. Webb},
keywords = {authentic assessment, computational thinking, computer programming, game design, problem solving, STEM education, technologybased assessment},
abstract = {To evaluate the effectiveness of an instructional unit for game design and computer programming, we designed an authentic assessment with five troubleshooting scenarios. This assessment was completed by 24 middle grades students (age 12 – 14 years) after 10hours of instruction using a visual programming environment. Students successfully completed most of the tasks in 45minutes. Results from the Troubleshooting Assessment demonstrated that students developed sufficient fluency with programming to be able to apply their knowledge to new problems. These results suggest that troubleshooting scenarios can be used to assess student fluency in computer programming and computer-based problem solving.}
}
@article{YILMAZ2023100005,
title = {Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100005},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Generative artificial intelligence, ChatGPT, Programming, Programming learning, Student opinions},
abstract = {With the diversification of generative artificial intelligence (AI) applications, the interest in their use in every segment and field of society in recent years has been increasing rapidly. One of these areas is programming learning and program writing processes. One of the generative AI tools used for this purpose is ChatGPT. The use of ChatGPT in program writing processes has become widespread, and this tool has a certain potential in the programming process. However, when the literature is examined, research results related to using ChatGPT for this purpose have yet to be found. The existing literature has a gap that requires exploration. This study aims to analyze the students' perspectives on using ChatGPT in the field of programming and programming learning. The study encompassed a cohort of 41 undergraduate students enrolled in a public university's Computer Technology and Information Systems department. The research was carried out within the scope of the Object-Oriented Programming II course for eight weeks. Throughout the research process, students were given project assignments related to the course every week, and they were asked to use ChatGPT while solving them. The research data was collected using a form consisting of open-ended questions and analyzed through content analysis. The research findings revealed both the advantages and disadvantages of ChatGPT usage, as perceived by the students. The students stated that the main benefits of using ChatGPT in programming learning are providing fast and mostly correct answers to questions, improving thinking skills, facilitating debugging, and increasing self-confidence. On the other hand, the main limitations of using ChatGPT in programming education were getting students used to laziness, being unable to answer some questions, or giving incomplete/incorrect answers, causing professional anxiety in students. Based on the results of the research, it can be said that it would be useful to integrate generative AI tools into programming courses considering the advantages they provide in programming teaching. However, appropriate measures should be taken regarding the limitations it brings. Based on the research findings, several recommendations were proposed regarding the integration of ChatGPT into lessons.}
}
@article{LITTLE20031285,
title = {The computational science major at SUNY Brockport},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1285-1292},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00086-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000864},
author = {Leigh J. Little},
keywords = {Computational science, Education, Undergraduate, Graduate},
abstract = {The field of computational science is a recent addition to academic study. While the content of such an education is generally agreed upon, effective methods for imparting this knowledge are still being investigated. This paper describes the current state of the computational science degree programs at SUNY Brockport and the successes that have been obtained. Issues relating to the implementation of such programs in the context of a small, liberal arts college are also discussed.}
}
@incollection{REIN2013199,
title = {Chapter 16 - Re-thinking Standardization for Interagency Information Sharing},
editor = {Babak Akhgar and Simeon Yates},
booktitle = {Strategic Intelligence Management},
publisher = {Butterworth-Heinemann},
pages = {199-211},
year = {2013},
isbn = {978-0-12-407191-9},
doi = {https://doi.org/10.1016/B978-0-12-407191-9.00016-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071919000168},
author = {Kellyn Rein},
keywords = {agencies, analysis, data, fusion, human, intelligence, language, management, national, security, sources, text},
abstract = {Abstracts:
The collection and analysis of data for intelligence purposes is vital to national security. There are a number of hurdles including the exponentially increasing volume of available data, the need for increased cooperation between national and international agencies due to the increasingly globalized nature of threats to citizens and nations, and the need to be flexible in identifying new threats. Increasing reliance on computers is necessary, but complications arise due to such issues as incompatible data formats, multiple natural languages, and data privacy concerns. However, a potential solution to solving some of these problems for national security and law enforcement agencies is C2LG (Command and Control Lexical Grammar), which was originally developed for use within NATO, and is being adapted for use in crisis management and the fight against international organized crime.}
}
@article{OLTETEANU201615,
title = {Object replacement and object composition in a creative cognitive system. Towards a computational solver of the Alternative Uses Test},
journal = {Cognitive Systems Research},
volume = {39},
pages = {15-32},
year = {2016},
note = {From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2015.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716000073},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Cognitive systems, Computational creativity, Creative object replacement, Creative object composition, Alternative uses test},
abstract = {In creative problem solving, humans perform object replacement and object composition to improvise tools in order to carry out tasks in everyday situations. In this paper, an approach to perform Object Replacement and Object Composition (OROC) inside a Creative Cognitive framework (CreaCogs) is proposed. Multi-feature correspondence is used to define similarity between objects in an everyday object domain. This enables the cognitive system OROC to perform creative replacement of objects and creative object composition. The generative properties of OROC are analysed and proof-of-concept experiments with OROC are reported. An evaluation of the results is carried out by human judges and compared to human performance in the Alternative Uses Test.}
}
@incollection{VASSILOPOULOS2020349,
title = {10 - Computational intelligence methods for the fatigue life modeling of composite materials},
editor = {Anastasios P. Vassilopoulos},
booktitle = {Fatigue Life Prediction of Composites and Composite Structures (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {349-383},
year = {2020},
series = {Woodhead Publishing Series in Composites Science and Engineering},
isbn = {978-0-08-102575-8},
doi = {https://doi.org/10.1016/B978-0-08-102575-8.00010-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780081025758000103},
author = {Anastasios P. Vassilopoulos and Efstratios F. Georgopoulos},
keywords = {Fatigue, Composites, Artificial neural network, Genetic programming, ANFIS, S-N curves},
abstract = {Novel computational methods such as artificial neural networks, adaptive neuro-fuzzy inference systems and genetic programming are used in this chapter for the modeling of the nonlinear behavior of composite laminates subjected to constant amplitude loading. The examined computational methods are stochastic nonlinear regression tools, and can therefore be used to model the fatigue behavior of any material, provided that sufficient data are available for training. They are material independent methods that simply follow the trend of the available data, in each case giving the best estimate of their behavior. Application on a wide range of experimental data gathered after fatigue testing glass/epoxy and glass/polyester laminates proved that their modeling ability compares favorably with, and is to some extent superior to, other modeling techniques.}
}
@article{TRUBA2024101496,
title = {Psycholinguistic underpinnings of image formation: Suggestion and manipulation in the educational network discourse},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101496},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000348},
author = {Hanna Truba and Sergii Khrapatyi and Kyrylo Harashchuk and Dmytro Shvets and Alina Proskurnia},
keywords = {Psycholinguistics, Image, Suggestion, Manipulation, Attraction, Fascination},
abstract = {This study delves into the intricate psycholinguistic mechanisms that underpin image formation within the educational network discourse, with a specific focus on the dynamics of suggestion and manipulation. In an era where digital communication reigns supreme, understanding how language shapes perceptions and influences behavior is paramount. This research seeks to unravel the complex interplay between suggestion, manipulation, and the formation of images within educational networks. Drawing from insights across disciplines such as psychology, linguistics, and communication studies, this study examines how linguistic cues and contextual factors interact to shape individuals' perceptions and responses within educational settings. Acknowledging the transformative power of language in shaping attitudes, beliefs, and actions, this study aims to shed light on the subtle yet profound ways in which educators employ linguistic strategies to influence discourse within educational networks. By employing a multifaceted approach that integrates theoretical frameworks with empirical analysis, this research endeavors to uncover the underlying mechanisms driving suggestion and manipulation within educational discourse. Through a meticulous examination of textual elements, discourse patterns, and communicative strategies employed by educators in digital environments, this study seeks to elucidate the intricate processes involved in image formation. By exploring the role of suggestion and manipulation in shaping perceptions, attitudes, and behaviors, this research contributes to a deeper understanding of the psycholinguistic underpinnings of educational network discourse. Furthermore, this study not only offers theoretical insights but also practical implications for educators, policymakers, and practitioners involved in educational communication. By highlighting the ethical considerations and implications of linguistic manipulation within educational networks, this research aims to empower stakeholders to navigate digital discourse with greater awareness and discernment. In conclusion, this study represents a significant contribution to the field of thinking skills and creativity by offering new insights into the psycholinguistic dynamics of image formation within educational networks. By unraveling the complexities of suggestion and manipulation, this research opens avenues for further inquiry and underscores the importance of critical thinking and creativity in navigating contemporary digital landscapes.}
}
@article{BRIMKOV2005233,
title = {Exact Image Reconstruction from a Single Projection through Real Computation},
journal = {Electronic Notes in Discrete Mathematics},
volume = {20},
pages = {233-246},
year = {2005},
note = {Proceedings of the Workshop on Discrete Tomography and its Applications},
issn = {1571-0653},
doi = {https://doi.org/10.1016/j.endm.2005.05.066},
url = {https://www.sciencedirect.com/science/article/pii/S1571065305050705},
author = {Valentin E. Brimkov and Reneta P. Barneva},
keywords = {Discrete tomography, Computed tomography, Algebraic computation model, Algebraic complexity, Linear Diophantine equation},
abstract = {In Discrete Tomography one aims to reconstruct a function (image) with a known discrete range from its projection along certain directions. By modern electron-microscopy techniques, one can count the number of atoms laying on a line representing, e.g., an X-ray. The so obtained data is used in the integer programming formulation. However, in real applications the size of the problem, that is well-known to be NP-hard, is so large that no method seems to be applicable to it. Other natural restrictions can make the problem even harder. In an attempt to avoid such kind of difficulties, we present an alternative approach to the problem. With this, we also aim to shed more light on the theoretical limitations for efficient computation in Discrete Tomography. Our approach is based on image reconstruction from a single projection, under the hypothesis that all computations take place in an algebraic computation model. In terms of computational efficiency, the proposed algorithm is significantly superior to the known algorithms for the problem. We also discuss on the possibilities for practical implementation of our method.}
}
@article{DELORME2019133,
title = {When the meditating mind wanders},
journal = {Current Opinion in Psychology},
volume = {28},
pages = {133-137},
year = {2019},
note = {Mindfulness},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X1830157X},
author = {Arnaud Delorme and Tracy Brandmeyer},
abstract = {The capacity for thought and the ability to assemble and manipulate concepts are cognitive features unique to humans. Spontaneous thoughts often occur when we are engaged in attention-demanding tasks, with an increased frequency predicting negative affect. Meditation does not require thinking; however, thinking occurs naturally during meditation. We develop the hypothesis that chronic thinking associated with strong emotional arousal during meditation practice might be detrimental to meditation practice and well-being. One goal of meditation is to identify the arousal of emotions and thoughts, and remain equanimous with them. Over time, meditation may help dampen the attention-grabbing power of these thoughts both during practice and in daily life, which may consequently help deepen meditation practice. However, when meditators fail to remain equanimous, the effects of these thoughts may be deleterious. We discuss how this hypothesis may help guide future research on meditation.}
}
@article{GOLDBERG2011171,
title = {Computational physiology of the neural networks of the primate globus pallidus: function and dysfunction},
journal = {Neuroscience},
volume = {198},
pages = {171-192},
year = {2011},
note = {Function and Dysfunction of the Basal Ganglia},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2011.08.068},
url = {https://www.sciencedirect.com/science/article/pii/S0306452211010268},
author = {J.A. Goldberg and H. Bergman},
keywords = {basal ganglia, primate, neurons, correlations, oscillations, Parkinson's disease},
abstract = {The dorsal pallidal complex is made up of the external and internal segments of the globus pallidus (GPe and GPi respectively). It is part of the main axis of the basal ganglia (BG) that connects the thalamo-cortical networks to the BG input stages (striatum and subthalamic nucleus) and continues directly, and indirectly through the GPe, to the BG output stages (GPi and substantia nigra reticulata). Here we review the unique anatomical and physiological features of the pallidal complex and argue that they support the main computational goal of the BG main axis (actor); namely, a behavioral policy that maximizes future cumulative gains and minimizes costs. The three mono-layer competitive networks of the BG main axis flexibly extract relevant features from the current state of the thalamo-cortical activity to control current (ongoing) and future actions. We hypothesize that the striatal and the subthalamic projections neurons act as mono-stable integrators (class I excitability) and the in-vivo pallidal neurons act as bi-stable resonators (class II excitability). GPe neurons exhibit pausing behavior because their membrane potential lingers in the vicinity of an unstable equilibrium point and bi-stability, and these pauses enable a less-greedy exploratory behavioral policy. Finally, degeneration of midbrain dopaminergic neurons and striatal dopamine depletion (as in Parkinson's disease) lead to augmentation of striatal excitability and competitive dynamics. As a consequence the pallidal network, whose elements tend to synchronize as a result of their bi-stable resonance behavior, shifts from a Poissonian-like non-correlated to synchronous oscillatory discharge mode. This article is part of a Special Issue entitled: Function and Dysfunction of the Basal Ganglia.}
}
@article{EKINS201165,
title = {Computational databases, pathway and cheminformatics tools for tuberculosis drug discovery},
journal = {Trends in Microbiology},
volume = {19},
number = {2},
pages = {65-74},
year = {2011},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X10001939},
author = {Sean Ekins and Joel S. Freundlich and Inhee Choi and Malabika Sarker and Carolyn Talcott},
abstract = {We are witnessing the growing menace of both increasing cases of drug-sensitive and drug-resistant Mycobacterium tuberculosis strains and the challenge to produce the first new tuberculosis (TB) drug in well over 40 years. The TB community, having invested in extensive high-throughput screening efforts, is faced with the question of how to optimally leverage these data to move from a hit to a lead to a clinical candidate and potentially, a new drug. Complementing this approach, yet conducted on a much smaller scale, cheminformatic techniques have been leveraged and are examined in this review. We suggest that these computational approaches should be optimally integrated within a workflow with experimental approaches to accelerate TB drug discovery.}
}
@article{BLOOM2001453,
title = {Novel thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {10},
pages = {453-454},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01758-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300017587},
author = {Paul Bloom}
}
@incollection{ZOHURI202225,
title = {Chapter 2 - A general approach to business resilience system (BRS)},
editor = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
booktitle = {Knowledge is Power in Four Dimensions: Models to Forecast Future Paradigm},
publisher = {Academic Press},
pages = {25-57},
year = {2022},
isbn = {978-0-323-95112-8},
doi = {https://doi.org/10.1016/B978-0-323-95112-8.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323951128000039},
author = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
keywords = {Artificial intelligence, Data analysis and information, Market and market share, Predictive analytics, Super artificial intelligence},
abstract = {The business resilience system (BRS) with its risk atom and processing data point is based on fuzzy logic and cloud computation in real time. Its purpose and objectives define a clear set of expectations for organizations and enterprises, so their network system and supply chain are totally resilient and protected against cyberattacks, man-made threats, and natural disasters. These enterprises include financial, organizational, homeland security, and supply chain operations with multipoint manufacturing across the world. Market share and marketing advantages are expected to result from the implementation of the system. The collected information and defined objectives provide the basis to monitor and analyze the data through cloud computation and will guarantee the success of their survivability against any unexpected threats. Putting this kind of operation in place allows the executive and stakeholders within those organizations and enterprises to make the right decision when encountering threats that interrupt their normal day-to-day operations, as well as, in cases such as defense and homeland security, to predict the next move of an adversary. Given the fact that the BRS, as part of its functionality, processes the incoming data and information if not real time, then near real time with the help of superartificial intelligence in place, this gives the stakeholder an edge against and threats as well as predicting issues with operational intelligence. Artificial intelligence (AI) is one of those technologies that seem to be expanding in every direction. This technology will take center stage at Think 2018. Resilience thinking is inevitably systems thinking, at least as much as sustainable development is. In fact, “when considering systems of humans and nature (social-ecological systems), it is important to consider the system as a whole.” The term “resilience” originated in the 1970s in the field of ecology from the research of C.S. Holling, who defined resilience as “a measure of the persistence of systems and of their ability to absorb change and disturbance and still maintain the same relationships between populations or state variables.” In short, resilience is best defined as “the ability of a system to absorb disturbances and still retain its basic function and structure.” In this chapter, we explain the BRS and how it works. Please note that the with minor editing and manipulation, the materials presented in this chapter have been borrowed from the book published from Zohuri and Moghaddam10 with permission from both authors and publisher as well.}
}
@article{IWENDI20225016,
title = {Combined power generation and electricity storage device using deep learning and internet of things technologies},
journal = {Energy Reports},
volume = {8},
pages = {5016-5025},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2022.02.304},
url = {https://www.sciencedirect.com/science/article/pii/S2352484722005510},
author = {Celestine Iwendi and Gai-Ge Wang},
keywords = {Energy storage, Machine learning, Internet of things, Fuzzy logic, Electricity storage device, Power generation},
abstract = {In microgrids, residential customers play a significant part in the operation. An alternative to client administration should be to utilize smart houses to deal with demand and implement demand responsiveness measures. A power generation and electricity storage device (PGESD) for next-generation technologies is proposed in this article. The current research provides an intelligent home load control system that promotes reaction to demand thinking about this circumstance. The technology is adapted to scenarios where users can charge fluctuating electric power and transmit microgeneration devices. The suggested system utilizes deep learning technology and a fuzzy logic model for better computation and lesser complexity. The choice process involves monitoring environmental information, power production, and battery storage. This article proposes a next-generation power generation and electricity storage device (PGESD). To create Smart Buildings and Microgrids, the proposed system employs technologies and techniques that have become increasingly important. With a precision and accuracy ratio of 89% and 92%, respectively, the proposed PGESD method yields precise numerical results.}
}
@incollection{HOUSE2018335,
title = {Chapter 14 - Comments on Computational Methods},
editor = {J.E. House},
booktitle = {Fundamentals of Quantum Mechanics (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {335-347},
year = {2018},
isbn = {978-0-12-809242-2},
doi = {https://doi.org/10.1016/B978-0-12-809242-2.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092422000140},
author = {J.E. House},
keywords = {Basis set, Slater-type orbitals, Gaussian orbitals, Extended Hückel, Wolfsberg-Helmoltz approximation, Ballhausen-Gray approximation, Cusachs' approximation, Self-consistent field, Density functional theory},
abstract = {There are numerous types of molecular orbital calculations that are routinely performed. One of the early versions is the extended Hückel method that begins with the approach used in the Hückel method, but with the overlap and exchange integrals (approximated by the Wolfsberg-Helmholtz, Ballhausen-Gray, or Cusachs' method) included. A more robust type of calculation is that in which an electron is presumed to move in a field generated by the nucleus and other electrons. A trial wave function with some adjustable parameter(s) is taken, and the energy calculated. The wave function improves and the calculations continue until there is no additional improvement (i.e., a “self-consistent field” has been obtained). There are numerous variations of this approach that differ in the trial wave function chosen, extent of electron-electron interaction included, etc. Density functional theory is a newer approach that uses less computational capacity. These types of molecular orbital calculations are surveyed briefly in this chapter.}
}
@article{ZHANG2022116187,
title = {Tri-level attribute reduction in rough set theory},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116187},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116187},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015050},
author = {Xianyong Zhang and Yiyu Yao},
keywords = {Attribute reduction, Three-way decision, Tri-level analysis, Object-specific attribute reducts, Tri-level attribute reducts, Granular computing},
abstract = {Attribute reduction serves as a pivotal topic of rough set theory for data analysis. The ideas of tri-level thinking from three-way decision can shed new light on three-level attribute reduction. Existing classification-specific and class-specific attribute reducts consider only macro-top and meso-middle levels. This paper introduces a micro-bottom level of object-specific reducts. The existing two types of reducts apply to the global classification with all objects and a local class with partial objects, respectively. The new type applies to an individual object. These three types of reducts constitute tri-level attribute reducts. Their development and hierarchy are worthy of systematical explorations. Firstly, object-specific reducts are defined by object consistency from dependency, and they improve both classification-specific and class-specific reducts. Secondly, tri-level reducts are unified by tri-level consistency. Hierarchical relationships between object-specific reducts and class-specific, classification-specific reducts are analyzed, and relevant connections of three-way classifications of attributes are given. Finally, tri-level reducts are systematically analyzed, and two approaches, i.e., the direct calculation and hierarchical transition, are suggested for constructing a specific reduct. We build a framework of tri-level thinking and analysis of attribute reduction to enrich three-way granular computing. Tri-level reducts lead to the sequential development and hierarchical deepening of attribute reduction, and their results profit intelligence processing and system reasoning.}
}
@article{DUBLJEVIC2024102480,
title = {Colleges and universities are important stakeholders for regulating large language models and other emerging AI},
journal = {Technology in Society},
volume = {76},
pages = {102480},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102480},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24000289},
author = {Veljko Dubljević},
keywords = {Artificial intelligence (AI), Ethics, Public policy, Legitimacy, Oversight},
abstract = {AI technology has already gone through one “winter,” and alarmist thinking may cause yet another one. Calls for a moratorium on AI research increase the salience of the public request for comment on “AI accountability.” Prohibitive approaches are an overreaction, especially when leveraged on virtual (non-embodied) AI agents. While there are legitimate concerns regarding expansion of AI models like ChatGPT in society, a better approach would be to forge a partnership between academia and industry, and utilize infrastructure of campuses to authenticate users and oversee new AI research. The public could also be involved with public libraries authenticating users. This staged approach to embedding AI in society would facilitate addressing ethical concerns, and implementing virtual AI agents in society in a responsible and safe manner.}
}
@article{LUCAS20218320,
title = {Implementing a Novel Software Program to Support Pharmacy Students’ Reflective Practice in Scientific Research},
journal = {American Journal of Pharmaceutical Education},
volume = {85},
number = {10},
pages = {8320},
year = {2021},
issn = {0002-9459},
doi = {https://doi.org/10.5688/ajpe8320},
url = {https://www.sciencedirect.com/science/article/pii/S0002945923015012},
author = {Cherie Lucas and Simon Buckingham Shum and Ming Liu and Mary Bebawy},
keywords = {reflection, formative feedback, pharmacy education, pharmaceutical research},
abstract = {ABSTRACT
Objective. To explore pharmacy students’ perceptions of a novel web application tool (AcaWriter) implemented in a Master of Pharmacy curriculum to support reflective thinking in scientific research. Methods. A qualitative research design involving a 50-minute focus group (n=12) was used. The focus group session was audio-taped, transcribed verbatim, and analyzed thematically using the Braun and Clarke framework. Results. Analysis generated four themes related to AcaWriter’s utility in enhancing students’ research thinking and capacity. The themes identified included: ease of use to prompt reflection, tangible tool with non-judgmental capacity; benefits for enhancing self and peer reflection on research techniques and group dynamics; benefits of the reflective writing process to enhance research capacity compared with engaging in reflective dialogue; and benefits beyond the writing process: cultivating self-improvement and self-confidence. Conclusion. The findings of this study show that a novel web application implemented within a pharmacy curriculum can assist students’ self and peer reflection on a research task. Further research is needed to explore the impact of using this tool and its relationship with academic performance and outcomes.}
}
@article{BELLEMAREPEPIN2022105103,
title = {Processing visual ambiguity in fractal patterns: Pareidolia as a sign of creativity},
journal = {iScience},
volume = {25},
number = {10},
pages = {105103},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.105103},
url = {https://www.sciencedirect.com/science/article/pii/S258900422201375X},
author = {Antoine Bellemare-Pepin and Yann Harel and Jordan O’Byrne and Geneviève Mageau and Arne Dietrich and Karim Jerbi},
keywords = {Cognitive neuroscience, Social sciences, Psychology},
abstract = {Summary
Creativity is a highly valued and beneficial skill that empirical research typically probes using “divergent thinking” (DT) tasks such as problem solving and novel idea generation. Here, in contrast, we examine the perceptual aspect of creativity by asking whether creative individuals are more likely to perceive recognizable forms in ambiguous stimuli –a phenomenon known as pareidolia. To this end, we designed a visual task in which participants were asked to identify as many recognizable forms as possible in cloud-like fractal images. We found that pareidolic perceptions arise more often and more rapidly in highly creative individuals. Furthermore, high-creatives report pareidolia across a broader range of image contrasts and fractal dimensions than do low creatives. These results extend the established body of work on DT by introducing divergent perception as a complementary manifestation of the creative mind, thus clarifying the perception-creation link while opening new paths for studying creative behavior in humans.}
}
@article{LI2024101590,
title = {Transforming maker mindsets: A case study of elementary students in a maker education context during lesson study},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101590},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101590},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001287},
author = {Jiajia Li and Zhuang Li and Huixin Gao and Tianying Yun},
keywords = {Maker mindsets, STEM learning, Maker education, Lesson study},
abstract = {Utilizing a case study approach, this research investigates the transformation of elementary students' Maker mindsets within the context of Maker education through a lesson study cycle. The study focuses on the Maker mindsets transformation of three students with varying abilities, deliberately chosen as information-rich participants. A project-specific questionnaire, the Maker Mindsets Scale, was employed to facilitate self-assessment of Maker mindsets before and after intervention. Additionally, teachers' post-lesson discussion meetings were observed, and semi-structured interviews with participating teachers were conducted to gauge their perceptions of students' Maker mindsets transformation. The analysis encompassed students' semi-structured reflection logs and interviews to uncover the underlying factors driving Maker mindsets transformation. The results revealed distinct variations in how students of different abilities perceived their Maker mindsets transformation. Nonetheless, participant teachers consistently observed transformations in STEM (Science, Technology, Engineering, Mathematics) thinking skills, self-efficacy, motivation, and collaborative learning across all students. The study further identifies a collaborative convergence of multiple factors contributing to Maker mindsets transformation, spanning teacher, student, and pedagogical perspectives. These findings carry significant implications for educators, advocating for the implementation of customized strategies, authentic contextualization, structured methodologies, and collaborative frameworks to holistically nurture Maker mindsets evolution. Moreover, our study underscores the practicality of the LS approach in fostering collaborative development of innovative pedagogical strategies aimed at fostering Maker mindsets formation.}
}
@article{CHIN20201054,
title = {Rethinking Cancer Immunotherapy by Embracing and Engineering Complexity},
journal = {Trends in Biotechnology},
volume = {38},
number = {10},
pages = {1054-1065},
year = {2020},
note = {Special Issue: Therapeutic Biomanufacturing},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779920301244},
author = {Matthew H.W. Chin and Eileen Gentleman and Marc-Olivier Coppens and Richard M. Day},
keywords = {bioengineering, complex systems, holism, immunotherapy, process intensification},
abstract = {The meteoric rise of cancer immunotherapy in the past decade has led to promising treatments for a number of hard-to-treat malignancies. In particular, adoptive T cell therapy has recently reached a major milestone with two products approved by the US FDA. However, the inherent complexity of cell-based immunotherapies means that their manufacturing time, cost, and controllability limit their effectiveness and geographic reach. One way to address these issues may lie in complementing the dominant, reductionistic mentality in modern medicine with complex systems thinking. In this opinion article, we identify key concepts from complexity theory to address manufacturing challenges in cell-based immunotherapies and raise the possibility of a unifying framework upon which future bioprocessing strategies may be designed.}
}
@article{JANES200673,
title = {A biological approach to computational models of proteomic networks},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {1},
pages = {73-80},
year = {2006},
note = {Proteomics and genomics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2005.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1367593105001687},
author = {Kevin A Janes and Douglas A Lauffenburger},
abstract = {Computational modeling is useful as a means to assemble and test what we know about proteins and networks. Models can help address key questions about the measurement, definition and function of proteomic networks. Here, we place these biological questions at the forefront in reviewing the computational strategies that are available to analyze proteomic networks. Recent examples illustrate how models can extract more information from proteomic data, test possible interactions between network proteins and link networks to cellular behavior. No single model can achieve all these goals, however, which is why it is critical to prioritize biological questions before specifying a particular modeling approach.}
}
@article{GILHOOLY2024100071,
title = {AI vs humans in the AUT: Simulations to LLMs},
journal = {Journal of Creativity},
volume = {34},
number = {1},
pages = {100071},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100071},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000304},
author = {Ken Gilhooly},
keywords = {AI, Alternative uses, Divergent thinking},
abstract = {This paper reviews studies of proposed creative machines applied to a prototypical creative task, i.e., the Alternative Uses Task (AUT). Although one system (OROC) did simulate some aspects of human strategies for the AUT, most recent attempts have not been simulation-oriented, but rather have used Large Language Model (LLM) systems such as GPT-3 which embody extremely large connectionist networks trained on huge volumes of textual data. Studies reviewed here indicate that LLM based systems are performing on the AUT at near or somewhat above human levels in terms of scores on originality and usefulness. Moreover, similar patterns are found in the data of humans and LLM models in the AUT, such as output order effects and a negative association between originality and value or utility. However, it is concluded that GPT-3 and similar systems, despite generating novel and useful responses, do not display creativity as they lack agency and are purely algorithmic. LLM studies so far in this area have largely been exploratory and future studies should guard against possible training data contamination.}
}
@article{CHEN2005121,
title = {Computational intelligence in economics and finance: Carrying on the legacy of Herbert Simon},
journal = {Information Sciences},
volume = {170},
number = {1},
pages = {121-131},
year = {2005},
note = {Computational Intelligence in Economics and Finance},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2003.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0020025503004444},
author = {Shu-Heng Chen},
keywords = {Computational intelligence, Artificial intelligence, Agent-based computational economics, Autonomous agents, Stock price-volume relation, Micro-macro relation},
abstract = {This is an editorial guide for the special issue on computational intelligence (CI) in economics and finance. A historical introduction to the background is given. This research paradigm is traced back to Herbert Simon, who, as a founder of artificial intelligence, pioneered the applications of AI to economics. The move from the classical AI to CI indicates a continuation of the legacy of Herbert Simon. Computational intelligence has proved to be a constructive foundation for economics. In responding to what Herbert Simon referred as procedural rationality, our study of bounded rationality has been enriched by bringing autonomous agents into the economic analysis.}
}
@article{GOODSELL2020472,
title = {Art and Science of the Cellular Mesoscale},
journal = {Trends in Biochemical Sciences},
volume = {45},
number = {6},
pages = {472-483},
year = {2020},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0968000420300566},
author = {David S. Goodsell and Arthur J. Olson and Stefano Forli},
keywords = {mesoscale modeling, integrative structural biology, drug discovery, drug design, cell structure, cell function, molecular structure, molecular function},
abstract = {Experimental information from microscopy, structural biology, and bioinformatics may be integrated to build structural models of entire cells with molecular detail. This integrative modeling is challenging in several ways: the intrinsic complexity of biology results in models with many closely packed and heterogeneous components; the wealth of available experimental data is scattered among multiple resources and must be gathered, reconciled, and curated; and computational infrastructure is only now gaining the capability of modeling and visualizing systems of this complexity. We present recent efforts to address these challenges, both with artistic approaches to depicting the cellular mesoscale, and development and application of methods to build quantitative models.}
}
@article{AMADORHIDALGO2021103694,
title = {Cognitive abilities and risk-taking: Errors, not preferences},
journal = {European Economic Review},
volume = {134},
pages = {103694},
year = {2021},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2021.103694},
url = {https://www.sciencedirect.com/science/article/pii/S0014292121000477},
author = {Luis Amador-Hidalgo and Pablo Brañas-Garza and Antonio M. Espín and Teresa García-Muñoz and Ana Hernández-Román},
keywords = {Decision making under uncertainty, Cognitive abilities, Online experiment, Risk and loss aversion, Factor analysis},
abstract = {There is an intense debate whether risk-taking behavior is partially driven by cognitive abilities. The critical issue is whether choices arising from subjects with lower cognitive abilities are more likely driven by errors or lack of understanding than pure preferences for risk. The latter implies that the often-argued link between risk preferences and cognitive abilities (a common finding is that abilities relate negatively to risk aversion and positively to loss aversion) might be a spurious correlation. This experiment reports evidence from a sample of 556 participants who made choices in two risk-related tasks and completed three cognitive tasks, all with real monetary incentives: number-additions (including incentive-compatible expected number of correct additions), the Cognitive Reflection Test (to measure analytical/reflective thinking) and the Remote Associates Test (for convergent thinking). Results are unambiguous: none of our cognition measures plays any systematic role on risky decision making. Using structural equation modeling and factor analysis, we show that cognitive abilities are negatively associated with noisy, inconsistent choices and this effect may make higher ability individuals appear to be less risk averse and more loss averse. Yet we show that errors are more likely to appear when the two payoffs in a given decision exhibit similar probability. Therefore, our results suggest that failing to account for noisy decision making might have led to erroneously inferring a correlation between cognitive abilities and risk preferences in previous studies.}
}