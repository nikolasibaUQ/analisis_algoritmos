@incollection{WARE2013375,
title = {Chapter Eleven - Visual Thinking Processes},
editor = {Colin Ware},
booktitle = {Information Visualization (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
address = {Boston},
pages = {375-423},
year = {2013},
series = {Interactive Technologies},
isbn = {978-0-12-381464-7},
doi = {https://doi.org/10.1016/B978-0-12-381464-7.00011-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780123814647000119},
author = {Colin Ware}
}
@article{STAVERT2023432,
title = {Unlocking the holy grail of sustainable and scalable mesoporous silica using computational modelling},
journal = {RSC Sustainability},
volume = {1},
number = {3},
pages = {432-438},
year = {2023},
issn = {2753-8125},
doi = {https://doi.org/10.1039/d3su00019b},
url = {https://www.sciencedirect.com/science/article/pii/S2753812523000952},
author = {Tom Stavert and Siddharth V. Patwardhan and Robert Pilling and Miguel Jorge},
abstract = {ABSTRACT
Bio-inspired methods offer a great alternative to design high-value mesoporous silica under more environmentally friendly conditions, allowing for an economical and sustainable scale-up. However, the synthesis of bio-inspired silica (BIS) is currently poorly understood, creating barriers to achieving products with comparable quality to traditional mesoporous silica. This perspective summarizes the key findings in the development of ordered mesoporous silica (OMS) and BIS synthesis, highlighting in particular the challenges faced in the development of scalable processing routes for these materials. Recent successes in improving mechanistic understanding of these syntheses using computational modelling are then presented, followed by suggestions as to how modelling may be used for predictive design of BIS with desired quality attributes. A multi-scale computational model, utilizing a combination of both ‘top-down’ and ‘bottom-up’ approaches, is argued to be critical for achieving a unified description of both BIS and OMS synthesis, allowing the potential of these materials to be fully realised.}
}
@article{DU2023108546,
title = {OSSCAR, an open platform for collaborative development of computational tools for education in science},
journal = {Computer Physics Communications},
volume = {282},
pages = {108546},
year = {2023},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2022.108546},
url = {https://www.sciencedirect.com/science/article/pii/S001046552200265X},
author = {Dou Du and Taylor J. Baird and Sara Bonella and Giovanni Pizzi},
keywords = {Jupyter, Notebooks, Computational physics, Computational chemistry, Computational materials science, Education},
abstract = {In this paper we present the Open Software Services for Classrooms and Research (OSSCAR) platform. OSSCAR provides an open collaborative environment to develop and access educational resources in the form of web applications, for which various deployment methods are discussed and compared. To minimize efforts in the creation and use of new educational material, OSSCAR combines software tools that have emerged as standards with custom domain-specific ones. The technical solutions adopted to create and distribute content are described and motivated on the basis of reliability, sustainability, ease of uptake and use. Examples from courses in the domains of physics, chemistry, and materials science are shown to demonstrate the style and level of interactivity of typical applications. The tools presented are easy to use, and create a uniform and open environment exploitable by a large community of teachers, students, and researchers with the goal of facilitating learning and avoiding, when possible, duplication of efforts in creating teaching material. Contributions to expand the educational content of the OSSCAR project are welcome.
Program summary
Program Title: OSSCAR Interactive Notebooks for Quantum Mechanics and Computational Materials Science CPC Library link to program files: https://doi.org/10.17632/26py5zz9f8.1 Developer's repository link: https://github.com/osscar-org/quantum-mechanics Licensing provisions: MIT Programming language: Python Nature of problem: Among others, computational courses (e.g. on quantum mechanics) can benefit from advanced interactive visualizations of the content. However, on the one hand it might be complicated for teachers to develop such interactive content; on the other hand, students need to be able to access very quickly and efficiently the content, reducing the time needed to install libraries and dependencies that might differ between courses. Solution method: Here, we developed interactive web applications to complement teaching and encourage computational thinking for courses in computational physics, chemistry and materials science, using Jupyter notebooks and their rendering as interactive web applications. The latter is powered by a combination of Voila, to hide code and convert notebooks into live web applications, and (existing or custom) Jupyter widgets to enable interactiveness. The code is ready to be deployed via a number of open approaches.}
}
@incollection{ALLAHVIRANLOO2024407,
title = {Chapter 23 - Computations with words},
editor = {Tofigh Allahviranloo and Witold Pedrycz and Amir Seyyedabbasi},
booktitle = {Decision-Making Models},
publisher = {Academic Press},
pages = {407-415},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-16147-6},
doi = {https://doi.org/10.1016/B978-0-443-16147-6.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161476000128},
author = {Tofigh Allahviranloo},
keywords = {Computation, Fuzzy, Application},
abstract = {In fact, computing with words is a method in which the objects are words, and the computations are propositions extracted from ordinary conversation. For example, small, large, far, and heavy, not very likely, the price of gas in Iran is low and increasing a lot. Computing with words is inspired by the remarkable ability of humans to perform various types of physical and mental activities without any measurement or calculation. Familiar examples of these activities are parking a car, driving in heavy traffic, riding a bicycle, understanding speech, etc.}
}
@article{IIVARI2023100600,
title = {Computational empowerment of children: Design research on empowering and impactful designs by children},
journal = {International Journal of Child-Computer Interaction},
volume = {37},
pages = {100600},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100600},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000375},
author = {Netta Iivari and Leena Ventä-Olkkonen and Heidi Hartikainen and Sumita Sharma and Essi Lehto and Jenni Holappa and Tonja Molin-Juustila},
keywords = {Children, Empowerment, Impact, Critical design, Critical making, Bullying, Design research},
abstract = {Prioritizing children’s empowerment in and through design has been on the agenda of child–computer interaction (CCI) research for a long time. Recently, the notion of the computational empowerment of children has received attention. However, there are still open issues in our understanding and advocacy of it. A related development is the recent interest in the longer-term impacts of our work. Fast and furious participation of children in design sessions is considered inadequate. We should advocate for longer-term trajectories and possibilities for children to make changes that will influence our world. However, the literature is limited in addressing longer-term impacts. This study taps into these two research gaps and showcases how we have addressed the computational empowerment of children in a project tackling bullying at school through critical design and making. In this paper, we examine in detail the children’s designs and their trajectories from the viewpoint of empowerment and impact: whether and how these children’s designs show potential for the empowerment of those bullied and whether and how their designs have had an impact in the realm of digital technology development. Our study has interesting conceptual and methodological implications for CCI research and practice on the computational empowerment of children and on our design research practice.}
}
@incollection{MARTINGAMBOA2021295,
title = {Chapter 16 - Coupled life cycle thinking and data envelopment analysis for quantitative sustainability improvement},
editor = {Jingzheng Ren},
booktitle = {Methods in Sustainability Science},
publisher = {Elsevier},
pages = {295-320},
year = {2021},
isbn = {978-0-12-823987-2},
doi = {https://doi.org/10.1016/B978-0-12-823987-2.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239872000039},
author = {Mario Martín-Gamboa and Diego Iribarren},
keywords = {Data Envelopment Analysis, Multicriteria Decision Analysis, Life Cycle Assessment, Sustainability Assessment},
abstract = {This chapter addresses the joint use of Data Envelopment Analysis (DEA) and Life Cycle Assessment (LCA) as a source of synergistic frameworks for quantitative sustainability assessment and benchmarking of multiple similar entities. In addition to current progress in the growing field of research in (environmental) LCA + DEA, novel approaches further integrating social life cycle indicators are proposed. This enhanced sustainability scope is expected to further promote the combined use of life cycle approaches and DEA when assessing and benchmarking a large number of resembling entities.}
}
@article{MAMMINO2022100743,
title = {Computational chemistry and green chemistry: Familiarizing chemistry students with the modes and benefits of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {29},
pages = {100743},
year = {2022},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2022.100743},
url = {https://www.sciencedirect.com/science/article/pii/S2352554122001474},
author = {Liliana Mammino},
keywords = {Computational modelling of molecules, Cross-area synergies for green chemistry, Green chemistry education, Molecular design for green chemistry, Student-friendly introduction to the bases of molecular studies},
abstract = {Because of its nature as the science of substances, chemistry is bound to play major roles in the pursuit of sustainable development. Green chemistry outlines the framework of this role and its 12 principles express objectives simultaneously constituting implementation guidelines. Tackling the challenges posed by the pursuit of sustainability is likely to become an increasingly permeating component of chemists' professional activities, and future chemists need to be adequately prepared for it. The principles of green chemistry entail the design of substances and processes that are inherently benign to human health and to the environment (benign-by-design concept). Computational chemistry constitutes a major resource for the design of molecules having desired properties. However, students’ exposure to the potentialities and practices of this type of cross-area synergies remains largely inadequate. The paper discusses the importance of adequate exposure and outlines possible routes to facilitate it in a student-friendly and constructive way.}
}
@article{LARKINS2010913,
title = {Introductory computational science using MATLAB and image processing},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {913-919},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001018},
author = {D. Brian Larkins and William Harvey},
abstract = {We describe a new course designed to introduce engineering students to computational thinking. One of the most significant challenges in teaching an introductory-level applied computing course is that students are not expected to have substantial math and science experience. To address this, we have developed exercises which use edge detection and basic image processing to motivate the use of programming MATLAB in a non-trivial scientific application. MATLAB is a popular high-level programming language and environment which supports a wide range of computational science applications. MATLAB has strong support for operating on image data, which allows us to balance solving practical engineering problems with basic core concepts of computer science such as functional abstraction, conditional execution, and iteration.}
}
@article{ATANCE2001533,
title = {Episodic future thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {12},
pages = {533-539},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01804-0},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300018040},
author = {Cristina M. Atance and Daniela K. O'Neill},
keywords = {episodic future thinking, planning, future orientation, self, time, episodic memory, semantic memory},
abstract = {Thinking about the future is an integral component of human cognition – one that has been claimed to distinguish us from other species. Building on the construct of episodic memory, we introduce the concept of ‘episodic future thinking’: a projection of the self into the future to pre-experience an event. We argue that episodic future thinking has explanatory value when considering recent work in many areas of psychology: cognitive, social and personality, developmental, clinical and neuropsychology. Episodic future thinking can serve as a unifying concept, connecting aspects of diverse research findings and identifying key questions requiring further reflection and study.}
}
@article{HUANG201244,
title = {Protocol analysis of designers using an interactive evolutionary computation},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {1},
pages = {44-50},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000040},
author = {Weixin Huang and Daisuke Matsushita and Junzo Munemoto},
keywords = {Interior color, Problem-solving behavior, Protocol analysis, Interactive evolutionary computation (IEC)},
abstract = {This paper explores the problem-solving behavior of people in design activities through a protocol analysis of verbal reports on the interior work design process simulated by an interactive evolutionary computation (IEC). The protocol analysis method was used to explore the ways of thinking of the participants throughout the process. The analysis reveals that different parts of the interior scene have different effects on the evaluations, and people tend to use the same evaluation criteria continuously on several images. This kind of behavior is consistent with that of professional designers in past studies and is revealed applicable to non-professionals in the current research.}
}
@article{SAXENA2023113238,
title = {Thinking green with 2-D and 3-D MXenes: Environment friendly synthesis and industrial scale applications and global impact},
journal = {Renewable and Sustainable Energy Reviews},
volume = {178},
pages = {113238},
year = {2023},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2023.113238},
url = {https://www.sciencedirect.com/science/article/pii/S1364032123000941},
author = {Shatakshi Saxena and Michael Johnson and Fuhar Dixit and Karl Zimmermann and Shreya Chaudhuri and Fiyanshu Kaka and Balasubramanian Kandasubramanian},
keywords = {MXene nanocomposites, Green synthesis, Defect engineering, Ionic liquid, Supercapacitors, Machine learning, Economic impact},
abstract = {MXenes are currently a research hotspot in the field of 2D materials, hinting to revolutionize material technology. Their layered architecture allows for molecular intercalation, defect engineering, and surface band gap functionalization, with applications as diverse as energy storage and drinking water desalination. Its structural and functional integrity has prompted the scientific community to investigate novel compositions in an effort to leverage electrochemical activity, mechanical robustness, flexibility and environmental stability. However, the current synthesis routes present a bottleneck in proposing MXenes as a sustainable material for the future. Therefore, by expanding the reach of synthetic chemistry towards efficient strategies for green production, we present the first comprehensive introspection of the use of green solvents and their impact on material properties during MXene synthesis. This review is an attempt to quantify the intriguing characteristics of MXene nanocomposites by embracing design tools like the ‘iceberg model’. To further evaluate the performance of MXenes fabricated using green strategies (such as eutectic etching) we have made an attempt to critically compare them with conventional MXenes by examining surface characteristics, electrochemical analysis, charge transfer mechanisms etc. Conclusively, we aim to instigate concern about the environmental impact of MXene synthesis and instil a multidisciplinary approach to tailor environmentally benign, scalable and efficient MXene derivatives for commercial energy applications. The review provides an immersive account linking UN sustainable development goals with the industrial outlook of green MXenes, it highlights their impact on climate change, potential to build technically advanced economies, low cost production and range of applications.}
}
@article{LLOYD2017A1,
title = {From Design Methods to Future-Focused Thinking: 50 years of design research},
journal = {Design Studies},
volume = {48},
pages = {A1-A8},
year = {2017},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2016.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X1630093X},
author = {Peter Lloyd},
abstract = {The 50th anniversary of the founding of the Design Research Society fell in 2016, and the biennial DRS conference for 2016 became a special 50th anniversary conference, which took place in Brighton, UK, last June.}
}
@article{FLY2017S105,
title = {Where Did They Go Wrong? Identifying Student Strategies Used in Analytic Thinking, Evaluating Data, and Problem Solving},
journal = {Journal of Nutrition Education and Behavior},
volume = {49},
number = {7, Supplement 1},
pages = {S105},
year = {2017},
note = {SNEB 2017 Annual Conference Proceedings},
issn = {1499-4046},
doi = {https://doi.org/10.1016/j.jneb.2017.05.125},
url = {https://www.sciencedirect.com/science/article/pii/S1499404617303913},
author = {Alyce Fly and Krisha Thiagarajah and Lisa Kurz}
}
@article{CZAKON202399,
title = {Re-thinking strategic myopia: A necessary condition analysis of heuristic and firm's performance},
journal = {Industrial Marketing Management},
volume = {115},
pages = {99-109},
year = {2023},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0019850123001864},
author = {Wojciech Czakon and Patrycja Klimas and Arkadiusz Kawa},
keywords = {Myopia, Managers, Heuristic, Performance, NCA},
abstract = {At times of fast paced technology progress and global disruptions strategic myopia can be particularly harmful to firms. A narrow view of actors, events and tendencies is a firm's environment, combined with short-term preferences is widely recognized in the literature as leading to belated or inadequate responses to challenges. Manager's myopia is typically portrayed as a systematic bias, inducing underperformance. However, empirical evidence is more than nuanced in this respect. In this study, we view strategic myopia as an effective heuristic triggered in uncertain environments and specific task conditions. We use the necessary condition analysis (NCA) to examine the association between strategic myopia and firm performance through a necessity logic lens. This innovative method provides insights into the relationship between low levels of strategic myopia dimensions and firm performance in both the short- and long term. We measure strategic myopia and firm performance as multidimensional constructs on a representative sample of 658 Polish managers. Our results challenge the conventional wisdom that low strategic myopia is necessary for high performance. We highlight the nuanced role of myopia across its dimensions (i.e., competitive, cooperative, temporal, and learning) and shed light on its implications for both short- and long-term performance.}
}
@article{JOHNSONRESTREPO2020101088,
title = {A computational science approach to understanding human conflict},
journal = {Journal of Computational Science},
volume = {46},
pages = {101088},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101088},
url = {https://www.sciencedirect.com/science/article/pii/S1877750319313456},
author = {D. Dylan {Johnson Restrepo} and Michael Spagat and Stijn {van Weezel} and Minzhang Zheng and Neil F. Johnson},
keywords = {Human conflict, Power laws, Generative models, Computational approaches, Agent-based models},
abstract = {We discuss how computational data science and agent-based modeling, are shedding new light on the age-old issue of human conflict. While social science approaches focus on individual cases, the recent proliferation of empirical data and complex systems thinking has opened up a computational approach based on identifying common statistical patterns and building generative but minimal agent-based models. We discuss a reconciliation for various disparate claims and results in the literature that stand in the way of a unified description and understanding of human wars and conflicts. We also discuss the unified interpretation of the origin of these power-law deviations in terms of dynamical processes. These findings show that a unified computational science framework can be used to understand and quantitatively describe collective human conflict.}
}
@article{GOLDSCHMIDT1994158,
title = {On visual design thinking: the vis kids of architecture},
journal = {Design Studies},
volume = {15},
number = {2},
pages = {158-174},
year = {1994},
issn = {0142-694X},
doi = {https://doi.org/10.1016/0142-694X(94)90022-1},
url = {https://www.sciencedirect.com/science/article/pii/0142694X94900221},
author = {Gabriela Goldschmidt},
keywords = {visual thinking, designing, imagery, sketching, architecture},
abstract = {Designers invariably use imagery to generate new form combinations which they represent through sketching. But they also do the reverse: they sketch to generate images of forms in their minds. Common belief regards such activity as non-rational. In contrast, we assert that interactive imagery through sketching is a rational mode of reasoning, characterized by systematic exchanges between conceptual and figural arguments. Cognitive science, strongly dominated by a linguistic paradigm, has yet to recognize the paramount role of visual reasoning in many instances of problem solving; and in design tool-making, computational and otherwise, we must learn to optimize rather than bypass intuitive visuality.}
}
@article{PICKLO2024112790,
title = {Denoising Particle-In-Cell data via Smoothness-Increasing Accuracy-Conserving filters with application to Bohm speed computation},
journal = {Journal of Computational Physics},
volume = {502},
pages = {112790},
year = {2024},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2024.112790},
url = {https://www.sciencedirect.com/science/article/pii/S0021999124000391},
author = {Matthew J. Picklo and Qi Tang and Yanzeng Zhang and Jennifer K. Ryan and Xian-Zhu Tang},
keywords = {Particle-In-Cell, SIAC filters, Denoising},
abstract = {The simulation of plasma physics is computationally expensive because the underlying physical system is of high dimensions, requiring three spatial dimensions and three velocity dimensions. One popular numerical approach is Particle-In-Cell (PIC) methods owing to its ease of implementation and favorable scalability in high-dimensional problems. An unfortunate drawback of the method is the introduction of statistical noise resulting from the use of finitely many particles. In this paper we examine the application of the Smoothness-Increasing Accuracy-Conserving (SIAC) family of convolution kernel filters as denoisers for moment data arising from PIC simulations. We show that SIAC filtering is a promising tool to denoise PIC data in the physical space as well as capture the appropriate scales in the Fourier space. Furthermore, we demonstrate how the application of the SIAC technique reduces the amount of information necessary in the computation of quantities of interest in plasma physics such as the Bohm speed.}
}
@article{ZHANG2002445,
title = {Measuring thinking styles in addition to measuring personality traits?},
journal = {Personality and Individual Differences},
volume = {33},
number = {3},
pages = {445-458},
year = {2002},
issn = {0191-8869},
doi = {https://doi.org/10.1016/S0191-8869(01)00166-0},
url = {https://www.sciencedirect.com/science/article/pii/S0191886901001660},
author = {Li-fang Zhang},
keywords = {Thinking styles, Personality traits, Measurement},
abstract = {This paper intends to join the long-standing debate regarding thinking styles and personality traits—should thinking styles be measured in addition to the measurement of personality traits? The means to achieve this goal was to provide empirical evidence as well as to review other studies in the literature. The Thinking Styles Inventory and the NEO Five-Factor Inventory were administered to 267 (67 male and 200 female) students from a large research university in Beijing, People's Republic of China. Results showed that thinking styles and personality traits statistically overlap. However, this overlap is limited. Two major arguments are made. First, thinking styles make a unique contribution to the understanding of human individual differences. Second, the necessity for measuring thinking styles apart from measuring personality traits depends on who uses the inventories and for what purposes.}
}
@article{LOWALEKAR201789,
title = {Revolutionizing blood bank inventory management using the TOC thinking process: An Indian case study},
journal = {International Journal of Production Economics},
volume = {186},
pages = {89-122},
year = {2017},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317300336},
author = {Harshal Lowalekar and R. Raghavendra Ravi},
keywords = {Inventory management, Blood banks, Theory of Constraints (TOC), Thinking Process},
abstract = {The purpose of this research is to demonstrate an application of TOC's thinking process (TP) in a blood bank environment. We take an example of a real-life blood bank which is struggling with the problems of high shortage and wastage of blood products, large inventory levels, poor and erratic blood collection, limited product variety, high error rate, high turnover of technicians, high operating expenses and low revenue levels. We show using the TOC approach how these seemingly unrelated problems faced by the bank are in fact highly inter-related and how they all originate from a single root-cause. A current reality tree (CRT) is used to identify the root cause responsible for all the major blood bank problems. A conflict resolution diagram (CRD) is constructed to identify the core-conflict(s) responsible for the blood bank's poor performance. A simple yet powerful solution is generated for the given bank by breaking the core-conflict resulting from a paradigm constraint in blood banking. A future reality tree (FRT) is then constructed to show how the TOC approach will help the blood bank in lowering its shortage and wastage levels in spite of collecting lesser number of units in blood donation camps. The bank will be able to significantly cut down its inventories and can issue fresher units to the patients. Blood bank's revenue levels will increase while its operating expense will decrease due to the TOC approach. The error rate as well as the turnover of technicians in the blood bank laboratory will also reduce considerably. A simulation model shows that the proposed TOC solution will reduce the annual shortage of red blood cells by 66% and platelets by 82% at the bank. Similarly, the wastage of red blood cells will decrease by 93%, plasma by 99% and platelets by 98%. The average inventory level of the red blood cells will drop by 41%, plasma by 95% and platelets by 10%. The major contribution of this research is to show that TP tools can be extremely powerful in constructing win-win solutions for complex systems like blood banks by addressing their major problems in an integrated fashion. The TOC approach reveals how one widely-held belief in the blood banking world is the main reason behind the blood banks' poor state of affairs. The solutions presented in this research should be readily applicable to other blood banks which are struggling to improve their operational and financial performance.}
}
@article{BAGO2018483,
title = {Fast and slow thinking: Electrophysiological evidence for early conflict sensitivity},
journal = {Neuropsychologia},
volume = {117},
pages = {483-490},
year = {2018},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2018.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218303440},
author = {Bence Bago and Darren Frey and Julie Vidal and Olivier Houdé and Gregoire Borst and Wim {De Neys}},
keywords = {EEG, Dual process theory},
abstract = {Popular dual process models have characterized reasoning as an interplay between fast, intuitive (System 1) and slow, deliberate (System 2) processes, but the precise nature of the interaction between the two systems is much debated. Here we relied on the temporal resolution of electroencephalogram (EEG) recordings to decide between different models. We adopted base-rate problems in which an intuitively cued stereotypical response was either congruent or incongruent with the correct response that was cued by the base-rates. Results showed that solving problems in which the base-rates and stereotypical description cued conflicting responses resulted in an increased centro-parietal N2 and frontal P3. This early conflict sensitivity suggests that the critical base-rates can be processed fast without slow and deliberate System 2 reflection. Findings validate prior EEG work and support recent hybrid dual process models in which the fast System 1 is processing both heuristic belief-based responses (e.g., stereotypes) and elementary logico-mathematical principles (e.g., base-rates).}
}
@article{FRADKIN2023S122,
title = {71. A Transdiagnostic Investigation of the Computational Mechanisms of Formal Thought Disorder},
journal = {Biological Psychiatry},
volume = {93},
number = {9, Supplement },
pages = {S122-S123},
year = {2023},
note = {Abstract Supplement},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2023.02.311},
url = {https://www.sciencedirect.com/science/article/pii/S0006322323003852},
author = {Isaac Fradkin and Rick Adams and Noam Siegelman and Rani Moran and Raymond Dolan}
}
@article{BROWNING2023104031,
title = {Language, common sense, and the Winograd schema challenge},
journal = {Artificial Intelligence},
volume = {325},
pages = {104031},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104031},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001777},
author = {Jacob Browning and Yann LeCun},
keywords = {Winograd schema challenge, Artificial intelligence, Common-sense, Disambiguation, Symbolic AI, Large language models},
abstract = {Since the 1950s, philosophers and AI researchers have held that disambiguating natural language sentences depended on common sense. In 2012, the Winograd Schema Challenge was established to evaluate the common-sense reasoning abilities of a machine by testing its ability to disambiguate sentences. The designers argued only a system capable of “thinking in the full-bodied sense” would be able to pass the test. However, by 2023, the original authors concede the test has been soundly defeated by large language models which still seem to lack common sense of full-bodied thinking. In this paper, we argue that disambiguating sentences only seemed like a good test of common-sense based on a certain picture of the relationship between linguistic comprehension and semantic knowledge—one typically associated with the early computational theory of mind and Symbolic AI. If this picture is rejected, as it is by most LLM researchers, then disambiguation ceases to look like a comprehensive test of common-sense and instead appear only to test linguistic competence. The upshot is that any linguistic test, not just disambiguation, is unlikely to tell us much about common sense or genuine intelligence.}
}
@incollection{WHITNEY2013231,
title = {Chapter 6 - Thinking . . . Machines},
editor = {Hunter Whitney},
booktitle = {Data Insights},
publisher = {Morgan Kaufmann},
pages = {231-263},
year = {2013},
isbn = {978-0-12-387793-2},
doi = {https://doi.org/10.1016/B978-0-12-387793-2.00006-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123877932000061},
author = {Hunter Whitney}
}
@article{LAMB2014116,
title = {A computational modeling of student cognitive processes in science education},
journal = {Computers & Education},
volume = {79},
pages = {116-125},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0360131514001651},
author = {Richard L. Lamb and David B. Vallett and Tariq Akmal and Kathryn Baldwin},
keywords = {Computational modeling, Cognitive processing, Science education, Critical reasoning, Serious educational games},
abstract = {The purpose of this paper is to explain and document the creation of a computational model in the form of an Artificial Neural Network (ANN) capable of simulating student cognition. Specifically, the model simulates students' cognition as they complete activities within a science classroom. This study also seeks to examine the effects, as evidenced in the ANN, of an intervention designed to develop increased levels of critical thinking related to science skills. This model is based on the identification of cognitive attributes and integration of two advanced measurement frameworks: cognitive diagnostics and Item Response Theory. Both frameworks examine student response patterns, providing initial inputs for the ANN portion of the model. Once initial task response patterns are identified, they are parameterized and presented to the ANN. The ANN within this study is the foundational component of a computational model based upon the interaction of multiple, connected, adaptive processing elements know as cognitive attributes. These cognitive attributes process student responses to cognitive tasks within science tasks. Using the Student Task and Cognition Model (STAC-M), the study authors simulated a cognitive training intervention using a randomized control trial design of 100,000 students. Results of the simulation suggest that it is possible to increase levels of student success using a targeted cognitive attribute approach and that computational modeling provides a means to test educational theory for future education research. The paper also discusses limitations of the use of this computational model within education and the possible future directions for educators and researchers.}
}
@article{OBRIEN2002313,
title = {Radical connectionism: thinking with (not in) language},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {313-329},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00010-1},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000101},
author = {Gerard O'Brien and Jon Opie},
keywords = {Analog, Computation, Connectionism, Representation, Resemblance, Thought},
abstract = {In this paper we defend a position we call radical connectionism. Radical connectionism claims that cognition never implicates an internal symbolic medium, not even when natural language plays a part in our thought processes. On the face of it, such a position renders the human capacity for abstract thought quite mysterious. However, we argue that connectionism is committed to an analog conception of neural computation, and that representation of the abstract is no more problematic for a system of analog vehicles than for a symbol system. Natural language is therefore not required as a representational medium for abstract thought. Since natural language is arguably not a representational medium at all, but a conventionally governed scheme of communicative signals, we suggest that the role of internalised (i.e. self-directed) language is best conceived in terms of the coordination and control of cognitive activities within the brain.}
}
@article{AZIZ2013679,
title = {Applying lean thinking in construction and performance improvement},
journal = {Alexandria Engineering Journal},
volume = {52},
number = {4},
pages = {679-695},
year = {2013},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2013.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S111001681300046X},
author = {Remon Fayek Aziz and Sherif Mohamed Hafez},
keywords = {Lean production, Lean thinking, Lean construction, Construction industry, Performance and, Improvement theories},
abstract = {The productivity of the construction industry worldwide has been declining over the past 40years. One approach for improving the situation is using lean construction. Lean construction results from the application of a new form of production management to construction. Essential features of lean construction include a clear set of objectives for the delivery process, aimed at maximizing performance for the customer at the project level, concurrent design, construction, and the application of project control throughout the life cycle of the project from design to delivery. An increasing number of construction academics and professionals have been storming the ramparts of conventional construction management in an effort to deliver better value to owners while making real profits. As a result, lean-based tools have emerged and have been successfully applied to simple and complex construction projects. In general, lean construction projects are easier to manage, safer, completed sooner, and cost less and are of better quality. Significant research remains to complete the translation to construction of lean thinking in Egypt. This research will discuss principles, methods, and implementation phases of lean construction showing the waste in construction and how it could be minimized. The Last Planner System technique, which is an important application of the lean construction concepts and methodologies and is more prevalent, proved that it could enhance the construction management practices in various aspects. Also, it is intended to develop methodology for process evaluation and define areas for improvement based on lean approach principles.}
}
@incollection{PARASHAR2024275,
title = {Chapter ten - Computational techniques for sustainable green procurement and production},
editor = {Sanjoy Kumar Paul and Sandeep Kautish},
booktitle = {Computational Intelligence Techniques for Sustainable Supply Chain Management},
publisher = {Academic Press},
pages = {275-300},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-18464-2},
doi = {https://doi.org/10.1016/B978-0-443-18464-2.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184642000042},
author = {Bhakti Parashar and Sandeep Kautish and Amrita Chaurasia},
keywords = {Computational techniques, computing, green procurement, procurement},
abstract = {Computational techniques are used to generate, solve, analyze, explain, or manage any simple or complex task. The use of environmentally responsible techniques to meet demand for resources, commodities, utilities, and services is known as green procurement. Computational technique in green procurement and production is one of the components of sustainable procurement, along with a commitment to social responsibility and good corporate behavior. Some solutions for this kind of issue are low-maintenance, energy-efficient, and long-lasting. Several experts and researchers provided their findings on the environmental impact of ICT with the use of computational techniques. Also, the importance of energy-efficient information technology for environmentally conscious and feasible information technology is a hot topic because a computer faces environmental challenges at every stage of its life, from development to use to disposal. Due to changing environmental conditions, corporations have prioritized carbon emissions in procurement and transportation, which have the highest carbon impact. To encourage potential suppliers to adopt environmentally friendly practices, green criteria should be introduced into public procurement. Environmentally friendly corporate practices and environmental conservation are considered significant tools through public procurement. Techniques for green procurement and production procedures have recently been correlated with the concept of computational techniques of green procurement and production, owing to the increased emphasis on the concept of computational approaches. For eco-friendly procurement and production operations, computational approaches are inculcated and presented in the same way that they are for green procurement and manufacturing. From this perspective, this chapter presents a methodology for merging computational techniques into green procurement and production in public procurement in the form of green computing.}
}
@article{LU2023100154,
title = {Developing a weather prediction project-based machine learning course in facilitating AI learning among high school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100154},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000334},
author = {Wen-Yen Lu and Szu-Chun Fan},
keywords = {Artificial intelligence, Machine learning, Computational thinking, Secondary education},
abstract = {The rapid growth of artificial intelligence (AI) technology has changed lifestyles, work patterns, and educational approaches. However, courses that can guide students through the practical applications of AI technology are still scarce in K-12 education. This study aimed to develop a project-based machine learning (ML) course for the implementation of AI technology. The core idea of this course, which focused on the supervised learning of AI ML technology, was designed based on the project of weather prediction. Furthermore, data collection and status display were realized using various hardware devices such as Arduino and sensors, whereas ML algorithms were implemented in Python programming language. A total of 68 eleventh-grade senior high school students from a public school in Southern Taiwan participated in this study. The main variables included understanding AI concepts, computational thinking (CT), and learning attitude. Data were analyzed using quantitative statistics, including descriptive statistics, t-test, and analysis of covariance, supplemented with qualitative data. Based on the findings, the following conclusions were drawn: (1) the proposed course on the implementation of ML helps students understand the basic concepts of AI; (2) students demonstrate a significant improvement in CT skills after attending this course; (3) although the students’ attitude toward learning AI shows no significant change after attending this course, their overall view for it is positive; (4) contrary to their learning attitude, the CT skills among the students with different capabilities of learning AI are significantly dissimilar. Overall, the machine-learning implementation course developed in this study can serve as a reference for promoting AI education in the future. However, considering learners’ prior knowledge in programming, setting up appropriate learning scaffolding for them, and providing them with more examples of the applications of AI in real-life scenarios is still necessary when conducting the course for improving the students’ attitude toward AI.}
}
@article{FLEMING2024896,
title = {Quality space computations for consciousness},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {896-906},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001657},
author = {Stephen M. Fleming and Nicholas Shea},
keywords = {consciousness, sensory states, quality space, similarity, neural representation},
abstract = {The quality space hypothesis about conscious experience proposes that conscious sensory states are experienced in relation to other possible sensory states. For instance, the colour red is experienced as being more like orange, and less like green or blue. Recent empirical findings suggest that subjective similarity space can be explained in terms of similarities in neural activation patterns. Here, we consider how localist, workspace, and higher-order theories of consciousness can accommodate claims about the qualitative character of experience and functionally support a quality space. We review existing empirical evidence for each of these positions, and highlight novel experimental tools, such as altering local activation spaces via brain stimulation or behavioural training, that can distinguish these accounts.}
}
@article{KAVGA2023102837,
title = {Design and simulation of a greenhouse in a computational environment (ANSYS/FLUENT) and an automatic control system in a LABVIEW environment},
journal = {Simulation Modelling Practice and Theory},
volume = {129},
pages = {102837},
year = {2023},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2023.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X23001144},
author = {Angeliki Kavga and Vasileios Thomopoulos and Evangelos Pischinas and Dimitris Tsipianitis and Pantelis Nikolakopoulos},
keywords = {Greenhouses, Digital twin, Control, Arduino, Fuzzy logic},
abstract = {Greenhouses have been used to increase agricultural production. With the development of technology, they can now be automated. Many studies have been done on the automatic control of their microclimate, from intelligent control systems to Computational Fluid Dynamics (CFD) analyses, with the main purpose of optimal control of the microclimate and at the same time saving energy. This research concerns the process of modeling, design, and simulation of an automatic control system in greenhouses. More specifically, a virtual greenhouse (digital twin) is designed, and in it, the natural phenomena that take place in a real greenhouse are simulated. The program used for the simulations is Ansys FLUENT, suitable for CFD analyses. A branch of artificial intelligence, fuzzy logic, which is a method of replicating human thinking was utilized. To find the optimal control system, four fuzzy controllers were tested, and the optimal control system that the simulations indicated was implemented on an Arduino board using the LabVIEW program. The control was done at the temperature inside the greenhouse, with real weather data from a real greenhouse.}
}
@article{DENEYS20081248,
title = {Conflict monitoring in dual process theories of thinking},
journal = {Cognition},
volume = {106},
number = {3},
pages = {1248-1299},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2007.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010027707001576},
author = {Wim {De Neys} and Tamara Glumicic},
keywords = {Reasoning, Decision making, Heuristics and biases, Conflict monitoring, Dual process theories},
abstract = {Popular dual process theories have characterized human thinking as an interplay between an intuitive-heuristic and demanding-analytic reasoning process. Although monitoring the output of the two systems for conflict is crucial to avoid decision making errors there are some widely different views on the efficiency of the process. Kahneman [Kahneman, D. (2002). Maps of bounded rationality: A perspective on intuitive judgement and choice. Nobel Prize Lecture. Retrieved January 11, 2006, from: http://nobelprize.org/nobel_prizes/economics/laureates/2002/kahnemann-lecture.pdf] and Evans [Evans, J. St. B. T. (1984). Heuristic and analytic processing in reasoning. British Journal of Psychology, 75, 451–468], for example, claim that the monitoring of the heuristic system is typically quite lax whereas others such as Sloman [Sloman, S. A. (1996). The empirical case for two systems of reasoning. Psychological Bulletin, 119, 3–22] and Epstein [Epstein, S. (1994). Integration of the cognitive and psychodynamic unconscious. American Psychologists, 49, 709–724] claim it is flawless and people typically experience a struggle between what they “know” and “feel” in case of a conflict. The present study contrasted these views. Participants solved classic base rate neglect problems while thinking aloud. In these problems a stereotypical description cues a response that conflicts with the response based on the analytic base rate information. Verbal protocols showed no direct evidence for an explicitly experienced conflict. As Kahneman and Evans predicted, participants hardly ever mentioned the base rates and seemed to base their judgment exclusively on heuristic reasoning. However, more implicit measures of conflict detection such as participants’ retrieval of the base rate information in an unannounced recall test, decision making latencies, and the tendency to review the base rates indicated that the base rates had been thoroughly processed. On control problems where base rates and description did not conflict this was not the case. Results suggest that whereas the popular characterization of conflict detection as an actively experienced struggle can be questioned there is nevertheless evidence for Sloman’s and Epstein’s basic claim about the flawless operation of the monitoring. Whenever the base rates and description disagree people will detect this conflict and consequently redirect attention towards a deeper processing of the base rates. Implications for the dual process framework and the rationality debate are discussed.}
}
@article{HELVACIOZACAR2023100560,
title = {Centering and decentering children in computing through joint activity at a computational science exhibit},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100560},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100560},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000782},
author = {Basak {Helvaci Ozacar} and Stephanie Hladik},
keywords = {Public computing, Joint activity, Science museums, Facilitation, Computer science education, Adult–child interactions},
abstract = {In this paper, we offer an investigation of the nuances of adult–child interactions at a computational science exhibit in a Canadian science museum. The theoretical lens of joint activity allows us to understand learning to code as a collaborative, intergenerational activity distributed between learners, educators, exhibit hardware, and the computer code itself. Specifically, we attend to the ways in which children can be centered at the computational science exhibit (moments in which their goals, histories, and desires are driving the exhibit’s interaction) by the actions of parents and museum facilitators or be decentered by them. Through qualitative analysis of video-recorded interactions of adults and children at the exhibit, we present categories of centering or decentering interactions while preserving the nuance and ambiguity involved in sociocultural contexts of learning. We also highlight two cases that illustrate the complexity and heterogeneity involved in facilitating a computational science exhibit. We close with a discussion and a call to eschew technocentric views of computing education that focus solely on device-level engagement and instead attend to the complex human–human interactions involved in computing education.}
}
@article{WEBER2014679,
title = {Does “thinking about thinking” interfere with memory? An experimental memory study in obsessive–compulsive disorder},
journal = {Journal of Anxiety Disorders},
volume = {28},
number = {7},
pages = {679-686},
year = {2014},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2014.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0887618514001029},
author = {Friederike Weber and Walter Hauke and Ina Jahn and Katarina Stengler and Hubertus Himmerich and Michael Zaudig and Cornelia Exner},
keywords = {Obsessive–compulsive disorder, Verbal memory, Cognitive self-consciousness, Proactive interference},
abstract = {Neuropsychological assessments of participants with obsessive–compulsive disorder (OCD) indicate impaired verbal memory if to be remembered material has to be organized. People with OCD also tend to focus their attention on their thoughts (heightened cognitive self-consciousness). We tested the hypothesis that cognitive self-consciousness causes verbal memory deficits by provoking a division of attention between study task and thoughts. Thirty-six participants with OCD, 36 matched healthy controls and 36 participants with major depressive disorder (MDD) learned under proactive interference in three study conditions: single-task condition, condition with heightened cognitive self-consciousness and condition with an external secondary task. Memory was impaired in the cognitive self-consciousness condition compared to both other conditions. Independent of condition, participants with OCD showed a reduced memory performance compared to healthy controls, but did not differ from participants with MDD. Our results are in line with the hypothesis that cognitive self-consciousness causes memory impairment.}
}
@incollection{PREISIG20121682,
title = {Thinking Ontologies},
editor = {Iftekhar A. Karimi and Rajagopalan Srinivasan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {31},
pages = {1682-1686},
year = {2012},
booktitle = {11th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-59506-5.50167-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044459506550167X},
author = {Heinz A. Preisig},
keywords = {computer-aided modelling, software tools, process engineering},
abstract = {Ontologies are a means of abstraction and concentrating information. Whilst it has mostly found acceptance in the computer and information technology domain, it is an excellent thinking pattern promoting a more structural approach to chemical engineering problems on all levels, starting with the representation of functionalities, their combination to form processing units and combined again as whole plants. The concepts helps in constructing models that adhere to basic concepts as they are the foundation for physical processes: the conservation principles and the description of transport phenomena. The material models, the interaction between different chemical species or biological species form a knowledge framework suitable in in case of biological processes also intensively mapped into ontologies. When properly used, The high density of information, makes it easy to check consistency and the consistent use in all applications yields a framework that produces reliable, checkable results quickly and efficiently and consistency across applications that in the past have been without any information link.}
}
@article{QFIASCO201836,
journal = {Artificial Intelligence},
volume = {260},
pages = {36-41},
year = {2018},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2018.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0004370218301528},
author = {Flash qFiasco}
}
@article{REGIER2019235,
title = {Choice certainty and deliberative thinking in discrete choice experiments. A theoretical and empirical investigation},
journal = {Journal of Economic Behavior & Organization},
volume = {164},
pages = {235-255},
year = {2019},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2019.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0167268119301830},
author = {Dean A. Regier and Jonathan Sicsic and Verity Watson},
keywords = {Choice certainty, Discrete choice experiments, Hypothetical bias, Information processing, Stated preferences, Survey engagement},
abstract = {Resource allocation decisions require information about individuals' preferences for goods and services. Survey based stated preference methods, such as discrete choice experiments (DCEs), are used to elicit preferences for non-market goods. A critique of stated preference research is that respondents to hypothetical surveys may not provide careful and thoughtful responses that reveal rational preferences. Choice certainty has been used to measure survey respondents' task engagement. Researchers assume that respondents who are certain about their choices provide deliberative responses. In the case of DCE, we argue that the variability of choice certainty is also important. We present a novel framework to identify thoughtful / deliberative respondents. The framework combines respondents’ certainty with their variability in certainty across a set of choice tasks. We test our framework empirically using data from two case studies. We find respondents with higher mean certainty and variability (i) seldom use decision heuristics, (ii) are more likely to have monotonic preferences, (iii) have longer response times, (iv) make choices that have higher interval validity, and (v) have higher choice consistency. We discuss the relevance of alternative ex-post calibration strategies with a view to improve the precision and accuracy of DCE-based welfare estimates.}
}
@article{WEST20121551,
title = {The importance of quantitative systemic thinking in medicine},
journal = {The Lancet},
volume = {379},
number = {9825},
pages = {1551-1559},
year = {2012},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(12)60281-5},
url = {https://www.sciencedirect.com/science/article/pii/S0140673612602815},
author = {Geoffrey B West},
abstract = {Summary
The study and practice of medicine could benefit from an enhanced engagement with the new perspectives provided by the emerging areas of complexity science and systems biology. A more integrated, systemic approach is needed to fully understand the processes of health, disease, and dysfunction, and the many challenges in medical research and education. Integral to this approach is the search for a quantitative, predictive, multilevel, theoretical conceptual framework that both complements the present approaches and stimulates a more integrated research agenda that will lead to novel questions and experimental programmes. As examples, the importance of network structures and scaling laws are discussed for the development of a broad, quantitative, mathematical understanding of issues that are important in health, including ageing and mortality, sleep, growth, circulatory systems, and drug doses. A common theme is the importance of understanding the quantifiable determinants of the baseline scale of life, and developing corresponding parameters that define the average, idealised, healthy individual.}
}
@article{DELUCA2021101553,
title = {The development of machine intelligence in a computational universe},
journal = {Technology in Society},
volume = {65},
pages = {101553},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101553},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000282},
author = {Gabriele {De Luca}},
keywords = {Machine intelligence, Computational universe, Bohmian mechanics, History of AI, Mechanical rationalism},
abstract = {The paper is dedicated to the study of the theoretical and technological development that occurred, in particular in the XX century, in the sector of Artificial Intelligence. According to the theoretical framework of mechanical rationalism, we study how the development of machine intelligence is a continuation, through different means, of the old process of outsourcing of cognitive activities by humans onto parts of their physical environments. Because of this process, an increasingly larger portion of the non-human environment performs perceptive and cognitive activities. From this follows that machine systems, not necessarily humans anymore, are the components of the physical environment that perform measurements on the universe of which the humans are also components. We suggest that the scientific discussion on the topic of AI development could be framed in the context of a more general phenomenon of an increase in the computational and perceptual capabilities of the physical universe, as opposed to a merely human and technological problem. This is because, ever so slightly, humans are being removed from the cognitive processes of technological systems they created, which continue to perceive and think autonomously. The act of machine cognition, or rather, of machine measurements, causes an effect on the environment in which humans live, and ever more so than the human measurements. Finally, we discuss the current approach to the development of viable AI systems that aim at increasing the reciprocal intelligence of humans and machines, rather than the replacement of the former's cognitive faculties by the latter.}
}
@article{KERN2000341,
title = {Structuring financial statement analysis projects to enhance critical thinking skills development},
journal = {Journal of Accounting Education},
volume = {18},
number = {4},
pages = {341-353},
year = {2000},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(01)00005-7},
url = {https://www.sciencedirect.com/science/article/pii/S0748575101000057},
author = {Beth B. Kern},
keywords = {Financial statement analysis, Critical thinking},
abstract = {This paper documents a method of structuring financial statement analysis projects to enhance the development of students’ critical thinking skills. The project is structured in a cooperative learning framework in which a student accesses financial statement information from the World Wide Web, performs a financial statement analysis, and then engages in an exercise with other students who have analyzed firms in the same industry. Both the individual and team phases of the project offer opportunities for students to develop several important critical thinking skills.}
}
@article{KANGAS2004101,
title = {The role of passive electrical analogs in H.T. Odum’s systems thinking},
journal = {Ecological Modelling},
volume = {178},
number = {1},
pages = {101-106},
year = {2004},
note = {Through the MACROSCOPE: the legacy of H.T. Odum},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2003.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0304380003005313},
author = {Patrick Kangas}
}
@incollection{HARTSON2012251,
title = {Chapter 7 - Design Thinking, Ideation, and Sketching},
editor = {Rex Hartson and Partha S. Pyla},
booktitle = {The UX Book},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {251-297},
year = {2012},
isbn = {978-0-12-385241-0},
doi = {https://doi.org/10.1016/B978-0-12-385241-0.00007-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852410000075},
author = {Rex Hartson and Partha S. Pyla}
}
@article{TUSHAR2020117141,
title = {Exploiting design thinking to improve energy efficiency of buildings},
journal = {Energy},
volume = {197},
pages = {117141},
year = {2020},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.117141},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220302486},
author = {Wayes Tushar and Lan Lan and Chathura Withanage and Hui En Karen Sng and Chau Yuen and Kristin L. Wood and Tapan Kumar Saha},
keywords = {Design thinking, design innovation, building, energy conservation, smart energy management},
abstract = {This paper studies an interdisciplinary approach for improving building energy efficiency. In particular, the proposed approach integrates design innovation (DI) techniques, existing energy audit methods (EAM), and data-driven & engineering modeling techniques (DET) in the process of sustainable smart energy system design. From this perspective, DI methods are extended and modified to suit the content of sustainable smart energy system design and a DI 4D (Discover, Define, Develop and Deliver) framework is introduced to guide the design process. The motivation behind and the implementation procedure of each of the DI phases is explained separately, and the process of integrating DI methods, EAM and DET in developing a sustainable smart energy system is demonstrated. The proposed approach is deployed within the campus of a tertiary education institution to show its effectiveness in designing a smart sustainable energy system.}
}
@article{DENOBEL2024109011,
title = {Biophysics-inspired spike rate adaptation for computationally efficient phenomenological nerve modeling},
journal = {Hearing Research},
volume = {447},
pages = {109011},
year = {2024},
issn = {0378-5955},
doi = {https://doi.org/10.1016/j.heares.2024.109011},
url = {https://www.sciencedirect.com/science/article/pii/S0378595524000649},
author = {Jacob {de Nobel} and Savine S.M. Martens and Jeroen J. Briaire and Thomas H.W. Bäck and Anna V. Kononova and Johan H.M. Frijns},
keywords = {Neural model, Spike rate adaptation, Auditory nerve, Cochlear implants, Optimization, Evolutionary algorithms},
abstract = {This study introduces and evaluates the PHAST+ model, part of a computational framework designed to simulate the behavior of auditory nerve fibers in response to the electrical stimulation from a cochlear implant. PHAST+ incorporates a highly efficient method for calculating accommodation and adaptation, making it particularly suited for simulations over extended stimulus durations. The proposed method uses a leaky integrator inspired by classic biophysical nerve models. Through evaluation against single-fiber animal data, our findings demonstrate the model’s effectiveness across various stimuli, including short pulse trains with variable amplitudes and rates. Notably, the PHAST+ model performs better than its predecessor, PHAST (a phenomenological model by van Gendt et al.), particularly in simulations of prolonged neural responses. While PHAST+ is optimized primarily on spike rate decay, it shows good behavior on several other neural measures, such as vector strength and degree of adaptation. The future implications of this research are promising. PHAST+ drastically reduces the computational burden to allow the real-time simulation of neural behavior over extended periods, opening the door to future simulations of psychophysical experiments and multi-electrode stimuli for evaluating novel speech-coding strategies for cochlear implants.}
}
@article{DUMAS20181,
title = {Relational reasoning and divergent thinking: An examination of the threshold hypothesis with quantile regression},
journal = {Contemporary Educational Psychology},
volume = {53},
pages = {1-14},
year = {2018},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2018.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X17304526},
author = {Denis Dumas},
abstract = {Relational reasoning (RR) and divergent thinking (DT) are two critical antecedents of creative problem solving, but the relation between them is not currently well understood psychologically, limiting efforts to support these constructs through education. The threshold hypothesis (TH) is currently the dominant explanation for the relation between RR and DT, and posits that RR fundamentally supports DT, but only up to a point. In this study, quantile regression was used to test the TH among RR and two separate dimensions of DT: originality and fluency. Results generally supported the TH in regards to originality, with RR being significantly positively related to originality, but only in students at or below the median of the originality distribution. However, the TH was not upheld for fluency, which was only significantly predicted by RR at the top (i.e. 9th decile) of the fluency distribution. In general, results suggest that direct instructional intervention of RR strategies may be most supportive of creativity for those students who are simultaneously highly fluent but low-original thinkers.}
}
@article{CHOPARD2024102115,
title = {Preface—From the modeling of social behavior to computational diplomacy},
journal = {Journal of Computational Science},
volume = {77},
pages = {102115},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102115},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001758},
author = {Bastien Chopard and Stephan Davishofer and Dirk Helbing and Nicolas Levrat and Peter Sloot}
}
@article{ZHANG2001883,
title = {Thinking styles and personality types revisited},
journal = {Personality and Individual Differences},
volume = {31},
number = {6},
pages = {883-894},
year = {2001},
issn = {0191-8869},
doi = {https://doi.org/10.1016/S0191-8869(00)00189-6},
url = {https://www.sciencedirect.com/science/article/pii/S0191886900001896},
author = {Li-fang Zhang},
keywords = {Thinking styles, Personality types},
abstract = {This study was designed to test the efficacy of the Short-Version Self-Directed Search (SVSDS) as well as to further investigate the relationships between thinking styles and personality types. Seven hundred and eighty-nine students (average 20 years) from two research-oriented universities from mainland China responded to the Thinking Styles Inventory and the SVSDS. Two major findings are: (1) the SVSDS is composed of six scales with good internal consistency, each assessing one of Holland’s six personality types; factor analysis yielded a two-factor solution, with one factor being characterized by people who like to work with things and data, and the other being dominated by people who like to work with people and ideas; and (2) thinking styles and personality types are related in predictable ways. Implications of these findings for test users, including teachers and counselors, are discussed.}
}
@article{ELLIOTT2024307a,
title = {Utilizing a structured undergraduate research framework to improve student success and mentoring capacity in a computational biophysics lab},
journal = {Biophysical Journal},
volume = {123},
number = {3, Supplement 1},
pages = {307a},
year = {2024},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2023.11.1898},
url = {https://www.sciencedirect.com/science/article/pii/S0006349523025985},
author = {Truitt J. Elliott and Jonathan Briganti and Anne M. Brown}
}
@article{WOLFENGAGEN2024101183,
title = {Building a cognitive system based on process interaction},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101183},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101183},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001171},
author = {Viacheslav E. Wolfengagen and Larisa Ismailova and Sergey Kosikov},
keywords = {Computational thinking, Applicative prestructure, Theory of combinators, Cognitive modeling, Computation process, Interaction, Semantic modeling},
abstract = {According to modern notions, computing is not separable from cognitive modeling and activity. This paper continues the tradition of the uniform approach and proposes a small number of general mechanisms that cope with the main known effects of computing as a science — the interaction of objects-as-processes, the interaction of processes with the environment, generalized interaction. As shown, the applicative prestructure (objects-as-processes, application) generates an applicative structure (processes, application, values), which ensures the generation of the result — the value of interactions, enabling the process of evaluation. The theory of combinators is used as the main (meta)mathematical means. A diagram mechanism has been developed that implements the emerging applicative computational system of object interaction and reflects the arity of accompanying the induced information processes. The processes are bidirectional in nature, both with a decrease in arity – reduction, and with an increase in arity – expansion.}
}
@article{FLACH2017612,
title = {Supporting productive thinking: The semiotic context for Cognitive Systems Engineering (CSE)},
journal = {Applied Ergonomics},
volume = {59},
pages = {612-624},
year = {2017},
note = {The Legacy of Jens Rasmussen},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2015.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0003687015300739},
author = {John Flach},
keywords = {Cognitive Systems Engineering, Abstraction Hierarchy, Work domain analysis, Decision Ladder, Skills-Rules-Knowledge Model, Ecological Interface Design, Proactive Risk Management},
abstract = {The central thesis of this paper is that Rasmussen framed his approach to Cognitive Systems Engineering from the perspective of a Triadic Semiotic Model. This frame became the context for integrating multiple intellectual threads including Control Theory, Information Theory, Ecological Psychology, and Gestalt Psychology into a coherent theoretical framework. The case is made that the triadic semiotic framework is essential for a complete appreciation of the constructs that were central to Rasmussen's approach: Abstraction Hierarchy, Skill-Rules-Knowledge Model, Ecological Interface Design, and Proactive Risk Management.}
}
@incollection{ROESE20171,
title = {Chapter One - The Functional Theory of Counterfactual Thinking: New Evidence, New Challenges, New Insights},
editor = {James M. Olson},
series = {Advances in Experimental Social Psychology},
publisher = {Academic Press},
volume = {56},
pages = {1-79},
year = {2017},
issn = {0065-2601},
doi = {https://doi.org/10.1016/bs.aesp.2017.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065260117300187},
author = {Neal J. Roese and Kai Epstude},
keywords = {Counterfactual, Regret, Mental simulation, Goal, Regulatory, Episodic, Self-regulation, Affect, Emotion, Attribution, Orbitofrontal, Nucleus accumbens, Insula, Functional theory, Mental models},
abstract = {Thinking about what might have been—counterfactual thinking—is a common feature of the mental landscape. Key questions about counterfactual thinking center on why and how they occur and what downstream cognitive and behavioral outcomes they engender. The functional theory of counterfactual thinking aims to answer these and other questions by drawing connections to goal cognition and by specifying distinct functions that counterfactuals may serve, including preparing for goal pursuit and regulating affect. Since the publication of our last theoretical statement (Epstude & Roese, 2008), numerous lines of empirical evidence support, or are rendered more readily understandable, when glimpsed through the lens of the functional theory. However, other lines of evidence have called into question the very basis of the theory. We integrate a broad range of findings spanning several psychological disciplines so as to present an updated version of the functional theory. We integrate findings from social psychology, cognitive neuroscience, developmental psychology, clinical psychology, and health psychology that support the claim that episodic counterfactual thoughts are geared mainly toward preparation and goal striving and are generally beneficial for individuals. Counterfactuals may influence behavior via either a content-specific pathway (in which the counterfactual insight informs behavior change) or a content-neutral pathway (in which the negative affect from the counterfactual motivates generic behavior change). Challenges to the functional theory of counterfactual thinking center on whether counterfactuals typically cohere to a structural form amenable to goal striving and whether behavioral consequences are mainly dysfunctional rather than functional. Integrating both supporting and challenging evidence, we offer a new theoretical synthesis intended to clarify the literature and guide future research in multiple disciplines of psychology.}
}
@article{BAYAGA2024100491,
title = {Enhancing M Enhancing mathematics problem-solving skills in AI-driven environment: Integrated SEM-neural network approach},
journal = {Computers in Human Behavior Reports},
volume = {16},
pages = {100491},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100491},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001246},
author = {Anass Bayaga},
keywords = {Gamification, AI, Digitisation, Education, Higher-order thinking, Game-based learning},
abstract = {This study explores the nexus of gamification, artificial intelligence (AI), and mathematics cognition. Sample size of 71 responded in an intervention using game-based learning (GBL) approach. The purpose of designing the GBL was to enhance computational thinking and mathematical skills. The research employed multigroup partial least squares structural equation modelling (MGA-PLS-SEM) and artificial neural networks (ANN) through multilayer perceptron (MLP) as data analysis technique. The findings showed significant positive influence on class engagement, attitudes toward mathematics, as well as student performance. The analysis also revealed gender-related variations, which affirmed the model's consistency across diverse groups. The study validated the hypothesis and consequently advocated for the transformative potential of gamification, in preparation of 21st-century learners for AI-driven digital landscape. The implications are to ensure the integration of gamified elements into educational strategies, benefiting educators, curriculum developers, and policymakers resonating strongly for educators, curriculum developers, and policymakers.}
}
@article{HAO2017237,
title = {A function-based computational method for design concept evaluation},
journal = {Advanced Engineering Informatics},
volume = {32},
pages = {237-247},
year = {2017},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2017.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S1474034616303664},
author = {Jia Hao and Qiangfu Zhao and Yan Yan},
keywords = {Concept generation, Evaluation metrics, Function basis, Word-embedding},
abstract = {Concept generation is an indispensable step of innovation design. However, the limited knowledge and design thinking fixation of designers often impede the generation of novel design concepts. Computational tools can be a necessary supplement for designers. They can generate a big number of design concepts based on an existing knowledge base. For filtering these design concepts, this work presents a computational measurement of novelty, feasibility and diversity based on 500,000 granted patents. First, about 1700 functional terms (terminologies) are mapped to high dimensional vectors (100 dimensional space) by word embedding technique. The resulted database is knowledge base-I (KB-I). Then, we adopt circular convolution to convert patents into high dimensional vectors. The resulted database is KB-II. Based on the two knowledge bases, the computational definitions of novelty, feasibility and diversity are developed. We conduct six experiments based on KB-II, a random dataset and a real product dataset, and the results show that these metrics can be used to roughly filter a big number of design concepts, and then expert-based method can be further used. This work provides a computational framework for measuring the novelty, feasibility and diversity of design concept.}
}
@article{CARNEY2014200,
title = {Using computational modeling to assess the impact of clinical decision support on cancer screening improvement strategies within the community health centers},
journal = {Journal of Biomedical Informatics},
volume = {51},
pages = {200-209},
year = {2014},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2014.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S1532046414001361},
author = {Timothy Jay Carney and Geoffrey P. Morgan and Josette Jones and Anna M. McDaniel and Michael Weaver and Bryan Weiner and David A. Haggstrom},
keywords = {Computational, Simulation, Modeling, Community health center, Systems-thinking, Cancer screening},
abstract = {Our conceptual model demonstrates our goal to investigate the impact of clinical decision support (CDS) utilization on cancer screening improvement strategies in the community health care (CHC) setting. We employed a dual modeling technique using both statistical and computational modeling to evaluate impact. Our statistical model used the Spearman’s Rho test to evaluate the strength of relationship between our proximal outcome measures (CDS utilization) against our distal outcome measure (provider self-reported cancer screening improvement). Our computational model relied on network evolution theory and made use of a tool called Construct-TM to model the use of CDS measured by the rate of organizational learning. We employed the use of previously collected survey data from community health centers Cancer Health Disparities Collaborative (HDCC). Our intent is to demonstrate the added valued gained by using a computational modeling tool in conjunction with a statistical analysis when evaluating the impact a health information technology, in the form of CDS, on health care quality process outcomes such as facility-level screening improvement. Significant simulated disparities in organizational learning over time were observed between community health centers beginning the simulation with high and low clinical decision support capability.}
}
@article{HENRIQUE2023100546,
title = {Who creates our computational worlds? A review of Critically Conscious Computing: Methods for secondary education},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100546},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100546},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000642},
author = {Brendan Henrique and Collette Roberto and Michelle Hoda Wilkerson},
keywords = {Computational thinking, Computational literacy, Computer science education, Critical computing, Critical computational literacy, Critical computer science education},
abstract = {Despite growing attention to the social and ethical dimensions of Computer Science (CS), few practical resources exist to teach and learn CS through the lens of social responsibility. In Critically Conscious Computing, Ko and colleagues provide a comprehensive overview of foundational computing concepts with a sharp and needed critical perspective. In this review, we attend not only to the content of the book, but also to its format as a free, online, “living” text. The book is commendable for its tight integration of technical and socio-critical aspects of computing, approachable conversational style, and collection of flexible and practical resources for teachers. It would benefit from refinement of the integration chapters and a more explicit model for how educators themselves can approach new or different CS concepts through a critical frame. Overall, we strongly recommend this book for CS Educators at all levels for its balance of depth and practicality.}
}
@article{HEMERY2024114432,
title = {On a model of online analog computation in the cell with absolute functional robustness: Algebraic characterization, function compiler and error control},
journal = {Theoretical Computer Science},
volume = {991},
pages = {114432},
year = {2024},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2024.114432},
url = {https://www.sciencedirect.com/science/article/pii/S0304397524000471},
author = {Mathieu Hemery and François Fages},
keywords = {Analog computation, Online computation, Robustness, Stabilization, Algebraic functions, Chemical reaction networks, Chemical computation},
abstract = {The Turing completeness of continuous Chemical Reaction Networks (CRNs) states that any computable real function can be computed by a continuous CRN on a finite set of molecular species, possibly restricted to elementary reactions, i.e. with at most two reactants and mass action law kinetics. In this paper, we introduce a more stringent notion of robust online analog computation, called Absolute Functional Robustness (AFR), for the CRNs that stabilize the concentration values of some output species to the result of one function of the input species concentrations, while allowing arbitrary perturbations for intermediate and output species throughout the attraction basin. We prove that the set of real functions stabilized by a CRN with mass action law kinetics is precisely the set of real algebraic functions. Based on this result, we present a compiler which takes as input any algebraic function (defined by one polynomial and one point for selecting one branch of the algebraic curve defined by the polynomial) and generates an abstract CRN to stabilize it. Furthermore, we provide error bounds to estimate and control the error of an unperturbed system, under the assumption that the environment inputs are driven by k-Lipschitz functions.}
}
@article{NA202250,
title = {Computational mechanisms underlying illusion of control in delusional individuals},
journal = {Schizophrenia Research},
volume = {245},
pages = {50-58},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.01.054},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422000652},
author = {Soojung Na and Sylvia Blackmore and Dongil Chung and Madeline O'Brien and Sarah M. Banker and Matthew Heflin and Vincenzo G. Fiore and Xiaosi Gu},
keywords = {Delusion, Social controllability, Illusion of control, Beliefs, Schizophrenia, Computational psychiatry},
abstract = {Humans navigate complex situations that require the accurate estimation of the controllability of the environment. Aberrant controllability computation might lead to maladaptive behaviors and poor mental health outcomes. Illusion of control, which refers to a heightened sense of control while the environment is uncontrollable, is one such manifestation and has been conceptually associated with delusional ideation. Nevertheless, this association has not yet been formally characterized in a computational framework. To address this, we used a computational psychiatry approach to quantify illusion of control in human participants with high (n = 125) or low (n = 126) trait delusion. Participants played a two-party exchange game in which their choices either did (“Controllable condition”) or did not (“Uncontrollable condition”) influence the future monetary offers made by simulated partners. We found that the two groups behaved similarly in model-agnostic measures (i.e., offer size, rejection rate). However, computational modeling revealed that compared to the low trait delusion group, the high delusion group overestimated their influence (“expected influence” parameter) over the offers made by their partners under the Uncontrollable condition. Highly delusional individuals also reported a stronger sense of control than those with low trait delusion in the Uncontrollable condition. Furthermore, the expected influence parameter and self-reported beliefs about controllability were significantly correlated in the Controllable condition in individuals with low trait delusion, whereas this relationship was diminished in those with high trait delusion. Collectively, these findings demonstrate that delusional ideation is associated with aberrant computation of and belief about environmental controllability, as well as a belief-behavior disconnect.}
}
@incollection{DUNN2023461,
title = {17 - Thinking in systems: sustainable design of nano-enabled agriculture informed by life cycle assessment},
editor = {Peng Zhang and Iseult Lynch and Jason C. White and Richard D. Handy},
booktitle = {Nano-Enabled Sustainable and Precision Agriculture},
publisher = {Academic Press},
pages = {461-491},
year = {2023},
isbn = {978-0-323-91233-4},
doi = {https://doi.org/10.1016/B978-0-323-91233-4.00019-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323912334000193},
author = {Patrick J. Dunn and Leila Pourzahedi and Thomas L. Theis and Leanne M. Gilbertson},
keywords = {Agriculture, food, environment, life cycle assessment, trade-off, production},
abstract = {Food systems are among the most complex systems devised by humankind with multiple stages involved in the production, marketing, and distribution, as well as the preparation and consumption of food.}
}
@article{HALES2023105083,
title = {Computational approaches to modeling gambling behaviour: Opportunities for understanding disordered gambling},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {147},
pages = {105083},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105083},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423000520},
author = {C.A. Hales and L. Clark and C.A. Winstanley},
keywords = {Gambling disorder, Reinforcement learning, Drift diffusion modeling, Bayesian, Computational psychiatry},
abstract = {Computational modeling has become an important tool in neuroscience and psychiatry research to provide insight into the cognitive processes underlying normal and pathological behavior. There are two modeling frameworks, reinforcement learning (RL) and drift diffusion modeling (DDM), that are well-developed in cognitive science, and have begun to be applied to Gambling Disorder. RL models focus on explaining how an agent uses reward to learn about the environment and make decisions based on outcomes. The DDM is a binary choice framework that breaks down decision making into psychologically meaningful components based on choice reaction time analyses. Both approaches have begun to yield insight into aspects of cognition that are important for, but not unique to, gambling, and thus relevant to the development of Gambling Disorder. However, these approaches also oversimplify or neglect various aspects of decision making seen in real-world gambling behavior. Gambling Disorder presents an opportunity for ‘bespoke’ modeling approaches to consider these neglected components. In this review, we discuss studies that have used RL and DDM frameworks to investigate some of the key cognitive components in gambling and Gambling Disorder. We also include an overview of Bayesian models, a methodology that could be useful for more tailored modeling approaches. We highlight areas in which computational modeling could enable progression in the investigation of the cognitive mechanisms relevant to gambling.}
}
@article{PAGANI2009382,
title = {Roadmapping 3G mobile TV: Strategic thinking and scenario planning through repeated cross-impact handling},
journal = {Technological Forecasting and Social Change},
volume = {76},
number = {3},
pages = {382-395},
year = {2009},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2008.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0040162508001303},
author = {Margherita Pagani},
keywords = {Scenario planning, Mobile TV, Strategic thinking, 3G wireless, Impact factor analysis},
abstract = {In order to deal with growing uncertainties emerging in the 3G wireless industry and to preserve their competitiveness, managers involved in the wireless value network should identify future success very early and develop their strategic planning on time. This study, based on a Scenario Evaluation and Analysis through Repeated Cross impact Handling, allows the generation of both qualitative and quantitative scenarios and can be used as an operative planning tool. The dynamic forces driving the scenario are based on the main principles of system thinking and multiple features. The probabilistic data have been elicited with the help of 40 executives in USA and Europe working for companies in the different phases of the wireless value chain. Findings allow to identify basic trends and uncertainties useful to develop corporate or business strategies.}
}
@incollection{DELLAVERSANA201337,
title = {2 - Circular thinking in geophysics},
editor = {Paolo Dell'Aversana},
booktitle = {Cognition in Geosciences},
publisher = {EAGE},
address = {Oxford},
pages = {37-55},
year = {2013},
isbn = {978-90-73834-41-5},
url = {https://www.sciencedirect.com/science/article/pii/B9789073834415500098},
author = {Paolo Dell'Aversana}
}
@article{HE2024115752,
title = {Navigating the semantic space: Unraveling the structure of meaning in psychosis using different computational language models},
journal = {Psychiatry Research},
volume = {333},
pages = {115752},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115752},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000398},
author = {Rui He and Claudio Palominos and Han Zhang and Maria Francisca Alonso-Sánchez and Lena Palaniyappan and Wolfram Hinzen},
keywords = {Connected speech, Incoherence, Semantic similarity, Semantic perplexity, Language model, Loosening of associations, Schizophrenia},
abstract = {Speech in psychosis has long been ascribed as involving ‘loosening of associations’. We pursued the aim to elucidate its underlying cognitive mechanisms by analysing picture descriptions from 94 subjects (29 healthy controls, 18 participants at clinical high risk, 29 with first-episode psychosis, and 18 with chronic schizophrenia), using five language models with different computational architectures: FastText, which represents meaning non-contextually/statically; BERT, which represents contextual meaning sensitive to grammar and context; Infersent and SBERT, which provide sentential representations; and CLIP, which evaluates speech relative to a visual stimulus. These models were used to quantify semantic distances crossed between successive tokens/sentences, and semantic perplexity indicating unexpectedness in continuations. Results showed that, among patients, semantic similarity increased when measured with FastText, Infersent, and SBERT, while it decreased with CLIP and BERT. Higher perplexity was observed in first-episode psychosis. Static semantic measures were associated with clinically measured impoverishment of thought and referential semantic measures with disorganization. These patterns indicate a shrinking conceptual semantic space as represented by static language models, which co-occurs with a widening in the referential semantic space as represented by contextual models. This duality underlines the need to separate these two forms of meaning for understanding mechanisms involved in semantic change in psychosis.}
}
@article{TIEJUN2021120322,
title = {Implementation Status and Development Thinking on “Cloud National Examination” in China under the situation of “Online Anti-COVID-19 Epidemic”},
journal = {Technological Forecasting and Social Change},
volume = {162},
pages = {120322},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120322},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520311483},
author = {Zhu Tiejun},
keywords = {Cloud National Examination, Online Anti-COVID-19 Epidemic, Implementation Status, Analysis and discussion, Thinking and enlightenment, Empirical Research},
abstract = {At the beginning of 2020, China was first hit by the COVID-19 epidemic. In order to effectively prevent the spread of the virus, the Chinese people work online, teach online, study online and shop online from home, the whole country rapidly entered the era of “Cloud Anti-COVID-19 Epidemic”. With the passage of time, the Chinese relevant national examinations such as postgraduate second round examination, the senior high school and college entrance examination gradually approach. In response, some regions have launched the “Cloud National Examination” model. Based on this background, through the actual situation commentary and case proof of adaptive mock test of the “Cloud National Examination” that has been carried out in some areas and schools, this article analyzes, discusses, summarizes and deeply reflects the epidemic prevention and control, policy formulation, education care, scientific and technological progress, and social problems hidden behind the hot phenomenon of “Cloud National Examination”, so as to offer advice and suggestions for online education in such a special period. Also, to provide reference for the rapid deployment, preparation and implementation of “Cloud National Examination” by relevant education administrative departments, schools, candidates and their families, and supply the evaluation viewpoint and theoretical contribution for similar global problems and phenomena.}
}
@article{SORIANO2017443,
title = {Thinking, fast and slow: highlights from the 2016 BJA seminar on anaesthetic neurotoxicity and neuroplasticity},
journal = {British Journal of Anaesthesia},
volume = {119},
number = {3},
pages = {443-447},
year = {2017},
issn = {0007-0912},
doi = {https://doi.org/10.1093/bja/aex238},
url = {https://www.sciencedirect.com/science/article/pii/S0007091217537575},
author = {S.G. Soriano and L. Vutskits and V. Jevtovic-Todorovic and H.C. Hemmings}
}
@article{KARUNATHILAKE201970,
title = {Optimal renewable energy supply choices for net-zero ready buildings: A life cycle thinking approach under uncertainty},
journal = {Energy and Buildings},
volume = {201},
pages = {70-89},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2019.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0378778819309582},
author = {Hirushie Karunathilake and Kasun Hewage and Joshua Brinkerhoff and Rehan Sadiq},
keywords = {Hybrid renewable energy systems, Net-zero buildings, Optimisation, Fuzzy logic, Life cycle assessment},
abstract = {The increasing concerns about the environmental and economic impacts of conventional centralised energy generation and fossil fuel usage have prompted an interest in renewable-based decentralised energy systems. Implementing such systems at building level can facilitate the development of net-zero energy buildings. Energy system planning is a multi-faceted problem that involves technical, economic, environmental, and social dimensions, and affects multiple stakeholders at different levels. A multi-objective optimisation approach is needed to identify the optimal energy choices at building level, while paying attention to stakeholder priorities and other constraints. The objective of this study is to develop a model to identify the optimal mix of renewable energy (RE) while also accounting for uncertainties, which can be integrated at building level with life cycle thinking. A framework was proposed for planning an optimised hybrid RE system at building level to support the net-zero development goals. The optimisation model was developed considering the objectives of minimising energy system cost, maximising operational cost savings, minimising the life cycle environmental impacts, and maximising the RE fraction. A combinatorial optimisation approach was adopted to reflect the practical engineering aspects of energy planning problems based on technologies available in the market. The developed framework was demonstrated through a case study conducted for an average multi-unit residential buildings (MURB) located in British Columbia, Canada. The results indicated that under the defined stakeholder priorities and constraints, ground source heat pumps and solar photovoltaics (PV) are the optimal energy choices for MURB, and the optimal energy system combination supplied 44% of the building's energy demand through RE. The findings will inform and guide community developers and other stakeholders with an interest in residential buildings, on the most suitable clean energy options for their building project during the pre-project planning stage.}
}
@article{SALEEM2024100124,
title = {Understanding 21st century skills needed in response to industry 4.0: Exploring scholarly insights using bibliometric analysis},
journal = {Telematics and Informatics Reports},
volume = {13},
pages = {100124},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000100},
author = {Sumayya Saleem and Elizabeth Dhuey and Linda White and Michal Perlman},
keywords = {21st century skills, Industry 4.0, Bibliometric analysis, Co-citation, Bibliographic coupling},
abstract = {International policy agendas are increasingly focusing on the 21st century skills needed by future workers in response to Industry 4.0. In this study, we conduct a bibliometric analysis of 2662 articles published by 6579 authors in the last two decades to understand the structure of the scholarly knowledge in this field. We first identify influential articles, documents, journals and trends in this literature. We use co-citation analysis to identify foundational themes in the development of 21st century skills literature, then using bibliometric coupling, we identify communities in the current research front. We then use co-word analysis to identify future directions in the field. Overall, we find that research on 21st century skills has grown exponentially in the past two decades, however, few researchers focus primarily on this topic. The existing research is primarily dominated by psychologists, education researchers and technology researchers. We also find that specific disciplines such as industrial engineering and nursing are prominent contributors in the field, and that critical thinking and computational thinking are key areas of focus.}
}
@incollection{SAHIN202431,
title = {Chapter Two - Computational psychiatry and AI - High hopes: heralded heights or hollow hype?},
editor = {Marcello Ienca and Georg Starke},
series = {Developments in Neuroethics and Bioethics},
publisher = {Academic Press},
volume = {7},
pages = {31-47},
year = {2024},
booktitle = {Brains and Machines: Towards a Unified Ethics of AI and Neuroscience},
issn = {2589-2959},
doi = {https://doi.org/10.1016/bs.dnb.2024.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S2589295924000183},
author = {Derya Şahin},
keywords = {computational psychiatry, epistemology, reductionism, psychiatry ethics, medical ethics, AI ethics in health, fairness, bias, explainability},
abstract = {Computational psychiatry is a multidisciplinary field that utilizes mathematical, statistical, and computational methods to better understand mental disorders. The integration of AI in computational psychiatry has opened new possibilities for creating more precise and nuanced models of psychiatric disorders, simultaneously raising important ethical concerns related to privacy, data security, transparency, bias, alignment, and limits of computational psychiatry. This chapter provides an overview of the ethical considerations and challenges of computational psychiatry and the use of AI, specifically related to nosology, reductionism, and data constraints specific to psychiatry. Finally, it questions the epistemological limits of computational psychiatry.}
}
@article{MIAO2024117850,
title = {Progress toward adsorption mechanism exploration method for capacitive deionization: Experimental, mathematical model, computational chemistry and machine learning},
journal = {Desalination},
volume = {586},
pages = {117850},
year = {2024},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2024.117850},
url = {https://www.sciencedirect.com/science/article/pii/S0011916424005617},
author = {Luwei Miao and Ming Gao and Weilong Xiao and Yuchen Kang and Ran Li and Hao Kong and Haiyan Mou and Wenqing Chen and Tianqi Ao},
keywords = {Capacitive deionization mechanism, Experimental, Mathematical model, Computational chemistry, Machine learning},
abstract = {Capacitive deionization (CDI) is a novel and prospective technique mainly for desalination, featuring low-cost, easy maintenance, and environmental-friendly. As CDI develops by leaps and bounds, the electrode materials, the cell architectures, and the application fields have gained a lot of progress as reported. In order to optimize electrode materials, innovate cell architectures, broaden application fields, CDI adsorption mechanism exploration, as a necessary and important approach, have aroused enormous interest by researchers. This work provides a review of the strategies for investigating CDI adsorption mechanism form four aspects: experimental, mathematical model, computational chemistry, and machine learning, accompanied by discussing the prospects of these methods. Through a fine-grained summarization of the correlative reports from initial studies to the publications of late, it is expected that the meticulous statement of the characteristics, progress, and challenges of these exploration methods in this review can provide a fundamental support to facilitate prospective development of CDI.}
}
@article{CRISTIANINI201639,
title = {A different way of thinking},
journal = {New Scientist},
volume = {232},
number = {3101},
pages = {39-43},
year = {2016},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(16)32190-X},
url = {https://www.sciencedirect.com/science/article/pii/S026240791632190X},
author = {Nello Cristianini},
abstract = {Artificial intelligences may not understand things like we do, but what they can achieve is still staggering, says Nello Cristianini}
}
@incollection{COWAN2017147,
title = {2.09 - Working Memory: The Information You Are Now Thinking of},
editor = {John H. Byrne},
booktitle = {Learning and Memory: A Comprehensive Reference (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {147-161},
year = {2017},
isbn = {978-0-12-805291-4},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21040-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245210407},
author = {Nelson Cowan},
keywords = {Immediate memory, Memory capacity, Memory decay, Partial report, Recall, Recognition, Selective attention, Short-term memory, Working memory, Working memory capacity},
abstract = {Working memory is the limited information that we keep in mind and use to carry out thinking. This chapter explains the early and modern history of investigation of working memory, current controversies regarding the nature of working memory, and practical applications of the concept. Working memory is important because its limits help define what one can or cannot comprehend. A better understanding of working memory should allow improvements in the diagnosis and treatment of various neural conditions. Thinking broadly, studying working memory and other general limitations of the cognitive system could produce more humble and accommodating styles of interaction with other people, as one keeps in mind one's own cognitive limitations.}
}
@article{ARASTOOPOURIRGENS2022100541,
title = {Characterizing children’s conceptual knowledge and computational practices in a critical machine learning educational program},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100541},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100541},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000599},
author = {Golnaz {Arastoopour Irgens} and Hazel Vega and Ibrahim Adisa and Cinamon Bailey},
keywords = {Critical pedagogies, Machine learning education, Elementary education, Design-based research, Robotics, Informal education},
abstract = {In this study, we describe the design and implementation of a CML (critical machine learning) education program for children between the ages of 9 and 13 at an after-school center. In this participatory design-based research, we collected learner artifacts, recordings of interactions, and pre/post drawings and written responses to model children’s developing knowledge and practices related to critical machine learning. Drawing from constructionist and critical pedagogical perspectives, our research questions are: (1) How do children develop machine learning knowledge grounded in social, ethical, and political orientations in a CML education program? and (2) What computational practices do children engage in when developing robots for social good in a CML education program? We found that (1) children made more sophisticated connections with socio-political orientations and ML content as they progressed through the program, and (2) they engaged in computational practices, such as experimenting and iterating, testing and debugging, reusing and remixing, and abstracting and modularizing. Further, our findings indicate that a critical lens to ML education can be characterized by posing and answering questions about the roles of AI technologies producers and consumers and identifying how these technologies are designed to apply this knowledge to build applications for marginalized populations. This study suggests that a critical lens is an effective approach towards engaging young children in designing their own machine learning tools in socially responsible ways.}
}
@article{KARVELIS2023105137,
title = {Individual differences in computational psychiatry: A review of current challenges},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {148},
pages = {105137},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105137},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001069},
author = {Povilas Karvelis and Martin P. Paulus and Andreea O. Diaconescu},
keywords = {Computational psychiatry, Reliability, Validity, Computational modelling, Individual differences},
abstract = {Bringing precision to the understanding and treatment of mental disorders requires instruments for studying clinically relevant individual differences. One promising approach is the development of computational assays: integrating computational models with cognitive tasks to infer latent patient-specific disease processes in brain computations. While recent years have seen many methodological advancements in computational modelling and many cross-sectional patient studies, much less attention has been paid to basic psychometric properties (reliability and construct validity) of the computational measures provided by the assays. In this review, we assess the extent of this issue by examining emerging empirical evidence. We find that many computational measures suffer from poor psychometric properties, which poses a risk of invalidating previous findings and undermining ongoing research efforts using computational assays to study individual (and even group) differences. We provide recommendations for how to address these problems and, crucially, embed them within a broader perspective on key developments that are needed for translating computational assays to clinical practice.}
}
@article{DECARVALHO202196,
title = {The enactive computational basis of cognition and the explanatory cognitive basis for computing},
journal = {Cognitive Systems Research},
volume = {67},
pages = {96-103},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720301108},
author = {Leonardo Lana {de Carvalho} and João Eduardo Kogler},
keywords = {Cognitive systems, Enaction, Computing, Socio-natural practices},
abstract = {The computational theory of cognition, or computationalism, holds that cognition is a form of computation. Two issues related to this view are comprised by the goal of this paper: A) Computing systems are traditionally seen as representational systems, but functional and enactive approaches support non-representational theories; B) Recently, a sociocultural theory against computationalism was proposed with the aim of ontologically reducing computing to cognition. We defend, however, that cognition and computation are in action, thus cognition is just a form of computing and that cognition is the explanatory basis for computation. We state that: 1. Representational theories of computing recurring to intentional content run into metaphysical problems. 2. Functional non-representational theories do not incur this metaphysical problem when describing computing in terms of the abstract machine. 3. Functional theories are consistent with enactive in describing computing machines not in a strictly functional way, but especially in terms of their organization. 4. Enactive cognition is consistent with the computationalism in describing Turing machines as functionally and organizationally closed systems. 5. The cognitive explanatory basis for computing improves the computational theory of cognition. When developed in the human linguistic domain, computer science is seen as a product of human socionatural normative practices, however, cognition is just an explanatory, not ontological, basis for computing. The paper concludes by supporting that computation is in action, that cognition is just one form of computing in the world and the explanatory basis for computation.}
}
@article{YAN2024107454,
title = {A computational social science approach to understanding predictors of Chafee service receipt},
journal = {Children and Youth Services Review},
volume = {158},
pages = {107454},
year = {2024},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2024.107454},
url = {https://www.sciencedirect.com/science/article/pii/S0190740924000264},
author = {Jason Yan and Seventy F. Hall and Melanie Sage and Yuhao Du and Kenneth Joseph},
keywords = {Chafee services, Computational social science, Predictive modeling, National Youth in Transition Database},
abstract = {The John H. Chafee Foster Care Program for Successful Transition to Adulthood (CFCIP) allocates funding to provide services to youth who are likely to age out of foster care. These services, covering everything from mentoring to financial aid, are expected to be distributed in ways that prepare youth for life after care. One natural question to ask is, which youth receive Chafee services? The present work makes use of the National Youth in Transition Database (NYTD), a large-scale administrative dataset that tracks services allocated to youth that use CFCIP funds to answer this question. Specifically, we conduct a forensic social science analysis of the NYTD data. To do so, we first use computational methods to help us uncover the factors that best predict which youth will receive services associated with service receipt. We find that the majority of variables in the Adoption and Foster Care Analysis and Reporting System (AFCARS) and NYTD have limited or no utility in predicting Chafee service receipt, and that a subset of three variables—youth age, youth time in care, and the state in which a youth is in care—explain almost all variability in service receipt. We conclude with a discussion of the implications of these and other findings on future research on Chafee service allocation, and the utility of predictive modeling in child welfare, with a particular focus on the utility of the NYTD in this context.}
}
@incollection{DEWOSKIN2024779,
title = {Virtual models (aka: in silico or computational models)},
editor = {Philip Wexler},
booktitle = {Encyclopedia of Toxicology (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Oxford},
pages = {779-793},
year = {2024},
isbn = {978-0-323-85434-4},
doi = {https://doi.org/10.1016/B978-0-12-824315-2.00094-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128243152000944},
author = {Robert S. DeWoskin and Thomas B. Knudsen and Imran Shah},
keywords = {Adverse outcome pathways, Computational model, Emergent properties, In silico models, Microphysiological systems (MPS), PBPK models, Physiome project, Systems biology, Virtual embryo, Virtual liver, Virtual model (vM), Virtual physiological human},
abstract = {Virtual models (vM) are mathematical representations of biological processes that are numerically solved computationally, and are used to investigate and predict system behaviors that cannot be predicted solely from studying the nature of the individual parts, or from the domain of the available data. Computational power is now available to develop advanced vMs capable of supporting predictive toxicology and drug efficacy, and of reducing the dependence on in vivo animal studies for basic research and risk assessment purposes. The ultimate goal is to simulate in vivo responses of biological organisms to environmental change, drugs, toxins, or human activities, and to predict the effects of defined perturbations on system behaviors. Examples of virtual models are presented from research in the fields of physiology, pharmacology, toxicology and risk assessment.}
}
@article{BAR20104,
title = {Wait for the Second Marshmallow? Future-Oriented Thinking and Delayed Reward Discounting in the Brain},
journal = {Neuron},
volume = {66},
number = {1},
pages = {4-5},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0896627310002412},
author = {Moshe Bar},
abstract = {Humans tend to discount the value of delayed rewards. Peters and Büchel show in this issue of Neuron that the ability to appraise the value of such future rewards improves when future-oriented cognitive processes in the brain are recruited using personally relevant information. These results provide the platform for exciting new questions.}
}
@incollection{YIN2016273,
title = {Chapter 7 - Engineering Thinking and a New Generation of Steel Manufacturing Process},
editor = {Ruiyu Yin},
booktitle = {Theory and Methods of Metallurgical Process Integration},
publisher = {Academic Press},
pages = {273-306},
year = {2016},
isbn = {978-0-12-809568-3},
doi = {https://doi.org/10.1016/B978-0-12-809568-3.00017-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128095683000176},
author = {Ruiyu Yin},
keywords = {Holistic view, dynamic view, essence view, analysis and integration, virtuality and substantiality},
abstract = {Traditional thinking mode in Chinese culture chronically emphasizes the whole observation and thinking, namely holistic view, pays attention to observe and think problems based on the development, evolution of things, and analyzes problem as time(s) changes, namely the dynamic view. It also emphasizes to explore deeply and reveal the internal essence through the study and observe the imagery of a matter, namely the essence view. For the engineering methodology, the current book emphasizes the combination between reductionism and holism theory, between analysis and integration, and between virtuality and substantiality. The new generation of the steel manufacturing process is proposed based on the thinking mode above. The thinking mode above clarifies that thinking and studying a new generation of the steel manufacturing process should neither consider things as its standard nor tend to the specific application of individual technology. The general theoretical study of integrity, openness, hierarchy, dynamic character in the steel manufacturing process is more important. The old method of figurative observation should be turned to the physical nature investigation of dynamic running process. Based on the rational abstract, concept research, top level design, the dynamic tailored design study and dynamic operation rules, etc., are performed. Thus the concept, connotation, function, design method, and operation rules of a new generation of the steel manufacturing process are established.}
}
@article{BONHAGE2016203,
title = {Thinking about thinking: Neural mechanisms and effects on memory},
journal = {NeuroImage},
volume = {127},
pages = {203-214},
year = {2016},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.11.067},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915011040},
author = {Corinna Bonhage and Friederike Weber and Cornelia Exner and Philipp Kanske},
keywords = {Attention, Cognitive self-consciousness, Default mode network, Proactive interference/ memory, Salience network, fMRI},
abstract = {It is a well-established finding that memory encoding is impaired if an external secondary task (e.g. tone discrimination) is performed simultaneously. Yet, while studying we are also often engaged in internal secondary tasks such as planning, ruminating, or daydreaming. It remains unclear whether such a secondary internal task has similar effects on memory and what the neural mechanisms underlying such an influence are. We therefore measured participants' blood oxygenation level dependent responses while they learned word-pairs and simultaneously performed different types of secondary tasks (i.e., internal, external, and control). Memory performance decreased in both internal and external secondary tasks compared to the easy control condition. However, while the external task reduced activity in memory-encoding related regions (hippocampus), the internal task increased neural activity in brain regions associated with self-reflection (anterior medial prefrontal cortex), as well as in regions associated with performance monitoring and the perception of salience (anterior insula, dorsal anterior cingulate cortex). Resting-state functional connectivity analyses confirmed that anterior medial prefrontal cortex and anterior insula/dorsal anterior cingulate cortex are part of the default mode network and salience network, respectively. In sum, a secondary internal task impairs memory performance just as a secondary external task, but operates through different neural mechanisms.}
}
@article{ACKERMAN2017607,
title = {Meta-Reasoning: Monitoring and Control of Thinking and Reasoning},
journal = {Trends in Cognitive Sciences},
volume = {21},
number = {8},
pages = {607-617},
year = {2017},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2017.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661317301055},
author = {Rakefet Ackerman and Valerie A. Thompson},
keywords = {reasoning, problem solving, metacognition, effort regulation, monitoring and control},
abstract = {Meta-Reasoning refers to the processes that monitor the progress of our reasoning and problem-solving activities and regulate the time and effort devoted to them. Monitoring processes are usually experienced as feelings of certainty or uncertainty about how well a process has, or will, unfold. These feelings are based on heuristic cues, which are not necessarily reliable. Nevertheless, we rely on these feelings of (un)certainty to regulate our mental effort. Most metacognitive research has focused on memorization and knowledge retrieval, with little attention paid to more complex processes, such as reasoning and problem solving. In that context, we recently developed a Meta-Reasoning framework, used here to review existing findings, consider their consequences, and frame questions for future research.}
}
@incollection{RAAB202129,
title = {Chapter Four - How the body and the environment affect our thinking?},
editor = {Markus Raab},
booktitle = {Judgment, Decision-Making, and Embodied Choices},
publisher = {Academic Press},
pages = {29-46},
year = {2021},
isbn = {978-0-12-823523-2},
doi = {https://doi.org/10.1016/B978-0-12-823523-2.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128235232000040},
author = {Markus Raab},
keywords = {Facial feedback, Court decision, Gut decision, Gesture, Emotional decision},
abstract = {This chapter deals with the question, why body conditions and the environment influence our choices. Therefore this chapter summarizes plenty of research and combines it with own experiences. One famous study cited is the one by Strack and colleagues [12] concerning the facial feedback effect: Subjects had to rate the funniness of cartoons which either a pen between their lips or their teeth. Depending on the condition, the movement facilitated either a smile or a neutral expression which transferred to the ratings of the cartoons. Also, the role of gut feelings is discussed again, as research shows that the state of hunger may influence judges’ decisions at the court and this connection therefore should not the neglected. Talking about the bacteria-brain-behavior relationship, research on probiotics is very promising, although the exact mechanism of action is not completely discovered yet. A last aspect covered in this chapter is the influence of the gut on risky behavior, which has not been fully explored neurophysiological, maybe due to the deficient distinction between risk and uncertainty.}
}
@article{SHARIATI201640,
title = {Model Predictive Control in two days: Educating a new way of thinking},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {6},
pages = {40-45},
year = {2016},
note = {11th IFAC Symposium on Advances in Control Education ACE 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.07.150},
url = {https://www.sciencedirect.com/science/article/pii/S240589631630355X},
author = {S. Shariati and D. Abel},
keywords = {Workshop, Model Predictive control, Process Control, Kalman Filter, Education, Tutorial},
abstract = {In this paper, a two-day workshop on Model Predictive Controllers (MPC) is developed and practiced. The goal is to introduce the concept of MPC in an easy and motivating fashion, so that at the end of the second day not only the students are familiar with the basics of the MPC, but also are capable of indipendently program, tune and observe the performance of the MPC for their various applications. The course is mainly designed for the students with basic control engineering background and elementary Matlab/Simulink experience.}
}
@article{KRASICH2024105624,
title = {A computational modeling approach to investigating mind wandering-related adjustments to gaze behavior during scene viewing},
journal = {Cognition},
volume = {242},
pages = {105624},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105624},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002585},
author = {Kristina Krasich and Kevin O'Neill and Samuel Murray and James R. Brockmole and Felipe {De Brigard} and Antje Nuthmann},
keywords = {Visual-cognitive processing, Mind wandering, Fixation duration, Computational modeling, Scene viewing},
abstract = {Research on gaze control has long shown that increased visual-cognitive processing demands in scene viewing are associated with longer fixation durations. More recently, though, longer durations have also been linked to mind wandering, a perceptually decoupled state of attention marked by decreased visual-cognitive processing. Toward better understanding the relationship between fixation durations and visual-cognitive processing, we ran simulations using an established random-walk model for saccade timing and programming and assessed which model parameters best predicted modulations in fixation durations associated with mind wandering compared to attentive viewing. Mind wandering-related fixation durations were best described as an increase in the variability of the fixation-generating process, leading to more variable—sometimes very long—durations. In contrast, past research showed that increased processing demands increased the mean duration of the fixation-generating process. The findings thus illustrate that mind wandering and processing demands modulate fixation durations through different mechanisms in scene viewing. This suggests that processing demands cannot be inferred from changes in fixation durations without understanding the underlying mechanism by which these changes were generated.}
}
@article{CHEN2022307,
title = {Computational markers of experience- but not description-based decision-making are associated with future depressive symptoms in young adults},
journal = {Journal of Psychiatric Research},
volume = {154},
pages = {307-314},
year = {2022},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022395622004484},
author = {Chong Chen and Yasuhiro Mochizuki and Kosuke Hagiwara and Masako Hirotsu and Toshio Matsubara and Shin Nakagawa},
keywords = {Decision-making, Description-experience gap, Risk preference, Probability weighting, Reinforcement learning, Computational psychiatry},
abstract = {Background
Early prediction of high depressive symptoms is crucial for selective intervention and the minimization of functional impairment. Recent cross-sectional studies indicated decision-making deficits in depression, which may be an important contributor to the disorder. Our goal was to test whether description- and experience-based decision making, two major neuroeconomic paradigms of decision-making under uncertainty, predict future depressive symptoms in young adults.
Methods
One hundred young adults performed two decision-making tasks, one description-based, in which subjects chose between two gambling options given explicitly stated rewards and their probabilities, and the other experience-based, in which subjects were shown rewards but had to learn the probability of those rewards (or cue-outcome contingencies) via trial-and-error experience. We evaluated subjects' depressive symptoms with BDI-II at baseline (T1) and half a year later (T2).
Results
Comparing subjects with low versus high levels of depressive symptoms at T2 showed that the latter performed worse on the experience- but not description-based task at T1. Computational modeling of the decision-making process suggested that subjects with high levels of depressive symptoms had a more concave utility function, indicating enhanced risk aversion. Furthermore, a more concave utility function at T1 increased the odds of high depressive symptoms at T2, even after controlling depressive symptoms at T1, perceived stress at T2, and several covariates (OR = 0.251, 95% CI [0.085, 0.741]).
Conclusions
This is the first study to demonstrate a prospective link between experience-based decision-making and depressive symptoms. Our results suggest that enhanced risk aversion in experience-based decision-making may be an important contributor to the development of depressive symptoms.}
}
@article{RZEPA2023725,
title = {Teaching FAIR in computational chemistry: managing and publishing data using the twin tools of compute portals and repositories},
journal = {Canadian Journal of Chemistry},
volume = {101},
number = {9},
pages = {725-733},
year = {2023},
issn = {0008-4042},
doi = {https://doi.org/10.1139/cjc-2022-0255},
url = {https://www.sciencedirect.com/science/article/pii/S0008404223000724},
author = {Henry S. Rzepa},
keywords = {repository, FAIR data, knowledge graphs, emerging areas, teaching tools},
abstract = {The history of the emerging area of tools for managing research resources and the data produced from them is summarised from the perspective of two decades of use in teaching and research at one institution. These tools are a portal or electronic laboratory notebook for computational chemistry interfaced in one direction to a high-performance computing resource and in the other direction to a modern research data repository. The essential features of both these tools are described over two generations of each, with examples of student work cited as examples using persistent identifiers or PIDs, better known as DOIs. Underpinning this is the metadata describing the data being processed. The article outlines the evolution of managing such metadata-rich data and its progress towards what can now be summarised by the acronym FAIR data, itself enabling future emerging areas such as knowledge graphs.}
}
@article{JOHANNING2004371,
title = {Supporting the development of algebraic thinking in middle school: a closer look at students’ informal strategies},
journal = {The Journal of Mathematical Behavior},
volume = {23},
number = {4},
pages = {371-388},
year = {2004},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2004.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312304000458},
author = {Debra I. Johanning},
keywords = {Algebra, Algebraic thinking, Middle school, Guess and check},
abstract = {This study investigated how 31 sixth-, seventh-, and eighth-grade middle school students who had not previously, nor were currently taking a formal Algebra course, approached word problems of an algebraic nature. Specifically, these algebraic word problems were of the form x + (x + a) + (x + b) = c or ax + bx + cx = d. An examination of students’ understanding of the relationships expressed in the problems and how they used this information to solve problems was conducted. Data included the students’ written responses to problems, field notes of researcher–student interactions while working on the problems, and follow-up interviews. Results showed that students had many informal strategies for solving the problems with systematic guess and check being the most common approach. Analysis of researcher–student interactions while working on the problems revealed ways in which students struggled to engage in the problems. Support mechanisms for students who struggle with these problems are suggested. Finally, implications are provided for drawing upon students’ informal and intuitive knowledge to support the development of algebraic thinking.}
}
@article{SCHACHTER2016261,
title = {A critical review of Real Options thinking for valuing investment flexibility in Smart Grids and low carbon energy systems},
journal = {Renewable and Sustainable Energy Reviews},
volume = {56},
pages = {261-271},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.11.071},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115013386},
author = {J.A. Schachter and P. Mancarella},
keywords = {Real Options, Flexibility, Renewable energy, Energy systems investment, Low carbon technologies, Smart Grid},
abstract = {This paper aims at serving as a critical analysis of Real Options (RO) methodologies that have so far been applied to the flexible evaluation of smart grid developments and as a practical guide to understanding the benefits but more importantly the limitations of RO methodologies. Hence, future research could focus on developing more practical RO tools for application to the energy industry, thus making the utilization of powerful “real options thinking” for decision making under uncertainty more widespread. This is particularly important for applications in low carbon power and energy systems with increasing renewable and sustainable energy resources, given the different types of uncertainty they are facing in the transition towards a truly Smart Grid. In order to do so, and based on an extensive relevant literature review, the analogies with financial options are first presented, with various assumptions and their validity being clearly discussed in order to understand if, when, and how specific methods can be applied. It is then argued how option theory is in most cases not directly applicable to investment in energy systems but requires the consideration of their physical characteristics. The paper finally gives recommendations for building practical RO approaches to energy system (and potentially all engineering) project investments under uncertainty, regardless of the scale, time frame, or type of uncertainty involved.}
}
@article{ALTUN2024e00312,
title = {Parametric modeling and fabrication as capturing knowledge: A design computation workflow for historical brick surfaces in Anatolia},
journal = {Digital Applications in Archaeology and Cultural Heritage},
volume = {32},
pages = {e00312},
year = {2024},
issn = {2212-0548},
doi = {https://doi.org/10.1016/j.daach.2023.e00312},
url = {https://www.sciencedirect.com/science/article/pii/S2212054823000577},
author = {Sevgi Altun and Mine Özkar},
keywords = {Historical bricklaying, Shape grammars, Architectural heritage documentation, Robotic fabrication},
abstract = {Using computational design tools to create meaningful digital representations of architectural heritage delivers both challenges and opportunities. On one hand, digital tools aid the fast and detailed three-dimensional modeling of architectural elements. On the other hand, these models do not sufficiently document the materials and techniques of making. This research proposes a workflow to use computational design tools to analyze historic Anatolian brick elements while integrating their geometry, construction, and part-whole relations in parametric modeling and robotic fabrication processes. Our approach demonstrates a correlation between the design of the surface pattern and material application in historical bricklaying. The proposed workflow can be applied to formalize implicit design knowledge, integrating it into the digital environment and numeric control production codes. This holistic approach to heritage prioritizes both the tangible aspects, such as form and material, and intangible aspects such as the knowledge base of applied techniques.}
}
@incollection{MEINKE201939,
title = {Chapter 3 - The role of modeling and systems thinking in contemporary agriculture},
editor = {Riccardo Accorsi and Riccardo Manzini},
booktitle = {Sustainable Food Supply Chains},
publisher = {Academic Press},
pages = {39-47},
year = {2019},
isbn = {978-0-12-813411-5},
doi = {https://doi.org/10.1016/B978-0-12-813411-5.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813411500003X},
author = {Holger Meinke},
keywords = {Agriculture, Systems thinking, Complexity, Adaptation, Risk management, Modeling, Bioeconomy, Value chains, Social license, Industry 4.0, Sustainability},
abstract = {The images and perceived roles of agriculture in our societies have changed over the last few decades. Today agriculture is regarded as an integral part of interconnected value chains that sit at the heart of our economies, providing invaluable services to society. In response, most governments around the world are now actively developing policies to support and grow their bio-economies. This increases the expectations that society and governments have in terms of agriculture’s services and performance: agriculture is not only expected to generate food for our growing populations and income for farmers, it must be part of value chains that provide raw materials that can be incorporated or converted into feed, fiber, fuel, pharmaceuticals, and other industrial products. Farmers are expected to be responsible custodians of our landscapes and their farming practices must be economically, environmentally, and socially sustainable and aligned with the broader and changing values of our societies. Often these three objectives conflict and consequently societal expectations are not met. In a world that is increasingly data rich, practicing agriculture in a way that lives up to these expectations requires tools that can help to foresee the consequences of complex interactions. Hence, this chapter explores the role of modeling and systems thinking to manage this complexity by explicitly considering three attributes of complex, adaptive systems, whereby (i) order emerges rather than being predetermined; (ii) the system’s future can only be assessed probabilistically rather than deterministically predicted; and (iii) the history of the system is largely irreversible. The chapter reflects on the contemporary use of models against these three systems characteristics and concludes that scientifically based and tested algorithms (i.e., models) are already a ubiquitous and indispensable management tool for modern farming. Countless apps are already in use for short-term, tactical decision making, while more complex modeling approaches are vital for strategic scenario planning and risk assessments for farmers, policymakers, and scientists.}
}
@article{OTANI2024104086,
title = {Computational study on the effects of central retinal blood vessels with asymmetric geometries on optic nerve head biomechanics},
journal = {Medical Engineering & Physics},
volume = {123},
pages = {104086},
year = {2024},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2023.104086},
url = {https://www.sciencedirect.com/science/article/pii/S1350453323001418},
author = {Tomohiro Otani and Kota Miyata and Atsuya Miki and Shigeo Wada},
keywords = {Central retinal vessel, Optic nerves head, Optical coherence tomography, Glaucoma, Smoothed finite element method},
abstract = {Optic nerve head (ONH) biomechanics are associated with glaucoma progression and have received considerable attention. Central retinal vessels (CRVs) oriented asymmetrically in the ONH are the single blood supply source to the retina and are believed to act as mechanically stable elements in the ONH in response to intraocular pressure (IOP). However, these mechanical effects are considered negligible in ONH biomechanical studies and received less attention. This study investigated the effects of CRVs on ONH biomechanics taking into consideration three-dimensional asymmetric CRV geometries. A CRV geometry was constructed based on CRV centerlines extracted from optical coherence tomography ONH images in eight healthy subjects and superimposed in the idealized ONH geometry established in previous studies. Mechanical analyses of the ONH in response to the IOP were conducted in the cases with and without CRVs for comparison. Obtained results demonstrated that the CRVs induced anisotropic ONH deformation, particularly in the lamina cribrosa and the associated upper neural tissues (prelamina) with wide ranges of spatial strain distributions. These results indicated that the CRVs result in anisotropic deformation with local strain concentration, rather than function to mechanically support in response to the IOP as in the conventional thinking in ophthalmology.}
}
@article{KASPERSEN2022100539,
title = {High school students exploring machine learning and its societal implications: Opportunities and challenges},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100539},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100539},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000575},
author = {Magnus Høholt Kaspersen and Karl-Emil Kjær Bilstrup and Maarten {Van Mechelen} and Arthur Hjort and Niels Olof Bouvin and Marianne Graves Petersen},
keywords = {Computational empowerment, Computational thinking, Machine learning, Learning tools, AI literacy},
abstract = {The increased use of AI and machine learning (ML) calls for a general AI literacy, in particular regarding understanding how ML works, the process behind creating ML models, and reflecting on its implications. Where existing learning tools focus on the first two, we explore opportunities and challenges for meaningfully engaging students in understanding and reflecting on ML in their everyday life. We designed VotestratesML, following a Constructive Design Research approach, as an ethics-first learning tool that allow students to explore implications of ML for democratic elections. Based on deployments of VotestratesML in two high school social studies classrooms, we found that safely exploring ML from a concrete starting point helped students reflect and form opinions about its use, that promoting iterative exploration through collaboration and competition motivated them to explore, and that foregrounding ethics in the design and grounding ML in a well-known subject area allowed them to engage with ML on a personal level.}
}
@article{GIANNANTONI201462,
title = {The Relevance of Emerging Solutions for Thinking, Decision Making and Acting. The case of Smart Grids},
journal = {Ecological Modelling},
volume = {271},
pages = {62-71},
year = {2014},
note = {Environmental Accounting: Emergy, Systems Ecology and Ecological Modelling},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013001907},
author = {Corrado Giannantoni},
keywords = {Emerging Solutions, Incipient Differential Calculus (IDC), Maximum Ordinality Principle, Intractable problems, Smart Grids},
abstract = {The paper presents a real novelty in Mathematical Modelling, which may have an enormous relevance in our way of Thinking, Decision Making and Acting. At the same time it would like to represent an explicit “Tribute” to Prof. Odum, because the original concept is already seminally present in his well-known Rules of Emergy Algebra. This novelty in Mathematical Modelling is represented by the so-called “Emerging Solutions”, which are radically different from solutions to traditional mathematical problems. This is because any traditional solution to an algebraic or differential problem is always represented by a formal expression that, when reintroduced into the initial formulation of the problem, reduces the latter to a perfect identity. Emerging Solutions, on the contrary, show an Ordinal Information content which is always much higher than the corresponding content pertaining to the initial formulation of the problem. Emerging Solutions, in fact, originate from any physical problem when this is modelled in accordance with the Maximum Ordinality Principle, and thus understood in Ordinal Terms. Such a property, which represents one of the most interesting aspects of the Maximum Ordinality Principle, then suggests we adopt a Generative way of Thinking when designing a new practical application. The same happens at the level of Will, that is at the level of Decision Making. Clearly, if we really want to take advantage of those “Emerging Exits” which arise from the physical behaviour of the system. Finally, at the level of Acting, if we are really interested in favouring any “emerging behaviour” of the system which is decisively capable to improve our design. For instance, to get the maximum intrinsic stability of the system, so as to prevent any possible disturbance that might significantly alter its expected behaviour. All these aspects will be illustrated through the case of Smart Grids, with particular reference to their large scale “intrinsic” instability and their recognized strong vulnerability to “cyber” attacks.}
}
@article{BERTOLDI2025108397,
title = {Linking systems to agencies in urban metabolism studies: A conceptual framework and computational analysis of research literature},
journal = {Ecological Economics},
volume = {227},
pages = {108397},
year = {2025},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0921800924002945},
author = {Nicola Bertoldi and Daniela Perrotti},
keywords = {Urban metabolism, Agency, Social ecology, Stock-flow-practice nexus, Semantic network analysis, Computational linguistics, Text mining},
abstract = {This study outlines a conceptual framework linking a conceptualization of agency in urban metabolism studies with a systems-based perspective. To this aim, we engage with contributions to socio-metabolic studies, notably from social ecology, that are not directly concerned with the urban dimension but explicitly question how systems and actors shape each other and how social practices can influence the distribution of resource flows and stocks and their interdependencies. Based on those contributions, we identify three critical axes of investigation that help track implicit uses of the concept of “agency” in urban metabolism studies and constitute the pillars of our proposed framework: (1) characterizing structures comprising urban social-ecological systems – understood as patterns of connections among elements and subsystems – as actors, (2) identifying the chains of events that such actors influence by exerting their agentic capacities, and (3) associating those same actors with definite agentic dimensions, i.e., specific modalities of agency. By drawing on methods from computational linguistics, text mining, and semantic network analysis, we extract concepts cognate to “urban metabolism” from a relevant body of research literature. Through our framework, we show how such concepts define forms of agency that can be ascribed to structural components of urban social-ecological systems.}
}
@article{DEBNATH2023314,
title = {Opportunities and limitations of integrating computational and collaborative approaches to scenario planning},
journal = {Journal of Urban Management},
volume = {12},
number = {4},
pages = {314-326},
year = {2023},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2023.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2226585623000468},
author = {Ripan Debnath and Christopher Pettit and Simone Zarpelon Leao},
keywords = {Scenario planning, Computational approach, CA-Model, Collaborative planning, Geodesign},
abstract = {In the context of changing global trends and growing uncertainties, creating and evaluating alternative future scenarios is crucial for urban and regional planning. Computational and collaborative approaches are two contemporary options for scenario planning. They have distinct roles and are often applied independently. This study investigates the integration of these two approaches, addressing a knowledge gap by explicitly integrating a Cellular Automata-based model within the collaborative geodesign framework. It assesses the integration process and scenario planning outcomes through a resilience planning case study. The key finding from this experiment is that integrating the information generated by a computational approach with the transparency and reliability inherent in a collaborative approach can enhance the end-user's scenario planning experience. The integration is also perceived to have positive effects on scenario outcomes, which is particularly relevant for joint evidence-based and collaborative resilience planning in cities and regions. However, the study also highlights the need for further investigation into the options for integrating computational methods into collaborative approaches and into the utility of integration in real-world planning with practitioners and the community.}
}
@article{MAMMINO2023101151,
title = {Green chemistry and computational chemistry: A wealth of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {34},
pages = {101151},
year = {2023},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S2352554123001857},
author = {Liliana Mammino},
keywords = {Design of new molecules, Education to cross-disciplinary attitudes, Prediction of, Molecular properties, Prediction of reaction mechanisms},
abstract = {The green chemistry principles envisage the design of substances and production processes that are benign for human health and the environment, where ‘benign’ refers to the entire life of a substance, from production through usage and to final disposal. The design of new substances entails the design of new molecules, and the design of more benign processes may entail the design of other substances (besides reactants and products) facilitating the process' ‘greenness’, from catalysts to green solvents. Designing molecules with specific properties requires the possibility of predicting their properties before the actual synthesis. Computational chemistry has made molecular design rational by being able to predict the properties of not-yet-synthesized molecules. The results of molecular calculations enable a preliminary selection singling out the promising molecules among a high number of possibilities; only the promising ones are then synthesized and experimentally tested. Synergies between computational chemistry and green chemistry would thus appear a natural outcome. The present work outlines them with reference to the main components of an industrial process and of their potential ‘greening’. The presentation follows a pattern that can be used within educational contexts. The conclusions stress the importance to familiarise students with the variety of possible synergies and the benefits of each of them, within a perspective viewing a ‘knowing each other’ criterion as the main key to nurture true cross-areas attitudes, that will be valuable for the students' future professional activities.}
}
@article{LOCKWOOD2021100857,
title = {Reinforcing key combinatorial ideas in a computational setting: A case of encoding outcomes in computer programming},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100857},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100857},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000183},
author = {Elise Lockwood and Adaline {De Chenne}},
keywords = {Combinatorics, Encoding outcomes, Computation, Programming, Discrete mathematics},
abstract = {Counting problems are difficult for students to solve, and there is a perennial need to investigate ways to help students solve counting problems successfully. One promising avenue for students’ successful counting is for them to think judiciously about how they encode outcomes – that is, how they symbolize and represent the outcomes they are trying to count. We provide a detailed case study of two students as they encoded outcomes in their work on several related counting problems within a computational setting. We highlight the role that a computational environment may have played in this encoding activity. We illustrate ways in which by-hand work and computer programming worked together to facilitate the students’ successful encoding activity. This case demonstrates ways in which the activity of computation seemed to interact with by-hand work to facilitate sophisticated encoding of outcomes.}
}
@article{XU2024100415,
title = {Measuring mutual engagement in the context of middle-school pair programming: Development and validation of a self-reported questionnaire},
journal = {Computers in Human Behavior Reports},
volume = {14},
pages = {100415},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100415},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824000484},
author = {Fan Xu and Ana-Paula Correia},
keywords = {Mutual engagement, Engagement questionnaire, Dyadic collaborative learning, Pair programming, Computational thinking, Middle school},
abstract = {With the increasing importance of equipping young learners with computational thinking skills through learning to code, pair programming has emerged as a prevalent collaborative learning strategy in this context. Successful pair programming interventions necessitate mutual engagement between partners within a dyad. However, the measurement of mutual engagement in dyadic collaborative learning remains an under-researched area. This research represents a foundational stage in bridging this gap by developing a comprehensive 20-item Pair-Programming Mutual Engagement Questionnaire (PPME-Q) as a measure of mutual engagement in pair programming at the activity level. The questionnaire was validated through a sample of 86 eighth-grade students. Confirmatory factor analysis confirmed the existence of a four-factor structure comprising of the behavioral, cognitive, emotional, and social engagement factors. The findings demonstrate the validity (χ2/df = 1.32) and reliability (Cronbach's α = 0.888) of the PPME-Q, establishing it as an effective tool for assessing eighth graders' mutual engagement in pair programming activities. As this tool is in the nascent stages of development the measurement, we emphasize the need for further empirical studies to establish criterion validity. We also discuss the implications of these findings for future research and educational practices. This targeted instrument can then potentially be adapted or scaled to other age groups based on the insights gained.}
}
@incollection{MAYER200115476,
title = {Teaching for Thinking},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {15476-15479},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/02466-9},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767024669},
author = {R.E. Mayer},
abstract = {Teaching for thinking refers to instruction intended to improve the effectiveness of people's thinking. A rationale for teaching for thinking is that students are expected to be effective thinkers but rarely are taught how to think. Teaching for thinking is intended to promote the ability to use what one has learned to solve new problems, which Wertheimer refers to as productive thinking. Teaching for thinking requires the consideration of four issues—what, how, where, and when to teach. Concerning what to teach, successful teaching for thinking focuses on helping students develop a collection of component skills for a particular cognitive task rather than on improving the mind in general. Concerning how to teach, successful teaching for thinking focuses on modeling the process of problem solving rather than solely drill and practice on getting the right answer. Concerning where to teach, successful teaching for thinking focuses on teaching within specific subject areas rather than in a content-independent course. Concerning when to teach, successful teaching for thinking includes teaching while students are novices rather than waiting until they have mastered all prerequisite basic skills.}
}
@article{AISH2017144,
title = {Comparative evaluation of parametric design systems for teaching design computation},
journal = {Design Studies},
volume = {52},
pages = {144-172},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300327},
author = {Robert Aish and Sean Hanna},
keywords = {architectural design, design education, human–computer interaction, parametric design, evaluation},
abstract = {Three parametric design systems were tested by the authors to assess their suitability for undergraduate teaching. We used criteria taken from the ‘cognitive dimensions’ literature and an exercise of typical geometric operations in ascending order of complexity. For each system the cognitive barriers associated with the sequence of operations were plotted to create a ‘learning curve’. Different parametric systems presented distinctly different learning curves. The test exercise had to be completed in its entirety to assess the potential challenges which students with different educational levels, skills and abilities might encounter, so a single expert user conducted the tests. This research is intended to develop methods, both design exercises and evaluative criteria that could be used in future empirical studies.}
}
@article{HALL2024541,
title = {The computational structure of consummatory anhedonia},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {6},
pages = {541-553},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000068},
author = {Anna F. Hall and Michael Browning and Quentin J.M. Huys},
keywords = {anhedonia, reinforcement learning, reward, goals, stress response, emotion appraisal},
abstract = {Anhedonia is a reduction in enjoyment, motivation, or interest. It is common across mental health disorders and a harbinger of poor treatment outcomes. The enjoyment aspect, termed ‘consummatory anhedonia’, in particular poses fundamental questions about how the brain constructs rewards: what processes determine how intensely a reward is experienced? Here, we outline limitations of existing computational conceptualisations of consummatory anhedonia. We then suggest a richer reinforcement learning (RL) account of consummatory anhedonia with a reconceptualisation of subjective hedonic experience in terms of goal progress. This accounts qualitatively for the impact of stress, dysfunctional cognitions, and maladaptive beliefs on hedonic experience. The model also offers new views on the treatments for anhedonia.}
}
@article{ANANE2023104782,
title = {BIM-driven computational design for robotic manufacturing in off-site construction: an integrated Design-to-Manufacturing (DtM) approach},
journal = {Automation in Construction},
volume = {150},
pages = {104782},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104782},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523000420},
author = {Walid Anane and Ivanka Iordanova and Claudiane Ouellet-Plamondon},
keywords = {Design-to-manufacturing, BIM, Computational design, Robotic manufacturing, Off-site construction, Interoperability},
abstract = {Technological interoperability is a driver for seamless data and information exchange between project team members in the Architecture, Engineering, and Construction (AEC) industry. It is defined as the ability of different systems to exchange information with minimum loss. Therefore, interoperability lack is often a barrier in modern construction applications, such as robotics. Construction and robotics, seen from their respective areas, are highly divergent in context, organization, procedures, and technologies. However, both paradigms use computation, which gives computational systems the potential to enable construction robotics. This research is based on the Design Science Research (DSR) methodology and aims to develop a framework for operationalizing industrial robots in construction. To this end, it uses Computational Design (CD) driven by Building Information Modeling (BIM) for Robotic Manufacturing (RM) within Off-Site Construction (OSC) systems. This technological alignment allowed the development of an integrated Design-to-Manufacturing (DtM) framework, validated by 16 evaluators.}
}
@article{ALBERT2002220,
title = {Relationships among bilingualism, critical thinking ability, and critical thinking disposition},
journal = {Journal of Professional Nursing},
volume = {18},
number = {4},
pages = {220-229},
year = {2002},
issn = {8755-7223},
doi = {https://doi.org/10.1053/jpnu.2002.127015},
url = {https://www.sciencedirect.com/science/article/pii/S8755722302000212},
author = {Raymond T. Albert and Rachel E. Albert and Jenny Radsma},
keywords = {Critical thinking, Critical thinking disposition, Bilingualism, Nursing, Baccalaureate},
abstract = {Evidence exists supporting relationships between bilingualism and many cognitive factors. Research, however, has not been conducted to specifically examine the relationships among bilingualism, critical thinking ability, and critical thinking disposition of baccalaureate nursing students. This cross-sectional study used a pooled, within-bilingual, correlational design to examine such relationships. Specific research questions posed were: (1) is there a statistically significant curvilinear relationship between bilingualism and critical thinking ability, (2) is there a statistically significant curvilinear relationship between bilingualism and critical thinking disposition, and (3) is there a statistically significant relationship between critical thinking disposition and critical thinking ability? A convenience sample of nursing students (N = 111) was administered a French language Cloze Test (C-Test), an English language C-Test, as well as the California Critical Thinking Skills Test, and the California Critical Thinking Disposition Inventory. Multiple regression analysis was used to test the hypotheses. Findings failed to provide sufficient evidence to support the existence of a relationship between either bilingualism and critical thinking ability, or between critical thinking disposition and critical thinking ability. However, there was sufficient evidence to support the existence of a curvilinear relationship between bilingualism and critical thinking disposition. Implications for nursing education are presented. J Prof Nurs 18:220-229, 2002. Copyright 2002, Elsevier Science (USA). All rights reserved.}
}