@article{SHYJA2023100465,
title = {Link quality and energy efficient optimal simplified cluster based routing scheme to enhance lifetime for wireless body area networks},
journal = {Nano Communication Networks},
volume = {37},
pages = {100465},
year = {2023},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2023.100465},
url = {https://www.sciencedirect.com/science/article/pii/S1878778923000315},
author = {V. Irine Shyja and G. Ranganathan and V. Bindhu},
keywords = {WBAN, Clustering, Cluster head, Multipath routing scheme, Link quality},
abstract = {Monitoring of patient’s health in the medical industry can be enabled using wireless body area networks (WBANs), which are already used for various purposes, including assisting in human safety. It is imperative to use better power management strategies since the body sensors are small and the battery cannot hold a charge for a long time. Due to the vast amounts of information generated by medical sensors, resource-constrained networks face a significant challenge when guaranteeing the specified quality of service (QoS). Moreover, the WBAN regularly meets the primary hassle of QoS degradation because of congestion WBAN structure can easily compromise heterogeneous and complex networks. Either inappropriate data collection or using energy effectively to transmit medical data without the expense of travel and length has become an important one. To address this issue, the present research work ‘Link Quality and Energy Efficient Optimal Clustering-Multipath (LEOC-MP)’ scheme tries to explore an answer. The main goals of the LEOC-MP (Optimal Link Quality and Energy Efficient Optimal Clustering-Multipath) system are to guarantee node-to-node link quality, lengthen network life, and compute high-performing cluster heads to guarantee reliable multi path data transfer. This work was executed in three phases. First, an optimal simplified clustering technique for data collection from body sensors using an improved pelican optimization (ICO) algorithm is introduced. Next, multiple design constraints for node rank computation, energy efficiency, link quality, path loss, distance, and delay are used. Besides, an Auto-Regressive Probabilistic Neural Network (AR-PNN) is introduced to optimize those design constraints and compute the cluster head (CH) of each cluster. Multipath firing is then performed using a moderated puffer-fish optimization (MPO) algorithm that finds the closest optimal and shortest node to transmit optimal drug data. The work is simulated using an NS-3 environment, and the results are obtained. The outcome of this work is analyzed with existing methodologies, and the results prove that the present work consistently outperforms the existing methodologies.}
}
@article{LAW2023112555,
title = {Frontopolar cortex represents complex features and decision value during choice between environments},
journal = {Cell Reports},
volume = {42},
number = {6},
pages = {112555},
year = {2023},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2023.112555},
url = {https://www.sciencedirect.com/science/article/pii/S2211124723005661},
author = {Chun-Kit Law and Nils Kolling and Chetwyn C.H. Chan and Bolton K.H. Chau},
keywords = {frontopolar cortex, ventromedial prefrontal cortex, decision making, environment choice, convolutional neural network, CNN},
abstract = {Summary
Important decisions often involve choosing between complex environments that define future item encounters. Despite its importance for adaptive behavior and distinct computational challenges, decision-making research primarily focuses on item choice, ignoring environment choice altogether. Here we contrast previously studied item choice in ventromedial prefrontal cortex with lateral frontopolar cortex (FPl) linked to environment choice. Furthermore, we propose a mechanism for how FPl decomposes and represents complex environments during decision making. Specifically, we trained a choice-optimized, brain-naive convolutional neural network (CNN) and compared predicted CNN activation with actual FPl activity. We showed that the high-dimensional FPl activity decomposes environment features to represent the complexity of an environment to make such choice possible. Moreover, FPl functionally connects with posterior cingulate cortex for guiding environment choice. Further probing FPl’s computation revealed a parallel processing mechanism in extracting multiple environment features.}
}
@article{EVANS2003454,
title = {In two minds: dual-process accounts of reasoning},
journal = {Trends in Cognitive Sciences},
volume = {7},
number = {10},
pages = {454-459},
year = {2003},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2003.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661303002250},
author = {Jonathan St.B.T. Evans},
abstract = {Researchers in thinking and reasoning have proposed recently that there are two distinct cognitive systems underlying reasoning. System 1 is old in evolutionary terms and shared with other animals: it comprises a set of autonomous subsystems that include both innate input modules and domain-specific knowledge acquired by a domain-general learning mechanism. System 2 is evolutionarily recent and distinctively human: it permits abstract reasoning and hypothetical thinking, but is constrained by working memory capacity and correlated with measures of general intelligence. These theories essentially posit two minds in one brain with a range of experimental psychological evidence showing that the two systems compete for control of our inferences and actions.}
}
@article{NAWAZ2024102806,
title = {Grappling with a sea change: Tensions in expert imaginaries of marine carbon dioxide removal},
journal = {Global Environmental Change},
volume = {85},
pages = {102806},
year = {2024},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2024.102806},
url = {https://www.sciencedirect.com/science/article/pii/S0959378024000104},
author = {Sara Nawaz and Javier Lezaun},
abstract = {While research on marine carbon dioxide removal (mCDR) expands apace, significant unknowns persist regarding the risks and benefits of individual mCDR options. This paper analyses the assumptions and expectations that animate expert understandings of mCDR, with a focus on issues that are central to the responsible governance of this emerging field of climate action. Drawing upon interviews with experts involved in mCDR research projects both academic and entrepreneurial, we highlight four thematic tensions that orient their thinking but are often unstated or left implicit in scientific and technical assessments: (1) the relevance of ‘naturalness’ as a criterion of evaluation for mCDR approaches; (2) the perceived need to accelerate research and development activities via alternative paradigms of evidence-building; (3) a framing of mCDR as a form of waste management that will, in turn, generate new (and currently poorly understood) forms of environmental pollutants; and (4) a commitment to inclusive governance mixed with difficulty in identifying specific stakeholders or constituencies in mCDR interventions. Although expert consensus on these four issues is unlikely, we suggest ways of ensuring that consideration of these themes enriches debate on the responsible development of novel mCDR capabilities.}
}
@article{KASHYAPKASHYAP2021395,
title = {The universal language: mathematics or music?},
journal = {Journal for Multicultural Education},
volume = {15},
number = {4},
pages = {395-415},
year = {2021},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-05-2021-0064},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X21000197},
author = {RaviRavi KashyapKashyap},
keywords = {Mathematics, Multicultural, Music, Education policy, Artistic encoding of knowledge, Universal language},
abstract = {Purpose
Music could be a challenger for mathematics and a potential candidate for the title “The Universal Language.” This paper aims to discuss the primary objectives of engaging with music, including the therapeutic benefits. Similarities, between mathematics and music and how studying one might enhance one’s abilities of the other are pointed out.
Design/methodology/approach
A formal definition for a universal language is given. A qualitative approach, supplemented with rigorous reasoning, is adopted. The narrative relies on the author’s experiences, teaching mathematical concepts and musical interactions, with students from several countries. A vast amount of literature is reviewed and the corresponding findings are connected toward the arguments made.
Findings
The paper demonstrates that one day, once we understand both mathematics and music better, we might see both of them as the same language. Until then, it is essential to supplement mathematics with music. The educational implications, for all fields, are to ensure that the future creators of knowledge are equally adept at both music and mathematics. The wider policy connotations are to create a blueprint for a society with a vibrant musical and artistic environment.
Originality/value
This study illuminates new ways of thinking about music and mathematics. The possibility that many seemingly complex entities (including our universe, virtual computer worlds, mathematical operations, etc.), are made up of combinations of much simpler building blocks is hinted at. Familiarity with any intricate element of life, without getting flustered, is bound to produce remarkable results in other such endeavors.}
}
@article{THOMPSON2024100094,
title = {Alzheimer’s disease and the mathematical mind},
journal = {Brain Multiphysics},
volume = {6},
pages = {100094},
year = {2024},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2024.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2666522024000054},
author = {Travis B. Thompson and Bradley Z. Vigil and Robert S. Young},
keywords = {Alzheimer’s disease, Mathematical modeling, Scientific computing},
abstract = {Throughout the 19th and 20th centuries, aided by advances in medical imaging, discoveries in physiology and medicine have added nearly 25 years to the average life expectancy. This resounding success brings with it a need to understand a broad range of age-related health conditions, such as dementia. Today, mathematics, neuroimaging and scientific computing are being combined with fresh insights, from animal models, to study the brain and to better understand the etiology and progression of Alzheimer’s disease, the most common cause of age-related dementia in humans. In this manuscript, we offer a brief primer to the reader interested in engaging with the exciting field of mathematical modeling and scientific computing to advance the study of the brain and, in particular, human AD research. Statement of Significance Modeling Alzheimer’s disease is a highly interdisciplinary field and finding an effective starting point can be a considerable challenge. To address this challenge, this manuscript briefly highlights some central components of AD related protein pathology, useful classes of mathematical models for brain and AD research and effective computational resources for the practical prospective practitioner.}
}
@article{EVANS2022281,
title = {The explainability paradox: Challenges for xAI in digital pathology},
journal = {Future Generation Computer Systems},
volume = {133},
pages = {281-296},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22000838},
author = {Theodore Evans and Carl Orge Retzlaff and Christian Geißler and Michaela Kargl and Markus Plass and Heimo Müller and Tim-Rasmus Kiehl and Norman Zerbe and Andreas Holzinger},
keywords = {Explainable AI, Digital pathology, Usability, Trust, Artificial intelligence},
abstract = {The increasing prevalence of digitised workflows in diagnostic pathology opens the door to life-saving applications of artificial intelligence (AI). Explainability is identified as a critical component for the safety, approval and acceptance of AI systems for clinical use. Despite the cross-disciplinary challenge of building explainable AI (xAI), very few application- and user-centric studies in this domain have been carried out. We conducted the first mixed-methods study of user interaction with samples of state-of-the-art AI explainability techniques for digital pathology. This study reveals challenging dilemmas faced by developers of xAI solutions for medicine and proposes empirically-backed principles for their safer and more effective design.}
}
@article{VIDENOVIK2024100616,
title = {Game-based learning approach in computer science in primary education: A systematic review},
journal = {Entertainment Computing},
volume = {48},
pages = {100616},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100616},
url = {https://www.sciencedirect.com/science/article/pii/S187595212300071X},
author = {Maja Videnovik and Ana {Madevska Bogdanova} and Vladimir Trajkovik},
keywords = {Educational game, Game-based learning, Computer science, Primary education},
abstract = {This paper reviews the current situation concerning the implementation of game-based learning in computer science in primary education, providing insight into current trends, identifying strengths and potential research topics. Articles published in four databases from 2017 to 2021 are included in the analysis and an in-depth analysis of 32 articles is done. Different types of games, implemented in various educational contexts, are presented in these articles. Most of them describe implemented methodology, game-based environment or are evaluating the effectiveness of the created game or the approach. The possibility of implementing a game-based approach while learning other computer science topics or measuring the effectiveness of learning by designing a game as a pedagogical strategy are some areas for future research.}
}
@article{KEMPF2023103747,
title = {Point pattern and spatial analyses using archaeological and environmental data – A case study from the Neolithic Carpathian Basin},
journal = {Journal of Archaeological Science: Reports},
volume = {47},
pages = {103747},
year = {2023},
issn = {2352-409X},
doi = {https://doi.org/10.1016/j.jasrep.2022.103747},
url = {https://www.sciencedirect.com/science/article/pii/S2352409X22004102},
author = {Michael Kempf and Gerrit Günther},
keywords = {Environmental archaeology, Quantitative archaeology, Computational methods, Spatial analysis, R, Point pattern analysis (PPA)},
abstract = {Computational methods recently gained momentum in archaeological science, particularly affecting large site distribution samples and environmental explanatory parameters. However, quantitative and environmental archaeology are still considered to be limited to a small number of experts and thus less ready to use in general research. Here, we present a case study that integrates computational methods and environmental data into archaeological spatial analyses using Point Pattern Analysis (PPA). We introduce a basic approach to model, visualise, and interpret archaeological site distributions as functions of explanatory covariates in a regional setting of the Neolithic period in the Carpathian Basin. The integration of environmental and socio-cultural variables in a multicomponent analysis allows to distinguish site location parameters and preferences across different chronological periods. Using the code to this article and open-access spatial data, the workflow can be adapted to different regional contexts and chronological periods, making it particularly suitable for spatial pattern comparison.}
}
@article{UDDIN2021106,
title = {Application of Theory in Chronic Pain Rehabilitation Research and Clinical Practice},
journal = {The Open Sports Sciences Journal},
volume = {14},
pages = {106-113},
year = {2021},
issn = {1875-399X},
doi = {https://doi.org/10.2174/1875399X02114010106},
url = {https://www.sciencedirect.com/science/article/pii/S1875399X2100013X},
author = {Zakir Uddin and Joy C. MacDermid and Fatma A. Hegazy and Tara L. Packham},
keywords = {Chronic pain , Hypersensitivity , Theory , Rehabilitation , Disability , T-cell},
abstract = {Introduction
Chronic pain has multiple aetiological factors and complexity. Pain theory helps us to guide and organize our thinking to deal with this complexity. The objective of this paper is to critically review the most influential theory in pain science history (the gate control theory of pain) and focus on its implications in chronic pain rehabilitation to minimize disability.
Methods
In this narrative review, all the published studies that focused upon pain theory were retrieved from Ovoid Medline (from 1946 till present), EMBAS, AMED and PsycINFO data bases.
Results
Chronic pain is considered a disease or dysfunction of the nervous system. In chronic pain conditions, hypersensitivity is thought to develop from changes to the physiological top-down control (inhibitory) mechanism of pain modulation according to the pain theory. Pain hypersensitivity manifestation is considered as abnormal central inhibitory control at the gate controlling mechanism. On the other hand, pain hypersensitivity is a prognostic factor in pain rehabilitation. It is clinically important to detect and manage hypersensitivity responses and their mechanisms.
Conclusion
Since somatosensory perception and integration are recognized as a contributor to the pain perception under the theory, then we can use the model to direct interventions aimed at pain relief. The pain theory should be leveraged to develop and refine measurement tools with clinical utility for detecting and monitoring hypersensitivity linked to chronic pain mechanisms.}
}
@article{DANAHY2001127,
title = {Technology for dynamic viewing and peripheral vision in landscape visualization},
journal = {Landscape and Urban Planning},
volume = {54},
number = {1},
pages = {127-138},
year = {2001},
note = {Our Visual Landscape: analysis, modeling, visualization and protection},
issn = {0169-2046},
doi = {https://doi.org/10.1016/S0169-2046(01)00131-1},
url = {https://www.sciencedirect.com/science/article/pii/S0169204601001311},
author = {John W. Danahy},
keywords = {Visualization, Real-time immersive virtual reality, Panorama, Peripheral vision, Foveal vision, Dynamic viewing},
abstract = {The dynamic qualities of looking around and moving about, directly sensing spatial queues, using one’s peripheral vision, and focusing with foveal vision on objects of attention are fundamental to a person’s visual experience in landscape. Unfortunately, the visual media commonly used to structure scientific analysis, professional design, decision-making and artistic interpretation of visual landscapes are quite weak at portraying the dynamic and peripheral dimensions of human vision. Also, visual media whether it be manual drawing, photomontage or state-of-the-art computer animation tend to be time consuming and difficult to apply to these dimensions of seeing. The absence of a convenient, cost-effective means for showing all the fundamental visual aspects of landscape in a balanced way is a serious limitation. This deficiency begs the following questions. Is the current state of knowledge in visual landscape management biased by the relative ease with which established media, such as illustration, photography, and photo-realistic rendering can be used? Do the characteristics of these media bias our perception and thinking about landscape toward static foveal aspects of visual experience? Are our ideas about dynamic viewing and computer animation limited by the didactic frame-by-frame approach characteristic of cinematography and video? Can the introduction of equally robust tools and methods for dynamic and peripheral viewing balance any bias caused by current visualization technology? If McLuhan’s insights about media are correct, then we need to do more research on this question. This paper suggests that the field of landscape visualization needs to develop instruments for research that more fully capture the fundamental components of human vision before we can properly study the question or advance practice. It outlines some ways the next generation of visualization technology can be used to balance the disproportionate emphasis on foveal ways of visual thinking commonly used in the past for the study of visual landscapes. The paper explains this deficiency and proposes some area for research and development of visualization instruments more capable of redressing this imbalance. The paper outlines this issue and proposes that as electronic media and computational media become more developed and are applied to the realm of visual concerns, it will become more practical to include peripheral vision and dynamic viewing in deliberations about visual landscapes. This paper reflects on the potential of visualization automation techniques to overcome these shortcomings through illustrations of project work using innovative software tools developed to explore this question at the Centre for Landscape Research (CLR) at the University of Toronto.}
}
@article{ARMSTRONG20161,
title = {A NIT-picking analysis: Abstractness dependence of subtests correlated to their Flynn effect magnitudes},
journal = {Intelligence},
volume = {57},
pages = {1-6},
year = {2016},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2016.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0160289616300812},
author = {Elijah L. Armstrong and Jan {te Nijenhuis} and Michael A. {Woodley of Menie} and Heitor B.F. Fernandes and Olev Must and Aasa Must},
keywords = {Abstract thinking, Flynn effect, Intelligence, National Intelligence Test, Estonia, g loading},
abstract = {We examine the association between the strength of the Flynn effect in Estonia and highly convergent panel-ratings of the ‘abstractness’ of nine subtests on the National Intelligence Test, in order to test the theory that the Flynn effect results in part from an increase in the use of abstract reference frames in solving cognitive problems. The vectors of abstractness ratings and Flynn effect gains, controlled for guessing) exhibit a near-zero correlation (r=−.02); however, abstractness correlates positively with (and is therefore confounded by) g-loadings (r=.61). A General Linear Model is used to determine the degree to which the abstractness vector predicts the Flynn effect vector, independently of subtest g-loadings and the portion of the secular IQ gain due to guessing (the Brand effect). Consistent with the abstract reasoning model of the Flynn effect, abstractness positively predicts Flynn effect magnitudes, once controlled for confounds (sr=.44), which indicates an increasing tendency to utilize factors external to the items in order to abstract their solutions.}
}
@article{TALANOV201641,
title = {Emotional simulations and depression diagnostics},
journal = {Biologically Inspired Cognitive Architectures},
volume = {18},
pages = {41-50},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300676},
author = {Max Talanov and Jordi Vallverdú and Bin Hu and Philip Moore and Alexander Toschev and Diana Shatunova and Anzhela Maganova and Denis Sedlenko and Alexey Leukhin},
keywords = {Dopamine, Serotonin, Fear, Artificial intelligence, Simulation, Rat brain, Affective computing, Emotion modelling, Neuromodulation},
abstract = {In this work we propose the following hypothesis: the neuromodulatory mechanisms that control the emotional states of mammals can be translated and re-implemented in a computer by controlling the computational performance of a hosted computational system. In our specific implementation, we represent the simulation of the ‘fear-like’ state based on the three dimensional neuromodulatory model of affects, in this paper ‘affects’ refer to the basic emotional inborn states, inherited from works of Hugo Lövheim. Whilst dopamine controls attention, serotonin is the key for inhibition, and fear is a elicitator for inhibitory and protective processes. This inhibition can promote [in a cognitive system] to blocking behaviour which can be labelled as ’depression’. Therefore, our interest is how to reimplement biomimetically both action-regulators without the computational system to resulting in a ‘failed’ scenario. We have simulated 1000ms of the dopamine system using NEST Neural Simulation Tool with the rat brain as the model. The results of the simulation experiments are reported with an evaluation to demonstrate the correctness of our hypothesis.}
}
@article{FESTA2024,
title = {Incidence of circular refurbishment measures on indoor air quality and comfort conditions in two real buildings: Experimental and numerical analysis},
journal = {Energy and Built Environment},
year = {2024},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666123324000394},
author = {Valentino Festa and Silvia Ruggiero and Sara Riccardi and Margarita- Niki Assimakopoulos and Dimitra Papadaki},
keywords = {Energy building refurbishment, Experimental campaign, Indoor air quality, Thermal comfort, Computational fluid dynamics analysis},
abstract = {The application of Circular Economy to construction sector is a key to attain carbon neutrality, since it is responsible of 40 % of natural resource consumption. In this frame the importance of an efficient building refurbishment process throughout recycled material and renewable energy is fundamental. From an overview about building refurbishment emerges the need to investigate aspects related to Indoor Environmental Quality and the comparison between in-field measurements with output of dynamic simulation models. The present study aims to fill these two gaps by means an energy renovation of two real buildings in Greece. The work develops within the European project “Drive 0″, born to promote deep environmentally friendly retrofitting by means of circular renovation concepts. The methodological approach involves on-site monitoring of a series of parameters describing the energy, microclimate environmental and air quality, before and after the energy requalification. In addition, a numerical model developed in Building Energy Simulation program is calibrated and a Computational Fluid Dynamics is developed. From the in-field measurements emerges that, on one hand, the refurbishment of heating system shows a great improvement of indoor thermal conditions, with Total Volatile Organic Compounds concentration that sometimes exceed 3.0 mg/m3; on the other hand an integrated thermal insulation reduces infiltrations and changes the envelope behaviour, with a global energy saving of 30 % during winter and autumn periods. Another result of the study shows that a numerical model developed in Building Energy Simulation program and calibrated on energy consumption can greatly fit the local thermal comfort distribution of the occupant zone and predict the indoor air quality, if it outputs are used as input data in a Computational Fluid Dynamics study. These results can be beneficial to decision makers and designers for evaluating emitters positioning, opening design and mechanical ventilation strategies, aimed at reducing energy costs.}
}
@incollection{VOINOV201733,
title = {Participatory Modeling for Sustainability},
editor = {Martin A. Abraham},
booktitle = {Encyclopedia of Sustainable Technologies},
publisher = {Elsevier},
address = {Oxford},
pages = {33-39},
year = {2017},
isbn = {978-0-12-804792-7},
doi = {https://doi.org/10.1016/B978-0-12-409548-9.10532-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780124095489105329},
author = {Alexey Voinov},
keywords = {Biases, Modeling process, Social media, Stakeholders, Wicked problem},
abstract = {Sustainability is a wicked problem, which is hard to define in a unique way. It cannot be solved and should be treated in a participatory approach involving as many stakeholders in the process as possible. Participatory modeling is an efficient method for dealing with wicked problems. It involves stakeholders in an open-ended process of shared learning and can be essential for developing sustainable technologies. While there may be various levels of participation, the process evolves around a model of the system at stake. The model is built in interaction with the stakeholders; it provides formalism to synchronize stakeholder thinking and knowledge about the system and to move toward consensus about the possible decision making.}
}
@article{THAGARD1986301,
title = {Parallel computation and the mind-body problem},
journal = {Cognitive Science},
volume = {10},
number = {3},
pages = {301-318},
year = {1986},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(86)80020-9},
url = {https://www.sciencedirect.com/science/article/pii/S0364021386800209},
author = {Paul Thagard},
abstract = {The position in the philosophy of mind called functionalism claims that mental states are to be understood in terms of their functional relationships to other mental states, not in terms of their material instantiation in any particular kind of hardware. But the argument that material instantiation is irrelevant to functional relationships is computationally naive. This paper uses recent work on parallel computation to argue that software and hardware are much more intertwined than the functionalists allow. Parallelism offers qualitative as well as quantitative advantages, leading to different styles of programming as well as increased speed. Hence hardware may well matter to the mental: only by further empirical investigations of the relation between the mind and brain and between artificial intelligence software and underlying hardware will we be able to achieve a defensible solution to the mind-body problem. The major disadvantage of parallel systems is the need to coordinate their subprocesses, but recent proposals that consciousness provides a serial control for parallel computation are implausible.}
}
@article{STEFIK1989241,
title = {Computation and cognition: Toward a foundation of cognitive science: Z.W. Pylyshyn, (MIT Press, Cambridge, MA, 1986); 292 pages, $33.75 (hardcover), $9.95 (paperback)},
journal = {Artificial Intelligence},
volume = {38},
number = {2},
pages = {241-247},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90061-1},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900611},
author = {Mark Stefik}
}
@article{MOEBEHRENS2013e201304003,
title = {THE BIOLOGICAL MICROPROCESSOR, OR HOW TO BUILD A COMPUTER WITH BIOLOGICAL PARTS},
journal = {Computational and Structural Biotechnology Journal},
volume = {7},
number = {8},
pages = {e201304003},
year = {2013},
issn = {2001-0370},
doi = {https://doi.org/10.5936/csbj.201304003},
url = {https://www.sciencedirect.com/science/article/pii/S200103701460026X},
author = {Gerd HG Moe-Behrens},
abstract = {Systemics, a revolutionary paradigm shift in scientific thinking, with applications in systems biology, and synthetic biology, have led to the idea of using silicon computers and their engineering principles as a blueprint for the engineering of a similar machine made from biological parts. Here we describe these building blocks and how they can be assembled to a general purpose computer system, a biological microprocessor. Such a system consists of biological parts building an input / output device, an arithmetic logic unit, a control unit, memory, and wires (busses) to interconnect these components. A biocomputer can be used to monitor and control a biological system.}
}
@article{PADGETT1994185,
title = {Computational intelligence standards: motivation, current activities and progress},
journal = {Computer Standards & Interfaces},
volume = {16},
number = {3},
pages = {185-203},
year = {1994},
issn = {0920-5489},
doi = {https://doi.org/10.1016/0920-5489(94)90011-6},
url = {https://www.sciencedirect.com/science/article/pii/0920548994900116},
author = {Mary Lou Padgett and Walter J Karplus and Steve Deiss and Robert Shelton},
keywords = {Terminology, Artificial neural networks, Specification, Virtual reality},
abstract = {Computational Intelligence is an emerging technology of keen interest to the developers of computer standards and interfaces. Coherent communications among the diverse set of users of computational AI is necessary for the protection of all parties and can help further the serious development of artificial neural networks, fuzzy systems, evolutionary programming and virtual reality. Current activities of the IEEE Neural Networks Council Standards Committee encompass all these areas, emphasizing the development of glossaries and symbologies, performance measures and interface standards for these interrelated fields. Progress toward these goals is described in this paper.}
}
@article{BARNES2021,
title = {Gene Expression and Data Analysis Pipeline Using Cancer BioPortal in the Classroom},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2315},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000277},
author = {Chassidy N. Barnes and Blake P. Johnson and Stefanie W. Leacock and Ruben M. Ceballos and Lori L. Hensley and Nathan S. Reyna},
abstract = {At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis.
ABSTRACT
At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis. Cancer BioPortal (cBioPortal) is an open-access collective cancer research resource for storing and exploring clinical, genomic, proteomic, and transcriptomic data. cBioPortal eliminates the computational barrier of interpreting complex genomic data by providing easily understandable visualization that can be interpreted and translated into relevant biological insights. Because no prior computational knowledge is required, cBioPortal is an ideal educational tool for either in-person or distance learning environments. We developed a pedagogical approach, video tutorials, and data analysis workflows centered on using cBioPortal. Pedagogically, students develop an initial research outline that is continually updated and graded throughout the project. Progress during the project or course is assessed by a series of student presentations that are 5 to 15 min in length and are aimed at explaining the approach used in data acquisition, interpretation of the data, and relevance to the initial hypothesis. While cancer-specific, this analysis platform appeals to a wide range of classes and student interests. Further, the project has been successfully done both as an independent research experience and as part of a virtual class-based research project.}
}
@article{WOLFENGAGEN2024101185,
title = {Semantic configuration model with natural transformations},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101185},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101185},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001195},
author = {Viacheslav Wolfengagen and Larisa Ismailova and Sergey Kosikov and Igor Slieptsov and Sebastian Dohrn and Alexander Marenkov and Vladislav Zaytsev},
keywords = {Information process, Configuration, Morphing, Cognitive preference, Semantic net, Functor, Natural transformation},
abstract = {In the present work, efforts have been made to create a configuration-based approach to knowledge extraction. The notion of granularity is developed, which allows fine-tuning the expressive possibilities of the semantic network. As known, the central issues for knowledge-based systems are what’s-in-a-node and what’s-in-a-link. As shown, the answer can be obtained from the functor-as-object representation. Then the nodes are functors, and the main links are natural transformations. Such a model is applicable to represent morphing, and the object is considered as a process, which is in a harmony with current ideas on computing. It is possible to represent information channels that carry out the transformations of processes. The possibility of generating displaced concepts and the generation of families of their morphs is shown, the evolvent of stages of knowledge and properties of the process serve as parameters.}
}
@article{CORFIELD2011571,
title = {Understanding the infinite II: Coalgebra},
journal = {Studies in History and Philosophy of Science Part A},
volume = {42},
number = {4},
pages = {571-579},
year = {2011},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2011.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S003936811100077X},
author = {David Corfield},
keywords = {Philosophy, Mathematics, Category theory, Coalgebra, Infinite},
abstract = {In this paper we give an account of the rise and development of coalgebraic thinking in mathematics and computer science as an illustration of the way mathematical frameworks may be transformed. Originating in a foundational dispute as to the correct way to characterise sets, logicians and computer scientists came to see maximizing and minimizing extremal axiomatisations as a dual pair, each necessary to represent entities of interest. In particular, many important infinitely large entities can be characterised in terms of such axiomatisations. We consider reasons for the delay in arriving at the coalgebraic framework, despite many unrecognised manifestations occurring years earlier, and discuss an apparent asymmetry in the relationship between algebra and coalgebra.}
}
@article{UBAN2021480,
title = {An emotion and cognitive based analysis of mental health disorders from social media data},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {480-494},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001825},
author = {Ana-Sabina Uban and Berta Chulvi and Paolo Rosso},
keywords = {Mental health disorders, Early risk prediction, Emotions, Cognitive styles, Deep learning, Social media},
abstract = {Mental disorders can severely affect quality of life, constitute a major predictive factor of suicide, and are usually underdiagnosed and undertreated. Early detection of signs of mental health problems is particularly important, since unattended, they can be life-threatening. This is why a deep understanding of the complex manifestations of mental disorder development is important. We present a study of mental disorders in social media, from different perspectives. We are interested in understanding whether monitoring language in social media could help with early detection of mental disorders, using computational methods. We developed deep learning models to learn linguistic markers of disorders, at different levels of the language (content, style, emotions), and further try to interpret the behavior of our models for a deeper understanding of mental disorder signs. We complement our prediction models with computational analyses grounded in theories from psychology related to cognitive styles and emotions, in order to understand to what extent it is possible to connect cognitive styles with the communication of emotions over time. The final goal is to distinguish between users diagnosed with a mental disorder and healthy users, in order to assist clinicians in diagnosing patients. We consider three different mental disorders, which we analyze separately and comparatively: depression, anorexia, and self-harm tendencies.}
}
@article{CAMARGO2022496,
title = {Existence, Hypotheses and Categories in Knowledge Representation},
journal = {Procedia Computer Science},
volume = {213},
pages = {496-503},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.096},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922017872},
author = {Eduardo Camargo and Eduardo Yuji Sakabe and Ricardo Gudwin},
keywords = {Knowledge Representation, Cognitive Architecture, Cognitive Semiotics, Artificial Intelligent Agent},
abstract = {Cognitive architectures employ different means for knowledge representation. In this work, we describe how the Cognitive Systems Toolkit (CST), a toolkit for the construction of cognitive architectures addresses the issue of knowledge representation, by introducing the notion of a computational idea, as being an abstract and generic building block for representing multiple different pieces of knowledge. We particularly address how computational ideas can be used to represent both facts that really happened at an environment and just hypothesis that are not to be considered as being a part of existence, explaining how these are instances of general categories. At the end, we provide different examples to illustrate the subtle differences that are possible to be represented using this knowledge representation scheme.}
}
@article{MILDNER2019763,
title = {Spontaneous Thought as an Unconstrained Memory Process},
journal = {Trends in Neurosciences},
volume = {42},
number = {11},
pages = {763-777},
year = {2019},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2019.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166223619301626},
author = {Judith N. Mildner and Diana I. Tamir},
keywords = {spontaneous thought, memory, computational model, mind wandering, default network},
abstract = {The stream of thought can flow freely, without much guidance from attention or cognitive control. What determines what we think about from one moment to the next? Spontaneous thought shares many commonalities with memory processes. We use insights from computational models of memory to explain how the stream of thought flows through the landscape of memory. In this framework of spontaneous thought, semantic memory scaffolds episodic memory to form the content of thought, and drifting context modulated by one's current state – both internal and external – constrains the area of memory to explore. This conceptualization of spontaneous thought can help to answer outstanding questions such as: what is the function of spontaneous thought, and how does the mind select what to think about?}
}
@article{MORAWSKI200231,
title = {Are measurement-oriented courses getting too difficult for Polish students?},
journal = {Measurement},
volume = {32},
number = {1},
pages = {31-38},
year = {2002},
issn = {0263-2241},
doi = {https://doi.org/10.1016/S0263-2241(01)00053-7},
url = {https://www.sciencedirect.com/science/article/pii/S0263224101000537},
author = {Roman Z Morawski},
keywords = {Measurement, Abstract thinking, Experimentation skills, Teaching methodology},
abstract = {The measurement is assumed to be the most reliable means of acquiring information on physical reality; consequently, measurement science and technology is of fundamental importance for all the branches of engineering which have to deal with real-world objects and phenomena. Unfortunately, the ability of today’s students of engineering to grasp basic ideas of measurement science and to master basic skills related to measurement technology seems to be seriously endangered, inter alia, by the omnipresence of computer-related topics in engineering curricula. Paradoxically, it is also endangered by some cultural changes that undermine the historically established role of abstract thinking in the development of Latin civilisation. Educators cannot avoid the question: what kind of remedial measures should be undertaken? This paper aims to contribute to better understanding of various difficulties the teachers of measurement-related courses are facing today.}
}
@article{MENG201851,
title = {Conducting highly principled data science: A statistician’s job and joy},
journal = {Statistics & Probability Letters},
volume = {136},
pages = {51-57},
year = {2018},
note = {The role of Statistics in the era of big data},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2018.02.053},
url = {https://www.sciencedirect.com/science/article/pii/S0167715218300981},
author = {Xiao-Li Meng},
keywords = {Astrostatistics, Computational efficiency, Principled corner cutting, Scientific justification},
abstract = {Highly Principled Data Science insists on methodologies that are: (1) scientifically justified; (2) statistically principled; and (3) computationally efficient. An astrostatistics collaboration, together with some reminiscences, illustrates the increased roles statisticians can and should play to ensure this trio, and to advance the science of data along the way.}
}
@article{FAYEZ2023105905,
title = {Moringa extract reverses pilocarpine-induced hippocampal sclerosis in rats with temporal lobe epilepsy},
journal = {Journal of Functional Foods},
volume = {111},
pages = {105905},
year = {2023},
issn = {1756-4646},
doi = {https://doi.org/10.1016/j.jff.2023.105905},
url = {https://www.sciencedirect.com/science/article/pii/S1756464623005054},
author = {Shaimaa Fayez and Nourhan {Hisham Shady} and Iten M. Fawzy and Sherif A. Maher and Entesar {Ali saber} and Mahmoud Elrehany and Alaa M. Alqahtani and Esam S. Allehyani and Ahmed M. Shawky and Usama {Ramadan Abdelmohsen} and Nada M. Mostafa},
keywords = {, Moringinine A, Computational studies, Epilepsy},
abstract = {The horseradish tree “Moringa oleifera” is the most nutritious terrestrial plant around the globe. Although native to India, its fast growth and drought resistance ability enabled the plant to be cultivated worldwide. In the current study, we report on the isolation of a new phenolic methyl ester namely moringinine A (1) along with four other known compounds viz. caffeic acid (2), ferulic acid (3), 4-hydroxybenzonitrile (4), and 4-hydroxyphenyl acetic acid (5) from Moringa seeds. The later compound was first to be isolated from family Moringaceae. Compounds identification was guided by interplay of NMR and HR-ESI-MS analysis. Anti-epileptic studies conducted in vivo showed that the extract attenuates convulsions by suppressing stress–induced pro-inflammatory markers TNF-α, IL-1β, IL-6, and IFN-ɣ whereas upregulating the anti-inflammatory markers TGF-β and IL-10 in the hippocampal tissues of epileptic rats. The isolated compounds were subjected to computational studies through docking on lactate dehydrogenase A(LDH) and interleukin-6 (IL-6), where all showed binding modes and interaction energies comparable to those of the reference drug diazepam. ADME investigation revealed good pharmacokinetic and drug-likeness properties. These results show that Moringa oleifera seeds could potentially be used as adjuvant in the management of epilepsy.}
}
@article{1995146,
title = {95/02164 Sequential pressure-based Navier-Stokes algorithms on SIMD computers: Computational issues},
journal = {Fuel and Energy Abstracts},
volume = {36},
number = {2},
pages = {146},
year = {1995},
issn = {0140-6701},
doi = {https://doi.org/10.1016/0140-6701(95)93829-X},
url = {https://www.sciencedirect.com/science/article/pii/014067019593829X}
}
@article{DELIMA2024107089,
title = {Integrating artificial intelligence and wing geometric morphometry to automate mosquito classification},
journal = {Acta Tropica},
volume = {249},
pages = {107089},
year = {2024},
issn = {0001-706X},
doi = {https://doi.org/10.1016/j.actatropica.2023.107089},
url = {https://www.sciencedirect.com/science/article/pii/S0001706X23002760},
author = {Vinicio Rodrigues {de Lima} and Mauro César Cafundó {de Morais} and Karin Kirchgatter},
keywords = {Mosquito-borne diseases, Species identification, Integrative approach},
abstract = {Mosquitoes (Diptera: Culicidae) comprise over 3500 global species, primarily in tropical regions, where the females act as disease vectors. Thus, identifying medically significant species is vital. In this context, Wing Geometric Morphometry (WGM) emerges as a precise and accessible method, excelling in species differentiation through mathematical approaches. Computational technologies and Artificial Intelligence (AI) promise to overcome WGM challenges, supporting mosquito identification. AI explores computers' thinking capacity, originating in the 1950s. Machine Learning (ML) arose in the 1980s as a subfield of AI, and deep Learning (DL) characterizes ML's subcategory, featuring hierarchical data processing layers. DL relies on data volume and layer adjustments. Over the past decade, AI demonstrated potential in mosquito identification. Various studies employed optical sensors, and Convolutional Neural Networks (CNNs) for mosquito identification, achieving average accuracy rates between 84 % and 93 %. Furthermore, larval Aedes identification reached accuracy rates of 92 % to 94 % using CNNs. DL models such as ResNet50 and VGG16 achieved up to 95 % accuracy in mosquito identification. Applying CNNs to georeference mosquito photos showed promising results. AI algorithms automated landmark detection in various insects' wings with repeatability rates exceeding 90 %. Companies have developed wing landmark detection algorithms, marking significant advancements in the field. In this review, we discuss how AI and WGM are being combined to identify mosquito species, offering benefits in monitoring and controlling mosquito populations.}
}
@article{ZIA2022108066,
title = {SoFTNet: A concept-controlled deep learning architecture for interpretable image classification},
journal = {Knowledge-Based Systems},
volume = {240},
pages = {108066},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.108066},
url = {https://www.sciencedirect.com/science/article/pii/S095070512101145X},
author = {Tehseen Zia and Nauman Bashir and Mirza Ahsan Ullah and Shakeeb Murtaza},
keywords = {Interpretability, Concepts, KNN, Explanation satisfaction},
abstract = {Interpreting deep learning (DL)-based computer vision models is challenging due to the complexity of internal representations. Most recent techniques for rendering DL learning outcomes interpretable operate on low-level features rather than high-level concepts. Methods that explicitly incorporate high-level concepts do so through a determination of the relevancy of user-defined concepts or else concepts extracted directly from the data. However, they do not leverage the potential of concepts to explain model predictions. To overcome this challenge, we introduce a novel DL architecture – the Slow/Fast Thinking Network (SoFTNet) – enabling users to define/control high-level features and utilize them to perform image classification predicatively. We draw inspiration from the dual-process theory of human thought processes, decoupling low-level, fast & non-transparent processing from high-level, slow & transparent processing. SoFTNet hence uses a shallow convolutional neural network for low-level processing in conjunction with a memory network for high-level concept-based reasoning. We conduct experiments on the CUB-200-2011 and STL-10 datasets and also present a novel concept-based deep K-nearest neighbor approach for baseline comparisons. Our experiments show that SoFTNet achieves comparable performance to state-of-art non-interpretable models and outperforms comparable interpretative methods.}
}
@incollection{KRINGELBACH2019139,
title = {24 - Whole-brain modeling of neuroimaging data: Moving beyond correlation to causation},
editor = {Amir Raz and Robert T. Thibault},
booktitle = {Casting Light on the Dark Side of Brain Imaging},
publisher = {Academic Press},
pages = {139-143},
year = {2019},
isbn = {978-0-12-816179-1},
doi = {https://doi.org/10.1016/B978-0-12-816179-1.00024-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128161791000244},
author = {Morten L. Kringelbach and Gustavo Deco},
keywords = {Whole-brain modeling, neuroimaging, causative mechanisms},
abstract = {Neuroimaging has offered an unprecedented window on human brain activity. While this advance has led to great expectations, many neuroscientists have grown increasingly frustrated with the lack of causal insights that this technique has provided into human brain function, in turn, leading to heated discussions on the potential rise of neophrenology. Elsewhere in this book, you can read about the apparent failure of brain imaging to tell us much new or meaningful about thinking and cognition in general. Such views are true to a certain extent; brain imaging often takes indirect measures of neural activity such as blood flow and, just because such brain measures correlate with behavioral output, does not mean that they cause the output. But, these new tools do measure important information about brain activity that could potentially tell us a great deal about brain and mind.}
}
@article{SPENCE2022100433,
title = {Gastrophysics: Getting creative with pairing flavours},
journal = {International Journal of Gastronomy and Food Science},
volume = {27},
pages = {100433},
year = {2022},
issn = {1878-450X},
doi = {https://doi.org/10.1016/j.ijgfs.2021.100433},
url = {https://www.sciencedirect.com/science/article/pii/S1878450X21001323},
author = {Charles Spence},
keywords = {Food pairing, Flavour pairing hypothesis, Sonic seasoning, Computational gastronomy, Data engineering, Gastrophysics},
abstract = {Traditionally, in the West, the decision about which flavours to pair in a tasting experience has been as much the personal choice of the chef or, more likely, the sommelier, as anything else. However, the last couple of decades have seen a rapid growth of research interest in the pairing of flavours. Nowadays, one can find examples of people pairing everything from beer with food, tea with cheese and chocolate, etc. As interest in the marketing potential of flavour pairing has risen, along with the growing public fascination in the topic, scientists have become increasingly interested in trying to understand the principles (both cognitive/intellectual and perceptual) underlying the successful pairing of flavours. In this narrative review, the relative strengths and weaknesses of the chemical, computational (gastronomy), and perceptual approaches to pairing flavours are highlighted. Thereafter, I show how the various principles of pairing (both perceptual and cognitive/intellectual) can be extended beyond the domain of pairing flavour with flavour to consider the rapidly growing are of sonic seasoning. The latter term refers to those situations in which specific pieces of music or soundscapes are matched, or paired, with particular tastes/flavours based on the crossmodal correspondences. The review ends by considering the future development of pairings flavours, and assessing novel means of establishing connections between flavours and other sensations.}
}
@article{MAGRI2023105535,
title = {Scene context is predictive of unconstrained object similarity judgments},
journal = {Cognition},
volume = {239},
pages = {105535},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105535},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001695},
author = {Caterina Magri and Eric Elmoznino and Michael F. Bonner},
keywords = {Contextual associations, Objects, Scenes, Similarity, Convolutional neural networks, Natural image statistics},
abstract = {What makes objects alike in the human mind? Computational approaches for characterizing object similarity have largely focused on the visual forms of objects or their linguistic associations. However, intuitive notions of object similarity may depend heavily on contextual reasoning—that is, objects may be grouped together in the mind if they occur in the context of similar scenes or events. Using large-scale analyses of natural scene statistics and human behavior, we found that a computational model of the associations between objects and their scene contexts is strongly predictive of how humans spontaneously group objects by similarity. Specifically, we learned contextual prototypes for a diverse set of object categories by taking the average response of a convolutional neural network (CNN) to the scene contexts in which the objects typically occurred. In behavioral experiments, we found that contextual prototypes were strongly predictive of human similarity judgments for a large set of objects and rivaled the performance of models based on CNN representations of the objects themselves or word embeddings for their names. Together, our findings reveal the remarkable degree to which the natural statistics of context predict commonsense notions of object similarity.}
}
@article{RAMOS202335,
title = {An institutional modernization project in chemical engineering education in Brazil: Developing broader competencies for societal challenges},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {35-44},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000167},
author = {Bruno Ramos and Moisés Teles dos Santos and Ardson S. Vianna and Luiz Kulay},
keywords = {Process safety, Chemical reaction engineering, Education, Active-based learning},
abstract = {Contemporary societal challenges put in evidence the need to improve the hard and soft skills of chemical engineering students. To promote a more student-centered approach, active-based learning, and improved assessment strategies, the Brazilian government approved the so-called New National Curriculum Guidelines (NCG) for engineering courses. To comply with those guidelines, the Department of Chemical Engineering of the Polytechnic School of the University of São Paulo (USP) is currently developing an educational modernization process sponsored by the Fulbright Commission in Brazil, called Special Program for Modernization of Undergraduate Education (PMG). The project is based on three pillars of modernization: content (what), form (how), and infrastructure (where). This paper describes initiatives in each of those pillars: content and format changes in Chemical Reaction Engineering and Process Safety courses and the creation of new spaces for a student-centered approach (an innovative classroom layout and a makerspace). By gathering two concrete classroom experiences guided by a broader institutional educational policies (the PMG project and the NCG), this paper highlights that slight changes can lead to great improvements in the learning process, leading to more engagement in the development of hard skills while favoring improvements in soft skills, such as communication, team-based work, and critical thinking.}
}
@article{CHEN2024132899,
title = {A novel offshore wind power prediction model based on TCN-DANet-sparse transformer and considering spatio-temporal coupling in multiple wind farms},
journal = {Energy},
volume = {308},
pages = {132899},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.132899},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224026732},
author = {Juntao Chen and Xueying Fu and Lingli Zhang and Haoye Shen and Jibo Wu},
keywords = {Dual attention network, Temporal convolutional network, Offshore wind power prediction, Sparse transformer, Spatio-temporal coupling},
abstract = {Offshore wind power capacity is growing, leading to larger clustered farms. Accurately predicting offshore wind power capacity is crucial for power system stability; however, current studies often overlook neighbouring installations. To address this, this study presents the Temporal Convolutional Network-Dual Attention Network-Sparse Transformer (TCN-DANet-Sparse Transformer) model, which considers the spatiotemporal coupling of multiple wind farms. Before detailing our model, we review the existing prediction methods, noting their limitations in capturing interconnected adjacent wind farms. Our model integrates spatial information from nearby farms to enhance prediction reliability. Through Pearson Correlation Coefficient analysis, we explore the temporal and spatial coupling features. Using overlapping sliding windows, we partition farms into subsequences, processed with TCN-DANet for efficient spatio-temporal feature extraction. These features are then input into the Sparse Transformer to improve the computational efficiency. Validated using a dataset from Kächele et al., our model outperforms the baseline on the London Wind Farm. In spring, for Case 1, the mean square error (MSE) of the main model decreased by 43.19 % compared to that of the TCN-DANet-transformer model. Similarly, for Case 2, the MSE of the main model is reduced by 41.69 %.}
}
@article{MIDGLEY2019181,
title = {Anticipatory practice and the making of surplus food},
journal = {Geoforum},
volume = {99},
pages = {181-189},
year = {2019},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2018.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0016718518302720},
author = {Jane L. Midgley},
keywords = {Surplus food, Anticipation, Market devices, Redistribution, United Kingdom},
abstract = {This paper explores the practices that have evolved between a global food retailer and a leading charitable surplus food redistributor to enable the utilization of surplus food in community and charitable meal settings in the UK. I argue that to understand surplus food and its potential futures (consumed or wasted), closer engagement with anticipatory thinking is needed. Drawing on interview data with key stakeholders and observations of the food industry redistribution process the paper explores the anticipatory actions taken by different actors as they attempt to manage the possible futures of foods that become categorized as surplus. The paper shows how different market devices are used to manage market concerns about surplus food and work to assure its future consumption. The devices focus on managing the risks of the food becoming unsafe and the associated legal liabilities. The market concerns, as expressions of anticipatory thinking, inform a series of anticipatory practices throughout the redistribution process to enable all actors, and especially the Retailer, to trust in the process. The paper concludes by noting how reliant the redistribution process is on anticipatory practices, especially pre-emption and improvisation to make the process workable, but also how these work to contain the various concerns within market arrangements. The paper highlights the importance of anticipation as a theoretical basis for exploring surplus food and the concept of surplus more widely.}
}
@incollection{FINI2019161,
title = {Chapter 7 - Sustainable Procurement and Transport of Construction Materials},
editor = {Vivian W.Y. Tam and Khoa N. Le},
booktitle = {Sustainable Construction Technologies},
publisher = {Butterworth-Heinemann},
pages = {161-209},
year = {2019},
isbn = {978-0-12-811749-1},
doi = {https://doi.org/10.1016/B978-0-12-811749-1.00005-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128117491000055},
author = {Alireza Ahmadian Fard Fini and Ali Akbarnezhad},
keywords = {Sustainable construction materials, life cycle thinking, procurement and transport, prefabrication technologies},
abstract = {Construction industry is the largest global consumer of materials. This huge share comes with the huge responsibility to account for economic, environmental, and social impacts associated with the materials through adoption of sustainable procurement strategies. Sustainable material procurement requires reconciliation among economic, environmental and social impacts of procurement decisions throughout the life cycle of materials. However, this is challenging mainly due to the broad range of economic, environmental and social impacts associated with different stages of material’s life cycle as well as the overlapping impacts that various supply decisions may have on multiple performance areas. Current practices of material procurement are, on the other hand, predominantly influenced by economy of construction stage and little attention is paid to environmental and social considerations over a long-term horizon. Moreover, material supply decisions made currently in practice are commonly traditional and tend to largely overlook the opportunities made available by advances in material science, computing, and decision-making areas. This chapter starts by presenting an overview of sustainability challenges associated with current material procurement practices to highlight the need for adoption of new sustainable approaches and technologies. It then continues by highlighting the challenges associated with adoption of new approaches and the important sustainability criteria to be considered in selection of new sustainable materials, technologies, and procurement strategies. A comprehensive decision-making framework for identifying the most sustainable procurement options in a construction project among various procurement options available is then presented. The framework is founded on the concepts of life cycle thinking and supply chain structure which are incorporated in to a computational module to compare the life cycle impacts of various supply decision based on the selection criteria determined collaboratively by different project stakeholders. The results of such comparative analysis leads to a ranking of various procurement decision alternatives comprised of different combinations of supply decision including material type, material supply structure, location of supplier, and mode of transport.}
}
@article{DELLANNA2022105064,
title = {Evolving Fuzzy logic Systems for creative personalized Socially Assistive Robots},
journal = {Engineering Applications of Artificial Intelligence},
volume = {114},
pages = {105064},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105064},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622002251},
author = {Davide Dell’Anna and Anahita Jamshidnejad},
keywords = {Evolving Fuzzy logic Systems, Personalized Socially Assistive Robots, Robot creativity},
abstract = {Socially Assistive Robots (SARs) are increasingly used in dementia and elderly care. In order to provide effective assistance, SARs need to be personalized to individual patients and account for stimulating their divergent thinking in creative ways. Rule-based fuzzy logic systems provide effective methods for automated decision-making of SARs. However, expanding and modifying the rules of fuzzy logic systems to account for the evolving needs, preferences, and medical conditions of patients can be tedious and costly. In this paper, we introduce EFS4SAR, a novel Evolving Fuzzy logic System for Socially Assistive Robots that supports autonomous evolution of the fuzzy rules that steer the behavior of the SAR. EFS4SAR combines traditional rule-based fuzzy logic systems with evolutionary algorithms, which model the process of evolution in nature and have shown to result in creative behaviors. We evaluate EFS4SAR via computer simulations on both synthetic and real-world data. The results show that the fuzzy rules evolved over time are not only personalized with respect to the personal preferences and therapeutic needs of the patients, but they also meet the following criteria for creativity of SARs: originality and effectiveness of the therapeutic tasks proposed to the patients. Compared to existing evolving fuzzy systems, EFS4SAR achieves similar effectiveness with higher degree of originality.}
}
@article{BARNES2021,
title = {Gene Expression and Data Analysis Pipeline Using Cancer BioPortal in the Classroom},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2313},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000721},
author = {Chassidy N. Barnes and Blake P. Johnson and Stefanie W. Leacock and Ruben M. Ceballos and Lori L. Hensley and Nathan S. Reyna},
abstract = {At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis.
ABSTRACT
At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis. Cancer BioPortal (cBioPortal) is an open-access collective cancer research resource for storing and exploring clinical, genomic, proteomic, and transcriptomic data. cBioPortal eliminates the computational barrier of interpreting complex genomic data by providing easily understandable visualization that can be interpreted and translated into relevant biological insights. Because no prior computational knowledge is required, cBioPortal is an ideal educational tool for either in-person or distance learning environments. We developed a pedagogical approach, video tutorials, and data analysis workflows centered on using cBioPortal. Pedagogically, students develop an initial research outline that is continually updated and graded throughout the project. Progress during the project or course is assessed by a series of student presentations that are 5 to 15 min in length and are aimed at explaining the approach used in data acquisition, interpretation of the data, and relevance to the initial hypothesis. While cancer-specific, this analysis platform appeals to a wide range of classes and student interests. Further, the project has been successfully done both as an independent research experience and as part of a virtual class-based research project.}
}
@article{HOSSEINI2019186,
title = {A morphological approach for kinetic façade design process to improve visual and thermal comfort: Review},
journal = {Building and Environment},
volume = {153},
pages = {186-204},
year = {2019},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2019.02.040},
url = {https://www.sciencedirect.com/science/article/pii/S0360132319301416},
author = {Seyed Morteza Hosseini and Masi Mohammadi and Alexander Rosemann and Torsten Schröder and Jos Lichtenberg},
keywords = {Kinetic façade, Biomimicry, Morphological approach, Comfort condition, Parametric design thinking},
abstract = {Visual and thermal comfort for occupants significantly depend on exterior environmental climatic conditions, which are continuously changing. In particular, optimizing visual and thermal comfort simultaneously is a difficult topic due to mutual conflicts between them. This literature review article studies the façade, as a complex interface between inside of buildings and the outside that has a capability to function as a protective or regulatory element against severe fluctuations of external climate. Six interrelated subjects are studied including kinetic façade, biomimicry, building form as a microclimate modifier, energy efficiency, comfort condition, parametric design thinking. The literature review process answers following research questions: (1) what are the interdisciplinary subjects corresponding to kinetic façade design process for creating an innovative architectural process? (2) What is the most important factor in kinetic façade design with the aim to improve occupants’ visual and thermal comfort simultaneously based on multidisciplinary investigation? Many research has been carried out about kinetic façade concepts strategies, principles, and criteria. However, interdisciplinary studies for proposing kinetic façade form is relatively rare. Also, adaptive daylight façade with daily solar geometry variation has been highly required. Therefore, generative-parametric and quick form finding method for responding to different climates would be a solution for providing more adaptability to dynamic daylight. This study aims to propose a kinetic façade design process which have capability to improve occupant visual & thermal comfort simultaneously by controlling on-site renewable energy resources consist of solar radiation and wind. Façade as an only interface between inside and outside of building, far from the literal and historical perceptions, is recognized by intrinsic functional attributes including complexity, heterogeneity and multidisciplinary. Moreover, the interrelated subjects impact façade form individually and aggregately regard to functional scenario that is changed the perception of kinetic façade from elegant and fashionable state to a functional and practical element.}
}
@article{TAMILVENDAN2024469,
title = {Parametric optimization in drilling of sisal–glass reinforced epoxy composites using Taguchi grey relational analysis method},
journal = {Transactions of the Canadian Society for Mechanical Engineering},
volume = {48},
number = {3},
pages = {469-476},
year = {2024},
issn = {0315-8977},
doi = {https://doi.org/10.1139/tcsme-2024-0018},
url = {https://www.sciencedirect.com/science/article/pii/S0315897724000570},
author = {D. Tamilvendan and A.R. Ravikumar and R. Thirumalai},
keywords = {Taguchi grey relational analysis, drlling, glass fiber, sisal fiber, composite},
abstract = {This research work intends to study the effect of hybridization of glass and sisal fiber, stacking sequence and tensile properties of the composite. The sisal-glass fiber hybrid composites laminates are prepared using reinforced plain woven sisal fabric (unidirectional) and plainwoven glass fabric. In this research study, 27 experiments are conducted as per L27 orthogonal array. Five process parameters are selected and three responses are considered in this work. The drilling of the composite specimen is considered and the drilling process parameters such as speed, feed rate, drill diameter, material thickness, and drill point angle are selected. The responses considered in this work are delamination factor, thrust force, and torque. Taguchi analysis is performed and the response table for means for the responses is determined, and the most influencing parameter in the drilling of the composite specimen is analyzed. The grey relational coefficients are computed and followed with the computation of the grey relational grade. The grey relational grades are calculated for determining the highest contributing parameter in the drilling of the sisal fiber and glass fiber reinforced hybrid composite specimen. The optimum drilling process parameters are ranked and the ranks presented represent the sequence of run resulting in optimum solutions.}
}
@article{DAI2024108354,
title = {Leveraging artificial intelligence (AI) in English as a foreign language (EFL) classes: Challenges and opportunities in the spotlight},
journal = {Computers in Human Behavior},
volume = {159},
pages = {108354},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108354},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400222X},
author = {Kun Dai and Quanguo Liu},
keywords = {Artificial intelligence (AI), AI-Powered instruments, Challenges and opportunities, English as a foreign language (EFL) classes, EFL students},
abstract = {The widespread use of Artificial Intelligence (AI) in language education contexts has motivated several scholars around the world to uncover the advantages and disadvantages of AI and AI-powered instruments in different language classrooms. Yet, as the review of earlier investigations revealed, few inquiries have been carried out to divulge the pros and cons of leveraging AI in EFL classes. To narrow this gap, using the phenomenological approach, this inquiry investigated the opportunities and challenges of implementing AI in EFL classes from the perspective of Chinese EFL students. To do so, through the criterion sampling technique, a total of 45 EFL students was recruited from different educational institutions in China. To collect the dataset, participants were asked to complete an open-ended questionnaire. For the sake of triangulation, among the 45 participants, 15 were randomly selected to engage in a follow-up interview session. With the aid of MAXQDA software (version 2023), participants’ perceptions of AI opportunities and challenges were carefully analyzed. Overall, the analysis findings uncovered that leveraging AI in EFL classes can bring numerous opportunities for EFL students, including individualized learning, timely and immediate feedback, rich educational resources, and an interactive learning atmosphere. However, as demonstrated by the analysis outcomes, implementing AI in EFL courses may also face students with a range of challenges and problems. The research outcomes would be of great help to teachers and educational leaders in mitigating the challenges of leveraging AI in language classrooms.}
}
@article{DOOLITTLE2019889,
title = {Making Evolutionary Sense of Gaia},
journal = {Trends in Ecology & Evolution},
volume = {34},
number = {10},
pages = {889-894},
year = {2019},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169534719301417},
author = {W. Ford Doolittle},
keywords = {Gaia hypothesis, evolution, differential persistence, clade selection},
abstract = {The Gaia hypothesis in a strong and frequently criticized form assumes that global homeostatic mechanisms have evolved by natural selection favoring the maintenance of conditions suitable for life. Traditional neoDarwinists hold this to be impossible in theory. But the hypothesis does make sense if one treats the clade that comprises the biological component of Gaia as an individual and allows differential persistence – as well as differential reproduction – to be an outcome of evolution by natural selection. Recent developments in theoretical and experimental evolutionary biology may justify both maneuvers.}
}
@article{LI2022126546,
title = {Dynamic forecasting performance and liquidity evaluation of financial market by Econophysics and Bayesian methods},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {588},
pages = {126546},
year = {2022},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2021.126546},
url = {https://www.sciencedirect.com/science/article/pii/S0378437121008190},
author = {Jiang-Cheng Li and Chen Tao and Hai-Feng Li},
keywords = {Econophysics, Agent-based model, Liquidity risk assessment, Machine learning thinking, Microcosmic evolution models},
abstract = {In a complex financial system, what is the forecasting performance of macro and micro evolution models of Econophysics on asset prices? For this problem, from the perspective of machine learning, we study the dynamic forecasting and liquidity assessment of financial markets, based on econophysics and Bayesian methods. We establish eight dynamic prediction methods, based on our proposed likelihood estimation and Bayesian estimation methods of macro and micro evolution models of econophysics. Combined machine learning thinking and real data, we empirically study and simulate the out-of-sample dynamic forecasting analysis of eight proposed methods and compare with the benchmark GARCH model. A variety of loss functions, superior predictive ability test (SPA), Akaike and Bayesian information criterion (AIC and BIC) methods are introduced to further evaluate the forecasting performance of our proposed methods. The research of out of sample prediction shows that (1) the method of the simplified stochastic model with Bayesian method for only sample return has the best forecasting performance; (2) the method of the stochastic model with Bayesian method for only return samples has the worst forecasting performance. For the liquidity assessment problem, there is a strong correlation between the trading probability evaluated by the proposed eight methods and the real turnover rate, and an increase of liquidity is correspond to the increase of asset risk. In other words, it suggests that all proposed methods can well evaluate market liquidity.}
}
@article{WHITE200337,
title = {Promoting productive mathematical classroom discourse with diverse students},
journal = {The Journal of Mathematical Behavior},
volume = {22},
number = {1},
pages = {37-53},
year = {2003},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(03)00003-8},
url = {https://www.sciencedirect.com/science/article/pii/S0732312303000038},
author = {Dorothy Y. White},
keywords = {Classroom discourse, Questioning techniques, Equity/diversity, Elementary mathematics teaching},
abstract = {Productive mathematical classroom discourse allows students to concentrate on sense making and reasoning; it allows teachers to reflect on students’ understanding and to stimulate mathematical thinking. The focus of the paper is to describe, through classroom vignettes of two teachers, the importance of including all students in classroom discourse and its influence on students’ mathematical thinking. Each classroom vignette illustrates one of four themes that emerged from the classroom discourse: (a) valuing students’ ideas, (b) exploring students’ answers, (c) incorporating students’ background knowledge, and (d) encouraging student-to-student communication. Recommendations for further research on classroom discourse in diverse settings are offered.}
}
@incollection{LEACH202221,
title = {Chapter 2 - AI and the limits of human creativity in urban planning and design},
editor = {Imdat As and Prithwish Basu and Pratap Talwar},
booktitle = {Artificial Intelligence in Urban Planning and Design},
publisher = {Elsevier},
pages = {21-37},
year = {2022},
isbn = {978-0-12-823941-4},
doi = {https://doi.org/10.1016/B978-0-12-823941-4.00013-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239414000135},
author = {Neil Leach},
keywords = {AlphaGo, AI, Strategy, Urban planning, Creativity, Perception},
abstract = {What can architects learn from AlphaGo? This chapter explores the lessons to be learnt from the famous match where AlphaGo, a machine-learning system developed by DeepMind, beat leading Korean Go player, Lee Sedol. It explores the ramifications of this victory on a series of different levels, from the global impact of the match on research into AI to the impact on Xkool Technologies and Spacemaker AI, two architectural start-ups developing AI systems for architecture and urban planning. It makes a particular comparison between the operations of AlphaGo and the strategic thinking of urban planning, arguing that AI now puts the future of urban planners—and possibly also architects—at risk. It then goes on to appraise the famous Move 37 made by AlphaGo in Game 2 of this match. It argues that, despite appearances, this move was not actually creative. Finally, it explores how we might view human creativity in the light of comments made about AlphaGo. The chapter concludes by speculating whether the ultimate lesson of AlphaGo is that creativity is simply a question of “perceived creativity.”}
}
@incollection{STAUFFER2006i,
title = {Biology, Sociology, Geology by Computational Physicists},
editor = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins},
series = {Monograph Series on Nonlinear Science and Complexity},
publisher = {Elsevier},
volume = {1},
pages = {i-276},
year = {2006},
booktitle = {Biology, Sociology, Geology by Computational Physicists},
issn = {1574-6917},
doi = {https://doi.org/10.1016/S1574-6917(05)01001-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574691705010019},
author = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins}
}
@article{YANG201451,
title = {Reactivity of concurrent verbal reporting in second language writing},
journal = {Journal of Second Language Writing},
volume = {24},
pages = {51-70},
year = {2014},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2014.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S1060374314000113},
author = {Chengsong Yang and Guangwei Hu and Lawrence Jun Zhang},
keywords = {Reactivity, Think-aloud, Second language acquisition (SLA), L2 writing, Argumentative writing, Chinese EFL writers},
abstract = {This paper reports an empirical study designed to explore whether concurrent verbal reporting has a reactive effect on the process of second language writing. Ninety-five Chinese EFL learners were randomly assigned to an argumentative writing task under three conditions: metacognitive thinking aloud (MTA), nonmetacognitive thinking aloud (NMTA), and no thinking aloud (NTA), after they completed a similar baseline writing task. Their essays were analyzed in terms of linguistic fluency, complexity, accuracy, and overall quality to examine if there were any significant between-group differences that could be taken as evidence of reactivity. After controlling for baseline differences, analyses revealed no traces of reactivity left on a majority of measures except that: (a) the two think-aloud conditions significantly increased dysfluencies in participants’ essays; (b) they also tended to reduce syntactic variety of the essays; and (c) MTA significantly prolonged time on task and retarded the speed of written production. These negative effects are interpreted in light of Kellogg's (1996) cognitive model of writing as suggesting no serious interference with L2 writing processes and are taken as cautions for, rather than counterevidence against, the use of the think-aloud method to obtain L2 writing process data.}
}
@article{YECKEL19971379,
title = {Parallel computation of incompressible flows in materials processing: Numerical experiments in diagonal preconditioning},
journal = {Parallel Computing},
volume = {23},
number = {9},
pages = {1379-1400},
year = {1997},
note = {Parallel computing methods in applied fluid mechanics},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(97)00059-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167819197000598},
author = {Andrew Yeckel and Jeffrey J. Derby},
keywords = {Incompressible flow, Finite element method, Preconditioning, Iterative solution, Linear systems},
abstract = {Massively parallel computing is enabling dramatic advances in the simulation of three-dimensional flows in materials processing systems. This study focuses on the efficiency and robustness of parallel algorithms applied to such systems. Specifically, various diagonal preconditioning schemes are tested for the iterative solution of the linear equations arising from Newton's method applied to finite element discretizations. Two finite element discretizations are considered — the classical Galerkin and the Galerkin/least-squares method. Results show that the choice of preconditioning method can greatly influence the rate of convergence, but that no type worked uniformly well in all cases.}
}
@article{LI2024124918,
title = {A method of dense point cloud SLAM based on improved YOLOV8 and fused with ORB-SLAM3 to cope with dynamic environments},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124918},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124918},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017858},
author = {Yanke Li and Huabo Shen and Yaping Fu and Kai Wang},
keywords = {SLAM, VSLAM, Neural Network, Deep learning},
abstract = {With the development of society and the advancement of technology, intelligent robots have been widely used in various fields. At the same time, Simultaneous Localization and Mapping (SLAM) technology is a key technology in the research field of intelligent robots. However, in dynamic environments, achieving accurate and robust visual SLAM remains a major challenge. In this paper, we propose a method based on improved YOLOv8 fused with ORB-SLAM3 to address dense point cloud SLAM in dynamic environments. Our proposed method successfully integrates real-time object detection and image segmentation technologies of YOLOv8 into the ORB-SLAM3 framework, achieving high-precision and robust visual SLAM in dynamic environments. In the YOLOv8 framework, we use a balanced convolution method, GSConv, instead of some traditional convolution layers (Conv), which balances accuracy with computational load. Based on the GSConv convolution method, we adopt a new feature fusion module, VoVGSCSP, to replace traditional C2f feature fusion modules, thereby improving the Neck structure of YOLOv8 and achieving a lightweight network model. We compare our proposed method with ORB-SLAM3 and some computer vision algorithms on the TUM dataset. Experimental data confirms that our method outperforms existing visual SLAM algorithms in dynamic environments. In fast-moving dynamic environments, the RMSE of absolute pose estimation of our method is 96.28% lower than that of ORB-SLAM3, and the RMSE of relative pose estimation is 51.57% lower than that of ORB-SLAM3. The experimental results demonstrate that our method significantly improves the accuracy of pose estimation in dynamic environments and greatly enhances the performance compared to ORB-SLAM3.}
}
@article{WU2023100739,
title = {The development of teacher feedback literacy in situ: EFL writing teachers’ endeavor to human-computer-AWE integral feedback innovation},
journal = {Assessing Writing},
volume = {57},
pages = {100739},
year = {2023},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2023.100739},
url = {https://www.sciencedirect.com/science/article/pii/S1075293523000478},
author = {Peisha Wu and Shulin Yu and Yanqi Luo},
keywords = {Teacher feedback literacy, Second language writing, Teacher feedback, Computer-mediated feedback, Writing assessment},
abstract = {While recent years have witnessed increasing theoretical and empirical elaboration on the construct of teacher feedback literacy in higher education and second language education, little research has investigated the development of teacher feedback literacy, especially when teachers collaborate in an attempt to improve feedback strategies with technology. To fill this gap, the present study examined two L2 writing teachers taking the initiative to create, update, and implement a human-computer-automatic writing evaluation (AWE) integral feedback platform, and how such a feedback innovation process impacted their feedback literacy development. The analysis of multiple sources of data, including semi-structured interviews, stimulated recalls, class observation, and artifacts, revealed that the two teachers approached the innovation by orchestrating mediating tools, interacting dialogically with social agents, reflecting critically, and crossing boundaries. Through this process, the development of teacher feedback literacy occurred at varying rates across different aspects. Specifically, positive changes were effected in the teachers’ feedback thinking as well as feedback giving and sharing practices. However, the teachers’ feedback literacy in classroom practice did not seem to have generated as salient a positive outcome. Possible reasons are discussed regarding the scope of the feedback innovation and contextual constraints, and implications are offered. The study underscored L2 writing teacher feedback literacy as a developmental phenomenon molded by situated social practice.}
}
@incollection{NIE2019205,
title = {Two-Stage Land Use Optimization for A Food-Energy-Water Nexus System: A Case Study In Texas Edwards Region},
editor = {Salvador Garcia Muñoz and Carl D. Laird and Matthew J. Realff},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {47},
pages = {205-210},
year = {2019},
booktitle = {Proceedings of the 9th International Conference on Foundations of Computer-Aided Process Design},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818597-1.50033-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185971500333},
author = {Yaling Nie and Styliani Avraamidou and Xin Xiao and Efstratios N. Pistikopoulos and Jie Li},
keywords = {Land use optimization, Food-Energy-Water Nexus, multi-period planning},
abstract = {Efficient land use planning and scheduling in Food-Energy-Water Nexus (FEW-N) related systems is a complicated decision-making problem with resource competitions and conflicting objectives. Systematic thinking based on FEW-N is a necessity for modeling and optimization of the systems. However, challenges arise in making decisions while encountering conflicting objectives, multi-scale and multi-period problems, and multiple stakeholders. To address these challenges, we developed a generic optimization-based land allocation approach, which provides i) a composite FEW-N metric to help solve the multi-objective optimization problem and carry out assessments, and ii) a two-stage decomposition strategy to solve the multi-scale and multi-period planning and scheduling problem. The developed strategy was applied in a case study within the Texas Edwards Region. Computational results indicate that the approach can provide a comprehensive FEW-N metric to select strategies for optimal land allocation and limit stresses in the FEW-N, and achieve trade-off solutions for the multi-scale and multi-period FEW land use systems.}
}
@incollection{TSOTSOS1993261,
title = {The Role of Computational Complexity in Perceptual Theory},
editor = {Sergio C. Masin},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {99},
pages = {261-296},
year = {1993},
booktitle = {Foundations of Perceptual Theory},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62776-4},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508627764},
author = {John K. Tsotsos},
abstract = {The validity of perceptual theories cannot be considered only in terms of how well the explanations fit experimental observations. Rather, it is argued that sufficient consideration must also be given to the physical realizability of the explanation. Experimental scientists attempt to explain their data and not just describe it, in essence, providing an algorithm whose behavior leads to the observed data. Thus, computational plausibility is not only an appropriate but a necessary consideration. One dimension of plausibility is satisfaction of the constraints imposed by the computational complexity of the problem, the resources available for the solution of the problem, and the specific algorithm proposed. It is shown that such constraints play critical roles in the explanations of perception, intelligent behavior, and evolution.}
}
@article{HOLYOAK2021118,
title = {Emergence of relational reasoning},
journal = {Current Opinion in Behavioral Sciences},
volume = {37},
pages = {118-124},
year = {2021},
note = {Same-different conceptualization},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2020.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2352154620301716},
author = {Keith J Holyoak and Hongjing Lu},
abstract = {We review recent theoretical and empirical work on the emergence of relational reasoning, drawing connections among the fields of comparative psychology, developmental psychology, cognitive neuroscience, cognitive science, and machine learning. Relational learning appears to involve multiple systems: a suite of Early Systems that are available to human infants and are shared to some extent with nonhuman animals; and a Late System that emerges in humans only, at approximately age three years. The Late System supports reasoning with explicit role-governed relations, and is closely tied to the functions of a frontoparietal network in the human brain. Recent work in cognitive science and machine learning suggests that humans (and perhaps machines) may acquire abstract relations from nonrelational inputs by means of processes that enable re-representation.}
}
@article{SOUSA2015113,
title = {Symmetry-based generative design and fabrication: A teaching experiment},
journal = {Automation in Construction},
volume = {51},
pages = {113-123},
year = {2015},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2014.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0926580514002283},
author = {José Pedro Sousa and João Pedro Xavier},
keywords = {Architecture, Geometry, Symmetry, Computational design, Digital fabrication, Design education},
abstract = {Throughout history, symmetry has been widely explored as a geometric strategy to conceive architectural forms and spaces. Nonetheless, its concept has changed and expanded overtime. Nowadays, it is understood as an ordering principle resulting from the application of isometric transformations that keep the original object invariant. Departing from this notion, scientists, philosophers and designers have extended it to embrace other geometric scenarios. Following this idea, exploring symmetry does not mean the generation of simple and predictable design solutions. On the contrary, it is a creative window to achieve geometric complexity based on very simple rules. In this context, this paper aims at discussing the relevance of exploring symmetry in architectural design today by means of digital technologies. It argues that the coupled use of computational design and digital fabrication processes allows designers to explore and materialize a higher level of design complexity in a structured and controlled way, especially when non-isometric transformations are involved. As the background for testing and illustrating its arguments, this paper describes a teaching experiment conducted in the Constructive Geometry course at the FAUP, following design-to-fabrication methodologies.}
}
@article{KHAN2021104263,
title = {A novel hybrid gravitational search particle swarm optimization algorithm},
journal = {Engineering Applications of Artificial Intelligence},
volume = {102},
pages = {104263},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104263},
url = {https://www.sciencedirect.com/science/article/pii/S095219762100110X},
author = {Talha Ali Khan and Sai Ho Ling},
keywords = {PSO, GSA, Hybrid, DNA computation},
abstract = {Particle Swarm Optimization (PSO) algorithm is a member of the swarm computational family and widely used for solving nonlinear optimization problems. But, it tends to suffer from premature stagnation, trapped in the local minimum and loses exploration capability as the iteration progresses. On the contrary, Gravitational Search Algorithm (GSA) is proficient for searching global optimum, however, its drawback is its slow searching speed in the final phase. To overcome these problems in this paper a novel Hybrid Gravitational Search Particle Swarm Optimization Algorithm (HGSPSO) is presented. The key concept behind the proposed method is to merge the local search ability of GSA with the capability for social thinking (gbest) of PSO. To examine the effectiveness of these methods in solving the abovementioned issues of slow convergence rate and trapping in local minima five standard and some modern CEC benchmark functions are used to ensure the efficacy of the presented method. Additionally, a DNA sequence problem is also solved to confirm the proficiency of the proposed method. Different parameters such as Hairpin, Continuity, H-measure, and Similarity are employed as objective functions. A hierarchal approach was used to solve this multi-objective problem where a single objective function is first obtained through a weighted sum method and the results were then empirically validated. The proposed algorithm has demonstrated an extraordinary performance per solution stability and convergence.}
}
@article{EBEL2024104612,
title = {Cooperative object transportation with differential-drive mobile robots: Control and experimentation},
journal = {Robotics and Autonomous Systems},
volume = {173},
pages = {104612},
year = {2024},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104612},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023002518},
author = {Henrik Ebel and Mario Rosenfelder and Peter Eberhard},
keywords = {Cooperative manipulation, Non-prehensile manipulation, Robotic networks, Distributed optimization, Non-holonomic robots, Hardware validation},
abstract = {Non-prehensile cooperative object transportation is a challenging model problem for distributed control and organization methods but also has practical applications. Therefore, it is widely studied in distributed robotics research. This paper describes and evaluates a novel transportation scheme for differential-drive mobile robots that is, to the authors’ best knowledge, the most versatile scheme of its kind successfully evaluated with real-world hardware. The proposed scheme can conceptually deal with any number of robots and arbitrary polygonal objects, including non-convex ones, without having to retune, retrain, or reconfigure any of the control parameters between different scenarios. This is achieved by splitting the task into a formation control and a formation finding task, both of which are tackled with model-based approaches using distributed optimization. Formation control and formation finding are complicated by the robots’ non-holonomic kinematic constraints. Therefore, a tailored distributed model predictive controller is used for formation control. Finding formations relies on a multibody-dynamics representation of the robots-object system to properly account for contact and non-holonomic constraints. Due to these measures, the transportation scheme achieves a very satisfactory performance and dexterity in real-world hardware experiments utilizing network communication and distributed computation.}
}
@article{KAMPPINEN1998481,
title = {Evolution and culture: the Darwinian view on infosphere},
journal = {Futures},
volume = {30},
number = {5},
pages = {481-484},
year = {1998},
issn = {0016-3287},
doi = {https://doi.org/10.1016/S0016-3287(98)00050-0},
url = {https://www.sciencedirect.com/science/article/pii/S0016328798000500},
author = {Matti Kamppinen},
abstract = {This essay looks at the idea that human culture is an evolving system, a complex entity that undergoes evolutionary processes. This idea can also be expressed as follows: the cultural infosphere has the same mode of operation as the organic biosphere. There are three parts to the essay: it begins with some highlights from the history of evolutionary thinking; second, it explains the mechanisms of cultural selection; and third, it discusses the vision of the future provided by evolutionary thinking. The kind of evolutionary thinking focused upon is one that takes Charles Darwin seriously. The depth, reach and relevance of Darwinian thinking has been aptly exposed by Daniel C. Dennett,[1]and this essay assesses its worth in futures research.}
}
@article{ENDICOTT2003403,
title = {Moral reasoning, intercultural development, and multicultural experiences: relations and cognitive underpinnings},
journal = {International Journal of Intercultural Relations},
volume = {27},
number = {4},
pages = {403-419},
year = {2003},
note = {Special Training Issue},
issn = {0147-1767},
doi = {https://doi.org/10.1016/S0147-1767(03)00030-0},
url = {https://www.sciencedirect.com/science/article/pii/S0147176703000300},
author = {Leilani Endicott and Tonia Bock and Darcia Narvaez},
keywords = {Moral development, Intercultural development, Flexible thinking, Cognitive complexity, Multicultural experience, Schema theory},
abstract = {The relation between moral reasoning and intercultural sensitivity is discussed. We hypothesize that multicultural experiences are related to both types of development, describe the cognitive processes through which multicultural experiences theoretically facilitate development, and present empirical data supporting the association. Though the underlying developmental constructs were initially conceptualized as stage theories, we borrow from cognitive science and contemporary theories of human learning (Derry, 1996) to think of moral and intercultural development in terms of increasing sociocognitive flexibility. Intercultural and moral development share the common element of a critical shift from rigid to flexible thinking. In moral reasoning, this is characterized by the shift from conventional to post-conventional thinking. In intercultural development, a similar movement occurs between the ethnocentric and ethnorelative orientations of intercultural sensitivity. In order to test our hypothesis, college students (n=70) took measures of intercultural development (Intercultural Development Inventory), moral judgment (Defining Issues Test), and multicultural experience (Multicultural Experience Questionnaire). The results indicate that moral judgment and intercultural development are significantly related to one another. Both are related to multicultural experiences, particularly depth of the experiences, as opposed to breadth.}
}
@article{ROOTESMURDY2024100987,
title = {Cortical similarities in psychiatric and mood disorders identified in federated VBM analysis via COINSTAC},
journal = {Patterns},
volume = {5},
number = {7},
pages = {100987},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001028},
author = {Kelly Rootes-Murdy and Sandeep Panta and Ross Kelly and Javier Romero and Yann Quidé and Murray J. Cairns and Carmel Loughland and Vaughan J. Carr and Stanley V. Catts and Assen Jablensky and Melissa J. Green and Frans Henskens and Dylan Kiltschewskij and Patricia T. Michie and Bryan Mowry and Christos Pantelis and Paul E. Rasser and William R. Reay and Ulrich Schall and Rodney J. Scott and Oliver J. Watkeys and Gloria Roberts and Philip B. Mitchell and Janice M. Fullerton and Bronwyn J. Overs and Masataka Kikuchi and Ryota Hashimoto and Junya Matsumoto and Masaki Fukunaga and Perminder S. Sachdev and Henry Brodaty and Wei Wen and Jiyang Jiang and Negar Fani and Timothy D. Ely and Adriana Lorio and Jennifer S. Stevens and Kerry Ressler and Tanja Jovanovic and Sanne J.H. {van Rooij} and Lydia M. Federmann and Christiane Jockwitz and Alexander Teumer and Andreas J. Forstner and Svenja Caspers and Sven Cichon and Sergey M. Plis and Anand D. Sarwate and Vince D. Calhoun},
keywords = {transdiagnostic, federated analysis, COINSTAC, psychiatric disorders, regression, mood disorders, decentralized, gray matter, PTSD, mild cognitive impairment},
abstract = {Summary
Structural neuroimaging studies have identified a combination of shared and disorder-specific patterns of gray matter (GM) deficits across psychiatric disorders. Pooling large data allows for examination of a possible common neuroanatomical basis that may identify a certain vulnerability for mental illness. Large-scale collaborative research is already facilitated by data repositories, institutionally supported databases, and data archives. However, these data-sharing methodologies can suffer from significant barriers. Federated approaches augment these approaches by enabling access or more sophisticated, shareable and scaled-up analyses of large-scale data. We examined GM alterations using Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation, an open-source, decentralized analysis application. Through federated analysis of eight sites, we identified significant overlap in the GM patterns (n = 4,102) of individuals with schizophrenia, major depressive disorder, and autism spectrum disorder. These results show cortical and subcortical regions that may indicate a shared vulnerability to psychiatric disorders.}
}
@article{BAILEY20158,
title = {Metacognitive beliefs moderate the relationship between catastrophic misinterpretation and health anxiety},
journal = {Journal of Anxiety Disorders},
volume = {34},
pages = {8-14},
year = {2015},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0887618515000791},
author = {Robin Bailey and Adrian Wells},
keywords = {Health anxiety, Metacognition, Catastrophic misinterpretation, Moderation, S-REF model},
abstract = {Catastrophic misinterpretations of bodily symptoms have a central role in cognitive-behavioural models of health anxiety. However, the metacognitive (S-REF) model postulates that psychological disturbance is linked more to beliefs about thinking i.e., metacognition. Equally the relationship between catastrophic misinterpretation and health anxiety should be moderated by metacognition, in particular negative beliefs about the uncontrollability and danger of thinking (MCQNeg). Participants (N=351) completed measures to examine the relationship between these variables. Results indicated positive relationships between metacognition, catastrophic misinterpretation, and health anxiety. Moderation analysis showed that the effect of catastrophic misinterpretations on health anxiety was explained by the proposed interaction with metacognition. Follow-up regression analysis demonstrated the interaction term explained variance in health anxiety when controlling for other variables, and was a stronger unique predictor of health anxiety than catastrophic misinterpretation. Metacognition appears to be an important factor in the relationship between catastrophic misinterpretation and health anxiety, and would have important implications for existing models and treatment.}
}
@article{NAKAKOJI2000451,
title = {Computational support for collective creativity},
journal = {Knowledge-Based Systems},
volume = {13},
number = {7},
pages = {451-458},
year = {2000},
issn = {0950-7051},
doi = {https://doi.org/10.1016/S0950-7051(00)00069-1},
url = {https://www.sciencedirect.com/science/article/pii/S0950705100000691},
author = {K Nakakoji and Y Yamamoto and M Ohira},
keywords = {Computer support for collective creativity, Human–computer interaction, Visual images in creative insight, Knowledge-based approaches, Visualization},
abstract = {The goal of our research is to develop computer systems that support designers’ collective creativity; such systems support individual creative aspects in design through the use of representations created by others in the community. We have developed two systems, IAM-eMMa and EVIDII, that both aim at supporting designers in finding visual images that would be useful for their creative design task. IAM-eMMa uses knowledge-based rules, which are constructed by other designers, to retrieve images related to a design task, and infers the underlying “rationale” when a designer chooses one of the images. EVIDII allows designers to associate affective words and images, and then shows several visual representations of the relationships among designers, images and words. By observing designers interacting with the two systems, we have identified that systems for supporting collective creativity need to be based on design knowledge that: (1) is contextualized; (2) is respectable and trustful; and (3) enables “appropriation” of a design task.}
}
@article{BALMER2024105411,
title = {Design Space Exploration and Explanation via Conditional Variational Autoencoders in Meta-Model-Based Conceptual Design of Pedestrian Bridges},
journal = {Automation in Construction},
volume = {163},
pages = {105411},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105411},
url = {https://www.sciencedirect.com/science/article/pii/S092658052400147X},
author = {Vera Balmer and Sophia V. Kuhn and Rafael Bischof and Luis Salamanca and Walter Kaufmann and Fernando Perez-Cruz and Michael A. Kraus},
keywords = {Computational design, Design space exploration, Generative AI, Conditional Variational Autoencoder, Explainable AI, Pedestrian bridge},
abstract = {Today, engineers rely on conventional iterative (often manual) techniques for conceptual design. Emerging parametric models facilitate design space exploration based on quantifiable performance metrics, yet remain time-consuming and computationally expensive, leaving room for improvement. This paper provides a design exploration and explanation framework to augment the designer via a Conditional Variational Autoencoder (CVAE), which serves as a forward performance predictor as well as an inverse design generator conditioned on a set of performance requests. Hence, the CVAE overcomes the limitations of traditional iterative techniques by learning a differentiable mapping for a highly nonlinear design space, thus enabling sensitivity analysis. These methods allow for informing designers about (i) relations of the model between features and performances and (ii) structural improvements under user-defined objectives. The framework is tested on a case-study and proves its potential to serve as a future co-pilot for conceptual design studies of diverse civil structures and beyond.}
}
@article{RUCH2024115840,
title = {Alterations in performance and discriminating power of the death/suicide implicit association test across the lifespan},
journal = {Psychiatry Research},
volume = {335},
pages = {115840},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115840},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124001252},
author = {Donna A. Ruch and Jeffrey A. Bridge and Jaclyn Tissue and Sean P. Madden and Hanga Galfavy and Marianne Gorlyn and Arielle H. Sheftall and Katalin Szanto and John G. Keilp},
keywords = {Death/suicide implicit association, Suicide, Suicide risk assessment, Suicide prevention/early detection},
abstract = {The Death/Suicide Implicit Association Test (d/s-IAT) has differentiated individuals with prior and prospective suicide attempts in previous studies, however, age effects on test results remains to be explored. A three-site study compared performance on the d/s-IAT among participants aged 16–80 years with depression and prior suicide attempt (n = 82), with depression and no attempts (n = 80), and healthy controls (n = 86). Outcome measures included the standard difference (D) score, median reaction times, and error rates. Higher D scores represent a stronger association between death/suicide and self, while lower scores represent a stronger association between life and self. The D scores differed significantly among groups overall. Participants with depression exhibited higher scores compared to healthy controls, but there was no difference between participants with and without prior suicide attempts(F[2,242]=8.76, p<.001). Response times for participants with prior attempts differed significantly from other groups, with no significant differences in error rates. The D score was significantly affected by age (β =-0.007, t = 3.65, p<.001), with slowing of response times in older ages. Results suggest reaction time d/s-IAT D scores may not distinguish implicit thinking about suicide as response times slow with age, but slowed response times may be sensitive to suicide risk potentially indicating basic information processing deficits.}
}
@article{XIE2024e34960,
title = {Enhanced nonlinear active noise control: A novel approach using brain storm optimization algorithm},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e34960},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e34960},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024109917},
author = {Jiangchun Xie and Jianmin Ma},
keywords = {Active noise control, Brain storm optimization (BSO) algorithm, Filtered-x least mean squares (FxLMS) algorithm, Nonlinear noise reduction extended Kalman Filter (EKF), Noise reduction performance, Multi-frequency noise},
abstract = {Active Noise Control (ANC) systems play a crucial role in reducing unwanted noise in various settings. Traditional ANC methods, like the Filtered-x Least Mean Squares (FxLMS) algorithm, are effective in linear noise scenarios. However, they often struggle with more nonlinear and complex noise patterns. This paper introduces a novel approach using the brain storm optimization (BSO) algorithm in nonlinear ANC systems, which represents a significant departure from conventional techniques. The BSO algorithm, inspired by human brainstorming processes, excels in addressing the complexities of nonlinear noise by incorporating principles, such as delayed evaluation, free imagination, quantity and quality, and comprehensive improvement. By combining the BSO algorithm with an Extended Kalman Filter (EKF), a new ANC system is proposed that can adapt to a wide range of noise types with improved speed and accuracy. Experimental results showcase the superior performance of the BSO algorithm, achieving an impressive noise reduction of up to 48 dB (dB) in a 500Hz sinusoidal noise scenario, with a convergence time as fast as 0.01 s, outperforming the FxLMS algorithm by a significant margin. Moreover, in complex environments with multi-frequency and random noise, the BSO algorithm consistently demonstrates better noise reduction and quicker convergence, reducing noise levels by up to 27 dB within 0.001 s. The innovative use of the BSO algorithm in ANC systems not only enhances noise reduction capabilities, especially for nonlinear and complex noise signals, but also improves convergence times, paving the way for future advancements in ANC technologies.}
}
@article{BRODO202025,
title = {A Constraint-based Language for Multiparty Interactions},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {351},
pages = {25-50},
year = {2020},
note = {Proceedings of LSFA 2020, the 15th International Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2020)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300396},
author = {Linda Brodo and Carlos Olarte},
keywords = {Concurrency theory, constraints, multiparty interactions},
abstract = {Multiparty interactions are common place in today's distributed systems. An agent usually communicates, in a single session, with other agents to accomplish a given task. Take for instance an online transaction including the vendor, the client, the credit card system and the bank. When specifying this kind of system, we probably observe a single transaction including several (binary) communications leading to changes in the state of all the involved agents. Multiway synchronization process calculi, that move from a binary to a multiparty synchronization discipline, have been proposed to formally study the behavior of those systems. However, adopting models such as Bodei, Brodo, and Bruni's Core Network Algebra (CNA), where the number of participants in an interaction is not fixed a priori, leads to an exponential blow-up in the number of states/behaviors that can be observed from the system. In this paper we explore mechanisms to tackle this problem. We extend CNA with constraints that declaratively allow the modeler to restrict the interaction that should actually happen. Our extended process algebra, called CCNA, finds application in balancing the interactions in a concurrent system, leading to a simple, deadlock-free and fair solution for the Dinning Philosopher problem. Our definition of constraints is general enough and it offers the possibility of accumulating costs in a multiparty negotiation. Hence, only computations respecting the thresholds imposed by the modeler are observed. We use this machinery to neatly model a Service Level Agreement protocol. We develop the theory of CCNA including its operational semantics and a behavioral equivalence that we prove to be a congruence. We also propose a prototypical implementation that allows us to verify, automatically, some of the systems explored in the paper.}
}
@article{WANG2024111131,
title = {Three-way clustering: Foundations, survey and challenges},
journal = {Applied Soft Computing},
volume = {151},
pages = {111131},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111131},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011493},
author = {Pingxin Wang and Xibei Yang and Weiping Ding and Jianming Zhan and Yiyu Yao},
keywords = {Cluster analysis, Two-way clustering, Three-way decision, Three-way clustering},
abstract = {Clustering, as an unsupervised data mining technique, allows us to classify similar objects into the same cluster according to certain criteria. It helps us identify patterns between objects, reveal the associations between objects, and discover hidden structures. Traditional two-way clustering (2W clustering) algorithms represent one cluster by one set and only two types of relationships are considered between a sample and a cluster, namely, belonging to and not belonging to. Two-way decision is not always feasible especially in situations that are characterized by uncertainty and lack of information. Guided by the principle of three-way decision (3WD) as thinking in threes, three-way clustering (3W clustering) addresses the information uncertainty problem using core and the fringe regions to character a cluster. The universe is split into three sections by these two sets, which capture three kinds of relationships between objects and a cluster, namely, belonging to, partially belonging to, and not belonging-to. Compared with 2W clustering methods, 3W clustering incorporates the fringe region to describe the uncertain relationship between objects and clusters, which provides more information about the clustering structure. This survey points out the historical developments of three-way clustering and makes an overview of the achievements in the field of three-way clustering. In addition, to reap a clearer grasp of the development and research significance of three-way clustering, we divide the existing three-way clustering approaches into two categories and present the bibliometric analysis of related approaches. Finally, we point out some challenges and future research topics in three-way clustering. It is hoped that this review can serve as a reference and provide convenience for scholars and practitioners in the field of three-way clustering.}
}
@article{LI2024120889,
title = {Hierarchical fuzzy inference based on Bandler-Kohout subproduct},
journal = {Information Sciences},
volume = {677},
pages = {120889},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120889},
url = {https://www.sciencedirect.com/science/article/pii/S002002552400803X},
author = {Dechao Li and Zhisong Liu and Qiannan Guo},
keywords = {Fuzzy implication, Fuzzy inference, Bandler-Kohout subproduct, Hierarchical system, T-norm},
abstract = {Fuzzy inference with the Bandler-Kohout subproduct (BKS) has been successfully applied in many fields such as fuzzy control, artificial intelligence, image processing, data mining, decision-making, prediction, classification and so on. However, one has to face with the rule explosion in these applications. To deal with this problem, hierarchical fuzzy systems with the compositional rule of inference (CRI) method have been constructed by a series of low-dimensional sub fuzzy systems. And it has been proved that hierarchical fuzzy inference method can efficiently restrain the explosion of fuzzy rules. Therefore, in order to increase the computational efficiency of the fuzzy inference based on the BKS when multi-input-single-output (MISO) fuzzy rules are involved, this paper mainly constructs two hierarchical fuzzy inference methods based on the BKS in which the if-then rules are respectively interpreted by fuzzy implications and ML-implications. Moreover, the validity of the two BKS hierarchical fuzzy inferences is studied with the GMP rules. Finally, two examples are employed to illustrate the computational efficiency of our proposed BKS hierarchical inference methods.}
}
@article{JAHANIFAR2024103132,
title = {Mitosis detection, fast and slow: Robust and efficient detection of mitotic figures},
journal = {Medical Image Analysis},
volume = {94},
pages = {103132},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103132},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524000574},
author = {Mostafa Jahanifar and Adam Shephard and Neda Zamanitajeddin and Simon Graham and Shan E. Ahmed Raza and Fayyaz Minhas and Nasir Rajpoot},
keywords = {Mitosis, Detection, Segmentation, Breast cancer, MIDOG, TUPAC, Computational pathology, Deep learning},
abstract = {Counting of mitotic figures is a fundamental step in grading and prognostication of several cancers. However, manual mitosis counting is tedious and time-consuming. In addition, variation in the appearance of mitotic figures causes a high degree of discordance among pathologists. With advances in deep learning models, several automatic mitosis detection algorithms have been proposed but they are sensitive to domain shift often seen in histology images. We propose a robust and efficient two-stage mitosis detection framework, which comprises mitosis candidate segmentation (Detecting Fast) and candidate refinement (Detecting Slow) stages. The proposed candidate segmentation model, termed EUNet, is fast and accurate due to its architectural design. EUNet can precisely segment candidates at a lower resolution to considerably speed up candidate detection. Candidates are then refined using a deeper classifier network, EfficientNet-B7, in the second stage. We make sure both stages are robust against domain shift by incorporating domain generalization methods. We demonstrate state-of-the-art performance and generalizability of the proposed model on the three largest publicly available mitosis datasets, winning the two mitosis domain generalization challenge contests (MIDOG21 and MIDOG22). Finally, we showcase the utility of the proposed algorithm by processing the TCGA breast cancer cohort (1,124 whole-slide images) to generate and release a repository of more than 620K potential mitotic figures (not exhaustively validated).}
}
@article{YIM2014144,
title = {A development of a quantitative situation awareness measurement tool: Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE)},
journal = {Annals of Nuclear Energy},
volume = {65},
pages = {144-157},
year = {2014},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2013.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S0306454913005598},
author = {Ho Bin Yim and Seung Min Lee and Poong Hyun Seong},
keywords = {Quantitative measure, Situation awareness, Graphical expression, NPP MCR operators},
abstract = {Operator performance measures are used for multiple purposes, such as control room design, human system interface (HSI) evaluation, training, and so on. Performance measures are often focused on results; however, especially for a training purpose – at least in a nuclear industry, more detailed descriptions about processes are required. Situation awareness (SA) measurements have directly/indirectly played as a complimentary measure and provided descriptive insights on how to improve performance of operators for the next training. Unfortunately, most of the well-developed SA measurement techniques, such as Situation Awareness Global Assessment Technique (SAGAT) need an expert opinion which sometimes troubles easy spread of measurement’s application or usage. A quantitative SA measurement tool named Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE) is introduced to resolve some of these concerns. CoRSAGE is based on production rules to represent a human operator’s cognitive process of problem solving, and Bayesian inference to quantify it. Petri Net concept is also used for graphical expressions of SA flow. Three components – inference transition, volatile/non-volatile memory tokens – were newly developed to achieve required functions. Training data of a Loss of Coolant Accident (LOCA) scenario for an emergency condition and an earthquake scenario for an abnormal condition by real plant operators were used to validate the tool. The validation result showed that CoRSAGE performed a reasonable match to other performance results.}
}
@article{BRENT19961,
title = {Advances in the computational study of language acquisition},
journal = {Cognition},
volume = {61},
number = {1},
pages = {1-38},
year = {1996},
note = {Compositional Language Acquisition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(96)00779-2},
url = {https://www.sciencedirect.com/science/article/pii/S0010027796007792},
author = {Michael R. Brent},
abstract = {This paper provides a tutorial introduction to computational studies of how children learn their native languages. Its aim is to make recent advances accessible to the broader research community, and to place them in the context of current theoretical issues. The first section locates computational studies and behavioral studies within a common theoretical framework. The next two sections review two papers that appear in this volume: one on learning the meanings of words and one on learning the sounds of words. The following section highlights an idea which emerges independently in these two papers and which I have dubbed autonomous bootstrapping. Classical bootstrapping hypotheses propose that children begin to get a toe-hold in a particular linguistic domain, such as syntax, by exploiting information from another domain, such as semantics. Autonomous bootstrapping complements the cross-domain acquisition strategies of classical bootstrapping with strategies that apply within a single domain. Autonomous bootstrapping strategies work by representing partial and/or uncertain linguistic knowledge and using it to analyze the input. The next two sections review two more more contributions to this special issue: one on learning word meanings via selectional preferences and one on algorithms for setting grammatical parameters. The final section suggests directions for future research.}
}
@article{BEATY201922,
title = {Network neuroscience of creative cognition: mapping cognitive mechanisms and individual differences in the creative brain},
journal = {Current Opinion in Behavioral Sciences},
volume = {27},
pages = {22-30},
year = {2019},
note = {Creativity},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2018.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2352154618301219},
author = {Roger E Beaty and Paul Seli and Daniel L Schacter},
abstract = {Network neuroscience research is providing increasing specificity on the contribution of large-scale brain networks to creative cognition. Here, we summarize recent experimental work examining cognitive mechanisms of network interactions and correlational studies assessing network dynamics associated with individual creative abilities. Our review identifies three cognitive processes related to network interactions during creative performance: goal-directed memory retrieval, prepotent-response inhibition, and internally-focused attention. Correlational work using prediction modeling indicates that functional connectivity between networks — particularly the executive control and default networks — can reliably predict an individual’s creative thinking ability. We discuss potential directions for future network neuroscience, including assessing creative performance in specific domains and using brain stimulation to test causal hypotheses regarding network interactions and cognitive mechanisms of creative thought.}
}
@article{CAMARGOJUNIOR2016190,
title = {Optimal economic result and risk of parallel development of concept options in dynamic markets},
journal = {RAI Revista de Administração e Inovação},
volume = {13},
number = {3},
pages = {190-198},
year = {2016},
issn = {1809-2039},
doi = {https://doi.org/10.1016/j.rai.2016.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S1809203916300377},
author = {Alceu Salles {Camargo Júnior} and Abraham Sin Oih Yu},
keywords = {New product development, Economic result and risk of projects, Option thinking},
abstract = {New product development is an essential competence to organizations. Launching success products requires elaborate and precise knowledge about the technological platforms, like the most important market needs and characteristics, and the project team have to employ information systems to support the project decisions, which must be rapid and accurate. However, when the market characteristics are much dynamic and change rapidly or the development project aims at a really new product, the levels of uncertainties are greater, and the project team must employ more robust strategies of risk management. Option thinking is useful to develop several concept alternatives of some crucial subsystems of the new product in order to achieve new technical and market knowledge by repeating cycles of design, built and tested by several and different prototypes in parallel. These different prototypes develop, test and can accumulate knowledge about each one, different technologies, architectures and quality attributes or the usability for potential customers. This study achieves the optimal number of concept options to develop in parallel in order to maximize the economic performance of the development project of a new product constituted of two important subsystems. Mathematical models simulating the sequential decision process are developed to determine the economic result and risk of a two-subsystem product innovation project. Our results point the parallel development of concept options as a robust strategy to manage new product development mostly in adverse conditions, that is, with greater levels of uncertainties.}
}
@article{HENRY2016119,
title = {Hofmeister series: The quantum mechanical viewpoint},
journal = {Current Opinion in Colloid & Interface Science},
volume = {23},
pages = {119-125},
year = {2016},
issn = {1359-0294},
doi = {https://doi.org/10.1016/j.cocis.2016.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1359029416301108},
author = {Marc Henry},
keywords = {Quantum mechanics, Phase coherence, Living cells, Condensed matter, Hofmeister series, Water, Aqueous solutions, Harmonic ratios},
abstract = {It is suggested that electromagnetic quantum vacuum fluctuations are at the very deep root of the so-called “specific ions effects” in concentrated solutions or in living cells. A many-body quantum-mechanical frame of thinking is proposed based on the concept of quantum coherence taking into account explicitly density and excitation frequencies of molecules and/or ionic species. It is also proposed that Hofmeister phenomena could have a natural explanation in the harmonic relationships between sets of characteristic frequencies ruled by quantum mechanical laws. It then follows that physical chemistry of concentrated media and biology should be ruled more by a quantum “symphony” between indistinguishable constituents rather than localized two-body electrical interactions between molecular or ionic species.}
}
@article{ELLIOT2022112418,
title = {An expanded framing of ecosystem services is needed for a sustainable urban future},
journal = {Renewable and Sustainable Energy Reviews},
volume = {162},
pages = {112418},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112418},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122003264},
author = {T. Elliot and J.A. Torres-Matallana and B. Goldstein and J. {Babí Almenar} and E. Gómez-Baggethun and V. Proença and B. Rugani},
keywords = {Urban ecosystem services, Urban metabolism, Life cycle thinking, Land cover change, System dynamics modelling, Urban land teleconnections},
abstract = {Urban activities are an important driver of ecosystem services decline. Sustainable urbanisation necessitates anticipating and mitigating these negative socio-ecological impacts, both within and beyond city boundaries. There is a lack of scalable, dynamic models of changes to ecosystems wrought by urban processes. We developed a system dynamics model, ESTIMUM, to predict locations, types, and magnitude of changes in ecosystem services. We tested the model in Lisbon (Portugal) under four specific urban development scenarios – a base case scenario and three local sustainability-driven scenarios – to the year 2050. Our results show that urban sustainability policies focused on reducing impacts within Lisbon can be undermined by increased impacts in the extended regions that supply resources to the city. In particular, carbon sequestration from urban greening pales in comparison to growing greenhouse gases from the consumption of food, energy and construction materials. We also find that policies targeted at these extended environmental impacts can be much more effective than those with a limited focus on the urban form. For example, dietary shifts could support positive changes outside that city to increase global climate regulation by 54% compared to a mere 1% increase through intensive urban greening. This highlights the urgent need for a reframing of urban sustainability in policy and scholarly circles from city-centric focus towards an expanded multi-scalar conceptualisation of urban sustainability that accounts for urban impacts beyond the city boundaries.}
}
@article{SCHAEFER198897,
title = {A history of ab initio computational quantum chemistry: 1950–1960},
journal = {Tetrahedron Computer Methodology},
volume = {1},
number = {2},
pages = {97-102},
year = {1988},
issn = {0898-5529},
doi = {https://doi.org/10.1016/0898-5529(88)90014-0},
url = {https://www.sciencedirect.com/science/article/pii/0898552988900140},
author = {Henry F. Schaefer},
keywords = {Quantum chemistry, Ab initio, Electronic structure theory, Molecular quantum mechanics, Computations},
abstract = {Although ab initio computational quantum chemistry produced virtually no predictions of chemical interest during the 1950's, an important foundation for future work was laid during this decade. Much of this fundamental computational research was carried out in the laboratories of Frank Boys in Cambridge (England) and Clemens Roothaan and Robert Mulliken in Chicago. Other senior contributors to ab initio chemical theory during this period include Klaus Ruedenberg, Robert Parr, John Pople, Robert Nesbet, Harrison Shull, Per-Olov Löwdin, Isaiah Shavitt, Albert Matsen, Douglas McLean, and Bernard Ransil.}
}
@article{XU201766,
title = {Emerging Trends for Microbiome Analysis: From Single-Cell Functional Imaging to Microbiome Big Data},
journal = {Engineering},
volume = {3},
number = {1},
pages = {66-70},
year = {2017},
issn = {2095-8099},
doi = {https://doi.org/10.1016/J.ENG.2017.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S2095809917301595},
author = {Jian Xu and Bo Ma and Xiaoquan Su and Shi Huang and Xin Xu and Xuedong Zhou and Wei E. Huang and Rob Knight},
keywords = {Microbiome, Method development, Single-cell analysis, Big data, China Microbiome Initiative},
abstract = {Method development has always been and will continue to be a core driving force of microbiome science. In this perspective, we argue that in the next decade, method development in microbiome analysis will be driven by three key changes in both ways of thinking and technological platforms: ① a shift from dissecting microbiota structure by sequencing to tracking microbiota state, function, and intercellular interaction via imaging; ② a shift from interrogating a consortium or population of cells to probing individual cells; and ③ a shift from microbiome data analysis to microbiome data science. Some of the recent method-development efforts by Chinese microbiome scientists and their international collaborators that underlie these technological trends are highlighted here. It is our belief that the China Microbiome Initiative has the opportunity to deliver outstanding “Made-in-China” tools to the international research community, by building an ambitious, competitive, and collaborative program at the forefront of method development for microbiome science.}
}
@incollection{GARDNER2024153,
title = {Chapter 7 - Smart design for cultural heritage},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {153-174},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000057},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Heritage futures, Interaction, Physical computing, Smart cultural heritage, Smart heritage, Smart city, Urban technology},
abstract = {This chapter explores the evolving relationship between cultural heritage and the smart city. The role of smart technologies in a cultural heritage context is often assumed to involve the integration of sensor-based technologies and computational systems to autonomously monitor and manage sites. This chapter expands the definition of smart heritage to include urban technology projects that use sensor-based technologies and physical computing to realize situated and embodied interaction experiences that encourage citizens and visitors to share and co-create cultural heritage experiences with each other. It discusses existing and speculative urban technology projects that combine spatial design and physical computing affordances to create cultural heritage experiences that can be simultaneously attuned to both the past and the future.}
}
@article{SFARD20121,
title = {Introduction: Developing mathematical discourse—Some insights from communicational research},
journal = {International Journal of Educational Research},
volume = {51-52},
pages = {1-9},
year = {2012},
note = {Developing mathematical discourse–Some insights from communicational research},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2011.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0883035511001327},
author = {Anna Sfard},
keywords = {Mathematics, Discourse, Learning, Development, Cognition, Emotions, Interactions},
abstract = {Quite diverse in their foci and specific themes, the seven articles collected in this special issue are unified by their common conceptual framework. Grounded in the premise that thinking can be usefully defined as self-communicating and that mathematics can thus be viewed as a discourse, the communicational framework provides a unified set of conceptual tools with which to investigate cognitive, affective and social aspects of mathematics learning. The communicational tools are employed by the authors as they investigate diverse aspects of mathematical discourse and explore its development in the classroom and beyond. The seven studies combine together to produce a set of insights, some of which go against widespread beliefs about teaching and learning mathematics.}
}
@article{GAO2023106199,
title = {Letter to the Editor on a shallow water wave equation in Results Phys. 43, 106048 (2022) and its generalization},
journal = {Results in Physics},
volume = {44},
pages = {106199},
year = {2023},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2022.106199},
url = {https://www.sciencedirect.com/science/article/pii/S2211379722008208},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Generalized shallow water wave equation, Similarity reductions, Symbolic computation},
abstract = {Results Phys. 43, 106048 (2022) has amusingly retrieved some solitonic and other analytic solutions for a shallow water wave equation presented there. In this Letter, we suggest that such an equation be moreover studied in line with Results Phys. 43, 106048 (2022). Employing symbolic computation, for a generalization of that equation, with respect to the displacement and velocity of the water, we construct a family of the similarity reductions, to a known ordinary differential equation. Our results depend on the gravitational force and wave height.}
}
@article{MOSKOWITZ200387,
title = {The intertwining of psychophysics and sensory analysis: historical perspectives and future opportunities—a personal view},
journal = {Food Quality and Preference},
volume = {14},
number = {2},
pages = {87-98},
year = {2003},
issn = {0950-3293},
doi = {https://doi.org/10.1016/S0950-3293(02)00072-1},
url = {https://www.sciencedirect.com/science/article/pii/S0950329302000721},
author = {Howard R. Moskowitz},
keywords = {History, Psychology, Psychophysics},
abstract = {From today’s point of view, psychophysics and sensory analysis appear conjoined, at least from the vantage point of sensory analysis. This paper shows how psychophysical thinking has not only entered sensory analysis, but also shaped some of the ways that modern day sensory analysts conceptualize their problems and go about solving them. The paper also shows how this was not always the case. The rapprochement of the two fields has only gradually developed as sensory analysis has come to accept psychophysical thinking. The paper concludes by listing a series of trends that may bring the two fields even closer in the future.}
}
@article{ESCOUFLAIRE2024129,
title = {Automated text classification of opinion vs. news French press articles. A comparison of transformer and feature-based approaches},
journal = {Language & Communication},
volume = {99},
pages = {129-140},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000624},
author = {Louis Escouflaire and Antonin Descampe and Cédrick Fairon},
keywords = {Subjectivity, Transformers, Feature-based model, Text classification, Discourse analysis, Explainability},
abstract = {This study explores Natural Language Processing (NLP) methods for distinguishing between press articles belonging to the journalistic genres of ‘objective’ news and ‘subjective’ opinion. Two classification models are compared: CamemBERT, a French transformer model fine-tuned for the task, and a machine learning model using 32 linguistic features. Trained on 8000 Belgian French articles, both models are evaluated on 1000 Canadian French articles. Results show CamemBERT’s superiority but highlight potential for hybrid approaches and emphasizes the need for robust and transparent methods in NLP. The research contributes to understanding NLP’s role in journalism by addressing challenges of point of view detection in press discourse.}
}
@article{KIM201828,
title = {Degree of satisfaction-difference (DOSD) method for measuring consumer acceptance: A signal detection measurement with higher reliability than hedonic scaling},
journal = {Food Quality and Preference},
volume = {63},
pages = {28-37},
year = {2018},
issn = {0950-3293},
doi = {https://doi.org/10.1016/j.foodqual.2017.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0950329317301738},
author = {Min-A Kim and Danielle {van Hout} and Jean-Marc Dessirier and Hye-Seong Lee},
keywords = {Acceptance test, Affective product discrimination, Range effects, Indirect scaling, Satisfaction, Reference framing},
abstract = {Predictions of consumer acceptance are often based on hedonic scores, but these are determined not only by the consumer level of product liking, but also by consumer scale usage, which in turn is affected by thinking style and experimental contexts. To improve the validity and reliability of consumer acceptance measurement, a new indirect scaling method, the ‘Degree of Satisfaction-Difference (DOSD)’, was developed using a reminder design and signal detection theory (SDT). In DOSD, a product-specified ‘cognitive warm-up’ was used to evoke the consumer personal context and the internal evaluative criteria prior to product evaluation. In DOSD, each test product was presented together with a fixed-reference (identified as such) and consumers were asked to evaluate their satisfaction with the reference first with a sureness rating, and then to evaluate the test product for both absolute satisfaction and comparative satisfaction to the reference. The reliability of DOSD was tested against traditional hedonic scaling using an independent samples design of two consumer groups with equivalent cognitive reflection test profiles, each including High Reflection Thinkers (HRTs) and Low Reflection Thinkers (LRTs) in equal proportion. Each group tested two sets of skin lotions differing in product range, either using DOSD or hedonic scaling. When examining the affective discriminations of the two common products in terms of d′ values between product sets, the LRT subjects generated inconsistent responses with hedonic scaling, but reproducible responses with DOSD. The HRT subjects performed consistently using both scaling methods. These results validate DOSD’s superior reliability in affective tests and demonstrate its potential as an alternative consumer acceptance measurement to hedonic scaling.}
}
@article{FEIZIZADEH2024103764,
title = {Spatiotemporal mapping of urban trade and shopping patterns: A geospatial big data approach},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {128},
pages = {103764},
year = {2024},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.103764},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224001183},
author = {Bakhtiar Feizizadeh and Davoud Omarzadeh and Thomas Blaschke},
keywords = {Shopping pattern mapping, GIS, Geospatial big data, Data-driven approaches, Spatially explicit, GIScience, Novel methodology},
abstract = {The economic viability of an urban area in terms of trade and shopping significantly impacts its residents’ quality of life and is crucial for any sustainable development initiative. Geographic information systems (GIS) are well established, but the use of GIS technology within finance and trade analysis is still in its infancy. In this article, we highlighted the potential of GIS technology and big data analytics and demonstrated the importance of thinking in spatial terms for analysing patterns within the trade and finance industries. We studied spatiotemporal trade and shopping patterns in the city of Tabriz using data generated by customer purchase transactions obtained from 5200 stores, shopping, business and service centres. We employed time series transaction data collected from the points of sale in stores, shopping, service and business centres located in different areas of the city. We applied four well known geospatial big data driven approaches including machine learning nearest neighbour, kernel density estimation, space–time pattern mining and spatiotemporal coupling tele-coupling for detecting and mapping of spatial trade hotspot patterns. The results of this study indicated the potential of GIScience methods for the explicit spatial mapping of trade and shopping patterns. The results revealed that the city centre, particularly the Bazaar of Tabriz, acts as the city’s heart of trade, and we identify additional major business hotspots. Furthermore, the results allow for studying the impacts of unbalanced urban development in Tabriz, where the wealthy suburbs with high quality of life, such as Valiasr and Elguli, host the major shopping hotspots. The spatial patterns obtained enable local stakeholders, decision makers and authorities to develop strategic plans for urban sustainable development in Tabriz. The geospatial big data approach used can stimulate novel and progressive research. Results of this study demonstrate methodological advancements in GIScience by ’spatializing’ individual purchase data and therefor proposing an explicit geospatial big data analysis approach.}
}
@article{NAGOEV2020615,
title = {Model of the reasoning process in a multiagent cognitive system},
journal = {Procedia Computer Science},
volume = {169},
pages = {615-619},
year = {2020},
note = {Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.202},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303252},
author = {Zalimhan Nagoev and Inna Pshenokova and Murat Anchekov},
keywords = {Multi-Agent Systems, Neurocognitive Architecture, Simulation Model, Artificial Intelligence Systems, Reasoning Models},
abstract = {A model of the reasoning process in a multiagent cognitive system for the synthesis of intelligent solutions of the problem is presented. The approach based on the computational abstraction of multi-agent neurocognitive systems that illustrates architectural conformity to self-organizing neurocognitive networks of the brain. The model represents the process of reasoning in the form of cognitive blocks that synthesize intelligent solutions and allow the user to effectively solve the tasks.}
}
@incollection{VERSCHAFFEL2010401,
title = {Mathematics Learning},
editor = {Penelope Peterson and Eva Baker and Barry McGaw},
booktitle = {International Encyclopedia of Education (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {401-406},
year = {2010},
isbn = {978-0-08-044894-7},
doi = {https://doi.org/10.1016/B978-0-08-044894-7.00517-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780080448947005170},
author = {L. Verschaffel and B. Greer and E. {De Corte}},
keywords = {Adaptive expertise, Assessment, Collaboration, Competence, Constructivism, Design experiment, High-stakes testing, Mathematical, Mathematics education, Mathematics learning, Mathematics teaching, Prior knowledge, Routine expertise, Situated cognition, Standards},
abstract = {This article presents a review of important recent themes and developments in research on the learning and teaching of mathematical knowledge and thinking. As a framework, we use a model for designing a powerful environment for learning and teaching mathematics; this model is structured according to four interrelated components, namely competence, learning, intervention, and assessment (CLIA-model) (De Corte et al., 2004). We argue and illustrate that our empirically based knowledge of each of these four interconnected components has substantially advanced over the past decades, enabling a progressively better understanding of not only the components that constitute a mathematical disposition, but also the nature of the learning and developmental processes that should be induced in students to facilitate the acquisition of competence, the characteristics of learning environments that are powerful in initiating and evoking those processes, and finally, the kind of assessment instruments that are appropriate to help monitor and support learning and teaching.}
}
@article{SON2015120,
title = {The history of Western futures studies: An exploration of the intellectual traditions and three-phase periodization},
journal = {Futures},
volume = {66},
pages = {120-137},
year = {2015},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2014.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0016328714002079},
author = {Hyeonju Son},
keywords = {History of Western futures studies, Intellectual tradition, Periodization, Rationalization of futures, Industrialization of futures, Fragmentation of futures.},
abstract = {The main purpose of this paper is to present a three-phase periodization of modern Western futures studies to construct historical classification. In order to reach this goal, the following intellectual traditions are introduced to review the philosophical and historical contexts that affect the very foundations of futures studies: (a) religions, (b) utopias, (c) historicism, (d) science fiction, and (e) systems thinking. The first phase (beginning in 1945 to the 1960s) was the era of scientific inquiry and rationalization of the futures characterized by the prevalence of technological forecasting, the rise of alternative futures in systematic ways, and the growth of professionalization of futures studies. In the first phase, futures had become objects of rationalization removed from the traditional approaches such as utopia, grandiose evolutionary ideas, naive prophecies, science fiction, religious attitudes, and mystical orientation. The second phase (the 1970s and the 1980s) saw the creation the global institution and industrialization of the futures. This era was marked by the rise of worldwide discourse on global futures, the development of normative futures, and the deep involvement of the business community in futures thinking. In the second phase, futures studies-industry ties were growing and the future-oriented thoughts extensively permeated the business decision-making process. The third phase (the 1990s – the present) reflects the current era of the neoliberal view and fragmentation of the futures. This phase is taking place in the time of neoliberal globalization and risk society discourses and is characterized by the dominance of foresight, the advance of critical futures studies, and the intensification of fragmentation. In the third phase, futures practice tends to be confined to the support of strategic planning, and hence is experiencing an identity crisis and loss of its earlier status of humanity-oriented futures.}
}
@article{LEE2021101596,
title = {Measuring Mohr social capital},
journal = {Poetics},
volume = {88},
pages = {101596},
year = {2021},
note = {Measure Mohr Culture},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2021.101596},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X21000863},
author = {Monica Lee and Amaç Herdağdelen and Minsu Park and John Levi Martin},
abstract = {We here bring together two different traditions of thinking about social capital. One, the Tocquevillian, looks to associations and group memberships as the core of social capital. The other, the Colemanian, looks to interpersonal networks as the core of social capital. We argue that the most common way of articulating how humans use these types of relationships in different ways—the distinction between “bridging” and “bonding” social capital—is epistemically unstable. What might be possible, however, is to use the insights developed by Ronald Burt regarding tie non-redundancy to study associational social capital. We do this by drawing on the insights of the approach consistently adopted and developed by John Mohr, which emphasizes duality and diversity, to develop measures of group affiliation-based social capital. We accordingly, for both Tocquevillian and Colemanian social capital, distinguish measures that focus on the mass of social capital from those that focus on its diversity. To illustrate, we use de-identified data from 77 Million U.S. Facebook Groups users to measure their degree of all resulting types of social capital. We show that our understanding of who has the most social capital varies greatly by whether we are considering Tocquevillian or Colemanian capital, and whether we are focusing on mass or diversity.}
}
@article{CORTESE2024108397,
title = {Applications of genome-scale metabolic models to the study of human diseases: A systematic review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {256},
pages = {108397},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003900},
author = {Nicola Cortese and Anna Procopio and Alessio Merola and Paolo Zaffino and Carlo Cosentino},
keywords = {Genome-scale metabolic networks, Constraint-based modeling, Systems biology, Simulation, Systematic literature review},
abstract = {Background and Objectives:
Genome-scale metabolic networks (GEMs) represent a valuable modeling and computational tool in the broad field of systems biology. Their ability to integrate constraints and high-throughput biological data enables the study of intricate metabolic aspects and processes of different cell types and conditions. The past decade has witnessed an increasing number and variety of applications of GEMs for the study of human diseases, along with a huge effort aimed at the reconstruction, integration and analysis of a high number of organisms. This paper presents a systematic review of the scientific literature, to pursue several important questions about the application of constraint-based modeling in the investigation of human diseases. Hopefully, this paper will provide a useful reference for researchers interested in the application of modeling and computational tools for the investigation of metabolic-related human diseases.
Methods:
This systematic review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Elsevier Scopus®, National Library of Medicine PubMed® and Clarivate Web of Science™ databases were enquired, resulting in 566 scientific articles. After applying exclusion and eligibility criteria, a total of 169 papers were selected and individually examined.
Results:
The reviewed papers offer a thorough and up-to-date picture of the latest modeling and computational approaches, based on genome-scale metabolic models, that can be leveraged for the investigation of a large variety of human diseases. The numerous studies have been categorized according to the clinical research area involved in the examined disease. Furthermore, the paper discusses the most typical approaches employed to derive clinically-relevant information using the computational models.
Conclusions:
The number of scientific papers, utilizing GEM-based approaches for the investigation of human diseases, suggests an increasing interest in these types of approaches; hopefully, the present review will represent a useful reference for scientists interested in applying computational modeling approaches to investigate the aetiopathology of human diseases; we also hope that this work will foster the development of novel applications and methods for the discovery of clinically-relevant insights on metabolic-related diseases.}
}
@article{BATTISTELLI2022,
title = {Online Strategies To Improve Quantitative Skills in Microbiology Laboratory Classes},
journal = {Journal of Microbiology & Biology Education},
volume = {23},
number = {1},
year = {2022},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00333-21},
url = {https://www.sciencedirect.com/science/article/pii/S1935787722000995},
author = {Joseph M. Battistelli and Rima B. Franklin},
keywords = {quantitative literacy, quantitative biology, problem solving, word problems, math skills, formula question, Canvas, spreadsheets, algebra, formula questions},
abstract = {Biology is an increasingly quantitative science. Thus, it is important that undergraduate biology curricula include frequent opportunities for students to practice their quantitative skills.
ABSTRACT
Biology is an increasingly quantitative science. Thus, it is important that undergraduate biology curricula include frequent opportunities for students to practice their quantitative skills. This can create a substantial grading burden for faculty teaching online and/or large enrollment courses, but the “formula question” feature present in many learning management systems (LMS) offers a solution. Using this feature, faculty set up a basic scaffold for an algebraic word problem, and the LMS can then automatically generate and grade many different versions of the question. In this paper, we describe the use of “formula questions” in an undergraduate microbiology course and specifically focus on how the strategic use of algebraic word problems at multiple points throughout the semester can help build quantitative literacy. Key to the success of this approach is that faculty provide a review of foundational mathematical skills early in the semester, even in upper-level classes. This should include reacquainting students with formatting conventions (e.g., rounding and scientific notation), familiarizing them with any idiosyncrasies of the technology platforms, and demonstrating how to solve math problems using spreadsheets. This initial effort increases student success when more complex problems are introduced later in the semester. Though the tips summarized in this paper focus on undergraduate microbiology teaching laboratories using Canvas, the approach can easily be modified to help students develop their critical thinking and quantitative reasoning skills at other levels and in other disciplines.}
}
@article{COUVELAS2020326,
title = {Bioclimatic building design theory and application},
journal = {Procedia Manufacturing},
volume = {44},
pages = {326-333},
year = {2020},
note = {The 1st International Conference on Optimization-Driven Architectural Design (OPTARCH 2019)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.02.238},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920308258},
author = {Agnes Couvelas},
keywords = {Modern architecture, Cultural heritage, Sustainable architecture design, Bioclimatic Performance Optimization, Inter-locality},
abstract = {Ecological thinking is the recognition of the dialectic unity between natural and man-made environment, the respect to what exists around us, and the concomitant “openness” toward others. Here, I present examples from my own work to describe a number of passive bioclimatic approaches focused on the above principles. First, the use of the wind as an expressive element in building design, including the enhancement of air flow in the interior space, the moderation of wind and sand accumulation, the moderation of the sound carried by prevailing winds, and the conversion of the wind into a means of protection against its own force. Second, the use of adaptive building envelopes and shading systems to achieve control of natural light, ventilation and temperature of the inner space through their own transformability, surface openings and materials, including planting as a building material; in a sense, treating buildings as living organisms. Three of these examples have been included in the H2020-MSCA-RISE OptArch project, in which I am scientifically responsible for the work package WP5 entitled “Improvement of bioclimatic design through optimization of performance”.}
}
@article{LOCKWOOD2019100688,
title = {Computing as a mathematical disciplinary practice},
journal = {The Journal of Mathematical Behavior},
volume = {54},
pages = {100688},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2019.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312318300282},
author = {Elise Lockwood and Anna F. DeJarnette and Matthew Thomas},
keywords = {Computation, Mathematical disciplinary practices, Mathematicians},
abstract = {In this paper, we make a case for computing as a mathematical disciplinary practice. We present results from interviews with research mathematicians in which they reflected on the use of computing in their professional work. We draw on their responses to present evidence that computing is an inherent part of doing mathematics and is a practice they want their students to develop. We also discuss the mathematicians’ perspectives on how they learned and teach computing, and we suggest that much needs to be explored about how to teach computing effectively. Our overarching goal is to draw attention to the importance of the teaching and learning of computing, and we argue that it is an imperative topic of study in mathematics education research.}
}
@article{REISS1967193,
title = {Individual thinking and family interaction—II. A study of pattern recognition and hypothesis testing in families of normals, character disorders and schizophrenics},
journal = {Journal of Psychiatric Research},
volume = {5},
number = {3},
pages = {193-211},
year = {1967},
issn = {0022-3956},
doi = {https://doi.org/10.1016/0022-3956(67)90002-7},
url = {https://www.sciencedirect.com/science/article/pii/0022395667900027},
author = {David Reiss},
abstract = {The present study investigated the relationship between family interaction and individual pattern recognition in five families of normals, five families of character disorders and five families of schizophrenics. Following a period of family interaction, members of normal families showed improvement in pattern recognition; members of families of schizophrenics showed deterioration or no change and members of character disorder families were in between. During the period of family interaction, members of normal families were independent and adventuresome in testing their pattern concepts whereas members of families of schizophrenics were cautios, copied each other's performance but showed little pooling of ideas. These findings support the hypothesis that family interaction can influence perceptual process in its individual members in a short time and points to some particular relationships between family interaction and individual perception.}
}
@article{CHERRIER2023104497,
title = {Household heterogeneity in macroeconomic models: A historical perspective},
journal = {European Economic Review},
volume = {158},
pages = {104497},
year = {2023},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2023.104497},
url = {https://www.sciencedirect.com/science/article/pii/S0014292123001265},
author = {Beatrice Cherrier and Pedro Garcia Duarte and Aurélien Saïdi},
keywords = {History of macroeconomics, Heterogeneous agents, Bewley models, Permanent income hypothesis, Aggregation, Equity premium puzzle, Precautionary savings},
abstract = {In this paper, we trace the rise of heterogeneous household models in mainstream macroeconomics from the turn of the 1980s to the early 2000s, when these models evolved into an identifiable and consistent literature. We show that different communities across the US and Europe considered heterogeneous agents for various reasons and developed models that differed in their theoretical and empirical strategies. Minnesota economists primarily focused on incorporating stochastic heterogeneity into general equilibrium models. Other researchers refined growth models or tried to find alternatives to the permanent income hypothesis, leading them to explore more structural heterogeneity. We also document the computational challenges that some of these communities faced, how they gradually became aware of each other's work, and how they faced criticisms from macro- and microeconomists, many of them trained in European countries and dissatisfied with the theoretical and empirical aggregation strategies underlying these models.}
}
@article{1995462,
title = {95/06537 Historical rates of atmospheric Pb deposition using 210Pb dated peat cores: Corroboration, computation, and interpretation},
journal = {Fuel and Energy Abstracts},
volume = {36},
number = {6},
pages = {462},
year = {1995},
issn = {0140-6701},
doi = {https://doi.org/10.1016/0140-6701(95)98112-5},
url = {https://www.sciencedirect.com/science/article/pii/0140670195981125}
}
@article{HAJELA20021,
title = {Soft computing in multidisciplinary aerospace design—new directions for research},
journal = {Progress in Aerospace Sciences},
volume = {38},
number = {1},
pages = {1-21},
year = {2002},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(01)00015-X},
url = {https://www.sciencedirect.com/science/article/pii/S037604210100015X},
author = {Prabhat Hajela},
abstract = {There has been increased activity in the study of methods for multidisciplinary analysis and design. This field of research has been a busy one over the past decade, driven by advances in computational methods and significant new developments in computer hardware. There is a concern, however, that while new computers will derive their computational speed through parallel processing, current algorithmic procedures that have roots in serial thinking are poor candidates for use on such machines—a paradigm shift is required! Among new advances in computational methods, soft computing techniques have enjoyed a remarkable period of development and growth. Of these, methods of neural computing, evolutionary search, and fuzzy logic have been the most extensively explored in problems of multidisciplinary analysis and design. The paper will summarize important accomplishments to-date, of neurocomputing, fuzzy logic, and evolutionary search, including immune network modeling, in the field of multidisciplinary aerospace design.}
}
@article{RAI201651,
title = {Fragmentary shape recognition: A BCI study},
journal = {Computer-Aided Design},
volume = {71},
pages = {51-64},
year = {2016},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2015.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010448515001542},
author = {Rahul Rai and Akshay V. Deshpande},
keywords = {Brain–Computer Interfaces (BCI), Fragmentary shape recognition, User studies, Cognitive load in shape processing, Natural interactions},
abstract = {Recently, Brain–Computer Interface (BCI) has emerged as a potential modality that utilizes natural and intuitive human mechanisms of thinking process to enable interactions in CAD interfaces. Before BCI could become a mainstream mode of HCI for CAD interfaces; fundamental studies directed towards understanding how humans mentally represent and process the geometry are needed. The outlined work in this paper presents an objective user study to understand shape recognition process in the humans. Specifically, we focus on the fundamental task of fragmentary shape identification. The problem of fragmentary shape recognition can be defined as follows: given a partial and incomplete minimalistic representation of a given shape, can one recognize the actual complete shape or object? In user studies, each subject was progressively (in stages) shown more informative fragmented images of an object to be recognized. During each stage of the experiment, the brain activity of users in the form of electroencephalogram (EEG) signals was recorded with a BCI headset. The recorded signals are then processed to objectively study the fragmentary shape recognition process. The results of user studies conclusively show that the measured brain activities of subjects can serve as a very accurate proxy to estimate subjects fragmentary shape recognition process.}
}
@article{SCOLOZZI2017957,
title = {The anthroposphere as an anticipatory system: Open questions on steering the climate},
journal = {Science of The Total Environment},
volume = {579},
pages = {957-965},
year = {2017},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2016.10.086},
url = {https://www.sciencedirect.com/science/article/pii/S0048969716322604},
author = {Rocco Scolozzi and Davide Geneletti},
keywords = {System thinking, Future studies, Climate change, System dynamics, Anticipatory system, Transdisciplinary},
abstract = {Climate change research and action counteracting it affect everyone and would involve cross-societal transformations reshaping the anthroposphere in its entirety. Scrutinizing climate-related science and policies, we recognize attempts to steer the evolution of climate according to expected (or modelled) futures. Such attempts would turn the anthroposphere into a large “anticipatory system”, in which human society seeks to anticipate and, possibly, to govern climate dynamics. The chief aim of this discussion paper is to open a critical debate on the climate change paradigm (CCP) drawing on a strategic and systemic framework grounded in the concept of anticipatory system sensu Rosen (1991). The proposed scheme is ambitiously intended to turn an intricate issue into a complex but structured problem that is to say, to make such complexity clear and manageable. This framework emerges from concepts borrowed from different scientific fields (including future studies and system dynamics) and its background lies in a simple quantitative literature overview, relying upon a broad level of analysis. The proposed framework will assist researchers and policy makers in thinking of CCP in terms of an anticipatory system, and in disentangling its interrelated (and sometimes intricate) aspects. In point of fact, several strategic questions related to CCP were not subjected to an adequate transdisciplinary discussion: what are the interplays between physical processes and social-political interventions, who is the observer (what he/she is looking for), and which paradigm is being used (or who defines the desirable future). The proposed scheme allows to structure such various topics in an arrangement which is easier to communicate, highlighting the linkages in between, and making them intelligible and open to verification and discussion. Furthermore, ideally developments will help scientists and policy makers address the strategic gaps between the evidence-based climatological assessments and the plurality of possible answers as applied to the geopolitical contingencies.}
}
@article{GLASSMEYER2021100873,
title = {Identifying and supporting teachers’ robust understanding of proportional reasoning},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100873},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100873},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000341},
author = {David Glassmeyer and Aaron Brakoniecki and Julie M. Amador},
keywords = {Content knowledge, Knowledge resource, Proportional reasoning, Proportions, Ratio, Teachers},
abstract = {This case study uses the Framework for Teachers’ Robust Understanding of Proportional Reasoning for Teaching (Weiland et al., 2020) to characterize how 51 mathematics teachers solved a comparison proportional problem. We found 50 of the 51 teachers productively drew upon four knowledge resources: (1) proportional situation, (2) ratios as part: part or part: whole, (3) unit rates, and (4) ratio as measure. This study details these and teachers’ less commonly used knowledge resources, as well as counterproductive statements related to the knowledge resources. We analyze the structure of the comparison proportion problem and suggest why teachers drew on particular knowledge resources. Lastly, we highlight how counterproductive statements highlight areas of focus for mathematics teacher educators and extends the operationalizing of the robust proportional reasoning framework for mathematics education researchers.}
}