@article{CHELLAM2018928,
title = {Intrusion Detection in Computer Networks using Lazy Learning Algorithm},
journal = {Procedia Computer Science},
volume = {132},
pages = {928-936},
year = {2018},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.05.108},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918308408},
author = {Aditya Chellam and Ramanathan L and Ramani S},
keywords = {Lazy Learning, Intrusion Detection System, Machine Learning, IBk, kNN},
abstract = {Intrusion Detection Systems (IDS) are used in computer networks to safeguard the integrity and confidentiality of sensitive data. In recent years, network traffic has become sizeable enough to be considered under the big data domain. Current machine learning based techniques used in IDS are largely defined on eager learning paradigms which lose performance efficiency by trying to generalize training data before receiving queries thereby incurring overheads for trivial computations. This paper, proposes the use of lazy learning methodologies to improve overall performance of IDS. A novel heuristic weight based indexing technique has been used to overcome the drawback of high search complexity inherent in lazy learning. IBk and LWL, two popular lazy learning algorithms have been compared and applied on the NSL-KDD dataset for simulating a real-world like scenario and comparing their relative performances with hw-IBk. The results of this paper clearly indicate lazy algorithms as a viable solution for real-world network intrusion detection.}
}
@article{FUSHING2023129227,
title = {Multiscale major factor selections for complex system data with structural dependency and heterogeneity},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {630},
pages = {129227},
year = {2023},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2023.129227},
url = {https://www.sciencedirect.com/science/article/pii/S0378437123007823},
author = {Hsieh Fushing and Elizabeth P. Chou and Ting-Li Chen},
keywords = {Broken symmetry, Conditional entropy, Contingency table, Major factor selection, Multiclass Classification, Pitching dynamics},
abstract = {The unknown multiscale structure hidden in large complex systems is explored bottom-up through discovered heterogeneity under structural dependency embedded within structured data sets. Via two real complex systems, we demonstrate computed hierarchical structures with broken symmetry constituting data’s information content. Through graphic displays, such information content indirectly, but efficiently resolves system-related scientific issues that are difficult to resolve directly. All bottom-up explorations and computations are based on conditional entropy and mutual information evaluated upon contingency table platforms after categorizing all quantitative features. Categorical Exploratory Data Analysis (CEDA) first extracts global major factors that share significant mutual information with the targeted response (Re) variable against many covariate (Co) features under the presence of structural dependency. Then each global major factor is taken as one perspective of heterogeneity to subdivide the entire data set according to its categories into sub-collections. This simple “de-associating” protocol significantly reduces structural dependency among the rest of the features such that another run of major factor selection performed on the sub-collection scale can precisely identify which feature sets could provide extra information beyond the global major factor. Finally, informative patterns collected from multiple perspectives of heterogeneity are displayed to explicitly resolve issues of prediction, classification, and detecting minute dynamic changes.}
}
@article{FU2015159,
title = {An iterative method for discovering feasible management interventions and targets conjointly using uncertainty visualizations},
journal = {Environmental Modelling & Software},
volume = {71},
pages = {159-173},
year = {2015},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2015.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S1364815215001656},
author = {Baihua Fu and Joseph H.A. Guillaume and Anthony J. Jakeman},
keywords = {Uncertainty, Environmental flows, Visualization, Wetlands, Decision making, Environmental management, Systems},
abstract = {This paper presents a generic method, referred to as Iterative Discovery, to guide deliberation with analysis where the aim is to plan refinements to management interventions with difficult-to-define objectives, often due to system uncertainties and diverse stakeholder positions. The method can be initiated by evaluating a scenario describing the current-best intervention. This provides the starting point for three evaluation cycles, focusing on model assumptions, alternative interventions and management targets. The outcome of this method is a list of management targets that can and cannot be achieved, the potential interventions that correspond to these targets, and the assumptions and uncertainties associated with these interventions. It was applied to a case study for environmental flow management in the Macquarie Marshes, Australia. We identified feasible management targets based on ecological outcomes in flood suitability across different locations, climate conditions and species, and the suitable environmental flow volumes that correspond to these targets.}
}
@article{MURAMATSU2005201,
title = {Emotions as a mechanism for boundedly rational agents: The fast and frugal way},
journal = {Journal of Economic Psychology},
volume = {26},
number = {2},
pages = {201-221},
year = {2005},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2004.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167487004000285},
author = {Roberta Muramatsu and Yaniv Hanoch},
keywords = {Bounded rationality, Emotion, Evolution, Mechanism},
abstract = {Herbert Simon has warned us that an explanatory account of human rationality must identify the significance of emotions for choice behavior. Customarily emphasizing the cognitive dimensions of decision making, relatively few researchers have paid close attention to specifying the complex ways in which emotion may shape human thinking and decisions. Accordingly, this paper is an attempt to follow Simon's suggestion and specify how emotions can enter into the theory of bounded rationality. To accomplish our task, we capitalize on Rom Harré's work on causal powers, from which we propose a strategy to study the significance of emotion in decision-making processes. In an attempt to elaborate on an explanation of behavior by mechanism, we discuss a version of bounded rationality recently put forward by Gigerenzer, Todd, and the ABC Research Group [Simple Heuristics that Make us Smart, Oxford University Press, New York, 1999] and Gigerenzer and Selten [Bounded Rationality: The Adaptive Toolbox, MIT Press, Cambridge, MA, 2001, pp. 1–12], the so-called adaptive toolbox of fast and frugal heuristics. Coupled with insights from evolutionary psychology and neuroscience, this version of bounded rationality gives us a better grasp of the functional role of emotions within the human decision machinery.}
}
@article{EBELING2023120768,
title = {A multi-dimensional framework to analyze group behavior based on political polarization},
journal = {Expert Systems with Applications},
volume = {233},
pages = {120768},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120768},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423012708},
author = {Régis Ebeling and Jéferson Nobre and Karin Becker},
keywords = {Analysis framework, Political polarization, Group behavior, Topic modeling, Social network analysis, COVID-19},
abstract = {The recent wave of elections won by right-wing worldwide brings up increased discussions biased by political polarization, including in social media. Social media data enables the investigation of the contexts where political polarization occurs, enabling to derive insights into how it affects human behavior. Related work has shown how computing techniques can be leveraged to understand political polarization in restricted scenarios, but the complexity of this behavior can be better understood when considered from different viewpoints. This article describes a multi-dimensional analysis framework to study the behavior of groups on Twitter in politically polarized scenarios. It can be applied to various themes where groups display stances that can be politically biased, and it aggregates a wide range of computational techniques in an innovative way to provide rich insights. The framework includes guidelines and techniques to: (a) collect data on Twitter to represent the groups; (b) automatically infer the political leaning of users; (c) derive topological properties of the groups’ social network and analyze political influence; (d) identify topics representing concerns at coarse and fine-grained granularity levels using a hybrid topic modeling approach; (e) identify psychological aspects based on linguistic cues, and (f) analyze the sources of information disseminated by the groups. Applying the framework in two case studies related to COVID-19 revealed patterns of behavior common to ideologies. We confirmed that the stances were politically motivated and that both groups, left/right, were subject to the echo chamber effect. Comparatively, the social structure of the right-oriented groups is more connected, and they rely on politicians and social media for information spreading. Left-oriented groups are less connected and more prone to facts. The psychological aspects reveal that both groups are emotionally distressed in arguing about being right, given their beliefs.}
}
@article{FUJINO201760,
title = {Role of Spontaneous Brain Activity in Explicit and Implicit Aspects of Cognitive Flexibility under Socially Conflicting Situations: A Resting-state fMRI Study using Fractional Amplitude of Low-frequency Fluctuations},
journal = {Neuroscience},
volume = {367},
pages = {60-71},
year = {2017},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2017.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S0306452217307534},
author = {Junya Fujino and Shisei Tei and Kathryn F. Jankowski and Ryosaku Kawada and Toshiya Murai and Hidehiko Takahashi},
keywords = {decision-making, cerebellum, prefrontal cortex, rationalism, experientialism},
abstract = {We are constantly exposed to socially conflicting situations in everyday life, and cognitive flexibility is essential for adaptively coping with such difficulties. Flexible goal choice and pursuit are not exclusively conscious, and therefore cognitive flexibility involves both explicit and implicit forms of processing. However, it is unclear how individual differences in explicit and implicit aspects of flexibility are associated with neural activity in a resting state. Here, we measured intrinsic fractional amplitude of low-frequency fluctuations (fALFF) by resting-state functional magnetic resonance imaging (RS-fMRI) as an indicator of regional brain spontaneous activity, together with explicit and implicit aspects of cognitive flexibility using the Cognitive Flexibility Scale (CFS) and Implicit Association Test (IAT). Consistent with the dual processing theory, there was a strong association between explicit aspects of flexibility (CFS score) and “rationalism” thinking style and between implicit aspects (IAT effect) and “experientialism.” The level of explicit flexibility was also correlated with fALFF values in the left lateral prefrontal cortex, whereas the level of implicit flexibility was correlated with fALFF values in the right cerebellum. Furthermore, the fALFF values in both regions predicted individual preference for flexible decision-making strategy in a vignettes simulation task. These results add to our understanding of the neural mechanisms underlying flexible decision-making for solving social conflicts. More generally, our findings highlight the utility of RS-fMRI combined with both explicit and implicit psychometric measures for better understanding individual differences in social cognition.}
}
@incollection{STRUBE20012158,
title = {Cognitive Science: Overview},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2158-2166},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01441-8},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767014418},
author = {G. Strube},
abstract = {Cognitive science (CS) emerged in 1975 as a field spanning parts of psychology, artificial intelligence, linguistics, philosophy, anthropology, and the neurosciences. CS is unique in its basic tenet that cognitive processes are computations, a perspective which allows for direct comparison of natural and artificial intelligence and emphasizes a methodology that integrates formal and empirical analyses with computational synthesis. Computer simulations have therefore become the hallmark of CS. Today, CS is an internationally established discipline. Its dominant tradition, close to symbol-processing architectures, has been enriched by neural networks and by the recognition that human cognition rests on both biological and cultural foundations. CS studies cognitive systems: organisms, machines, or any combination of these, acting in dynamically changing environments. Cognition in CS denotes advanced control mechanisms that allow for sophisticated adaptation through computations operating on mental representations. CS recognizes that cognition in biological systems is implemented in brain processes, but emphasizes analyses at the functional level, with cognitive neuroscience relating both domains. Applications of CS may be found in the design of software, in human factors engineering, health care, and education.}
}
@article{UTHAMACUMARAN2020759,
title = {Cancer: A turbulence problem},
journal = {Neoplasia},
volume = {22},
number = {12},
pages = {759-769},
year = {2020},
issn = {1476-5586},
doi = {https://doi.org/10.1016/j.neo.2020.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1476558620301548},
author = {Abicumaran Uthamacumaran},
keywords = {Cancer, Complexity, Chaos, Nonlinear dynamics, Fractals, Chemical turbulence},
abstract = {Cancers are complex, adaptive ecosystems. They remain the leading cause of disease-related death among children in North America. As we approach computational oncology and Deep Learning Healthcare, our mathematical models of cancer dynamics must be revised. Recent findings support the perspective that cancer-microenvironment interactions may consist of chaotic gene expressions and turbulent protein flows during pattern formation. As such, cancer pattern formation, protein-folding and metastatic invasion are discussed herein as processes driven by chemical turbulence within the framework of complex systems theory. To conclude, cancer stem cells are presented as strange attractors of the Waddington landscape.}
}
@article{ANDIC2023490,
title = {A robust crow search algorithm based power system state estimation},
journal = {Energy Reports},
volume = {9},
pages = {490-501},
year = {2023},
note = {Proceedings of 2022 7th International Conference on Renewable Energy and Conservation},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2023.09.075},
url = {https://www.sciencedirect.com/science/article/pii/S2352484723013124},
author = {Cenk Andic and Ali Ozturk and Belgin Turkay},
keywords = {Crow search algorithm, Power systems, State estimation},
abstract = {The State Estimation (SE) computational procedure plays a crucial role in modern electric power system security control by monitoring and analyzing operational conditions and predicting any emergency. In order to estimate state variables, Power System State Estimation (PSSE) takes into account the magnitudes and phases of voltage on each bus. To address the state estimation challenges in power systems, in this paper, we propose a novel application of the Crow Search Algorithm (CSA) specifically tailored for the state estimation problem. We have assessed the introduced algorithm using the frameworks of both the IEEE 14-bus and IEEE 30-bus test systems. The first formulation is the Weighted Least Square (WLS) method, and the second is the Weighted Least Absolute Value (WLAV) method, both of which are objective function formulations. By comparing the results, it is clear that CSA-based SE is superior to the other metaheuristic algorithms considered, namely Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Artificial Bee Swarm Optimization (ABSO). As a point of comparison, we use the Newton–Raphson method for calculating load flow. It has been shown that the proposed CSA-based SE technique has better accuracy than the other two algorithms in all different test systems. With this study, the power system is operated more accurately and reliably by the operators operating the system.}
}
@article{LANG20151369,
title = {Beyond the Golden Era of public health: charting a path from sanitarianism to ecological public health},
journal = {Public Health},
volume = {129},
number = {10},
pages = {1369-1382},
year = {2015},
issn = {0033-3506},
doi = {https://doi.org/10.1016/j.puhe.2015.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0033350615003029},
author = {Tim Lang and Geof Rayner},
keywords = {Public health, Prosperity, Economic growth, Human progress, Societal & ecosystem costs, Public policy, 21st century challenges, Ecological public health, Institutional reform},
abstract = {The paper considers the long-term trajectory of public health and whether a ‘Golden Era’ in Public Health might be coming to an end. While successful elements of the 20th century policy approach need still to be applied in the developing world, two significant flaws are now apparent within its core thinking. It assumes that continuing economic growth will generate sufficient wealth to pay for the public health infrastructure and improvement needed in the 21st century when, in reality, externalised costs are spiralling. Secondly, there is evidence of growing mismatch between ecosystems and human progress. While 20th century development has undeniably improved public health, it has also undermined the capacity to maintain life on a sustainable basis and has generated other more negative health consequences. For these and other reasons a rethink about the role, purpose and direction of public health is needed. While health has to be at the heart of any viable notion of progress the dominant policy path offers new versions of the ‘health follows wealth’ position. The paper posits ecological public health as a radical project to reshape the conditions of existence. Both of these broad paths require different functions and purposes from their institutions, professions and politicians. The paper suggests that eco-systems pressures, including climate change, are already adding to pressure for a change of course.}
}
@article{BOYCE2004565,
title = {Critical accounting education: teaching and learning outside the circle},
journal = {Critical Perspectives on Accounting},
volume = {15},
number = {4},
pages = {565-586},
year = {2004},
note = {A Critical Response to Managerialism in the Academy},
issn = {1045-2354},
doi = {https://doi.org/10.1016/S1045-2354(03)00047-9},
url = {https://www.sciencedirect.com/science/article/pii/S1045235403000479},
author = {Gordon Boyce},
keywords = {Critical accounting, Corporate university, Accounting research, Accounting education, Intellectuals},
abstract = {The development of the corporate university is an element in the suite of “economically rational” public policy changes promulgated in recent decades. Working from a position that the practice of accounting is centrally implicated in these changes, it is contended in this paper that accounting, and accounting education, can in fact play a part in challenging these positions. Extant accounting research is sufficiently well-developed such that we are aware of the conflicts and contradictions both within accounting and flowing from the practice of the discipline, yet the effect of this body of knowledge on the content of teaching and learning within the accounting classroom remains limited. By and large, accounting education continues to be constrained within narrowly defined, but mis-conceived, disciplinary boundaries, focusing on the techniques and “skills” of accounting practice. In outlining a case for broadening the accounting education curriculum, this paper adopts the heuristic of “tangential thinking” as a means of transcending narrowly constructed disciplinary boundaries. In doing so, it is suggested that accounting education reform needs to go well beyond the putative reform agenda of the organised professional accounting bodies. The exploration of tangents lead to areas of knowledge that initially seem to be outside of accounting, but which nevertheless have an integral connection to the realities of the practice of the discipline. The paper outlines a case for tangential thinking in teaching and learning activities in the accounting classroom, within extant accreditation and curricular arrangements. Teaching and learning “outside the circle” in this manner is suggested as a way to make accounting education relevant in its socio-historical context and, particularly, relevant to the lived experience of students.}
}
@article{DELIGUORO2023114082,
title = {From semantics to types: The case of the imperative λ-calculus},
journal = {Theoretical Computer Science},
volume = {973},
pages = {114082},
year = {2023},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2023.114082},
url = {https://www.sciencedirect.com/science/article/pii/S030439752300395X},
author = {Ugo de'Liguoro and Riccardo Treglia},
keywords = {State monad, Imperative lambda calculus, Type assignment systems, Filter models},
abstract = {We study the logical semantics of an untyped λ-calculus equipped with operators representing read and write operations from and to a global store. Such a logic consists of an intersection type assignment system, which we derive from the denotational semantics of the calculus, based on the monadic approach to model computational λ-calculi. The system is obtained by constructing a filter model in the category of ω-algebraic lattices, such that the typing rules can be recovered out of the term interpretation. By construction, the so-obtained type system satisfies the “type-semantics” property and completeness.}
}
@article{KOULADOUM2024200052,
title = {The role of institutional quality on the impact of Chinese foreign direct investments and human capital development on macroeconomic performance in the CEMAC zone},
journal = {Transnational Corporations Review},
volume = {16},
number = {2},
pages = {200052},
year = {2024},
issn = {1925-2099},
doi = {https://doi.org/10.1016/j.tncr.2024.200052},
url = {https://www.sciencedirect.com/science/article/pii/S1925209924005783},
author = {Jean-Claude Kouladoum},
keywords = {Institutional quality, Chinese foreign direct investments, Human capital development, Macroeconomic performance, CEMAC zone},
abstract = {This paper investigates the role of institutional quality in terms of governance on the impact of Chinese foreign direct investments and human capital development on the macroeconomic performance of the CEMAC zone between 2003 and 2020. The data were analyzed using descriptive statistics and the Correlated Panels Corrected Standard Errors (PCSEs) Approach. The findings indicated that poor governance performance in the CEMAC zone deteriorates the effects of Chinese foreign direct investments and human capital development on the macroeconomic performance of the CEMAC zone. At the same time, poor governance performance also deteriorates the impact of foreign aid and personal remittances received on the macroeconomic performance of the CEMAC zone. This study strongly recommends measures to improve institutional quality such as increased training on ethical thinking in all forms of education, meritocratic recruitment to the civil service, and auditing of public finances and services.}
}
@article{MCCRADDEN2023100864,
title = {A normative framework for artificial intelligence as a sociotechnical system in healthcare},
journal = {Patterns},
volume = {4},
number = {11},
pages = {100864},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100864},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923002489},
author = {Melissa D. McCradden and Shalmali Joshi and James A. Anderson and Alex John London},
abstract = {Summary
Artificial intelligence (AI) tools are of great interest to healthcare organizations for their potential to improve patient care, yet their translation into clinical settings remains inconsistent. One of the reasons for this gap is that good technical performance does not inevitably result in patient benefit. We advocate for a conceptual shift wherein AI tools are seen as components of an intervention ensemble. The intervention ensemble describes the constellation of practices that, together, bring about benefit to patients or health systems. Shifting from a narrow focus on the tool itself toward the intervention ensemble prioritizes a “sociotechnical” vision for translation of AI that values all components of use that support beneficial patient outcomes. The intervention ensemble approach can be used for regulation, institutional oversight, and for AI adopters to responsibly and ethically appraise, evaluate, and use AI tools.}
}
@article{ZEITHAMMER2024,
title = {Strange Case of Dr. Bidder and Mr. Entrant: Consumer Preference Inconsistencies in Costly Price Offers},
journal = {International Journal of Research in Marketing},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2024.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S016781162400079X},
author = {Robert Zeithammer and Lucas Stich and Martin Spann and Gerald Häubl},
keywords = {Pricing, Auctions, Entry costs, Behavioral economics, Experiments},
abstract = {Consumers make price offers to sellers in a variety of domains, such as when buying cars or houses or when bidding in auctions for airline upgrades, art, or collectibles. Submitting an offer typically entails administrative, waiting, and opportunity costs. Making such costly price offers involves two intertwined decisions—in addition to determining how much to offer, consumers must also decide whether to make an offer in the first place. We examine the impact of offer-submission costs on consumer behavior using a series of incentive-compatible experiments. Our findings reveal a preference inconsistency, whereby the preferences implied by one of the decisions do not align with the preferences implied by the other. In particular, potential buyers enter more often than their offer amounts would predict based on standard economic models. This preference inconsistency is robust to two interventions designed to help consumers make offer-amount and entry decisions—(1)the provision of interactive-feedback decision aids and (2)the sequencing of the two sub-decisions in the normative order. Neither of these interventions resolves the inconsistency. Instead, the patterns of results suggest that consumers approach the offer-amount and entry decisions as if they were unrelated. We discuss the implications of our findings for the design of offer-submission interfaces, as well as for econometric attempts to infer consumer preferences from offer and bidding data.}
}
@article{DILUZIO2023104418,
title = {A randomized deep neural network for emotion recognition with landmarks detection},
journal = {Biomedical Signal Processing and Control},
volume = {81},
pages = {104418},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104418},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422008722},
author = {Francesco {Di Luzio} and Antonello Rosato and Massimo Panella},
keywords = {Emotion recognition, Randomized neural networks, Facial landmarks, Deep learning, Video sequences},
abstract = {In this paper, we present an innovative deep neural architecture employing parameter randomization in a complex classification model for emotion recognition. Actually, randomized deep neural networks represent an interesting alternative to exploring the efficiency-to-accuracy balance in real-life applications. Moreover, we also introduce the use of input frames composed of 468 facial landmarks coordinates and an innovative sampling procedure avoiding padding. The proposed randomized classifier is trained for emotion recognition on video sequences and the related accuracy is compared with a non-randomized version of the same model and with well-known benchmark architectures, demonstrating the robustness of the proposed approach in terms of classification accuracy and training time.}
}
@article{LAVIGNE2007630,
title = {Statistical reasoning of middle school children engaged in survey inquiry},
journal = {Contemporary Educational Psychology},
volume = {32},
number = {4},
pages = {630-666},
year = {2007},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2006.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X06000488},
author = {Nancy C. Lavigne and Susanne P. Lajoie},
keywords = {Statistical reasoning, Inquiry, Mathematics education, Middle school, Thinking, Cognition},
abstract = {The case study examined two groups of grade 7 students as they engaged in four inquiry phases: posing a question and collecting, analyzing, and representing data. Previous studies reported analyses of statistical reasoning on a single inquiry phase. Our goal was to identify the modes of statistical reasoning displayed during group discussions in all phases as children designed and conducted their own inquiry. A content analysis of audio and video recorded discussions yielded 10 statistical reasoning modes: six relate to Garfield and Gal’s [Garfield, J., Gal, I. (1999). Teaching and assessing statistical reasoning. In L. V. Stiff, & F. R. Curcio (Eds.), Developing mathematical reasoning in grades K-12. 1999 Yearbook (pp. 207–219). Reston, VA: National Council of Teachers of Mathematics] statistical reasoning types involved in the collection, analysis, and representation of data and four modes deal with an aspect of inquiry not exclusively focused upon in the literature on statistical reasoning—i.e., the problem-posing phase. Although students’ reasoning reflected an incomplete understanding of statistics they serve as building blocks for instruction.}
}
@article{GUI2024111972,
title = {Molten salt-promoted MgO-based CO2 adsorbents: Selective adsorption on polycrystalline surfaces},
journal = {Journal of Environmental Chemical Engineering},
volume = {12},
number = {2},
pages = {111972},
year = {2024},
issn = {2213-3437},
doi = {https://doi.org/10.1016/j.jece.2024.111972},
url = {https://www.sciencedirect.com/science/article/pii/S2213343724001027},
author = {Changqing Gui and Zirui Wang and Changjian Ling and Zhongfeng Tang},
keywords = {CO, MgCl·6 HO, Molten salt, MgO, Capture},
abstract = {Molten salt-doped MgO adsorbent is considered one of the most promising CO2 adsorbents in the field. In this work, MgO-based adsorbents were prepared by one-step calcination using MgCl2·6 H2O as magnesium source. The CO2 adsorption performance of MgO-based adsorbents was investigated via different methods. Results showed that the maximum CO2 adsorption capacity of MgO doped by LiNO3-NaNO3-KNO3 was 57.1% at the CO2 concentration of 80% and 350 ℃, and the MgO-based adsorbents showed good regeneration. The nanosheet structure of the MgO-based adsorbents decreased with the increase in the number of cycles, whereas the crystal structures of MgO and alkali metal nitrates did not change because of multiple decarbonization. DFT computation revealed selective adsorption of CO2 on different crystal faces of MgO. The (200) crystal face of molten salt-doped MgO did not have CO2 trap ability. In addition, the doped nitrate did not directly participate in the reaction but reduced the adsorption energy of MgO carbonation. The adsorption energies of the MgO (220) and (222) crystal faces after doping with nitrate were reduced to − 2.07 and − 3.26 eV, respectively. The overall energy level of adsorption decreased as the number of resonance peaks and the stability of the structure increased. This study explains why MgO currently fails to reach the theoretical adsorption capacity and reveals the underlying mechanism of molten salts.}
}
@article{CORREA2008140,
title = {Connected and culturally embedded beliefs: Chinese and US teachers talk about how their students best learn mathematics},
journal = {Teaching and Teacher Education},
volume = {24},
number = {1},
pages = {140-153},
year = {2008},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2006.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X06001715},
author = {Christopher A. Correa and Michelle Perry and Linda M. Sims and Kevin F. Miller and Ge Fang},
keywords = {Teacher beliefs, Mathematics education, China, United States, Cross-cultural, Culture},
abstract = {This study compares US and Chinese elementary mathematics teachers' beliefs about how students learn mathematics. Interviews with teachers in each country revealed that Chinese and US teachers have distinct ways of thinking about how mathematics should be taught and how students learn. Many Chinese teachers talked about developing students’ interest in mathematics and relating the content of mathematics lessons to real-life situations. The US teachers talked about students' learning styles and using hands-on approaches to learning mathematics. Furthermore, these beliefs may be widespread and persistent within each country because the set of ideas among teachers appear to be internally consistent. Implications for teacher change and the study of teachers' beliefs are discussed.}
}
@article{DECHARMS2007473,
title = {Reading and controlling human brain activation using real-time functional magnetic resonance imaging},
journal = {Trends in Cognitive Sciences},
volume = {11},
number = {11},
pages = {473-481},
year = {2007},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2007.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661307002471},
author = {R. Christopher deCharms},
abstract = {Understanding how to control how the brain's functioning mediates mental experience and the brain's processing to alter cognition or disease are central projects of cognitive and neural science. The advent of real-time functional magnetic resonance imaging (rtfMRI) now makes it possible to observe the biology of one's own brain while thinking, feeling and acting. Recent evidence suggests that people can learn to control brain activation in localized regions, with corresponding changes in their mental operations, by observing information from their brain while inside an MRI scanner. For example, subjects can learn to deliberately control activation in brain regions involved in pain processing with corresponding changes in experienced pain. This may provide a novel, non-invasive means of observing and controlling brain function, potentially altering cognitive processes or disease.}
}
@article{KEBEDE2024131461,
title = {Transfer learning-based deep learning models for proton exchange membrane fuel remaining useful life prediction},
journal = {Fuel},
volume = {367},
pages = {131461},
year = {2024},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2024.131461},
url = {https://www.sciencedirect.com/science/article/pii/S0016236124006094},
author = {Getnet Awoke Kebede and Shih-Che Lo and Fu-Kwun Wang and Jia-Hong Chou},
keywords = {Drop method, Long-short term memory with attention, Remaining useful life prediction, Transfer learning, Variational autoencoder},
abstract = {Proton exchange membrane fuel cells (PEMFCs) offer power generation capabilities for diverse applications including commercial enterprises, industrial sectors, and residential technologies. Nevertheless, the comprehensive integration of PEMFC applications could be improved by challenges related to degradation and durability. The imperative development of efficient performance prognostic models assumes a pivotal role in the prognosis of remaining useful life (RUL), health monitoring, and effective utilization of PEMFCs. This paper centers on the prognostication of critical components within PEMFCs and introduces a transfer learning approach based on variational autoencoder and bi-directional long short-term memory with an attention mechanism (Bi-LSTM-AM) model. This approach combines feature fusion, knee-point detection, and a sophisticated deep-learning-based predictive model. Notably, incorporating the variational autoencoder as the framework for feature fusion introduces a novel perspective previously unexplored. Identifying the knee point and knowing the start point on the training data, facilitates optimized parameter computation. The application of transfer learning facilitates the transfer of optimal model parameters and weights from a source to a target dataset. Conclusively, the estimation of stack voltage degradation and real-time RUL prediction based on the test dataset is executed by implementing our proposed method. The stack voltage prediction findings showcase the Bi-LSTM-AM model’s superior performance relative to comparison models. The proposed online rolling prediction model, utilizing a sliding window technique for RUL prediction, yields significantly enhanced accuracy, culminating in a relative error margin ranging from approximately 1.69% to 5.04%.}
}
@incollection{HERNANDEZGARCIA2021307,
title = {Chapter 16 - Smart and informal? Self-organization and everyday},
editor = {Alessandro Aurigi and Nancy Odendaal},
booktitle = {Shaping Smart for Better Cities},
publisher = {Academic Press},
pages = {307-319},
year = {2021},
isbn = {978-0-12-818636-7},
doi = {https://doi.org/10.1016/B978-0-12-818636-7.00012-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186367000123},
author = {Jaime Hernández-García and Iliana Hernández-García},
keywords = {Smart cities, Smart technologies, Informal settlements, Self-organization, Everyday, Complexity},
abstract = {With the aim to offer an alternative understanding of smart cities, this chapter explores the relationship between smart and informal characteristics, presenting a discussion of two concepts arguably found in both smart and informal types of urban development: self-organization and the everyday. For this purpose, this chapter discusses the social and spatial production of informal settlements—how these areas show high degrees of self-organization based on everyday actions and interactions. In line with Rauws (2016), observers can see smart cities as networks of knowledge, actions, and selection of choices; yet this view also aligns with the actions informal settlers in Latin America take to produce their own living environments via self-organization and everyday practices. The chapter suggests how smart technologies can utilize computational logics to help measure and interpret these self-organized systems, as well as help decipher everyday creativity, based on uncertainty, autonomy, and freedom. An urban area may possess no formal planning processes, yet residents’ bottom-up social and spatial initiatives give shape to their settlements and to the city. In this sense the use of smart technologies can bring heightened understandings to informality; therefore not only the smart but also the informal can undergo reconceptualizing. We suggest viewing the smart and the informal as collective and adaptive self-organized systems fuelled by everyday practices where the social emerges as everyday creativity.}
}
@article{SINHA2008955,
title = {Thermal pressure of ionic solids at high temperatures},
journal = {Solid State Sciences},
volume = {10},
number = {7},
pages = {955-959},
year = {2008},
issn = {1293-2558},
doi = {https://doi.org/10.1016/j.solidstatesciences.2007.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1293255807003366},
author = {Pallavi Sinha},
keywords = {Thermal pressure, Volume expansion},
abstract = {In the present study, a relationship between thermal pressure and volume expansion ratio is disclosed for ionic solids at 1bar pressure. The ionic solids NaCl, KCl, MgO and CaO are considered for the analytic thinking. The analysis is based on the experimental data tabulated by Anderson and generalized data reported by Srivastava. A close agreement between the present study and the experiment reveals the validity of the present work. The extrapolated values of thermal pressure at higher temperatures are useful to understand the thermoelastic behaviour of solids.}
}
@article{ZAGREBAEV2018568,
title = {About using of AI to choosing a refueling channel and manipulating control rods in RBMK-type reactor},
journal = {Procedia Computer Science},
volume = {123},
pages = {568-572},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.086},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300875},
author = {A.M. Zagrebaev and R.N. Ramazanov and A.V. Trifonenkov},
keywords = {AI, refueling channel, manipulating control rods, RBMK-type reactor},
abstract = {Nuclear reactor control is usually the composition of automatic and manual control types. This article deals with manual parts of power control and refueling systems of RBMK-type reactor. There are always such aspects of the reactor operation, which automatic systems do not control. The aim of this research is to determine the set of actual choices made by the operator and create mathematical model of decision-making operator based on a neural network. The further research may include estimations of the automatic control system imperfection, estimations of the quality of decisions made and performance tests for the composite computational and AI decision-making software for nuclear reactors.}
}
@article{KLASIOS2016103,
title = {Evolutionizing human nature},
journal = {New Ideas in Psychology},
volume = {40},
pages = {103-114},
year = {2016},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2015.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X15000501},
author = {John Klasios},
keywords = {Human nature, Evolutionary psychology, Adaptationism, Darwin, Homeostatic property clusters, Developmental systems},
abstract = {Many have argued that the very notion of human nature is untenable given the facts of evolution and should accordingly be discarded. This paper, by contrast, argues that the notion can be retained in a coherent and modern way. The present account expounds on the view of human nature as a collection of species-typical psychological adaptations, and outlines how it can be understood in formally modeled computational terms. The view defended is also heavily developmental and connects directly with contemporary evolutionary developmental biology. Furthermore, the notion of human nature developed here allows us to abstract away from the obfuscating variability that manifests not only between individuals across ontogeny, but also cross-culturally and throughout time.}
}
@article{SETO2022102891,
title = {Connected in health: Place-to-place commuting networks and COVID-19 spillovers},
journal = {Health & Place},
volume = {77},
pages = {102891},
year = {2022},
issn = {1353-8292},
doi = {https://doi.org/10.1016/j.healthplace.2022.102891},
url = {https://www.sciencedirect.com/science/article/pii/S1353829222001526},
author = {Christopher H. Seto and Corina Graif and Aria Khademi and Vasant G. Honavar and Claire E. Kelling},
keywords = {Commuting networks, COVID-19, Fixed-effects, Spatial models, Computational statistics, Mobility data},
abstract = {Biweekly county COVID-19 data were linked with Longitudinal Employer-Household Dynamics data to analyze population risk exposures enabled by pre-pandemic, country-wide commuter networks. Results from fixed-effects, spatial, and computational statistical approaches showed that commuting network exposure to COVID-19 predicted an area's COVID-19 cases and deaths, indicating spillovers. Commuting spillovers between counties were independent from geographic contiguity, pandemic-time mobility, or social media ties. Results suggest that commuting connections form enduring social linkages with effects on health that can withstand mobility disruptions. Findings contribute to a growing relational view of health and place, with implications for neighborhood effects research and place-based policies.}
}
@article{YANG2023105120,
title = {Thoughts of brain EEG signal-to-text conversion using weighted feature fusion-based Multiscale Dilated Adaptive DenseNet with Attention Mechanism},
journal = {Biomedical Signal Processing and Control},
volume = {86},
pages = {105120},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105120},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423005530},
author = {Jing Yang and Muhammad Awais and Md. Amzad Hossain and Por {Lip Yee} and Ma. Haowei and Ibrahim M. Mehedi and A.I.M. Iskanderani},
keywords = {Thought-to-text conversion, Electroencephalography signal, Optimal weighted feature fusion, Eurasian oystercatcher wild geese migration optimization, Multiscale Dilated Adaptive DenseNet with Attention Mechanism},
abstract = {Individuals with visual inefficiencies or different abilities face difficulties using their hands to operate smartphones and computers, necessitating reliance on others to enter data. Such dependence may lead to security and privacy issues, especially when sensitive information is shared with helpers. To address this problem, we present Think2Type, an efficient Brain-Computer Interface (BCI) that enables users to translate their active intentions into text format based on Morse code. BCI leverages brain activity to facilitate interaction with computers, often captured via Electroencephalography (EEG). This work proposes an enhanced attention-based deep learning strategy to develop an efficient text conversion mechanism from EEG signals. We begin by collecting EEG signals from standard benchmark datasets and extracting spectral and statistical features in phase 1, concatenating them into concatenated feature set 1 (F1). In phase 2, we extract spatial and temporal features via a One-Dimensional Convolutional Neural Network (1DCNN) and a Recurrent Neural Network (RNN), respectively, concatenating them into concatenated feature set 2 (F2). Weighted feature fusion is performed on concatenated features F1 and F2, with the hybrid optimization algorithm Eurasian Oystercatcher Wild Geese Migration Optimization (EOWGMO) optimizing the weight for improved fusion efficiency. The text conversion phase utilizes the Multiscale Dilated Adaptive DenseNet with Attention Mechanism (MDADenseNet-AM) to obtain the converted text information. The MDADenseNet-A's parameters are optimized to improve thought-to-text conversion performance. The developed model's performance is evaluated via experimental analysis and compared to conventional techniques, resulting in a higher accuracy value of 96.41%, facilitating appropriate text conversion.}
}
@article{BURCH2023101039,
title = {Investigating two teachers’ development of combinatorial meaning for algebraic structure},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101039},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101039},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000093},
author = {Lori J. Burch},
keywords = {Mathematical meanings, Combinatorial reasoning, Algebraic reasoning, Polynomial operations, Secondary teachers},
abstract = {This paper reports on the results of a four-day teaching experiment that supported two algebra teachers to develop a combinatorial meaning for algebraic structure. The purpose of the teaching episodes was to support the teachers (a) to establish a combinatorial understanding for algebraic structure (Tillema & Burch, 2022) by generalizing the cubic identity, a+b3=a3+3a2b+3ab2+b3, as a symbolization of quantitative and combinatorial relationships out of a contextualized problem (Tillema & Gatza, 2016) and (b) to develop a combinatorial meaning as a mobilization of their understanding through a series of algebraic tasks (cf. Thompson et al., 2014). The findings from this study contribute to research literature on teachers’ mathematical meanings within secondary algebra by investigating how teachers’ combinatorial meanings developed and how differences in their combinatorial meanings impacted their algebraic reasoning. The findings demonstrate a combinatorial pathway for supporting the development of expanding and factoring as reversible polynomial operations (cf. Sangwin & Jones, 2017).}
}
@article{KHADE20214955,
title = {hdANM: a new comprehensive dynamics model for protein hinges},
journal = {Biophysical Journal},
volume = {120},
number = {22},
pages = {4955-4965},
year = {2021},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2021.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0006349521008766},
author = {Pranav M. Khade and Domenico Scaramozzino and Ambuj Kumar and Giuseppe Lacidogna and Alberto Carpinteri and Robert L. Jernigan},
abstract = {Hinge motions are essential for many protein functions, and their dynamics are important to understand underlying biological mechanisms. The ways that these motions are represented by various computational methods differ significantly. By focusing on a specific class of motion, we have developed a new hinge-domain anisotropic network model (hdANM) that is based on the prior identification of flexible hinges and rigid domains in the protein structure and the subsequent generation of global hinge motions. This yields a set of motions in which the relative translations and rotations of the rigid domains are modulated and controlled by the deformation of the flexible hinges, leading to a more restricted, specific view of these motions. hdANM is the first model, to our knowledge, that combines information about protein hinges and domains to model the characteristic hinge motions of a protein. The motions predicted with this new elastic network model provide important conceptual advantages for understanding the underlying biological mechanisms. As a matter of fact, the generated hinge movements are found to resemble the expected mechanisms required for the biological functions of diverse proteins. Another advantage of this model is that the domain-level coarse graining makes it significantly more computationally efficient, enabling the generation of hinge motions within even the largest molecular assemblies, such as those from cryo-electron microscopy. hdANM is also comprehensive as it can perform in the same way as the well-known protein dynamics models (anisotropic network model, rotations-translations of blocks, and nonlinear rigid block normal mode analysis), depending on the definition of flexible and rigid parts in the protein structure and on whether the motions are extrapolated in a linear or nonlinear fashion. Furthermore, our results indicate that hdANM produces more realistic motions as compared to the anisotropic network model. hdANM is an open-source software, freely available, and hosted on a user-friendly website.}
}
@article{RIZZI19871,
title = {Selected topics in the theory and practice of computational fluid dynamics},
journal = {Journal of Computational Physics},
volume = {72},
number = {1},
pages = {1-69},
year = {1987},
issn = {0021-9991},
doi = {https://doi.org/10.1016/0021-9991(87)90072-6},
url = {https://www.sciencedirect.com/science/article/pii/0021999187900726},
author = {Arthur Rizzi and Björn Engquist},
abstract = {Computational fluid dynamics (CFD) is a large branch of scientific computing that lately has undergone explosive growth. It draws upon elements from related disciplines: fluid mechanics, numerical analysis, theory of partial differential equations, computer science, and computational geometry. By selecting certain topics we try to trace the way the dramatic growth came about and to illustrate the interplay of the related disciplines. The scope is broad and the emphasis is on discussing the underlying fundamentals in order to present an overall perspective on CFD. The focus is on the evolution of nonsmooth features in inviscid flows, primarily macroscale discontinuities like shock waves and vortex sheets admitted as solutions to the Euler equations, but also with some view to their possible unstable progression into small-scale features, ending ultimately in turbulence. Some of the current finite-difference methods, and the theory they are based upon, which are used to treat these problems are reviewed, and different grid generation techniques are introduced. Together with some principles for using advanced supercomputers, we also discuss how the methods are implemented on these machines. A number of computed results, some of them new and of large scale with up to one million grid points, are presented which reflect the limits of the theory and the current status of the field.}
}
@article{HAMEDUH20203494,
title = {Homology modeling in the time of collective and artificial intelligence},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3494-3506},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304748},
author = {Tareq Hameduh and Yazan Haddad and Vojtech Adam and Zbynek Heger},
keywords = {Homology modeling, Machine learning, Protein 3D structure, Structural bioinformatics, Collective intelligence, Artificial intelligence},
abstract = {Homology modeling is a method for building protein 3D structures using protein primary sequence and utilizing prior knowledge gained from structural similarities with other proteins. The homology modeling process is done in sequential steps where sequence/structure alignment is optimized, then a backbone is built and later, side-chains are added. Once the low-homology loops are modeled, the whole 3D structure is optimized and validated. In the past three decades, a few collective and collaborative initiatives allowed for continuous progress in both homology and ab initio modeling. Critical Assessment of protein Structure Prediction (CASP) is a worldwide community experiment that has historically recorded the progress in this field. Folding@Home and Rosetta@Home are examples of crowd-sourcing initiatives where the community is sharing computational resources, whereas RosettaCommons is an example of an initiative where a community is sharing a codebase for the development of computational algorithms. Foldit is another initiative where participants compete with each other in a protein folding video game to predict 3D structure. In the past few years, contact maps deep machine learning was introduced to the 3D structure prediction process, adding more information and increasing the accuracy of models significantly. In this review, we will take the reader in a journey of exploration from the beginnings to the most recent turnabouts, which have revolutionized the field of homology modeling. Moreover, we discuss the new trends emerging in this rapidly growing field.}
}
@article{CHAUDHARI201687,
title = {Traffic and mobility aware resource prediction using cognitive agent in mobile ad hoc networks},
journal = {Journal of Network and Computer Applications},
volume = {72},
pages = {87-103},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S108480451630131X},
author = {Shilpa Shashikant Chaudhari and Rajashekhar C. Biradar},
keywords = {Mobile ad hoc network, Wavelet neural network, Resource prediction, Cognitive agent, Belief desire intention architecture},
abstract = {Mobile Ad hoc NETwork (MANET) characteristics such as limited resources, shared channel, unpredictable mobility, improper load balancing, and variation in signal strength affect the routing of real-time multimedia data that requires Quality of Service (QoS) provisioning. Accurate prediction of the resource availability assists efficient resource allocation before the routing of such data. Most of the published work on resource prediction in MANET focuses on either bandwidth or energy without considering mobility effects. Adoption of intelligent software agent such as Cognitive Agent (CA) for the accurate resource prediction has a significant potential to solve the challenges of resource prediction in MANET. The intelligence provided in CA is similar to the logical thinking like a human for decision-making. The predominant CA architecture is the Belief-Desire-Intention (BDI) model, which performs the various tasks on behalf of the human user as an assistant. In this paper, we propose a CA-based Resource Prediction mechanism considering Mobility (CA-RPM) that predicts the resources using agents through the resource prediction agency consisting of one static agent, one cognitive agent and two mobile agents. Agents predict the traffic, mobility, buffer space, energy, and bandwidth effectively that is necessary for efficient resource allocation to support real-time and multimedia communications. The mobile agents collect and distribute network traffic statistics over MANET whereas a static agent collects the local statistics. CA creates static/mobile agent during the process of resource prediction. Initially, the designed time-series Wavelet Neural Networks (WNNs) predict traffic and mobility. Buffer space, energy, and bandwidth prediction use the predicted mobility and traffic. Simulation results show that the predicted resources closely match with the real values at the cost of little overheads due to the usage of agents. Simulation analysis of predicted traffic and mobility also shows the improvement compared to recurrent WNN in terms of mean square error, covariance, memory overhead, agent overhead and computation overhead. We plan to use these predicted resources for its efficient utilization in QoS routing is our future work.}
}
@article{JINADU20106753,
title = {Globalization & State Capacity in Africa},
journal = {Procedia - Social and Behavioral Sciences},
volume = {2},
number = {5},
pages = {6753-6763},
year = {2010},
note = {The Harmony of Civilization and Prosperity for All: Selected Papers of Beijing Forum(2004-2008)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S1877042810011559},
author = {L. Adele Jinadu},
abstract = {The paper examines the impact of globalization on state capacity in Africa. It problematizes globalization as a central determining factor in building the capable state in Africa. Globalization, although it requires typologizing and contextualizing or historicizing, is used to refer to a complex set of interconnected multi-linear, multifaceted and dialectical and still unfolding historical processes, propelled by the transnationalization of finance capital, in search of new markets, and the logic of capital accumulation, and typically characterized by structural differentiation and unequal functional integration between metropolitan and dependent or satellite nations, peoples and markets. State capacity is used neither narrowly nor exclusively as human and physical resource capacity-building or capacity-enhancement, nor limited to econometric or statistical computations of gross domestic product or national income data, though it includes and requires both. Its use assumes a democratic, open, participatory, and socially inclusive political system, as important conditions for expanding and consolidating state capacity on a sustainable basis in Africa. The paper situates the problem of globalization for state capacity in Africa in the wider Pan African context. Historically, globalization has divided and balkanized African countries, carving out political, economic and cultural spheres of influence, and weakening their ability to act collectively to defend their common interests. Collective action by African countries to confront the challenges and opportunities of globalization requires new governance structures to strengthen African regional economic communities, the African Union and the New Partnership for Africa's Development, along lines that will, by democratizing decision-making and public political processes within their member-states, enhance state capacity in various sectors. Attributing the problematic character of state capacity in Africa to the massive problem of the structural condition of the African state, the paper argues that this is notably and significantly due to the contradictions arising from globalization and the dependent character of the African state, reflecting the lingering or residual colonial inheritance of dependent political and socioeconomic and psycho-cultural structures, institutions and processes, which are at the heart of the problem of state capacity in Africa. They reflect the dialectics or antinomies, the age-old or historically deep contradictory push and pull of globalization and localization or indigenization in Africa. The paper suggests that, resolving these antinomies or contradictions, requires the following: (a) Transforming contemporary globalization, on the basis of mutuality, recognition and reciprocity, emphasizing new Afrocentric epistemological foundations for thinking about African and global development, global social justice, global income redistribution, economic and socio-cultural rights, global inclusion, and global democracy. (b) Emphasizing the use of “appropriate” technologies, to ‘fit’ the lifestyles and social organizations of local communities, growing from them, requiring less reliance on outside experts and using more local expertise. (c) Re-designing new Pan-African approaches to state capacity, to strengthen the collective capacity of African continental and regional institutions to respond to globalization, turning its negative implications for Africa into opportunities to reform globalization, and make it truly global. (d) Reconceptualizing democracy, on the basis of the positive role of culture in generating and institutionalizing new modes of self-reliant, and transparent democratic governance.}
}
@article{LIENERT1996845,
title = {LSD response in Eysenckian trait types identified by polypredictive CFA},
journal = {Personality and Individual Differences},
volume = {21},
number = {6},
pages = {845-850},
year = {1996},
issn = {0191-8869},
doi = {https://doi.org/10.1016/S0191-8869(96)00143-2},
url = {https://www.sciencedirect.com/science/article/pii/S0191886996001432},
author = {Gustav A. Lienert and Petra Netter},
abstract = {The four personality type combinations derived from high and low extraversion (E+E−) and high and low neuroticism (N+N−) have been related to response patterns composed of three symptoms (affective disturbances, thinking disturbances, and blackouts) scored as present (+) or absent (−) after a single oral dose of the hallucinogenic drug LSD-25. Hypotheses for expected response patterns for each personality group were derived from a data set obtained by Kohnen and Lienert (1987). Significance of associations was tested by two strategies of polyprediction configural frequency analysis (CFA): multiple uniprediction and biprediction CFA. Both strategies yielded a significant hyperpresentation of all three symptoms present in E+N+ (hysterics), merely thinking disorders in dysthymics (E−N+), merely affective symptoms in E+N− (stable extraverts), and merely blackouts in N−E− (stable introverts). Authors tried to relate these symptoms to Kretschmer's temperament types and could afterwards show by a chessboard modification of prediction CFA, that by applying two combined hypotheses for two personality types each, the significance of the predicted associations could be increased.}
}
@article{REIHLEN2013706,
title = {Uncertainty, pluralism, and the knowledge-based theory of the firm: From J.-C. Spender’s contribution to a socio-cognitive approach},
journal = {European Management Journal},
volume = {31},
number = {6},
pages = {706-716},
year = {2013},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2013.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0263237313001011},
author = {Markus Reihlen and Torsten Ringberg},
keywords = {Knowledge-based approach, Theory of the firm, Knowledge transfer, Social constructionism, Tacit knowledge, Socio-cognitive theory, Intuition, Mental models},
abstract = {J.-C. Spender’s award-winning, knowledge-based theory of the firm is based on four premises: (1) The firm can be sufficiently understood as a system of knowledge, (2) explicit and implicit knowing can be clearly dissociated, (3) organizations are conceived as cognizing entities, and (4) intuition shaped by shared cultural practices is a superior source of managerial knowledge. This line of reasoning represents a social constructionist view of the enactment, transfer, and storage of knowledge according to which managerial knowledge is largely tacitly shaped by industry recipes and the firm’s socio-cultural conventions and other social processes. Although comprehensive in scope, we argue that a knowledge-based theory of the firm needs to integrate a cognitivist approach that includes the synergetic production of tacit and explicit knowledge, the role of reflective thinking in resolving strategic uncertainties, and the interaction between the individual and the social. This socio-cognitive theory of the firm posits that sustained competitive advantage of a firm is founded on the ability to align knowledge internally within the firm as well as externally with its stakeholders through the individual sense-making of feedback from other individuals.}
}
@article{BOSCHETTI201671,
title = {Modelling and attitudes towards the future},
journal = {Ecological Modelling},
volume = {322},
pages = {71-81},
year = {2016},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2015.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304380015005311},
author = {Fabio Boschetti and Iain Walker and Jennifer Price},
keywords = {Forecasting, Futures Studies, Ecological modelling, Natural resource management, Cognitive science},
abstract = {The outputs of ecological models often need to be projected several years, or decades, into the future. The psychological literature tells us that stakeholders rarely think of such a distant future and when they do, they employ cognitive styles different from the ones commonly used for planning and decision making, which the ecological models are designed to facilitate. This may affect the reception of modelling efforts in several ways. Stakeholders may question the very purpose of trying to say anything meaningful about such a distant future; may consider model outputs as irrelevant to planning; or may provide emotional, often unconscious, responses motivated by deeply held fears and aspirations. Modellers too may display some of these behaviours. Here, we review the relevant literature and describe a questionnaire a modeller could use to explore these issues within a stakeholder group. We also report an experiment which shows how the very act of answering the questionnaire can significantly change the perception of future time horizon and future concerns and discuss the possible implications for modelling projects.}
}
@article{RENNA2023104420,
title = {A randomized controlled trial comparing two doses of emotion regulation therapy: Preliminary evidence that gains in attentional and metacognitive regulation reduce worry, rumination, and distress},
journal = {Behaviour Research and Therapy},
volume = {170},
pages = {104420},
year = {2023},
issn = {0005-7967},
doi = {https://doi.org/10.1016/j.brat.2023.104420},
url = {https://www.sciencedirect.com/science/article/pii/S0005796723001687},
author = {Megan E. Renna and Phillip E. Spaeth and Jean M. Quintero and Mia S. O'Toole and Christina F. Sandman and David M. Fresco and Douglas S. Mennin},
keywords = {Emotion regulation, Randomized controlled trial, Distress, Anxiety, Depression},
abstract = {Background
Emotion regulation therapy (ERT) promotes resilience in distress disorders by strengthening attentional and metacognitive capacities. Regulation skills are presented with the goal of ameliorating the perseverative negative thinking (PNT) that characterizes these disorders. This study tested ERT in a randomized controlled trial comparing the effectiveness of 16-session (ERT16) versus 8-session (ERT8) doses.
Method
Patients (N = 72) endorsing elevated worry and/or rumination and meeting diagnostic criteria for a distress disorder were randomized to ERT8 or ERT16. PNT, anxiety/depressive symptoms, functioning/quality of life, and treatment mechanisms (attention shifting, attention focusing, decentering, reappraisal) were measured at pre, mid, and post treatment. Clinical symptom severity was also assigned via diagnostic interview at each timepoint.
Results
ERT produced significant improvements across outcomes. ERT16 showed an advantage over ERT8 for distress disorder severity, worry, rumination, and attention shifting from pre-post treatment. Changes in ERT treatment mechanisms mediated changes in clinical improvement.
Conclusion
These findings provide evidence of the effectiveness of two doses of ERT in reducing PNT and distress through improvements in regulation skills.
Clinicaltrials.gov identifier
NCT04060940.}
}
@article{TRONCOSOGARCIA2023108387,
title = {Explainable hybrid deep learning and Coronavirus Optimization Algorithm for improving evapotranspiration forecasting},
journal = {Computers and Electronics in Agriculture},
volume = {215},
pages = {108387},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108387},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923007755},
author = {A.R. Troncoso-García and I.S. Brito and A. Troncoso and F. Martínez-Álvarez},
keywords = {XAI, Deep learning, Evapotranspiration forecasting, Hyperparameter optimization},
abstract = {Reference evapotranspiration is a critical hydrological measurement closely associated with agriculture. Accurate forecasting is vital in effective water management and crop planning in sustainable agriculture. In this study, the future values of reference evapotranspiration are forecasted by applying a recurrent long short-term memory neural network optimized using the Coronavirus Optimization Algorithm, a novel bioinspired metaheuristic based on the spread of COVID-19. The input data is sourced from the Sistema Agrometeorológico para a Gestão da Rega no Alentejo, in Portugal, with meteorological data such as air temperature or wind speed. Several baseline models are applied to the same problem to facilitate comparisons, including support vector machines, multi-layer perceptron, Lasso and decision tree. The results demonstrate the successful forecasting performance of the proposed model and its potential in this field. In turn, to gain deeper insights into the model’s inner workings, the SHapley Additive exPlanation tool is applied for explainability. Consequently, the study identifies the most relevant variables for reference evapotranspiration forecasting, including previously measured evapotranspiration values. Additionally, a univariable model is tested using historic evapotranspiration values as input, offering a comparable performance with a considerable reduction of computational time.}
}
@article{VANDERVERT2003159,
title = {How working memory and cognitive modeling functions of the cerebellum contribute to discoveries in mathematics},
journal = {New Ideas in Psychology},
volume = {21},
number = {2},
pages = {159-175},
year = {2003},
issn = {0732-118X},
doi = {https://doi.org/10.1016/S0732-118X(03)00012-6},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X03000126},
author = {Larry Vandervert},
keywords = {Einstein, Cerebellum, Intuition, Mathematics, Mental models, Working memory},
abstract = {A theory of how connections between working memory and cognitive functions of the cerebellum lead to mathematical discovery is presented. It is proposed that (a) patterns of repetitious working memory processing are learned in the cerebellum, and (b) when these cerebellar patterns are subsequently fed back to control processing in working memory, they are learned in visuospatial imagery and language as the concepts and axioms that underlie mathematical discovery. Paralleling Einstein's description of “thinking,” a working memory/cerebellar model of mathematical intuition is presented. It is concluded that the collaboration of the cerebellum and working memory constructs the only fundamental patterns (mathematics) of the joint framework that binds our cognitive consciousness with the socially verifiable operational specification of an external world.}
}
@article{MAXVILLE20111953,
title = {eScience: Building our Body of Knowledge},
journal = {Procedia Computer Science},
volume = {4},
pages = {1953-1963},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.213},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911002717},
author = {Valerie Maxville},
abstract = {This paper describes the need for an eScience BoK, particularly as a resource for educators. eScience is a term representing the computational technology and techniques utilised when undertaking research. As eScience matures, stakeholders, and particularly educators, can benefit from the clarity that a defined Body of Knowledge (BOK) can provide. The BOK would require domain-specific and technological aspects to be addressed. This paper describes a framework for a prototype BOK for eScience and discusses how the BOK can be used as a tool to drive education, outreach and infrastructure planning.}
}
@incollection{BAKER2023209,
title = {From capacity to ability to automation: “Western” conceptions of the figure of man and ableist subjectivities},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {209-218},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.12005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305120056},
author = {Bernadette Baker},
keywords = {Ableist subjectivities, Wynter, Colonialism, Humanism, Locke, Gall, Artificial intelligence (AI)},
abstract = {This chapter analyzes the shifting construct of ableist subjectivities that lie at the heart of a modernity-colonialism-racialization vortex and that were entangled with humanism's rise. Drawing on and building on the work of Sylvia Wynter, it examines how a “figure of Man” in three different but related iterations helped shape ontological hierarchies and violent inclusions/exclusions. It illustrates these moves via whitestream scholarship that came to dominate certain geopolitical locales from the 1600s, 1800s, and 2000s and that subsequently spread. From discourses of capacity (tutoring children), to ability (compulsory schooling), to automation (systems theory and computational superintelligence), the figure of Man not only overrepresents for “the human” but also puts in jeopardy all lives and ways of being beyond its exclusive borders. The questions that remain for education exceed standard policy debates about school reform, inclusive schooling, or evaluation, pointing instead toward a wider planetary context, existential issues, and power relations that sit within the tensions between “Man's” exclusivity, “the human's” idiosyncracies and primacy, and the potential rewriting/erasure of both via new technologies.}
}
@article{DIMARCO2020101290,
title = {(re)Producing mtEve},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {83},
pages = {101290},
year = {2020},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2020.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1369848620300303},
author = {Marina DiMarco},
abstract = {In their 1987 Nature publication, “Mitochondrial DNA and Human Evolution,” Rebecca Cann, Mark Stoneking, and Allan C. Wilson gave a new reconstruction of human evolution on the basis of differences in mitochondrial DNA among contemporary human populations. This phylogeny included an African common ancestor for all human mitochondrial DNA (mtDNA) lineages, and Cann et al.’s reconstruction became known as the “Out of Africa” hypothesis. Since mtDNA is inherited exclusively through the maternal line, the common ancestor who was first branded African Eve later became known as Mitochondrial Eve (mtEve, for short). In this paper, I show that mtEve was not a single, successful, or purely scientific discovery. Instead, she was produced many times and in many ways, each of which informed the next. Importantly, though Wilson and colleagues heralded mitochondrial DNA as a source of certainty, objectivity, and consensus for evolutionary inference, their productions of Mitochondrial Eve depended as much on popular assumptions about the certainty of maternal inheritance as they did on new molecular and computational tools. This recognition lets us reevaluate the complex consequences of these productions, which, like mtEve herself, could not be confined to a purely social, material, or scientific dimension.}
}
@article{SALAMATI2014283,
title = {Personal Wellness: Complex and Elusive Product and Distributed Self-services},
journal = {Procedia CIRP},
volume = {16},
pages = {283-288},
year = {2014},
note = {Product Services Systems and Value Creation. Proceedings of the 6th CIRP Conference on Industrial Product-Service Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2014.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S2212827114001310},
author = {Farzaneh Salamati and Zbigniew J. Pasek},
keywords = {Consumer-personalized medicine, Quantified self-tracking, Health social networks},
abstract = {In many countries across the world a universal issue of growing concern is increasing demand for health services and corresponding escalating costs. While there are many reasons for these two trends, reasonable solutions are nowhere in sight and a subject of heated debates. One potential source of relief for the health care systems is to shift some (if not majority – but in long term) of responsibilities to patients themselves. To do so effectively, however, better definition of personal well-being is needed, supported by medical knowledge transfer to the consumer and creation of some personal health management tools. Service engineering concepts, such as service package, are useful in decoupling all elements needed to develop an infrastructure in support of wellness as a core product and addressed by variety of limited-focus services. This paper reviews the emerging health care paradigms, in particular health care networks, consumer-personalized medicine and quantified self-tracking. With the Quantified Self movement on the rise for the past several years and a corresponding growth in offering of tools for variety of personal data collection (both hardware- and software-based), the obvious question arises how effective they are and what impact they actually have. The discussion also addresses the question whether it is possible to reframe the personal health issues by applying both design thinking and service engineering approaches aimed at individual's own well-being.}
}
@article{MOTSA2023116912,
title = {A data-driven, machine learning scheme used to predict the structural response of masonry arches},
journal = {Engineering Structures},
volume = {296},
pages = {116912},
year = {2023},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2023.116912},
url = {https://www.sciencedirect.com/science/article/pii/S0141029623013275},
author = {Siphesihle Mpho Motsa and Georgios Ε. Stavroulakis and Georgios Α. Drosopoulos},
keywords = {FEM, Machine Learning, Artificial Neural Network, Multi-hinge failure, Damage Prediction, Masonry Arches, Data-driven Mechanics, Digital Twin},
abstract = {A data-driven methodology is proposed, for the investigation of the ultimate response of masonry arches. Aiming to evaluate their structural response in a computationally efficient framework, machine learning metamodels, in the form of artificial neural networks, are adopted. Datasets are numerically built, integrating Matlab, Python and commercial finite element software. Heyman’s assumptions are adopted within non-linear finite element analysis, incorporating contact-friction laws between adjacent stones, to capture failure in the arch. The artificial neural networks are trained, validated, and tested using the least square minimization technique. It is shown that the proposed scheme can be used to provide a fast and accurate prediction of the deformed geometry, the collapse mechanism and the ultimate load. Cases studies demonstrate the efficiency of the method in random, new arch geometries. Relevant Matlab/Python scripts and datasets are provided. The method can be extended towards structural health monitoring and the concept of digital twin.}
}
@article{REINOSOCARVALHO2020389,
title = {A sprinkle of emotions vs a pinch of crossmodality: Towards globally meaningful sonic seasoning strategies for enhanced multisensory tasting experiences},
journal = {Journal of Business Research},
volume = {117},
pages = {389-399},
year = {2020},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2020.04.055},
url = {https://www.sciencedirect.com/science/article/pii/S0148296320302800},
author = {Felipe Reinoso-Carvalho and Laura Gunn and German Molina and Takuji Narumi and Charles Spence and Yuji Suzuki and Enrique {ter Horst} and Johan Wagemans},
keywords = {Crossmodal, Emotions, Flavors, Multisensory, Music, Purchase intention},
abstract = {We report a study designed to determine the most efficient means of pursuing sonic seasoning in international marketing. For the first time, music chosen to trigger specific emotional responses was directly and cross-culturally compared with music chosen as crossmodally congruent with specific taste/flavors (the latter usually referred to as ‘sonic seasoning’). The effects triggered by ‘emotional’ music were more prominent than those triggered by ‘crossmodally-corresponding’ music. Specifically, chocolate was liked more, rated as sweeter, and the purchase intent was higher, when tasted while listening to music that conveyed positive, as compared to negative, emotion. By contrast, the same chocolate was mostly rated as tasting more bitter with the negative music, as compared to the positive music. Companies looking to use sonic seasoning in marketing strategies, should therefore principally aim at intelligently classifying music based on the likely emotions that they can trigger in their customers (at least when thinking globally).}
}
@article{MARKOVSKY202142,
title = {Behavioral systems theory in data-driven analysis, signal processing, and control},
journal = {Annual Reviews in Control},
volume = {52},
pages = {42-64},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000754},
author = {Ivan Markovsky and Florian Dörfler},
keywords = {Behavioral systems theory, Data-driven control, Missing data estimation, System identification},
abstract = {The behavioral approach to systems theory, put forward 40 years ago by Jan C. Willems, takes a representation-free perspective of a dynamical system as a set of trajectories. Till recently, it was an unorthodox niche of research but has gained renewed interest for the newly emerged data-driven paradigm, for which it is uniquely suited due to the representation-free perspective paired with recently developed computational methods. A result derived in the behavioral setting that became known as the fundamental lemma started a new class of subspace-type data-driven methods. The fundamental lemma gives conditions for a non-parametric representation of a linear time-invariant system by the image of a Hankel matrix constructed from raw time series data. This paper reviews the fundamental lemma, its generalizations, and related data-driven analysis, signal processing, and control methods. A prototypical signal processing problem, reviewed in the paper, is missing data estimation. It includes simulation, state estimation, and output tracking control as special cases. The direct data-driven control methods using the fundamental lemma and the non-parametric representation are loosely classified as implicit and explicit approaches. Representative examples are data-enabled predictive control (an implicit method) and data-driven linear quadratic regulation (an explicit method). These methods are equally amenable to certainty-equivalence as well as to robust control. Emphasis is put on the robustness of the methods under noise. The methods allow for theoretical certification, they are computationally tractable, in comparison with machine learning methods require small amount of data, and are robustly implementable in real-time on complex physical systems.}
}
@incollection{ODENBAUGH2011421,
title = {Complex Ecological Systems},
editor = {Cliff Hooker},
booktitle = {Philosophy of Complex Systems},
publisher = {North-Holland},
address = {Amsterdam},
pages = {421-439},
year = {2011},
volume = {10},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-52076-0.50015-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444520760500158},
author = {Jay Odenbaugh},
abstract = {Publisher Summary
This chapter considers some of the ways in which nonlinear dynamics is changing the science of ecology. Specifically, it considers a bit of history; namely, debates over the stability of populations and communities in population and community ecology. Further, it explores arguments over population regulation in population ecology and the debate over diversity-complexity-stability in community ecology. This serves to highlight how ecological systems have been evaluated with the tools and assumptions of linear dynamical systems. Second, it turns to some conceptual issues. That is, what different concepts of stability are at work in ecology. Additionally, it provides a taxonomy of these concepts and how they are related to one another. Unfortunately, many of these concepts are mostly applicable when thinking of linear systems. As an example of nonlinear dynamics in ecology, it considers the case of deterministic chaos. Using very simple discrete difference equations suited for insect populations, for example, one can see the characteristic of sensitivity to initial conditions. Finally, it discusses the impact of complex systems analysis on issues in and around ecology. Specifically, it examines the rise of “resilience thinking” and debates over ecological laws as examples of how nonlinear dynamics is challenging ecological theory and practice.}
}
@article{JIANG2015154,
title = {Defining least community as a homogeneous group in complex networks},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {428},
pages = {154-160},
year = {2015},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2015.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0378437115001326},
author = {Bin Jiang and Ding Ma},
keywords = {Head/tail breaks, ht-index, Scaling, k-means, Natural breaks, Classification},
abstract = {This paper introduces a new concept of least community that is as homogeneous as a random graph, and develops a new community detection algorithm from the perspective of homogeneity or heterogeneity. Based on this concept, we adopt head/tail breaks–a newly developed classification scheme for data with a heavy-tailed distribution–and rely on edge betweenness given its heavy-tailed distribution to iteratively partition a network into many heterogeneous and homogeneous communities. Surprisingly, the derived communities for any self-organized and/or self-evolved large networks demonstrate very striking power laws, implying that there are far more small communities than large ones. This notion of far more small things than large ones constitutes a new fundamental way of thinking for community detection.}
}
@article{HALKOS2017140,
title = {Climate change effects and their interactions: An analysis aiming at policy implications},
journal = {Economic Analysis and Policy},
volume = {53},
pages = {140-146},
year = {2017},
issn = {0313-5926},
doi = {https://doi.org/10.1016/j.eap.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S031359261630217X},
author = {George E. Halkos and Kyriaki D. Tsilika},
keywords = {Graph theory, Node centrality, Mathematica, Climate related factors, Environmental economics computation},
abstract = {In this study we provide a computerized graph structure for synthesizing and displaying the data on a region’s ecosystem-economic system. By applying Mathematica-based graph modeling we create a causal network of the synergistic impact mechanism among certain climate related factors. Our computational approach identifies a climate factor that affects most immediately or most strongly the others. Important factors are indicated through the use of graph theoretical tools. Our graph-based approach and its computational aspects allow for factor ranking(s) according to their importance to the network both numerically and visually, for certain settlement types. Our contribution provides quantitative estimates of impacts and adaptation potentials of five potential effects of climate change (migration, flooding-landslides-fire, air and water pollution, human health and energy-water-other resources) which play a substantial role at the synergistic impact mechanism. By using graph visualization techniques, the structure of the synergistic impact mechanism is self-evident. Specifically, graph layouts are created to detect i) the causal relationships of the synergistic mechanism under study ii) the most influential factor(s) in the synergistic mechanism and iii) classify the factor’s roles (based on the degree of their impact) within the coping mechanism. Highlighting graph elements let information for policy implications stand out.}
}
@article{YIN2024110392,
title = {Embrace sustainable AI: Dynamic data subset selection for image classification},
journal = {Pattern Recognition},
volume = {151},
pages = {110392},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110392},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324001432},
author = {Zimo Yin and Jian Pu and Ru Wan and Xiangyang Xue},
keywords = {Data selection, Dynamic subset selection, Weighted sampling, Class distribution, Training efficiency},
abstract = {Data selection is commonly used to reduce costs and energy usage by training on a subset of available data. However, determining the appropriate subset size requires extensive dataset knowledge and experimentation, limiting transferability. Varying the validation set also produces unstable results and wastes computational resources. In this paper, we propose a data selection method for dynamically determining subset ratios based on model performance using only a training set. The data search space is narrowed through weighted sampling, leveraging statistical selection patterns. Parallel analysis of class distributions identifies the most representative samples with high selection potential. Extensive experiments validate our approach and demonstrate improved training efficiency. Our method speeds up various subset ratios by up to 2.2x on CIFAR-10, 1.9x on CIFAR-100, 2.0x on TinyImageNet, and 2.3x on ImageNet with negligible accuracy drops.}
}
@article{PROCTOR2021142852,
title = {Gateway to the perspectives of the Food-Energy-Water nexus},
journal = {Science of The Total Environment},
volume = {764},
pages = {142852},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.142852},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720363828},
author = {Kyle Proctor and Seyed M.H. Tabatabaie and Ganti S. Murthy},
keywords = {Food-energy–water nexus, Water security, Life cycle assessment, Problem archetype, Resource governance, Systems thinking},
abstract = {The Food-Energy–Water (FEW) nexus has been promoted as a tool for improving food, energy, and water resource security via an interdisciplinary approach that acknowledges the inherent synergies and tradeoffs involved in managing these resources. Over the past decade discussion of the nexus has increased rapidly, along with research funding and output. However, because the nexus encompasses so many different disciplines, researchers engage with and study the nexus from differing perspectives with distinct motivations and analytical methodologies. Understanding these motivations is critical to understanding the value of a given work. This paper first uses a narrative review to identify the motivations and toolsets of five key perspectives used to view the nexus, including: ecosystem health, waste management, public and private institutional change, stakeholder trust, and the learning process. Then, a systematic review is conducted to examine how publication trends have changed over the past decade, both generally and for each of these perspectives. The Food-Energy-Water nexus is not the first systems-based approach for addressing resource management and critiques of the nexus as a “Buzzword” or simply a reinvention of previous systems are growing in the literature. Challenging authors to explicitly define the role and motivations of their research within the broader category of the FEW nexus can improve the actionability of the research, better allow researchers to build from each other's work, and help reduce the ambiguity surrounding the nexus.}
}
@article{YAHIAOUI20243958,
title = {Two parallel expansions for improving supersonic axisymmetric nozzle performance},
journal = {Advances in Space Research},
volume = {74},
number = {8},
pages = {3958-3982},
year = {2024},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2024.06.066},
url = {https://www.sciencedirect.com/science/article/pii/S0273117724006562},
author = {Toufik Yahiaoui},
keywords = {MLN, BPN, DEN, HT, MOC, Error computation},
abstract = {The aim of this work is to develop a numerical computation program allowing designing new contours of a supersonic axisymmetric nozzle having two expansions at the throat, named by DEN (Dual Expansion Nozzle). This new nozzle gives a uniform and parallel flow at the exit section, to improve considerably the performances compared to the conventional Minimum Length Nozzle (MLN), and the Best Performances Nozzle (BPN). The present nozzle has a two unknowns external and central body curved walls. Each of them is started by an initial expansion angle to give a uniform and horizontal flow at the exit section. Two others transition regions are calculated in parallel with the contours points to give the desired exit Mach number. The walls are determined point by point by the High Temperature Method of Characteristics (HT MOC) model. The resolution of the four compatibility and characteristics equations is done numerically by the finite difference predictor corrector algorithm. The validation of the results is controlled by the convergence of the calculated critical sections ratio to that given by the theory. The design depends on four parameters, where MLN and BPN become special cases of DEN. A comparison is made with MLN, since it is currently used in the aerospace propulsion and with BPN aiming to improve their performances. The comparison is made for the same critical mass flow rate. The results demonstrate a remarkable reduction up of 45 %, and 52 % in the mass of DEN when the exit Mach number ME = 3.00 and the stagnation temperature T0 = 2000 K. The application is made for air and for future aerospace missiles in order to improve their trajectory parameters. The chosen example demonstrates an improvement of 13 % and 16 % on the missile range compared, respectively to MLN, and BPN.}
}
@article{KARTHIK2022243,
title = {Prognostic Kalman Filter Based Bayesian Learning Model for Data Accuracy Prediction},
journal = {Computers, Materials and Continua},
volume = {72},
number = {1},
pages = {243-259},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.023864},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822010840},
author = {S. Karthik and Robin Singh Bhadoria and Jeong Gon Lee and Arun Kumar Sivaraman and Sovan Samanta and A. Balasundaram and Brijesh Kumar Chaurasia and S. Ashokkumar},
keywords = {Bayesian learning model, kalman filter, machine learning, data accuracy prediction},
abstract = {Data is always a crucial issue of concern especially during its prediction and computation in digital revolution. This paper exactly helps in providing efficient learning mechanism for accurate predictability and reducing redundant data communication. It also discusses the Bayesian analysis that finds the conditional probability of at least two parametric based predictions for the data. The paper presents a method for improving the performance of Bayesian classification using the combination of Kalman Filter and K-means. The method is applied on a small dataset just for establishing the fact that the proposed algorithm can reduce the time for computing the clusters from data. The proposed Bayesian learning probabilistic model is used to check the statistical noise and other inaccuracies using unknown variables. This scenario is being implemented using efficient machine learning algorithm to perpetuate the Bayesian probabilistic approach. It also demonstrates the generative function for Kalman-filer based prediction model and its observations. This paper implements the algorithm using open source platform of Python and efficiently integrates all different modules to piece of code via Common Platform Enumeration (CPE) for Python.}
}
@article{BEJINES2023108405,
title = {Counting semicopulas on finite structures},
journal = {Fuzzy Sets and Systems},
volume = {462},
pages = {108405},
year = {2023},
note = {Aggregation operations (186 p.)},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2022.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0165011422004122},
author = {C. Bejines and M. Ojeda-Hernández},
keywords = {Semicopula, Fuzzy Logic, Finite plane partition, Discrete Mathematics},
abstract = {Semicopulas are the operators chosen to model conjunction in the fuzzy/many-valued logics. In fact, a special kind of semicopula, called t-norm, is widely used in many applications of logic to engineering, computer science and fuzzy systems. The main result of this paper is the computation of the exact number of semicopulas that can be defined on a finite chain in terms of its length. The final formula is achieved via relating semicopulas with finite plane partitions.}
}
@article{DEBRUIJNSMOLDERS2024e39439,
title = {Effective Student Engagement with Blended Learning A systematic review},
journal = {Heliyon},
pages = {e39439},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e39439},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024154709},
author = {M. {De Bruijn-Smolders} and F.R. Prinsen},
keywords = {blended learning, student engagement, learning outcomes, systematic review},
abstract = {Although student engagement is known to promote learning outcomes in higher education, what elements of blended learning designs impact effective student engagement and hereby learning outcomes, has not been clarified yet. Hence, it is unknown how to engage students with blended learning in an effective manner. The current study breaks down student engagement into four dimensions (academic, behavioral, cognitive, and affective), and reviews the evidence regarding blended learning that engages students effectively, whether this is academically, personally, socially, or with regard to citizenship. The studies reviewed (k = 15, N = 1,428) overall asserted that all blended learning interventions investigated had a moderate to high impact on student engagement and on learning outcomes. This review, a summary and insight into the evidence, is important for the field’s understanding as well as for professionals in higher education: for lecturers and policy makers who want to introduce and monitor blended learning as a means to promote both student engagement and their learning outcomes in higher education. Further research is required to increase our knowledge of how blended learning impacts both multi-dimensional constructs: student engagement and learning outcomes.}
}
@article{CAFFERATA2023106879,
title = {Financial fragility and credit risk: A simulation model},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {116},
pages = {106879},
year = {2023},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2022.106879},
url = {https://www.sciencedirect.com/science/article/pii/S1007570422003665},
author = {Alessia Cafferata and Simone Casellina and Simone Landini and Mariacristina Uberti},
keywords = {Credit risk, Financial instability, Minsky, Agent-based model},
abstract = {Financial and economic crises are not always the same. It is important to understand why some episodes of crisis generate prolonged and systemic recessions. Developing the Financial Instability Hypothesis, Hyman Minsky introduced the idea that in periods of stability, financial actors tend to increase their risk exposure, moving from a stable hedge-dominated structure to an unstable one, characterized by speculative and ultra-speculative (Ponzi) financial positions: hence, stability turns out being destabilizing. Starting from the three different relationships introduced by Minsky (income–debt–hedge, speculative and Ponzi) for financial units, we involve a simple partial equilibrium agent-based model in which firms, the banking sector, the real and financial sides of the economy, interact. This theoretic framework is used as computational laboratory to extend the migration rates open system modelling based on the E(ntry)–S(tay)–L(eave) processes by considering the economic system, the business cycle and with attention to so-called zombie-firms.}
}
@article{GIGERENZER200193,
title = {Content-blind norms, no norms, or good norms? A reply to Vranas},
journal = {Cognition},
volume = {81},
number = {1},
pages = {93-103},
year = {2001},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(00)00135-9},
url = {https://www.sciencedirect.com/science/article/pii/S0010027700001359},
author = {Gerd Gigerenzer},
keywords = {Reasoning, Probability, Norms, Rationality, Fallacy, Error},
abstract = {In the psychology of thinking, little thought is given to what constitutes good thinking. Instead, normative solutions to problems have been accepted at face value, thereby determining what counts as a reasoning fallacy. I applaud Vranas (Cognition 76 (2000) 179) for thinking seriously about norms. I do, however, disagree with his attempt to provide post hoc justifications for supposed reasoning fallacies in terms of ‘content-neutral’ norms. Norms need to be constructed for a specific situation, not imposed upon it in a content-blind way. The reason is that content-blind norms disregard relevant structural properties of the given situation, including polysemy, reference classes, and sampling. I also show that content-blind norms can, unwittingly, lead to double standards: the norm in one problem is the fallacy in the next. The alternative to content-blind norms is not no norms, but rather carefully designed norms.}
}
@article{PIRES2024625,
title = {Selection of Naval Bases and Stations for submarines: a multimethodological approach},
journal = {Procedia Computer Science},
volume = {242},
pages = {625-632},
year = {2024},
note = {11th International Conference on Information Technology and Quantitative Management (ITQM 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.08.119},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924018386},
author = {Tullio Pires and Celio Manso {de Azevedo Junior} and Mateus Vanzetta and Marcos {dos Santos} and Carlos Francisco {Simões Gomes}},
keywords = {Submarines, Naval Base, Multicriteria, MPSI-MARA, SCA},
abstract = {With the PROSUB program, the Brazilian Navy (MB) has been renewing its feet of submarines. However, this is not a movement that is exclusively Brazilian. With the worsening of crises around the world, many countries are in the process of expanding their armed forces, and coastal nations, in particular, are paying significant attention to their submarine weapons. However, as it is not only convenient to acquire submarines but also to operate them, it is necessary to define from where they will do so. Given the above, this current work aims to present a framework with a multimethodological focus, that is, presenting a combined use of the problem structuring method (PSM) Strategic Choice Approach with the multicriteria method MPSI-MARA. As a result, the ordering of some points along the Brazilian coast, made non-specific, is presented as a suggestion for the implementation of new Submarine Bases and/or Naval Support Stations.}
}
@article{LI2023297,
title = {BalanceHRNet: An effective network for bottom-up human pose estimation},
journal = {Neural Networks},
volume = {161},
pages = {297-305},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.01.036},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023000485},
author = {Yaoping Li and Shuangcheng Jia and Qian Li},
keywords = {Multi-branch structure, Fusion, Balance structure, Branch attention},
abstract = {In the study of human pose estimation, which is widely used in safety and sports scenes, the performance of deep learning methods is greatly reduced in high overlap rate and crowded scenes. Therefore, we propose a bottom-up model, called BalanceHRNet, which is based on balanced high-resolution module and a new branch attention module. BalanceHRNet draws on the multi-branch structure and fusion method of a popular model HigherHRNet. And our model overcomes the shortcoming of HigherHRNet that cannot obtain a large enough receptive field. Specifically, through the connecting structure in balanced high-resolution module, we can connect almost all convolutional layers and obtain a sufficiently large receptive field. At the same time, the multi-resolution representation can be maintained due to the use of balanced high-resolution module, which enable our model to recognize objects with richer scales and obtain more complex semantics information. And for branch fusion method, we design branch attention to obtain the importance of different branches at different stages. Finally, our model improves the accuracy while ensuring a smaller amount of computation than HigherHRNet. The CrowdPose dataset is used as test dataset, and HigherHRNet, AlphaPose, OpenPose and so on are taken as comparison models. The AP measured by BalanceHRNet is 63.0%, increased by 3.1% compared to best model — HigherHRNet. We also demonstrate the effectiveness of our network through the COCO(2017) keypoint detection dataset. Compared with HigherHRNet-w32, the AP of our model is improved by 1.6%.}
}
@article{1987755,
title = {Computation of signatures of linear airgun arrays: Vaage, S. and B. Ursin, 1987. Geophys. Prospect., 35(3):281–287. SERES A/S, P.O. Box 1965, Moholtan, 7001 Trondheim, Norway},
journal = {Deep Sea Research Part B. Oceanographic Literature Review},
volume = {34},
number = {9},
pages = {755},
year = {1987},
issn = {0198-0254},
doi = {https://doi.org/10.1016/0198-0254(87)90164-6},
url = {https://www.sciencedirect.com/science/article/pii/0198025487901646}
}
@article{AHMED20201,
title = {A cognitive model to predict human interest in smart environments},
journal = {Computer Communications},
volume = {161},
pages = {1-9},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420306812},
author = {Tanveer Ahmed and Rishav Singh and Anil K. Pandey and Sanjay K. Singh},
keywords = {Cognition, Interest, Machine learning, Man Machine systems},
abstract = {Recently, the idea of smart cities has made several strides forward in literature. Work has hypothesize that the combination of Artificial Intelligence, Cloud Computing, and High powered computers will make technology more human-centric, even, the idea that smart cities will be able to understand the thought process of a human being seems very much likely today. This paper is along this line of thought. In particular, we try to present a method to model the cognitive state of human interest. This is done to take one more step towards the realization of a smart cognitive city. An approach which is Subjective–Objective in nature is presented to model the computation of activity inspired by interest. Based on activity, human latent state values are indirectly deduced. Inspiration is drawn from Physics and interest is modeled upon the Ornstein–Uhlenbeck (OU) process. Concepts of Adaptive filtering are used to formulate an evolving transformation function that automatically and adaptively models the conversion of interest into activity. Particle filter is employed to provide an elucidation which is computationally feasible. To validate the viability of the method, experimentation is performed with real datasets.}
}
@article{ALDULAIMY2024101272,
title = {The computing continuum: From IoT to the cloud},
journal = {Internet of Things},
volume = {27},
pages = {101272},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101272},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524002130},
author = {Auday Al-Dulaimy and Matthijs Jansen and Bjarne Johansson and Animesh Trivedi and Alexandru Iosup and Mohammad Ashjaei and Antonino Galletta and Dragi Kimovski and Radu Prodan and Konstantinos Tserpes and George Kousiouris and Chris Giannakos and Ivona Brandic and Nawfal Ali and André B. Bondi and Alessandro V. Papadopoulos},
keywords = {Computing continuum, Cloud computing, Fog computing, Edge computing, Mobile cloud computing, Multi-access edge computing, SDN, NFV, IoT, Use case, Reference architecture},
abstract = {In the era of the IoT revolution, applications are becoming ever more sophisticated and accompanied by diverse functional and non-functional requirements, including those related to computing resources and performance levels. Such requirements make the development and implementation of these applications complex and challenging. Computing models, such as cloud computing, can provide applications with on-demand computation and storage resources to meet their needs. Although cloud computing is a great enabler for IoT and endpoint devices, its limitations make it unsuitable to fulfill all design goals of novel applications and use cases. Instead of only relying on cloud computing, leveraging and integrating resources at different layers (like IoT, edge, and cloud) is necessary to form and utilize a computing continuum. The layers’ integration in the computing continuum offers a wide range of innovative services, but it introduces new challenges (e.g., monitoring performance and ensuring security) that need to be investigated. A better grasp and more profound understanding of the computing continuum can guide researchers and developers in tackling and overcoming such challenges. Thus, this paper provides a comprehensive and unified view of the computing continuum. The paper discusses computing models in general with a focus on cloud computing, the computing models that emerged beyond the cloud, and the communication technologies that enable computing in the continuum. In addition, two novel reference architectures are presented in this work: one for edge–cloud computing models and the other for edge–cloud communication technologies. We demonstrate real use cases from different application domains (like industry and science) to validate the proposed reference architectures, and we show how these use cases map onto the reference architectures. Finally, the paper highlights key points that express the authors’ vision about efficiently enabling and utilizing the computing continuum in the future.}
}
@article{GONZALEZRODRIGUEZ201827,
title = {Self-Organized Linguistic Systems: From traditional AI to bottom-up generative processes},
journal = {Futures},
volume = {103},
pages = {27-34},
year = {2018},
note = {Futures of Society: The Interactions Revolution},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302161},
author = {Diego Gonzalez-Rodriguez and Jose Rodolfo Hernandez-Carrion},
keywords = {Artificial intelligence, Self-organization, Emergence, Constructed languages, Conlangs, Agent-based modelling},
abstract = {This work seeks to explore the potential of bottom-up generative processes in the context of conlang production, aiming to describe the basis of a new field of research: Self-Organized Linguistic Systems or SOLS, specified under the perspective of both self-organized systems and constructed languages. SOLS approach provides a framework for the creation of self-generated artificial languages and may serve as a starting point for the development of context-dependent or domain-specific languages. It acknowledges that the development of conlangs can happen in artificial societies of simple agents, as the output of social interactions in computational simulations under the agent-based modelling paradigm. In the proposed initial SOLS model, automatic generation of lexicon takes place in the context of a digital environment with objects, actions and agents with embodied cognition through peer-to-peer interactions. Specifically, this paper exposes how SOLS can be developed with bi-dimensional games and simulations. An initial work has been done with the xmunch-atomspace and the SciArt simulator, which constitute the first implementations of both our knowledge representation toolbox and our bi-dimensional simulator of P2P Social Dynamics. Non-interactive agent-based SOLS can allow artificial agents to independently evolve emergent languages as part of their self-organizing or adaptation processes.}
}
@incollection{YE201842,
title = {1.05 - Open Data and Open Source GIS},
editor = {Bo Huang},
booktitle = {Comprehensive Geographic Information Systems},
publisher = {Elsevier},
address = {Oxford},
pages = {42-49},
year = {2018},
isbn = {978-0-12-804793-4},
doi = {https://doi.org/10.1016/B978-0-12-409548-9.09592-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780124095489095920},
author = {Xinyue Ye},
keywords = {Open data, Open GIS, Open source},
abstract = {The multiple dimensions and scales of emerging open data pose numerous challenges for the application and evaluation of public policies. At the same time, domain researchers have been relatively slow to adopt and implement new spatiotemporally explicit data analysis methods due to the availability of suitable data and the lack of extensible software packages, which becomes a major impediment to the promotion of spatiotemporal thinking and collaboration. In this regard, more attention to open data and open source geographic information system (GIS) is necessary. Free access to the data and source code allows the broader GIS and domain science communities to incorporate additional advances in theoretical perspectives and analytical methods, thus facilitating interdisciplinary collaboration of spatial science and education. A case study of comparative LISA time path is illustrated in the open source GIS context. Additionally, open source implementation of new methods can expedite comparative studies of geographical dynamics.}
}
@article{GIPPERT199015,
title = {Computational methods for determining protein structures from NMR data},
journal = {Biochemical Pharmacology},
volume = {40},
number = {1},
pages = {15-22},
year = {1990},
issn = {0006-2952},
doi = {https://doi.org/10.1016/0006-2952(90)90172-H},
url = {https://www.sciencedirect.com/science/article/pii/000629529090172H},
author = {Garry P. Gippert and Ping F. Yip and Peter E. Wright and David A. Case},
abstract = {The general procedures by which solution structures of proteins may be deduced from distance and angular constraints derived from NMR are reviewed, with an emphasis on practical aspects of the calculations. In addition, novel methods based on chemical shift calculations and on quantitative fits to nuclear Overhauser effect intensities are presented; these should provide improved understanding of the limits of our ability to simulate complex spectra, and may permit higher precision structures to be determined.}
}
@article{BENDER2024156,
title = {Dimension results for extremal-generic polynomial systems over complete toric varieties},
journal = {Journal of Algebra},
volume = {646},
pages = {156-182},
year = {2024},
issn = {0021-8693},
doi = {https://doi.org/10.1016/j.jalgebra.2024.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0021869324000553},
author = {Matías Bender and Pierre-Jean Spaenlehauer},
keywords = {Sparse polynomial systems, Toric varieties},
abstract = {We study polynomial systems with prescribed monomial supports in the Cox ring of a toric variety built from a complete polyhedral fan. We present combinatorial formulas for the dimension of their associated subvarieties under genericity assumptions on the coefficients of the polynomials. Using these formulas, we identify at which degrees generic systems in polytopal algebras form regular sequences. Our motivation comes from sparse elimination theory, where knowing the expected dimension of these subvarieties leads to specialized algorithms and to large speed-ups for solving sparse polynomial systems. As a special case, we classify the degrees at which regular sequences defined by weighted homogeneous polynomials can be found, answering an open question in the Gröbner bases literature. We also show that deciding whether a sparse system is generically a regular sequence in a polytopal algebra is hard from the point of view of theoretical computational complexity.}
}
@article{LIU2024,
title = {Water Quality System Informatics: An Emerging Inter-Discipline of Environmental Engineering},
journal = {Engineering},
year = {2024},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2024.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S2095809924002601},
author = {Hong Liu and Zhaoming Chen and Zhiwei Wang and Ming Xu and Yutao Wang and Jinju Geng and Fengjun Yin},
keywords = {Water quality system, Water quality system informatics, Environmental engineering, Emerging interdisciplinary, Research pattern},
abstract = {Water quality system informatics (WQSI) is an emerging field that employs cybernetics to collect and digitize data associated with water quality. It involves monitoring the physical, chemical, and biological processes that affect water quality and the ecological impacts and interconnections within water quality systems. WQSI integrates theories and methods from water quality engineering, information engineering, and system control theory, enabling the intelligent management and control of water quality. This integration revolutionizes the understanding and management of water quality systems with greater precision and higher resolution. WQSI is a new stage of development in environmental engineering that is driven by the digital age. This work explores the fundamental concepts, research topics, and methods of WQSI and its features and potential to promote disciplinary development. The innovation and development of WQSI are crucial for driving the digital and intelligent transformation of national industry patterns in China, positioning China at the forefront of environmental engineering and ecological environment research on a global scale.}
}
@article{LEE2019325,
title = {Improving process safety: What roles for Digitalization and Industry 4.0?},
journal = {Process Safety and Environmental Protection},
volume = {132},
pages = {325-339},
year = {2019},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2019.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0957582019317057},
author = {John Lee and Ian Cameron and Maureen Hassall},
keywords = {Process safety, Digital twin, Digitalization, Industry 4.0, Models, Life cycle, ISO15926},
abstract = {Process safety and risk management remain a significant challenge for the process and manufacturing industries. Digital systems have been applied over many decades to assist in process safety management throughout the lifecycle of a process plant. There has been much hype in recent years regarding Industry 4.0, digitalization and digital twins regarding the transformative potential that exists within these technologies to improve operational performance and reduce process safety accidents. In this article, a fundamental systems thinking approach is applied to the implementation of the digital twin within the process industries. The importance of having a standardized language and ontology, such as ISO15926, enables the use of reasoning engines and the ability to interconnect models and systems across the process and product lifecycle. We discuss use-cases and forms of the digital twin to improve safety within the process industries. A specific focus shows how an operator training simulator and its embedded dynamic models are applied within this environment. The article concludes with a summary of process safety related opportunities and threats associated with the application of digitalized dynamic models in industry.}
}
@article{CASAJUS202488,
title = {Random partitions, potential, value, and externalities},
journal = {Games and Economic Behavior},
volume = {147},
pages = {88-106},
year = {2024},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2024.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S089982562400085X},
author = {André Casajus and Yukihiko Funaki and Frank Huettner},
keywords = {Shapley value, Partition function form, Random partition, Restriction operator, Ewens distribution, Chinese restaurant process, Potential, Externalities, Null player, Expected accumulated worth},
abstract = {The Shapley value equals a player's contribution to the potential of a game. The potential is a most natural one-number summary of a game, which can be computed as the expected accumulated worth of a random partition of the players. This computation integrates the coalition formation of all players and readily extends to games with externalities. We investigate those potential functions for games with externalities that can be computed this way. It turns out that the potential that corresponds to the MPW solution introduced by Macho-Stadler et al. (2007, J. Econ. Theory 135, 339–356) is unique in the following sense. It is obtained as the expected accumulated worth of a random partition, it generalizes the potential for games without externalities, and it induces a solution that satisfies the null player property even in the presence of externalities.}
}
@incollection{VALLERO2025503,
title = {Chapter 19 - The future},
editor = {Daniel A. Vallero},
booktitle = {Fundamentals of Water Pollution},
publisher = {Elsevier},
pages = {503-504},
year = {2025},
isbn = {978-0-443-28987-3},
doi = {https://doi.org/10.1016/B978-0-443-28987-3.00014-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328987300014X},
author = {Daniel A. Vallero},
keywords = {Emerging water pollutants, Emerging treatment technologies, Environmental communications},
abstract = {Those chapter concludes the book with a discussion of some of the successes of water pollution controls and water supply, along with remaining challenges.}
}
@article{SPRUGNOLI201799,
title = {Neural correlates of Eureka moment},
journal = {Intelligence},
volume = {62},
pages = {99-118},
year = {2017},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2017.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0160289616302756},
author = {Giulia Sprugnoli and Simone Rossi and Alexandra Emmendorfer and Alessandro Rossi and Sook-Lei Liew and Elisa Tatti and Giorgio {di Lorenzo} and Alvaro Pascual-Leone and Emiliano Santarnecchi},
keywords = {Insight, , , Cognition, fMRI, EEG, ERPs, Non-invasive brain stimulation, Neuroenhancement, NIBS, Creativity},
abstract = {Insight processes that peak in “unpredictable moments of exceptional thinking” are often referred to as Aha! or Eureka moments. During insight, connections between previously unrelated concepts are made and new patterns arise at the perceptual level while new solutions to apparently insolvable problems suddenly emerge to consciousness. Given its unpredictable nature, the definition, and behavioral and neurophysiological measurement of insight problem solving represent a major challenge in contemporary cognitive neuroscience. Numerous attempts have been made, yet results show limited consistency across experimental approaches. Here we provide a comprehensive overview of available neuroscience of insight, including: i) a discussion about the theoretical definition of insight and an overview of the most widely accepted theoretical models, including those debating its relationship with creativity and intelligence; ii) an overview of available tasks used to investigate insight; iii) an ad-hoc quantitative meta-analysis of functional magnetic resonance imaging studies investigating the Eureka moment, using activation likelihood estimation maps; iv) a review of electroencephalographic evidence in the time and frequency domains, as well as v) an overview of the application of non-invasive brain stimulation techniques to causally assess the neurobiological basis of insight as well as enhance insight-related cognition.}
}
@article{PETRELLA2024139,
title = {The AI Future of Emergency Medicine},
journal = {Annals of Emergency Medicine},
volume = {84},
number = {2},
pages = {139-153},
year = {2024},
issn = {0196-0644},
doi = {https://doi.org/10.1016/j.annemergmed.2024.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S019606442400043X},
author = {Robert J. Petrella},
abstract = {In the coming years, artificial intelligence (AI) and machine learning will likely give rise to profound changes in the field of emergency medicine, and medicine more broadly. This article discusses these anticipated changes in terms of 3 overlapping yet distinct stages of AI development. It reviews some fundamental concepts in AI and explores their relation to clinical practice, with a focus on emergency medicine. In addition, it describes some of the applications of AI in disease diagnosis, prognosis, and treatment, as well as some of the practical issues that they raise, the barriers to their implementation, and some of the legal and regulatory challenges they create.}
}
@article{DOWLING201949,
title = {Interactive Visual Analytics for Sensemaking with Big Text},
journal = {Big Data Research},
volume = {16},
pages = {49-58},
year = {2019},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2019.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S2214579618302995},
author = {Michelle Dowling and Nathan Wycoff and Brian Mayer and John Wenskovitch and Scotland Leman and Leanna House and Nicholas Polys and Chris North and Peter Hauck},
keywords = {Text analytics, Big data, Visualization, Interactive visual analytics, Semantic interaction, Topic modeling},
abstract = {Analysts face many steep challenges when performing sensemaking tasks on collections of textual information larger than can be reasonably analyzed without computational assistance. To scale up such sensemaking tasks, new methods are needed to interactively integrate human cognitive sensemaking activity with machine learning. Towards that goal, we offer a human-in-the-loop computational model that mirrors the human sensemaking process, and consists of foraging and synthesis sub-processes. We model the synthesis loop as an interactive spatial projection and the foraging loop as an interactive relevance ranking combined with topic modeling. We combine these two components of the sensemaking process using semantic interaction such that the human's spatial synthesis actions are transformed into automated foraging and synthesis of new relevant information. Ultimately, the model's ability to forage as a result of the analyst's synthesis activities makes interacting with big text data easier and more efficient, thereby facilitating analysts' sensemaking ability. We discuss the interaction design and theory behind our interactive sensemaking model. The model is embodied in a novel visual analytics prototype called Cosmos in which analysts synthesize structure within the larger corpus by directly interacting with a reduced-dimensionality space to express relationships on a subset of data. We then demonstrate how Cosmos supports sensemaking tasks with a realistic scenario that investigates the affect of natural disasters in Adelaide, Australia in September 2016 using a database of over 30,000 news articles.}
}
@article{ALBABA20191,
title = {Modeling cyber-physical human systems via an interplay between reinforcement learning and game theory},
journal = {Annual Reviews in Control},
volume = {48},
pages = {1-21},
year = {2019},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2019.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1367578819301026},
author = {Berat Mert Albaba and Yildiray Yildiz},
keywords = {Cyber-physical human systems, Game theory, Reinforcement learning, Model validation},
abstract = {Predicting the outcomes of cyber-physical systems with multiple human interactions is a challenging problem. This article reviews a game theoretical approach to address this issue, where reinforcement learning is employed to predict the time-extended interaction dynamics. We explain that the most attractive feature of the method is proposing a computationally feasible approach to simultaneously model multiple humans as decision makers, instead of determining the decision dynamics of the intelligent agent of interest and forcing the others to obey certain kinematic and dynamic constraints imposed by the environment. We present two recent exploitations of the method to model (1) unmanned aircraft integration into the National Airspace System and (2) highway traffic. We conclude the article by providing ongoing and future work about employing, improving and validating the method. We also provide related open problems and research opportunities.}
}
@article{MEYER202013,
title = {Changing Design Education for the 21st Century},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {6},
number = {1},
pages = {13-49},
year = {2020},
note = {Design Education. Part I},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2019.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872620300046},
author = {Michael W. Meyer and Don Norman},
keywords = {Design education, Design-driven transformation, Design thinking, Design doing, Major societal challenges, Complex sociotechnical systems, DesignX},
abstract = {Designers are entrusted with increasingly complex and impactful challenges. However, the current system of design education does not always prepare students for these challenges. When we examine what and how our system teaches young designers, we discover that the most valuable elements of the designer’s perspective and process are seldom taught. Instead, some designers grow beyond their education through their experience working in industry, essentially learning by accident. Many design programs still maintain an insular perspective and an inefficient mechanism of tacit knowledge transfer. Meanwhile, skills for developing creative solutions to complex problems are increasingly essential. Organizations are starting to recognize that designers bring something special to this type of work, a rational belief based upon numerous studies that link commercial success to a design-driven approach. So, what are we to do? Other learned professions such as medicine, law, and business provide excellent advice and guidance embedded within their own histories of professionalization. In this article, we borrow from their experiences to recommend a course of action for design. It will not be easy: it will require a study group to make recommendations for a roster of design and educational practices that schools can use to build a curriculum that matches their goals and abilities. And then it will require a conscious effort to bootstrap the design profession toward both a robust practitioner community and an effective professoriate, capable together of fully realizing the value of design in the 21st century. In this article, we lay out that path.}
}
@article{FANOUS2023105658,
title = {Challenges and prospects of climate change impact assessment on mangrove environments through mathematical models},
journal = {Environmental Modelling & Software},
volume = {162},
pages = {105658},
year = {2023},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2023.105658},
url = {https://www.sciencedirect.com/science/article/pii/S1364815223000440},
author = {Majdi Fanous and Jonathan M. Eden and Renji Remesan and Alireza Daneshkhah},
keywords = {Mangrove environments, Climate change, Hydro-morphodynamic modelling, Adaptation policies, Machine learning, Data-driven modelling},
abstract = {The impacts of climate change, especially sea-level rise, are an increasing threat to the world’s coastal regions. Following recommendations made by the United Nations about the preservation of mangrove environments, particularly given their potential for effective natural defence against wave-driven hazards, a series of experiments have been conducted to quantify the ability of mangroves to counter climate change impacts. To date, these experiments have been limited by computational cost and inability to model multiple scenarios. With improved data quality and availability, machine learning has enormous potential to supplement, or even replace, existing numerical methods. This article presents both an outline of the importance of protecting mangrove environments and a review of methods currently used to quantify the capacity of mangroves to adapt to climate change impacts. In view of the limitations of existing numerical methods, the article also discusses the potential of machine learning as an efficient and effective alternative.}
}
@article{LIANG201291,
title = {Psychological-Physical Force Model for Bicycle Dynamics},
journal = {Journal of Transportation Systems Engineering and Information Technology},
volume = {12},
number = {2},
pages = {91-97},
year = {2012},
issn = {1570-6672},
doi = {https://doi.org/10.1016/S1570-6672(11)60197-9},
url = {https://www.sciencedirect.com/science/article/pii/S1570667211601979},
author = {Xiao LIANG and Baohua MAO and Qi XU},
keywords = {urban traffic, bicycle, micro behavior, dynamics, psychological-physical force model, interaction},
abstract = {The core challenge in modeling bicyclist behavior dynamics is how to tackle the interaction between the lateral and the longitudinal movements. Further the bicycle transportation could be considered as multi-particle self-driven system. The combined dynamic model, psychological-physical force model (PPFM) and trajectories choice model (TCM), is proposed as a multi agent model to describe bicycle microscopic behavior dynamics. The PPFM is a continuous force model, which obeyed to the Newton's second law. By introducing the trajectories choice behavior in the tactical level, the TCM is modeled to describe the ability to individual autonomous thinking and to respond to changes ambient conditions for predefined behavior tank. Through designing computational experiments, the simulation data is collected to calibrate and validate the models. The simulation results show that the fundamental diagram obtained by simulation is dovetail into the empirical data. The PPFM is capable of describing the nonlinear interaction between individuals and the microscopic behavior of the proposed bicycle dynamic model with reasonable traffic.
摘要
自行车微观行为动力学建模的关键是如何描述自行车横向和纵向的运动关系。本文将自行车交通系统视作具有自主性的多粒子系统，提出了由心理生理力模型和轨迹选择模型构成的、描述自行车微观行为动力学特性的多主体模型。心理生理力模型为连续力模型，自行车/骑行者个体被视作是受心理力和生理力作用的、服从牛顿力学的基本粒子。在轨迹选择模型中，通过在行为模型层面引入个体运动的轨迹选择行为，预定义个体面对不同交通状况时的行为库，描述组成自行车群体中的个体独立思考和对周围环境变化做出反应的能力。通过设计计算机模拟实验并收集数据，对模型进行有效性验证。模拟结果表明：模拟得到的自行车交通流的密度-速度关系与实测数据具有良好的一致性，认为本文提出的自行车微观行为动力学模型具有交通上的合理性。}
}
@article{ZHENG2019109539,
title = {Development of bridge influence line identification methods based on direct measurement data: A comprehensive review and comparison},
journal = {Engineering Structures},
volume = {198},
pages = {109539},
year = {2019},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2019.109539},
url = {https://www.sciencedirect.com/science/article/pii/S0141029619309538},
author = {Xu Zheng and Dong-Hui Yang and Ting-Hua Yi and Hong-Nan Li},
keywords = {Bridge influence line, Inverse problem, B-WIM, Bridge evaluation, Damage detection, Model correction},
abstract = {Bridge influence line, which is defined as the response curve of a certain point of the bridge under the moving unit concentrated load, contains tremendous structural information. However, the real bridge influence lines seldom correspond well with them calculated by bridge model. Accordingly, exact identification of the bridge influence line from the direct measurement data grows up to be an important issue for bridge weight-in-motion system, performance evaluation, model correction and bridge damage detection. This paper provides a comprehensive review of current research and development activities in bridge influence line identification method. At first, the development and applications of the bridge influence line are introduced. Following that, the mathematical models of bridge influence line identification and different bridge influence line identification methods are provided. Finally, four different indexes including noise immunity, peak reconstruction accuracy, computational complexity, and adaptability for axle weight change of different methods are compared and the features of these methods are summarized. The end of this paper provides a criterion for selecting suitable influence line identification method in different conditions and an outlook for further development of bridge influence line identification method.}
}
@article{PEREZESCOBAR202423,
title = {Minimal logical teleology in artifacts and biology connects the two domains and frames mechanisms via epistemic circularity},
journal = {Studies in History and Philosophy of Science},
volume = {104},
pages = {23-37},
year = {2024},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2024.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0039368124000104},
author = {José Antonio Pérez-Escobar},
keywords = {Minimal logical teleology, Analogies, Scientific explanation, Epistemic circularity, Scientific modelling, Cognitive neuroscience},
abstract = {The understanding of artifacts and biological phenomena has often influenced each other. This work argues that at the core of these epistemic bridges there are shared teleological notions and explanations manifested in analogies between artifacts and biological phenomena. To this end, I first propose a focus on the logical structure of minimal teleological explanations, which renders said epistemic bridges more evident than an ontological or metaphysical approach to teleology, and which can be used to describe scientific practices in different areas by virtue of formal generality and minimalism (section 2). Second, I show how this approach highlights some epistemic features shared by the understanding of artifacts and biological phenomena, like a specific kind of epistemic circularity, and how functional analogies between artifacts and biological phenomena translate such epistemic circularity from one domain to the other (section 3). Third, I conduct a case study on the scientific practice around the brain's “compass”, showing how the understanding of artifacts influences purpose ascription and measurement, and frames mechanisms in biology, especially in areas where purpose ascription is most difficult, like cognitive neuroscience (sections 4 and 5).}
}
@article{MYERS2021100349,
title = {Mechanistic and data-driven models of cell signaling: Tools for fundamental discovery and rational design of therapy},
journal = {Current Opinion in Systems Biology},
volume = {28},
pages = {100349},
year = {2021},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2021.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S2452310021000342},
author = {Paul J. Myers and Sung Hyun Lee and Matthew J. Lazzara},
keywords = {Uncertainty, Sensitivity, Parameter sampling, Parameter estimation, Regression, Clustering, Classification, Cancer, Immunology},
abstract = {A full understanding of cell signaling processes requires knowledge of protein structure–function relationships, protein–protein interactions, and the abilities of pathways to control phenotypes. Computational models offer a valuable framework for integrating that knowledge to predict the effects of system perturbations and interventions in health and disease. Whereas mechanistic models are well suited for understanding the biophysical basis for signal transduction and principles of therapeutic design, data-driven models are particularly suited to distill complex signaling relationships among samples and between multivariate signaling changes and phenotypes. Both approaches have limitations and provide incomplete representations of signaling biology, but their careful implementation and integration can provide new understanding for how manipulating system variables impacts cellular decisions.}
}
@article{KERNER202154,
title = {Machine learning and big data provide crucial insight for future biomaterials discovery and research},
journal = {Acta Biomaterialia},
volume = {130},
pages = {54-65},
year = {2021},
issn = {1742-7061},
doi = {https://doi.org/10.1016/j.actbio.2021.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S1742706121003639},
author = {Jacob Kerner and Alan Dogan and Horst {von Recum}},
keywords = {Machine learning, QSAR, QSPR, Material informatics},
abstract = {Machine learning have been widely adopted in a variety of fields including engineering, science, and medicine revolutionizing how data is collected, used, and stored. Their implementation has led to a drastic increase in the number of computational models for the prediction of various numerical, categorical, or association events given input variables. We aim to examine recent advances in the use of machine learning when applied to the biomaterial field. Specifically, quantitative structure properties relationships offer the unique ability to correlate microscale molecular descriptors to larger macroscale material properties. These new models can be broken down further into four categories: regression, classification, association, and clustering. We examine recent approaches and new uses of machine learning in the three major categories of biomaterials: metals, polymers, and ceramics for rapid property prediction and trend identification. While current research is promising, limitations in the form of lack of standardized reporting and available databases complicates the implementation of described models. Herein, we hope to provide a snapshot of the current state of the field and a beginner's guide to navigating the intersection of biomaterials research and machine learning.
Statement of significance
Machine learning and its methods have found a variety of uses beyond the field of computer science but have largely been neglected by those in realm of biomaterials. Through the use of more computational methods, biomaterials development can be expediated while reducing the need for standard trial and error methods. Within, we introduce four basic models that readers can potentially apply to their current research as well as current applications within the field. Furthermore, we hope that this article may act as a “call to action” for readers to realize and address the current lack of implementation within the biomaterials field.}
}
@article{AIBINU2023100590,
title = {Solutions of fractional differential equations by using a blend of variational iteration method with Sumudu transform and application to price adjustment equations},
journal = {Partial Differential Equations in Applied Mathematics},
volume = {8},
pages = {100590},
year = {2023},
issn = {2666-8181},
doi = {https://doi.org/10.1016/j.padiff.2023.100590},
url = {https://www.sciencedirect.com/science/article/pii/S2666818123001031},
author = {M.O. Aibinu and S. Moyo},
keywords = {Sumudu transform, Caputo fractional derivative, Price adjustment, Model, Market equilibrium},
abstract = {The presence of delays in a mathematical model can improve its vitality and suitability in describing several phenomena. However, in the presence of delays, nonlinear fractional differential equations are more difficult to study. This paper presents the use of a blend of variational iteration method with Sumudu transform for solving delay differential equations with Caputo derivatives of fractional variable order. Moreover, the paper introduces delays into the price adjustment equations to propose new price adjustment models with more potential for vitality and suitability. The paper assigns suitable real values to the parameters for the graphical display and comparison of the obtained solutions. The paper presents the interactions that exist among the price, demand, supply and dependence of supply and demand on the price, which can be applied to estimate the equilibrium price.}
}
@article{PINTOCARVALHO2022107255,
title = {An efficient multiscale strategy to predict the evolution of the real contact area between rough surfaces},
journal = {Tribology International},
volume = {165},
pages = {107255},
year = {2022},
issn = {0301-679X},
doi = {https://doi.org/10.1016/j.triboint.2021.107255},
url = {https://www.sciencedirect.com/science/article/pii/S0301679X21004035},
author = {R. {Pinto Carvalho} and A.M. {Couto Carneiro} and F.M. {Andrade Pires} and T. Doca},
keywords = {Contact area, Roughness, Contact homogenisation, Multiscale modelling},
abstract = {An efficient and general multiscale strategy to model rough contact and determine the evolution of the real contact area is proposed, based on the splitting of the surface power spectrum. A multiplicative homogenisation scheme is developed to evaluate the contact area fraction effectively, by incorporating statistical information of the contact pressure field in the scale transitions. A strategy for separating the roughness frequencies and for generating the topography at each scale is proposed. The comparison between direct numerical simulation and the proposed multiscale strategy demonstrates the capability to predict the contact area evolution of multiscale rough topographies. The significant reduction of the computational cost endorses the applicability of the proposed multiscale framework to practical circumstances.}
}
@article{YANG2024111470,
title = {A lattice-theoretic model of three-way conflict analysis},
journal = {Knowledge-Based Systems},
volume = {288},
pages = {111470},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111470},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124001059},
author = {Han Yang and Yiyu Yao and Keyun Qin},
keywords = {MS.F-bilattice, Three-way decision, Three-way conflict analysis},
abstract = {Pawlak conflict analysis uses a three-valued situation table for representing the ratings of a set of agents on a set of issues. This paper examines a lattice-theoretic basis of three-way conflict analysis. Qualitatively, we adopt a triangle, namely, an MS.F-bilattice, to characterize the structures of agents ratings, which gives an intuitive and effective tool for ordering a single agent and a pair of agents. We consider a strength ordering and a rating ordering to construct MS.F-bilattices. By applying the principles of three-way decision as thinking in threes, we trisect, according to the rating ordering, the nine pairs of ratings into three regions: potential opposition (PO), potential conflict (PC), and potential support (PS) regions. For each region, according to the strength ordering, we construct the weak, medium, and strong three subregions. Quantitatively, we introduce opposition-alliance and support-alliance measures based on the rating ordering for one issue to trisect these pairs of ratings into PO, PC, and PS regions. We study opposition strength, conflict strength, and support strength measures based on strength ordering for one issue to trisect each of the three regions into three subregions. Finally, we extend the five types of measures for a set of issues. The lattice-theoretic model of three-way conflict analysis clarifies the semantics of pairs of ratings by two agents and gives a different perspective on trisection methods in conflict analysis. To demonstrate the value of the proposed methods, we analyze a case study of the development planning of the Gansu Province of China.}
}
@article{SITTI2021101340,
title = {Physical intelligence as a new paradigm},
journal = {Extreme Mechanics Letters},
volume = {46},
pages = {101340},
year = {2021},
issn = {2352-4316},
doi = {https://doi.org/10.1016/j.eml.2021.101340},
url = {https://www.sciencedirect.com/science/article/pii/S2352431621001012},
author = {Metin Sitti},
keywords = {Physical Intelligence, mechanics, meta materials, multistability, mechanical memory, mechanical computation},
abstract = {Intelligence of physical agents, such as human-made (e.g., robots, autonomous cars) and biological (e.g., animals, plants) ones, is not only enabled by their computational intelligence (CI) in their brain, but also by their physical intelligence (PI) encoded in their body. Therefore, it is essential to advance the PI of human-made agents as much as possible, in addition to their CI, to operate them in unstructured and complex real-world environments like the biological agents. This article gives a perspective on what PI paradigm is, when PI can be more significant and dominant in physical and biological agents at different length scales and how bioinspired and abstract PI methods can be created in agent bodies. PI paradigm aims to synergize and merge many research fields, such as mechanics, materials science, robotics, mechanical design, fluidics, active matter, biology, self-assembly and collective systems, to enable advanced PI capabilities in human-made agent bodies, comparable to the ones observed in biological organisms. Such capabilities would progress the future robots and other machines beyond what can be realized using the current frameworks.}
}
@article{HOLSAPPLE2014130,
title = {A unified foundation for business analytics},
journal = {Decision Support Systems},
volume = {64},
pages = {130-141},
year = {2014},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2014.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167923614001730},
author = {Clyde Holsapple and Anita Lee-Post and Ram Pakath},
keywords = {Analytics, Business analytics, Business intelligence, Decision making, Decision support, Evidence-based},
abstract = {Synthesizing prior research, this paper designs a relatively comprehensive and holistic characterization of business analytics – one that serves as a foundation on which researchers, practitioners, and educators can base their studies of business analytics. As such, it serves as an initial ontology for business analytics as a field of study. The foundation has three main parts dealing with the whence and whither of business analytics: identification of dimensions along which business analytics possibilities can be examined, derivation of a six-class taxonomy that covers business analytics perspectives in the literature, and design of an inclusive framework for the field of business analytics. In addition to unifying the literature, a major contribution of the designed framework is that it can stimulate thinking about the nature, roles, and future of business analytics initiatives. We show how this is done by deducing a host of unresolved issues for consideration by researchers, practitioners, and educators. We find that business analytics involves issues quite aside from data management, number crunching, technology use, systematic reasoning, and so forth.}
}
@article{CEMPEL2013328,
title = {Application of TRIZ approach to machine vibration condition monitoring problems},
journal = {Mechanical Systems and Signal Processing},
volume = {41},
number = {1},
pages = {328-334},
year = {2013},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2013.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0888327013003610},
author = {Czesław Cempel},
keywords = {Vibration condition monitoring, TRIZ, Ideal final result –IFR, Engineering parameters, Inventive principles, Contradiction matrix},
abstract = {Up to now machine condition monitoring has not been seriously approached by TRIZ11TRIZ= Russian acronym for Inventive Problem Solving System, created by G. Altshuller ca 50 years ago. users, and the knowledge of TRIZ methodology has not been applied there intensively. However, there are some introductory papers of present author posted on Diagnostic Congress in Cracow (Cempel, in press [11]), and Diagnostyka Journal as well. But it seems to be further need to make such approach from different sides in order to see, if some new knowledge and technology will emerge. In doing this we need at first to define the ideal final result (IFR) of our innovation problem. As a next we need a set of parameters to describe the problems of system condition monitoring (CM) in terms of TRIZ language and set of inventive principles possible to apply, on the way to IFR. This means we should present the machine CM problem by means of contradiction and contradiction matrix. When specifying the problem parameters and inventive principles, one should use analogy and metaphorical thinking, which by definition is not exact but fuzzy, and leads sometimes to unexpected results and outcomes. The paper undertakes this important problem again and brings some new insight into system and machine CM problems. This may mean for example the minimal dimensionality of TRIZ engineering parameter set for the description of machine CM problems, and the set of most useful inventive principles applied to given engineering parameter and contradictions of TRIZ.}
}
@article{WANG2023170277,
title = {MLKCA-Unet: Multiscale large-kernel convolution and attention in Unet for spine MRI segmentation},
journal = {Optik},
volume = {272},
pages = {170277},
year = {2023},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2022.170277},
url = {https://www.sciencedirect.com/science/article/pii/S0030402622015352},
author = {Biao Wang and Juan Qin and Lianrong Lv and Mengdan Cheng and Lei Li and Dan Xia and Shike Wang},
keywords = {Deep learning, Spine segmentation, Receptive fields, Multiscale large-kernel convolution, Attention},
abstract = {Medical image segmentation plays a key role in the diagnosis of spinal diseases. Unet has become a universal structure for image segmentation because of its unique skip connection structure in recent years. However, since Unet uses small-kernel convolution, the relationship between remote features is difficult to obtain due to the small receptive fields, and the key information cannot be highlighted, resulting in insufficient edge information. To overcome these problems, this paper proposes multiscale large-kernel convolution Unet (MLKCA-Unet), which develops MLKC block for effective feature extraction. Large-kernel convolution with different convolution kernels is used according to the feature map. For large feature maps, smaller large- kernel convolution is used, and for small feature maps, larger large-kernel convolution is used. All large-kernel convolution can be reduced the dimension by 1 × 1 convolution kernel. This method has a significant reduction in computation. By paralleling each large kernel convolution branch with the 3 × 3 convolution branch, it helps to capture detailed information. At the same time, an attention mechanism is added to the network to emphasize rich feature areas and enhance useful information. Finally, various indicators are employed to evaluate the network’s accuracy, similarity and speed, including IOU, DSC, TPR, PPV, and ET. The published spinesagt2wdataset3 spinal MRI image dataset is adopted in the experiment. The IOU, DSC, TPR, PPV, and ET on the test set are 0.8302, 0.9017, 0.9000, 0.9051 and 70 s/epoch respectively. The experimental result shows that MLKCA-Unet demonstrates superior segmentation performance and robustness, which can be well extended to other medical image segmentation.}
}
@article{CHECHURIN2016119,
title = {Understanding TRIZ through the review of top cited publications},
journal = {Computers in Industry},
volume = {82},
pages = {119-134},
year = {2016},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2016.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0166361516301129},
author = {Leonid Chechurin and Yuri Borgianni},
keywords = {TRIZ, Conceptual design, Industrial practice, Information processing, Computer-Aided Innovation},
abstract = {The development of the Theory of Inventive Problem Solving (TRIZ) has not followed the usual patterns of scientific validation required by engineering methods. Consequently, its outreach within engineering design is interpreted differently in the scholarly community. At the same time, the claimed powerful support in tackling technical problems of any degree of difficulty conflicts with TRIZ diffusion in industrial settings, which is relatively low according to insights into product development practices. The mismatch between ambitious goals and moderate spill-over benefits in the industry ranges among the various open issues concerning TRIZ, its way of thinking, its effectiveness, the usability of its tools. In order to provide a general overview of TRIZ in science, the authors have attempted to analyse reliable and influential sources from the literature. The performed survey includes the top 100 indexed publications concerning TRIZ, according to the number of received citations. Variegated and poorly interconnected research directions emerge in the abundant literature that tackles TRIZ-related topics. The outcomes of the investigation highlight the successful implementation of TRIZ within, among the others, biomimetics and information processing. The traditional borders of mechanical and industrial engineering have been frequently crossed, as the use of TRIZ is also witnessed in the domain of business and services. At the same time, computer-aided platforms represent diffused attempts to boost TRIZ diffusion and applicability.}
}
@article{WANG2023109577,
title = {Study of the flow field of a new fishtail-type stirring impeller in a stirred tank},
journal = {Chemical Engineering and Processing - Process Intensification},
volume = {194},
pages = {109577},
year = {2023},
issn = {0255-2701},
doi = {https://doi.org/10.1016/j.cep.2023.109577},
url = {https://www.sciencedirect.com/science/article/pii/S0255270123003148},
author = {Zhaohui Wang and Deli Li and Quanjie Gao and Qianwen Yang and Xiao Xiong and Changzhi Jiang and Feng Zhang},
keywords = {Computational fluid dynamics, Power consumption, Particle image velocimetry, Impeller design, Blade inclination},
abstract = {Abstracts
In this study, a new fishtail impeller was introduced to improve the mixing of fluids in the stirred tank. The validity of the numerical model was first demonstrated by PIV experiments. Secondly, the CFD technique was used to analyze and predict the flow field characteristics in the stirred tank. Also, the effect of blade inclination on the mixing effect is analyzed. Finally, a comparative Analysis with the whale tail impeller is carried out to demonstrate the superiority of this research work. The results show that The results of the study showed that the power number of the fishtail impeller was reduced by 16.4 % compared to the RT impeller. The pumping efficiency of the fishtail impeller was increased by 25.52 %. The results also show that increasing the blade inclination increases the turbulent kinetic energy in the stirred tank. Comparative analysis with the whale-tail impeller reveals that the power number of the fish-tail impeller is reduced by 17.2 % and the pumping efficiency is increased by 19.97 %.}
}
@article{MISRA201964,
title = {Do religious and conscious investors make better economic decisions? Evidence from India},
journal = {Journal of Behavioral and Experimental Finance},
volume = {22},
pages = {64-74},
year = {2019},
issn = {2214-6350},
doi = {https://doi.org/10.1016/j.jbef.2019.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2214635018301217},
author = {Rupali Misra and Sumita Srivastava and D.K. Banwet},
keywords = {Religiosity, Consciousness, Intuition, Rationality, Ambidextrous decision-making, Information processing models, Investor efficacy, Investment decision-making},
abstract = {Investment decision-making in India is different from the world and is affected by social settings. Religion lies at the core of the prevailing socio-cultural environment strengthening social-norms and belief-system, while consciousness is considered core ingredient of life which improves awareness beyond the physical plane, not attributable to cortical processes. Although socio-cultural influence on economic behaviour is quite discernible in countries following eastern-religious traditions, yet studies examining its impact on decision efficacy are scant. Present research addresses this and explores causal role of religiosity and consciousness in shaping investor’s intuitive and analytical abilities. Following a multi-step procedure with qualitative procedure – using engaged scholarship of experts in participative research model and quantitative assessment – surveying investors, the role of these innate behavioural variables in investment decision making has been examined. The paper also validates ambidextrous decision-making style in investment efficacy where intuition improves analytical thinking which further enhances investment efficacy.}
}
@article{WILKINS202440,
title = {We need to think differently about artificial intelligence},
journal = {New Scientist},
volume = {263},
number = {3509},
pages = {40-43},
year = {2024},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(24)01696-8},
url = {https://www.sciencedirect.com/science/article/pii/S0262407924016968},
author = {Alex Wilkins},
abstract = {Will AI ever emulate human intelligence? Professor of machine intelligence Neil Lawrence tells Alex Wilkins it is misleading to compare the two}
}
@article{BURKE2024102382,
title = {A chance for models to show their quality: Stochastic process model-log dimensions},
journal = {Information Systems},
volume = {124},
pages = {102382},
year = {2024},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2024.102382},
url = {https://www.sciencedirect.com/science/article/pii/S0306437924000401},
author = {Adam T. Burke and Sander J.J. Leemans and Moe T. Wynn and Wil M.P. {van der Aalst} and Arthur H.M. {ter Hofstede}},
keywords = {Stochastic process mining, Process conformance, Stochastic Petri nets, Adhesion, Relevance, Simplicity},
abstract = {Process models describe the desired or observed behaviour of organisations. In stochastic process mining, computational analysis of trace data yields process models which describe process paths and their probability of execution. To understand the quality of these models, and to compare them, quantitative quality measures are used. This research investigates model comparison empirically, using stochastic process models built from real-life logs. The experimental design collects a large number of models generated randomly and using process discovery techniques. Twenty-five different metrics are taken on these models, using both existing process model metrics and new, exploratory ones. The results are analysed quantitatively, making particular use of principal component analysis. Based on this analysis, we suggest three stochastic process model dimensions: adhesion, relevance and simplicity. We also suggest possible metrics for these dimensions, and demonstrate their use on example models.}
}
@article{FUSON2009343,
title = {Avoiding misinterpretations of Piaget and Vygotsky: Mathematical teaching without learning, learning without teaching, or helpful learning-path teaching?},
journal = {Cognitive Development},
volume = {24},
number = {4},
pages = {343-361},
year = {2009},
note = {Atypical Development of Numerical Cognition},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2009.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0885201409000707},
author = {Karen C. Fuson},
abstract = {This article provides an overview of some perspectives about special issues in classroom mathematical teaching and learning that have stemmed from the huge explosion of research in children's mathematical thinking stimulated by Piaget. It concentrates on issues that are particularly important for less-advanced learners and for those who might be having special difficulties in learning mathematics. A major goal of the article is to develop a framework for understanding what effective mathematics teaching and learning is, because doing so is so important for struggling students and for research about them. Piaget's research had a fundamental influence on the on-going tension between understanding and fluency in the classroom, supporting efforts toward increasing understanding. But in some countries, misinterpretations of Piaget led to practices that are counterproductive for children, especially struggling learners. Such misinterpretations are identified and a more balanced approach that also draws on Vygotsky is described—a learning-path developmentally-appropriate learning/teaching approach.}
}
@article{DSOUZA2021100949,
title = {What characterises creativity in narrative writing, and how do we assess it? Research findings from a systematic literature search},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100949},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100949},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001644},
author = {Richard D'Souza},
keywords = {Creativity, Writing, Assessment, Narrative, Review},
abstract = {This paper reports findings from a systematic search of the empirical literature from 2000 to 2020 on the assessment of creativity in narrative writing. It seeks to synthesise the designs, methods and findings on how different disciplines have gathered relevant data to the question of how creativity in writing might be assessed, and feedback made more effective. It draws together the established knowledge base around two research questions. The methodology for the systematic involved searches on five academic databases for relevant keywords, producing 1796 papers. Initial screening of the abstracts identified 97 studies for further scrutiny, and for which full texts were accessed for secondary screening based on the inclusion criteria. The final 39 papers judged to satisfy the selection criteria were subject to in-depth analysis and synthesis. The findings of the review reveal that four main techniques have been utilised in efforts to assess creativity in writing, each with their own merits and limitations, and a paucity of research in several crucial areas. The review indicates that, while several disciplines have contributed to the knowledge base in this area, few interdisciplinary studies exist that draw together multiple techniques and provide clear answers for the research questions used in the study. Furthermore, there is little empirical evidence suggesting that assessment improves student creativity with regard to writing, and new research in the field would be advanced by addressing explicit definitions of creativity, the practices of writing ‘experts’, and writing considered within its social and cultural context.}
}
@article{GAO2022112486,
title = {Regarding the shallow water in an ocean via a Whitham-Broer-Kaup-like system: hetero-Bäcklund transformations, bilinear forms and M solitons},
journal = {Chaos, Solitons & Fractals},
volume = {162},
pages = {112486},
year = {2022},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2022.112486},
url = {https://www.sciencedirect.com/science/article/pii/S0960077922006944},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Ocean, Shallow water, Whitham-Broer-Kaup-like system, Hetero-Bäcklund transformations, Bilinear forms,  solitons, Symbolic computation},
abstract = {Considering the water waves, people have investigated many systems. In this paper, what we study is a Whitham-Broer-Kaup-like system for the dispersive long waves in the shallow water in an ocean. With respect to the water-wave horizontal velocity and deviation height from the equilibrium of the water, we construct (A) two branches of the hetero-Bäcklund transformations, from that system to a known constant-coefficient nonlinear dispersive-wave system, (B) two branches of the bilinear forms and (C) two branches of the M-soliton solutions, with M as a positive integer. Results rely upon the oceanic shallow-water coefficients in that system.}
}
@article{SMITH2019473,
title = {Neurocomputational mechanisms underlying emotional awareness: Insights afforded by deep active inference and their potential clinical relevance},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {107},
pages = {473-491},
year = {2019},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2019.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S014976341930541X},
author = {Ryan Smith and Richard D. Lane and Thomas Parr and Karl J. Friston},
keywords = {Active inference, Emotional awareness, Somatic misattribution, Emotional working memory, Computational neuroscience},
abstract = {Emotional awareness (EA) is recognized as clinically relevant to the vulnerability to, and maintenance of, psychiatric disorders. However, the neurocomputational processes that underwrite individual variations remain unclear. In this paper, we describe a deep (active) inference model that reproduces the cognitive-emotional processes and self-report behaviors associated with EA. We then present simulations to illustrate (seven) distinct mechanisms that (either alone or in combination) can produce phenomena – such as somatic misattribution, coarse-grained emotion conceptualization, and constrained reflective capacity – characteristic of low EA. Our simulations suggest that the clinical phenotype of impoverished EA can be reproduced by dissociable computational processes. The possibility that different processes are at work in different individuals suggests that they may benefit from distinct clinical interventions. As active inference makes particular predictions about the underlying neurobiology of such aberrant inference, we also discuss how this type of modelling could be used to design neuroimaging tasks to test predictions and identify which processes operate in different individuals – and provide a principled basis for personalized precision medicine.}
}
@article{RATTEN2023100857,
title = {Generative artificial intelligence (ChatGPT): Implications for management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100857},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100857},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000952},
author = {Vanessa Ratten and Paul Jones},
keywords = {Academic research, Teaching, Learning, Digital transformation, Management education, Artificial intelligence, ChatGPT},
abstract = {ChatGPT has been one of the most talked about computer programs amongst management educators in recent weeks due to its transformative ability to change how assessments are undertaken and graded. Unlike other educational technologies that can be tracked when used, ChatGPT has superior abilities that make it virtually untraceable when used. This creates a dilemma for management educators wanting to utilise the technology whilst staying relevant but also interested in authentic learning. Thus, it is critical for management educators to quickly implement policies regarding ChatGPT and subsequent new generative artificial intelligence because of its ease of use and affordability. This article is conceptual in nature and discusses ChatGPT as a generative form of artificial intelligence that presents challenges for management educators that need to be addressed through appropriate strategies. Thereby contributing to the literature on how technological innovations can be included in curriculum design and management learning practices. Practical and managerial implications are stated that highlight the critical need to re-examine existing education practices as a way of incorporating new technological innovation that can be utilised in a beneficial way.}
}
@article{WONG2021105042,
title = {Empathic accuracy of young boys and girls in ongoing parent–child interactions: Performance and (mis)perception},
journal = {Journal of Experimental Child Psychology},
volume = {203},
pages = {105042},
year = {2021},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2020.105042},
url = {https://www.sciencedirect.com/science/article/pii/S0022096520304963},
author = {Wang Ivy Wong and Wai Bong Patrick Tsui and Tik-Sze Carrey Siu},
keywords = {Interpersonal interaction, Performance estimation, Social cognition, Gender, Empathic accuracy, Parent and child},
abstract = {Understanding others accurately is crucial in relationships and learning. Research shows that adults face challenges in empathic accuracy, that is, the ability to read the content of others’ moment-to-moment mental states during interactions. Although young children possess some empathic understanding, the extent of their empathic accuracy is uncharted. Using a new SSP, 106 Chinese children aged 60 to 80 months (M = 70 months) were assessed on their ability to infer the mental states of adults in ongoing parent–child interactions. Replicating and extending extant findings on adults and adolescents, the children’s inferences were found to be, at least computationally on a scale of .00 to 1.00, more often inaccurate than accurate regardless of the gender of the targets or participants (overall accuracy rate = .28). However, both the children and their primary caregivers overestimated the children’s performance. In addition, although the primary caregivers expected girls to outperform boys, no gender difference in empathic accuracy was found when controlling for verbal fluency. Drawing on the findings of this first-ever application of the empathic accuracy paradigm in young children, the implications of empathic accuracy performance and misperceptions about such accuracy are discussed.}
}
@article{SHUKLA2024e31397,
title = {AI as a user of AI: Towards responsible autonomy},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31397},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31397},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024074280},
author = {Amit K. Shukla and Vagan Terziyan and Timo Tiihonen},
keywords = {Artificial Intelligence (AI), Autonomy, Responsible AI, ChatGPT, Prompt engineering, AI accountability},
abstract = {Recent advancements in Artificial Intelligence (AI), particularly in generative language models and algorithms, have led to significant impacts across diverse domains. AI capabilities to address prompts are growing beyond human capability but we expect AI to perform well also as a prompt engineer. Additionally, AI can serve as a guardian for ethical, security, and other predefined issues related to generated content. We postulate that enforcing dialogues among AI-as-prompt-engineer, AI-as-prompt-responder, and AI-as-Compliance-Guardian can lead to high-quality and responsible solutions. This paper introduces a novel AI collaboration paradigm emphasizing responsible autonomy, with implications for addressing real-world challenges. The paradigm of responsible AI-AI conversation establishes structured interaction patterns, guaranteeing decision-making autonomy. Key implications include enhanced understanding of AI dialogue flow, compliance with rules and regulations, and decision-making scenarios exemplifying responsible autonomy. Real-world applications envision AI systems autonomously addressing complex challenges. We have made preliminary testing of such a paradigm involving instances of ChatGPT autonomously playing various roles in a set of experimental AI-AI conversations and observed evident added value of such a framework.}
}