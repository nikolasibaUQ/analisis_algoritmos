@article{WU2018127,
title = {Single dose testosterone administration modulates emotional reactivity and counterfactual choice in healthy males},
journal = {Psychoneuroendocrinology},
volume = {90},
pages = {127-133},
year = {2018},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2018.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0306453017312532},
author = {Yin Wu and Luke Clark and Samuele Zilioli and Christoph Eisenegger and Claire M. Gillan and Huihua Deng and Hong Li},
keywords = {Testosterone, Reward, Regret, Emotion, Human male, Dual process},
abstract = {Testosterone has been implicated in the regulation of emotional responses and risky decision-making. However, the causal effect of testosterone upon emotional decision-making, especially in non-social settings, is still unclear. The present study investigated the role of testosterone in counterfactual thinking: regret is an intense negative emotion that arises from comparison of an obtained outcome from a decision against a better, non-obtained (i.e. counterfactual) alternative. Healthy male participants (n = 64) received a single-dose of 150 mg testosterone Androgel in a double-blind, placebo-controlled, between-participants design. At 180 min post-administration, participants performed the counterfactual thinking task. We applied a computational model derived from behavioral economic principles to uncover latent decision-making mechanisms that may be invisible in simple choice analyses. Our data showed that testosterone increased the ability to use anticipated regret to guide choice behavior, while reducing choice based on expected value. On affective ratings, testosterone increased sensitivity to both obtained and counterfactual outcomes. These findings provide evidence that testosterone causally modulates emotional decision-making, and highlight the role of testosterone in affective sensitivity.}
}
@incollection{CRUZQUIROGA2016103,
title = {Chapter 5 - Neurobiological Computation and Neural Networks},
editor = {Munish Puri and Yashwant Pathak and Vijay Kumar Sutariya and Srinivas Tipparaju and Wilfrido Moreno},
booktitle = {Artificial Neural Network for Drug Design, Delivery and Disposition},
publisher = {Academic Press},
address = {Boston},
pages = {103-120},
year = {2016},
isbn = {978-0-12-801559-9},
doi = {https://doi.org/10.1016/B978-0-12-801559-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128015599000053},
author = {Luis Fernando {Cruz Quiroga} and Wilfrido Alejandro Moreno},
keywords = {Complex problem solving, Neural networks, Neurobiology, Neuroscience},
abstract = {This chapter presents the neurobiological basis for the convergence of interdisciplinary work (Nano-Bio-Info-Cogno) in the research of artificial neural networks. The neurobiological study was conducted from neuroscience and technology; the topics explained are genetics and cognition, complexity of information, information processing, brain and problem solving, emotions, and solutions as well as the relationship between the nervous system cells and biological synthesis of information as part of studies to the given problems. The most specific cognitive functions related to decision making and problem solving—attention, time, process, motion, relevance of information, and memory—as well as reasoning processes not typically associated with solving complex problems are reviewed.}
}
@incollection{DASILVASOARES202349,
title = {Chapter Three - Exploring the potential of eye tracking on personalized learning and real-time feedback in modern education},
editor = {Mariuche Gomides and Isabela Starling-Alves and Flávia H. Santos},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {282},
pages = {49-70},
year = {2023},
booktitle = {Brain and Maths in Ibero-America},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000936},
author = {Raimundo {da Silva Soares} and Amanda Yumi Ambriola Oku and Cândida da Silva Ferreira Barreto and João Ricardo Sato},
keywords = {Mathematics education, Eye tracking, Teaching practice, Student gaze},
abstract = {Eye tracking is one of the techniques used to investigate cognitive mechanisms involved in the school context, such as joint attention and visual perception. Eye tracker has portability, straightforward application, cost-effectiveness, and infant-friendly neuroimaging measures of cognitive processes such as attention, engagement, and learning. Furthermore, the ongoing software enhancements coupled with the implementation of artificial intelligence algorithms have improved the precision of collecting eye movement data and simplified the calibration process. These characteristics make it plausible to consider eye-tracking technology a promising tool to assist the teaching-learning process in school routines. However, eye tracking needs to be explored more as an educational instrument for real-time classroom activities and teachers' feedback. This perspective article briefly presents the fundamentals of the eye-tracking technique and four illustrative examples of employing this method in everyday school life. The first application shows how eye tracker information may contribute to teacher assessment of students' computational thinking in coding classes. In the second and third illustrations, we discuss the additional information provided by the eye-tracker to the teacher assessing the student's strategies to solve fraction problems and chart interpretation. The last illustration demonstrates the potential of eye tracking to provide Real-time feedback on learning difficulties/disabilities. Thus, we highlight the potential of the eye tracker as a complementary tool to promote personalized education and discuss future perspectives. In conclusion, we suggest that an eye-tracking system could be helpful by providing real-time student gaze leading to immediate teacher interventions and metacognition strategies.}
}
@article{PHANG2019100837,
title = {How to derive causal insights for digital commerce in China? A research commentary on computational social science methods},
journal = {Electronic Commerce Research and Applications},
volume = {35},
pages = {100837},
year = {2019},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2019.100837},
url = {https://www.sciencedirect.com/science/article/pii/S1567422319300146},
author = {David C.W. Phang and Kanliang Wang and Qiuhong Wang and Robert J. Kauffman and Maurizio Naldi},
keywords = {Big data, Business insights, Causal inference, Causal methods, Computational social science (CSS), Consumer behavior, China, Data analytics, Digital economy, E-commerce, Emerging markets, Empirical research, Information systems (IS) research, Machine learning (ML), M-commerce, Policy analytics, Research design, Secondary data, Sensor data, Streaming data, Social insights, Theory testing},
abstract = {The transformation of empirical research due to the arrival of big data analytics and data science, as well as the new availability of methods that emphasize causal inference, are moving forward at full speed. In this Research Commentary, we examine the extent to which this has the potential to influence how e-commerce research is conducted. China offers the ultimate in data-at-scale settings, and the construction of real-world natural experiments. Chinese e-commerce includes some of the largest firms involved in e-commerce, mobile commerce, social media and social networks. This article was written to encourage young faculty and doctoral students to engage in research that can be carried out in near real-time, with truly experimental or quasi-experimental research designs, and with the clear intention of establishing causal inferences that relate the precursors and drivers of observable outcomes through various kinds of processes. We discuss: the relevant data sources and research contexts; the methods perspectives that are appropriate which blend Computer Science, Statistics and Econometrics, how the research can be made relevant for China; and what kinds of findings and research directions are available. This article is not a tutorial on big data analytics methods in general though, nor does it cover just those published works that demonstrate big data methods and empirical causality in other disciplines. Instead, the empirical research covered is mostly taken from Electronic Commerce Research and Applications, which has published many articles on Chinese e-commerce. This Research Commentary invites researchers in China and the Asia Pacific region to expand their coverage to bring into their empirical work the new methods and philosophy of causal data science.}
}
@article{JARAETTINGER2016589,
title = {The Naïve Utility Calculus: Computational Principles Underlying Commonsense Psychology},
journal = {Trends in Cognitive Sciences},
volume = {20},
number = {8},
pages = {589-604},
year = {2016},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661316300535},
author = {Julian Jara-Ettinger and Hyowon Gweon and Laura E. Schulz and Joshua B. Tenenbaum},
abstract = {We propose that human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers: from a young age, humans implicitly assume that agents choose goals and actions to maximize the rewards they expect to obtain relative to the costs they expect to incur. This ‘naïve utility calculus’ allows both children and adults observe the behavior of others and infer their beliefs and desires, their longer-term knowledge and preferences, and even their character: who is knowledgeable or competent, who is praiseworthy or blameworthy, who is friendly, indifferent, or an enemy. We review studies providing support for the naïve utility calculus, and we show how it captures much of the rich social reasoning humans engage in from infancy.}
}
@article{ALANZI201713,
title = {Inferring rooted species trees from unrooted gene trees using approximate Bayesian computation},
journal = {Molecular Phylogenetics and Evolution},
volume = {116},
pages = {13-24},
year = {2017},
issn = {1055-7903},
doi = {https://doi.org/10.1016/j.ympev.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1055790317305390},
author = {Ayed R.A. Alanzi and James H. Degnan},
keywords = {Multispecies coalescent, Outgroup, Midpoint rooting, Molecular clock, Identifiability, Sufficiency},
abstract = {Methods for inferring species trees from gene trees motivated by incomplete lineage sorting typically use either rooted gene trees to infer a rooted species tree, or use unrooted gene trees to infer an unrooted species tree, which is then typically rooted using one or more outgroups. Theoretically, however, it has been known since 2011 that it is possible to consistently infer the root of the species tree directly from unrooted gene trees without assuming an outgroup. Here, we use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees assuming the multispecies coalescent model. It is hoped that this approach will be useful in cases where an appropriate outgroup is difficult to find and gene trees do not follow a molecular clock. We use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees. This approach could also be useful when there is prior information that makes a small number of root locations plausible in an unrooted species tree.}
}
@article{KEITZER20161322,
title = {Thinking outside of the lake: Can controls on nutrient inputs into Lake Erie benefit stream conservation in its watershed?},
journal = {Journal of Great Lakes Research},
volume = {42},
number = {6},
pages = {1322-1331},
year = {2016},
issn = {0380-1330},
doi = {https://doi.org/10.1016/j.jglr.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0380133016300958},
author = {S. Conor Keitzer and Stuart A. Ludsin and Scott P. Sowa and Gust Annis and Jeff G. Arnold and Prasad Daggupati and August M. Froehlich and Matt E. Herbert and Mari-Vaughn V. Johnson and Anthony M. Sasson and Haw Yen and Mike J. White and Charles A. Rewa},
keywords = {Best management practices, SWAT, Non-point source pollution, Great Lakes, Ecosystem-based management, Index of Biotic Integrity},
abstract = {Investment in agricultural conservation practices (CPs) to address Lake Erie's re-eutrophication may offer benefits that extend beyond the lake, such as improved habitat conditions for fish communities throughout the watershed. If such conditions are not explicitly considered in Lake Erie nutrient management strategies, however, this opportunity might be missed. Herein, we quantify the potential for common CPs that will be used to meet nutrient management goals for Lake Erie to simultaneously improve stream biological conditions throughout the western Lake Erie basin (WLEB) watershed. To do so, we linked a high-resolution watershed-hydrology model to predictive biological models in a conservation scenario framework. Our modeling simulations showed that the implementation of CPs on farm acres in critical and moderate need of treatment, representing nearly half of the watershed, would be needed to reduce spring/early summer total phosphorus loads from the WLEB watershed to acceptable levels. This widespread CP implementation also would improve potential stream biological conditions in >11,000km of streams and reduce the percentage of streams where water quality is limiting biological conditions, from 31% to 20%. Despite these improvements, we found that even with additional treatment of acres in low need of CPs, degraded water quality conditions would limit biological conditions in >3200streamkm. Thus, while we expect CPs to play an important role in mitigating eutrophication problems in the Lake Erie ecosystem, additional strategies and emerging technologies appear necessary to fully reduce water quality limitation throughout the watershed.}
}
@article{ORTEGA2010171,
title = {Parallel drainage network computation on CUDA},
journal = {Computers & Geosciences},
volume = {36},
number = {2},
pages = {171-178},
year = {2010},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098300409002970},
author = {L. Ortega and A. Rueda},
keywords = {GPU, GPGPU, CUDA, Drainage network, D8 algorithm},
abstract = {Drainage networks determination from digital elevation models (DEM) has been a widely studied problem in the last three decades. During this time, satellite technology has been improving and optimizing digitalized images, and computers have been increasing their capabilities to manage such a huge quantity of information. The rapid growth of CPU power and memory size has concentrated the discussion of DEM algorithms on the accuracy of their results more than their running times. However, obtaining improved running times remains crucial when DEM dimensions and their resolutions increase. Parallel computation provides an opportunity to reduce run times. Recently developed graphics processing units (GPUs) are computationally fast not only in Computer Graphics but in General Purpose Computation, the so-called GPGPU. In this paper we explore the parallel characteristics of these GPUs for drainage network determination, using the C-oriented language of CUDA developed by NVIDIA. The results are simple algorithms that run on low-cost technology with a high performance response, obtaining CPU improvements of up to 8×.}
}
@article{GOK201249,
title = {A philosophical assessment of computational models of consciousness},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {49-62},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000635},
author = {Selvi Elif Gök and Erdinç Sayan},
keywords = {Consciousness, Computational cognitive modeling, Clarion, LIDA, ACT-R, Neuronal Work Space Model, ART, GMU-BICA},
abstract = {There has been a recent flurry of activity in consciousness research. Although an operational definition of consciousness has not yet been developed, philosophy has come to identify a set of features and aspects that are thought to be associated with the various elements of consciousness. On the other hand, there have been several recent attempts to develop computational models of consciousness that are claimed to capture or illustrate one or more aspects of consciousness. As a plausible substitute to evaluating how well the current computational models model consciousness, this study examines how the current computational models fare in modeling those aspects and features of consciousness identified by philosophy. Following a review of the literature on the philosophy of consciousness, this study constructs a list of features and aspects that would be expected in any successful model of consciousness. The study then evaluates, from the viewpoint of that list, some of the current self-claimed and implemented computational models of consciousness. The computational models studied are evaluated with respect to each identified aspect and feature of consciousness.}
}
@article{JIA2024101456,
title = {Memory backtracking strategy: An evolutionary updating mechanism for meta-heuristic algorithms},
journal = {Swarm and Evolutionary Computation},
volume = {84},
pages = {101456},
year = {2024},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2023.101456},
url = {https://www.sciencedirect.com/science/article/pii/S2210650223002286},
author = {Heming Jia and Chenghao Lu and Zhikai Xing},
keywords = {Memory backtracking strategies, New evolutionary updating strategy, Meta-heuristic optimization algorithm},
abstract = {The search domain of meta-heuristic algorithms is always constantly changing, which make it difficult to adapt the diverse optimization issues. To overcome above issue, an evolutionary updating mechanism called Memory Backtracking Strategy (MBS) is proposed, which contains thinking stage, recall stage, and memory stage. Overall, the adoption of the MBS enhances the efficiency of MHSs by incorporating group memory, clue recall, and memory forgetting mechanisms. These strategies improve the algorithm's ability to explore the search space, optimize the search process, and escape local optima. MBS will be applied to three different types of MHS algorithms: evolutionary based (LSHADE_SPACMA), physical based (Stochastic Fractal Search, SFS), and biological based (Marine Predators Algorithmnm, MPA) to demonstrate the universality of MBS. In the experimental section including 57 engineering problems, algorithm complexity analysis, CEC2020 Friedman ranking, convergence curve, Wilcoxon statistical, and box plot. Among them, 21 algorithms participated in the Friedman experiment, including MBS_LSHADE_SPACMA ranked first, LSHADE_SPACMA ranked second, MBS_MPA ranked 6th, MPA ranked 8th, MBS_SFS ranked 9th and SFS ranked 12th. Combined with the analysis of "MBS testing analysis" and the experimental results of engineering problems, it has proven that MBS has universality and good ability to improve optimization algorithm performance. The source codes of the proposed MBS (MBS_MPA) can be accessed by https://github.com/luchenghao2022/Memory-Backtracking-Strategy}
}
@incollection{BODEN2008741,
title = {INFORMATION, COMPUTATION, AND COGNITIVE SCIENCE},
editor = {Pieter Adriaans and Johan {van Benthem}},
booktitle = {Philosophy of Information},
publisher = {North-Holland},
address = {Amsterdam},
pages = {741-761},
year = {2008},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51726-5.50023-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517265500236},
author = {Margaret A. Boden}
}
@article{ARDALAN2018170,
title = {Neurofinance versus the efficient markets hypothesis},
journal = {Global Finance Journal},
volume = {35},
pages = {170-176},
year = {2018},
issn = {1044-0283},
doi = {https://doi.org/10.1016/j.gfj.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1044028317302715},
author = {Kavous Ardalan},
keywords = {Neurofinance, Behavioral finance, Costly thinking, Efficient markets hypothesis},
abstract = {This paper develops the implication of neurofinance with respect to the efficient markets hypothesis. Neurofinance informs us that thinking imposes strain on the mind, in the sense that thinking is a comparatively laborious, biologically costly, and neurologically expensive cognitive process. The paper shows that people balance the costs and benefits of thinking and demonstrates mathematically that such balancing makes financial markets inefficient.}
}
@article{SHI2018117,
title = {Toward automated reasoning for analog IC design by symbolic computation – A survey},
journal = {Integration},
volume = {60},
pages = {117-131},
year = {2018},
issn = {0167-9260},
doi = {https://doi.org/10.1016/j.vlsi.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167926017304182},
author = {Guoyong Shi},
keywords = {Analog integrated circuit (IC), Computer-aided reasoning (CAR), Formal information processing, Graph-pair decision diagram (GPDD), Knowledge representation, Operational amplifier (opamp), Symbolic computation},
abstract = {Analog integrated circuit (IC) design highly depends on reasoning, which distinguishes itself from other areas of IC design. Most of its innovation arises from qualitative reasoning by a pencil and paper. Innovation on the circuit structure needs quick analytical justification. Circuit-level reduced-scale modeling is a popular reasoning means. Circuit simulation tools can only serve partial justification on a design, while design insight still has to be acquired via manual analysis. A basic question has been in existence for many decades: how can we automate the analog IC design process? Many analog synthesis tools proposed decades ago could not make it to this date in the design practice. In this survey the major reason is attributed to the black-box style of the tool design. Human designer's creativity is shielded away from the tool operation while the formal design knowledge hardcoded in those tools remains at a very primitive level. By analyzing the defects of those existing tools, this survey advocates an open tool development philosophy whose major goal is to support human-machine interaction. On the one side a design automation tool is mainly aimed at providing aid for tasks that require analytical deduction while on the other side designers are expected to exercise their creativity based on the machine-generated results. Such human-machine co-working style is believed to be a more feasible solution to analog IC design automation based on the currently available computation technology. In this survey the art of symbolic computation is promoted to be the enabling technology for computer-aided analytical generation. The symbolic computation technology today can support topological and analytical reasoning that is the most demanding need in the analog IC design practice. This survey further calls for more research on the formal methods that are applicable to design knowledge representation, human-machine interaction, and design inference. Some preliminary research results are reviewed and future research directions are pointed out.}
}
@article{BEGGS20091311,
title = {Computations via Newtonian and relativistic kinematic systems},
journal = {Applied Mathematics and Computation},
volume = {215},
number = {4},
pages = {1311-1322},
year = {2009},
note = {Physics and Computation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2009.04.052},
url = {https://www.sciencedirect.com/science/article/pii/S0096300309004214},
author = {E.J. Beggs and J.V. Tucker},
keywords = {Foundations of computation, Computable functions and sets, Newtonian kinematic systems, Relativistic kinematic systems, Foundations of mechanics, Theory of Gedanken experiments, Non-computable physical systems},
abstract = {We are developing a rigorous methodology to analyse experimental computation, by which we mean the idea of computing a set or function by experimenting with some physical equipment. Here we consider experimental computation by kinematic systems under both Newtonian and relativistic kinematics. An experimental procedure, expressed in a language similar to imperative programming languages, is applied to equipment, having the form of a bagatelle, and is interpreted using the two theories. We prove that for any set A of natural numbers there exists a two-dimensional kinematic system BA with a single particle P whose observable behaviour decides n∈A for all n∈N. The procedure can operate under (a) Newtonian mechanics or (b) relativistic mechanics. The proofs show how any information (coded by some A) can be embedded in the structure of a simple kinematic system and retrieved by simple observations of its behaviour. We reflect on the methodology, which seeks a formal theory for performing abstract experiments with physical restrictions on the construction of systems. We conclude with some open problems.}
}
@article{NEUMANN2020281,
title = {Parametrised second-order complexity theory with applications to the study of interval computation},
journal = {Theoretical Computer Science},
volume = {806},
pages = {281-304},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519302889},
author = {Eike Neumann and Florian Steinberg},
keywords = {Second-order complexity, Type two complexity, Interval computation, Computable analysis},
abstract = {We extend the framework for complexity of operators in analysis devised by Kawamura and Cook (2012) to allow for the treatment of a wider class of representations. The main novelty is to endow represented spaces of interest with an additional function on names, called a parameter, which measures the complexity of a given name. This parameter generalises the size function which is usually used in second-order complexity theory and therefore also central to the framework of Kawamura and Cook. The complexity of an algorithm is measured in terms of its running time as a second-order function in the parameter, as well as in terms of how much it increases the complexity of a given name, as measured by the parameters on the input and output side. As an application we develop a rigorous computational complexity theory for interval computation. In the framework of Kawamura and Cook the representation of real numbers based on nested interval enclosures does not yield a reasonable complexity theory. In our new framework this representation is polytime equivalent to the usual Cauchy representation based on dyadic rational approximation. By contrast, the representation of continuous real functions based on interval enclosures is strictly smaller in the polytime reducibility lattice than the usual representation, which encodes a modulus of continuity. Furthermore, the function space representation based on interval enclosures is optimal in the sense that it contains the minimal amount of information amongst those representations which render evaluation polytime computable.}
}
@article{OTOOLE2024100080,
title = {Extending human creativity with AI},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100080},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000062},
author = {Katherine O'Toole and Emőke-Ágnes Horvát},
keywords = {Computational creativity, Generative AI, HCI},
abstract = {The development of generative AI has led to novel ways that technology can be integrated into creative activities. However, this has also raised concerns about how human creators will be affected, and what impact it may have on creative industries. As a result, there has been research into how we can design AI tools that work with human creators, rather than replacing them. In this paper we review approaches utilized to build AI tools that facilitate human creativity and allow users to engage fully and authentically in the creative process. These include leveraging AI models to help us shed light on elements of the creative process, building interfaces that encourage exploration of ideas, and designing technological affordances that can support the development of new creative practices.}
}
@article{SANGALLI2018117,
title = {Matrix-free weighted quadrature for a computationally efficient isogeometric k-method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {117-133},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518302081},
author = {G. Sangalli and M. Tani},
keywords = {Isogeometric analysis, 
               -method, Matrix-free, Weighted quadrature, Preconditioner},
abstract = {The k-method is the isogeometric method based on splines (or NURBS, etc.) with maximum regularity. When implemented following the paradigms of classical finite element methods, the computational resources required by the k-method are prohibitive even for moderate degree. In order to address this issue, we propose a matrix-free strategy combined with weighted quadrature, which is an ad-hoc strategy to compute the integrals of the Galerkin system. Matrix-free weighted quadrature (MF-WQ) speeds up matrix operations, and, perhaps even more important, greatly reduces memory consumption. Our strategy also requires an efficient preconditioner for the linear system iterative solver. In this work we deal with an elliptic model problem, and adopt a preconditioner based on the Fast Diagonalization method, an old idea to solve Sylvester-like equations. Our numerical tests show that the isogeometric solver based on MF-WQ is faster than standard approaches (where the main cost is the matrix formation by standard Gaussian quadrature) even for low degree. But the main achievement is that, with MF-WQ, the k-method gets orders of magnitude faster by increasing the degree, given a target accuracy. Therefore, we are able to show the superiority, in terms of computational efficiency, of the high-degree k-method with respect to low-degree isogeometric discretizations. What we present here is applicable to more complex and realistic differential problems, but its effectiveness will depend on the preconditioner stage, which is as always problem-dependent. This situation is typical of modern high-order methods: the overall performance is mainly related to the quality of the preconditioner.}
}
@article{DUKHANOV20141433,
title = {Double-degree Master's Program in Computational Science: Experiences of ITMO University and University of Amsterdam},
journal = {Procedia Computer Science},
volume = {29},
pages = {1433-1445},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.130},
url = {https://www.sciencedirect.com/science/article/pii/S187705091400307X},
author = {Alexey V. Dukhanov and Valeria V. Krzhizhanovskaya and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {teaching computational science, M aster's program, double degree, curriculum, enrollment, student research, funding opportunities},
abstract = {We present a new double-degree graduate (Master's) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of d ifferent educational systems and list some funding opportunities fro m European foundations. Then we describe our double-degree program curricu lu m, suggest the time line of enrollment and studies, and give some e xa mples of student research topics. Finally, we d iscuss the peculiarities of joint progra ms with Russia, re flect on the first lessons learnt, and share our thoughts and experiences that could be of interest to the international community e xpanding the educational ma rkets to the vast countries like Russia, Ch ina or India. The paper is written for education professionals and contains useful information for potential students.}
}
@article{BURTONROBERTS20112089,
title = {On the grounding of syntax and the role of phonology in human cognition},
journal = {Lingua},
volume = {121},
number = {14},
pages = {2089-2102},
year = {2011},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2011.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S002438411100146X},
author = {Noel Burton-Roberts},
keywords = {Syntactic grounding, Interface interpretation, Language faculty, Language of thought, Phonology-free generativity, Phonology in human cognition},
abstract = {Chomskyan generative grammar has long been committed to the ‘double-interface’ assumption that the faculty of language (FL) serves two interfaces, PF and LF, and correlatively that expressions have phonological and semantic properties. The paper argues this gives rise to (a) a grounding problem for syntax – i.e. for the interpretable content of syntax – and (b) a problem for the assumption that FL is a generative computation. It is argued these problems are resolved if we think of syntax as grounded exclusively in semantic/conceptual properties. Since this implies that FL is phonology-free, it is argued that FL should not be distinguished from a generative computation describable as ‘the language of thought’ (LOT). The paper explores to what extent this (FL=LOT) thesis is consistent with Chomsky's thinking. Chomsky's recent work can be seen as pointing in that direction but it is not consistent with the double-interface assumption, which he continues to regard as conceptually necessary. In the light of discussion of the issues, the paper concludes with a speculation on the role of phonology in human cognition and its evolution.}
}
@article{HODGMAN2012261,
title = {Cell-free synthetic biology: Thinking outside the cell},
journal = {Metabolic Engineering},
volume = {14},
number = {3},
pages = {261-269},
year = {2012},
note = {Synthetic Biology: New Methodologies and Applications for Metabolic Engineering},
issn = {1096-7176},
doi = {https://doi.org/10.1016/j.ymben.2011.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1096717611000929},
author = {C. Eric Hodgman and Michael C. Jewett},
keywords = {Cell-free biology,  protein synthesis, Metabolic engineering, Synthetic biology, Synthetic enzymatic pathways, Biocatalysis},
abstract = {Cell-free synthetic biology is emerging as a powerful approach aimed to understand, harness, and expand the capabilities of natural biological systems without using intact cells. Cell-free systems bypass cell walls and remove genetic regulation to enable direct access to the inner workings of the cell. The unprecedented level of control and freedom of design, relative to in vivo systems, has inspired the rapid development of engineering foundations for cell-free systems in recent years. These efforts have led to programmed circuits, spatially organized pathways, co-activated catalytic ensembles, rational optimization of synthetic multi-enzyme pathways, and linear scalability from the micro-liter to the 100-liter scale. It is now clear that cell-free systems offer a versatile test-bed for understanding why nature's designs work the way they do and also for enabling biosynthetic routes to novel chemicals, sustainable fuels, and new classes of tunable materials. While challenges remain, the emergence of cell-free systems is poised to open the way to novel products that until now have been impractical, if not impossible, to produce by other means.}
}
@incollection{BONSIGNORE2019291,
title = {Chapter 14 - Device Design and Computational Simulation},
editor = {Christopher P. Cheng},
booktitle = {Handbook of Vascular Motion},
publisher = {Academic Press},
pages = {291-312},
year = {2019},
isbn = {978-0-12-815713-8},
doi = {https://doi.org/10.1016/B978-0-12-815713-8.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128157138000140},
author = {C. Bonsignore},
keywords = {Device design, boundary conditions, simulation, stress and strain, finite element analysis, nitinol, prototyping, iteration, design control},
abstract = {Medical device development consists of ideation, prototyping, simulation, preclinical testing, and clinical trials. In the early stages, design and test iterations offer insights to incorporate into subsequent iterations and should be repeated often with only as much complexity as necessary. Computational simulations, in the form of analytic calculations or finite element analysis (FEA), can be utilized for design concept screening all the way to design verification testing under design control. For FEA, while the mathematics is complicated, and the programming is intricate, the utility of the simulation is only as good as the realism of the anatomic loading boundary conditions. While boundary conditions may not be able to be prescribed exactly as they happen in vivo, good engineering intuition and judgment are invaluable for making reasonable approximations.}
}
@article{STENROOS2019116159,
title = {Real-time computation of the TMS-induced electric field in a realistic head model},
journal = {NeuroImage},
volume = {203},
pages = {116159},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2019.116159},
url = {https://www.sciencedirect.com/science/article/pii/S1053811919307505},
author = {Matti Stenroos and Lari M. Koponen},
keywords = {Transcranial magnetic stimulation (TMS), Navigated transcranial magnetic stimulation, Electric field calculation, Coil model, Volume conductor model},
abstract = {Transcranial magnetic stimulation (TMS) is often targeted using a model of TMS-induced electric field (E). In such navigated TMS, the E-field models have been based on spherical approximation of the head. Such models omit the effects of cerebrospinal fluid (CSF) and gyral folding, leading to potentially large errors in the computed E-field. So far, realistic models have been too slow for interactive TMS navigation. We present computational methods that enable real-time solving of the E-field in a realistic five-compartment (5-C) head model that contains isotropic white matter, gray matter, CSF, skull and scalp. Using reciprocity and Geselowitz integral equation, we separate the computations to coil-dependent and -independent parts. For the Geselowitz integrals, we present a fast numerical quadrature. Further, we present a moment-matching approach for optimizing dipole-based coil models. We verified and benchmarked the new methods using simulations with over 100 coil locations. The new quadrature introduced a relative error (RE) of 0.3–0.6%. For a coil model with 42 dipoles, the total RE of the quadrature and coil model was 0.44–0.72%. Taking also other model errors into account, the contribution of the new approximations to the RE was 0.1%. For comparison, the RE due to omitting the separation of white and gray matter was >11%, and the RE due to omitting also the CSF was >23%. After the coil-independent part of the model has been built, E-fields can be computed very quickly: Using a standard PC and basic GPU, our solver computed the full E-field in a 5-C model in 9000 points on the cortex in 27 coil positions per second (cps). When the separation of white and gray matter was omitted, the speed was 43–65 cps. Solving only one component of the E-field tripled the speed. The presented methods enable real-time solving of the TMS-induced E-field in a realistic head model that contains the CSF and gyral folding. The new methodology allows more accurate targeting and precise adjustment of stimulation intensity during experimental or clinical TMS mapping.}
}
@article{MUKTI2024117407,
title = {Computer aided sketching in the early-stage design of complex vessels},
journal = {Ocean Engineering},
volume = {305},
pages = {117407},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117407},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824007443},
author = {M.H. Mukti and R.J. Pawling and D.J. Andrews},
abstract = {Various methods have been developed for automated and semi-automated architecture generation in the computer aided ship design processes. The question remains as to how this can speed up the design process without losing the requirement elucidation intent for concept phase. This paper presents a novel approach with a software toolset to develop design and analysis approaches to early stage ship design and provide a sketching tool. This was done by enhancing the user interface and experience of the UCL Network Block Approach to achieve a “thinking sketch” in a way that is “quick” and “fluid” enough to promote inventive and creative sketching comparable to hand sketching. The UCL Network Block Approach draws on the UCL Design Building Block (DBB) approach and uses network methods applied to the synthesis of distributed ship service systems (DS3) and Computer Aided Ship Design (CASD) to expand DS3 definition in early stage ship design. The UCL originated inside-out/DBB approach to sketch driven synthesis has been made translatable to both DBB ship descriptions and ensuring early stage naval architectural “balance”. The proposed approach has been used for the first time successfully to not only carry out a rapid sketching exercise for a naval ship design but also enable quick preliminary analysis of a set of DS3 networks.}
}
@article{GOLLISCH2010150,
title = {Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina},
journal = {Neuron},
volume = {65},
number = {2},
pages = {150-164},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627309009994},
author = {Tim Gollisch and Markus Meister},
abstract = {We rely on our visual system to cope with the vast barrage of incoming light patterns and to extract features from the scene that are relevant to our well-being. The necessary reduction of visual information already begins in the eye. In this review, we summarize recent progress in understanding the computations performed in the vertebrate retina and how they are implemented by the neural circuitry. A new picture emerges from these findings that helps resolve a vexing paradox between the retina's structure and function. Whereas the conventional wisdom treats the eye as a simple prefilter for visual images, it now appears that the retina solves a diverse set of specific tasks and provides the results explicitly to downstream brain areas.}
}
@article{SUN2001241,
title = {Computation, reduction, and teleology of consciousness},
journal = {Cognitive Systems Research},
volume = {1},
number = {4},
pages = {241-249},
year = {2001},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(00)00013-9},
url = {https://www.sciencedirect.com/science/article/pii/S1389041700000139},
author = {Ron Sun},
keywords = {Consciousness, Cognition, Qualia, Implicit learning, Computation, Reduction, Teleology},
abstract = {This paper aims to explore mechanistic and teleological explanations of consciousness. In terms of mechanistic explanations, it critiques various existing views, especially those embodied by existing computational cognitive models. In this regard, the paper argues in favor of the explanation based on the distinction between localist (symbolic) representation and distributed representation (as formulated in the connectionist literature), which reduces the phenomenological difference to a mechanistic difference. Furthermore, to establish a teleological explanation of consciousness, the paper discusses the issue of the functional role of consciousness on the basis of the aforementioned mechanistic explanation. A proposal based on synergistic interaction between the conscious and the unconscious is advanced that encompasses various existing views concerning the functional role of consciousness. This two-step deepening explanation has some empirical support, in the form of a cognitive model and various cognitive data that it captures.}
}
@incollection{PETRUZZELLI20121,
title = {1 - Re-thinking the innovation approach},
editor = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
booktitle = {When Tradition Turns Into Innovation},
publisher = {Chandos Publishing},
pages = {1-18},
year = {2012},
isbn = {978-1-84334-664-7},
doi = {https://doi.org/10.1016/B978-1-84334-664-7.50007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9781843346647500070},
author = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
keywords = {triple crisis, innovation, tradition},
abstract = {Abstract
This chapter presents a review and criticism of the actual innovation approaches, highlighting how the social and economic scenario imposes the necessity of rethinking innovation and consumption models. Specifically, we discuss how the recent crises – which together affect finance, food and climate change and their implications for human development – are forcing organisations to find new solutions and models for responding to emerging needs and expectations. In this regard, we elaborate on the important role that may be played by traditional knowledge as a source of inspiration for innovation, since creativity can find a reliable support in what society has found to be suitable in the past for its development needs.}
}
@article{PAN2006448,
title = {Human and social behavior in computational modeling and analysis of egress},
journal = {Automation in Construction},
volume = {15},
number = {4},
pages = {448-461},
year = {2006},
note = {The first conference on the Future of the AEC Industry (BFC05)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2005.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0926580505000737},
author = {Xiaoshan Pan and Charles S. Han and Ken Dauber and Kincho H. Law},
keywords = {Human and social behavior, Decision-making, Egress, Emergency, Computational modeling, Multi-agent system},
abstract = {Safe egress is one of the key design issues identified by facility planners, manager and inspectors. Computational tools are now available for the simulation and design of emergency evacuation and egress. However, these tools rely heavily on assumptions about individual human and social behaviors, which have been found to be oversimplified, inconsistent and even incorrect. Furthermore, the behaviors are usually incorporated into the computational model in an ad hoc manner. This paper presents a framework for studying human and social behavior, from the perspectives of human decision-making and social interaction, and for incorporating such behavior systematically in a dynamic computational model suitable for emergency egress analysis.}
}
@article{ZHANG2024109147,
title = {Three-phase multi-criteria ranking considering three-way decision framework and criterion fuzzy concept},
journal = {International Journal of Approximate Reasoning},
volume = {168},
pages = {109147},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109147},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24000343},
author = {Kai Zhang and Jianhua Dai},
keywords = {Three-way decision, Criterion fuzzy concept, Three-phase ranking, Multi-criteria ranking},
abstract = {The criterion fuzzy concept refers to a fuzzy set that represents the decision-maker's subjective preference for each criterion within the universe of criteria. Addressing the challenge of ranking all alternatives based on a given criterion fuzzy concept is a novel research direction in the field of fuzzy multi-criteria ranking issues. This paper proposes a three-phase approach for multi-criteria ranking in fuzzy environments, which combines the criterion fuzzy concept and three-way decision thinking. The proposed approach not only analyzes the decision-making characteristics of all alternatives but also facilitates their ranking. During the first phase, a qualitative classification method based on the criterion fuzzy concept and ideal solutions is defined, which divides all alternatives into three independent decision sub-regions. During the second phase, by analyzing the priority relationships among the alternatives within every sub-region, three local ranking rules for alternatives are proposed to determine the ranking of alternatives in each classification region. During the third phase, the semantic relations among three classification regions are considered to give an overall ranking of all alternatives. Finally, combined with two existing quantitative ranking indicators, multiple data sets are employed to verify the feasibility and superiority of the proposed three-phase multi-criteria ranking approach.}
}
@article{SCHULZ2024210,
title = {Political reinforcement learners},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {3},
pages = {210-222},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002875},
author = {Lion Schulz and Rahul Bhui},
keywords = {computational models, reinforcement learning, political psychology},
abstract = {Politics can seem home to the most calculating and yet least rational elements of humanity. How might we systematically characterize this spectrum of political cognition? Here, we propose reinforcement learning (RL) as a unified framework to dissect the political mind. RL describes how agents algorithmically navigate complex and uncertain domains like politics. Through this computational lens, we outline three routes to political differences, stemming from variability in agents’ conceptions of a problem, the cognitive operations applied to solve the problem, or the backdrop of information available from the environment. A computational vantage on maladies of the political mind offers enhanced precision in assessing their causes, consequences, and cures.}
}
@article{GOLIGHER20241067,
title = {Bayesian statistics for clinical research},
journal = {The Lancet},
volume = {404},
number = {10457},
pages = {1067-1076},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01295-9},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624012959},
author = {Ewan C Goligher and Anna Heath and Michael O Harhay},
abstract = {Summary
Frequentist and Bayesian statistics represent two differing paradigms for the analysis of data. Frequentism became the dominant mode of statistical thinking in medical practice during the 20th century. The advent of modern computing has made Bayesian analysis increasingly accessible, enabling growing use of Bayesian methods in a range of disciplines, including medical research. Rather than conceiving of probability as the expected frequency of an event (purported to be measurable and objective), Bayesian thinking conceives of probability as a measure of strength of belief (an explicitly subjective concept). Bayesian analysis combines previous information (represented by a mathematical probability distribution, the prior) with information from the study (the likelihood function) to generate an updated probability distribution (the posterior) representing the information available for clinical decision making. Owing to its fundamentally different conception of probability, Bayesian statistics offers an intuitive, flexible, and informative approach that facilitates the design, analysis, and interpretation of clinical trials. In this Review, we provide a brief account of the philosophical and methodological differences between Bayesian and frequentist approaches and survey the use of Bayesian methods for the design and analysis of clinical research.}
}
@article{MCLEAN2023104019,
title = {From Anti-doping-I to Anti-doping-II: Toward a paradigm shift for doping prevention in sport},
journal = {International Journal of Drug Policy},
volume = {115},
pages = {104019},
year = {2023},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0955395923000683},
author = {Scott McLean and Mitchell Naughton and Hugo Kerhervé and Paul M. Salmon},
keywords = {Sport, Doping, World anti-doping agency, Systems thinking, Systems analysis},
abstract = {Doping remains an intractable issue in sport and occurs in a complex and dynamic environment comprising interactions between individual, situational, and environmental factors. Anti-doping efforts have previously predominantly focused on athlete behaviours and sophisticated detection methods, however, doping issues remain. As such, there is merit in exploring an alternative approach. The aim of this study was to apply a systems thinking approach to model the current anti-doping system for four football codes in Australia, using the Systems Theoretic Accident Model and Processes (STAMP). The STAMP control structure was developed and validated by eighteen subject matter experts across a five-phase validation process. Within the developed model, education was identified as a prominent approach anti-doping authorities use to combat doping. Further, the model suggests that a majority of existing controls are reactive, and hence that there is potential to employ leading indicators to proactively prevent doping and that new incident reporting systems could be developed to capture such information. It is our contention that anti-doping research and practice should consider a shift away from the current reactive and reductionist approach of detection and enforcement to a proactive and systemic approach focused on leading indicators. This will provide anti-doping agencies a new lens to look at doping in sport.}
}
@article{KHANUM2022131890,
title = {Synthesis, single crystal, characterization and computational study of 2-amino-N-cyclopropyl-5-ethyl-thiophene-3-carboxamide},
journal = {Journal of Molecular Structure},
volume = {1250},
pages = {131890},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131890},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021020123},
author = {Ghazala Khanum and Aysha Fatima and Nazia Siddiqui and D.D. Agarwal and R.J. Butcher and Sanjay Kumar Srivastava and Saleem Javed},
keywords = {DFT studies, Fukui function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {2-amino-N-cyclopropyl-5-ethylthiophene-3-carboxamide (ACPETC) (C10H14N2OS) has been synthesized, characterized via single-crystal X-ray diffraction at 296 K and studied theoretically via DFT approach. The compound crystallizes in tetragonal crystal system, space group I-4 with Z = 8 and the following unit cell dimensions: a = 16.0892(4) Å, b = 16.0892(4) Å, c = 8.4059(2) Å. ACPETC was experimentally characterized by 1H, 13C NMR, FT-IR, UV–Vis and ESI-MS analysis. The molecular structure, vibrational spectra, MEP, ELF, NLO, NBO, NHO, and FMO analysis of ACPETC (C10H14N2OS) in the ground state were estimated using HF, MP2, DFT/B3LYP using the 6–311++G(d,p) basis set. Computed NMR chemical shifts (1H and 13C), as well as discrete regions in IR active vibrations, are in good concurrence with their experimental counterparts. FT-IR spectra of ACPETC were obtained in the ranges of 4000−450 cm−1. The UV–vis spectrum as well as the effects of solvents has been studied. The estimated HOMO and LUMO energies reveal that charge transfer happens within the molecule and MEP surface to be a chemically reactive region suitable for drug action. The O1-atom appears to be more vulnerable to electrophilic assault. The NBO analysis was also performed. It indicates that the greatest second order perturbation energy E(2) = 50.11 kcal/mol associated with electron delocalization from the donor (N15) → π* (C10-O14) acceptor interaction. On the atomic charges of the title chemical, the Fukui function and Mulliken analysis have been calculated. 3-D and 2-D interactions in crystals were studies and Hirshfeld surface analysis was used. To discover the optimum ligand-protein interactions, molecular docking was used using eight protein receptors.}
}
@article{CONTI2021272,
title = {Harnessing Visual Imagery and Oculomotor Behaviour to Understand Prospection},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {4},
pages = {272-283},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000115},
author = {Federica Conti and Muireann Irish},
keywords = {future thinking, visual mental imagery, episodic memory, imagination, hippocampus, default mode network},
abstract = {Much of the rich internal world constructed by humans is derived from, and experienced through, visual mental imagery. Despite growing appreciation of visual exploration in guiding episodic memory processes, extant theories of prospection have yet to accommodate the precise role of visual mental imagery in the service of future-oriented thinking. We propose that the construction of future events relies on the assimilation of perceptual details originally experienced, and subsequently reinstantiated, predominantly in the visual domain. Individual differences in the capacity to summon discrete aspects of visual imagery can therefore account for the diversity of content generated by humans during future simulation. Our integrative framework provides a novel testbed to query alterations in future thinking in health and disease.}
}
@article{AHLQUIST201584,
title = {Development of a digital framework for the computation of complex material and morphological behavior of biological and technological systems},
journal = {Computer-Aided Design},
volume = {60},
pages = {84-104},
year = {2015},
note = {Material Ecology},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2014.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010448514000141},
author = {Sean Ahlquist and Tim Kampowski and Omid {Oliyan Torghabehi} and Achim Menges and Thomas Speck},
keywords = {Material behavior, Spring-based simulation, Computational design, Biomimetic research},
abstract = {Research in material behavior involves the study of relationships between material composition and capacities to negotiate internal and external pressures. Tuning material composition for performance allows for the integration of multifaceted functionality and embedded responsiveness within minimal material means. The relationships of material composition and system performance can be dissected into properties of topology (in count, type and association), forces (as the simulation of contextual pressures), and materiality (material properties and constraints of fabrication). When resourcing information about these aspects of material behavior from biological or technological systems, the physical precedents, as specimens and/or models, serve as the primary, and often sole, exemplar. While this is necessary to initiate the study of material make-up as it relates to specific morphological performance, there is an inherent limit when asking how and to what degree the knowledge resourced from that instance applies when alterations from the norm are generated. This research proposes the possibility for testing variants of a morphological system using physical models as the precedent while incorporating multiple means of computational analysis for extensive exploration. The framework begins with the initial stage of deducing principles, regarding material organization and behavior, through comparative physical and computational study. Subsequently, through methods of abduction, new vocabularies of form and potentials in performance are generated primarily through computational exploration. The framework is shaped by research into the design and materialization of complex pre-stressed form- and bending-active architectures. A novel aspect of this framework is the development of a software environment called springFORM. In this environment, material behavior is simulated using basic spring-based (particle system) methods. The novel contribution of this software is in providing means for both manual and algorithmic manipulations of mesh topologies and material properties during the form-finding process. A series of architectural prototypes, which range in scale, define rules for the relationship between topological-material complexity and the sequencing of particular exploratory methods. The studies define the value of the physical precedent as it engenders further material prototypes, spring-based explorations and simulations with finite element analysis. These rules and methods are further elaborated upon through studying the particularly fascinating structural capacity of banana leaf stalks, a material system which is stiff in bending yet highly flexible in torsion. Of interest is a functional robustness which allows for the negotiation of both self-weight and wind loading for a large and fully integrated leaf structure. Methods of simulation and meta-heuristics are developed to address the continual material and topological differentiation of the banana leaf stalk. Case studies are based upon examination of specimens from the species Musa acuminata and Ensete ventricosum. Mechanical properties and geometric descriptions of isolated moments within the stalk provide the basis for computational comparison. Fundamental properties and behaviors are extracted from the plant specimens, yet a full description is not possible because of the plant’s intricate spatial structure. In this case, the computational means serve to elucidate upon the behavior of the complete system as well as provide avenues for exploring its variants. This paper describes an extensible and calibrated framework which can foster enhanced biomimetic insights by explorations which are based upon but extend well beyond initial biological and/or technological precedents.}
}
@article{DENEF201893,
title = {Computational complexity of the landscape II—Cosmological considerations},
journal = {Annals of Physics},
volume = {392},
pages = {93-127},
year = {2018},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2018.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S000349161830068X},
author = {Frederik Denef and Michael R. Douglas and Brian Greene and Claire Zukowski},
keywords = {Computational complexity, String theory, Multiverse, Measures},
abstract = {We propose a new approach for multiverse analysis based on computational complexity, which leads to a new family of “computational” measure factors. By defining a cosmology as a space–time containing a vacuum with specified properties (for example small cosmological constant) together with rules for how time evolution will produce the vacuum, we can associate global time in a multiverse with clock time on a supercomputer which simulates it. We argue for a principle of “limited computational complexity” governing early universe dynamics as simulated by this supercomputer, which translates to a global measure for regulating the infinities of eternal inflation. The rules for time evolution can be thought of as a search algorithm, whose details should be constrained by a stronger principle of “minimal computational complexity”. Unlike previously studied global measures, ours avoids standard equilibrium considerations and the well-known problems of Boltzmann Brains and the youngness paradox. We also give various definitions of the computational complexity of a cosmology, and argue that there are only a few natural complexity classes.}
}
@article{KESICI2011472,
title = {Self-regulated learning strategies in relation with statistics anxiety},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {472-477},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000203},
author = {Şahin Kesici and Mustafa Baloğlu and M. Engin Deniz},
keywords = {Statistical anxiety, Statistics learning, Learning strategies, Metacognition},
abstract = {Dealing with students' attitudinal problems related to statistics is an important aspect of statistics instruction. Employing the appropriate learning strategies may have a relationship with anxiety during the process of statistics learning. Thus, the present study investigated multivariate relationships between self-regulated learning strategies and statistical anxiety using canonical correlation analysis (CCA). Three hundred twenty Turkish college students responded to the Motivated Strategies for Learning Questionnaire and the Statistical Anxiety Rating Scale. Of the group, 189 (59.1%) were women and 131 (40.9%) were men. Participants' ages ranged from 18 to 33years with a mean of 21.28years (SD=1.53). Bivariate correlation coefficients showed significant relationships between the dimensions of learning strategies and statistical anxiety. CCA showed that students who used more rehearsal, elaboration, organization, critical thinking, metacognitive regulation, time and study environment management, and effort regulation strategies experienced lower computational anxiety and had more positive attitudes toward statistics. Additionally, a combination of effort regulation and help seeking strategies is associated with test/class anxiety.}
}
@incollection{MOLE2022367,
title = {Executive/Cognitive Control},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {367-376},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-819641-0.00111-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128196410001110},
author = {Joseph Mole and Lisa Cipolotti},
keywords = {Frontal lobes, Active thought, Executive functioning, Fluid intelligence, Language, Focal lesions, Neuropsychology, Supervisory system, Reasoning, Lateralization of function},
abstract = {The capacity for active thought is arguably one of humanity's defining features. The frontal lobes are critically involved in active thinking. In this article we will consider what can be learned from the effects of frontal lobe lesions about: (1) the relationship between active thought and intelligence, (2) whether active thought can occur without language, and (3) the processes involved in active thinking. The evidence reviewed reveals that different forms of active thought and their essential pre-requisites can be fractionated and appear to be underpinned by different frontal areas. Hence, active thinking may be achieved by distinct, interacting cognitive processes.}
}
@article{BOSSE201239,
title = {A computational model for dynamics of desiring and feeling},
journal = {Cognitive Systems Research},
volume = {19-20},
pages = {39-61},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2012.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041712000228},
author = {Tibor Bosse and Mark Hoogendoorn and Zulfiqar A. Memon and Jan Treur and Muhammad Umair},
keywords = {Desire, Feeling, Computational model},
abstract = {In this paper a computational model is presented for how a desire triggers responses and feelings. The model shows how these feelings can be biased, for example due to addicting experiences in the past. Both the strength of a response and of the associated feeling result from a converging dynamic pattern modeled by reciprocal causal interactions between the two. The model has been used to conduct a number of simulation experiments under varying circumstances. Moreover, it has been evaluated by formal analysis of emerging patterns entailed by the model. Furthermore, it has been pointed out how the computational model can be applied within an ambient agent system supporting a human in not being tempted. In a simple example scenario it is shown such an ambient agent system is able to predict and assess a human’s desire state, and use this assessment to suggest alternatives to avoid falling for certain temptations.}
}
@article{SUTHAR2023122,
title = {The integrative approach of learning chemical engineering thermodynamics by using simulation-based exercises},
journal = {Education for Chemical Engineers},
volume = {45},
pages = {122-129},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S174977282300043X},
author = {Krunal J. Suthar and Milind H. Joshipura},
keywords = {Process simulation, Thermodynamics, Teaching-learning, Fluid package},
abstract = {The active learning integrative approach of simulation-based exercises along with the core course would help undergraduate students with more engaged learning. The present study describes the simulation approach using an open-source process simulator with the help of three simulation-based exercises. The first one exemplifies the importance of the selection of an appropriate fluid package. The second exercise presented in the study shows the effect of using optimized and default values of binary interaction parameters on VLE prediction of alcohol-ester systems. The small interactive simulation-based problems with expected outcomes were presented in the third exercise which makes the learning more engaging and interesting. The current study highlights an integrative approach to inculcating critical thinking and self-learning abilities using small simulation-based exercises while learning chemical engineering thermodynamics. Finally, a survey with closed- and open-ended questions was used to gather the opinions of students on the presented exercises. A short communication is needed that sheds light on the integrative approach of learning process simulation complementing the thermodynamic theory learning.}
}
@article{HUANG201727,
title = {A computational cognitive modeling approach to understand and design mobile crowdsourcing for campus safety reporting},
journal = {International Journal of Human-Computer Studies},
volume = {102},
pages = {27-40},
year = {2017},
note = {Special Issue on Mobile and Situated Crowdsourcing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301549},
author = {Yun Huang and Corey White and Huichuan Xia and Yang Wang},
keywords = {Mobile crowdsourcing, Cognitive computational method, Public safety, User contribution, Drift-diffusion decision model, Nudge mechanism},
abstract = {The under-reporting of public safety incidents is a long-standing issue. In this paper, we propose a computational cognitive modeling approach to understand and design a mobile crowdsourcing system for improving campus safety reporting. In particular, we adopt drift-diffusion models (DDMs) from cognitive psychology to investigate the effect of various factors on users’ reporting tendency for public safety. Our lab experiment and online study show consistent results on how location context impacts people's reporting decisions. This finding informs the design of a novel location-based nudge mechanism, which is tested in another lab experiment with 84 participants and proved to be effective in changing users’ reporting decisions. Our follow-up interview study further suggests that the influence of people's mobility patterns (e.g., expected walking distance) could explain why the nudge design is effective. Our work not only informs the design of mobile crowdsourcing for public safety reporting but also demonstrates the value of applying a computational cognitive modeling approach to address HCI research questions more broadly.}
}
@article{CHIASTRA20162102,
title = {Computational replication of the patient-specific stenting procedure for coronary artery bifurcations: From OCT and CT imaging to structural and hemodynamics analyses},
journal = {Journal of Biomechanics},
volume = {49},
number = {11},
pages = {2102-2111},
year = {2016},
note = {Selected Articles from the International Conference on CFD in Medicine and Biology (Albufeira, Portugal – August 30th - September 4th, 2015)},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2015.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0021929015006661},
author = {Claudio Chiastra and Wei Wu and Benjamin Dickerhoff and Ali Aleiou and Gabriele Dubini and Hiromasa Otake and Francesco Migliavacca and John F. LaDisa},
keywords = {Mathematical model, Finite element analysis, Computational fluid dynamics, Coronary bifurcation, Stent},
abstract = {The optimal stenting technique for coronary artery bifurcations is still debated. With additional advances computational simulations can soon be used to compare stent designs or strategies based on verified structural and hemodynamics results in order to identify the optimal solution for each individual’s anatomy. In this study, patient-specific simulations of stent deployment were performed for 2 cases to replicate the complete procedure conducted by interventional cardiologists. Subsequent computational fluid dynamics (CFD) analyses were conducted to quantify hemodynamic quantities linked to restenosis. Patient-specific pre-operative models of coronary bifurcations were reconstructed from CT angiography and optical coherence tomography (OCT). Plaque location and composition were estimated from OCT and assigned to models, and structural simulations were performed in Abaqus. Artery geometries after virtual stent expansion of Xience Prime or Nobori stents created in SolidWorks were compared to post-operative geometry from OCT and CT before being extracted and used for CFD simulations in SimVascular. Inflow boundary conditions based on body surface area, and downstream vascular resistances and capacitances were applied at branches to mimic physiology. Artery geometries obtained after virtual expansion were in good agreement with those reconstructed from patient images. Quantitative comparison of the distance between reconstructed and post-stent geometries revealed a maximum difference in area of 20.4%. Adverse indices of wall shear stress were more pronounced for thicker Nobori stents in both patients. These findings verify structural analyses of stent expansion, introduce a workflow to combine software packages for solid and fluid mechanics analysis, and underscore important stent design features from prior idealized studies. The proposed approach may ultimately be useful in determining an optimal choice of stent and position for each patient.}
}
@article{HOGENDOORN2022128,
title = {Perception in real-time: predicting the present, reconstructing the past},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {2},
pages = {128-141},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002886},
author = {Hinze Hogendoorn},
keywords = {perception, time, prediction, real-time, neural delays},
abstract = {We feel that we perceive events in the environment as they unfold in real-time. However, this intuitive view of perception is impossible to implement in the nervous system due to biological constraints such as neural transmission delays. I propose a new way of thinking about real-time perception: at any given moment, instead of representing a single timepoint, perceptual mechanisms represent an entire timeline. On this timeline, predictive mechanisms predict ahead to compensate for delays in incoming sensory input, and reconstruction mechanisms retroactively revise perception when those predictions do not come true. This proposal integrates and extends previous work to address a crucial gap in our understanding of a fundamental aspect of our everyday life: the experience of perceiving the present.}
}
@article{DOGAN2018464,
title = {Differing instructional modalities and cognitive structures: Linear algebra},
journal = {Linear Algebra and its Applications},
volume = {542},
pages = {464-483},
year = {2018},
note = {Proceedings of the 20th ILAS Conference, Leuven, Belgium 2016},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0024379517304172},
author = {Hamide Dogan},
keywords = {Mathematics education, Linear algebra, Thinking modes, Instructional modalities, Cognitive schemes},
abstract = {This paper discusses the aspects of twelve first-year linear algebra students' thinking modes displayed on their interview responses to questions addressing linear independence ideas. Studying thinking modes allowed us to make inferences about the role of differing instructional modalities in shaping one's cognitive structures.}
}
@incollection{RUNCO2023115,
title = {Chapter 4 - Biological Perspectives on Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {115-154},
year = {2023},
isbn = {978-0-08-102617-5},
doi = {https://doi.org/10.1016/B978-0-08-102617-5.00005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081026175000059},
author = {Mark A. Runco},
keywords = {Adoption studies, Altered states of consciousness, Cerebellum, Corpus callosum, Dopamine, Dreams, Drugs, Exercise, Genealogies, Genetics, Prefrontal cortex, Split brain, Stress},
abstract = {This chapter discusses biological perspectives on creativity. Some of the research on creativity as of late involves the brain and biological correlates of originality, novelty, and insight. Handedness has long been used as an indication of hemispheric dominance or hemisphericity, with right-handed people being compared with left-handed people. There are several reports of left-handed persons outnumbering the right-handed ones in creative and eminent samples. Hemisphericity and other important brain structures and processes contributing to creative thinking and behavior have more recently been studied with electroencephalogram (EEG), positron emission topography (PET), cerebral blood flow, and magnetic resonance imaging (MRI) techniques. Numerous EEG studies suggest that there are particular brain wave patterns and brain structures that are associated with creative problem-solving or at least with specific phases within the problem-solving process. EEGs suggest a complex kind of activity while individuals work on tasks indicative of creative potential. Much of the complexity disappears when those same individuals work on convergent thinking tasks. Research suggests that the prefrontal cortex plays an important role in creative thinking and behaviour.}
}
@article{DEUTSCH2018156,
title = {Computational mechanisms in genetic regulation by RNA},
journal = {Journal of Theoretical Biology},
volume = {458},
pages = {156-168},
year = {2018},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318304466},
author = {J.M. Deutsch},
abstract = {The evolution of the genome has led to very sophisticated and complex regulation. Because of the abundance of non-coding RNA (ncRNA) in the cell, different species will promiscuously associate with each other, suggesting collective dynamics similar to artificial neural networks. A simple mechanism is proposed allowing ncRNA to perform computations equivalent to neural network algorithms such as Boltzmann machines and the Hopfield model. The quantities analogous to the neural couplings are the equilibrium constants between different RNA species. The relatively rapid equilibration of RNA binding and unbinding is regulated by a slower process that degrades and creates new RNA. The model requires that the creation rate for each species be an increasing function of the ratio of total to unbound RNA. Similar mechanisms have already been found to exist experimentally for ncRNA regulation. With the overall concentration of RNA regulated, equilibrium constants can be chosen to store many different patterns, or many different input–output relations. The network is also quite insensitive to random mutations in equilibrium constants. Therefore one expects that this kind of mechanism will have a much higher mutation rate than ones typically regarded as being under evolutionary constraint.}
}
@article{LIGOMENIDES200910,
title = {The reality of Mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {227},
number = {1},
pages = {10-16},
year = {2009},
note = {Special Issue of Proceedings of NUMAN 2007 Conference: Recent Approaches to Numerical Analysis: Theory, Methods and Applications},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2008.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0377042708003257},
author = {Panos A. Ligomenides},
keywords = {Languages of mathematics, Mathematical reality, Information science, Cyber-world},
abstract = {The power of mathematics is discussed as a way of expressing reasoning, aesthetics and insight in symbolic non-verbal communication. The human culture of discovering mathematical ways of thinking in the enterprise of exploring the understanding of the nature and the evolution of our world through hypotheses, theories and experimental affirmation of the scientific notion of algorithmic and non-algorithmic ‘computation’, is examined and commended upon.}
}
@article{GARFIELD19844,
title = {Artificial intelligence: Using computers to think about thinking, part I: Representing knowledge},
journal = {Computer Compacts},
volume = {2},
number = {1},
pages = {4-9},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90071-4},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900714},
author = {Eugene Garfield}
}
@article{YAO199959,
title = {Evolutionary computation comes of age},
journal = {Cognitive Systems Research},
volume = {1},
number = {1},
pages = {59-64},
year = {1999},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(99)00006-6},
url = {https://www.sciencedirect.com/science/article/pii/S1389041799000066},
author = {Xin Yao},
abstract = {Evolutionary computation is a field of study of computational systems which uses ideas and gets inspirations from natural evolution and adaptation. Although the history of evolutionary computation can be traced back to 1950s, it was only in the last decade or so that the field started to grow rapidly. In recent years, there have been many successful applications of various evolutionary computation techniques in artificial intelligence, machine learning, numerical optimization, combinatorial optimization, etc. The theory of evolutionary computation has also been enriched greatly. There is a much better understanding of why and how evolutionary computation techniques work (or do not work) than five or six years ago. This article reports some of the latest developments presented at the recent 1999 Congress on Evolutionary Computation (CEC '99).}
}
@article{CLEMENTZ2023143,
title = {Clinical characterization and differentiation of B-SNIP psychosis Biotypes: Algorithmic Diagnostics for Efficient Prescription of Treatments (ADEPT)-1},
journal = {Schizophrenia Research},
volume = {260},
pages = {143-151},
year = {2023},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423002645},
author = {Brett A. Clementz and Ishanu Chattopadhyay and Rebekah L. Trotti and David A. Parker and Elliot S. Gershon and S. Kristian Hill and Elena I. Ivleva and Sarah K. Keedy and Matcheri S. Keshavan and Jennifer E. McDowell and Godfrey D. Pearlson and Carol A. Tamminga and Robert D. Gibbons},
abstract = {Clinically defined psychosis diagnoses are neurobiologically heterogeneous. The B-SNIP consortium identified and validated more neurobiologically homogeneous psychosis Biotypes using an extensive battery of neurocognitive and psychophysiological laboratory measures. However, typically the first step in any diagnostic evaluation is the clinical interview. In this project, we evaluated if psychosis Biotypes have clinical characteristics that can support their differentiation in addition to obtaining laboratory testing. Clinical interview data from 1907 individuals with a psychosis Biotype were used to create a diagnostic algorithm. The features were 58 ratings from standard clinical scales. Extremely randomized tree algorithms were used to evaluate sensitivity, specificity, and overall classification success. Biotype classification accuracy peaked at 91 % with the use of 57 items on average. A reduced feature set of 28 items, though, also showed 81 % classification accuracy. Using this reduced item set, we found that only 10–11 items achieved a one-vs-all (Biotype-1 or not, Biotype-2 or not, Biotype-3 or not) area under the sensitivity-specificity curve of .78 to .81. The top clinical characteristics for differentiating psychosis Biotypes, in order of importance, were (i) difficulty in abstract thinking, (ii) multiple indicators of social functioning, (iii) conceptual disorganization, (iv) severity of hallucinations, (v) stereotyped thinking, (vi) suspiciousness, (vii) unusual thought content, (viii) lack of spontaneous speech, and (ix) severity of delusions. These features were remarkably different from those that differentiated DSM psychosis diagnoses. This low-burden adaptive algorithm achieved reasonable classification accuracy and will support Biotype-specific etiological and treatment investigations even in under-resourced clinical and research environments.}
}
@article{LEROYER20112070,
title = {Numerical strategies to speed up CFD computations with free surface—Application to the dynamic equilibrium of hulls},
journal = {Ocean Engineering},
volume = {38},
number = {17},
pages = {2070-2076},
year = {2011},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2011.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0029801811002009},
author = {Alban Leroyer and Jeroen Wackers and Patrick Queutey and Emmanuel Guilmineau},
keywords = {Marine hydrodynamics, Free surface capturing, Dynamic equilibrium, RANS simulation},
abstract = {This article presents two numerical procedures to speed up computations when dealing with a Reynolds Averaged Navier Stokes (RANS) solver based on the Volume of Fluid (VoF) or multifluid method to treat the free surface. The first one is a time-splitting procedure for the volume fraction equation, enabling the use of larger time steps for the resolution of the flow, without penalizing accuracy. However, these large time steps destabilize the coupling with the ship motion simulation when computing a dynamic equilibrium position in marine applications. The second procedure is therefore a quasi-static approach to solve the coupled problem of dynamic equilibrium. A comparison of these procedures with classical simulations shows that numerical solutions of realistic problems can be obtained up to four times faster.}
}
@article{GERSTEIN200773,
title = {An interdepartmental Ph.D. program in computational biology and bioinformatics: The Yale perspective},
journal = {Journal of Biomedical Informatics},
volume = {40},
number = {1},
pages = {73-79},
year = {2007},
note = {Bio*Medical Informatics},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2006.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S1532046406000335},
author = {Mark Gerstein and Dov Greenbaum and Kei Cheung and Perry L. Miller},
keywords = {Bioinformatics, Computational biology, Educational programs, Curriculum},
abstract = {Computational biology and bioinformatics (CBB), the terms often used interchangeably, represent a rapidly evolving biological discipline. With the clear potential for discovery and innovation, and the need to deal with the deluge of biological data, many academic institutions are committing significant resources to develop CBB research and training programs. Yale formally established an interdepartmental Ph.D. program in CBB in May 2003. This paper describes Yale’s program, discussing the scope of the field, the program’s goals and curriculum, as well as a number of issues that arose in implementing the program. (Further updated information is available from the program’s website, www.cbb.yale.edu.)}
}
@article{BEDEWY2023101299,
title = {STEAM + X - Extending the transdisciplinary of STEAM-based educational approaches: A theoretical contribution},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101299},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101299},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300069X},
author = {Shereen El Bedewy and Zsolt Lavicza},
keywords = {STEAM, Design-based research, Culture, Technology, Design principles},
abstract = {This design-based research methodological paper is proposing a theoretical understanding in the form of STEAM + X framework that emerged from the empirical findings of implementing transdisciplinary STEAM practices featuring architecture, culture, and history. This paper shows how the proposed STEAM practices, involving creativities, to promote the integration of various disciplines with multiple cross-cultural iterations. These STEAM practices allow teachers to integrate cultural, architectural, environmental, or technological options into mathematics teaching and learning. These STEAM practices foster creativity and thinking skills in connecting disciplines in a transdisciplinary learning approach. Moreover, this paper introduces the study outcomes including the developed design principles and a framework that connects the underlying theoretical framework with emerging themes from our qualitative data analysis.}
}
@incollection{TOPLAK20221,
title = {1 - Defining cognitive sophistication in the development of judgment and decision-making},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {1-22},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000104},
author = {Maggie E. Toplak},
keywords = {Judgment and decision-making, Children and youth, Development, Cognitive sophistication, Critical thinking, Rationality, Stimulus equivalence, Miserly processing},
abstract = {Judgment and decision-making paradigms have been relatively well-studied in developmental samples. The measurement of these competencies in developmental samples has been of scientific interest. They have been recognized as having important implications for defining rational thinking in children and youth but also for teaching and training (such as, critical thinking in education). The origin of the theories and paradigms come from the adult literature, which has also undergone considerable progress in theoretical advancements and empirical studies over the last several years. The integration of our understanding from the work conducted in adults with consideration of developmental factors provides a way to advance our understanding of judgment and decision-making in children and youth. To accomplish this, establishing stimulus equivalence will be important given that these paradigms were first designed for adult samples. In addition, taking into account the rapid growth and change in cognitive capacities, that happen in development, are central for understanding performance on these paradigms. Using a working taxonomy of rational thinking based on adult samples, data from a longitudinal developmental study were used to empirically examine performance patterns on these paradigms.}
}
@article{STARK2021571,
title = {Autistic Cognition: Charting Routes to Anxiety},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {7},
pages = {571-581},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000899},
author = {Eloise Stark and James Stacey and Will Mandy and Morten L. Kringelbach and Francesca Happé},
keywords = {autism, cognition, anxiety, predictive processing, intolerance of uncertainty, black and white thinking},
abstract = {Autism Spectrum Conditions are typified by a divergence in cognitive style from that of the non-autistic population. Cognitive differences in autism may underlie significant strengths, but also increase vulnerability to psychopathology such as anxiety, which is a major problem for many autistic people. Many autistic people also do not respond to typical psychotherapeutic interventions, suggesting that autism-specific models and interventions are needed. We advance a theoretical model explaining how three constructs, attenuated predictions, intolerance of uncertainty, and ‘black and white thinking’, may interact to lead to anxiety in autism. We hope to start a dialogue surrounding how we can best address specific autistic cognitive differences that may lead to distress by developing appropriate models, measurements, and psychotherapeutic interventions.}
}
@article{YON2021R1026,
title = {Precision and the Bayesian brain},
journal = {Current Biology},
volume = {31},
number = {17},
pages = {R1026-R1032},
year = {2021},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2021.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0960982221010344},
author = {Daniel Yon and Chris D. Frith},
abstract = {Summary
Scientific thinking about the minds of humans and other animals has been transformed by the idea that the brain is Bayesian. A cornerstone of this idea is that agents set the balance between prior knowledge and incoming evidence based on how reliable or ‘precise’ these different sources of information are — lending the most weight to that which is most reliable. This concept of precision has crept into several branches of cognitive science and is a lynchpin of emerging ideas in computational psychiatry — where unusual beliefs or experiences are explained as abnormalities in how the brain estimates precision. But what precisely is precision? In this Primer we explain how precision has found its way into classic and contemporary models of perception, learning, self-awareness, and social interaction. We also chart how ideas around precision are beginning to change in radical ways, meaning we must get more precise about how precision works.}
}
@article{DAW2006199,
title = {The computational neurobiology of learning and reward},
journal = {Current Opinion in Neurobiology},
volume = {16},
number = {2},
pages = {199-204},
year = {2006},
note = {Cognitive neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2006.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0959438806000316},
author = {Nathaniel D Daw and Kenji Doya},
abstract = {Following the suggestion that midbrain dopaminergic neurons encode a signal, known as a ‘reward prediction error’, used by artificial intelligence algorithms for learning to choose advantageous actions, the study of the neural substrates for reward-based learning has been strongly influenced by computational theories. In recent work, such theories have been increasingly integrated into experimental design and analysis. Such hybrid approaches have offered detailed new insights into the function of a number of brain areas, especially the cortex and basal ganglia. In part this is because these approaches enable the study of neural correlates of subjective factors (such as a participant's beliefs about the reward to be received for performing some action) that the computational theories purport to quantify.}
}
@article{FAUL2024,
title = {Update on “Emotion and autobiographical memory”: 14 years of advances in understanding functions, constructions, and consequences},
journal = {Physics of Life Reviews},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524001301},
author = {Leonard Faul and Jaclyn H. Ford and Elizabeth A. Kensinger},
abstract = {Holland and Kensinger (2010) reviewed the literature on “Emotion and autobiographical memory.” They focused on two broad ways that emotions influence memory: (1) emotion during an event influences how the event is remembered, and (2) emotion and emotional goals during memory retrieval influence how past events are remembered. We begin by providing a brief update on the key points from that review. Holland and Kensinger (2010) also had noted a number of important avenues for future work. Here, we describe what has been learned about the functions of autobiographical memory and their reconstructive nature. Relatedly, we review more recent research on memory reconstruction in the context of visual perspective shifts, counterfactual thinking, nostalgia, and morality. This research has emphasized the reciprocal nature of the interactions between emotion and autobiographical memory: Not only do emotions influence memory, memories influence emotions. Next, we discuss advances that have been made in understanding the reciprocal relations between stress, mood, and autobiographical memory. Finally, we discuss the research that is situating emotional autobiographical memories within a social framework, providing a bedrock for collective memories. Despite the many advances of the past 14 years, many open questions remain; throughout the review we note domains in which we hope to see advances over the next decades.}
}
@incollection{WILLETT2018231,
title = {Chapter 8 - Application of Mathematical Models and Computation in Plant Metabolomics},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {231-254},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000080},
author = {Denis S. Willett and Caitlin C. Rering and Dominique A. Ardura and John J. Beck},
keywords = {Big data, Machine learning, Data science, Agriculture},
abstract = {The investigation and reporting of plant chemical constituents has greatly evolved over the course of natural products and phytochemical research. Starting from the extraction and identification of plant-based bioactive components, such as historical salicin or more recent paclitaxel, phytochemistry-based research now includes plant metabolomics that help delineate chemotaxonomy, phylogenetic biomarkers and the functional genetics of a plant’s response to biotic or abiotic stressors. Here, we examine the invaluable contributions of mathematical models and computation for analysing plant metabolomics data and discuss the analytics mindset, highlight best practices, provide example workflows, as well as introduce future opportunities. Important in this chapter is the application of statistical methods for the improved visualization and interpretation of plant metabolomics data and their relevance for future project planning.}
}
@article{FEKETE2011807,
title = {Towards a computational theory of experience},
journal = {Consciousness and Cognition},
volume = {20},
number = {3},
pages = {807-827},
year = {2011},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2011.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1053810011000365},
author = {Tomer Fekete and Shimon Edelman},
keywords = {Representation, Experience, Qualia, Computation, State space, Trajectory, Dynamics, Brain activation, Concept, Clustering},
abstract = {A standing challenge for the science of mind is to account for the datum that every mind faces in the most immediate – that is, unmediated – fashion: its phenomenal experience. The complementary tasks of explaining what it means for a system to give rise to experience and what constitutes the content of experience (qualia) in computational terms are particularly challenging, given the multiple realizability of computation. In this paper, we identify a set of conditions that a computational theory must satisfy for it to constitute not just a sufficient but a necessary, and therefore naturalistic and intrinsic, explanation of qualia. We show that a common assumption behind many neurocomputational theories of the mind, according to which mind states can be formalized solely in terms of instantaneous vectors of activities of representational units such as neurons, does not meet the requisite conditions, in part because it relies on inactive units to shape presently experienced qualia and implies a homogeneous representation space, which is devoid of intrinsic structure. We then sketch a naturalistic computational theory of qualia, which posits that experience is realized by dynamical activity-space trajectories (rather than points) and that its richness is measured by the representational capacity of the trajectory space in which it unfolds.}
}
@article{COMPTON2018392,
title = {The aprosody of schizophrenia: Computationally derived acoustic phonetic underpinnings of monotone speech},
journal = {Schizophrenia Research},
volume = {197},
pages = {392-399},
year = {2018},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2018.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996418300276},
author = {Michael T. Compton and Anya Lunden and Sean D. Cleary and Luca Pauselli and Yazeed Alolayan and Brooke Halpern and Beth Broussard and Anthony Crisafio and Leslie Capulong and Pierfrancesco Maria Balducci and Francesco Bernardini and Michael A. Covington},
keywords = {Acoustic resonance, Aprosody, Linguistics, Negative symptoms, Phonetics, Phonology, Psychosis, Schizophrenia},
abstract = {Objective
Acoustic phonetic methods are useful in examining some symptoms of schizophrenia; we used such methods to understand the underpinnings of aprosody. We hypothesized that, compared to controls and patients without clinically rated aprosody, patients with aprosody would exhibit reduced variability in: pitch (F0), jaw/mouth opening and tongue height (formant F1), tongue front/back position and/or lip rounding (formant F2), and intensity/loudness.
Methods
Audiorecorded speech was obtained from 98 patients (including 25 with clinically rated aprosody and 29 without) and 102 unaffected controls using five tasks: one describing a drawing, two based on spontaneous speech elicited through a question (Tasks 2 and 3), and two based on reading prose excerpts (Tasks 4 and 5). We compared groups on variation in pitch (F0), formant F1 and F2, and intensity/loudness.
Results
Regarding pitch variation, patients with aprosody differed significantly from controls in Task 5 in both unadjusted tests and those adjusted for sociodemographics. For the standard deviation (SD) of F1, no significant differences were found in adjusted tests. Regarding SD of F2, patients with aprosody had lower values than controls in Task 3, 4, and 5. For variation in intensity/loudness, patients with aprosody had lower values than patients without aprosody and controls across the five tasks.
Conclusions
Findings could represent a step toward developing new methods for measuring and tracking the severity of this specific negative symptom using acoustic phonetic parameters; such work is relevant to other psychiatric and neurological disorders.}
}
@incollection{CARLSON2017425,
title = {Chapter 20 - Computational Perspectives on Adult Neurogenesis},
editor = {Arjen {van Ooyen} and Markus Butz-Ostendorf},
booktitle = {The Rewiring Brain},
publisher = {Academic Press},
address = {San Diego},
pages = {425-441},
year = {2017},
isbn = {978-0-12-803784-3},
doi = {https://doi.org/10.1016/B978-0-12-803784-3.00020-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128037843000202},
author = {Kristofor D. Carlson and Fred Rothganger and James B. Aimone},
keywords = {Adult neurogenesis, structural plasticity, computational neural model, hippocampus, dentate gyrus},
abstract = {The continuous integration of young neurons into the adult brain represents a novel form of structural plasticity and has inspired the creation of numerous computational models to understand the functional role of adult neurogenesis. These computational models consist of abstract models that focus on the utility of new neurons in simple neural networks and biologically based models constrained by anatomical data that explore the role of new neurons in specific neural circuits such as the hippocampus. Simulation results from both classes of models have suggested a number of theoretical roles for neurogenesis such as increasing the capacity to learn novel information, promoting temporal context encoding, and influencing pattern separation. In this review, we discuss strategies and findings of past computational modeling efforts, current challenges and limitations, and new computational approaches pertinent to modeling adult neurogenesis.}
}
@incollection{SILVA20203,
title = {Chapter 1 - Introduction and overview of using computational fluid dynamics tools},
editor = {Valter Bruno Reis E. Silva and João Cardoso},
booktitle = {Computational Fluid Dynamics Applied to Waste-to-Energy Processes},
publisher = {Butterworth-Heinemann},
pages = {3-28},
year = {2020},
isbn = {978-0-12-817540-8},
doi = {https://doi.org/10.1016/B978-0-12-817540-8.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128175408000017},
author = {Valter Bruno Reis E. Silva and João Cardoso},
keywords = {Computer fluid dynamics, Waste-to-energy, Simulation workflow, Fluid dynamics history},
abstract = {Over the last decades, with the increasing computational power and numerical solvers efficiency, computational fluid dynamics (CFD) is broadly used to design, optimize, and predict the physical-chemical phenomena regarding energy-related processes. A set of elaborate mathematical models is governed by partial differential equations representing conservation laws for mass, momentum, and energy, alongside with theoretical and empirical correlation. Therefore, CFD simulation is a crucial asset to understand the influence of parameters of interest in these processes and related operation and optimization of the technology involved. This chapter discusses how CFD can be used advantageously over waste-to-energy processes, also outlining advantages, disadvantages, and main setbacks with such an approach.}
}
@article{RINGACH2009439,
title = {Spontaneous and driven cortical activity: implications for computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {439-444},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000786},
author = {Dario L Ringach},
abstract = {The traditional view of spontaneous neural activity as ‘noise’ has been challenged by recent findings suggesting that: (a) spontaneous activity in cortical populations is highly structured in both space and time, (b) the spatio-temporal structure of spontaneous activity is linked to the underlying connectivity of the cortical network, (c) spontaneous cortical activity interacts with external stimulation to generate responses to the individual presentations of a stimulus, (d) network connectivity is shaped in part by the statistics of natural signals and (e) ongoing cortical activity represents a continuous top-down prediction/expectation signal that interacts with incoming input to generate an updated representation of the world. These results can be integrated to provide a new framework for the study of cortical computation.}
}
@incollection{GARDNER20243,
title = {Chapter 1 - Scaling the smart city},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {3-25},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044318452900001X},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Interaction, IoT, Scalar, Scale, Scaling, Smart city, Techno-urban imaginary, Urban design, Urban technology},
abstract = {This chapter explores the smart city through the conceptual lens of scale, as a scale-making project and as a project that is subject to scaling processes. It explores how scalar notions figure in smart city discourses, and how the drive to scale shapes the prevailing approach to digital technology and urban space integration. It argues that deprioritizing the smart city's scalability logic can bring into view different ways of designing the integration of digital technologies and urban space that can better connect with the contextual and material specificities of local contexts and less attended to dimensions of urban livability. Rescaling the smart city to the local urban precinct scale and paying close attention to life-technology relations is further reasoned as a way to productively re-orient and extend thinking on the ethical significance of the smart city.}
}
@article{MILLER1990489,
title = {Towards a believable theory of planning: D. E. Wilkins. Practical Planning. San Mateo, CA: Morgan Kaufmann, 1988. Pp. xii + 205. $49.95. S. L. Friedman. E. K. Scholnick, and R. R. Cocking. Blueprints for Thinking, London/New York: Cambridge Univ. Press, 1987. Pp. xv + 559. $58.50 K. Hammond. Case-Based Planning. San Diego: Academic Press, 1989. Pp. xviii + 277. $34.95},
journal = {Journal of Mathematical Psychology},
volume = {34},
number = {4},
pages = {489-498},
year = {1990},
issn = {0022-2496},
doi = {https://doi.org/10.1016/0022-2496(90)90028-8},
url = {https://www.sciencedirect.com/science/article/pii/0022249690900288},
author = {David P. Miller}
}
@article{DAVIES2016617,
title = {Computational Screening of All Stoichiometric Inorganic Materials},
journal = {Chem},
volume = {1},
number = {4},
pages = {617-627},
year = {2016},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2016.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2451929416301553},
author = {Daniel W. Davies and Keith T. Butler and Adam J. Jackson and Andrew Morris and Jarvist M. Frost and Jonathan M. Skelton and Aron Walsh},
keywords = {functional materials, computational chemistry, materials design, solar energy, high-throughput screening, water splitting, perovskites, structure prediction, SDG7: Affordable and clean energy},
abstract = {Summary
Forming a four-component compound from the first 103 elements of the periodic table results in more than 1012 combinations. Such a materials space is intractable to high-throughput experiment or first-principle computation. We introduce a framework to address this problem and quantify how many materials can exist. We apply principles of valency and electronegativity to filter chemically implausible compositions, which reduces the inorganic quaternary space to 1010 combinations. We demonstrate that estimates of band gaps and absolute electron energies can be made simply on the basis of the chemical composition and apply this to the search for new semiconducting materials to support the photoelectrochemical splitting of water. We show the applicability to predicting crystal structure by analogy with known compounds, including exploration of the phase space for ternary combinations that form a perovskite lattice. Computer screening reproduces known perovskite materials and predicts the feasibility of thousands more. Given the simplicity of the approach, large-scale searches can be performed on a single workstation.}
}
@article{SHAHZAD2022102190,
title = {Thermal cooling process by nanofluid flowing near stagnating point of expanding surface under induced magnetism force: A computational case study},
journal = {Case Studies in Thermal Engineering},
volume = {36},
pages = {102190},
year = {2022},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2022.102190},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X22004361},
author = {Faisal Shahzad and Wasim Jamshed and Amjad Ali Pasha and Rabia Safdar and Md. Mottahir Alam and Misbah Arshad and Syed M. Hussain and Muhammad Bilal Hafeez and Marek Krawczuk},
keywords = {, , , , },
abstract = {This paper is dedicated to the exam of entropy age and research of the effect of mixing nanosolid additives over an extending sheet. In this review, Newtonian nanofluid version turned into researched at the actuated appealing field, heat radiation and variable heat conductivity results. With becoming modifications, the proven PDEs are moved into popular differential situations and paintings mathematically making use of a specific mathematical plan called the Keller box method (KBM). The ranges of different dimensionless parameters used in our study are volume fraction of nanoparticles 0.01≤φ≤0.04, magnetic parameter 0.5≤Λ≤2, thermal radiation 0.1≤Nr≤0.3, heat source/sink parameter 0.5≤Q0≤2, Prandtl number 5.7≤Pr≤6.2, variable thermal conductivity 0.1≤ε≤0.3, reciprocal magnetic Prandtl number 0.6≤λ∗≤1, Brinkman number 5≤Br≤15, Reynolds number 5≤Re≤15, which shows up during mathematical arrangement are shown as tables and charts.Positive modifications in heat radiation and heat conductivity affects increment the hotness pass coefficient of solar primarily based totally plane wings. Titanium alloy primarily based totally water (H2O) are taken into consideration for our research. We will likewise alternate the grouping of nanoparticles to pay attention on their impact on numerous dynamic barriers of the framework. We can see that because the Reynolds range and Brinkman range increment, the entropy increments. The thermodynamic exhibition of Titanium alloy-water (Ti6Al4V–H2O) nanofluid has been portrayed higher that of base nanofluid with comparable situations. Recorded hypothetical reproductions may be greater beneficial to similarly increase daylight primarily based totally nuclear strength frameworks.}
}
@incollection{ZHENG202411,
title = {Chapter Two - Reviewing the past enables us to learn},
editor = {Wenbo Zheng and Fei-Yue Wang},
booktitle = {Computational Knowledge Vision},
publisher = {Academic Press},
pages = {11-38},
year = {2024},
isbn = {978-0-443-21619-0},
doi = {https://doi.org/10.1016/B978-0-44-321619-0.00008-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044321619000008X},
author = {Wenbo Zheng and Fei-Yue Wang},
keywords = {Computer vision, Artificial intelligence, Knowledge, Knowledge-based vision, Visual information},
abstract = {This chapter reviews the history of computer vision and artificial intelligence. Computer vision is the field of artificial intelligence that studies how computers can simulate the visual system of humans or other living things. It aims to enable computers to perceive and understand through the processing of visual information based on images or videos. From the 20th century onward, computer vision theory has been progressively developed. King-Sun Fu proposed syntactically structured representation and computation and constructed a top-down computational theory of vision. In the 1970s, David Marr then combined the knowledge of neuroscience, psychology, and other subjects of his time to systematically formulate a computational theory of vision, which made it possible to develop a more rigorous theory of the processing of visual information. Since then, computer vision has been flourishing.}
}
@article{SANTOS2015127,
title = {Phenotypic plasticity, the Baldwin effect, and the speeding up of evolution: The computational roots of an illusion},
journal = {Journal of Theoretical Biology},
volume = {371},
pages = {127-136},
year = {2015},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022519315000715},
author = {Mauro Santos and Eörs Szathmáry and José F. Fontanari},
keywords = {Evolutionary search, Genetic algorithm, Learning, The Baldwin effect, Speed of evolution},
abstract = {An increasing number of dissident voices claim that the standard neo-Darwinian view of genes as ‘leaders’ and phenotypes as ‘followers’ during the process of adaptive evolution should be turned on its head. This idea is older than the rediscovery of Mendel’s laws of inheritance, with the turn-of-the-twentieth-century notion eventually labeled as the ‘Baldwin effect’ as one of the many ways in which the standard neo-Darwinian view can be turned around. A condition for this effect is that environmentally induced variation such as phenotypic plasticity or learning is crucial for the initial establishment of a trait. This gives the additional time for natural selection to act on genetic variation and the adaptive trait can be eventually encoded in the genotype. An influential paper published in the late 1980s claimed the Baldwin effect to happen in computer simulations, and avowed that it was crucial to solve a difficult adaptive task. This generated much excitement among scholars in various disciplines that regard neo-Darwinian accounts to explain the evolutionary emergence of high-order phenotypic traits such as consciousness or language almost hopeless. Here, we use analytical and computational approaches to show that a standard population genetics treatment can easily crack what the scientific community has granted as an unsolvable adaptive problem without learning. Evolutionary psychologists and linguists have invoked the (claimed) Baldwin effect to make wild assertions that should not be taken seriously. What the Baldwin effect needs are plausible case-histories.}
}
@article{LI20203666,
title = {The computational approaches of lncRNA identification based on coding potential: Status quo and challenges},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3666-3677},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304979},
author = {Jing Li and Xuan Zhang and Changning Liu},
keywords = {LncRNA identification, , Algorithm, Feature, Coding potential, sORF},
abstract = {Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data.}
}
@article{MACCORMAC1984207,
title = {Men and machines: The computational metaphor},
journal = {Technology in Society},
volume = {6},
number = {3},
pages = {207-216},
year = {1984},
note = {Special Issue Technology and Philosophy},
issn = {0160-791X},
doi = {https://doi.org/10.1016/0160-791X(84)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0160791X84900332},
author = {Earl R. MacCormac},
abstract = {In the 20th century the interpretation of the human mind and brain as a computer has replaced the 18th century metaphor of “man as a machine”. This paper traces the development of the computational metaphor with some attention to its 18th century roots, and then argues that its employment need not lead to the mechanization of thinking and the autonomy of technique. An awareness of the metaphoric and, therefore, hypothetical status of the computational metaphor will prevent technique from escaping intentional human control. This is a shortened version of a paper included in C. Mitcham and Alois Huning, eds., Philosophy and Technology II: Information Technology and Computers in Theory and Practice (Boston: D. Reidel, in press), and is included here with permission.}
}
@article{RAJ2021474,
title = {Assessment of antiviral potencies of cannabinoids against SARS-CoV-2 using computational and in vitro approaches},
journal = {International Journal of Biological Macromolecules},
volume = {168},
pages = {474-485},
year = {2021},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2020.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0141813020351783},
author = {Vinit Raj and Jae Gyu Park and Kiu-Hyung Cho and Pilju Choi and Taejung Kim and Jungyeob Ham and Jintae Lee},
keywords = {Cannabinols,  antiviral assay, SARS-CoV-2 and M enzyme},
abstract = {Effective treatment choices to the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) are limited because of the absence of effective target-based therapeutics. The main object of the current research was to estimate the antiviral activity of cannabinoids (CBDs) against the human coronavirus SARS-CoV-2. In the presented research work, we performed in silico and in vitro experiments to aid the sighting of lead CBDs for treating the viral infections of SARS-CoV-2. Virtual screening was carried out for interactions between 32 CBDs and the SARS-CoV-2 Mpro enzyme. Afterward, in vitro antiviral activity was carried out of five CBDs molecules against SARS-CoV-2. Interestingly, among them, two CBDs molecules namely Δ9 -tetrahydrocannabinol (IC50 = 10.25 μM) and cannabidiol (IC50 = 7.91 μM) were observed to be more potent antiviral molecules against SARS-CoV-2 compared to the reference drugs lopinavir, chloroquine, and remdesivir (IC50 ranges of 8.16–13.15 μM). These molecules were found to have stable conformations with the active binding pocket of the SARS-CoV-2 Mpro by molecular dynamic simulation and density functional theory. Our findings suggest cannabidiol and Δ9 -tetrahydrocannabinol are possible drugs against human coronavirus that might be used in combination or with other drug molecules to treat COVID-19 patients.}
}
@incollection{SLEPIAN2024516,
title = {4.01 - Synergistic Approaches of Cross-Fertilization and Feedback Together Driving and Advancing Health for All},
editor = {Kenneth S. Ramos},
booktitle = {Comprehensive Precision Medicine (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {516-523},
year = {2024},
isbn = {978-0-12-824256-8},
doi = {https://doi.org/10.1016/B978-0-12-824010-6.00081-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240106000812},
author = {Marvin J. Slepian},
keywords = {Digital Health, Multiscale, Nested pots, Personalized medicine, Pharmacogenomics, Point-of-care, Precision medicine, System synergies, Systems biology, Wearable technologies},
abstract = {We are at a point in time with rapid advances occurring in digital technologies, developing a range of new quantifiable markers termed “digital biomarkers,” which are increasingly utilized for diagnostics, as well as defining new operative mechanisms of health and disease. In parallel, significant advances have occurred in precision medicine, utilizing breakthroughs in “omics biology,” coupled with our understanding of their impact across systems in “systems biology.” Contemporaneously, a new approach to thinking of how health and disease evolve and impact an individual has emerged—that of considering mechanisms and impact across scales, i.e. on a “multi-scale” level, extending from the patient down to the molecule, and similarly from the patient up to society. In this chapter details of each of these approaches, their evolution and key current concepts are outlined. Moreover, the main theme and postulate developed in this chapter outlines the interconnectedness and the way in which each approach informs each other. In essence a cyclic, reinforcing, feedback loop exists, connecting digital technologies with precision and personalization approaches, across systems and scales, leading to enhanced diagnostics, the potential for new therapeutics and increasing insight into mechanisms. This cyclic flow of information will lead to new, more exacting technologies, with the ultimate outcome of enhanced efficacy, safety and improved health outcomes for patients and society.}
}
@article{BOHMANN2018185,
title = {Computational tools for topological coHochschild homology},
journal = {Topology and its Applications},
volume = {235},
pages = {185-213},
year = {2018},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2017.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0166864117306442},
author = {Anna Marie Bohmann and Teena Gerhardt and Amalie Høgenhaven and Brooke Shipley and Stephanie Ziegenhagen},
keywords = {Topological Hochschild homology, Coalgebra, Hochschild–Kostant–Rosenberg},
abstract = {In recent work, Hess and Shipley [18] defined a theory of topological coHochschild homology (coTHH) for coalgebras. In this paper we develop computational tools to study this new theory. In particular, we prove a Hochschild–Kostant–Rosenberg type theorem in the cofree case for differential graded coalgebras. We also develop a coBökstedt spectral sequence to compute the homology of coTHH for coalgebra spectra. We use a coalgebra structure on this spectral sequence to produce several computations.}
}
@article{BICER2021100823,
title = {Investigating creativity-directed tasks in middle school mathematics curricula},
journal = {Thinking Skills and Creativity},
volume = {40},
pages = {100823},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100823},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000389},
author = {Ali Bicer and Aylin Marquez and Karla Valesca Matute Colindres and Angela Ann Schanke and Libni Berenice Castellon and Luke M. Audette and Celal Perihan and Yujin Lee},
keywords = {Creativity-directed tasks, Creativity in mathematics textbooks, Creativity in mathematics curricula, Creative thinking in mathematics},
abstract = {Developing students’ creative thinking abilities while learning mathematics has been recently emphasized by many scholars, with many nations including creative thinking in mathematics as one of their overarching curriculum goals. The first purpose of the present study is to develop a framework to identify what type of mathematical tasks promote the mathematical creativity of students. The second purpose is to analyze to what degree the most commonly used three middle school curricula (i.e., Eureka, The Go Math!, and CPM) in the U.S. include creativity-directed tasks in their textbooks using this framework. Analyzing 1,500 mathematical tasks in each curriculum revealed that different curricula emphasize different dimensions of the creativity-directed tasks categories (i.e., open-ended tasks, problem-posing, connections, extensions, visualizations, and communication) presented in the framework. The result also revealed that open-ended problems are more common in the 6th grade textbooks than 7th and 8th grade textbooks regardless of the three selected middle school mathematics curricula. The implication of this study is to guide teachers with the strength and weakness of textbooks in terms of their inclusiveness of creativity-directed tasks to inform their teaching. Additionally, it is critical for curriculum developers to pay particular attention in including tasks that supporting each category and subcategory proportionately across the three years of middle school rather than emphasizing a few of them in one grade and almost completely ignoring them in previous or later years.}
}
@article{PU2023102577,
title = {Generative adversarial one-shot diagnosis of transmission faults for industrial robots},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102577},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102577},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000534},
author = {Ziqiang Pu and Diego Cabrera and Yun Bai and Chuan Li},
keywords = {One-shot diagnosis, Bi-directional generative adversarial network, Random forest, Industrial robot, Transmission system},
abstract = {Transmission systems of industrial robots are prone to get failures due to harsh operating environments. Fault diagnosis is of great significance for realizing safe operations for industrial robots. However, it is difficult to obtain faulty data in real applications. To migrate this issue, a generative adversarial one-shot diagnosis (GAOSD) approach is proposed to diagnose robot transmission faults with only one sample per faulty pattern. Signals representing kinematical characteristics were acquired by an attitude sensor. A bidirectional generative adversarial network (Bi-GAN) was then trained using healthy signals. Inspired by way of human thinking, the trained encoder in Bi-GAN was taken out to perform information abstraction for all signals. Finally, the abstracted signals were sent to a random forest for the one-shot diagnosis. The performance of the present technique was evaluated on an industrial robot experimental setup. Experimental results show that the proposed GAOSD has promising performance on the fault diagnosis of robot transmission systems.}
}
@article{CABITZA201765,
title = {The semiotics of configurations for the immanent design of interactive computational systems},
journal = {Journal of Visual Languages & Computing},
volume = {40},
pages = {65-90},
year = {2017},
note = {Semiotics, Human-Computer Interaction and End-User Development},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16300246},
author = {Federico Cabitza and Alvise Mattozzi},
keywords = {Semiotics of Configurations, Immanent design, End-User Development platforms, Document management systems, Electronic Health Record},
abstract = {In this paper the authors propose a novel semiotic approach to the design of interactive systems and computational systems, grounded in the most recent contributions within the debate around semiotic theory and analysis. This approach, that is here called Semiotics of Configurations (SoC), is proposed for its analytic power in describing material artifacts and settings with a purposely a-conceptualistic stance. The resulting analysis informs a kind of design that is aimed at reproducing and supporting the programs of action detected in the use of artifacts, as this use is “abducted” from the physical and material form of the artifacts themselves and from the observation of how content is transformed within and across them. This approach to design, called immanent design, has inspired a platform for the user-driven development and use of electronic documents and forms in cooperative and organizational domains. The framework is illustrated with a case drawn from a study performed in the domain of hospital work.}
}
@incollection{MISHRA2024231,
title = {Chapter Twelve - Unravelling the gut microbiome: Connecting with AI for deeper insights},
editor = {Akanksha Srivastava and Vaibhav Mishra},
series = {Methods in Microbiology},
publisher = {Academic Press},
volume = {55},
pages = {231-246},
year = {2024},
booktitle = {Artificial Intelligence in Microbiology: Scope and Challenges Volume 1},
issn = {0580-9517},
doi = {https://doi.org/10.1016/bs.mim.2024.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S058095172400028X},
author = {Vaibhav Mishra and Chhavi Atri and Raj Pandey and Akanksha Srivastava},
keywords = {Artificial intelligence, Gut microbes, Microbiology, Gastroenterology, Machine learning, Deep learning},
abstract = {Artificial intelligence (AI) remains a relatively unfamiliar concept for many, but its significance in the biomedical field is gaining recognition as the world undergoes transformative changes. Furthermore, AI possesses the potential to emulate critical thinking, reasoning, problem-solving abilities, and logical capacities of machines. Additionally, in the realm of gut microbiota research, AI emerges as a valuable asset. The synergy between gut microbes and AI not only holds promise for treating diverse gastroenterological diseases but also aids in comprehending the intricate relationships between gut microbes and microbes of resides into the other body parts. Moreover, AI facilitates a deeper understanding of different facets within gut-microbes interaction research. These direct communications are governed by chemical messengers, hormones, and neurotransmitters, detectable through biosensor chips employing machine learning (ML). Additionally, the indirect regulation of gut function by the brain via the hypothalamic-pituitary-adrenal (HPA) axis can be analysed using different computational models. This promising prospect remains largely unexplored, and in this chapter, our aim is to delve into and harness the potential of AI in gut microbial research.}
}
@article{DOGANDUNLAP20102141,
title = {Linear algebra students’ modes of reasoning: Geometric representations},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {8},
pages = {2141-2159},
year = {2010},
note = {Special issue devoted to the 15th ILAS Conference at Cancun, Mexico, June 16-20, 2008},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509004728},
author = {Hamide Dogan-Dunlap},
keywords = {Mathematics education, Linear algebra, Thinking modes, Geometric representations},
abstract = {Main goal of our research was to document differences on the types of modes linear algebra students displayed in their responses to the questions of linear independence from two different assignments. In this paper, modes from the second assignment are discussed in detail. Second assignment was administered with the support of graphical representations through an interactive web-module. Additionally, for comparison purposes, we briefly talk about the modes from the first assignment. First assignment was administered with the support of computational devices such as calculators providing the row reduced echelon form (rref) of matrices. Sierpinska’s framework on thinking modes (2000) was considered while qualitatively documenting the aspects of 45 matrix algebra students’ modes of reasoning. Our analysis revealed 17 categories of the modes of reasoning for the second assignment, and 15 categories for the first assignment. In conclusion, the findings of our analysis support the view of the geometric representations not replacing one’s arithmetic or algebraic modes but encouraging students to utilize multiple modes in their reasoning. Specifically, geometric representations in the presence of algebraic and arithmetic modes appear to help learners begin to consider the diverse representational aspects of a concept flexibly.}
}
@article{SALVATORE2024143,
title = {The affective grounds of the mind. The Affective Pertinentization (APER) model},
journal = {Physics of Life Reviews},
volume = {50},
pages = {143-165},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524000903},
author = {Sergio Salvatore and Arianna Palmieri and Raffaele {De Luca Picione} and Vincenzo Bochicchio and Matteo Reho and Maria Rita Serio and Giampaolo Salvatore},
keywords = {Affective Pertinentization model, Affective Landscape, Phase Space of Meaning, Meaning dimensionality},
abstract = {The paper presents the Affective Pertinentization model (APER), a theory of the affect and its role it plays in meaning-making. APER views the affect as the basic form of making sense of reality. It consists of a global, bipolar pattern of neurophysiological activity through which the organism maps the instant-by-instant variation of its environment. Such a pattern of neuropsychological activity is constituted by a plurality of bipolar affective dimensions, each of which maps a component of the environmental variability. The affect has a pluri-componential structure defining a multidimensional affective landscape that foregrounds (i.e., makes pertinent) a certain pattern of facets of the environment (e.g., its pleasantness/unpleasantness) relevant to survival, while backgrounding the others. Doing so, the affect grounds the following cognitive processes. Accordingly, meaning-making can be modeled as a function of the dimensionality of the affective landscape. The greater the dimensionality of the affective landscape, the more differentiated the system of meaning is. Following a brief review of current theories pertaining to the affect, the paper proceeds discussing the APER's core tenets – the multidimensional view of the affect, its semiotic function, and the concepts of Affective Landscape and Phase Space of Meaning. The paper then proceeds deepening the relationship between the APER model and other theories, highlighting how the APER succeeds in framing original conceptualizations of several challenging issues – the intertwinement between affect and sensory modalities, the manner in which the mind constitutes the content of the experience, the determinants of psychopathology, the intertwinement of mind and culture, and the spreading of affective forms of thinking and behaving in society. Finally, the unsolved issues and future developments of the model are briefly envisaged.}
}
@article{KALELIOGLU2015200,
title = {A new way of teaching programming skills to K-12 students: Code.org},
journal = {Computers in Human Behavior},
volume = {52},
pages = {200-210},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004288},
author = {Filiz Kalelioğlu},
keywords = {Improving classroom teaching, Programming and programming languages, Elementary education},
abstract = {This study attempts to investigate the effect of teaching code.org site on reflective thinking skills towards problem solving. More specifically, this study attempts to investigate whether there is a gender difference in terms of students’ reflective thinking skills towards problem solving. This triangulation study was conducted with 32 primary school students. The quantitative part of the study was conducted in pre-test/post-test comparison design of quasi-experimental design. The scores of reflective problem solving skills were gathered through the reflective thinking skill scale towards problem solving and the students’ performances in the code-org site were examined. In the qualitative part of the research, after the five-week experimental process, focus group interviews were conducted with ten students and a reflection paper from the IT teacher was analysed. According to the t-test results, teaching programming to primary school students in the code.org site did not cause any differences in reflective thinking skills towards problem solving. However, there is a slight increment in the means of female students’ reflective thinking skills towards problem solving over the males’ reflective thinking skills towards problem solving. On the other hand, qualitative data provided more information about the students’ experiences. Students developed a positive attitude towards programming, and female students showed that they were as successful as their male counterparts, and that programming could be part of their future plans.}
}
@article{PESKIN201213,
title = {Fostering symbolic interpretation during adolescence},
journal = {Journal of Applied Developmental Psychology},
volume = {33},
number = {1},
pages = {13-23},
year = {2012},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0193397311000931},
author = {Joan Peskin and Rebecca Wells-Jopling},
keywords = {Adolescence, Symbolic interpretation, Domain-specific knowledge, Poetry, Concrete scaffolds, Computational skills},
abstract = {Although by 11years children demonstrate impressive performance on various tasks that assess symbolic thinking in language development, research suggests that few young adolescents demonstrate evidence of symbolic processing when reading literature. This study investigated whether the difficulty might be due to a lack of adequate exposure to domain-specific knowledge. Students in the experimental groups in three age groups — preadolescence, middle adolescence and later adolescence — received concrete scaffolds designed to foster domain-specific knowledge of the symbolic process. A comparison of the experimental and control groups showed that students at all three ages who had experienced the scaffolds demonstrated significantly greater symbolic interpretation. Furthermore, despite concerns that the scaffolds might dampen the readers' personal response, the experimental groups at all three ages provided significantly higher enjoyment ratings of the test poems.}
}
@article{DEOLIVEIRA2023133,
title = {Transdisciplinary competency-based development in the process engineering subjects: A case study in Brazil},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {133-154},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000246},
author = {Roger Assis {de Oliveira} and Giovanna Milena Borges Hipólito and Ricardo de Freitas Fernandes Pontes and Paulo Henrique Nascimento Ferreira and Ricardo Sanz Moreira and José Plácido and Carlos Alexandre Moreira da Silva and Laura Plazas Tovar},
keywords = {Chemical engineering education, Competency, Learning outcome, Lifelong learning, Process systems engineering, Sustainability},
abstract = {Recently, the Brazilian Ministry of Education issued New Curriculum Guidelines for engineering programs. This paper encompasses a pedagogical intervention reflecting our efforts to incorporate these new guidelines into our engineering program. Specifically, this work has led to the competency-based rework of the following subjects offered in the Chemical Engineering Undergraduate Program at the Federal University of São Paulo (Unifesp): I) Modeling and Systems Analysis; II) Synthesis and Optimization of Chemical Processes; III) Chemical Process Simulation; IV) Process Analysis and Control; V) Chemical Process Design; and VI) Chemical Installations Design. Thirteen transdisciplinary competencies are integrated throughout the six subjects. Students highlighted design thinking, lifelong knowledge/learning, openness to act autonomously, teamwork, communication, and cooperation as essential qualities. Moreover, the greater focus on the process systems engineering approach involving the analysis, synthesis, design, and control of sustainable processes helps chemical engineers to face new challenges using renewable resources.}
}
@article{FITRIANI2023e14769,
title = {The differential item functioning (DIF) testing for the WOCC (Ways of Coping Checklist) instrument based on gender},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e14769},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14769},
url = {https://www.sciencedirect.com/science/article/pii/S240584402301976X},
author = {Arbania Fitriani and Dominikus David {Biondi Situmorang}},
keywords = {Differential item functioning, DIF, IRT, Stress, Coping stress, Psychometry},
abstract = {This study examined the Item Response Theory (IRT) method with statistical analysis to determine Differential Item Functioning (DIF) between men and women on the Ways of Coping Checklist (WOCC) Instruments revised by Vitaliano, Russo, Carr, Mauiro, and Becker (1985). Furthermore, it utilized primary data from 722 respondents with educational backgrounds ranging from senior high school, diplomas, and doctorates. The software packages QUEST, BILOG-MG, LISREL, and ITEMAN were used for analysis to address the concerns. Meanwhile, several items on the WOCC instrument indicated the presence of the DIF based on the calculation results using the IRT method with the QUEST and BILOG-MG software. According to the overall calculation for 1 PL and 2 PL using both tools, 8 items containing the DIF are distributed over the dimensions of problem solving, seeking social support, blaming self, and wishful thinking.}
}
@article{SAUNDERS20121024,
title = {Children without parents in the TANF caseload: Thinking beyond the child-only label},
journal = {Children and Youth Services Review},
volume = {34},
number = {5},
pages = {1024-1034},
year = {2012},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0190740912000771},
author = {Correne Saunders and Andrea Hetling and Pamela C. Ovwigho and Catherine E. Born},
keywords = {Kinship care, Child-only cases, Temporary Assistance for Needy Families, Relative caregiver, Child welfare policy},
abstract = {Child welfare policy has historically emphasized the positive impact relative caregivers can have on foster children. This emphasis coupled with recent changes in the composition of the Temporary Assistance for Needy Families (TANF) caseload has led to interest in child-only, relative caregiver cases. Child-only research, however, ignores cases in which the relative caregiver is also receiving benefits. Using the universe of welfare cases in Maryland in October 2005, this article compares and contrasts the demographic and case characteristics of parental and relative caregiver cases, also analyzing differences between cases with and without an adult receiving benefits. Findings indicate that relative caregivers have service needs that differ from those of parents and that recipient relative caregivers are more disadvantaged than child-only cases.}
}
@article{ESTRELLA20221,
title = {Early statistics in kindergarten: analysis of an educator's pedagogical content knowledge in lessons promoting informal inferential reasoning},
journal = {International Journal for Lesson and Learning Studies},
volume = {11},
number = {1},
pages = {1-13},
year = {2022},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-07-2021-0061},
url = {https://www.sciencedirect.com/science/article/pii/S2046825322000348},
author = {Soledad Estrella and Maritza Mendez-Reina and Raimundo Olfos and Jocelyn Aguilera},
keywords = {Pedagogical content knowledge, Early statistics, Informal inferential reasoning, Lesson study},
abstract = {Purpose
This study aims to describe the pedagogical content knowledge (PCK) of a kindergarten educator who implements a lesson plan about informal inferential reasoning designed in a lesson study group.
Design/methodology/approach
To this end, we analyzed teaching interventions in two kindergarten lessons focused on the playful task of tossing two coins, associated with inferential statistical reasoning. The study highlights the importance of arguing and promoting this reasoning to develop statistical thinking. It is crucial to recognize how early students can be subject to learning experiences that promote a language of uncertainty, assess the evidence provided by the data, and make generalizations.
Findings
The results reveal that while the educator demonstrated knowledge and skills relevant to the curriculum and conceptual teaching strategies, the understanding of the content by the students and the integration of the PCK components still present a challenge.
Practical implications
The lesson study collaborative teaching practices that promote PCK have proven effective for informing the design and implementation of instructional practices supporting the development of early statistical thinking in young children.
Originality/value
The study enriches the knowledge regarding the potential of the lesson study (LS) in the professional learning of kindergarten educators. It also contributes to a comprehensive approach based on authentic playful experiences in grade K that supports the development of early statistical thinking in young children.}
}
@incollection{BOSSE2017311,
title = {Chapter 13 - On Computational Models of Emotion Regulation and Their Applications Within HCI},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {311-337},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00013-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000136},
author = {Tibor Bosse},
keywords = {emotion regulation, computational modeling, dynamics, virtual characters, simulation-based training},
abstract = {Emotion regulation, or the ability to regulate one’s own and other people’s emotions, is an important skill for human beings, enabling them to function adequately in their social environment. The development of computational models of emotion regulation opens up a range of interesting applications in human–computer interaction, varying from virtual characters to simulation-based training systems. To provide more insight in the underlying mechanisms as well as the application areas of computational emotion regulation models, the current chapter provides an overview of the state-of-the-art in this area. After briefly reviewing the psychological literature on emotion generation and regulation, I will explain how these phenomena can be formalized into computational models. Next, a computational model of emotion regulation is presented in detail, and a number of resulting simulation runs are shown. The chapter concludes with a discussion of potential applications of such models.}
}
@article{NEGI2022100096,
title = {A deep dive into metacognition: Insightful tool for moral reasoning and emotional maturity},
journal = {Neuroscience Informatics},
volume = {2},
number = {4},
pages = {100096},
year = {2022},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2772528622000589},
author = {Sunder Kala Negi and Yaisna Rajkumari and Minakshi Rana},
keywords = {Metacognitive thinking, Moral reasoning, Emotional maturity, Artificial intelligence},
abstract = {The impact of metacognition on pupils' moral ideals and emotional development was investigated as well as it highlights on a collaborative research between metacognition and artificial intelligence that can bridge the gap (emotional, ethical, moral reasoning, common sense) existing in AI. A total of 200 pupils were selected in the study's sample. Participants (100 high metacognitive students and 100 low metacognitive students) were chosen at random and ranged in age from 17 to 21 years old. The influence of metacognition on students' moral ideals and emotional development was studied using a t-test. The outcome reveals that the mean score of moral reasoning on high metacognitive students as 66.77 and for low metacognitive students as 63.08, t value = 3.21, at the 0.01 level, statistically highly significant. The mean emotional maturity score for high metacognitive students was 29.99, while for low metacognitive students was 33.01, t value as 2.81, shows statistically significant at the 0.05 level. This demonstrates that the higher the score, the less emotionally stable the pupils are. The current findings show that metacognitive thinking has a major impact on moral reasoning and emotional maturity, and that as metacognition levels rise, so do moral reasoning and emotional maturity. Metacognition can strengthen the humanistic qualities which are majorly lacking in AI. In addition, there are new avenues being opened in the study of artificial intelligence via metacognitive study which is significant and futuristic.}
}
@incollection{HARDIN2024,
title = {Disinformation, Misinformation, and Fake News: The Latest Trends and Issues in Research},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00171-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001711},
author = {Greg Hardin},
keywords = {Disinformation, Evaluating sources, Fake news, Information literacy, Malinformation, Misinformation},
abstract = {Information comes in many forms and there are various ways in which false or fabricated information travels throughout the information ecosystem. Fake news, disinformation, misinformation, and malinformation have similarities and differences, but all have in common that they cause harm. Understanding misinformation in all its various forms is key to minimizing the negative effects on individuals and society. While it may be impossible to eradicate misinformation in all its various forms, librarians have a history of and are poised to promote information literacy and critical thinking skills.}
}
@article{AHMED20191,
title = {Computational intelligence based prediction of drilling rate of penetration: A comparative study},
journal = {Journal of Petroleum Science and Engineering},
volume = {172},
pages = {1-12},
year = {2019},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2018.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0920410518307824},
author = {Omogbolahan S. Ahmed and Ahmed A. Adeniran and Ariffin Samsuri},
keywords = {ROP prediction, Neural network, Least square support vector regression, Specific energy, Drilling efficiency, Extreme learning machine},
abstract = {Application of artificial intelligence in the accurate prediction of the rate of penetration (ROP), an important measure of drilling performance, has lately gained significant interest in oil and gas well drilling operations. Consequently, several computational intelligence techniques (CITs) for the prediction of ROP have been explored in the literature. This study explores the predictive capabilities of four commonly used CITs in the prediction of ROP and experimentally compare their predictive performance. The CIT algorithm utilizes predictors which are easily accessible continuous drilling data that have physical but complex relationship with ROP based on hydro-mechanical specific energy ROP model. The four CITs compared are the artificial neural network (ANN), extreme learning machine, support vector Regression and least-square support vector regression (LS-SVR). Two experiments were carried out; the first experiment investigates the comparative performance of the CITs while the second investigates the effect of reduced number of predictors on the performance of the models. The results show that all the CITs perform within acceptable accuracy with testing root mean square error range (RMSE) of 18.27–28.84 and testing correlation coefficient (CC) range of 0.71–0.94. LS-SVR has the best predictive performance in terms of accuracy with RMSE of 18.27 and CC of 0.94 while ANN has the best testing execution time at 0.03 s. Also utilizing the specific energy concept in chosen drilling parameters to be included among the predictors shows improved performance with five drilling parameters showing an improvement of 3%–9% in RMSE for LS-SVR in the two well studied. The utilization of the specific energy concept in the selection of the predictors in this study has demonstrated that the easily accessible drilling parameters have immense value to provide acceptable performance in the development of ROP model with CITs.}
}
@article{KAY20231697,
title = {Tasks and their role in visual neuroscience},
journal = {Neuron},
volume = {111},
number = {11},
pages = {1697-1713},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2023.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0896627323002180},
author = {Kendrick Kay and Kathryn Bonnen and Rachel N. Denison and Mike J. Arcaro and David L. Barack},
keywords = {task, brain, behavior, visual cortex, information processing, modeling},
abstract = {Summary
Vision is widely used as a model system to gain insights into how sensory inputs are processed and interpreted by the brain. Historically, careful quantification and control of visual stimuli have served as the backbone of visual neuroscience. There has been less emphasis, however, on how an observer’s task influences the processing of sensory inputs. Motivated by diverse observations of task-dependent activity in the visual system, we propose a framework for thinking about tasks, their role in sensory processing, and how we might formally incorporate tasks into our models of vision.}
}
@article{PEZZANO2024100078,
title = {Are we done with (Wordy) manifestos? Towards an introverted digital humanism},
journal = {Journal of Responsible Technology},
volume = {17},
pages = {100078},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000040},
author = {Giacomo Pezzano},
keywords = {Mediatic turn, Philosophy of technology, Learning, Book, Video game},
abstract = {Beginning with a reconstruction of the anthropological paradigms underlying The Vienna Manifesto and The Onlife Manifesto (§ 1.1), this paper distinguishes between two possible approaches to digital humanism: an extroverted one, principally engaged in finding a way to humanize digital technologies, and an introverted one, pointing instead attention to how digital technologies can re-humanize us, particularly our “mindframe” (§ 1.2). On this basis, I stress that if we take seriously the consequences of the “mediatic turn”, according to which human reason is finally recognized as mediatically contingent (§ 2.1), then we should accept that just as the book created the poietic context for the development of traditional humanism and its “bookish” idea of private and public reason, so too digital psycho-technologies today provide the conditions for the rise of a new humanism (§ 2.2). I then discuss the possible humanizing potential of digital simulated worlds: I compare the symbolic-reconstructive mindset to the sensorimotor mindset (§ 3.1), and I highlight their respective mediological association with the book and the video game, advocating for the peculiar thinking and reasoning affordances now offered by the new digital psycho-technologies (§ 3.2).}
}
@article{BROCAS2021105366,
title = {Value computation and modulation: A neuroeconomic theory of self-control as constrained optimization},
journal = {Journal of Economic Theory},
volume = {198},
pages = {105366},
year = {2021},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105366},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121001836},
author = {Isabelle Brocas and Juan D. Carrillo},
keywords = {Neuroeconomic theory, Multiple brain systems, Self-control, Cue-triggered behavior, Self-regulation},
abstract = {We develop a theory based on the evidence reported in Hare et al. (2009) to explain consumption of goods that feature a low-order attribute (e.g., taste) and a high-order attribute (e.g., health). One brain system with access to the low-order attribute computes the goal value of consumption while another brain system can modulate this value, at a cost, by transmitting information regarding the high-order attribute. We determine the optimal modulation and consumption strategy as a function of the cost of information transmission and the environment. We show that in healthy environments, modulation is used to signal surprisingly unhealthy goods so as to trigger abstinence when consumption would ordinarily occur. Conversely, in unhealthy environments, modulation is used to signal surprisingly healthy choices so as to trigger consumption when abstinence would ordinarily occur. From an outside perspective, individuals may appear to under-regulate their choices (self-indulgence) but also to over-regulate them (self-restraint). Both modulation and decisions are affected by factors orthogonal to the decision problem. In particular, taxing executive functions results in less modulation and more inefficient behavior. Finally, the model can shed light on issues related to eating disorders, present-biased preferences, habit formation and compulsive behavior.}
}
@article{DAVELAAR2018175,
title = {Mechanisms of Neurofeedback: A Computation-theoretic Approach},
journal = {Neuroscience},
volume = {378},
pages = {175-188},
year = {2018},
note = {Neurofeedback and Functional Enhancement: Mechanisms, Methodology, Behavioral and Clinical Applications},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2017.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S030645221730386X},
author = {Eddy J. Davelaar},
keywords = {neurofeedback, electroencephalography, computational neuroscience, computer model},
abstract = {Neurofeedback training is a form of brain training in which information about a neural measure is fed back to the trainee who is instructed to increase or decrease the value of that particular measure. This paper focuses on electroencephalography (EEG) neurofeedback in which the neural measures of interest are the brain oscillations. To date, the neural mechanisms that underlie successful neurofeedback training are still unexplained. Such an understanding would benefit researchers, funding agencies, clinicians, regulatory bodies, and insurance firms. Based on recent empirical work, an emerging theory couched firmly within computational neuroscience is proposed that advocates a critical role of the striatum in modulating EEG frequencies. The theory is implemented as a computer simulation of peak alpha upregulation, but in principle any frequency band at one or more electrode sites could be addressed. The simulation successfully learns to increase its peak alpha frequency and demonstrates the influence of threshold setting – the threshold that determines whether positive or negative feedback is provided. Analyses of the model suggest that neurofeedback can be likened to a search process that uses importance sampling to estimate the posterior probability distribution over striatal representational space, with each representation being associated with a distribution of values of the target EEG band. The model provides an important proof of concept to address pertinent methodological questions about how to understand and improve EEG neurofeedback success.}
}
@article{CUADRA20161223,
title = {Computational intelligence in wave energy: Comprehensive review and case study},
journal = {Renewable and Sustainable Energy Reviews},
volume = {58},
pages = {1223-1246},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.12.253},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115016366},
author = {L. Cuadra and S. Salcedo-Sanz and J.C. Nieto-Borge and E. Alexandre and G. Rodríguez},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Wave energy converters, Environmental impact},
abstract = {Wind-generated wave energy is a renewable energy source that exhibits a huge potential for sustainable growth. The design and deployment of wave energy converters at a given location require the prediction of the amount of available wave energy flux. This and other wave parameters can be estimated by means of Computational Intelligence techniques (Neural, Fuzzy, and Evolutionary Computation). This paper reviews those used in wave energy applications, both in the resource estimation and in the design and control of wave energy converters. In particular, most of the applications of Neural Computation techniques, considered here in a broad sense, focus on the prediction of a variety of wave energy parameters by means of Multilayer Perceptrons and, at a lesser extent, by Support Vector Machines, and Extreme Learning Machines. Fuzzy Computation is also applied to estimate wave parameters and control floating wave energy converter. Evolutionary Computation algorithms are used to estimate parameters and design wave energy collectors. We complete this paper with a case study that illustrates, for the first time to the best of our knowledge, the potential of hybridizing a Coral Reefs Optimization algorithm with an Extreme Learning Machine to tackle the problem of significant wave height reconstruction.}
}
@article{SAYHAN201714166,
title = {Computational investigation and comparison of hydrogen storage properties of B24N24 and Al24N24 nanocages},
journal = {International Journal of Hydrogen Energy},
volume = {42},
number = {20},
pages = {14166-14180},
year = {2017},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2017.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0360319917314490},
author = {Sinan Sayhan and Armağan Kinal},
keywords = {Boron nitride nanocages, Aluminum nitride nanocages, Hyrdogen storage materials, BN, AlN, The DFT methods},
abstract = {In this study, hydrogen storage properties of the B24N24 and Al24N24 nanocages have been computationally investigated by the DFT method whose suitability was determined with a thorough methodological analysis. This analysis includes comparison of the performances of a number of DFT functionals against the CCSD(T) method for the determination of the best DFT method that is able to accurately model H2-BN and H2-AlN systems. The ɷB97X-D, B3LYP-D2, PBEPBE-D2, BHandH methods produced results close to that of the reference CCSD(T) method. Of all methods studied, ɷB97X-D, showing the best performance, is found to be the most appropriate DFT method for H2-B24N24 and Al24N24 systems including dispersive interactions between hydrogen and the host molecule. The ɷB97X-D calculations result in that H2 molecule make the tightest adsorptive bond with Al atom in Al24N24 having an adsorption energy of −0.116 eV, by forming much more stable complex than the H2-B24N24 one. This indicates that Al24N24 has better exohedral hydrogen storage properties. The calculations also revealed that H2 molecules cannot pass through hexagonal rings of B24N24 instead they chemisorb on the cage atoms by breaking BN bond while they can pass through hexagonal rings of Al24N24 without making any damage in the Al–N bond, leading the fact that the Al–N bond is stronger than the B–N bond. Moreover, endohedral addition of H2 molecules up to three can form thermodynamically stable nH2@Al24N24 complexes while endohedral hydrogen addition to B24N24 destabilizes the complexes. Thus, the Al24N24 nanocage is not only structurally more stable than B24N24 nanocage, but also it can accommodate more hydrogen molecules, so it is better candidate for both endohedrally and exohedrally hydrogen storage compared to B24N24.}
}
@article{GIOT2013788,
title = {Fast computation of the performance evaluation of biometric systems: Application to multibiometrics},
journal = {Future Generation Computer Systems},
volume = {29},
number = {3},
pages = {788-799},
year = {2013},
note = {Special Section: Recent Developments in High Performance Computing and Security},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12000362},
author = {Romain Giot and Mohamad El-Abed and Christophe Rosenberger},
keywords = {Biometrics, Authentication, Error estimation, Access control},
abstract = {The performance evaluation of biometric systems is a crucial step when designing and evaluating such systems. The evaluation process uses the Equal Error Rate (EER) metric proposed by the International Organization for Standardization (ISO/IEC). The EER metric is a powerful metric which allows easily comparing and evaluating biometric systems. However, the computation time of the EER is, most of the time, very intensive. In this paper, we propose a fast method which computes an approximated value of the EER. We illustrate the benefit of the proposed method on two applications: the computing of non parametric confidence intervals and the use of genetic algorithms to compute the parameters of fusion functions. Experimental results show the superiority of the proposed EER approximation method in term of computing time, and the interest of its use to reduce the learning of parameters with genetic algorithms. The proposed method opens new perspectives for the development of secure multibiometrics systems by speeding up their computation time.}
}
@article{YANG2023106838,
title = {Neuromorphic electronics for robotic perception, navigation and control: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {106838},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106838},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623010229},
author = {Yi Yang and Chiara Bartolozzi and Haiyan H. Zhang and Robert A. Nawrocki},
keywords = {Neuromorphic electronics, Organic and flexible electronic materials, Neuromorphic robot, Perception, Navigation, Control, SLAM, Path planning},
abstract = {Neuromorphic electronics have great potential in the emulation of the sensory, cognitive, self-learning, and actuating functions of robots. While typically implemented in rigid silicon, emerging technologies in organic and flexible electronic materials have also led to tremendous advances in the development of neuromorphic perception systems. However, a comprehensive review of the contribution/role of organic neuromorphic electronics for robotic applications is still missing. This review presents advancements in silicon-based and organic neuromorphic electronics for intelligent robot development, focusing on perception, navigation, and learning-based control. Organic synaptic devices, along with dynamic vision sensors, enable diverse forms of sensory-enabled computational perception, offering tunability, stability, low power consumption, and conformal substrates. Integration of simultaneous localization and mapping techniques and path planning algorithms empowers robots to efficiently navigate, build accurate maps, and make informed decisions. Different learning algorithms and their hardware implementations in neuromorphic robotic control are explored, enabling robots to learn and adapt to dynamic environments. The review highlights the potential of neuromorphic electronics for sensing, thinking, and acting in advanced robotic systems. Organic, inorganic, and hybrid materials are discussed for implementing perception, navigation, and control in robots. Future research directions in the field are outlined. Leveraging various neuromorphic electronics unlocks the full potential of intelligent robotic systems for diverse applications.}
}
@incollection{MARS20253,
title = {What every cognitive neuroscientist should know about prefrontal cortex evolution},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00127-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801001273},
author = {Rogier B. Mars},
keywords = {Prefrontal cortex, Brain evolution, Foraging, Granular prefrontal cortex, Dorsolateral prefrontal cortex, Cognitive control, Comparative neuroscience, Primate, Connectivity, Human},
abstract = {Most theories of cognitive control assign a vital role to human prefrontal cortex (PFC). Although models of PFC function are abundant, most fail to capture the complexity of this part of the brain. Here we argue that an improved understanding of the evolution of PFC can aid in the formulation of better models. By better understanding what PFC is, why it evolved, and what benefit it provided to our ancestors, we can constrain our thinking and put the plethora of neuroimaging data showing PFC activation into context.}
}
@article{LORD2023490,
title = {The sustainability of the gig economy food delivery system (Deliveroo, UberEATS and Just-Eat): Histories and futures of rebound, lock-in and path dependency},
journal = {International Journal of Sustainable Transportation},
volume = {17},
number = {5},
pages = {490-502},
year = {2023},
issn = {1556-8318},
doi = {https://doi.org/10.1080/15568318.2022.2066583},
url = {https://www.sciencedirect.com/science/article/pii/S1556831822007018},
author = {Carolynne Lord and Oliver Bates and Adrian Friday and Fraser McLeod and Tom Cherrett and Antonio Martinez-Sykora and Andy Oakey},
keywords = {Gig economy couriers, path dependence, rebounds, sustainability, systems thinking},
abstract = {ABSTRACT
Online food delivery has transformed the last-mile of food and grocery delivery, with unnoticed yet often significant impacts upon the transport and logistics network. This new model of food delivery is not just increasing congestion in urban centers though, it is also changing the contours and qualities of those doing delivery—namely through gig economy work. This new system of food consumption and provision is rapidly gaining traction, but assessments around its current and future sustainability tend to hold separate the notions of social, environmental and economic sustainability—with few to date working to understand how these can interact, influence and be in conflict with one another. This paper seeks to work with this broader understanding of sustainability, whilst also foregrounding the perspectives of gig economy couriers who are often marginalized in such assessments of the online food delivery system. We make use of systems thinking and Campbell’s conflict model of sustainability to do this. In assessing the online food delivery in this way, we seek to not only provide a counternarrative to some of these previous assessments, but to also challenge those proposing the use of gig economy couriers as an environmentally sustainable logistics intervention in other areas of last-mile logistics to consider how this might impact the broader sustainability of their system, now and in the future.}
}