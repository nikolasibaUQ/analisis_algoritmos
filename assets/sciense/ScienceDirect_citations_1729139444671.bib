@incollection{DIX2003381,
title = {CHAPTER 14 - Upside-Down ∀s and Algorithms—Computational Formalisms and Theory},
editor = {John M. Carroll},
booktitle = {HCI Models, Theories, and Frameworks},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {381-429},
year = {2003},
series = {Interactive Technologies},
isbn = {978-1-55860-808-5},
doi = {https://doi.org/10.1016/B978-155860808-5/50014-9},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608085500149},
author = {Alan Dix}
}
@article{BERNALMANRIQUE202086,
title = {Effect of acceptance and commitment therapy in improving interpersonal skills in adolescents: A randomized waitlist control trial},
journal = {Journal of Contextual Behavioral Science},
volume = {17},
pages = {86-94},
year = {2020},
issn = {2212-1447},
doi = {https://doi.org/10.1016/j.jcbs.2020.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S2212144720301551},
author = {Koryn N. Bernal-Manrique and María B. García-Martín and Francisco J. Ruiz},
keywords = {Acceptance and commitment therapy, Interpersonal skills, Emotional disorders, Psychological flexibility, Repetitive negative thinking},
abstract = {This parallel randomized controlled trial evaluated the effect of acceptance and commitment therapy (ACT) focused on repetitive negative thinking (RNT) versus a waitlist control (WLC) in improving interpersonal skills in adolescents with problems of social and school adaptation. Forty-two adolescents (11–17 years) agreed to participate. Participants were allocated through simple randomization to the intervention condition or the waitlist control condition. The intervention was a 3-session, group-based, RNT-focused ACT protocol. The primary outcome was the performance on a test of interpersonal skills (Interpersonal Conflict Resolution Assessment, ESCI). At posttreatment, repeated measures ANOVA showed that the intervention was efficacious in increasing overall interpersonal skills (d = 2.62), progress in values (d = 1.23), and reducing emotional symptoms (d = 0.98). No adverse events were found. A brief RNT-focused ACT intervention was highly efficacious in improving interpersonal skills and reducing emotional symptoms in adolescents.}
}
@article{GERPOTT2024101783,
title = {New ways of seeing: Four ways you have not thought about Registered Reports yet},
journal = {The Leadership Quarterly},
volume = {35},
number = {2},
pages = {101783},
year = {2024},
issn = {1048-9843},
doi = {https://doi.org/10.1016/j.leaqua.2024.101783},
url = {https://www.sciencedirect.com/science/article/pii/S1048984324000122},
author = {Fabiola H. Gerpott and Roman Briker and George Banks},
keywords = {Registered Reports, Open Science, Transparency, Quantitative, Qualitative, Leadership},
abstract = {The Leadership Quarterly has helped as a pioneer in accepting Registered Reports (RRs), a submission format where authors provide the introduction, theory section, and methods of their paper for peer review before data collection. Proud but never satisfied, we aim to further boost the number of suitable RR submissions due to our firm belief in their potential for fostering transparent, high-impact research. To inspire authors to explore diverse data collection strategies and methods beyond experiments and survey-based (replication) studies, this work presents four distinct but equally suitable research formats for RRs: meta-analyses, qualitative research, computational approaches, and field intervention studies. Expanding prior research that has explored and promoted general practices and methodological standards for RRs, we offer unique recommendations for preparing an adequate RR proposal along each of these four RR avenues. Additionally, we provide a table of summary resources for authors, reviewers, and editors looking to engage more with RR. In conclusion, we envision a future where other top-tier journals and funding agencies follow The Leadership Quarterly by embracing the incorporation of RRs as a critical component of their strategic approach.}
}
@article{AMADEI2020120149,
title = {Revisiting positive peace using systems tools},
journal = {Technological Forecasting and Social Change},
volume = {158},
pages = {120149},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120149},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520309756},
author = {Bernard Amadei},
keywords = {Complex systems, Systems thinking, System dynamics, Cross-impact analysis, Network analysis, Positive peace, Peace geometry},
abstract = {This paper looks at peace with an integrated perspective. As a state, peace cannot be measured directly and requires the use of proxies and indicators. This paper revisits the positive peace index (PPI) introduced by the Institute for Economy and Peace (IEP) through the lens of systems thinking and modeling. Three sets of systems tools (cross-impact analysis, network analysis, and system dynamics) are proposed to explicitly account for the different levels of influence and dependence among the eight domains used to determine the PPI at the country level. Although more comprehensive than the original IEP formulation, the integrated approach proposed herein requires decisionmakers to be systems thinkers and able to conduct a detailed analysis of how the eight domains influence (impact) or depend on (sensitive to) each other. The proposed approach allows decisionmakers to capture the multidimensional and cross-disciplinary nature of positive peace better. This paper also shows that the three components of peace (positive, negative, and cultural) initially proposed by Johan Galtung can be represented using three-dimensional geometric features.}
}
@article{ZAKI2024100188,
title = {A data-driven framework to inform sustainable management of animal manure in rural agricultural regions using emerging resource recovery technologies},
journal = {Cleaner Environmental Systems},
volume = {13},
pages = {100188},
year = {2024},
issn = {2666-7894},
doi = {https://doi.org/10.1016/j.cesys.2024.100188},
url = {https://www.sciencedirect.com/science/article/pii/S2666789424000266},
author = {Mohammed T. Zaki and Lewis S. Rowles and Jeff Hallowell and Kevin D. Orner},
keywords = {Machine learning, Life cycle assessment, Techno-economic analysis, Pyrolysis, Hydrothermal carbonization, Carbon dioxide removal},
abstract = {Thermochemical conversion technologies are emerging as preferred resource recovery practices for managing animal manure in agricultural regions. Although the implementation of such technologies has been previously studied, difficulties exist in maintaining balance between high rate of resource recovery and low environmental, economic, and social impacts, particularly in rural regions with limited resources. We developed a data-driven framework by integrating machine learning with life cycle thinking that can be used as an open-source tool to help overcome these barriers. The framework was applied to compare two emerging technologies: pyrolysis versus hydrothermal carbonization for managing the excess poultry litter in a rural agricultural region. Among different machine learning models, random forest regression was the most successful to predict resource recovery of both technologies. Next, sustainability analysis indicated that the environmental (global warming), economic (annual worth), and social (system intrusiveness) impacts of pyrolysis was lower than hydrothermal carbonization. Finally, the framework revealed that implementation of pyrolysis at 600 °C for 1 h with the heating rate of 20 °C/min would result in the highest rate of resource recovery that corresponded to the lowest impacts. These results can be helpful in providing operational conditions for implementing emerging resource recovery technologies in rural agricultural regions.}
}
@article{HEILMAN20041,
title = {Computational models of epileptiform activity in single neurons},
journal = {Biosystems},
volume = {78},
number = {1},
pages = {1-21},
year = {2004},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2004.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0303264704000978},
author = {Avram D. Heilman and James Quattrochi},
keywords = {Paroxysmal depolarizing shifts (PDS), Sustained depolarizations (SD), Hippocampus, Autaptic CA1/CA3 pyramidal neuron, Voltage-gated Ca channels, Ca-dependent K channels},
abstract = {A series of original computational models written in NEURON of increasing physiological and morphological complexity were developed to determine the dominant causes of epileptiform behavior. Current injections to a model hippocampal pyramidal neuron consisting of three compartments produced the sustained depolarizations (SD) and simple paroxysmal depolarizing shifts (PDS) characteristic of ictal and interictal behavior in a cell, respectively. Our results indicate that SDs are the result of the semi-saturation of Na+, Ca2+ and K+ active channels, particularly the CaN, with regular Na+/K+ spikes riding atop a saturated depolarization; PDS rides on a similar semi-saturated depolarization whose shape depends more heavily on interactions between low-threshold voltage-gated Ca2+ channels (CaT) and Ca2+-dependent K+ channels. Our results reflect and predict recent physiological data, and we report here a cellular basis of epilepsy whose mechanisms reside mainly in the membrane channels, and not in specific morphology or network interactions, advancing a possible resolution to the cellular/network debate over the etiology of epileptiform activity.}
}
@article{NAZIDIZAJI2015318,
title = {Does the smartest designer design better? Effect of intelligence quotient on students’ design skills in architectural design studio},
journal = {Frontiers of Architectural Research},
volume = {4},
number = {4},
pages = {318-329},
year = {2015},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2015.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263515000394},
author = {Sajjad Nazidizaji and Ana Tomé and Francisco Regateiro},
keywords = {Architectural design studio, Intelligence quotient (IQ), Design education, Human factors, Design thinking},
abstract = {Understanding the cognitive processes of the human mind is necessary to further learn about design thinking processes. Cognitive studies are also significant in the research about design studio. The aim of this study is to examine the effect of designers intelligence quotient (IQ) on their designs. The statistical population in this study consisted of all Deylaman Institute of Higher Education architecture graduate students enrolled in 2011. Sixty of these students were selected via simple random sampling based on the finite population sample size calculation formula. The students’ IQ was measured using Raven’s Progressive Matrices. The students’ scores in Architecture Design Studio (ADS) courses from first grade (ADS-1) to fifth grade (ADS-5) and the mean scores of the design courses were used in determining the students’ design ability. Inferential statistics, as well as correlation analysis and mean comparison test for independent samples with SPSS, were also employed to analyze the research data. Results indicated that the students’ IQ, ADS-1 to ADS-4 scores, and the mean scores of the students’ design courses were not significantly correlated. By contrast, the students’ IQ and ADS-5 scores were significantly correlated. As the complexity of the design problem and designers’ experience increased, the effect of IQ on design seemingly intensified.}
}
@article{LI202231,
title = {Application Analysis of Artificial Intelligent Neural Network Based on Intelligent Diagnosis},
journal = {Procedia Computer Science},
volume = {208},
pages = {31-35},
year = {2022},
note = {7th International Conference on Intelligent, Interactive Systems and Applications},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922014478},
author = {Yukun Li},
keywords = {Intelligent diagnosis, artificial intelligence network, automobile fault diagnosis, the neural network},
abstract = {In recent years, the continuous development of computer science and AI technology makes the application prospect of artificial intelligence in fault diagnosis emerge. As a simulation technology of human thinking pattern, intelligent diagnosis technology can check and manage the monitoring target in real time to ensure the accuracy of data information. This paper introduces the basic principles of key artificial intelligence technologies in the field of sports, such as convolutional neural network, object detection, object tracking and action recognition. Then it analyzes the application status of intelligent diagnosis technology and artificial intelligence network under intelligent diagnosis, and puts forward the application of artificial intelligence neural network in automobile fault diagnosis based on examples. In the construction of the neural network system, the real-time collection of vehicle operation data can be analyzed, once the fault is found, the driver can be notified in time to avoid safety accidents. The author summarizes the existing research results on the application of artificial intelligence algorithm in intelligent diagnosis, in order to provide help for the subsequent research.}
}
@article{M2023120604,
title = {Design of a Cognitive Knowledge Representation Model to Assess the Reasoning Levels of Primary School Children},
journal = {Expert Systems with Applications},
volume = {231},
pages = {120604},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120604},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423011065},
author = {Srivani M. and Abirami Murugappan},
keywords = {Customized AI based teaching, Cognitive performance test, Reasoning coefficient, Cognition level, Knowledge representation, Cognitive metrics},
abstract = {Background and aim:
In recent days, the research on student’s intelligence level modelling is a challenging Artificial Intelligence (AI) task, which gains more attraction because it provides actionable insights to the tutor by analysing the intelligence level of the learners. Each learner’s knowledge, comprehension, and intellectual capacities are unique. It is critical to identify these capacities and provide learners, particularly slow learners, with the necessary knowledge. Cognitive Performance Test (CPT) is an essential component for assessing the knowledge level of students. The reasoning level or coefficient deals with the analysis of the thinking capability in a logical way. It also reflects the child’s learning potential. The main aim of the proposed system is to design a Cognitive Knowledge Representation Model (CKRM), which fuses Cognitive Performance Metrics (CPM) calculation and Reasoning Coefficient Calculation (RCC) algorithms to assess the student’s intelligence level. The result of the proposed system is stratification of students to three different ranges of reasoning coefficient.
Methods:
The CKRM consists of the following phases: data collection, statistical Exploratory Data Analysis (EDA), model building and analysis, which involve the assessment of the knowledge level using CPT and calculation of reasoning coefficient using First Order Logic (FOL), and finally model evaluation using cognitive evaluation metrics. CPM and RCC algorithms have been proposed in this paper to calculate the student’s reasoning coefficient by using the forward chaining FOL inference engine. The dataset is a real time data which consists of the academic and cognitive performance details of school students from classes 1 to 6 for the year 2019 to 2020. The academic data are collected from the Educational Management Information System (EMIS) maintained by the school. The cognitive performance data are collected by conducting the tests for the students using the memory training application called Lumosity.
Results:
The proposed system’s performance is evaluated using ten Machine Learning (ML) algorithms in which the Quadratic Discriminant Analysis achieved an accuracy of 0.97 for classes 1, 2, and 3. For classes 4, 5, and 6, nearly twelve ML algorithms are evaluated in which Random Forest (RF) Classifier achieved an accuracy of 0.98. Six math expert committee teachers concluded that the reasoning coefficient value was acceptable with an average accuracy of 0.92 for classes 1, 2, 3 and 0.9 for classes 4, 5, 6. In comparison to the pre-existing models employed in the prior research, it was determined that the created CKRM (academic and cognitive) was superior. The cognitive metrics such as taskability, Response Time (RT), knowledge capacity and utilization has also been evaluated. The average values of taskability, RT, knowledge capacity and knowledge utilization are 0.85, 0.81, 0.55, and 0.44.
Conclusion:
The ultimate goal is to make customized teaching easier; hence, this article involves determining a student’s cognitive level by estimating their reasoning coefficient. The suggested approach analyses and categorizes students’ cognitive abilities, such as memory, reasoning, problem solving, thinking, and logical reasoning, using three different reasoning coefficients. This approach assists teachers in determining the degree of intelligence of their students.}
}
@article{LI2021104369,
title = {Elementary effects analysis of factors controlling COVID-19 infections in computational simulation reveals the importance of social distancing and mask usage},
journal = {Computers in Biology and Medicine},
volume = {134},
pages = {104369},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104369},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521001633},
author = {Kelvin K.F. Li and Stephen A. Jarvis and Fayyaz Minhas},
keywords = {COVID-19, Agent-based modelling, Coronavirus, Simulation, SARS-COV-2, netlogo, Python, Epidemiology, Survival, Infectious diseases, VIRUS, Stochastic processes, Stochasticity, Social distancing, Masks, Isolation, Lockdown},
abstract = {COVID-19 was declared a pandemic by the World Health Organisation (WHO) on March 11th, 2020. With half of the world's countries in lockdown as of April due to this pandemic, monitoring and understanding the spread of the virus and infection rates and how these factors relate to behavioural and societal parameters is crucial for developing control strategies. This paper aims to investigate the effectiveness of masks, social distancing, lockdown and self-isolation for reducing the spread of SARS-CoV-2 infections. Our findings from an agent-based simulation modelling showed that whilst requiring a lockdown is widely believed to be the most efficient method to quickly reduce infection numbers, the practice of social distancing and the usage of surgical masks can potentially be more effective than requiring a lockdown. Our multivariate analysis of simulation results using the Morris Elementary Effects Method suggests that if a sufficient proportion of the population uses surgical masks and follows social distancing regulations, then SARS-CoV-2 infections can be controlled without requiring a lockdown.}
}
@article{AMACHER2020100022,
title = {Specificity in PDZ-peptide interaction networks: Computational analysis and review},
journal = {Journal of Structural Biology: X},
volume = {4},
pages = {100022},
year = {2020},
issn = {2590-1524},
doi = {https://doi.org/10.1016/j.yjsbx.2020.100022},
url = {https://www.sciencedirect.com/science/article/pii/S2590152420300040},
author = {Jeanine F. Amacher and Lionel Brooks and Thomas H. Hampton and Dean R. Madden},
keywords = {Protein-protein interactions, PDZ, Peptide-binding domains, Therapeutic targets},
abstract = {Globular PDZ domains typically serve as protein–protein interaction modules that regulate a wide variety of cellular functions via recognition of short linear motifs (SLiMs). Often, PDZ mediated-interactions are essential components of macromolecular complexes, and disruption affects the entire scaffold. Due to their roles as linchpins in trafficking and signaling pathways, PDZ domains are attractive targets: both for controlling viral pathogens, which bind PDZ domains and hijack cellular machinery, as well as for developing therapies to combat human disease. However, successful therapeutic interventions that avoid off-target effects are a challenge, because each PDZ domain interacts with a number of cellular targets, and specific binding preferences can be difficult to decipher. Over twenty-five years of research has produced a wealth of data on the stereochemical preferences of individual PDZ proteins and their binding partners. Currently the field lacks a central repository for this information. Here, we provide this important resource and provide a manually curated, comprehensive list of the 271 human PDZ domains. We use individual domain, as well as recent genomic and proteomic, data in order to gain a holistic view of PDZ domains and interaction networks, arguing this knowledge is critical to optimize targeting selectivity and to benefit human health.}
}
@article{FLATER2018144,
title = {Architecture for software-assisted quantity calculus},
journal = {Computer Standards & Interfaces},
volume = {56},
pages = {144-147},
year = {2018},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2017.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0920548917303069},
author = {David Flater},
keywords = {SI, Quantity, Unit, Uncertainty, Value, Unit 1},
abstract = {A quantity value, such as 5 kg, consists of a number and a reference (often an International System of Units (SI) unit) that together express the magnitude of a quantity. Many software libraries, packages, and ontologies that implement “quantities and units” functions are available. Although all of them begin with SI and associated practices, they differ in how they address issues such as ad hoc counting units, ratios of two quantities of the same kind, and uncertainty. This short article describes an architecture that addresses the complete set of functions in a simple and consistent fashion. Its goal is to encourage more convergent thinking about the functions and the underlying concepts so that the many disparate implementations, present and future, will become more consistent with one another.}
}
@incollection{ALISEDA2007431,
title = { - Logical, Historical and Computational Approaches},
editor = {Theo A.F. Kuipers},
booktitle = {General Philosophy of Science},
publisher = {North-Holland},
address = {Amsterdam},
pages = {431-513},
year = {2007},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-044451548-3/50010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444515483500100},
author = {Atocha Aliseda and Donald Gillies},
abstract = {Publisher Summary
This chapter focuses on the logical, historical and computational approaches to the philosophy of science. It discusses how the logical approach to philosophy of science was introduced by the Vienna Circle, and developed by them and their followers and associates. The logical approach to philosophy of science remained the dominant subject throughout the 1950s; but, from the early 1960s, it was challenged by a striking development of the historical approach. The historical approach was not introduced for the ﬁrst time in the 1960s. On the contrary, it had been developed by Mach and Duhem much earlier. Although, Mach and Duhem are cited by the Vienna Circle as important inﬂuences on their philosophy, the Vienna Circle did not adopt the historical features of these two thinkers. In the excitement generated by the new logic of Frege and Russell, history of science seems to have been temporarily forgotten. The general idea of the historical approach is not new in the 1960s, however, that decade saw striking developments in this approach. After Kuhn, the analysis of scientiﬁc revolutions became a major problem for philosophy of science, while Lakatos applied the historical approach to mathematics for the ﬁrst time.}
}
@article{SEVERENGIZ2018429,
title = {Influence of Gaming Elements on Summative Assessment in Engineering Education for Sustainable Manufacturing},
journal = {Procedia Manufacturing},
volume = {21},
pages = {429-437},
year = {2018},
note = {15th Global Conference on Sustainable Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2018.02.141},
url = {https://www.sciencedirect.com/science/article/pii/S235197891830180X},
author = {Mustafa Severengiz and Ina Roeder and Kristina Schindler and Günther Seliger},
keywords = {summative assessment, gamification, higher education, engineering education},
abstract = {Regarding the massive sustainability challenge mankind is currently facing, there is an indisputable need to implement sustainability as the key reference point into higher engineering education in order to prepare the stakeholders of tomorrow. This requires networked thinking on the part of the learner and increases the learning goals’ complexity dramatically. The actual achieved learning outcomes are often evaluated by assessing factual knowledge in higher education. However, it has been shown many times that students choose the examination format for orientation when studying. Thus, the authors propose a gamified summative assessment approach that requires networked thinking to direct students’ learning efforts towards broad competency building. In a study with 25 students of a master engineering course, the effects of a gamified examination design are investigated.}
}
@article{FATTAHITABASI20221151,
title = {Design and mechanism of building responsive skins: State-of-the-art and systematic analysis},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {6},
pages = {1151-1176},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S2095263522000565},
author = {Saba {Fattahi Tabasi} and Saeed Banihashemi},
keywords = {Responsive skin, Architectural design, Mechanism design},
abstract = {The demand to satisfy environmental and economic performance requirements of buildings highlights the application of the responsive skin facades in offering superior performance, as compared to conventional façades. With this respect, responsive skins have become a growing field of research during the recent decade while a thorough review of studies investigating their design and technology aspects is still missing. To fill the identified gap, this study aims to present a systematic literature review and state of the art in an untouched research area of the responsive skins, integrated with their geometric and mechanism design approaches. To this end, a total of 89 studies, collected from two major bibliographic databases of Scopus and Google Scholar from the first of 2010 to the mid of 2021, were reviewed and several classifications and analyses on the associated design thinking, skin systems and responsive mechanisms were presented. The gap analysis of the findings indicates that the lack of controllable substitution design for mechanical skins is one of the reasons preventing the application of responsive skins in construction industry. Furthermore, the gap between simulation and constructability and the relationship between the designed skin geometry with climatic analysis and performance provide basis for future studies.}
}
@article{BONCHEKDOKOW201444,
title = {Towards computational models of intention detection and intention prediction},
journal = {Cognitive Systems Research},
volume = {28},
pages = {44-79},
year = {2014},
note = {Special Issue on Mindreading},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000399},
author = {Elisheva Bonchek-Dokow and Gal A. Kaminka},
keywords = {Intention recognition, Intention prediction, Cognitive modeling},
abstract = {Intention recognition is one of the core components of mindreading, an important process in social cognition. Human beings, from age of 18months, have been shown to be able to extrapolate intentions from observed actions, even when the performer failed at achieving the goal. Existing accounts of intention recognition emphasize the use of an intent (plan) library, which is matched against observed actions for recognition. These therefore cannot account for recognition of failed sequences of actions, nor novel actions. In this paper, we begin to tackle these open questions by examining computational models for components of human intention recognition, which emphasize the ability of humans to detect and identify intentions in a sequence of observed actions, based solely on the rationality of movement (its efficiency). We provide a high-level overview of intention recognition as a whole, and then elaborate on two components of the model, which we believe to be at its core, namely, those of intention detection and intention prediction. By intention detection we mean the ability to discern whether a sequence of actions has any underlying intention at all, or whether it was performed in an arbitrary manner with no goal in mind. By intention prediction we mean the ability to extend an incomplete sequence of actions to its most likely intended goal. We evaluate the model, and these two components, in context of existing literature, and in a number of experiments with more than 140 human subjects. For intention detection, our model was able to attribute high levels of intention to those traces perceived by humans as intentional, and vice versa. For intention prediction as well, our model performed in a way that closely matched that of humans. The work highlights the intimate relationship between the ability to generate plans, and the ability to recognize intentions.}
}
@article{KRONICK2011435,
title = {Compensatory beliefs and intentions contribute to the prediction of caloric intake in dieters},
journal = {Appetite},
volume = {57},
number = {2},
pages = {435-438},
year = {2011},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2011.05.306},
url = {https://www.sciencedirect.com/science/article/pii/S0195666311004636},
author = {Ilana Kronick and Randy P. Auerbach and Christine Stich and Bärbel Knäuper},
keywords = {Compensatory beliefs, Compensatory intentions, Restraint, Disinhibition, Caloric intake, Experience sampling methodology},
abstract = {One cognitive process that impacts dieters’ decision to indulge is the activation of compensatory beliefs. Compensatory beliefs (CBs) are convictions that the consequences of engaging in an indulgent behaviour (eating cake) can be neutralized by the effects of another behaviour (skipping dinner). Using experience sampling methodology, this study hypothesized that, in addition to the cognitive processes associated with restraint and disinhibition, compensatory thinking contributes to the prediction of caloric intake. Results indicated that higher scores on CB, CI and TFEQ-D predicted a greater number of portions eaten signifying that, along with disinhibition, compensatory thinking predicts caloric intake in dieters.}
}
@article{COELHOLOPES2023103555,
title = {The structure of a strategic crisis management model: The context and characteristics of a brazilian community college},
journal = {International Journal of Disaster Risk Reduction},
volume = {87},
pages = {103555},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2023.103555},
url = {https://www.sciencedirect.com/science/article/pii/S2212420923000353},
author = {Gisele Silveira {Coelho Lopes} and Carlos Ricardo Rossetto and Micheline {Ramos de Oliveira} and Jorge Oneide Sausen and Rudimar {Antunes da Rocha}},
keywords = {Crisis management, Organizational strategy, Community university},
abstract = {This study presents the structure of a strategic crisis management model, considering the context and characteristics of a Brazilian community college. Strategic crisis management associated with coordination and control mechanisms theoretically underpinned the problem under study. It is a single case study, with grounded theory as the strategy for data treatment and content analysis to interpret and present the findings. In the model, the strategic and tactical stages systematized the dynamics of crisis management in a coordinated manner. Strategic crisis management was considered a continuous process rather than a strictly punctual one. The dynamism of the model's operationalization considered some premises that guided the behavior of the leadership and the crisis management team: i) pragmatic strategic thinking shaped by rationality; ii) quick responses in facing the crisis; iii) simplicity in actions; iv) reversible decisions susceptible to flexibilization; v) creativity and boldness to innovate and set new standards; v) collaboration for common causes.}
}
@article{JAYAPRAKASAM2015229,
title = {PSOGSA-Explore: A new hybrid metaheuristic approach for beampattern optimization in collaborative beamforming},
journal = {Applied Soft Computing},
volume = {30},
pages = {229-237},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615000435},
author = {S. Jayaprakasam and S.K.A. Rahim and Chee Yen Leow},
keywords = {Collaborative beamforming, Random array, Sidelobe suppression, Particle swarm optimization (PSO), Gravitational search algorithm (GSA)},
abstract = {A conventional collaborative beamforming (CB) system suffers from high sidelobes due to the random positioning of the nodes. This paper introduces a hybrid metaheuristic optimization algorithm called the Particle Swarm Optimization and Gravitational Search Algorithm-Explore (PSOGSA-E) to suppress the peak sidelobe level (PSL) in CB, by the means of finding the best weight for each node. The proposed algorithm combines the local search ability of the gravitational search algorithm (GSA) with the social thinking skills of the legacy particle swarm optimization (PSO) and allows exploration to avoid premature convergence. The proposed algorithm also simplifies the cost of variable parameter tuning compared to the legacy optimization algorithms. Simulations show that the proposed PSOGSA-E outperforms the conventional, the legacy PSO, GSA and PSOGSA optimized collaborative beamformer by obtaining better results faster, producing up to 100% improvement in PSL reduction when the disk size is small.}
}
@article{PARTTO2012442,
title = {Explaining failures in innovative thought processes in engineering design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {41},
pages = {442-449},
year = {2012},
note = {The First International Conference on Leadership, Technology and Innovation Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.04.053},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812009330},
author = {Minna Pärttö and Pertti Saariluoma},
keywords = {Microinnovation processes, engineering design, thought errors, thought failures},
abstract = {The aim of this study is to explore factors causing failures in innovative thought processes in engineering design. An innovation process is here understood as a complex and multi-phased thinking and problem solving process generating new and mostly unforeseeable solutions. The phases are partly overlapping and simultaneous. This complicated nature of innovation process demands a lot from innovation management, and thus it is not unusual that innovation processes fail. Identifying problems and shortcomings is important because it helps organizations to eliminate them in the future. This study focus on thought processes of individual participants in an innovation process, which is referred by us as microinnovation approach. This approach understands innovations as being based on human thinking.This study shows that factors related to knowledge, management and interaction are causing failures in engineering design. We found haste to be the most common reason for failures. Other contributing factors were lack of long-term thinking and inability to understand others’ perspective.}
}
@article{GENTILI2024150060,
title = {Living cells and biological mechanisms as prototypes for developing chemical artificial intelligence},
journal = {Biochemical and Biophysical Research Communications},
volume = {720},
pages = {150060},
year = {2024},
issn = {0006-291X},
doi = {https://doi.org/10.1016/j.bbrc.2024.150060},
url = {https://www.sciencedirect.com/science/article/pii/S0006291X24005965},
author = {Pier Luigi Gentili and Pasquale Stano},
keywords = {Chemical AI, Synthetic cell, Chemical neural networks, Neuromorphic engineering, Molecular fuzzy sets, Molecular computing},
abstract = {Artificial Intelligence (AI) is having a revolutionary impact on our societies. It is helping humans in facing the global challenges of this century. Traditionally, AI is developed in software or through neuromorphic engineering in hardware. More recently, a brand-new strategy has been proposed. It is the so-called Chemical AI (CAI), which exploits molecular, supramolecular, and systems chemistry in wetware to mimic human intelligence. In this work, two promising approaches for boosting CAI are described. One regards designing and implementing neural surrogates that can communicate through optical or chemical signals and give rise to networks for computational purposes and to develop micro/nanorobotics. The other approach concerns “bottom-up synthetic cells” that can be exploited for applications in various scenarios, including future nano-medicine. Both topics are presented at a basic level, mainly to inform the broader audience of non-specialists, and so favour the rise of interest in these frontier subjects.}
}
@incollection{PAUL2005431,
title = {Chapter 15 - Models of Computation for Systems-on-Chips},
editor = {Ahmed Amine Jerraya and Wayne Wolf},
booktitle = {Multiprocessor Systems-on-Chips},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {431-463},
year = {2005},
series = {Systems on Silicon},
issn = {18759661},
doi = {https://doi.org/10.1016/B978-012385251-9/50031-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852519500311},
author = {JoAnn M. Paul and Donald E. Thomas},
abstract = {Publisher Summary
This chapter describes system modeling and its relationship to models of computation. It compares several different models of computation and evaluates their usefulness at various stages in system design. It also describes the modeling environment for software and hardware (MESH) environment for hardware and software modeling. Models of computation (MoCs) are abstract representations of computing systems. Computer modeling can be separated into three areas—formal MoCs, computer artifacts, and computer design tools. A formal MoC is generally considered to be one with a mathematical basis. Simulations of formal models may be more efficient for large systems; however, the properties of formal models permit the representation of the system to be manipulated purely mathematically. Computer artifacts are the objects of computer architects. They include software, hardware, or both. Design tools are computer programs that are used to assist the construction of instances of computers as well as the conceptualization of computer artifacts. Design tools may be considered synonymous with design artifacts because they are objects, or entities, used to facilitate the design process. They may have a formal mathematical basis.}
}
@article{LIU2024111728,
title = {DuaPIN: Auxiliary task enhanced dual path interaction network for civil court view generation},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111728},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111728},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124003630},
author = {Nayu Liu and Luyao Ma and Yiquan Wu and Kaiwen Wei and Cunhang Fan and Yating Zhang},
keywords = {Dual path interaction network, Auxiliary task, Civil court view generation, Natural language processing},
abstract = {Civil court view generation (CCVG) is a novel but important task for legal intelligence that aims to automatically generate a judge’s opinion based on the plaintiff’s claims and fact descriptions to interpret the judgment result. The task is more challenging than criminal court view generation as the latter generates views based only on criminal facts as input, whereas the CCVG must consider both the plaintiff’s claims and civil facts under the principle of “no claim, no trial.” However, current approaches still follow criminal domain practices to solve problems in civil cases. Moreover, the explicit modeling of the potential correspondence between claims and facts has often been neglected, as court views are required to respond to each corresponding claim based on factual evidence. To address the issues, we propose a dual path interaction network augmented by two self-supervised auxiliary tasks (named DuaPIN), which follows a bionic design by simulating the thinking logic of judges when writing opinions. Specifically, we construct a structurally symmetric Transformer-based dual path multi-encoder–decoder model such that the two inputs, claim and fact, contribute equally to the generation of civil court views. Moreover, an auxiliary task enhanced (ATE) training paradigm using multiple DuaPIN decoders is proposed to explicitly model the potential correspondence between claims and facts. Extensive experiments on public legal document dataset demonstrated that DuaPIN achieves competitive performance compared with previous methods and offers certain performance improvements to popular pre-trained language models via the ATE training method.}
}
@incollection{SALTZER20091,
title = {Chapter 1 - Systems},
editor = {Jerome H. Saltzer and M. Frans Kaashoek},
booktitle = {Principles of Computer System Design},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {1-42},
year = {2009},
isbn = {978-0-12-374957-4},
doi = {https://doi.org/10.1016/B978-0-12-374957-4.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749574000104},
author = {Jerome H. Saltzer and M. Frans Kaashoek},
abstract = {Publisher Summary
This chapter introduces some of the vocabulary and concepts used in designing computer systems. It also introduces the “systems perspective,” a way of thinking about systems that is global and encompassing rather than focused on particular issues. The usual course of study of computer science and engineering begins with linguistic constructs for describing computations (software) and physical constructs for realizing computations (hardware). To develop applications that have these requirements, the designer must look beyond the software and hardware and view the computer system as a whole. In doing so, the designer encounters many new problems—so many that the limit on the scope of computer systems generally arises neither from laws of physics nor from theoretical impossibility, but rather from limitations of human understanding.}
}
@article{WARD202154,
title = {On value-laden science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {85},
pages = {54-62},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2020.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0039368120301783},
author = {Zina B. Ward},
keywords = {Values, Values in science, Argument from inductive risk, Motivating reasons, Justifying reasons},
abstract = {Philosophical work on values in science is held back by widespread ambiguity about how values bear on scientific choices. Here, I disambiguate several ways in which a choice can be value-laden and show that this disambiguation has the potential to solve and dissolve philosophical problems about values in science. First, I characterize four ways in which values relate to choices: values can motivate, justify, cause, or be impacted by the choices we make. Next, I put my proposed taxonomy to work, using it to clarify one version of the argument from inductive risk. The claim that non-epistemic values must play a role in scientific choices that run inductive risk makes most sense as a claim about values being needed to justify such choices. The argument from inductive risk is not unique: many philosophical arguments about values in science can be more clearly understood and assessed by paying close attention to how values and choices are related.}
}
@article{CHEN1998475,
title = {A computationally attractive nonlinear predictive control scheme with guaranteed stability for stable systems},
journal = {Journal of Process Control},
volume = {8},
number = {5},
pages = {475-485},
year = {1998},
note = {ADCHEM '97 IFAC Symposium: Advanced Control of Chemical Processes},
issn = {0959-1524},
doi = {https://doi.org/10.1016/S0959-1524(98)00021-3},
url = {https://www.sciencedirect.com/science/article/pii/S0959152498000213},
author = {H. Chen and F. Allgöwer},
keywords = {nonlinear predictive control, constraints, stability, terminal conditions},
abstract = {We introduce in this paper a nonlinear model predictive control scheme for open-loop stable systems subject to input and state constraints. Closed-loop stability is guaranteed by an appropriate choice of the finite prediction horizon, independent of the specification of the desired control performance. In addition, this control scheme is likely to allow ‘real time’ implementation, because of its computational attractiveness. The theoretical results are demonstrated and discussed with a CSTR control application.}
}
@article{HO1993567,
title = {Recent Applications of Symbolic Computation in Control System Design},
journal = {IFAC Proceedings Volumes},
volume = {26},
number = {2, Part 2},
pages = {567-570},
year = {1993},
note = {12th Triennal Wold Congress of the International Federation of Automatic control. Volume 2 Robust Control, Design and Software, Sydney, Australia, 18-23 July},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)49006-9},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017490069},
author = {D.W.C. Ho and J. Lam and S.K. Tin and C.Y. Han},
keywords = {Symbolic Computation, Computer-aided Control System Design},
abstract = {In this paper we describe several recent applications of symbolic computation to control system design based on MACSYMA. These include routines to calculate the transfer function of a control system in block diagram representation and to compute and simplify state space realizations of multivariable control systems. The programs provide a quick way to formulate design problem and automate the calculation in the initial stage of a control system design process. An example on the application of these routines in the setting up of generalized plant state space realization for use in H∞/H2 optimial control is provided}
}
@article{VANHOOIJDONK2022101044,
title = {Creativity and change of context: The influence of object-context (in)congruency on cognitive flexibility},
journal = {Thinking Skills and Creativity},
volume = {45},
pages = {101044},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101044},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000475},
author = {Mare {van Hooijdonk} and Simone M. Ritter and Marcel Linka and Evelyn Kroesbergen},
keywords = {Creativity, Spatial context, Object congruence, Cognitive flexibility, Stimulating creativity},
abstract = {Specific environmental features, such as natural settings or spatial design, can foster creativity. The effect of object-context congruency on creativity has not yet been investigated. While congruence between an object and its visual context provides meaning to the object, it may hamper creativity due to mental fixation effects. In the current study, virtual reality technology (VR) was employed to examine the hypothesis that people display more cognitive flexibility - a key element of creativity, representing the ability to overcome mental fixation - when thinking about an object while being in an incongruent than in a congruent environment. Participants (N = 184) performed an Alternative Uses Task, in which they had to name as many uses for a book as possible, while being immersed in a virtual environment that was either object-context congruent (i.e., places where you would expect a book; e.g., a library or a living room; n = 91) or object-context incongruent (i.e., places where a book is not expected; e.g., a clothing store or a car workshop; n = 93). The effect of object (in)congruency was also assessed for three other indices of creativity: fluency (i.e., the number of ideas generated), originality and usefulness. In line with our hypothesis, participants scored higher on pure cognitive flexibility in the object-context incongruent than in the object-context congruent environment. Moreover, participants in the object-context incongruent environment condition generated more original ideas. The theoretical and practical implications of the current findings are discussed.}
}
@incollection{JAIN2015181,
title = {Chapter Seven - Computational Methods for RNA Structure Validation and Improvement},
editor = {Sarah A. Woodson and Frédéric H.T. Allain},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {558},
pages = {181-212},
year = {2015},
booktitle = {Structures of Large RNA Molecules and Their Complexes},
issn = {0076-6879},
doi = {https://doi.org/10.1016/bs.mie.2015.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0076687915000208},
author = {Swati Jain and David C. Richardson and Jane S. Richardson},
keywords = {RNA crystallography, RNA backbone conformers, Ribose pucker, Clash correction, MolProbity, PHENIX, ERRASER, wwPDB validation},
abstract = {With increasing recognition of the roles RNA molecules and RNA/protein complexes play in an unexpected variety of biological processes, understanding of RNA structure–function relationships is of high current importance. To make clean biological interpretations from three-dimensional structures, it is imperative to have high-quality, accurate RNA crystal structures available, and the community has thoroughly embraced that goal. However, due to the many degrees of freedom inherent in RNA structure (especially for the backbone), it is a significant challenge to succeed in building accurate experimental models for RNA structures. This chapter describes the tools and techniques our research group and our collaborators have developed over the years to help RNA structural biologists both evaluate and achieve better accuracy. Expert analysis of large, high-resolution, quality-conscious RNA datasets provides the fundamental information that enables automated methods for robust and efficient error diagnosis in validating RNA structures at all resolutions. The even more crucial goal of correcting the diagnosed outliers has steadily developed toward highly effective, computationally based techniques. Automation enables solving complex issues in large RNA structures, but cannot circumvent the need for thoughtful examination of local details, and so we also provide some guidance for interpreting and acting on the results of current structure validation for RNA.}
}
@article{ZHAI2023101373,
title = {Can reflective interventions improve students’ academic achievement? A meta-analysis},
journal = {Thinking Skills and Creativity},
volume = {49},
pages = {101373},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101373},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123001414},
author = {Na Zhai and Yong Huang and Xiaomei Ma and Jingchun Chen},
keywords = {Reflection, Reflective intervention, Academic achievement, Meta-analysis},
abstract = {Reflection is widely acknowledged as a crucial skill for successful learning and decision-making. Recent evidence has shown that reflection can enhance motivation for in-depth learning, improve cognitive and metacognitive strategies, and promote self-regulated learning. While some studies have reported the positive effects of reflective interventions on student academic outcomes, conflicting findings exist. To provide a comprehensive understanding of the effectiveness of reflective interventions on academic achievement, this meta-analysis synthesized data from 25 quantitative studies (comprising 29 effect sizes) conducted between 2012 and 2022, with a total of 2,111 participants. The results revealed a significant overall effect of reflective interventions on academic achievement (g = 0.793, p < 0.001). Further moderator analyses indicated that the effectiveness of reflective interventions was influenced by factors such as learning mode, intervention duration, the role of reflective writing, and culture. However, education level, discipline, teacher or expert feedback, peer interaction, and technological scaffolding did not significantly affect the impact of reflective interventions across studies. These findings highlight the importance of fostering reflective thinking and refining the detailed design of reflective interventions to enhance students’ academic achievement.}
}
@article{PUPUNWIWAT2011827,
title = {Conceptual Selective RFID Anti-Collision Technique Management},
journal = {Procedia Computer Science},
volume = {5},
pages = {827-834},
year = {2011},
note = {The 2nd International Conference on Ambient Systems, Networks and Technologies (ANT-2011) / The 8th International Conference on Mobile Web Information Systems (MobiWIS 2011)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.07.114},
url = {https://www.sciencedirect.com/science/article/pii/S187705091100439X},
author = {Prapassara Pupunwiwat and Peter Darcy and Bela Stantic},
keywords = {Radio Frequency Identification (RFID), Anti-Collision, Decision Tree, Six Thinking Hats},
abstract = {Radio Frequency Identification (RFID) uses wireless radio frequency technology to automatically identify tagged objects. Despite the extensive development of RFID technology, tag collisions still remains a major drawback. The collision issue can be solved by using anti-collision techniques. While existing research has focused on improving anti-collision methods alone, it is also essential that a suitable type of anti-collision algorithm is selected for the specific circumstance. In this work, we evaluate anti-collision techniques and perform a comparative analysis in order to find the advantages and disadvantages of each approach. To identify the best anti-collision selection method in various scenarios, we have proposed two strategies for selective anti-collision technique management: a “Novel Decision Tree Strategy” and a “Six Thinking Hats Strategy”. We have shown that the selection of the correct technique for specific scenarios improve the quality of the data collection which, in turn, will increase the integrity of the data after being transformed, aggregated, and used for event processing.}
}
@article{JUDD1997907,
title = {Computational economics and economic theory: Substitutes or complements?},
journal = {Journal of Economic Dynamics and Control},
volume = {21},
number = {6},
pages = {907-942},
year = {1997},
note = {Society of Computational Economics Conference},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(97)00010-9},
url = {https://www.sciencedirect.com/science/article/pii/S0165188997000109},
author = {Kenneth L. Judd},
keywords = {Computational approach, Theoretical analysis},
abstract = {This essay examines the idea and potential of a ‘computational approach to theory’, discusses methodological issues raised by such computational methods, and outlines the problems associated with the dissemination of computational methods and the exposition of computational results. We argue that the study of a theory need not be confined to proving theorems, that current and future computer technologies create new possibilities for theoretical analysis, and that by resolving these issues we will create an intellectual atmosphere in which computational methods can make substantial contributions to economic analysis.}
}
@article{ALKABI202368,
title = {Proposed artificial intelligence algorithm and deep learning techniques for development of higher education},
journal = {International Journal of Intelligent Networks},
volume = {4},
pages = {68-73},
year = {2023},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2023.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666603023000039},
author = {Amin {Al Ka'bi}},
keywords = {Artificial intelligence (AI), Communication systems, Higher education, Neural networks, Attention process, Deep learning},
abstract = {Artificial intelligence (AI) has been increasingly impacting various aspects of our daily lives, including education. With the rise of digital technologies, higher education has also been experiencing a transformation, and AI has been playing a crucial role in this transformation. The application of AI in higher education has been rapidly increasing, with a focus on improving student engagement, increasing efficiency, and enhancing the learning experience. The use of AI in higher education is not without its challenges and ethical considerations. One of the biggest challenges is ensuring the accuracy and fairness of AI algorithms, as well as avoiding potential biases. In addition, there are concerns about the privacy of student data, as well as the potential for AI to replace human instructors and support staff. Another challenge is ensuring that AI is used in a way that supports the overall goals of higher education, such as promoting critical thinking and creativity, rather than just being used as a tool for automating tasks and increasing efficiency. In this article, we will discuss the various ways in which AI is being applied in higher education where a proposed model for improving the cognitive capability of students is proposed and compared to other existing algorithms. It will be shown that the proposed model shows better performance compared to other models.}
}
@article{JORAJURIA2022664,
title = {Oscillatory Source Tensor Discriminant Analysis (OSTDA): A regularized tensor pipeline for SSVEP-based BCI systems},
journal = {Neurocomputing},
volume = {492},
pages = {664-675},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.07.103},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221018956},
author = {Tania Jorajuría and Mina {Jamshidi Idaji} and Zafer İşcan and Marisol Gómez and Vadim V. Nikulin and Carmen Vidaurre},
keywords = {Brain-computer interface, Steady-state visual evoked potential, Spatio-spectral decomposition, Higher order discriminant analysis, Analytical regularization, Tensor-based feature reduction},
abstract = {Periodic signals called Steady-State Visual Evoked Potentials (SSVEP) are elicited in the brain by flickering stimuli. They are usually detected by means of regression techniques that need relatively long trial lengths to provide feedback and/or sufficient number of calibration trials to be reliably estimated in the context of brain-computer interface (BCI). Thus, for BCI systems designed to operate with SSVEP signals, reliability is achieved at the expense of speed or extra recording time. Furthermore, regardless of the trial length, calibration free regression-based methods have been shown to suffer from significant performance drops when cognitive perturbations are present affecting the attention to the flickering stimuli. In this study we present a novel technique called Oscillatory Source Tensor Discriminant Analysis (OSTDA) that extracts oscillatory sources and classifies them using the newly developed tensor-based discriminant analysis with shrinkage. The proposed approach is robust for small sample size settings where only a few calibration trials are available. Besides, it works well with both low- and high-number-of-channel settings, using trials as short as one second. OSTDA performs similarly or significantly better than other three benchmarked state-of-the-art techniques under different experimental settings, including those with cognitive disturbances (i.e. four datasets with control, listening, speaking and thinking conditions). Overall, in this paper we show that OSTDA is the only pipeline among all the studied ones that can achieve optimal results in all analyzed conditions.}
}
@article{LIU2023109530,
title = {Quantum computing for power systems: Tutorial, review, challenges, and prospects},
journal = {Electric Power Systems Research},
volume = {223},
pages = {109530},
year = {2023},
issn = {0378-7796},
doi = {https://doi.org/10.1016/j.epsr.2023.109530},
url = {https://www.sciencedirect.com/science/article/pii/S0378779623004194},
author = {Hualong Liu and Wenyuan Tang},
keywords = {Quantum computing, Optimization, Power systems, Renewable energy, Climate neutrality},
abstract = {As a large number of renewable energy resources are connected to power systems, the operation, planning, and optimization of power systems have been becoming more and more complex. Power flow calculation, unit commitment, economic dispatch, energy pricing, and power system planning are essentially computation problems. A lot of computing resources are required for these problems, which are non-trivial, especially for large-scale power systems with the high penetration of renewable energy. Traditionally, the calculation and optimization of power systems are completed by classical computers based on the classical computing theory and the von Neumann architecture. However, with Moore’s law getting closer and closer to the limit, the importance of quantum computing has become increasingly prominent. Quantum computing has been applied to some fields to a certain extent, yet the applications of quantum computing in power systems are rare. As the power industry is the foundation of the national economy, introducing quantum computing into the power system has far-reaching and crucial significance, such as improving the penetration of renewable energy, enhancing the computing efficiency, and helping in achieving the goal of net zero and climate neutrality by 2050. This paper first introduces the core concepts, essential ideas and theories of quantum computing, and then reviews the existing literature on the applications of quantum computing in power systems, and puts forward our critical thinking about the applications of quantum computing in power systems. In brief, this paper is dedicated to a tutorial on quantum computing targeting power system professionals and a review of its applications in power systems. The main contributions of this paper are: (1) introduce quantum computing into the field of power engineering in a thoroughly detailed way and delineate the analysis methodologies of quantum circuits systematically without losing mathematical rigor; (2) based on Dirac’s notation, the related formulae are derived meticulously with sophisticated schematic diagrams; (3) elaborate and derive some critical quantum algorithms in depth, which play an important role in the applications of quantum computing in power systems; (4) critically summarize and comment on the existing literature on the applications of quantum computing in power systems; (5) the future applications and challenges of quantum computing in power systems are prospected and remarked.}
}
@article{BAKER2021101933,
title = {Who is marginalized in energy justice? Amplifying community leader perspectives of energy transitions in Ghana},
journal = {Energy Research & Social Science},
volume = {73},
pages = {101933},
year = {2021},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2021.101933},
url = {https://www.sciencedirect.com/science/article/pii/S2214629621000268},
author = {Erin Baker and Destenie Nock and Todd Levin and Samuel A. Atarah and Anthony Afful-Dadzie and David Dodoo-Arhin and Léonce Ndikumana and Ekundayo Shittu and Edwin Muchapondwa and Charles Van-Hein Sackey},
abstract = {There is a divide in energy access studies, between technologically-focused modeling papers in engineering and economics, and energy justice frameworks and principles grounded in social sciences. Quantitative computational models are necessary when analyzing energy, and more specifically electricity, systems, as they are technologically-complex systems that can diverge from intuitive patterns. To assure energy justice, these models must be reflective of, and informative to, a wide range of stakeholders, including households and communities alongside utilities, governments, and others. Yet, moving from a qualitative understanding of preferences to quantitative modeling is challenging. In this perspective piece, we pilot the use of the value-focused thinking framework to inform stakeholder engagement. The result is a strategic objective hierarchy that highlights the tradeoffs and the social, economic and technological factors that need to be measured in models. We apply the process in Ghana, using a survey, stakeholder workshops, and follow-up interviews to uncover key tradeoffs and stakeholder-derived objectives. We discuss three key areas that have been rarely, if ever, well-represented in energy models: (1) the relationship between the dynamics of electricity end-use and the technology and economic structure of the system; (2) explicit tradeoffs between electricity access, cost, and reliability as defined by stakeholders; and (3) the definition of new objectives, such as minimizing hazards related to theft. We conclude that this model of engagement provides an opportunity to tie together rigorous qualitative analysis and stakeholder engagement with crucial quantitative models of the electricity system.}
}
@article{CHAN2022102109,
title = {Slow down to speed up: Longer pause time before solving problems relates to higher strategy efficiency},
journal = {Learning and Individual Differences},
volume = {93},
pages = {102109},
year = {2022},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2021.102109},
url = {https://www.sciencedirect.com/science/article/pii/S1041608021001461},
author = {Jenny Yun-Chen Chan and Erin R. Ottmar and Ji-Eun Lee},
keywords = {Pause time, Strategy efficiency, Algebra problem-solving, Online learning environment, Metacognitive skills},
abstract = {We examined the influences of pre-solving pause time, algebraic knowledge, mathematics self-efficacy, and mathematics anxiety on middle-schoolers' strategy efficiency in an algebra learning game. We measured strategy efficiency using (a) the number of steps taken to complete a problem, (b) the proportion of problems completed on the initial attempt, and (c) the number of resets prior to completing the problems. Using the log data from the game, we found that longer pre-solving pause time was associated with more efficient strategies, as indicated by fewer solution steps, higher initial completion rate, and fewer resets. Higher algebraic knowledge was associated with higher initial completion rate and fewer resets. Mathematics self-efficacy and mathematics anxiety was not associated with any measures of strategy efficiency. The results suggest that pause time may be an indicator of student thinking before problem-solving, and provide insights into using data from online learning platforms to examine students' problem-solving processes.}
}
@article{ROY2020106210,
title = {Fixed subgroups and computation of auto-fixed closures in free-abelian times free groups},
journal = {Journal of Pure and Applied Algebra},
volume = {224},
number = {4},
pages = {106210},
year = {2020},
issn = {0022-4049},
doi = {https://doi.org/10.1016/j.jpaa.2019.106210},
url = {https://www.sciencedirect.com/science/article/pii/S0022404919302178},
author = {Mallika Roy and Enric Ventura},
keywords = {Free-abelian times free, Automorphism, Fixed subgroup, Periodic subgroup, Auto-fixed closure},
abstract = {The classical result by Dyer–Scott about fixed subgroups of finite order automorphisms of Fn being free factors of Fn is no longer true in Zm×Fn. Within this more general context, we prove a relaxed version in the spirit of Bestvina–Handel Theorem: the rank of fixed subgroups of finite order automorphisms is uniformly bounded in terms of m,n. We also study periodic points of endomorphisms of Zm×Fn, and give an algorithm to compute auto-fixed closures of finitely generated subgroups of Zm×Fn. On the way, we prove the analog of Day's Theorem for real elements in Zm×Fn, contributing a modest step into the project of doing so for any right angled Artin group (as McCool did with respect to Whitehead's Theorem in the free context).}
}
@article{FAELENS2021106510,
title = {Social media use and well-being: A prospective experience-sampling study},
journal = {Computers in Human Behavior},
volume = {114},
pages = {106510},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106510},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220302624},
author = {Lien Faelens and Kristof Hoorelbeke and Bart Soenens and Kyle {Van Gaeveren} and Lieven {De Marez} and Rudi {De Raedt} and Ernst H.W. Koster},
keywords = {Social media, Social comparison, Self-esteem, Repetitive negative thinking, Negative affect},
abstract = {Facebook and Instagram are currently the most popular Social Network Sites (SNS) for young adults. A large amount of research examined the relationship between these SNS and well-being, and possible intermediate constructs such as social comparison, self-esteem, and repetitive negative thinking (RNT). However, most of these studies have cross-sectional designs and use self-report indicators of SNS use. Therefore, their conclusions should be interpreted cautiously. Consequently, the goal of the current experience sampling study was to examine the temporal dynamics between objective indicators of SNS use, and self-reports of social comparison, RNT, and daily fluctuations in negative affect. More specifically, we assessed 98 participants 6 times per day during 14 days to examine reciprocal relationships between SNS use, negative affect, emotion regulation, and key psychological constructs. Results indicate that (1) both Facebook and Instagram use predicted reduced well-being, and (2) self-esteem and RNT appear to be important intermediate constructs in these relationships. Future longitudinal and experimental studies are needed to further support and extend the current research findings.}
}
@article{LI2023101752,
title = {The role of inhibition in overcoming arithmetic natural number bias in the Chinese context: Evidence from behavioral and ERP experiments},
journal = {Learning and Instruction},
volume = {86},
pages = {101752},
year = {2023},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2023.101752},
url = {https://www.sciencedirect.com/science/article/pii/S095947522300021X},
author = {Xiaodong Li and Ping Xu and Ronghuan Jiang and Shuang Chen},
keywords = {Inhibitory control, Negative priming, Natural number bias, Arithmetic operation, Event-related potential},
abstract = {The natural number bias (NNB) in arithmetic operations refers to the application of natural number properties to reasoning about rational numbers. Previous studies found the NNB interferes with students’ problem-solving. However, few studies have examined it in the Chinese context or the underlying mechanism by which it can be overcome. Addressing these gaps, in Experiments 1a (n = 31) and 1b (n = 30), we found that Chinese students demonstrate the NNB despite linguistic differences between Chinese and western languages. Experiment 2 (n = 38) adopted a negative priming paradigm and found that inhibitory control was necessary to overcome the NNB. Experiment 3 (n = 34) employed the event-related potential technique; we observed increased P2 amplitude when students solved congruent problems, and increased N2 and decreased P3 amplitude when they solved incongruent problems. These results indicated that the NNB is rooted in intuitive thinking, and overcoming this bias relies on inhibition.}
}
@article{EDELMAN1997296,
title = {Computational theories of object recognition},
journal = {Trends in Cognitive Sciences},
volume = {1},
number = {8},
pages = {296-304},
year = {1997},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(97)01090-5},
url = {https://www.sciencedirect.com/science/article/pii/S1364661397010905},
author = {S. Edelman},
abstract = {This paper examines four current theoretical approaches to the representation and recognition of visual objects: structural descriptions, geometric constraints, multidimensional feature spaces and shape-space approximation. The strengths and weaknesses of the four theories are considered, with a special focus on their approach to categorization — a computationally challenging task which is not widely addressed in computer vision, where the stress is rather on the generalization of recognition across changes of viewpoint.}
}
@incollection{KISS2019109,
title = {Process Systems Engineering from an industrial and academic perspective},
editor = {Anton A. Kiss and Edwin Zondervan and Richard Lakerveld and Leyla Özkan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {46},
pages = {109-114},
year = {2019},
booktitle = {29th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818634-3.50019-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186343500199},
author = {Anton A. Kiss and Johan Grievink},
keywords = {PSE, industry, education, research, interface, perspectives},
abstract = {Process Systems Engineering (PSE) deals with decision-making, at all levels and scales, by understanding complex process systems using a holistic view. Computer Aided Process Engineering (CAPE) is a complementary field that focuses on developing methods and providing solution through systematic computer aided techniques for problems related to the design, control and operation of chemical systems. The ‘PSE’ term suffers from a branding issue to the point that PSE does not get the recognition it deserves. This work aims to provide an informative industrial and academic perspective on PSE, arguing that the ‘systems thinking’ and ‘systems problem solving’ have to be prioritized ahead of just applications of computational problem solving methods. A multi-level view of the PSE field is provided within the academic and industrial context, and enhancements for PSE are suggested at their industrial and academic interfaces.}
}
@article{SURYARAJ2024124407,
title = {Block based motion estimation model using CNN with representative point matching algorithm for object tracking in videos},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124407},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124407},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424012739},
author = {C.K. Suryaraj and M.R. Geetha},
keywords = {Motion Estimation, Object Tracking, CNN, RPM, SSIM, Video Sequence, Computation Time},
abstract = {Motion estimation is considered significant for tracking the movement of an object in video sequences, and it is widely used in various video processing applications. Traditionally, many researchers focus on pixel-based motion estimation for object tracking, but it experienced increased computation time and cost. To reduce computation time, the utilization of a block-based motion estimation approach for object tracking is a recent trend. The existing block-based approach faces difficulty in finding representative points within the intensity domain. Therefore, this current research merged the deep learning approach with a block-matching algorithm for achieving efficient object tracking. In this proposed work, initially, video sequences are collected from a benchmark video dataset. Then, the acquired video sequences are segmented into frames. From the segmented frames, current and previous frames are considered for motion estimation. Frames are sent for the data augmentation process in which the process of flipping, cropping, and rotation is carried out. Then, the augmented frames are sent into Convolutional Neural Network (CNN) for feature extraction. Representative Point Matching (RPM) is used to estimate the motion vector based on the extracted features. After estimating the motion vector, the similarity between two consecutive frames is found using Structural Similarity Index (SSIM) technique. Finally, based on the similarity score, the movement of an object in the video is tracked effectively. Simulation analysis of the proposed block-based motion estimation model is done by evaluating some performance metrics. RMSE, PSNR, Execution Time, SSIM, and accuracy obtained for the proposed model are 27.5, 26.5 db, 31 sec, 0.91, and 94 %. This analysis suggested that the proposed CNN-RPM motion estimation model performs better in tracking the movement of the object.}
}
@article{HAGSTROM1998385,
title = {Experiments with approximate radiation boundary conditions for computational aeroacoustics},
journal = {Applied Numerical Mathematics},
volume = {27},
number = {4},
pages = {385-402},
year = {1998},
note = {Special Issue on Absorbing Boundary Conditions},
issn = {0168-9274},
doi = {https://doi.org/10.1016/S0168-9274(98)00021-X},
url = {https://www.sciencedirect.com/science/article/pii/S016892749800021X},
author = {Thomas Hagstrom and John Goodrich},
keywords = {Nonreflecting Boundary Conditions, Aeroacoustics},
abstract = {We present a series of numerical experiments on the accuracy of approximate radiation boundary conditions for computational aeroacoustics based on Padé approximants. Our test problem is described by an infinite periodic array of pressure pulses, for which we can independently evaluate the exact solution by numerical quadrature. It is demonstrated that acceptable long time accuracy can be achieved, but only if conditions of high order are employed. As predicted by theory, the order required for a given accuracy is proportional to the time of the simulation.}
}
@article{GARGALO2024108504,
title = {A process systems engineering view of environmental impact assessment in renewable and sustainable energy production: Status and perspectives},
journal = {Computers & Chemical Engineering},
volume = {180},
pages = {108504},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108504},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423003745},
author = {Carina L. Gargalo and Haoshui Yu and Nikolaus Vollmer and Ahmad Arabkoohsar and Krist V. Gernaey and Gürkan Sin},
keywords = {Renewable and sustainable energy systems, Environmental impact assessment, Process systems engineering, Life cycle assessment, Sustainability},
abstract = {With the increasing concern for climate change, renewable and sustainable energy production has attracted considerable attention from the scientific community, industrial practitioners, and policy and decision-makers. There are many technological alternatives for each sub-category of complex sustainable energy systems. Life cycle assessment (LCA) can be an effective tool to compare the environmental impacts of each pathway and identify the most promising alternatives from an environmental impact perspective. This contribution first reviews the environmental assessment methods and tools developed over the years. Secondly, a comprehensive review of the contribution of the PSE community to the environmental impact analysis of renewable energy systems is performed. It is observed that while LCA is the preferred method, these studies differed widely concerning the choice of impact assessment method used, the level of details shared concerning the underlying LCA calculations, and whether or not sensitivity and uncertainty analyses were carried out, among many others. This makes the comparison of results from different studies difficult and often impossible. It is clear that the PSE community, with its emphasis on systems thinking and holistic approaches, plays a critical role in the design, integration, and operation of complex sustainable energy systems. However, the thorough calculations necessary to ensure a robust and transparent LCA analysis require a shared methodology and a detailed description of the rules. Such explicit, systematic, and transparent methods will set the bar for a minimum requirement for thorough LCA calculations, ensuring fair comparison and discussions of different technical solutions developed in the wider PSE community for sustainable renewables.}
}
@article{ABEYSEKERA2024100213,
title = {ChatGPT and academia on accounting assessments},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {10},
number = {1},
pages = {100213},
year = {2024},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124000076},
author = {Indra Abeysekera},
keywords = {Academia, Accounting, Assessments, ChatGPT, Multiple Choice Questions, Sustainable Development Goals of the United Nations},
abstract = {ChatGPT is considered a risk and an opportunity for academia. An area of threat in contemporary settings is whether it can become a student agent for assessments in academia. This study determines how ChatGPT can become a human agent for students on two financial accounting course units, multiple choice question assessments. The study provided five numerical-based and five narrative-based multiple choice questions. There were ten questions for the Introductory Financial Accounting and 10 for the Advanced Financial Accounting course units. ChatGPT received one question at a time requesting a solution. In the Introductory Financial Accounting section, ChatGPT produced incorrect answers because it incorrectly assumed the underlying assumptions contained in those questions. In Advanced Financial Accounting, ChatGPT presented incorrect answers because of the complexity of the task contained in those questions. ChatGPT demonstrated similar competencies in providing solutions to numerical-based and narrative-based questions. ChatGPT obtained the correct answers to sit in the 80th percentile in the Introductory Financial Accounting course unit assessment and the 50th percentile in the Advanced Financial course unit assessment. ChatGPT4 showed improved performance, with the 90th percentile for Introductory Financial Accounting and the 70th percentile for Advanced Financial Accounting. The findings indicate that the knowledge construct requires reflective thinking with ChatGPT in the ecosystem, and what is assumed and assessable knowledge must be revisited.}
}
@article{LI2023113687,
title = {Twins transformer: Cross-attention based two-branch transformer network for rotating bearing fault diagnosis},
journal = {Measurement},
volume = {223},
pages = {113687},
year = {2023},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2023.113687},
url = {https://www.sciencedirect.com/science/article/pii/S0263224123012514},
author = {Jie Li and Yu Bao and WenXin Liu and PengXiang Ji and LeKang Wang and Zhongbing Wang},
keywords = {Attention mechanisms, Cross-attention, Fault diagnosis, Transformer},
abstract = {Due to the inherent shortcomings of traditional depth models, the Transformer model based on the self-attention mechanism has become popular in the field of fault diagnosis. The current Transformer's self-attentive mechanism provides an alternative way of thinking, which can make direct association between each signal. However, it can only focus on the association information within a sequence, and it is difficult to understand the information gap between samples. Therefore, this paper proposes the two-branch Twins attention, which for the first time uses cross-attention to focus on information associations between samples. Twins attention uses cross-attention to learn information associations between samples in addition to retaining the information associations within sequences learned by self-attention. The performance of the proposed model was validated on four popular bearing datasets. Compared to the original transformer structure, the average accuracy of each dataset improved by 1.73% to 99.42%, leading the noise experiments.}
}
@incollection{KIHLSTROM2018,
title = {Cognitive Psychology: Overview☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21702-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245217021},
author = {John F. Kihlstrom and Lillian Park},
keywords = {Cognition, Sensation, Perception, Attention, Memory, Categorization, Learning, Language, Reasoning, Judgment, Decision-making, Choice, Cognitive development, Cognitive neuroscience, Cognitive sociology},
abstract = {Cognitive psychology seeks to understand how we acquire knowledge about ourselves and the world, how this knowledge is represented in the mind and brain, and how we use knowledge to guide behavior. Major topics in cognitive psychology include sensation and perception, attention, memory, categorization, learning, language and communication, and thinking, reasoning, judgment, and decision-making. Cognitive development is discussed from both an ontogenetic and phylogenetic point of view. Cognitive neuroscience explores the neural substrates of cognitive processes. The cognitive point of view has been extended to personality, social, and clinical psychology, as well as to sociology, anthropology, and other social-science disciplines.}
}
@article{KING2023104028,
title = {Identifying risk controls for future advanced brain-computer interfaces: A prospective risk assessment approach using work domain analysis},
journal = {Applied Ergonomics},
volume = {111},
pages = {104028},
year = {2023},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2023.104028},
url = {https://www.sciencedirect.com/science/article/pii/S0003687023000662},
author = {Brandon J. King and Gemma J.M. Read and Paul M. Salmon},
keywords = {Brain-computer interfaces, Risk assessment, System modelling},
abstract = {Brain-computer interface (BCI) technologies are progressing rapidly and may eventually be implemented widely within society, yet their risks have arguably not yet been comprehensively identified, nor understood. This study analysed an anticipated invasive BCI system lifecycle to identify the individual, organisational, and societal risks associated with BCIs, and controls that could be used to mitigate or eliminate these risks. A BCI system lifecycle work domain analysis model was developed and validated with 10 subject matter experts. The model was subsequently used to undertake a systems thinking-based risk assessment approach to identify risks that could emerge when functions are either undertaken sub-optimally or not undertaken at all. Eighteen broad risk themes were identified that could negatively impact the BCI system lifecycle in a variety of unique ways, while a larger number of controls for these risks were also identified. The most concerning risks included inadequate regulation of BCI technologies and inadequate training of BCI stakeholders, such as users and clinicians. In addition to specifying a practical set of risk controls to inform BCI device design, manufacture, adoption, and utilisation, the results demonstrate the complexity involved in managing BCI risks and suggests that a system-wide coordinated response is required. Future research is required to evaluate the comprehensiveness of the identified risks and the practicality of implementing the risk controls.}
}
@incollection{MAIDA201639,
title = {Chapter 2 - Cognitive Computing and Neural Networks: Reverse Engineering the Brain},
editor = {Venkat N. Gudivada and Vijay V. Raghavan and Venu Govindaraju and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {35},
pages = {39-78},
year = {2016},
booktitle = {Cognitive Computing: Theory and Applications},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2016.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0169716116300529},
author = {A.S. Maida},
keywords = {Brain simulation, Deep belief networks, Convolutional networks, Liquid computing, Biological neural networks, Neocortex},
abstract = {Cognitive computing seeks to build applications which model and mimic human thinking. One approach toward achieving this goal is to develop brain-inspired computational models. A prime example of such a model is the class of deep convolutional networks which is currently used in pattern recognition, machine vision, and machine learning. We offer a brief review of the mammalian neocortex, the minicolumn, and the ventral pathway. We provide descriptions of abstract neural circuits that have been used to model these areas of the brain. This include Poisson spiking networks, liquid computing networks, spiking models of feature discovery in the ventral pathway, spike-timing-dependent plasticity learning, restricted Boltzmann machines, deep belief networks, and deep convolutional networks. In summary, this chapter explores abstractions of neural networks found within the mammalian neocortex that support cognition and the beginnings of cognitive computation.}
}
@article{ITO2024326,
title = {A Discrete Predator-Prey Brain Storm Optimization Technique for Optimal Allocation of Micro-PMUs in Distribution System State Estimation},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {13},
pages = {326-331},
year = {2024},
note = {12th IFAC Symposium on Control of Power and Energy Systems - CPES 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.503},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324006025},
author = {Akio Ito and Hiroyuki Mori and Hsiao-Dong Chiang},
keywords = {distribution network state estimation, distribution automation, evolutionary computation, micro-PMU, smart grids, intelligent control of power systems},
abstract = {This paper proposes a practical method for determining the optimal allocation of micro-Phasor Measurement Units (μPMUs) for distribution system state estimation (DSSE). The proposed method formulates the state estimation based on the nest structure of DistFlow, which is used for power flow calculation in distribution systems due to the redundancy of less than 1. The use of μPMUs can significantly improve the accuracy of estimates. However, Distribution System Operators (DSOs) need to consider optimization constraints before deciding on the optimal location of μPMUs. To tackle this issue, this paper proposes the use of DPPBSO (Discrete Predator-Prey Brain Storm Optimization) of Evolutionary Computation (EC) to optimize the location of μPMUs. PPBSO is an extension method that applies the Predator-Prey strategy to Brain Storm Optimization (BSO), and DPPSO is the discrete version of PPBSO used in solving combinatorial optimization problems. The Predator-Prey strategy is critical in improving the solution candidates by intensifying and diversifying solution searches in EC. Simulation results demonstrate the effectiveness of the proposed method in the IEEE 69-node distribution system.}
}
@article{DALLAQUA2021422,
title = {ForestEyes Project: Conception, enhancements, and challenges},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {422-435},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001965},
author = {Fernanda B.J.R. Dallaqua and Álvaro L. Fazenda and Fabio A. Faria},
keywords = {Citizen Science, Deforestation area detection, Rainforest, Tropical forest, Volunteered Thinking},
abstract = {Rainforests play an important role in the global ecosystem. However, significant regions of them are facing deforestation and degradation due to several reasons. Diverse government and private initiatives were created to monitor and alert for deforestation increases from remote sensing images, using different ways to deal with the notable amount of generated data. Citizen Science projects can also be used to reach the same goal. Citizen Science consists of scientific research involving nonprofessional volunteers for analyzing, collecting data, and using their computational resources to outcome advancements in science and to increase the public’s understanding of problems in specific knowledge areas such as astronomy, chemistry, mathematics, and physics. In this sense, this work presents a Citizen Science project called ForestEyes, which uses volunteer’s answers through the analysis and classification of remote sensing images to monitor deforestation regions in rainforests. To evaluate the quality of those answers, different campaigns/workflows were launched using remote sensing images from Brazilian Legal Amazon and their results were compared to an official groundtruth from the Amazon Deforestation Monitoring Project PRODES. In this work, the first two workflows that enclose the State of Rondônia in the years 2013 and 2016 received more than 35,000 answers from 383 volunteers in the 2,050 created tasks in only two and a half weeks after their launch. For the other four workflows, even enclosing the same area (Rondônia) and different setups (e.g., image segmentation method, image spatial resolution, and detection target), they received 51,035 volunteers’ answers gathered from 281 volunteers in 3,358 tasks. In the performed experiments, it was possible to observe that the volunteers achieved satisfactory overall accuracy, higher than 75%, in the classification of forestation and non-forestation areas using the ForestEyes project. Furthermore, considering an efficient segmentation and a better image spatial resolution, they achieved almost 66% accuracy in the classification of recent deforestation, which is a great challenge to overcome. Therefore, these results show that Citizen Science might be a powerful tool in monitoring deforestation regions in rainforests as well as in obtaining high-quality labeled data.}
}
@article{DECARO200758,
title = {Methodologies for examining problem solving success and failure},
journal = {Methods},
volume = {42},
number = {1},
pages = {58-67},
year = {2007},
note = {Neurocognitive Mechanisms of Creativity: A Toolkit},
issn = {1046-2023},
doi = {https://doi.org/10.1016/j.ymeth.2006.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1046202306002982},
author = {Marci S. DeCaro and Mareike Wieth and Sian L. Beilock},
keywords = {Working memory, Performance, Pressure, Individual differences, Problem solving, Creativity, Short term memory, Stress, Math},
abstract = {When designing research to examine the variables underlying creative thinking and problem solving success, one must not only consider (a) the demands of the task being performed, but (b) the characteristics of the individual performing the task and (c) the constraints of the skill execution environment. In the current paper we describe methodologies that allow one to effectively study creative thinking by capturing interactions among the individual, task, and problem solving situation. In doing so, we demonstrate that the relation between executive functioning and problem solving success is not always as straightforward as one might initially believe.}
}
@article{RYDER2022100703,
title = {Rethinking reflective practice: John Boyd’s OODA loop as an alternative to Kolb},
journal = {The International Journal of Management Education},
volume = {20},
number = {3},
pages = {100703},
year = {2022},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2022.100703},
url = {https://www.sciencedirect.com/science/article/pii/S1472811722001057},
author = {Mike Ryder and Carolyn Downs},
keywords = {OODA, Reflective practice, Experiential learning, Work-based learning, Employability, Business education},
abstract = {The world is changing and business schools are struggling to keep up. Theories of reflective practice developed by the likes of Schon (1983), Gibbs (1988), Driscoll (1994, 2007) and Kolb (1984, 2015) are outdated and unfit for current purposes. Problems include the chronology of events, the orientation of the observer, the impact of external inputs, and the fact that neither education nor the workplace follow a structured, linear path. In response to these challenges, we propose a new ‘solution’: John Boyd's OODA loop. We argue that OODA loops offer the chance to reshape reflective practice and work-based learning for a world in which individuals must cope with ‘an unfolding evolving reality that is uncertain, ever changing and unpredictable’ (Boyd, 1995, slide 1). By embracing the philosophy of John Boyd and his OODA loop theory, business schools can develop greater resilience and employability in graduates, preparing them to embrace change while also embedding the concept of life-long learning to make them better equipped to face the uncertainty that the modern world brings.}
}
@article{CIULLO2021100349,
title = {A framework for building climate storylines based on downward counterfactuals: The case of the European Union Solidarity fund},
journal = {Climate Risk Management},
volume = {33},
pages = {100349},
year = {2021},
issn = {2212-0963},
doi = {https://doi.org/10.1016/j.crm.2021.100349},
url = {https://www.sciencedirect.com/science/article/pii/S2212096321000784},
author = {Alessio Ciullo and Olivia Martius and Eric Strobl and David N. Bresch},
keywords = {Climate storylines, Downward counterfactuals, European Union Solidarity Fund},
abstract = {Recent research introduced the concept of climate storylines as an alternative approach to estimate climate impact and better deal with uncertainties. A climate storyline is an event-based approach which aims at building “physically self-consistent unfolding of past events, or of plausible future events or pathways”. As such, climate storylines may profit from downward counterfactual thinking, which aims at analyzing how past events could have been worse. Notwithstanding the various applications of downward counterfactual thinking in the natural risk management literature, no study relates this with the climate storyline approach. The main goal of this paper is thus to introduce a framework that supports the development of climate storylines from downward counterfactuals. The framework is event-oriented, it focuses on impact, and it is designed to be applied in a participatory fashion. As a proof-of-concept application, we study the impact of tropical cyclones on the European Union Solidarity Fund (EUSF) without conducting a participatory analysis. Tropical cyclones represent a serious threat for the European outermost regions, and their impact to the EUSF capital availability has never been studied. We find that payouts due to tropical cyclones can hamper a recovery of the fund if large payouts concurrently occur in mainland Europe. To avoid this also considering future changes, an increase in capitalization up to 90 % percent may be required.}
}
@article{FERREIRA20131446,
title = {Fostering the Creative Development of Computer Science Students in Programming and Interaction Design},
journal = {Procedia Computer Science},
volume = {18},
pages = {1446-1455},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.312},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913004559},
author = {Deller James Ferreira},
keywords = {Creativity, Programming, Interaction design},
abstract = {This study explores the enhancement of creativity in undergraduate students studying computer science. We assume that everybody has creative potential. As a teacher, we can explicitly encourage creative thinking, providing space to let students collaboratively discover and explore their creativity. This paper presents a dialogical framework to help the teacher fostering creativity among students of computer science in programming and interaction design. The framework presented here involves underlying dialogic processes from seven collaborative and creative dimensions that allow students to develop creativity. The use of the pedagogical framework makes it possible to teachers create significant interaction design and computer programming experiences to students, motivating them to activate mental processes underlying creativity. Students can simultaneously activate two or more ideas, images, or thoughts and have them interact, prompt thought experiments, change cognitive perspectives, raise new points of view, and risk category mistakes.}
}
@article{GOSAK2024103888,
title = {The ChatGPT effect and transforming nursing education with generative AI: Discussion paper},
journal = {Nurse Education in Practice},
volume = {75},
pages = {103888},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.103888},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324000179},
author = {Lucija Gosak and Lisiane Pruinelli and Maxim Topaz and Gregor Štiglic},
keywords = {Artificial Intelligence, ChatGPT, Documentation, Education, Nursing, Nursing Diagnosis},
abstract = {Aim
The aim of this study is to present the possibilities of nurse education in the use of the Chat Generative Pre-training Transformer (ChatGPT) tool to support the documentation process.
Background
The success of the nursing process is based on the accuracy of nursing diagnoses, which also determine nursing interventions and nursing outcomes. Educating nurses in the use of artificial intelligence in the nursing process can significantly reduce the time nurses spend on documentation.
Design
Discussion paper.
Methods
We used a case study from Train4Health in the field of preventive care to demonstrate the potential of using Generative Pre-training Transformer (ChatGPT) to educate nurses in documenting the nursing process using generative artificial intelligence. Based on the case study, we entered a description of the patient's condition into Generative Pre-training Transformer (ChatGPT) and asked questions about nursing diagnoses, nursing interventions and nursing outcomes. We further synthesized these results.
Results
In the process of educating nurses about the nursing process and nursing diagnosis, Generative Pre-training Transformer (ChatGPT) can present potential patient problems to nurses and guide them through the process from taking a medical history, setting nursing diagnoses and planning goals and interventions. Generative Pre-training Transformer (ChatGPT) returned appropriate nursing diagnoses, but these were not in line with the North American Nursing Diagnosis Association – International (NANDA-I) classification as requested. Of all the nursing diagnoses provided, only one was consistent with the most recent version of the North American Nursing Diagnosis Association – International (NANDA-I). Generative Pre-training Transformer (ChatGPT) is still not specific enough for nursing diagnoses, resulting in incorrect answers in several cases.
Conclusions
Using Generative Pre-training Transformer (ChatGPT) to educate nurses and support the documentation process is time-efficient, but it still requires a certain level of human critical-thinking and fact-checking.}
}
@article{TIAN2018104,
title = {The association between visual creativity and cortical thickness in healthy adults},
journal = {Neuroscience Letters},
volume = {683},
pages = {104-110},
year = {2018},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2018.06.036},
url = {https://www.sciencedirect.com/science/article/pii/S0304394018304397},
author = {Fang Tian and Qunlin Chen and Wenfeng Zhu and Yongming Wang and Wenjing Yang and Xingxing Zhu and Xue Tian and Qinglin Zhang and Guikang Cao and Jiang Qiu},
keywords = {Visual creativity, Cortical thickness, Prefrontal cortex, Supplementary motor cortex, Insula},
abstract = {Creativity is necessary to human survival, human prosperity, civilization and well-being. Visual creativity is an important part of creativity and is the ability to create products of novel and useful visual forms, playing important role in many fields such as art, painting and sculpture. There have been several neuroimaging studies exploring the neural basis of visual creativity. However, to date, little is known about the relationship between cortical structure and visual creativity as measured by the Torrance Tests of Creative Thinking. Here, we investigated the association between cortical thickness and visual creativity in a large sample of 310 healthy adults. We used multiple regression to analyze the correlation between cortical thickness and visual creativity, adjusting for gender, age and general intelligence. The results showed that visual creativity was significantly negatively correlated with cortical thickness in the left middle frontal gyrus (MFG), right inferior frontal gyrus (IFG), right supplementary motor cortex (SMA) and the left insula. These observations have implications for understanding that a thinner prefrontal cortex (PFC) (e.g. IFG, MFG), SMA and insula correspond to higher visual creative performance, presumably due to their role in executive attention, cognitive control, motor planning and dynamic switching.}
}
@article{CALEFFI2024110672,
title = {Distributed quantum computing: A survey},
journal = {Computer Networks},
volume = {254},
pages = {110672},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110672},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624005048},
author = {Marcello Caleffi and Michele Amoretti and Davide Ferrari and Jessica Illiano and Antonio Manzalini and Angela Sara Cacciapuoti},
keywords = {Quantum internet, Quantum networks, Quantum communications, Quantum computing, Quantum computation, Distributed quantum computing, Quantum algorithms, Quantum compiler, Quantum compiling, Simulator},
abstract = {Nowadays, quantum computing has reached the engineering phase, with fully-functional quantum processors integrating hundreds of noisy qubits. Yet – to fully unveil the potential of quantum computing out of the labs into the business reality – the challenge ahead is to substantially scale the qubit number, reaching orders of magnitude exceeding thousands of fault-tolerant qubits. To this aim, the distributed quantum computing paradigm is recognized as the key solution for scaling the number of qubits. Indeed, accordingly to such a paradigm, multiple small-to-moderate-scale quantum processors communicate and cooperate for executing computational tasks exceeding the computational power of single processing devices. The aim of this survey is to provide the reader with an overview about the main challenges and open problems arising with distributed quantum computing from a computer and communications engineering perspective. Furthermore, this survey provides an easy access and guide towards the relevant literature and the prominent results in the field.}
}
@article{PERCHTOLDSTEFAN202398,
title = {Functional EEG Alpha Activation Patterns During Malevolent Creativity},
journal = {Neuroscience},
volume = {522},
pages = {98-108},
year = {2023},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2023.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0306452223002178},
author = {Corinna M. Perchtold-Stefan and Christian Rominger and Ilona Papousek and Andreas Fink},
keywords = {malevolent creativity, EEG, alpha power, time-course, divergent thinking},
abstract = {On the dark side of creativity, creative ideation is intentionally used to damage others. This first electroencephalogram (EEG) study on malevolent creativity investigated task-related power (TRP) changes in the alpha band while n = 89 participants (52 women, 37 men) generated original ideas for revenge in the psychometric Malevolent Creativity Test. TRP changes were assessed for different stages of the idea generation process and linked to performance indicators of malevolent creativity. This study revealed three crucial findings: 1) Malevolent creativity yielded topographically distinct alpha power increases similar to conventional creative ideation. 2) Time-related activity changes during malevolent creative ideation were reflected in early prefrontal and mid-stage temporal alpha power increases in individuals with higher malevolent creativity performance. This performance-related, time-sensitive pattern of TRP changes during malevolent creativity may reflect early conceptual expansion from prosocial to antisocial perspectives, and subsequent inhibition of dominant semantic associations in favor of novel revenge ideas. 3) The observed, right-lateralized alpha power increases over the entire ideation phase may denote an additional emotional load of creative ideation. Our study highlights the seminal role of EEG alpha oscillations as a biomarker for creativity, also when creative processes operate in a malevolent context.}
}
@article{GOLDBERG20007,
title = {The Design of Innovation: Lessons from Genetic Algorithms, Lessons for the Real World},
journal = {Technological Forecasting and Social Change},
volume = {64},
number = {1},
pages = {7-12},
year = {2000},
issn = {0040-1625},
doi = {https://doi.org/10.1016/S0040-1625(99)00079-7},
url = {https://www.sciencedirect.com/science/article/pii/S0040162599000797},
author = {David E Goldberg},
abstract = {This article considers some of the connections between genetic algorithms (GAs)—search procedures based on the mechanics of natural selection and natural genetics—and human innovation. Simply stated, innovation has been a source of inspiration for thinking about genetic algorithms, and as the algorithms have improved, GAs have become increasingly interesting computational models of the processes of innovation. The article reviews the basics of genetic algorithm operation and connects the basic mechanics to two processes of innovation: continual improvement and discontinuous change. Thereafter, some of the technical lessons of genetic algorithm processing are reviewed and their implications are briefly explored in the context of organizational change.}
}
@article{TRAGER20241555,
title = {The human touch: Utilizing AlphaFold 3 to analyze structures of endogenous metabolons},
journal = {Structure},
volume = {32},
number = {10},
pages = {1555-1562},
year = {2024},
issn = {0969-2126},
doi = {https://doi.org/10.1016/j.str.2024.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0969212624003356},
author = {Toni K. Träger and Christian Tüting and Panagiotis L. Kastritis},
abstract = {Summary
Computational structural biology aims to accurately predict biomolecular complexes with AlphaFold 3 spearheading the field. However, challenges loom for structural analysis, especially when complex assemblies such as the pyruvate dehydrogenase complex (PDHc), which catalyzes the link reaction in cellular respiration, are studied. PDHc subcomplexes are challenging to predict, particularly interactions involving weaker, lower-affinity subcomplexes. Supervised modeling, i.e., integrative structural biology, will continue to play a role in fine-tuning this type of prediction (e.g., removing clashes, rebuilding loops/disordered regions, and redocking interfaces). 3D analysis of endogenous metabolic complexes continues to require, in addition to AI, precise and multi-faceted interrogation methods.}
}
@article{LANGE2024101191,
title = {What are explanatory proofs in mathematics and how can they contribute to teaching and learning?},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101191},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101191},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000683},
author = {Marc Lange},
keywords = {Explanation, Proof, Generalization, Pedagogy, Unification, Coincidence},
abstract = {This paper will examine several simple examples (drawn from the mathematics literature) where there are multiple proofs of the same theorem, but only some of these proofs are widely regarded by mathematicians as explanatory. These examples will motivate an account of explanatory proofs in mathematics. Along the way, the paper will discuss why deus ex machina proofs are not explanatory, what a mathematical coincidence is, and how a theorem's proper setting reflects the naturalness of various mathematical kinds. The paper will also investigate how context influences which features of a theorem are salient and consequently which proofs are explanatory. The paper will discuss several ways in which explanatory proofs can contribute to teaching and learning, including how shifts in context (and hence in a proof’s explanatory power) can be exploited in a classroom setting, leading students to dig more deeply into why some theorem holds. More generally, the paper will examine how “Why?” questions operate in mathematical thinking, teaching, and learning.}
}
@incollection{PESCE2024123,
title = {Chapter Seven - Creativity and consciousness in motion: The roundtrip of “mindful” and “mindless” processes in embodied creativity},
editor = {Tal Dotan Ben-Soussan and Joseph Glicksohn and Narayanan Srinivasan},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {287},
pages = {123-151},
year = {2024},
booktitle = {The Neurophysiology of Silence (C): Creativity, Aesthetic Experience and Time},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2024.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612324000785},
author = {Caterina Pesce and Nicoletta Tocci},
keywords = {Creative thinking, Motor creativity, Embodiment, Hypofrontality, Flow, Incubation, Mind wandering, Nature, Green exercise, Mindful movements},
abstract = {In this opinion paper, we make a journey across different accounts of creativity that emphasize either the mindful, conscious and cognitive expression of creativity, or its mindless, unconscious and sensorimotor expression. We try to go beyond dichotomy, putting creativity in motion and outlining its embodied and enactive features. Based on the assumption that no creative act is purely conscious or purely unconscious, our discussion on creativity relies on the distinction of three types of creativity that complementarily contribute to the creative process through shifts in the activation of their substrates in the brain: the deliberate, spontaneous and flow types of creativity. The latter is a hybrid and embodied type, in which movement and physical activity meet creativity. We then focus on the most fascinating contribution of unconscious processes and mind wandering to spontaneous and flow modes of creativity, exploring what happens when the individual apparently takes a break from a deliberate and effortful search for solutions and the creative process progresses through an incubation phase. This phase and the overall creative process can be facilitated by physical activity which, depending on its features and context, can disengage the cognitive control network and free the mind from filters that constrain cognitive processes or, conversely, can engage attentional control on sensorimotor and cognitive task components in a mindful way. Lastly, we focus on the unique features of the outer natural environment of physical activity and of the inner environment during mindful movements that can restore capacities and boost creativity.}
}
@article{ZHURAVLEV2023104934,
title = {Three levels of information processing in the brain},
journal = {Biosystems},
volume = {229},
pages = {104934},
year = {2023},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2023.104934},
url = {https://www.sciencedirect.com/science/article/pii/S0303264723001090},
author = {Aleksandr V. Zhuravlev},
keywords = {Brain, Information, Consciousness, The hard problem of consciousness, Qualia, Entropy},
abstract = {Information, the measure of order in a complex system, is the opposite of entropy, the measure of chaos and disorder. We can distinguish several levels at which information is processed in the brain. The first one is the level of serial molecular genetic processes, similar in some aspects to digital computations (DC). At the same time, higher cognitive activity is probably based on parallel neural network computations (NNC). The advantage of neural networks is their intrinsic ability to learn, adapting their parameters to specific tasks and to external data. However, there seems to be a third level of information processing as well, which involves subjective consciousness and its units, so called qualia. They are difficult to study experimentally, and the very fact of their existence is hard to explain within the framework of modern physical theory. Here I propose a way to consider consciousness as the extension of basic physical laws – namely, total entropy dissipation leading to a system simplification. At the level of subjective consciousness, the brain seems to convert information embodied by neural activity to a more simple and compact form, internally observed as qualia. Whereas physical implementations of both DC and NNC are essentially approximate and probabilistic, qualia-associated computations (QAC) make the brain capable of recognizing general laws and relationships. While elaborating a behavioral program, the conscious brain does not act blindly or gropingly but according to the very meaning of such general laws, which gives it an advantage compared to any artificial intelligence system.}
}
@incollection{DRYGAS20201,
title = {1 - Introduction to computational methods and theory of composites},
editor = {Piotr Drygaś and Simon Gluzman and Vladimir Mityushev and Wojciech Nawalaniec},
booktitle = {Applied Analysis of Composite Media},
publisher = {Woodhead Publishing},
pages = {1-56},
year = {2020},
series = {Woodhead Publishing Series in Composites Science and Engineering},
isbn = {978-0-08-102670-0},
doi = {https://doi.org/10.1016/B978-0-08-102670-0.00010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008102670000010X},
author = {Piotr Drygaś and Simon Gluzman and Vladimir Mityushev and Wojciech Nawalaniec},
keywords = {Self-consistent approximation, structural sum, statistical mechanics methods, self-Similarity and renormalization-group},
abstract = {Overview of traditional approaches based on self-consistent approximations in composite materials is presented. Their restrictions are underlined. Neoclassical approach previously introduced in the Preface, is illustrated and compared to methods applied in statistical mechanics. The structural sums, the key construction of the neoclassical approach, are outlined. Method of series and asymptotic method of approximants, Padé approximants, DLog Padé approximants, Factor, Root, Additive approximants are briefly discussed. Notion of Self-Similarity and renormalization-group is introduced. Minimal difference and minimal derivative methods of calculation for short series are discussed in detail. Critical Index is calculated from various short series. DLog root approximants are introduced and illustrate by several examples, where the DLog Padé approximants fail. DLog additive approximants are introduced and presented iteratively. Multiple examples are presented in the chapter and in the appendix. Method of Log Padé approximants is suggested.}
}
@article{ALY2014206,
title = {Atmospheric boundary-layer simulation for the built environment: Past, present and future},
journal = {Building and Environment},
volume = {75},
pages = {206-221},
year = {2014},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2014.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0360132314000444},
author = {Aly Mousaad Aly},
keywords = {Aerodynamics, Aeroelasticity, Atmospheric boundary-layer, Built environment, Experimental/computational wind engineering},
abstract = {This paper summarizes the state-of-the-art techniques used to simulate hurricane winds in atmospheric boundary-layer (ABL) for wind engineering testing. The wind tunnel simulation concept is presented along with its potential applications, advantages and challenges. ABL simulation at open-jet simulators is presented along with an application example followed by a discussion on the advantages and challenges of testing at these facilities. Some of the challenges and advantages of using computational fluid dynamics (CFD) are presented with an application example. The paper show that the way the wind can be simulated is complex and matching one parameter at full-scale may lead to a mismatch of other parameters. For instance, while large-scale testing is expected to improve Reynolds number and hence approach the full-scale scenario, it is challenging to generate large-scale turbulence in an artificially created wind. New testing protocols for low-rise structures and small-size architectural features are presented as an answer to challenging questions associated with both wind tunnel and open-jet testing. Results show that it is the testing protocol that can be adapted to enhance the prediction of full-scale physics in nature. Thinking out of the box and accepting non-traditional ABL is necessary to compensate for Reynolds effects and to allow for convenient experimentation. New research directions with focus on wind, rain and waves as well as other types of non-synoptic winds are needed, in addition to a more focus on the flow physics in the lower part of the ABL, where the major part of the infrastructure exists.}
}
@article{KNAPP2017370,
title = {Energy-efficient Legionella control that mimics nature and an open-source computational model to aid system design},
journal = {Applied Thermal Engineering},
volume = {127},
pages = {370-377},
year = {2017},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2017.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S135943111633664X},
author = {Samuel Knapp and Bo Nordell},
keywords = {Thermal model, Heat exchanger, Pasteurization, Legionnaire’s disease, Microsoft Excel},
abstract = {Although there is no direct connection, the incidence of Legionnaire’s disease has increased concurrently with increased usage of energy efficient domestic hot water (DHW) systems, which serve as ideal growth environments for Legionella pneumophila, the bacteria responsible for Legionnaire’s disease. The Duck Foot Heat Exchange Model (DFHXM) was developed to aid design of energy efficient thermal pasteurization systems with Legionella control specifically in mind. The model simulates a system design imitating the countercurrent heat exchange in the feet of ducks, an evolutionary adaption reducing environmental heat losses in cold climates. Such systems use a heat exchanger to preheat fluids prior to pasteurization and cool the same fluid after pasteurization. Thus, the design requires minimal addition of heat to achieve pasteurization temperatures and to cover environmental heat losses. This article describes the underlying principles and use of the freely available Microsoft Excel model, as well as compares results from the DFHXM to measurements of an experimental pilot system. Simulation outputs agreed well with experimental results for transient and steady-state temperatures, the largest discrepancy in steady-state temperatures being 4.6%. Lastly, we discuss the flexibility of the DFHXM to simulate a wide variety of designs with special emphasis on Legionella control and solar-thermal water disinfection.}
}
@article{ESCOLAGASCON2023111893,
title = {Who falls for fake news? Psychological and clinical profiling evidence of fake news consumers},
journal = {Personality and Individual Differences},
volume = {200},
pages = {111893},
year = {2023},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2022.111893},
url = {https://www.sciencedirect.com/science/article/pii/S0191886922003981},
author = {Álex Escolà-Gascón and Neil Dagnall and Andrew Denovan and Kenneth Drinkwater and Miriam Diez-Bosch},
keywords = {Fake news, Pseudoscientific information, Cognitive biases, Individual differences, Clinical prevention},
abstract = {Awareness of the potential psychological significance of false news increased during the coronavirus pandemic, however, its impact on psychopathology and individual differences remains unclear. Acknowledging this, the authors investigated the psychological and psychopathological profiles that characterize fake news consumption. A total of 1452 volunteers from the general population with no previous psychiatric history participated. They responded to clinical psychopathology assessment tests. Respondents solved a fake news screening test, which allowed them to be allocated to a quasi-experimental condition: group 1 (non-fake news consumers) or group 2 (fake news consumers). Mean comparison, Bayesian inference, and multiple regression analyses were applied. Participants with a schizotypal, paranoid, and histrionic personality were ineffective at detecting fake news. They were also more vulnerable to suffer its negative effects. Specifically, they displayed higher levels of anxiety and committed more cognitive biases based on suggestibility and the Barnum Effect. No significant effects on psychotic symptomatology or affective mood states were observed. Corresponding to these outcomes, two clinical and therapeutic recommendations related to the reduction of the Barnum Effect and the reinterpretation of digital media sensationalism were made. The impact of fake news and possible ways of prevention are discussed.}
}
@article{XIA2023100730,
title = {Understanding common human driving semantics for autonomous vehicles},
journal = {Patterns},
volume = {4},
number = {7},
pages = {100730},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100730},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923000703},
author = {Yingji Xia and Maosi Geng and Yong Chen and Sudan Sun and Chenlei Liao and Zheng Zhu and Zhihui Li and Washington Yotto Ochieng and Panagiotis Angeloudis and Mireille Elhajj and Lei Zhang and Zhenyu Zeng and Bing Zhang and Ziyou Gao and Xiqun (Michael) Chen},
keywords = {human-machine interaction, neuroscience, hierarchical understanding abstraction, electroencephalography, neural-informed model, driving behavior perception, driving semantics, autonomous vehicle},
abstract = {Summary
Autonomous vehicles will share roads with human-driven vehicles until the transition to fully autonomous transport systems is complete. The critical challenge of improving mutual understanding between both vehicle types cannot be addressed only by feeding extensive driving data into data-driven models but by enabling autonomous vehicles to understand and apply common driving behaviors analogous to human drivers. Therefore, we designed and conducted two electroencephalography experiments for comparing the cerebral activities of human linguistics and driving understanding. The results showed that driving activates hierarchical neural functions in the auditory cortex, which is analogous to abstraction in linguistic understanding. Subsequently, we proposed a neural-informed, semantics-driven framework to understand common human driving behavior in a brain-inspired manner. This study highlights the pathway of fusing neuroscience into complex human behavior understanding tasks and provides a computational neural model to understand human driving behaviors, which will enable autonomous vehicles to perceive and think like human drivers.}
}
@article{SAVIN202110,
title = {Main topics in EIST during its first decade: A computational-linguistic analysis},
journal = {Environmental Innovation and Societal Transitions},
volume = {41},
pages = {10-17},
year = {2021},
note = {Celebrating a decade of EIST: What’s next for transition studies?},
issn = {2210-4224},
doi = {https://doi.org/10.1016/j.eist.2021.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S221042242100037X},
author = {Ivan Savin and Jeroen {van den Bergh}},
keywords = {Machine learning, Topic modelling, Literature review},
abstract = {We analyse 465 articles published in EIST from June 2011 until June 2021 to identify topics addressed in the journal. We find eight main topics and assess how their shares changed over time as well as how many citations they received. The topics with the largest shares in all publications are “Theory of socio-technical transitions” and “Urban regimes and niches”. The two most cited topics, “Theory of socio-technical transitions” and “Geography and diffusion of eco-innovations”, showed a rising share over time, while the share of topic “Finance, investment and growth” declined. We further assess the geographical coverage of topics, through affiliations of the corresponding authors. The resulting map indicates dominant topics for the 34 countries that contributed to publications in EIST.}
}
@article{PORNSUWANCHAROEN20181034,
title = {Meditation mathematical formalism and Lorentz factor calculation based-on Mindfulness foundation},
journal = {Results in Physics},
volume = {11},
pages = {1034-1038},
year = {2018},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2018.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211379718325294},
author = {N. Pornsuwancharoen and I.S. Amiri and J. Ali and P. Youplao and P. Yupapin},
keywords = {Meditation science, Mindfulness Foundation, Buddhism philosophy, Mathematics foundation, Natural science},
abstract = {Mindfulness foundation is an excellent method of the human spiritual development by the reasonable thinking and consideration, which was established by Lord Buddha a long time ago. There are four ways of thinking and consideration-(i) form (body), (ii) sensation, (iii) spiritual and (iv) Dhamma. In this paper, we propose the use of the form consideration for the spiritual development, in which the form can be considered thoroughly inside the body by the spiritual projection. By using the nonlinear microring resonator known as a Panda-ring resonator, the electromagnetic (EM) signals called polaritons can be generated by the coupling interaction between the intense EM fields and the ionic diploes within the almost closed system, where the dipoles can obtain from the coupling between the gold grating and the strong electromagnetic fields. In the manipulation, cells, tissues, and organs inside the human body can communicate with the spiritual (polaritonic) signals and investigation. The simulation results obtained have shown that the Lorentz factor of 0.99999959 is obtained. The successively filtering of the signal circulation within the body during the meditation can be formulated and the meditation behaviors modeled. The aura, the stopping, and the cold body states can be configured and explained.}
}
@article{KALAY199837,
title = {P3: Computational environment to support design collaboration},
journal = {Automation in Construction},
volume = {8},
number = {1},
pages = {37-48},
year = {1998},
issn = {0926-5805},
doi = {https://doi.org/10.1016/S0926-5805(98)00064-8},
url = {https://www.sciencedirect.com/science/article/pii/S0926580598000648},
author = {Yehuda E Kalay},
keywords = {Collaborative design, Design environment, Product model, Performance model, Process model},
abstract = {The work reported in this paper addresses the paradoxical state of the construction industry (also known as A/E/C, for Architecture, Engineering and Construction), where the design of highly integrated facilities is undertaken by severely fragmented teams, leading to diminished performance of both processes and products. The construction industry has been trying to overcome this problem by partitioning the design process hierarchically or temporally. While these methods are procedurally efficient, their piecemeal nature diminishes the overall performance of the project. Computational methods intended to facilitate collaboration in the construction industry have, so far, focused primarily on improving the flow of information among the participants. They have largely met their stated objective of improved communication, but have done little to improve joint decision-making, and therefore have not significantly improved the quality of the design project itself. We suggest that the main impediment to effective collaboration and joint decision-making in the A/E/C industry is the divergence of disciplinary `world-views', which are the product of educational and professional processes through which the individuals participating in the design process have been socialized into their respective disciplines. To maximize the performance of the overall project, these different world-views must be reconciled, possibly at the expense of individual goals. Such reconciliation can only be accomplished if the participants find the attainment of the overall goals of the project more compelling than their individual disciplinary goals. This will happen when the participants have become cognizant and appreciative of world-views other than their own, including the objectives and concerns of other participants. To achieve this state of knowledge, we propose to avail to the participants of the design team highly specific, contextualized information, reflecting each participant's valuation of the proposed design actions. P3 is a semantically-rich computational environment, which is intended to fulfill this mission. It consists of: (1) a shared representation of the evolving design project, connected (through the World Wide Web) to (2) individual experts and their discipline-specific knowledge repositories; and (3) a computational project manager makes the individual valuations visible to all the participants, and helps them deliberate and negotiate their respective positions for the purpose of improving the overall performance of the project. The paper discusses the theories on which the three components are founded, their function, and the principles of their implementation.}
}
@article{WANG2024109589,
title = {Cellular gradient algorithm for solving complex mechanical optimization design problems},
journal = {International Journal of Mechanical Sciences},
volume = {282},
pages = {109589},
year = {2024},
issn = {0020-7403},
doi = {https://doi.org/10.1016/j.ijmecsci.2024.109589},
url = {https://www.sciencedirect.com/science/article/pii/S0020740324006301},
author = {Rugui Wang and Xinpeng Li and Haibo Huang and Zhipeng Fan and Fuqiang Huang and Ningjuan Zhao},
keywords = {Mechanical optimization, Optimization algorithm, Discrete integrable problem, Cellular automaton, Gradient descent},
abstract = {In mechanical optimization design problems, there are often some non-continuous or non-differentiable objective functions. For these non-continuous and non-differentiable optimization objectives, it is often difficult for existing optimal design algorithms to find the desired optimal solutions. In this paper, we incorporate the idea of gradient descent into cellular automata and propose a Cellular Gradient (CG) method. First, we have given the basic rules and algorithmic framework of CG and designed three kinds of growth and extinction rules respectively. Then, the three evolutionary rules for cellular within a single cycle are analyzed separately for form and ordering. The best expressions for the cellular jealous neighbor rule and the solitary regeneration rule are given, and the most appropriate order in which the rules are run is selected. Finally, the solution results of the cellular gradient algorithm and other classical optimization design algorithms are compared with a multi-objective multi-parameter mechanical optimization design problem as an example. The computational results show that the cellular gradient algorithm has an advantage over other algorithms in solving global and dynamic mechanical optimal design problems. The novelty of CG is to provide a new way of thinking for solving optimization problems with global discontinuities.}
}
@article{LUNGU2008255,
title = {Partial current information and signal extraction in a rational expectations macroeconomic model: A computational solution},
journal = {Economic Modelling},
volume = {25},
number = {2},
pages = {255-273},
year = {2008},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2007.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0264999307000818},
author = {L. Lungu and K.G.P. Matthews and A.P.L. Minford},
keywords = {Rational expectations, Partial current information, Signal extraction, Macroeconomic modelling},
abstract = {Previous attempts at modelling current observed endogenous financial variables in a macroeconomic model have concentrated on only one variable — the short-term rate of interest. This paper applies a general search algorithm to a macroeconomic model with an observed interest rate and exchange rate to solve the signal extraction problem. Firstly, the algorithm is tested against a linear model with a known analytical solution. Then, the algorithm is applied to all the observed current endogenous variables in a non-linear rational expectations model of the UK. The informational advantage of applying the signal extraction algorithm is evaluated in terms of the forecasting efficiency of the model.}
}
@article{ANURADHA2022100429,
title = {A RNN based offloading scheme to reduce latency and preserve energy using RNNBOS},
journal = {Measurement: Sensors},
volume = {24},
pages = {100429},
year = {2022},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100429},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422000630},
author = {C. Anuradha and M. Ponnavaikko},
keywords = {Computational offloading, Mobile edge computing, Deep neural network, Energy consumption and mobile cloud computing},
abstract = {Mobile cloud computing is currently evolving quickly in today's trend and it provides infinite number of applications to the people those who are using regularly.MCC means the mobile gadgets are strongly tied up with cloud technology to execute various application for attaining many tasks. Mobile devices contain different application according to its own capacity to hold each application. In which many applications are in need of connecting with cloud storage. A new proposed technique named RNNBOS (Recurrent Neural Network Based Offloading scheme) is used to compute calculations in terms of energy source of mobile device along with active conditions of network, Load computations, delay possibility of request from device and quantitative amount of data being transferred for this purpose. We have simulated the above technique using python tool and observed RNN based offloading scheme is good in execution of application using MCC.}
}
@article{CANADAS201687,
title = {Second graders articulating ideas about linear functional relationships},
journal = {The Journal of Mathematical Behavior},
volume = {41},
pages = {87-103},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2015.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312315300055},
author = {María C. Cañadas and Bárbara M. Brizuela and Maria Blanton},
keywords = {Quantities, Functional thinking, Early algebra, Elementary students},
abstract = {In this paper, we explore the ideas that second grade students articulate about functional relationships. We adopt a function-based approach to introduce elementary school children to algebraic content. We present results from a design-based research study carried out with 21 second-grade students (approximately 7 years of age). We focus on a lesson from our classroom teaching experiment in which the students were working on a problem that involved a linear functional relationship (y=2x). From the analysis of students’ written work and classroom video, we illustrate two different approaches that students adopt to express the relationship between two quantities. Students show fluency recontextualizing the problem posed, moving between extra-mathematical and intra-mathematical contexts.}
}
@article{SHUKLA2024117388,
title = {Association of road traffic noise exposure and school childrens’ cognition: A structural equation model approach},
journal = {Environmental Research},
volume = {240},
pages = {117388},
year = {2024},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2023.117388},
url = {https://www.sciencedirect.com/science/article/pii/S0013935123021928},
author = {Avnish Shukla and Bhaven N. Tandel},
keywords = {School children, Cognition, Traffic noise index (TNI), Exploratory factor analysis (EFA), Structural equation modeling (SEM)},
abstract = {This study explores the complex relationship between traffic noise and school children's cognition, acknowledging existing empirical inconsistencies and aiming to contribute to a richer understanding of this pivotal issue. Schools adjacent to noisy roads were selected, and outdoor noise levels were measured employing a Kimo dB300 sound level meter, focusing on noise level indices LAeq, L10, and L90. Subsequent calculations were performed to determine the noise pollution level (Lnp), noise climate (NC), and traffic noise index (TNI), revealing a severe noise exposure when compared to standard guidelines. A perception questionnaire for various noise and acoustic factors influencing cognition was developed, and 1524 student responses were collected. Data analysis incorporated Principal Component Analysis (PCA) and Exploratory Factor Analysis (EFA) for dimension reduction, revealing three latent factors labelled 'annoyance,' 'behaviour,' and 'cognition'. Further, Structural Equation Modeling (SEM) was utilized to explore multivariate relationships between variables and latent factors. Resultant path coefficients were obtained as 0.12, 0.98, and 0.10 for the impact of 'behaviour' and 'annoyance' on 'cognition' and the correlation between 'annoyance' and 'behaviour', respectively. Findings underscore a potent positive impact of annoyance, stemming from acute ambient noise exposure, on the deterioration of children's cognition. While suggesting that ambient noise may be correlated with adverse health impacts due to its influence on cognition, this study emphasizes the pressing necessity for noise mitigation in roadside schools and stringent enforcement of noise pollution guidelines in academic zones.}
}
@article{CADART2024113107,
title = {An optimal penalty method for the joint stiffening in beam models of additively manufactured lattice structures},
journal = {International Journal of Solids and Structures},
pages = {113107},
year = {2024},
issn = {0020-7683},
doi = {https://doi.org/10.1016/j.ijsolstr.2024.113107},
url = {https://www.sciencedirect.com/science/article/pii/S0020768324004669},
author = {T. Cadart and T. Hirschler and S. Bahi and S. Roth and F. Demoly and N. Lebaal},
keywords = {Lattice structure, Beam formulation, Penalty method, Joint stiffening, Optimization, Additive manufacturing, Material jetting},
abstract = {Additive manufacturing is revolutionizing structural design, with lattice structures becoming increasingly prominent due to their superior mechanical properties. However, simulating these structures quickly and accurately using the finite element method (FEM) remains challenging. Recent research has highlighted beam element simulation within FEM as a more efficient alternative to traditional solid FE simulations, achieving similar accuracy with reduced computational resources. However, a significant challenge is managing the lack of rigidity at nodes and the prevalence of low aspect ratio beams. While various methodologies have been proposed to address these issues, there is still a gap in the comprehensive evaluation of their limitations. An optimal node penalization methodology is required to expand the limited range of accurately represented lattice behavior. A preliminary study investigates lattice geometries through comparative analysis of solid and beam FE simulations. Built on this, we developed a methodology suitable to linear, dynamics and nonlinear beam FE simulations, contributing to enhanced computational speed and accuracy. Several lattice structures were printed using material jetting and quasi-static compressive tests were conducted to validate the methodology’s accuracy. The numerical results reveal a good accuracy between the proposed beam FE methodology and the experimental data, offering a better alternative to conventional FEM for energy absorption in terms of computing time.}
}
@article{SEWALL2020,
title = {Fiber Force: A Fiber Diet Intervention in an Advanced Course-Based Undergraduate Research Experience (CURE) Course},
journal = {Journal of Microbiology & Biology Education},
volume = {21},
number = {1},
year = {2020},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v21i1.1991},
url = {https://www.sciencedirect.com/science/article/pii/S1935787720000660},
author = {Julia Massimelli Sewall and Andrew Oliver and Kameryn Denaro and Alexander B. Chase and Claudia Weihe and Mi Lay and Jennifer B. H. Martiny and Katrine Whiteson},
abstract = {Course-based undergraduate research experiences (CUREs) are an effective way to introduce students to contemporary scientific research. Research experiences have been shown to promote critical thinking, improve understanding and proper use of the scientific method, and help students learn practical skills including writing and oral communication. We aimed to improve scientific training by engaging students enrolled in an upper division elective course in a human microbiome CURE. The “Fiber Force” course is aimed at studying the effect of a wholesome high-fiber diet (40 to 50 g/day for two weeks) on the students’ gut microbiomes. Enrolled students participated in a noninvasive diet intervention, designed health surveys, tested hypotheses on the effect of a diet intervention on the gut microbiome, and analyzed their own samples (as anonymized aggregates). The course involved learning laboratory techniques (e.g., DNA extraction, PCR, and 16S sequencing) and the incorporation of computational techniques to analyze microbiome data with QIIME2 and within the R software environment. In addition, the learning objectives focused on effective student performance in writing, data analysis, and oral communication. Enrolled students showed high performance grades on writing, data analysis and oral communication assignments. Pre- and post-course surveys indicate that the students found the experience favorable, increased their interest in science, and heightened awareness of their diet habits. Fiber Force constitutes a validated case of a research experience on microbiology with the capacity to improve research training and promote healthy dietary habits.}
}
@article{QIAN2024120487,
title = {E3WD: A three-way decision model based on ensemble learning},
journal = {Information Sciences},
volume = {667},
pages = {120487},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120487},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524004006},
author = {Jin Qian and Di Wang and Ying Yu and XiBei Yang and Shang Gao},
keywords = {Three-way decision, Ensemble strategy, Cluster ensemble, Membership degree, Critical threshold},
abstract = {Three-way decision model is an effective way to deal with complex decision problems. However, since the three-way decision models now proposed are all based on a single decision criterion, the decision results typically reflect only one preference of decision-makers. Thus, these models may also not effectively deal with complex decision-making problems. To solve the above problems, this paper proposes a new three-way decision model based on ensemble learning. Specifically, we first obtain different three-way decision results by employing different decision criteria. Then, we can acquire the core and candidate sets of the positive and negative regions through set operations. Next, we use the K-means algorithm to divide the candidate sets into three disjoint subsets based on similarities. After that, we adopt a hierarchical filtering method to select suitable objects from the candidate sets and add them to the core sets. Finally, we employ four three-way decision models with different decision criteria as examples to conduct experiments on eight datasets. Experimental results show that our proposed model can obtain higher classification accuracy and lower deferment rate than other traditional three-way decision models under most experimental conditions.}
}
@article{TWORZYDLO1995759,
title = {Knowledge-based methods and smart algorithms in computational mechanics},
journal = {Engineering Fracture Mechanics},
volume = {50},
number = {5},
pages = {759-800},
year = {1995},
issn = {0013-7944},
doi = {https://doi.org/10.1016/0013-7944(94)E0060-T},
url = {https://www.sciencedirect.com/science/article/pii/0013794494E0060T},
author = {W.W. Tworzydlo and J.T. Oden},
abstract = {Effective methods leading to automated, computer-based solution of complex engineering design problems are studied in this paper. In particular, methods of automation of the finite element analyses are of primary interest here. These include algorithmic approaches, based on error estimation, adaptivity and smart algorithms, as well as heuristic approaches based on methods of knowledge engineering. A computational environment, which interactively couples h-p adaptive finite element methods with object-oriented programming and expert system tools, is presented. Several examples illustrate the merit and potential of the approaches studied here.}
}
@article{RAHMAN20125541,
title = {Developing Mathematical Communication Skills of Engineering Students},
journal = {Procedia - Social and Behavioral Sciences},
volume = {46},
pages = {5541-5547},
year = {2012},
note = {4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.472},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812022082},
author = {Roselainy Abdul Rahman and Yudariah Mohammad Yusof and Hamidreza Kashefi and Sabariah Baharun},
keywords = {Communication, Mathematical Thinking, Multivariable Calculus, Student's Obstacles},
abstract = {In Malaysia and also elsewhere in the world the demands for graduates who have employability skills such as ability to think critically, solve problems and can communicate are highly sought in the workplace. In the early 2006, the development of such skills was recognized as integral goals of undergraduate education at Universiti Teknologi Malaysia. Since then rigorous efforts have been made to inculcate these skills amongst the undergraduates. In this paper, we will share some of our experiences in coping with the challenges of changing our teaching practices to accommodate this quest though focusing on communication. For mathematics learning to occur, we believed that students should participate actively in the knowledge construction and be able to take charge of their own learning. Taking these aspects into consideration, we had developed a framework of active learning and used it to guide our instruction in engineering mathematics at UTM. Here we will discuss the strategies that we had designed and employed in engaging students with the subject matter as well as to initiate and support student's thinking and communication in the language of mathematics. Some student's responses that gave indications of their struggle, progress and growth encountered in the research implementation will also be presented.}
}
@article{MUSGRAVE2017137,
title = {Understanding and advancing graduate teaching assistants’ mathematical knowledge for teaching},
journal = {The Journal of Mathematical Behavior},
volume = {45},
pages = {137-149},
year = {2017},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2016.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0732312316302012},
author = {Stacy Musgrave and Marilyn P. Carlson},
keywords = {Graduate student teaching assistant, Mathematical meanings, Average rate of change, Precalculus},
abstract = {Graduate student teaching assistants (GTAs) usually teach introductory level courses at the undergraduate level. Since GTAs constitute the majority of future mathematics faculty, their image of effective teaching and preparedness to lead instructional improvements will impact future directions in undergraduate mathematics curriculum and instruction. In this paper, we argue for the need to support GTAs in improving their mathematical meanings of foundational ideas and their ability to support productive student thinking. By investigating GTAs’ meanings for average rate of change, a key content area in precalculus and calculus, we found evidence that even mathematically sophisticated GTAs possess impoverished meanings of this key idea. We argue for the need, and highlight one approach, for supporting GTAs to improve their understanding of foundational mathematical ideas and how these ideas are learned.}
}
@article{IVANOV2023108938,
title = {Intelligent digital twin (iDT) for supply chain stress-testing, resilience, and viability},
journal = {International Journal of Production Economics},
volume = {263},
pages = {108938},
year = {2023},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2023.108938},
url = {https://www.sciencedirect.com/science/article/pii/S0925527323001706},
author = {Dmitry Ivanov},
keywords = {Supply chain resilience, Intelligent digital twin, Data analytics, Stress-test, Ripple effect, anyLogistix},
abstract = {A large variety of models have been developed in the last two decades aiming at supply chain (SC) stress-testing and resilience. New digital and artificial intelligence (AI) technologies allow to develop novel approaches and tools in this area for the transition from standalone models to intelligent decision-support systems (DSSs). However, the literature lacks concepts and guidelines for the design of such systems. In this paper, we offer a generalized decision-making framework for using digital twins in SC stress-testing and resilience analysis as well as delineate how digital twins can contribute to theory development in SC resilience and viability. We position our proposed approach as an intelligent digital twin (iDT) – a human–AI system which visualizes physical SCs in digital form, collects and processes data for modelling using analytics methods, mimics human decision-making rules, and creates new knowledge and decision-making algorithms through human–AI collaboration. We conclude that the iDT supports monitoring, disruption prediction (early signals), event-driven responses, learning, and proactive thinking, integrating proactive and reactive approaches to SC resilience. The iDT helps to make the unknown known and so contributes to the development of a proactive, adaptation-based view on SC resilience and viability. This research can be used to solve existing problems in the industry, and it develops new methods and infrastructures for solutions to future problems.}
}
@article{NISSEL2024105856,
title = {Why wearing a yellow hat is impossible: Chinese and U.S. children's possibility judgments},
journal = {Cognition},
volume = {251},
pages = {105856},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105856},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724001422},
author = {Jenny Nissel and Jiaying Xu and Lihanjing Wu and Zachary Bricken and Jennifer M. Clegg and Hui Li and Jacqueline D. Woolley},
keywords = {Cognitive development, Social development, Possibility, Intuitive theories, Cross-cultural, LIWC},
abstract = {When thinking about possibility, one can consider both epistemic and deontic principles (i.e., physical possibility and permissibility). Cultural influences may lead individuals to weigh epistemic and deontic obligations differently; developing possibility conceptions are therefore positioned to be affected by cultural surroundings. Across two studies, 251 U.S. and Chinese 4-, 6-, and 8-year-olds sampled from major metropolitan areas in Texas and the Hubei, Sichuan, Gansu, and Guangdong Provinces judged the possibility of impossible, improbable, and ordinary events. Across cultures and ages, children judged ordinary events as possible and impossible events as impossible; cultural differences emerged in developing conceptions of improbable events. Whereas U.S. children became more likely to judge these events possible with age, Chinese children's judgments remained consistent with age: Chinese 4- to 8-year-olds judged these events to be possible ∼25% of the time. In Study 2, to test whether this difference was attributable to differential prioritization of epistemic versus deontic constraints, children also judged whether each event was an epistemic violation (i.e., required magic to happen) and a deontic violation (i.e., would result in someone getting in trouble). With age, epistemic judgments were increasingly predictive of possibility judgments for improbable events for U.S. children, and decreasingly so for Chinese children. Contrary to our predictions, deontic judgments were not predictive. We propose that cultural valuation of norms might shape children's developing intuitions about possibility. We discuss our findings in light of three accounts of possibility conceptions, suggesting ways to integrate cultural context into each.}
}
@article{SINGH2024101269,
title = {An empirical approach to understand the role of emotions in code comprehension},
journal = {Journal of Computer Languages},
volume = {79},
pages = {101269},
year = {2024},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2024.101269},
url = {https://www.sciencedirect.com/science/article/pii/S2590118424000121},
author = {Divjot Singh and Ashutosh Mishra and Ashutosh Aggarwal},
keywords = {Code comprehension, Systematic literature review, Emotions, Cognitive skills},
abstract = {Programming and cognitive skills are two pivotal abilities of programmers to maintain software products. First, this study included a systematic literature review on code comprehension, emotions, cognitive psychology, and belief-desire-intention domains to analyse various code comprehension monitoring techniques, performance metrics, and computational methodologies. Second, a case study is conducted to examine the influence of various emotional stages on programmers’ programming and cognitive skills while comprehending the software code. The categorization of the participants is done empirically based on their expertism level, and the same results are verified using various machine learning models and performance metrics.}
}
@article{FALBEN2023105386,
title = {The power of the unexpected: Prediction errors enhance stereotype-based learning},
journal = {Cognition},
volume = {235},
pages = {105386},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105386},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723000203},
author = {Johanna K. Falbén and Marius Golubickis and Dimitra Tsamadi and Linn M. Persson and C. Neil Macrae},
keywords = {Stereotyping, Person perception, Reinforcement learning, Prediction errors, Drift diffusion model},
abstract = {Stereotyping is a ubiquitous feature of social cognition, yet surprisingly little is known about how group-related beliefs influence the acquisition of person knowledge. Accordingly, in combination with computational modeling (i.e., Reinforcement Learning Drift Diffusion Model analysis), here we used a probabilistic selection task to explore the extent to which gender stereotypes impact instrumental learning. Several theoretically interesting effects were observed. First, reflecting the impact of cultural socialization on person construal, an expectancy-based preference for stereotype-consistent (vs. stereotype-inconsistent) responses was observed. Second, underscoring the potency of unexpected information, learning rates were faster for counter-stereotypic compared to stereotypic individuals, both for negative and positive prediction errors. Collectively, these findings are consistent with predictive accounts of social perception and have implications for the conditions under which stereotyping can potentially be reduced.}
}
@article{WANG2024111842,
title = {Three-way decision based island harmony search algorithm for robust flow-shop scheduling with uncertain processing times depicted by big data},
journal = {Applied Soft Computing},
volume = {162},
pages = {111842},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111842},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624006161},
author = {Bing Wang and Pengfei Zhang and Xiaozhi Wang and Quanke Pan},
keywords = {Robust flow-shop scheduling, Island harmony search, Big data, Three-way decision, Surrogate worst-case scenario},
abstract = {This paper discusses an uncertain two-machine permutation flow-shop scheduling problem (2PFSP) with total weighted tardiness and common due date. Uncertain processing times are described by a large set of discrete scenarios, which is a type of big data. The objective is to minimize the schedule performance under the worst-case scenario. Identifying the worst-case scenario for each evaluated schedule is quite time-consuming in the situation that the scenario set size is large so that the objective evaluation might be computationally expensive. To handle this difficulty, three-way decision is used to preprocess the large-size scenario set to get a reduced scenario set so that the concept of surrogate worst-case scenario is adopted. A hybrid harmony search algorithm of combining three-island framework and the scenario-based local search is developed to solve the discussed problem. Based on the single-scenario knowledge of 2PFSP, a problem-specific scenario-dependent neighborhood structure is constructed under the surrogate worst-case scenario. An extensive experiment was carried out. The computational results show that the application of surrogate worst-case scenario based on three-way decision is effective in reducing the time consuming while keeping schedule performance evaluation. Being compared to the worst-case scenario objective evaluation, for an example in the case of the middle bad-scenario ratio, the surrogate worst-case scenario objective evaluation made the solution algorithm save 12.95 % in average CPU time for all instances while the relative performance difference is only 1.809 % in average. Being compared to possible alternative algorithms derived from the state-of-the-art algorithms, the developed algorithm is advantageous for the addressed problems.}
}
@article{KINNEAR2024101190,
title = {Lecturers' use of questions in undergraduate mathematics lectures},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101190},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101190},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000671},
author = {George Kinnear and Gemma Hood and Eloise Lardet and Colette Sheard and Colin Foster},
keywords = {Funneling, Lecturing styles, Questioning, Student participation, University mathematics},
abstract = {Mathematics lecturers frequently ask questions in their lectures, and these questions presumably play an important role in students’ thinking about and learning of the lecture content. We replicated and developed a coding scheme used in previous research in the US to categorise lecturers’ questions in a sample of 136 lectures given by 24 lecturers at a research-intensive UK university. We found that the coding scheme could be applied reliably, and that factual questions were predominant (as in previous research). We explore differences in the lecturers’ use of questions – both between our UK sample and the previous US work, and between individual lecturers in our sample. We note the presence of strings of related successive questions from the lecturer, which we term ‘question chains’. We explore the nature of these, examine their prevalence, and seek to account for them in terms of the lecturers’ possible intentions.}
}
@article{XU2023108916,
title = {Joint optimization task offloading and trajectory control for unmanned-aerial-vehicle-assisted mobile edge computing},
journal = {Computers and Electrical Engineering},
volume = {111},
pages = {108916},
year = {2023},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2023.108916},
url = {https://www.sciencedirect.com/science/article/pii/S0045790623003403},
author = {Fei Xu and Sen Wang and Weiya Su and Lin Zhang},
keywords = {Edge computing, Computation offloading, Deep reinforcement learning, Unmanned Aerial Vehicle, Trajectory control},
abstract = {The appearance of Mobile Edge Computing (MEC) and Unmanned Aerial Vehicle (UAV) is significant for the future progress of the Internet of Things (IoT). Since the system model with a continuous action space and high-dimensional state space, the joint optimization of UAV trajectory and the computational offloading problem is non-convex, and traditional algorithms for instance ant colony algorithm, genetic algorithm, Actor Critic (AC) algorithm, and Deep Deterministic Policy Gradient (DDPG) algorithm are difficult to cope with. Reasonably formulating the computational task offloading strategy and the trajectory control of the UAV is crucial for the high-efficiency completion of the task. In this paper, a computational offloading and trajectory control system model for UAV-assisted MEC is proposed. We seek to maximize the user ratio of coverage by jointly optimizing computing offload scheduling and UAV trajectories. We propose an improved DDPG algorithm to optimize the objective function and achieve the optimal solution. Meanwhile, our algorithm can achieve an improvement in the user rate of coverage while avoiding obstacles as compared with baseline algorithms, AC, and DDPG.}
}
@article{STOLOWY2022101334,
title = {Competing for narrative authority in capital markets: Activist short sellers vs. financial analysts},
journal = {Accounting, Organizations and Society},
volume = {100},
pages = {101334},
year = {2022},
issn = {0361-3682},
doi = {https://doi.org/10.1016/j.aos.2022.101334},
url = {https://www.sciencedirect.com/science/article/pii/S0361368222000010},
author = {Hervé Stolowy and Luc Paugam and Yves Gendron},
keywords = {Activist short sellers, Expertise, Financial analysts, Framing, Narrative authority},
abstract = {Activist short sellers (AShSs) and financial analysts are information intermediaries who analyze firm disclosures as well as produce and disseminate influential investment narratives. This study aims to better understand narrative challenges surrounding the legitimate expertise of financial analysts. Specifically, we examine how AShSs challenge sell-side financial analysts' narrative authority (i.e., the perception that they produce expert knowledge) in interpreting firms' performance and future prospects. We investigate how analysts respond (or do not respond) to this challenge. We use 442 AShS reports, 12 interviews with AShSs and analysts, and analysts' stock recommendations and target prices. In their criticisms of analysts (found in one-third of reports), AShSs frequently frame analysts as lacking market expertise and critical thinking – two core dimensions of analysts' narrative authority. Sixty-six percent of analysts, although explicitly criticized in AShS reports, do not engage in written responses in their equity research reports because they reportedly either adopt a renunciation attitude to the challenge or they engage in off-the-record discussions with certain market participants. However, 34% of analysts respond overtly by counter-framing AShSs as lacking market expertise and objectivity. After the dissemination of AShS reports, analysts, on average, do not revise their highly visible stock recommendations but they revise target prices downward. Theoretically, this study extends our understanding of the construction of narrative authority in capital markets as we examine a challenge to the expertise of influential information intermediaries.}
}
@article{BIELZA2000725,
title = {Structural, elicitation and computational issues faced when solving complex decision making problems with influence diagrams},
journal = {Computers & Operations Research},
volume = {27},
number = {7},
pages = {725-740},
year = {2000},
issn = {0305-0548},
doi = {https://doi.org/10.1016/S0305-0548(99)00113-6},
url = {https://www.sciencedirect.com/science/article/pii/S0305054899001136},
author = {C. Bielza and M. Gómez and S. Rı́os-Insua and J.A.Fernández {del Pozo}},
keywords = {Decision analysis, Influence diagrams, Implementation issues, Medical decision making, Neonatal jaundice},
abstract = {Influence diagrams have become a popular tool for representing and solving decision making problems under uncertainty (Shachter, Operations Research 1986;34:871–82). We show here some practical difficulties when using them to construct a medical decision support system. Specifically, it is hard to tackle issues related to the problem structuring, like the existence of constraints on the sequence of decisions, and the time evolution modeling; related to the knowledge-acquisition, like probability and utility assignment; and related to computational limitations, in memory storage and evaluation phases, as well as the explanation of results. We have recently developed a complex decision support system for neonatal jaundice management — a very common medical problem — , encountering all these difficulties. In this paper, we describe them and how they have been undertaken, providing insights into the community involved in the design and solution of decision models by means of influence diagrams.
Scope and purpose
Decision Analysis is a very well-known discipline that deals with the practice of Decision Theory (Clemen, Making hard decisions: an introduction to decision analysis, 2nd ed. Pacific Grove, CA: Duxbury, 1996). It comprises various steps usually implemented in a decision support system: definition of the alternatives and objectives, modelization of the structure of the decision problem, as well as the beliefs and preferences of the decision maker. The recommended alternative is the one with maximum expected utility, once all the assignments have been refined via sensitivity analyses. However, there are a number of difficulties faced in practice when solving large problems, that require an attentive study.}
}
@article{GOLTZ2021103417,
title = {Do you listen to music while studying? A portrait of how people use music to optimize their cognitive performance},
journal = {Acta Psychologica},
volume = {220},
pages = {103417},
year = {2021},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2021.103417},
url = {https://www.sciencedirect.com/science/article/pii/S0001691821001670},
author = {Franziska Goltz and Makiko Sadakata},
keywords = {Background music, Cognitive performance, Music perception},
abstract = {The effect of background music (BGM) on cognitive task performance is a popular topic. However, the evidence is not converging: experimental studies show mixed results depending on the task, the type of music used and individual characteristics. Here, we explored how people use BGM while optimally performing various cognitive tasks in everyday life, such as reading, writing, memorizing, and critical thinking. Specifically, the frequency of BGM usage, preferred music types, beliefs about the scientific evidence on BGM, and individual characteristics, such as age, extraversion and musical background were investigated. Although the results confirmed highly diverse strategies among individuals regarding when, how often, why and what type of BGM is used, we found several general tendencies: people tend to use less BGM when engaged in more difficult tasks, they become less critical about the type of BGM when engaged in easier tasks, and there is a negative correlation between the frequency of BGM and age, indicating that younger generations tend to use more BGM than older adults. The current and previous evidence are discussed in light of existing theories. Altogether, this study identifies essential variables to consider in future research and further forwards a theory-driven perspective in the field.}
}
@article{SEEMAN202211461,
title = {Understanding chemistry: from “heuristic (soft) explanations and reasoning by analogy” to “quantum chemistry”††Dedicated to Dudley Herschbach in celebration of his 90th year who, when asked whether he was a theoretician or an experimentalist, responded, “The molecules don't know and don't care.”},
journal = {Chemical Science},
volume = {13},
number = {39},
pages = {11461-11486},
year = {2022},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d2sc02535c},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023014347},
author = {Jeffrey I. Seeman and Dean J. Tantillo},
abstract = {ABSTRACT
“Soft theories,” i.e., “heuristic models based on reasoning by analogy” largely drove chemistry understanding for 150 years or more. But soft theories have their limitations and with the expansion of chemistry in the mid-20th century, more and more inexplicable (by soft theory) experimental results were being obtained. In the past 50 years, quantum chemistry, most often in the guise of applied theoretical chemistry including computational chemistry, has provided (a) the underlying “hard evidence” for many soft theories and (b) the explanations for chemical phenomena that were unavailable by soft theories. In this publication, we define “hard theories” as “theories derived from quantum chemistry.” Both soft and hard theories can be qualitative and quantitative, and the “Houk quadrant” is proposed as a helpful categorization tool. Furthermore, the language of soft theories is often used appropriately to describe quantum chemical results. A valid and useful way of doing science is the appropriate use and application of both soft and hard theories along with the best nomenclature available for successful communication of results and ideas.}
}
@incollection{TONDEUR2024184,
title = {Chapter 6 - Batch control spike},
editor = {Yves Tondeur},
booktitle = {Sustainable Quality Improvements for Isotope Dilution in Molecular Ultratrace Analyses},
publisher = {Elsevier},
pages = {184-239},
year = {2024},
isbn = {978-0-443-29034-3},
doi = {https://doi.org/10.1016/B978-0-443-29034-3.00031-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290343000314},
author = {Yves Tondeur},
keywords = {Compliance with PBMS/methods innovation rule & ISO 17025, Critical step, Erroneous beliefs & mental models, Function of the labeled standards, Out-of-control analytical system, Performance improvement, Sample fortification integrity, Systematic errors, Technology-in-use definition, Thinking method, Traditional QC samples effectiveness, Working relative response factors},
abstract = {When we are unaware of the causes for the observed deviations, we are more likely to react. When we react or are unaware of problems, we fail. Increasing the effectiveness of quality control samples starts with addressing what we do not know about them. So, this chapter first clarifies what we want, then describes what we have, and lastly what can be done to fill the gaps. The development, validation, and application of the batch control spike is a great illustration highlighting the importance the quality of the performance feedback and learning capacity the control samples are supposed to provide. When done correctly—while contextually questioning the relevance and appropriateness of current operating criteria, imposed limits and standards—the introduction of the batch control spike allows a process of critical errors identification, compensation, and progressive elimination to take place so that at the end, no significant systematic errors remain. This fact is demonstrated using z-scores from multiple international round-robin studies. In the context of achieving accuracy, the batch control spike examines the relationships between the standards used, when they are spiked, how they are spiked, and their purpose, that is, it renders the technology-in-use (isotope dilution) transparent and keeps it honest. It is also an excellent teaching tool. It is a quality learning sample helping the transformation of our methods into “thinking tools.”}
}
@incollection{RUNCO20141,
title = {Chapter 1 - Cognition and Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {1-38},
year = {2014},
isbn = {978-0-12-410512-6},
doi = {https://doi.org/10.1016/B978-0-12-410512-6.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780124105126000011},
author = {Mark A. Runco},
keywords = {Threshold theory, IQ, Structure of intellect, Associative theory, Problem solving, Problem finding, Incubation, Insight, Intuition, Meta-cognition, Mindfulness, Overinclusive thinking},
abstract = {This chapter discusses various aspects of cognition and creativity. Cognitive theories focus on thinking skills and intellectual processes. The approaches to creative cognition are extremely varied. There are bridges between basic cognitive processes and creative problem solving, as well as connections with intelligence, problem solving, language, and other indications of individual differences. The basic processes are generally nomothetic, meaning that they represent universals. Divergent thinking is employed when an individual is faced with an open-ended task. From this perspective divergent thinking is a kind of problem solving. Divergent thinking is not synonymous with creative thinking, but it does tell something about the cognitive processes that may lead to original ideas and solutions. Many theories of creative cognition look to associative processes. Associative theories focus on how ideas are generated and chained together. Cognitive theories of creativity often focus specifically on the problem-solving process. A problem can be defined as a situation with a goal and an obstacle. The stage models of creative cognition are also elaborated.}
}
@article{LU2024103920,
title = {The integrated multi-performance fast optimization strategy for battery thermal management system},
journal = {Case Studies in Thermal Engineering},
volume = {54},
pages = {103920},
year = {2024},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.103920},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23012261},
author = {Hao Lu and Xiaole Tang and Hongchang Li and Wenjun Zhao and Xiqiang Chang and Weifang Lin},
keywords = {Short-cut computation, Computational fluid dynamics, Weighted average, Optimization algorithm},
abstract = {Increased battery energy density is required to boost electric vehicle endurance; however, this also raises the possibility of thermal runaway and power battery explosion. Improving the cooling system performance requires optimization and enhancement of classical systems. Traditional design approaches struggle to simultaneously enhance multiple aspects of performance, while an optimization based on Computational Fluid Dynamics (CFD) methods is often inefficient. Therefore, by integrating a flow resistance network model (FRNM) with a weighted average optimization algorithm (INFO), an efficient optimization for the comprehensive performance of the system can be achieved. Five optimized systems under different airflow rates were obtained through optimization. A comparison with two existing systems validated the effectiveness of the optimized system. The results demonstrate that, compared to the two reference systems, the optimized system decreases the maximum temperature difference by 65.51 % and 39.07 %, respectively. Furthermore, the improvement in temperature uniformity is more significant, increasing by 63.76 % and 34.40 %, respectively.}
}
@article{HIPOLITO2017432,
title = {Mind-life continuity: A qualitative study of conscious experience},
journal = {Progress in Biophysics and Molecular Biology},
volume = {131},
pages = {432-444},
year = {2017},
note = {Integral Biomathics 2017: The Necessary Conjunction of Western and Eastern Thought Traditions for Exploring the Nature of Mind and Life},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717301165},
author = {Inês Hipólito and Jorge Martins},
keywords = {Conscious experience, Qualitative study, Meditation, , Mind-life continuity thesis},
abstract = {There are two fundamental models to understanding the phenomenon of natural life. One is the computational model, which is based on the symbolic thinking paradigm. The other is the biological organism model. The common difficulty attributed to these paradigms is that their reductive tools allow the phenomenological aspects of experience to remain hidden behind yes/no responses (behavioral tests), or brain ‘pictures’ (neuroimaging). Hence, one of the problems regards how to overcome methodological difficulties towards a non-reductive investigation of conscious experience. It is our aim in this paper to show how cooperation between Eastern and Western traditions may shed light for a non-reductive study of mind and life. This study focuses on the first-person experience associated with cognitive and mental events. We studied phenomenal data as a crucial fact for the domain of living beings, which, we expect, can provide the ground for a subsequent third-person study. The intervention with Jhana meditation, and its qualitative assessment, provided us with experiential profiles based upon subjects' evaluations of their own conscious experiences. The overall results should move towards an integrated or global perspective on mind where neither experience nor external mechanisms have the final word.}
}
@article{AGRAWAL2022101673,
title = {Spectrum sensing in cognitive radio networks and metacognition for dynamic spectrum sharing between radar and communication system: A review},
journal = {Physical Communication},
volume = {52},
pages = {101673},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2022.101673},
url = {https://www.sciencedirect.com/science/article/pii/S187449072200043X},
author = {Sumit Kumar Agrawal and Abhay Samant and Sandeep Kumar Yadav},
keywords = {Cognitive radio, Spectrum sensing, Spectrum sharing, Cognitive radar, Metacognition, Metacognitive radar},
abstract = {The massive growth in mobile users and wireless technologies has resulted in increased data traffic and created demand for additional radio spectrum. This growing demand for radio spectrum has resulted in spectrum congestion and mandated the need for coexistence between radar and interfering communication emitters. To address the aforementioned issues, it is critical to review existing policies and evaluate new technologies that can utilize spectrum in an efficient and intelligent manner. Cognitive radio and cognitive radar are two promising technologies that exploit spectrum using dynamic spectrum access techniques. Additionally, introducing the bio-inspired concept ‘metacognition’ in a cognitive process has shown to increase the effectiveness and robustness of the cognitive radio and cognitive radar system. Metacognition is a high-order thinking agent that monitors and regulates the cognition process through a feedback and control process called the perception–action cycle. Extensive research has been done in the field of spectrum sensing in cognitive radio and spectral coexistence between radar and communication systems. This paper provides a detailed classification of spectrum sensing schemes and explains how dynamic spectrum access strategies share the spectrum between radar and communication systems. In addition to this, the fundamentals of cognitive radio, its architecture, spectrum management framework, and metacognition concept in radar are discussed. Furthermore, this paper presents various research issues, challenges, and future research directions associated with spectrum sensing in cognitive radar and dynamic spectrum access strategies in cognitive radar.}
}