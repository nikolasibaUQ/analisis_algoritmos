@incollection{BHATE2024165,
title = {Chapter 7 - Tissue schematics: Representing tissues as assemblies of neighborhoods},
editor = {Wendy J. Fantl},
booktitle = {Revealing Uncharted Biology With Single Cell Multiplex Proteomic Technologies},
publisher = {Academic Press},
pages = {165-189},
year = {2024},
isbn = {978-0-12-822209-6},
doi = {https://doi.org/10.1016/B978-0-12-822209-6.00005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222096000059},
author = {Salil S. Bhate and Graham L. Barlow and Garry P. Nolan},
keywords = {Cellular neighborhoods, Spatial biology, Tissue schematics, Tumor microenvironment},
abstract = {The technologies discussed in previous chapters provide an unprecedented lens on single cells, phenotypes, and their interactions. In this chapter, we discuss tissue schematics (as introduced in Bhate et al., 2021): a computational and conceptual framework for using highly multiplexed imaging data to infer and visually represent how complex, tissue-level behaviors are generated through the composition of simpler, interpretable biological processes. We focus on the practical application of tissue schematics for generating biological understanding of tissues from imaging data.}
}
@article{ROOS2020112975,
title = {Online conferences – Towards a new (virtual) reality},
journal = {Computational and Theoretical Chemistry},
volume = {1189},
pages = {112975},
year = {2020},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2020.112975},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X20302759},
author = {Goedele Roos and Julianna Oláh and Rebecca Ingle and Rika Kobayashi and Milica Feldt},
keywords = {Virtual conference, Virtual Winter School on Computational Chemistry, Hybrid online/in-person conference},
abstract = {The recent article: Nature 579, 327–328 (2020), ending with the phrase: “You can’t just suddenly make a conference be online.”, has motivated us to write about the practicalities and philosophy of running online events, drawing on our extensive experience running an annual online computational chemistry conference. Our goals for this online conference series have always been: (1) Availability; (2) Community building and (3) Supporting young scientists. In this article, we highlight the motivations behind our initiative, how this has influenced the organisation of our online meeting, and discuss the benefits as well as the drawbacks of virtual meetings. Virtual conferences may not fully replace in-person meetings, but they are rapidly becoming an accepted alternative format. We discuss the hybrid online/in-person conference format as a future possibility that may offer an opportunity to reduce the environmental impact and accessibility barriers associate with in-person meetings without comprising networking and community-building opportunities.}
}
@article{BISWAS2008127,
title = {Towards an agent-oriented approach to conceptualization},
journal = {Applied Soft Computing},
volume = {8},
number = {1},
pages = {127-139},
year = {2008},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2006.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S1568494606001062},
author = {Pratik K. Biswas},
keywords = {Intelligent agents, Multi-agent systems, Agent-oriented software engineering, Agent-oriented thinking, Agent-oriented modeling, Extended agent model, Agent-oriented analysis, Agent-oriented design},
abstract = {Agent-oriented modeling provides a new technique for the conceptualization of agent-based systems. This paper extends and formalizes this agent-oriented modeling approach to the conceptualization process. It defines agent models and proposes a high-level methodology for agent-oriented analysis and design. It also includes analogies with the object-oriented and other existing agent-oriented methodologies, wherever applicable. The paper is concluded with a case study and an insight to future challenges.}
}
@article{THEOFILIDIS2024219,
title = {Mental Imagery: Investigating the Limits of Mental Partitioning},
journal = {Revista Colombiana de Psiquiatría},
volume = {53},
number = {3},
pages = {219-228},
year = {2024},
issn = {0034-7450},
doi = {https://doi.org/10.1016/j.rcp.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S003474502400009X},
author = {Antonios Theofilidis and Maria-Valeria Karakasi and Filippos Kargopoulos},
keywords = {Mental imagery, Mental partitioning, Memory, Cognition, Neuroscience, Imaginería mental, Partición mental, Memoria, Cognición, Neurociencia},
abstract = {Introduction
Do we form mental models which bear an analogical relation to the real world like those of a photograph? Has the language of thought an analogue nature (it makes use of mental imagery) or whether it is exclusively of digital nature like language?
Objectives
The basic aim of the present study is to contribute to the ongoing work on mental imagery by extending the research to an unexplored area that of mental partitioning.
Methods
The present research sample consisted of 498 participants (234 males and 264 females). We used the SPSS software package in order to analyze our data.
Results
According to our results, we detected significant peculiarities in the cognitive performance of the participants in the tasks of mental partitioning of the Moebius strip, indicating certain limitations inherent in human thinking.
Conclusions
The position we are led to adopt is closer to that of Pylyshyn (2003), who maintained that visual mental imagery depends on abstract form of thought and on previous knowledge. Specifically, it rests on previous abstract propositional thought and knowledge rather than on concrete perceptual processes like the ones proposed by Kosslyn and Sheppard. The present work investigates a potentially valuable theoretical basis in imagery research for understanding maladaptive imagery across various related clinical disorders, while encouraging multidisciplinary approaches among cognitive psychological/neuroscientific and clinical domains.
Resumen
Introducción
¿Formamos modelos mentales que guardan una relación analógica con el mundo real como los de una fotografía? ¿Tiene el lenguaje del pensamiento una naturaleza analógica (hace uso de imágenes mentales) o es exclusivamente de naturaleza digital como el lenguaje?
Objetivos
El objetivo básico del presente estudio es contribuir al trabajo en curso sobre la imaginería mental extendiendo la investigación a un área inexplorada que es la partición mental.
Métodos
La muestra de la presente investigación estuvo compuesta por 498 participantes (234 varones y 264 mujeres). Usamos el paquete de software SPSS® para analizar nuestros datos.
Resultados
De acuerdo con nuestros resultados, detectamos peculiaridades significativas en el desempeño cognitivo de los participantes en las tareas de partición mental de la tira de Moebius, indicando ciertas limitaciones inherentes al pensamiento humano.
Conclusiones
La posición a la que nos vemos llevados a adoptar se acerca más a la de Pylyshyn (2003), quien sostenía que la imaginería mental visual depende de formas abstractas de pensamiento y de conocimientos previos. Específicamente, se basa en el pensamiento y el conocimiento proposicionales abstractos previos más que en procesos de percepción concretos como los propuestos por Kosslyn y Sheppard. El presente trabajo investiga una base teórica potencialmente valiosa en la investigación de imágenes para comprender las imágenes desadaptativas en varios trastornos clínicos relacionados, al tiempo que fomenta enfoques multidisciplinarios entre los dominios cognitivos psicológicos/neurocientíficos y clínicos.}
}
@article{JAHANIYEKTA2024100078,
title = {The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100078},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000316},
author = {Mohammad Mahdi {Jahani Yekta}},
keywords = {GPT–4, Artificial general intelligence, Knowledge diffusion, Interpretability and explainability, Societal influences, Governance},
abstract = {Recent breakthroughs in artificial intelligence (AI) research include advancements in natural language processing (NLP) achieved by large language models (LLMs), and; in particular, generative pre–trained transformer (GPT) architectures. The latest GPT developed by OpenAI, GPT–4, has shown remarkable intelligence across various domains and tasks. It exhibits capabilities in abstraction, comprehension, vision, computer coding, mathematics, and more, suggesting it to be a significant step towards artificial general intelligence (AGI), a level of AI that possesses capabilities similar to human intelligence. This paper explores this AGI, its knowledge diffusive and societal influences, and its governance. In addition to coverage of the major associated topics studied in the literature, and making up for their loopholes, we scrutinize how GPT-4 can facilitate the diffusion of knowledge across different areas of science by promoting their interpretability and explainability (IE) to inexperts. Where applicable, the topics are also accompanied by their specific potential implications on medical imaging.}
}
@article{NGUYEN2022108381,
title = {Knowledge mapping of digital twin and physical internet in Supply Chain Management: A systematic literature review},
journal = {International Journal of Production Economics},
volume = {244},
pages = {108381},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108381},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321003571},
author = {Tiep Nguyen and Quang Huy Duong and Truong Van Nguyen and You Zhu and Li Zhou},
keywords = {, , , },
abstract = {Physical Internet (PI) is an open global logistics system of which components are hyperconnected for increased efficiency and sustainability. Digital twin (DT), referring to the virtual representation of a physical object, is well-perceived as a key driver in the development of PI-based Supply Chain Management (SCM). Due to the capabilities of real-time monitoring and evaluation of large-scale complex systems, significant research efforts have been made to exploit values of PI/DT in SCM. Despite this, the current literature remained largely unstructured and scattered due to a lack of systematic literature reviews to synergise research findings, analyse the evolution of research fronts and extract emerging trends in the field. To address this issue, the paper deploys a bibliometric knowledge mapping approach to provide a bird's eye view of the current research status in the PI/DT-SCM area. Using CiteSpace's keyword co-occurrence network, 518 journal articles are clustered into 10 key research streams on PI/DT applications in: job shop scheduling, smart manufacturing design, PI-based SCM, manufacturing virtualisation, information management, sustainability development, data analytics, manufacturing operations management, simulation and optimisation, and assembly process planning. Based on citation burst rate, keywords representing research frontiers of the PI/DT are detected and their temporal evolutions are discussed. Likewise, some identified emerging research trends are production process and system, robotics, computer architecture, and cost. Finally, seven future research directions are suggested, which emphasise on several PI/DT-related issues, including business ecosystem, sustainability development, SC downstream management, cognitive thinking in Industry 5.0, citizen twin in digital society, and SC resilience.}
}
@article{DRACK2011150,
title = {System approaches of Weiss and Bertalanffy and their relevance for systems biology today},
journal = {Seminars in Cancer Biology},
volume = {21},
number = {3},
pages = {150-155},
year = {2011},
note = {Why Systems Biology and Cancer?},
issn = {1044-579X},
doi = {https://doi.org/10.1016/j.semcancer.2011.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1044579X11000307},
author = {Manfred Drack and Olaf Wolkenhauer},
keywords = {Paul Alfred Weiss, Ludwig von Bertalanffy, Organismic biology, System theory of life, Systems biology},
abstract = {System approaches in biology have a long history. We focus here on the thinking of Paul A. Weiss and Ludwig von Bertalanffy, who contributed a great deal towards making the system concept operable in biology in the early 20th century. To them, considering whole living systems, which includes their organisation or order, is equally important as the dynamics within systems and the interplay between different levels from molecules over cells to organisms. They also called for taking the intrinsic activity of living systems and the conservation of system states into account. We compare these notions with today's systems biology, which is often a bottom-up approach from molecular dynamics to cellular behaviour. We conclude that bringing together the early heuristics with recent formalisms and novel experimental set-ups can lead to fruitful results and understanding.}
}
@article{POGGIO1981258,
title = {Marr's computational approach to vision},
journal = {Trends in Neurosciences},
volume = {4},
pages = {258-262},
year = {1981},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(81)90081-3},
url = {https://www.sciencedirect.com/science/article/pii/0166223681900813},
author = {T. Poggio},
abstract = {In the last 7 years a new computational approach has led to promising advances in our understanding of visual perception. The foundations of the approach, its overall framework and its first solid results are largely due to the work of a single man, David Marr at MIT. Now, after his death in Boston on 17 November, 1980, research in vision will never be the same.}
}
@article{DEMAZIERE2024113028,
title = {Enhancing higher education through hybrid and flipped learning: Experiences from the GRE@T-PIONEeR project},
journal = {Nuclear Engineering and Design},
volume = {421},
pages = {113028},
year = {2024},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2024.113028},
url = {https://www.sciencedirect.com/science/article/pii/S0029549324001286},
author = {C. Demazière and C. Stöhr and Y. Zhang and O. Cabellos and S. Dulla and N. Garcia-Herranz and R. Miró and R. Macian and M. Szieberth and C. Lange and M. Hursin and S. Strola},
keywords = {Nuclear education and training, Computational reactor physics, Experimental reactor physics, Flipped classroom, Active learning, Hybrid teaching, Online learning},
abstract = {GRE@T-PIONEeR is a Horizon 2020 project coordinated by Chalmers University of Technology, running over the period 2020–2024. 18 university teachers from 8 different universities located in 6 different countries gathered forces to develop and offer advanced courses in computational and experimental nuclear reactor physics and safety. All courses are flipped hybrid courses, i.e., students work on online preparatory activities at their own pace before attending a set of interactive sessions organized on five consecutive days. Those sessions can be attended either onsite or remotely. During the academic year 2022/2023, 8 different courses were offered, and 185 students successfully completed the courses, with a success rate of 87.7% for the students taking at least one activity during the interactive sessions. Student behaviour and performance were monitored via the Learning Management System (LMS) used in all courses. This paper presents an analysis of various metrics from the LMS and demonstrates a high level of engagement of the students committed to the courses and a high success rate for those students. Whereas all students are equally engaged in the online preparatory work and perform equally well, significant differences exist during the interactive sessions between the students who opted for onsite participation and those who attended the sessions online, with the onsite students outperforming the online students.}
}
@article{DENG2023104944,
title = {A VR-based BCI interactive system for UAV swarm control},
journal = {Biomedical Signal Processing and Control},
volume = {85},
pages = {104944},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.104944},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423003774},
author = {Tao Deng and Zhen Huo and Lihua Zhang and Zhiyan Dong and Lan Niu and Xiaoyang Kang and Xiuwei Huang},
keywords = {Brain-computer interface (BCI), Swarm control, Steady state visual evoked potential (SSVEP), Electroencephalogram (EEG), Unmanned Aerial Vehicle (UAV), Quadcopter, Virtual Reality (VR)},
abstract = {The traditional Unmanned Aerial Vehicle (UAV) swarm control mainly adopts the ground station method, which is too fixed, and the interaction is difficult to meet the high dynamic task requirements. There is an urgent need for new interaction methods to integrate the advantages of human thinking in dealing with uncertain problems. Nevertheless, brain-computer interface(BCI) technology is directly controlled by thoughts, one of the most promising next-generation human–computer interaction technologies. Therefore, in this study, we innovatively applied the BCI system based on Virtual Reality (VR) to the group UAV and realized a novel and intelligent group control method, which proposes new ideas and paradigms for the control of swarm UAVs in the future. Specifically, this study takes a quadcopter as an example. A modular and extensible multi-quadcopter system was created, and then a visual stimulation 3D VR scene system with a digital twin function was established. On this basis, the BCI system based on the Stable state visual evoked potential (SSVEP) paradigm was adopted for the swarm control of the quadcopter. The experimental results show that the formation control of multi-quadcopter is successfully realized by the subjects using the proposed VR-based BCI interactive system, with an accuracy rate of 90% and a good performance in information transmission rate. In addition, the immersive VR twin system established one-to-one for EEG signal acquisition allows subjects to have a better experience.}
}
@article{VAKILI2021112687,
title = {The development of a transdisciplinary policy framework for shipping companies to mitigate underwater noise pollution from commercial vessels},
journal = {Marine Pollution Bulletin},
volume = {171},
pages = {112687},
year = {2021},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2021.112687},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X21007219},
author = {Seyedvahid Vakili and Aykut I. Ölçer and Fabio Ballini},
keywords = {Energy Efficiency Design Index, Energy Efficiency Existing Ship Index, Enhanced Ship Energy Efficiency Management Plan, Policy, Transdisciplinary, Underwater noise pollution},
abstract = {One of the newly emerging environmental issues is underwater noise pollution. It has both negative environmental and socio-economic impacts and threatens sustainable shipping. While other types of shipping pollutants have been regulated and societal awareness has been raised, due to the intangible characteristics of underwater noise pollution, there is neither societal awareness nor an international legally binding instrument to mitigate underwater noise pollution. This paper aims to raise awareness of ship owners regarding UWN pollution by introducing the sources of UWN pollution, as well as proposing a transdisciplinary policy for shipping companies to mitigate UWN pollution from their ships. The proposed policy is aligned with IMO's initial GHG strategy, especially the Energy Efficiency Design Index, Energy Efficiency Existing Ship Index, and Enhanced Ship Energy Efficiency Management Plan. This multi-dimensional approach will make stakeholders more enthusiastic to tackle underwater noise pollution while enhancing the efficient use of capacities and resources.}
}
@incollection{YUCESOY2024,
title = {Systems Biology in Immunotoxicology},
booktitle = {Reference Module in Biomedical Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-801238-3},
doi = {https://doi.org/10.1016/B978-0-323-95488-4.00046-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323954884000462},
author = {Berran Yucesoy and Randle Gallucci},
keywords = {Biological networks, Biomarkers, Epigenetics, Genetics, Immune system, Immunotoxicology, Proteomics, Risk assessment, System biology, Transcriptomics},
abstract = {Systems biology is an emerging field that focuses on the interactions between the components of biological systems. In the past two decades, high-throughput, large-scale molecular biology approaches (omics technologies) and advances in computational approaches have significantly grown and provided valuable insight into disease mechanisms, underlying toxicities, and gene–environment interactions. Systems biology approaches have also been widely used in immunotoxicology and helped understand the structure and function of immune system at multiple levels. Integrative models of the human immune response allowed for the assessment of complex immune effects, multilevel networks of interactions, identification of biomarkers and extrapolation of early molecular/cellular events to long-term outcomes at the organism level. Such efforts also created a potential for more predictive and accurate risk-assessment strategies. This chapter focuses on systems biology approaches and computational tools used in immunotoxicology and discuss their application in risk assessment.}
}
@incollection{NEWMAN2020183,
title = {Chapter 7 - Cognitive developmental theories},
editor = {Barbara M. Newman and Philip R. Newman},
booktitle = {Theories of Adolescent Development},
publisher = {Academic Press},
pages = {183-211},
year = {2020},
isbn = {978-0-12-815450-2},
doi = {https://doi.org/10.1016/B978-0-12-815450-2.00007-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154502000073},
author = {Barbara M. Newman and Philip R. Newman},
keywords = {Problem solving, Equilibrium, Schemes, Adaptation, Egocentrism, Formal operational thought, Moral reasoning, Social reasoning, Metacognition, Education},
abstract = {The chapter focuses on cognitive developmental theories which address the emerging nature of concept formation, reasoning, planning, and problem solving, and the increasingly complex structures that support changing and flexible capacities for thinking about multidimensional problems with probabilistic outcomes. This chapter summarizes the work of Jean Piaget and the extension of his ideas among neo-Piagetian theorists including Deanna Kuhn, Paul Klacziynski, and Robbie Case. The following key concepts are explained: equilibrium, schemes, organization, adaptation, stages of development, and egocentrism. The stage of Formal Operational Reasoning and elaboration of cognitive capacities in adolescence are described in detail. Application of these theories to moral reasoning, social reasoning, metacognition, and educational initiatives are discussed. Experimental approaches and paper and pencil measures of cognitive reasoning are described. The strengths and limitations of cognitive developmental theories are reviewed.}
}
@article{WU201655,
title = {Vertical position of Chinese power words influences power judgments: Evidence from spatial compatibility task and event-related Potentials},
journal = {International Journal of Psychophysiology},
volume = {102},
pages = {55-61},
year = {2016},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2016.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167876016300253},
author = {Xiangci Wu and Huibin Jia and Enguo Wang and Chenguang Du and Xianghua Wu and Caiping Dang},
keywords = {Conceptual representation, Metaphor, Vertical position, Power},
abstract = {The present study used event-related potentials (ERPs) to explore the influence of vertical position on power judgments. Participants were asked to identify whether a Chinese word represented a powerful or powerless group (e.g., “king” or “servant”), which was presented in the top or bottom of the screen. The behavioral analysis showed that judging the power of powerful words were significantly faster when they were presented at the top position, compared with when they were presented at the bottom position. The ERP analysis showed enhanced N1 amplitude for congruent trials (i.e., the powerful words in the top and the powerless words in the bottom of the screen) and larger P300 and LPC amplitude for incongruent trials (i.e., the powerful words in the bottom and the powerless words in the top of the screen). The present findings provide further electrophysiological evidence that thinking about power can automatically activate the underlying spatial up-down (verticality) image schema and that the influence of vertical position on the power judgments not only occurs at the early perceptual stage of power word processing, but also at the higher cognitive stage (i.e., allocation of attention resources, conflict solving and response selection). This study revealed the neural underpinnings of metaphor congruent effect which have great significance to our understanding of the abstract concept power.}
}
@article{WEERASINGHE2024,
title = {ABC-based forecasting in misspecified state space models},
journal = {International Journal of Forecasting},
year = {2024},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S016920702400044X},
author = {Chaya Weerasinghe and Rubén Loaiza-Maya and Gael M. Martin and David T. Frazier},
keywords = {Approximate Bayesian computation, Auxiliary model, Loss-based prediction, Focused Bayesian prediction, Proper scoring rules, Stochastic volatility model},
abstract = {Approximate Bayesian Computation (ABC) has gained popularity as a method for conducting inference and forecasting in complex models, most notably those which are intractable in some sense. In this paper, we use ABC to produce probabilistic forecasts in state space models (SSMs). Whilst ABC-based forecasting in correctly-specified SSMs has been studied, the misspecified case has not been investigated. It is this case that we emphasize. We invoke recent principles of ‘focused’ Bayesian prediction, whereby Bayesian updates are driven by a scoring rule that rewards predictive accuracy; the aim being to produce predictives that perform well in that rule, despite misspecification. Two methods are investigated for producing the focused predictions. In a simulation setting, ‘coherent’ predictions are in evidence for both methods. That is, the predictive constructed using a particular scoring rule often predicts best according to that rule. Importantly, both focused methods typically produce more accurate forecasts than an exact but misspecified predictive, in particular when the degree of misspecification is marked. An empirical application to a truly intractable SSM completes the paper.}
}
@incollection{WANG202427,
title = {2 - Neuromorphic computing},
editor = {Min Gu and Elena Goi and Yangyundou Wang and Zhengfen Wan and Yibo Dong and Yuchao Zhang and Haoyi Yu},
booktitle = {Neuromorphic Photonic Devices and Applications},
publisher = {Elsevier},
pages = {27-45},
year = {2024},
series = {Photonic Materials and Applications Series},
isbn = {978-0-323-98829-2},
doi = {https://doi.org/10.1016/B978-0-323-98829-2.00006-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323988292000062},
author = {Wenju Wang and Haoran Zhou and Wei Li and Elena Goi},
keywords = {Artificial intelligence, machine learning, deep learning, machine learning models, neuromorphic computing},
abstract = {One of the aims of neuromorphic engineering is to implement elements of artificial intelligence (AI) algorithms, in particular artificial neural networks, with hardware that reflects the massively distributed nature of these bioinspired architectures. In this chapter, we introduce history, basic concepts, and applications of AI, in order to establish a working framework for the development of neuromorphic systems. We present the fundamentals of machine learning (ML) and deep learning (DL) and expound on the relationship among these algorithms based on neural networks, to generate a broader understanding of the methodical underpinning of current AI systems. Basic concepts and working principles, such as neurons, activation functions, feedforward networks, etc., are presented, and the performances of these algorithms in terms of functionality, computational complexity, and energy consumption are reviewed. Moreover, strengths and limits of different AI architectures are discussed, giving an overview of the development and applications of neuromorphic computing architectures.}
}
@article{GIANNAKOS201777,
title = {Entertainment, engagement, and education: Foundations and developments in digital and physical spaces to support learning through making},
journal = {Entertainment Computing},
volume = {21},
pages = {77-81},
year = {2017},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2017.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1875952117300307},
author = {Michail N. Giannakos and Monica Divitini and Ole Sejer Iversen},
keywords = {Maker movement, Learning technologies, Entertainment technologies, Creativity, Knowledge construction, Technological fluency, Constructionist},
abstract = {Making is a relatively new concept applied to describe the increasing attention paid to constructing activities to enable entertaining, and engaging learning. Making focuses on the process that occurs in digital and/or physical spaces that is not always learning oriented, but enables qualities such as problem solving, design thinking, collaboration, and innovation, to name a few. Contemporary technical and infrastructural developments, such as Hackerspaces, Makerspaces, TechShops, and FabLabs, and the appearance of tools such as wearable computing, robotics, 3D printing, microprocessors, and intuitive programming languages, posit making as a very promising research area to support learning processes, especially towards the acquisition of 21st-century learning competences. Collecting learning evidence via rigorous multidimensional and multidisciplinary case studies will allow us to better understand and improve the value of making and the role of the various digital and physical spaces. Drawing from our experience with a recent workshop that used making as a pathway to foster joyful engagement and creativity in learning (Make2Learn), we present the developments, as well as the four selected contributions of this special issue. The paper further draws attention to the great potential and need for research in the area of making to enable entertaining, and engaging, and learning.}
}
@article{WOLFENGAGEN2016353,
title = {Concordance in the Crowdsourcing Activity},
journal = {Procedia Computer Science},
volume = {88},
pages = {353-358},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.448},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317045},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey Kosikov},
keywords = {crowdsourcing, Big Data, Thick Data, variable domains, cognition model, concordance, computational model},
abstract = {A concordance in cognition activity of possibly interrelated crowdsourcers aimed to property recognition in the voluminous data sources is considered. Data sources are of either usual nature or manually generated with the crowdsourcing. The proposed model is based on the variable domains assumption. A general layout is able to take into account an interaction of crowdsourcers and properties when they are varying with the evolving the events. The cognition model is of stage-by-stage type and has the representable functor. This model as may be shown is faithfully embedded into a category of indexed sets. Using the proposed neighborhood for cognition activity leads to a flexible computing model.}
}
@article{SHAHIM2021102345,
title = {Security of the digital transformation},
journal = {Computers & Security},
volume = {108},
pages = {102345},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102345},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001693},
author = {Abbas Shahim},
keywords = {Digital transformation, Digital security, Information security, Digital disruption, IT auditing},
abstract = {In the early days of computation the focus was mainly on designing, developing, maintaining, and administering infrastructures and information systems housed in data centers. To this extend, security was traditionally organized around the basic technical components (e.g. data center facilities). The point was that an associated security activity was mostly separated from a business context and in general executed by the technical staff. Security was not fully understood by other audiences because the computer terminologies were frequently used. When security elements (e.g. logical access protocols used for identification, authentication, authorization) became part of the financial statement audit, its context became clearer, and it was conducted for external auditors. However, the presented outcome of the work was not completely interpretable for these practitioners as again, it was mainly reported in Information Technology (IT) jargon, and was not linked with the financial statement either. With the emergence the Sarbanes–Oxley Act (SOX) and the fundamental role of IT in relation hereto, the context of security suddenly changed to a great extent. The audience extended as compliance, including security, became the dominating item on the agenda of many C-levels (e.g. CFOs).}
}
@incollection{BENTHEM1989331,
title = {Semantic Parallels in Natural Language and Computation},
editor = {H.-D. Ebbinghaus and J. Fernandez-Prida and M. Garrido and D. Lascar and M. Rodriquez Artalejo},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {129},
pages = {331-375},
year = {1989},
booktitle = {Logic Colloquium'87},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(08)70133-2},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X08701332},
author = {Johan van Benthem},
abstract = {Publisher Summary
This chapter describes two major themes: (1) techniques for local strengthening of logical inference via minimization of models and (2) the more general dynamics of progressive handling of information in interpretation and argument. The chapter provides a coherent pattern behind some recent developments in these areas and discusses their value as affecting logic in general. The chapter also provides a mathematical analysis of the minimization operator on classes of models while also investigating several special systems in which minimal models play a central role. The chapter develops an analogy with earlier work in the philosophy of science on so-called “Ramsey eliminability” of theoretical terms in scientific theories. A technical connection is found between the general inferential properties of circumscription and more traditional conditional logic. It considers possible reductions of circumscriptive inference to standard first-order logic, establishing a high complexity for the question just when this is possible. The chapter reviews a number of results on dynamical semantics and several reductions of proposed dynamic systems to standard first-order logic. The latter system provides a promising tool for investigating dynamic modes of handling propositions.}
}
@article{TAPIA2019170,
title = {Design of biomass value chains that are synergistic with the food–energy–water nexus: Strategies and opportunities},
journal = {Food and Bioproducts Processing},
volume = {116},
pages = {170-185},
year = {2019},
issn = {0960-3085},
doi = {https://doi.org/10.1016/j.fbp.2019.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0960308519300641},
author = {John Frederick D. Tapia and Sheila Samsatli and Stephen S. Doliente and Elias Martinez-Hernandez and Wan Azlina Binti Wan Ab Karim Ghani and Kean Long Lim and Helmi Zulhaidi Mohd Shafri and Nur Shafira Nisa Binti Shaharum},
keywords = {Biomass value chains (BVCs), Food–energy–water (FEW) nexus, Mathematical modelling, Biomass supply chains, Optimisation, Process systems engineering, Sustainable land use, Bioenergy},
abstract = {Humanity’s future sustainable supply of energy, fuels and materials is aiming towards renewable sources such as biomass. Several studies on biomass value chains (BVCs) have demonstrated the feasibility of biomass in replacing fossil fuels. However, many of the activities along the chain can disrupt the food–energy–water (FEW) nexus given that these resource systems have been ever more interlinked due to increased global population and urbanisation. Essentially, the design of BVCs has to integrate the systems-thinking approach of the FEW nexus; such that, existing concerns on food, water and energy security, as well as the interactions of the BVCs with the nexus, can be incorporated in future policies. To date, there has been little to no literature that captures the synergistic opportunities between BVCs and the FEW nexus. This paper presents the first survey of process systems engineering approaches for the design of BVCs, focusing on whether and how these approaches considered synergies with the FEW nexus. Among the surveyed mathematical models, the approaches include multi-stage supply chain, temporal and spatial integration, multi-objective optimisation and uncertainty-based risk management. Although the majority of current studies are more focused on the economic impacts of BVCs, the mathematical tools can be remarkably useful in addressing critical sustainability issues in BVCs. Thus, future research directions must capture the details of food–energy–water interactions with the BVCs, together with the development of more insightful multi-scale, multi-stage, multi-objective and uncertainty-based approaches.}
}
@incollection{MOITRA198793,
title = {Parallel Algorithms for Some Computational Problems},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {26},
pages = {93-153},
year = {1987},
booktitle = {Advances in Computers},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60006-6},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808600066},
author = {Abha Moitra and S. {Sitharama Iyengar}},
abstract = {Publisher Summary
The chapter presents a survey of parallel algorithms for finding the connected and biconnected components of a graph. The chapter classifies the various parallel algorithms for finding the connected components of undirected graphs according to two major criteria: the basic technique employed and the format of the input. The basic techniques used in these algorithms are breadth-first search, transitive closure, and vertex collapse. The most common form of input is adjacency matrix. The chapter presents several parallel minimum spanning tree algorithms for different types of parallel computational models. A minimum spanning tree of a weighted, connected, and undirected graph is defined as a set of edges of the graph that connects all vertices and whose total edge weight is minimum. The chapter discusses various other parallel graph algorithms for shortest path, maximum matching, planarity testing, and maximal independent set. It describes parallel algorithms for various nongraph-theoretic problems like arithmetic expression and polynomial evaluation, string matching, tree balancing, and alpha-beta search.}
}
@article{ZHANG2024111498,
title = {Modular reverse design of acoustic metamaterial and sound barrier engineering applications: High ventilation and broadband sound insulation},
journal = {Thin-Walled Structures},
volume = {196},
pages = {111498},
year = {2024},
issn = {0263-8231},
doi = {https://doi.org/10.1016/j.tws.2023.111498},
url = {https://www.sciencedirect.com/science/article/pii/S0263823123009758},
author = {Xinhao Zhang and Qi Yu and Caiyou Zhao and Duojia Shi and Mingjing Geng and Junyuan Zheng and Tao Lu and Ping Wang},
keywords = {Novel acoustic metamaterials, Modular inverse design, High ventilation broadband acoustic insulation, PSO-DNN algorithm, Impedance tube test, OMCAM sound barrier},
abstract = {A multi-gradient cavity acoustic metamaterial (MCAM) structure and a modular reverse design method (MRDM) that can realize high ventilation and broadband acoustic isolation are proposed. The method controls the deep neural network model of acoustic metamaterials through a particle swarm algorithm, and the optimized multi-gradient cavity acoustic metamaterial structure (OMCAM) can be reverse-designed by inputting only the constraints and the objective function such as the amount of noise reduction. Compared with the finite element method, the computational efficiency can be improved by about 500 times to achieve an optimized design. The acoustic simulation results show that the average noise reduction of the structure is 23.5 dB in the range of 0∼4000 Hz, and a broadband sound attenuation with 38 dB noise reduction is formed in the target frequency band of 500Hz∼2000 Hz. The acoustic experimental results of the 3D-printed structure are in agreement with the simulation results. Compared with the two existing ventilated acoustic metamaterials, the average noise reduction of OMCAM under equal ventilation capacity is improved by 10.6 dB and 17.4 dB, respectively. The sound barrier based on the proposed OMCAM design is implemented on an elevated rail transit line, showing an improvement of 9.4 dB of average noise reduction compared with existing upright railroad sound barriers. The noise reduction mechanism of the OMCAM structure was finally revealed by the sound field distribution in different modes.}
}
@article{GAFFLEY2024477,
title = {Survey on the Perceptions of Pregnancy and Parenthood in Trainees: Advances, Obstacles, and Growth Opportunities},
journal = {Journal of Surgical Research},
volume = {295},
pages = {477-486},
year = {2024},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2023.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0022480423005528},
author = {Michaela Gaffley and Sean Hernandez and Katherine M. Riera and Saskia Anzola},
keywords = {Graduate medical education, Parenting, Pregnancy, Residency},
abstract = {Introduction
Despite national policy changes, perspective changes on pregnancy and parenting in training are often lacking. We evaluated current viewpoints regarding pregnancy, parenthood, leave needs, and perceptions of support across trainees at our institution.
Methods
A cross-sectional survey was sent to all residents and fellows at a tertiary care academic center with >700 trainees. Demographic information, opinions on maternity and paternity leave, and opinions on institutional support and career goals were collected. The survey was sent via the Graduate Medical Education Office listserv -- 66 Accreditation Council for Graduate Medical Education (ACGME) programs and 40 non-ACGME programs.
Results
Seven hundred and forty-seven house officers received the survey with a response rate of 21.9% (n = 164). Of respondents, 81% were residents and 99 respondents were female (representing 31% of female trainees at our institution). Thirty-seven point two percent of respondents reported being parents. Twenty-five point three percent of respondents had been pregnant while a trainee with no statistical difference by specialty type (P = 0.0817). Statistically significant difference was noted in having children based on sex with men becoming parents at twice the rate of women (56% vs 26%, P < 0.001). No difference was noted between specialties on perceived support while pregnant and peripartum. Thirty percent of parent respondents reported thinking about leaving medical training after having children given family stressors. Statistical difference in thoughts of leaving medicine overall between females (46%) and males (17.6%; P = 0.0238).
Conclusions
Men and women need support as they navigate becoming parents at a naturally stressful transition period. Females consider leaving medicine at twice the rate of males after becoming parents. Our institution and other ACGME programs need greater transparency and consistent leave practices that reflect changing times.}
}
@article{YANG2010209,
title = {Creativity of student information system projects: From the perspective of network embeddedness},
journal = {Computers & Education},
volume = {54},
number = {1},
pages = {209-221},
year = {2010},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0360131509001997},
author = {Heng-Li Yang and Hsiu-Hua Cheng},
keywords = {Project team creativity, Network embeddedness, Affiliation network, Innovation climate, Centrality},
abstract = {Many companies have pursued innovation to obtain a competitive edge. Thus, educational reform focuses mainly on training creative students. This study adopted the concept of an affiliated network of projects to investigate how project embeddedness influences project team creativity. This work surveys 60 projects in a Management Information Systems Department of a University. Validity of the specific study hypotheses is tested by using moderate hierarchical regression analysis to determine how project embeddedness affects project team creativity and assess how the team innovation climate moderates the relationships between project embeddedness and project team creativity. Analytical results indicate a positive association between structural embeddedness and project team creativity, a negative relationship between positional embeddedness and project team creativity, and a positive influence of team innovation climate on the relationships between network embeddedness and project team creativity. An attempt is also made to understand the role of positional embeddedness by classifying the interactions based on the content of interactions. According to those results, positional embeddedness is positively related to project team creativity during problem–identification interaction; during solution–design interaction, positional embeddedness is negatively related to project team creativity. Results of this study explain the phenomena of divergent thinking and convergent thinking during creative development.}
}
@article{HAGHGOO2024108332,
title = {The percolation inception of the CNT-polymer nanocomposites with the magneto-electric field effects on the CNT subbands},
journal = {Composites Part A: Applied Science and Manufacturing},
volume = {185},
pages = {108332},
year = {2024},
issn = {1359-835X},
doi = {https://doi.org/10.1016/j.compositesa.2024.108332},
url = {https://www.sciencedirect.com/science/article/pii/S1359835X24003294},
author = {Mojtaba Haghgoo and Reza Ansari and Mohammad {Kazem Hassanzadeh-Aghdam} and Jaehwan Kim},
keywords = {A. Carbon nanotubes and nanofibers, A. Multifunctional composites, B. Electrical properties, C. Analytical modelling},
abstract = {The percolation inception of CNT-polymer nanocomposites is studied considering the magneto-electric field effects on CNT subbands. The analytical model predicts the electrical conductivity where CNTs are modeled as slender rods with their geometric orientations as randomly distributed or aligned to transfer electrons at tunneling distance range. The tunneling effect takes into account the electron transmission between every linked pair of CNTs when evaluating electrical resistance. The subsequent CNT displacement computation and the resistance change comprise the other phase of the modeling approach. Piezoresistivity results of the analyses agree well with the experimental data when considering tunneling behavior in the percolation transition zone. The magnetic field enhances the field affected subbands and increases the electrical conductivity by enhancing the mobility of the charges. The results reveal that the efficiency of CNT network in transmitting charges is increased with higher aspect ratio CNTs that scaled the sensitivity to lower values.}
}
@article{MARKMAN20181,
title = {Combining the Strengths of Naturalistic and Laboratory Decision-Making Research to Create Integrative Theories of Choice},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {7},
number = {1},
pages = {1-10},
year = {2018},
issn = {2211-3681},
doi = {https://doi.org/10.1016/j.jarmac.2017.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211368117301778},
author = {Arthur B. Markman},
keywords = {Decision making, Naturalistic decision making, External validity, Internal validity},
abstract = {Naturalistic decision-making research contrasts with traditional laboratory research along a number of dimensions. It is typically more observational, more focused on expert performance, and more attentive to the context in which decisions are made than laboratory studies. This approach helps to shore up some of the weaknesses of laboratory research by providing incentive to develop integrative theories of choice and examining strong methods of problem solving in a choice domain. This paper contrasts the strengths and weaknesses of laboratory and naturalistic approaches to decision making. Then, it explores strategies for using both of these approaches as well as mathematical and computational modeling to find the optimal tradeoff between internal and external validity for research projects.}
}
@article{GUAN2022256,
title = {AFE-CNN: 3D Skeleton-based Action Recognition with Action Feature Enhancement},
journal = {Neurocomputing},
volume = {514},
pages = {256-267},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222012784},
author = {Shannan Guan and Haiyan Lu and Linchao Zhu and Gengfa Fang},
keywords = {3D Skeleton, Action Recognition, Feature Enhance, Attention},
abstract = {Existing 3D skeleton-based action recognition approaches reach impressive performance by encoding handcrafted action features to image format and decoding by CNNs. However, such methods are limited in two ways: a) the handcrafted action features are difficult to handle challenging actions, and b) they generally require complex CNN models to improve action recognition accuracy, which usually occur heavy computational burden. To overcome these limitations, we introduce a novel AFE-CNN, which devotes to enhance the features of 3D skeleton-based actions to adapt to challenging actions. We propose feature enhance modules from key joint, bone vector, key frame and temporal perspectives, thus the AFE-CNN is more robust to camera views and body sizes variation, and significantly improve the recognition accuracy on challenging actions. Moreover, our AFE-CNN adopts a light-weight CNN model to decode images with action feature enhanced, which ensures a much lower computational burden than the state-of-the-art methods. We evaluate the AFE-CNN on three benchmark skeleton-based action datasets: NTU RGB + D, NTU RGB + D 120, and UTKinect-Action3D, with extensive experimental results demonstrate our outstanding performance of AFE-CNN.}
}
@article{IMM2012130,
title = {Talking mathematically: An analysis of discourse communities},
journal = {The Journal of Mathematical Behavior},
volume = {31},
number = {1},
pages = {130-148},
year = {2012},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2011.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312311000630},
author = {Kara Imm and Despina A. Stylianou},
keywords = {Discourse, Cognitively demand tasks, Local authority},
abstract = {Discourse has always been at the heart of teaching. In more recent years, the mathematics education community has also turned its attention towards understanding the role of discourse in mathematics teaching and learning. Using earlier classifications of discourse, in this paper, we looked at three types of classrooms: classrooms that engage in high discourse, low discourse and a hybrid of the two. We aimed to understand how the elements of each discourse affected classroom learning, relationships between teachers and students, and participatory structures for students. Overall, our findings highlight the important relationship between cognitively demanding tasks and mathematical talk, and the power of discourse as a “thinking device” as opposed to mere conduit of knowledge. Our work also points to the under-theorized nature of hybrid discourse in mathematics classrooms, thereby providing some directions for pedagogy and further research.}
}
@article{WANG2022799,
title = {BMW-TOPSIS: A generalized TOPSIS model based on three-way decision},
journal = {Information Sciences},
volume = {607},
pages = {799-818},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522006004},
author = {Yumei Wang and Peide Liu and Yiyu Yao},
keywords = {Three-way decision, TOPSIS, Reference point, Multiple attribute decision making},
abstract = {TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) uses a pair of a positive ideal solution and a negative ideal solution as two reference points to rank a set of decision alternatives. In some situations, a trade-off of the distances to the two extreme reference points may not necessarily be meaningful. Inspired by the theory of three-way decision as thinking in threes (e.g., two opposite poles and a third middle), in this paper we generalize the classical TOPSIS by adding a third middle reference point. We use a common setting for investigating systematically reference-point-based TOPSIS-style multi-criteria decision-making methods. In particular, we examine three classes of approaches: a) a best reference point based model (i.e., B-TOPSIS) and a worst reference point based model (i.e., W-TOPSIS), b) the classical best and worst reference points based model (i.e., BW-TOPSIS), and c) a new best, mean, and worst reference points based model (i.e., BMW-TOPSIS). The three classes are one-way TOPSIS, two-way TOPSIS, and three-way TOPSIS, respectively. Based on one-way and two-way TOPSISs, we give two specific methods of three-way TOPSIS. The experimental results, compared with the existing TOPSIS methods, show that the BMW-TOPSIS model is feasible and effective.}
}
@incollection{JANELLE2015415,
title = {Time-Space in Geography},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {415-420},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.72070-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868720708},
author = {Donald G. Janelle},
keywords = {Activity patterns, Communication, Cyberinfrastructure, Geographic information systems, Human extensibility, Space-time path, Space-time prism, Time geography, Time-space compression, Time-space convergence, Time-space distanciation, Transportation, Travel},
abstract = {This article reviews the development of time-space perspectives in geography and exposes linkages between these perspectives and society's prevailing technologies for travel and communication. Special attention is given to the role of information, computation, and visualization technologies that shape the research practices that advance the potential to understand social organization and human activity behavior in a time-space context.}
}
@article{DULIC201654,
title = {Designing futures: Inquiry in climate change communication},
journal = {Futures},
volume = {81},
pages = {54-67},
year = {2016},
note = {Modelling and Simulation in Futures Studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0016328716000057},
author = {Aleksandra Dulic and Jeannette Angel and Stephen Sheppard},
keywords = {Design inquiry, Designing futures, Climate change communication, Interaction design, 3D game simulation, Transdisciplinary research},
abstract = {There are many barriers and challenges associated with climate change communication focused on promoting community-based action for sustainable futures. Of particular interest is the challenge to embed community perspectives in a communication process of climate change solutions. In this paper we argue that 3D interactive simulations using design inquiry as a development process, can be an effective way of communicating climate change solutions and multiple community responses. People are more likely to engage with the challenges associated with complexity of climate change at the local level when their perspectives are integrated into viable and multiple pathways for action. Future scenarios of change processes situated in local experiences in compelling and interactive ways can be disseminated holistically by making links between scientific, social, political, economic and cultural elements. Design inquiry, as a research approach, integrates contextual knowledge into communication processes to aid imagining, re-thinking and reembodying viable pathways that explore the kinds of futures we collectively envision. This paper examines the contributions that design inquiry makes to climate change communication using an interactive simulation environment for designing futures. We discuss these ideas using the example of the Future Delta project, a virtual 3D environment that enables the exploration and simulation of multiple community-based climate change solutions in the Corporation of Delta, British Columbia.}
}
@article{CHI2024117852,
title = {Artificial intelligence in metabolomics: a current review},
journal = {TrAC Trends in Analytical Chemistry},
volume = {178},
pages = {117852},
year = {2024},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2024.117852},
url = {https://www.sciencedirect.com/science/article/pii/S0165993624003352},
author = {Jinhua Chi and Jingmin Shu and Ming Li and Rekha Mudappathi and Yan Jin and Freeman Lewis and Alexandria Boon and Xiaoyan Qin and Li Liu and Haiwei Gu},
keywords = {Artificial intelligence, Metabolomics, Machine learning, Deep learning, Systems biology, Disease diagnosis, Precision medicine, Drug discovery},
abstract = {Metabolomics and artificial intelligence (AI) form a synergistic partnership. Metabolomics generates large datasets comprising hundreds to thousands of metabolites with complex relationships. AI, aiming to mimic human intelligence through computational modeling, possesses extraordinary capabilities for big data analysis. In this review, we provide a recent overview of the methodologies and applications of AI in metabolomics studies in the context of systems biology and human health. We first introduce the AI concept, history, and key algorithms for machine learning and deep learning, summarizing their strengths and weaknesses. We then discuss studies that have successfully used AI across different aspects of metabolomic analysis, including analytical detection, data preprocessing, biomarker discovery, predictive modeling, and multi-omics data integration. Lastly, we discuss the existing challenges and future perspectives in this rapidly evolving field. Despite limitations and challenges, the combination of metabolomics and AI holds great promises for revolutionary advancements in enhancing human health.}
}
@article{AICHA2022107933,
title = {A mathematical formulation for processing time computing in disassembly lines and its optimization},
journal = {Computers & Industrial Engineering},
volume = {165},
pages = {107933},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.107933},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222000031},
author = {Mahdi Aicha and Imen Belhadj and Moncef Hammadi and Nizar Aifaoui},
keywords = {DP Evaluation, Index of Quality, Operating time, Optimization, Lean thinking},
abstract = {Disassembly is the first practice in maintenance and recycling of industrial products. For productivity and efficiency, it is necessary to optimize its operative manners by reducing: change of tools and directions, process variation, wastes, etc. The simulation of Disassembly Plan (DP) allows the detection and identification of difficulties from the design stage in order to avoid them. This paper proposes a mathematical formulation which combines two principal indicators: the index of Quality (Qi) and the index of processing Time (Ti) in order to choose the best and feasible disassembly plan. The Failure Mode, Effects and Criticality Analysis method is implemented to compute Qi. Ti is obtained according to real manufacturing constraints (workspace, layout, tools, machines, etc.). Based on 5S method, the workspace can be optimized which directly impacts the timing index and contribute to the selection of the best DP. A gear box is used to show up the efficiency of the proposed approach.}
}
@article{PICCIONI2024114222,
title = {From layer to building: Multiscale modeling of thermo-optical properties in 3D-printed facades},
journal = {Energy and Buildings},
volume = {314},
pages = {114222},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114222},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824003384},
author = {Valeria Piccioni and Lars O. Grobe and Illias Hischier and Arno Schlueter},
keywords = {3D-printed facades, Thermo-optical properties, Multi-scale modeling, Experimental validation},
abstract = {The challenge of building sector decarbonization has driven an integral rethinking of the way we design and build facades. Recently, large scale 3D-printing has emerged as an alternative manufacturing technique for novel facade components aiming at high operational efficiency and low environmental impact. Focusing on translucent polymer 3DPFs, this study tackles the challenges of modeling thermal and optical effects in geometrically complex components where interactions across multiple domains and scales occur. In particular, we introduce a novel method for modeling the irregular thermo-optical properties of 3DPFs, capable of capturing relevant effects often out of the scope of traditional modeling approaches. Our model accounts for geometry-dependent physical effects ranging from millimeter-scale fabrication details that impact optical behavior to centimeter-scale geometric features influencing heat and radiation transfer, extending up to the meter-scale implications for the building application. By employing computational techniques such as ray-tracing, computational fluid dynamics, and finite element analysis, we establish a model that offers detailed thermal and optical analysis to support performance-driven design iterations. Finally, demonstrating this approach in an office building context, we show that 3DPFs can match the performance of double glazing with dynamic shading, providing effective solar and thermal management over the year. This is achieved in a single, mono-material component with no active control, suggesting 3DPFs are a promising direction for low-environmental impact facade design.}
}
@article{COMPANY2009592,
title = {Computer-aided sketching as a tool to promote innovation in the new product development process},
journal = {Computers in Industry},
volume = {60},
number = {8},
pages = {592-603},
year = {2009},
note = {Computer Aided Innovation},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2009.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S016636150900133X},
author = {Pedro Company and Manuel Contero and Peter Varley and Nuria Aleixos and Ferran Naya},
keywords = {Engineering design and innovation, CAI software, Computer-aided sketching},
abstract = {Sketching is an established part of engineering culture. Sketches assist product designers during the creative stages of design and help them to develop inventions. Paper-and-pencil sketching is highly useful but lacks functionalities, mainly because it is disconnected from the rest of the (computer-aided) design process. However, CAS tools are not yet as usable as paper-and-pencil, although they provide full integration with the subsequent phases of the design processes (CAD, CAE, CAM, etc.) and other interesting functionalities. We desire computer-aided sketching (CAS) tools which furnish users with the sketching environment they require to make full use of their conceptual design and innovation talents, while providing full integration with the subsequent phases of the design processes (CAD, CAE, CAM, etc.). In this paper we discuss the importance of sketching in conceptual design, we review the current situation of engineering sketching, and we then analyze the main characteristics which a successful and fully integrated CAS tool should include. We consider CAS, not as a single problem, but as at least three: thinking, prescriptive and talking sketches require different approaches to functionality. Finally, we present the current state of the art in CAS tools by describing the main features and outstanding problems of our own applications.}
}
@article{GRIFFEN20208695,
title = {Chemists: AI Is Here; Unite To Get the Benefits},
journal = {Journal of Medicinal Chemistry},
volume = {63},
number = {16},
pages = {8695-8704},
year = {2020},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.0c00163},
url = {https://www.sciencedirect.com/science/article/pii/S1520480420001672},
author = {Edward J. Griffen and Alexander G. Dossetter and Andrew G. Leach},
abstract = {The latest developments in artificial intelligence (AI) have arrived into an existing state of creative tension between computational and medicinal chemists. At their most productive, medicinal and computational chemists have made significant progress in delivering new therapeutic agents into the clinic. However, the relationship between these communities has the prospect of being weakened by application of oversimplistic AI methods that, if they fail to deliver, will reinforce unproductive prejudices. We review what can be learned from our history of integrating QSAR and structure-based methods into drug discovery. Now with synthesis and testing available as contract services, the environment for computational innovation has changed and we consider the impact this may have on the relationships in our disciplines. We discuss the current state of interdisciplinary communication and suggest approaches to bring the subdisciplines together in order to improve computational medicinal chemistry and, most importantly, deliver better medicines to the clinic faster.
}
}
@article{MILLET2023107707,
title = {Defending humankind: Anthropocentric bias in the appreciation of AI art},
journal = {Computers in Human Behavior},
volume = {143},
pages = {107707},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107707},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223000584},
author = {Kobe Millet and Florian Buehler and Guanzhong Du and Michail D. Kokkoris},
keywords = {Anthropocentrism, Speciesism, Artificial intelligence (AI), Computational creativity, Computer-generated art, Awe},
abstract = {We argue that recent advances of artificial intelligence (AI) in the domain of art (e.g., music, painting) pose a profound ontological threat to anthropocentric worldviews because they challenge one of the last frontiers of the human uniqueness narrative: artistic creativity. Four experiments (N = 1708), including a high-powered preregistered experiment, consistently reveal a pervasive bias against AI-made artworks and shed light on its psychological underpinnings. The same artwork is preferred less when labeled as AI-made (vs. human-made) because it is perceived as less creative and subsequently induces less awe, an emotional response typically associated with the aesthetic appreciation of art. These effects are more pronounced among people with stronger anthropocentric creativity beliefs (i.e., who believe that creativity is a uniquely human characteristic). Systematic depreciation of AI-made art (assignment of lower creative value, suppression of emotional reactions) appears to serve a shaken anthropocentric worldview whereby creativity is exclusively reserved for humans.}
}
@article{SAMPAYO2022100348,
title = {CPSD2: A new approach for cyber-physical systems design and development},
journal = {Journal of Industrial Information Integration},
volume = {28},
pages = {100348},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2022.100348},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X22000206},
author = {M. Sampayo and P. Peças},
keywords = {Cyber-physical system, Product design and development, Business model, Operational and production needs, Design of cyber-physical systems, Industry 4.0},
abstract = {Cyber-physical systems (CPS) allow the integration of computation to physical contexts, unlocking more sophisticated capabilities in engineering systems. A methodology is needed to properly guide the entire process of creating, designing, building and implementing a CPS. Methodologies addressing the essential aspects of CPS design already exist. However, none was found that properly concerns the company's business model and its way of market interaction, in order to identify opportunities where the use of CPS could improve the performance. Therefore, this article proposes CPSD2: a CPS design and development methodology approach based on generic product design and development methods.}
}
@article{CARBONELL2016145,
title = {The role of metaphors in the development of technologies. The case of the artificial intelligence},
journal = {Futures},
volume = {84},
pages = {145-153},
year = {2016},
note = {SI: Metaphors in FS},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0016328715300902},
author = {Javier Carbonell and Antonio Sánchez-Esguevillas and Belén Carro},
keywords = {CLA, Metaphors, Artificial intelligence, Lakoff and Johnson},
abstract = {Technology plays a prominent role in configuring the way we live and work. In this paper we go further and think that it is a first level driver in the configuration of our deepest perceptions and has a paramount influence on shaping our worldviews and metaphors, though this aspect goes unnoticed for most of the population. In this paper we analyze how metaphors take action in the characterization of technologies, mainly emerging technologies, and in their evolution, and furthermore the impact of technologies and metaphors on the way we perceive our daily life. We analyze metaphors underlying brain nature and artificial intelligence, raising the connections between them and showing how metaphors in one of these fields impact on the way we understand the other. This fact has important consequences, for instance it conditions the evolution of computational systems, and we propose two scenarios for this evolution. This paper relies on the conceptual model and classification of metaphors proposed by Lakoff and Johnson in “Metaphors we live by”, from the orientational metaphors that show values and mantras, to the deepest structural metaphors that are reconfiguring how life is conceived. It also relies on CLA (Causal Layered Analysis) and to its reference book “CLA 2.0” in order to insert this analysis in a wider and future oriented framework and to analyze scenarios.}
}
@article{BARRON1992245,
title = {A bibliography on computational molecular biology and genetics},
journal = {Mathematical and Computer Modelling},
volume = {16},
number = {6},
pages = {245-319},
year = {1992},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(92)90166-I},
url = {https://www.sciencedirect.com/science/article/pii/089571779290166I},
author = {Sarah Barron and Matthew Witten and Gongxian Liu},
abstract = {The field of computational molecular biology and genetics is expanding at an enormous rate. Journals such as CABIOS and Nucleic Acids Research routinely publish articles on computational and mathematical aspects of biology. The purpose of this paper is to provide a bibliographic review of the literature in this area related to DNA mapping and sequence analysis. We have focused on computer and mathematical aspects of molecular biology and genetics (interpreted in a broad sense). Authors are solicited for their additions/corrections to this bibliography. Contact us at the above address.}
}
@article{CLEMENTZ2020808,
title = {Testing Psychosis Phenotypes From Bipolar–Schizophrenia Network for Intermediate Phenotypes for Clinical Application: Biotype Characteristics and Targets},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {5},
number = {8},
pages = {808-818},
year = {2020},
note = {Understanding the Nature and Treatment of Psychopathology: Letting the Data Guide the Way},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2020.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S2451902220301002},
author = {Brett A. Clementz and Rebekah L. Trotti and Godfrey D. Pearlson and Matcheri S. Keshavan and Elliot S. Gershon and Sarah K. Keedy and Elena I. Ivleva and Jennifer E. McDowell and Carol A. Tamminga},
keywords = {Biomarkers, Computational neuroscience, Neurobiological, Precision medicine, Psychopathology, Transdiagnostic},
abstract = {Background
Psychiatry aspires to the molecular understanding of its disorders and, with that knowledge, to precision medicine. Research supporting such goals in the dimension of psychosis has been compromised, in part, by using phenomenology alone to estimate disease entities. To this end, we are proponents of a deep phenotyping approach in psychosis, using computational strategies to discover the most informative phenotypic fingerprint as a promising strategy to uncover mechanisms in psychosis.
Methods
Doing this, the Bipolar–Schizophrenia Network for Intermediate Phenotypes (B-SNIP) has used biomarkers to identify distinct subtypes of psychosis with replicable biomarker characteristics. While we have presented these entities as relevant, their potential utility in clinical practice has not yet been demonstrated.
Results
Here we carried out an analysis of clinical features that characterize biotypes. We found that biotypes have unique and defining clinical characteristics that could be used as initial screens in the clinical and research settings. Differences in these clinical features appear to be consistent with biotype biomarker profiles, indicating a link between biological features and clinical presentation. Clinical features associated with biotypes differ from those associated with DSM diagnoses, indicating that biotypes and DSM syndromes are not redundant and are likely to yield different treatment predictions. We highlight 3 predictions based on biotype that are derived from individual biomarker features and cannot be obtained from DSM psychosis syndromes.
Conclusions
In the future, biotypes may prove to be useful for targeting distinct molecular, circuit, cognitive, and psychosocial therapies for improved functional outcomes.}
}
@article{SALEMDEEB2022200069,
title = {Beyond recycling: An LCA-based decision-support tool to accelerate Scotland's transition to a circular economy},
journal = {Resources, Conservation & Recycling Advances},
volume = {13},
pages = {200069},
year = {2022},
issn = {2667-3789},
doi = {https://doi.org/10.1016/j.rcradv.2022.200069},
url = {https://www.sciencedirect.com/science/article/pii/S2667378922000074},
author = {Ramy Salemdeeb and Ruth Saint and Francesco Pomponi and Kimberley Pratt and Michael Lenaghan},
keywords = {Life cycle assessment, Policy development, Resource and waste management, Circular economy, Zero waste},
abstract = {Resources and waste strategies have recently seen a shift in focus from weight-based recycling targets to impact-driven policies. To support this transition, numerous decision-support tools were developed to help identify waste streams with the highest impacts. However, the majority of these tools focus solely on greenhouse gas emissions and show a narrow picture of the overall environmental impacts. Furthermore, they cover burdens associated with direct waste management activities and hence fall short when it comes to highlighting the substantial benefits that can be achieved by preventing waste in the first place. This paper quantitatively demonstrates the necessity to adopt impact-based targets that go beyond estimating the greenhouse gas emissions of waste and highlights the substantial benefits of waste reduction and prevention. Using a state-of-the-art waste environmental footprint tool, the paper quantifies the overall environmental impacts of Scotland's household waste and shows how targeting ‘heavy’ materials does not necessarily have the highest overall environmental benefit. Results show that embodied environmental impacts of household waste dominate the total environmental burdens, contributing more than 90% to the whole life cycle impacts, and hence policymakers should prioritise interventions that aim at waste reduction and prevention. Moreover, our analysis shows that food and textile wastes are high-priority materials in Scotland, with the largest contribution to overall environmental burdens; up to 42% and 30%, respectively. Considering the overall environmental impacts of specific waste materials will enable policymakers to develop more granular and targeted interventions to accelerate our transition to a sustainable circular economy.}
}
@article{VARUGHESE2023684,
title = {The intersection of space and sustainability: The need for a transdisciplinary and bi-cultural approach},
journal = {Acta Astronautica},
volume = {211},
pages = {684-701},
year = {2023},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2023.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0094576523003600},
author = {Carolle Varughese and Lena Henry and Adam Morris and Sarah Bickerton and Nicholas Rattenbury and Cody Mankelow and Alice Gorman and Stevie Katavich-Barton and Priyanka Dhopade},
keywords = {Max of six for acta astronautica, Space sustainability, Transdisciplinary, Indigenous sustainability, Terrestrial sustainability, Space debris},
abstract = {Aotearoa New Zealand's emerging New Space economy provides an opportunity for key actors to focus on space and sustainability issues beyond space debris. The conflict between competing definitions and paradigms of sustainability highlights the importance of diverse values, assumptions, and drivers of change that shape the normative understanding of space sustainability issues. This paper recognises that Indigenous knowledges and practices are in parallel with systems-thinking and transdisciplinary approaches to space and sustainability. The aim of this paper is to describe how current actions can have long term impacts on using and accessing space commercially, scientifically, and culturally.}
}
@article{FAIRHALL2014ix,
title = {The receptive field is dead. Long live the receptive field?},
journal = {Current Opinion in Neurobiology},
volume = {25},
pages = {ix-xii},
year = {2014},
note = {Theoretical and computational neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2014.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0959438814000361},
author = {Adrienne Fairhall},
abstract = {Advances in experimental techniques, including behavioral paradigms using rich stimuli under closed loop conditions and the interfacing of neural systems with external inputs and outputs, reveal complex dynamics in the neural code and require a revisiting of standard concepts of representation. High-throughput recording and imaging methods along with the ability to observe and control neuronal subpopulations allow increasingly detailed access to the neural circuitry that subserves neural representations and the computations they support. How do we harness theory to build biologically grounded models of complex neural function?}
}
@article{OKEREKE2014637,
title = {Virtual testing of advanced composites, cellular materials and biomaterials: A review},
journal = {Composites Part B: Engineering},
volume = {60},
pages = {637-662},
year = {2014},
issn = {1359-8368},
doi = {https://doi.org/10.1016/j.compositesb.2014.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S1359836814000109},
author = {M.I. Okereke and A.I. Akpoyomare and M.S. Bingley},
keywords = {A. Polymer–matrix composites (PMCs), C. Computational modelling, C. Numerical analysis, E. Weaving, Virtual testing},
abstract = {This paper documents the emergence of virtual testing frameworks for prediction of the constitutive responses of engineering materials. A detailed study is presented, of the philosophy underpinning virtual testing schemes: highlighting the structure, challenges and opportunities posed by a virtual testing strategy compared with traditional laboratory experiments. The virtual testing process has been discussed from atomistic to macrostructural length scales of analyses. Several implementations of virtual testing frameworks for diverse categories of materials are also presented, with particular emphasis on composites, cellular materials and biomaterials (collectively described as heterogeneous systems, in this context). The robustness of virtual frameworks for prediction of the constitutive behaviour of these materials is discussed. The paper also considers the current thinking on developing virtual laboratories in relation to availability of computational resources as well as the development of multi-scale material model algorithms. In conclusion, the paper highlights the challenges facing developments of future virtual testing frameworks. This review represents a comprehensive documentation of the state of knowledge on virtual testing from microscale to macroscale length scales for heterogeneous materials across constitutive responses from elastic to damage regimes.}
}
@article{ALQARALLEH20223913,
title = {Automated Handwriting Recognition and Speech Synthesizer for Indigenous Language Processing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {2},
pages = {3913-3927},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.026531},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822014461},
author = {Bassam A. Y. Alqaralleh and Fahad Aldhaban and Feras Mohammed A-Matarneh and Esam A. AlQaralleh},
keywords = {Computational linguistics, handwriting character recognition, natural language processing, indigenous language},
abstract = {In recent years, researchers in handwriting recognition analysis relating to indigenous languages have gained significant internet among research communities. The recent developments of artificial intelligence (AI), natural language processing (NLP), and computational linguistics (CL) find useful in the analysis of regional low resource languages. Automatic lexical task participation might be elaborated to various applications in the NLP. It is apparent from the availability of effective machine recognition models and open access handwritten databases. Arabic language is a commonly spoken Semitic language, and it is written with the cursive Arabic alphabet from right to left. Arabic handwritten Character Recognition (HCR) is a crucial process in optical character recognition. In this view, this paper presents effective Computational linguistics with Deep Learning based Handwriting Recognition and Speech Synthesizer (CLDL-THRSS) for Indigenous Language. The presented CLDL-THRSS model involves two stages of operations namely automated handwriting recognition and speech recognition. Firstly, the automated handwriting recognition procedure involves preprocessing, segmentation, feature extraction, and classification. Also, the Capsule Network (CapsNet) based feature extractor is employed for the recognition of handwritten Arabic characters. For optimal hyperparameter tuning, the cuckoo search (CS) optimization technique was included to tune the parameters of the CapsNet method. Besides, deep neural network with hidden Markov model (DNN-HMM) model is employed for the automatic speech synthesizer. To validate the effective performance of the proposed CLDL-THRSS model, a detailed experimental validation process takes place and investigates the outcomes interms of different measures. The experimental outcomes denoted that the CLDL-THRSS technique has demonstrated the compared methods.}
}
@article{AQDA2011260,
title = {The impact of constructivist and cognitive distance instructional design on the learner’s creativity},
journal = {Procedia Computer Science},
volume = {3},
pages = {260-265},
year = {2011},
note = {World Conference on Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.12.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910004199},
author = {Mahnaz Fatemi Aqda and Farideh Hamidi and Farhad Ghorbandordinejad},
keywords = {Instructional design, Distance education, E-learning, Creativity, Cognitivism, Constructivism},
abstract = {Creativity is at the heart of the 21st century educational work. Learner’ creativity or learner’s creative thinking skills are among the most important skills they need to be prepared for the knowledge society. The rapid development of technology in the modern era sheds light on the place and importance of creativity in education. Technology also has brought change in the way the students learn (collaboration strategy) and recently the computer-based instruction associated with electrical technologies has been a popular way of instruction that learning is no longer confined to classrooms (distance learning). Also in the case of the students if they want to take effective advantage of technology, they have to use the constructivist and cognitive skills (psychological learning theory). Recently education experts have tried to show how a distance instructional can be designed. The main question of this paper is what effects the distance instructional design based on the views of constructivism and cognitivism have on the learners’ creativity.The definition of distance education (e-learning), the instruction design based on constructivist view and its function in education and distance learning (e-learning), the instruction design based on cognitive view and its function in education and distance learning (e-learning), the factors affecting the creativity development and accommodation (comparison) the characteristics of the instructural context, and the impact of the appropriate learning on the creativity development according to these settings are among the other main points of this review.}
}
@article{NAGANANDHINI2019548,
title = {Effective Diagnosis of Alzheimer’s Disease using Modified Decision Tree Classifier},
journal = {Procedia Computer Science},
volume = {165},
pages = {548-555},
year = {2019},
note = {2nd International Conference on Recent Trends in Advanced Computing ICRTAC -DISRUP - TIV INNOVATION , 2019 November 11-12, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.01.049},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920300570},
author = {S. Naganandhini and P. Shanmugavadivu},
keywords = {Alzheimer’s Disease, Feature Selection, Classification, Decision Tree, Early Detection, Hyper Parameter Tuning},
abstract = {Alzheimer’s disease (AD) is described as a severe form of the neural disorder that collectively degenerate the essential cognitive activities of a human being (thinking, memory retention, etc.,) in particular among the elderly individuals and eventually results in death. In addition to the adverse ill-health effects on the patients, AD imposes paramount responsibility and burden on the caretakers too. Several genetic and pathological traits and non-invasive diagnostic strategies are being vigorously investigated and explored to discover the early onset of this debilitating disease. The prognosis of AD assumes importance, as the deterioration of health due to its progression may be either contained or controlled. Moreover, early and accurate detection of AD helps medical practitioners to prescribe case-specific medical treatment procedure. Among the popular machine learning algorithms, decision tree technique is widely used for classification/prediction, due to its accuracy and speed.This research article presents a novel decision tree-based classification technique, with optimum hyper parametertuning, that is ideally suitable for AD diagnosis, even at the early stages of development. The performance of this newly proposed Decision Tree Classifier with Hyper Parameters Tuning (DTC-HPT) is validated on the Open Access Imaging Studies Series (OASIS) dataset that contains patients’ data on the different stages of AD. The DTC-HPT is designed with the primary objective to classify the nature of brain abnormality using the most relevantand potentially significant data attributes/parameters. The efficiency of DTC-HPT on AD classification is measured as Accuracy, Precision, Recall, and F1-Score. The correctness of AD classification by DTC-HPTwith an average accuracy of 99.10% endorse that this classification technique can be used for AD detection on the AD clinical datasets.}
}
@incollection{MOUSTAFA202149,
title = {3 - Deductive reasoning abilities in schizophrenia and related disorders: A systematic review},
editor = {Ahmed A. Moustafa},
booktitle = {Cognitive and Behavioral Dysfunction in Schizophrenia},
publisher = {Academic Press},
pages = {49-65},
year = {2021},
isbn = {978-0-12-820005-6},
doi = {https://doi.org/10.1016/B978-0-12-820005-6.00004-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128200056000049},
author = {Ahmed A. Moustafa and Anchal Garg and Ahmed A. Helal and Eid {Abo Hamza}},
keywords = {Schizophrenia, Delusions, Hallucinations, Negative symptoms, Reasoning, Transitive inference, Wason Selection Task, Syllogism, Inductive vs. deductive reasoning},
abstract = {Background: Schizophrenia is a psychiatric disorder characterized by delusions, hallucinations, negative symptoms, and disorganized thinking. There has been a multitude of studies assessing reasoning performance in schizophrenia patients by using various reasoning tasks. Methods: We reviewed the existing literature using the following reasoning tasks in schizophrenia and related disorders: Transitive Inferences, Wason Card Selection, conditional reasoning, syllogisms, and other related tasks. Results: Some deductive reasoning studies have reported conflicting results where schizophrenia patients sometimes, outperform or underperform healthy controls. These findings are related to the plausibility, emotional content of logical sentences used in these studies. Importantly, data show that performance in deductive reasoning tasks is impacted by emotional and cognitive processes, such as theory of mind and working memory. However, neural studies report different brain mechanisms underlying different deductive reasoning task performance. Conclusions: Overall, there are differences in the findings of reasoning tasks which should be investigated in future studies as it will contribute towards an accurate understanding of reasoning processes in schizophrenia spectrum and related disorders.}
}
@article{THEISE200417,
title = {Understanding cell lineages as complex adaptive systems},
journal = {Blood Cells, Molecules, and Diseases},
volume = {32},
number = {1},
pages = {17-20},
year = {2004},
note = {Stem Cell Plasticity},
issn = {1079-9796},
doi = {https://doi.org/10.1016/j.bcmd.2003.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S1079979603002523},
author = {Neil D Theise and Mark d'Inverno},
keywords = {Stem cells, Lineage system, Reactive systems},
abstract = {Stem cells may be considered complex reactive systems because of their vast number in a living system, their reactive nature, and the influence of local environmental factors (such as the state of neighboring cells, tissue matrix, stem cell physiological processes) on their behavior. In such systems, emergent global behavior arises through the multitude of local interactions among the cell agents. Approaching hematopoietic and other stem cell lineages from this perspective have critical ramifications on current thinking relating to the plasticity of these lineage systems, the modeling of stem cell systems, and the interpretation of clinical data regarding many diseases within such models.}
}
@article{ALSAMHORI2024100133,
title = {Artificial intelligence for hearing loss prevention, diagnosis, and management},
journal = {Journal of Medicine, Surgery, and Public Health},
volume = {3},
pages = {100133},
year = {2024},
issn = {2949-916X},
doi = {https://doi.org/10.1016/j.glmedi.2024.100133},
url = {https://www.sciencedirect.com/science/article/pii/S2949916X24000860},
author = {Jehad Feras AlSamhori and Abdel Rahman Feras AlSamhori and Rama Mezyad Amourah and Yara AlQadi and Zina Wael Koro and Toleen Ramzi Abdallah Haddad and Ahmad Feras AlSamhori and Diala Kakish and Maya Jamal Kawwa and Margaret Zuriekat and Abdulqadir J. Nashwan},
keywords = {Artificial intelligence, Hearing loss, Machine learning, Computational audiology},
abstract = {This paper explores the transformative impact of artificial intelligence (AI), particularly machine learning (ML), on diagnosing and treating hearing loss, which affects over 5% of the global population across all ages and demographics. AI encompasses various applications, from natural language processing models like ChatGPT to image recognition systems; however, this paper focuses on ML, a subfield of AI that can revolutionize audiology by enhancing early detection, formulating personalized rehabilitation plans, and integrating electronic health records for streamlined patient care. The integration of ML into audiometry, termed "computational audiology," allows for automated, accurate hearing tests. AI algorithms can process vast data sets, provide detailed audiograms, and facilitate early detection of hearing impairments. Research shows ML's effectiveness in classifying audiograms, conducting automated audiometry, and predicting hearing loss based on noise exposure and genetics. These advancements suggest that AI can make audiological diagnostics and treatment more accessible and efficient. The future of audiology lies in the seamless integration of AI technologies. Collaborative efforts between audiologists, AI experts, and individuals with hearing loss are essential to overcome challenges and leverage AI's full potential. Continued research and development will enhance AI applications in audiology, improving patient outcomes and quality of life worldwide.}
}
@article{KEE1984198,
title = {Computational modeling of flame structure},
journal = {Physica D: Nonlinear Phenomena},
volume = {12},
number = {1},
pages = {198-211},
year = {1984},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(84)90524-4},
url = {https://www.sciencedirect.com/science/article/pii/0167278984905244},
author = {Robert J. Kee and James A. Miller},
abstract = {In this paper we discuss the need to model the detailed structure of a flame. That is, we argue the value of tracing the elementary reaction steps that are responsible for the creation of pollutant species and the release of heat. Accomplishing this task requires the computational solution of equations describing the conservation of mass, momentum, energy, and chemical species. In the course of our development we compare the computational approach with that of large activation energy asymptotic analysis. In the second half of the paper we concentrate on the computational consequences of flame modeling. Typically the governing equations are large and stiff systems of partial differential equations. Computational solution requires strongly stable implicit numerical algorithms, and we discuss these methods. We also discuss the adaptive meshing strategies that are required to resolve accurately the structure of thin flames in relatively large domains.}
}
@article{CHATANAKA2022100007,
title = {Immunoinformatics: Pushing the boundaries of immunology research and medicine},
journal = {ImmunoInformatics},
volume = {5},
pages = {100007},
year = {2022},
issn = {2667-1190},
doi = {https://doi.org/10.1016/j.immuno.2021.100007},
url = {https://www.sciencedirect.com/science/article/pii/S2667119021000070},
author = {Miyo K. Chatanaka and Antigona Ulndreaj and Dorsa Sohaei and Ioannis Prassas},
keywords = {Immunoinformatics, Immunology, Informatics, Perspective},
abstract = {Immunology has come a long way, from its early religious beginnings thousands of years ago, to the explosion of immunological data in the 21st century. Thanks to discoveries in immunology, our world has seen tremendous progress in how we understand and treat disease. However, a lot of unmet clinical needs remain, which require focused, real-time collaboration at the clinical and scientific research forefronts. Moreover, the current exponential growth in the generation of research data makes it impossible to handle, analyze, visualize, and interpret such data without the use of advanced computational tools. We think immunoinformatics- a discipline at the intersection of immunology and computer science- will greatly increase efficiency in research productivity and disease treatment. This perspective paper aims to emphasize the role of immunoinformatics toward pushing the boundaries of immunology research. It will also illustrate its clinical applications, including disease prevention, diagnosis, prognosis, treatment, monitoring, as well as in drug discovery. We believe informatics approaches will be implemented increasingly more frequently in research. Thus, here we also discuss a set of fundamental prerequisites to facilitate the efficient and ethical integration of informatics in research and ensure immunological advancements provide maximum benefits to society.}
}
@article{BELABES2015639,
title = {Designing Islamic Finance Programmes in a Competitive Educational Space: The Islamic Economics Institute Experiment},
journal = {Procedia - Social and Behavioral Sciences},
volume = {191},
pages = {639-643},
year = {2015},
note = {The Proceedings of 6th World Conference on educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.300},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815025604},
author = {Abderrazak Belabes and Ahmed Belouafi and Mohamed Daoudi},
keywords = {Curricula design, glocalization, competitiveness, Islamic finance, Islamic Economics Institute},
abstract = {This paper aims at exploring the experiment of the Islamic Economics Institute (IEI) of King Abdulaziz University in the design of the first ever Islamic finance higher educational programme at a Saudi Public University. An evaluative analytical framework has been utilized to meet this goal. Results show that the Institute has pursued a ‘glocalization’; thinking globally and acting locally approach in designing the programme. This approach aims at providing learners with ‘cutting-edge’ skills that will enhance their chances for employment at the local as well as regional markets. What are the advantages of this approach? And how can the Institute preserve its ‘distinctive research’ positioning that it has gained over the years, at the same time, being able to provide ‘world-class’ educational programmes?}
}
@article{CHEN201910,
title = {An artificial intelligence based data-driven approach for design ideation},
journal = {Journal of Visual Communication and Image Representation},
volume = {61},
pages = {10-22},
year = {2019},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2019.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1047320319300604},
author = {Liuqing Chen and Pan Wang and Hao Dong and Feng Shi and Ji Han and Yike Guo and Peter R.N. Childs and Jun Xiao and Chao Wu},
keywords = {Idea generation, Artificial intelligence in design, Data-driven design, Generative adversarial networks, Semantic network analysis, Network visualisation, Computational creativity},
abstract = {Ideation is a source of innovation and creativity, and is commonly used in early stages of engineering design processes. This paper proposes an integrated approach for enhancing design ideation by applying artificial intelligence and data mining techniques. This approach consists of two models, a semantic ideation network and a visual concepts combination model, which provide inspiration semantically and visually based on computational creativity theory. The semantic ideation network aims to provoke new ideas by mining potential knowledge connections across multiple knowledge domains, and this was achieved by applying “step-forward” and “path-track” algorithms which assist in exploring forward given a concept and in tracking back the paths going from a departure concept through a destination concept. In the visual concepts combination model, a generative adversarial networks model is proposed for generating images which synthesize two distinct concepts. An implementation of these two models was developed and tested in a design case study, which indicated that the proposed approach is able to not only generate a variety of cross-domain concept associations but also advance the ideation process quickly and easily in terms of quantity and novelty.}
}
@article{LIU2023113460,
title = {What is the “DNA” of healthy buildings? A critical review and future directions},
journal = {Renewable and Sustainable Energy Reviews},
volume = {183},
pages = {113460},
year = {2023},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2023.113460},
url = {https://www.sciencedirect.com/science/article/pii/S1364032123003179},
author = {Hui Liu and Xiaoxiao Xu and Vivian W.Y. Tam and Peng Mao},
keywords = {Healthy building, Indoor environment, DNA framework, Sustainability, Life-cycle, Future directions},
abstract = {Since the outbreak of COVID-19, buildings that provide improved performance have aroused extensive discussion. Nowadays, the connotation of healthy building is becoming complex, performance metrics for healthy buildings vary significantly from different regions in the world and there may be information asymmetry among stakeholders. Consequently, building health performance cannot be effectively achieved. However, previous studies have launched extensive reviews on green building, and there remains a lack of comprehensive and systematic reviews on healthy buildings. To address the above issues, therefore, this research aims to (1) conduct a thorough review of healthy building research and reveal its nature; and (2) identify the current research gaps and propose possible future research directions. Content analysis using NVivo were applied to review 238 relevant publications. A DNA framework of healthy buildings, which clarifies the characteristics, triggers, guides and actions, was then constructed for better understanding of the nature of them. Subsequently, the application of DNA framework and the directions of future research were discussed. Six future research directions were finally recommended, including life-cycle thinking, standard systems improvement, policies & regulations, awareness increase, healthy building examination, and multidisciplinary integration. This research differs from previous ones because it painted a panorama of previous healthy building research. Findings of this research contribute to reveal knowledge map of healthy buildings, guide researchers to fill existing knowledge gaps, provide a standardized platform for healthy building stakeholders, and promote high-quality development of healthy buildings.}
}
@article{TSIGKINOPOULOU2017518,
title = {Respectful Modeling: Addressing Uncertainty in Dynamic System Models for Molecular Biology},
journal = {Trends in Biotechnology},
volume = {35},
number = {6},
pages = {518-529},
year = {2017},
note = {Special Issue: Computation and Modeling},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2016.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167779916302311},
author = {Areti Tsigkinopoulou and Syed Murtuza Baker and Rainer Breitling},
abstract = {Although there is still some skepticism in the biological community regarding the value and significance of quantitative computational modeling, important steps are continually being taken to enhance its accessibility and predictive power. We view these developments as essential components of an emerging ‘respectful modeling’ framework which has two key aims: (i) respecting the models themselves and facilitating the reproduction and update of modeling results by other scientists, and (ii) respecting the predictions of the models and rigorously quantifying the confidence associated with the modeling results. This respectful attitude will guide the design of higher-quality models and facilitate the use of models in modern applications such as engineering and manipulating microbial metabolism by synthetic biology.}
}
@article{OSTLUND1985109,
title = {WATERLOPP V2/64: A highly parallel machine for numerical computation},
journal = {Computer Physics Communications},
volume = {37},
number = {1},
pages = {109-117},
year = {1985},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(85)90142-0},
url = {https://www.sciencedirect.com/science/article/pii/0010465585901420},
author = {Neil S. Ostlund},
abstract = {Current technological trends suggest that the high performance scientific machines of the future are very likely to consist of a large number (greater than 1024) of processors connected and communicating with each other in some as yet undetermined manner. Such an assembly of processors should behave as a single machine in obtaining numerical solutions to scientific problems. However, the appropriate way of organizing both the hardware and software of such an assembly of processors is an unsolved and active area of research. It is particularly important to minimize the organizational overhead of interprocessor comunication, global synchronization, and contention for shared resources if the performance of a large number (n) of processors is to be anything like the desirable n times the performance of a single processor. In many situations, adding a processor actually decreases the performance of the overall system since the extra organizational overhead is larger than the extra processing power added. The systolic loop architecture is a new multiple processor architecture which attemps at a solution to the problem of how to organize a large number of asynchronous processors into an effective computational system while minimizing the organizational overhead. This paper gives a brief overview of the basic systolic loop architecture, systolic loop algorithms for numerical computation, and a 64-processor implementation of the architecture, WATERLOOP V2/64, that is being used as a testbed for exploring the hardware, software, and algorithmic aspects of the architecture.}
}
@article{TUYSUZ2024107221,
title = {A novel decomposed Z-fuzzy TOPSIS method with functional and dysfunctional judgments: An application to transfer center location selection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {127},
pages = {107221},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107221},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623014057},
author = {Nurdan Tüysüz and Cengiz Kahraman},
keywords = {Decomposed fuzzy sets, Fuzzy MCDM, Reliability, TOPSIS, Z-Fuzzy numbers},
abstract = {Decomposed fuzzy sets (DFSs) are one of the latest extensions of intuitionistic fuzzy sets which are introduced to express vague and imprecise information to be used in multi-criteria decision-making. DFSs represent the human thinking structure in a multidirectional way, and they enable it through functional and dysfunctional judgments. However, DFSs cannot completely represent the entire human mindset as they are incapable of capturing reliability information, as it is in the other extensions, and this inability may cause wrong decisions to be given. To handle this problem, decomposed Z-fuzzy numbers, which are the integrated DFSs with reliability information provided by Z-fuzzy numbers, are introduced to model functional and dysfunctional judgments for taking the consistency of decision makers into account. Collecting judgments with both their fuzzy restrictions and fuzzy reliabilities from decision makers based on functional and dysfunctional questions provide more consistent and reliable judgments in the practice. Subsequently, a new decomposed Z-fuzzy linguistic scale and defuzzification formula are introduced to reach a final solution. Then, decomposed Z-fuzzy TOPSIS method is developed. Finally, we analyze the effect of the reliability parameter on the given decisions and present a comparative analysis with crisp TOPSIS method by an application of transfer center location selection for a private cargo company in Marmara Region of Turkey.}
}
@incollection{GRANJOU20161,
title = {1 - The Time Beast},
editor = {Céline Granjou},
booktitle = {Environmental Changes},
publisher = {Elsevier},
pages = {1-43},
year = {2016},
isbn = {978-1-78548-026-3},
doi = {https://doi.org/10.1016/B978-1-78548-026-3.50001-5},
url = {https://www.sciencedirect.com/science/article/pii/B9781785480263500015},
author = {Céline Granjou},
keywords = {Analogism, Anthropophagy, Doctrine of the Apocalypse, Environmental change, Environmental humanities, Evolution, Multi-species ethnography, Nature/society partition, Plate tectonics, Sociology},
abstract = {Abstract:
This chapter will give insights into the historical shaping of the very peculiar notion of a nature without any future. We will retrace some of its roots in the secularization of Christian apocalypse, Newtonian physics and Linnean classification – while at the same time, Cartesian, Kantian and Hegelian philosophies perceived humans as subjects of reason, emancipation and civilization. We will revisit the way that, in the 19th Century, the Darwinian theory of evolution and, more recently, the development of geophysics, both contributed in the thinking of nature itself as able to instigate and create new futures.}
}
@article{FENG2024117540,
title = {Large language models for biomolecular analysis: From methods to applications},
journal = {TrAC Trends in Analytical Chemistry},
volume = {171},
pages = {117540},
year = {2024},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2024.117540},
url = {https://www.sciencedirect.com/science/article/pii/S0165993624000220},
author = {Ruijun Feng and Chi Zhang and Yang Zhang},
keywords = {Large language model, Biomolecular analysis, Fine-tuning, Prompt engineering, Parameter-efficient fine-tuning, In-context learning, Protein structure analysis, Protein sequence generation, Gene sequence analysis, Molecular representation learning},
abstract = {Large language models (LLMs) are proving to be very useful in many fields, especially chemistry and biology, because of their amazing capabilities. Biomolecular data is often represented sequentially, much like textual data used to train LLMs. However, developing LLMs from scratch requires a substantial amount of data and computational resources, which may not be feasible for most researchers. A more workable solution to this problem is to change the inputs or parameters so that the previously trained general LLMs can pick up the specific knowledge needed for biomolecular analysis. These adaption strategies lower the amount of data and hardware needed, providing a more affordable option. This review provides the introduction of two popular LLM adaptation techniques: fine-tuning and prompt engineering, along with their uses in the analysis of molecules, proteins, and genes. A thorough overview of current common datasets and pre-trained models is also provided. This review outlines the possible advantages and difficulties of LLMs for biomolecular analysis, opening the door for chemists and biologists to effectively utilize LLMs in their future studies.}
}
@article{QAYYUM20231739,
title = {Flexible Global Aggregation and Dynamic Client Selection for Federated Learning in Internet of Vehicles},
journal = {Computers, Materials and Continua},
volume = {77},
number = {2},
pages = {1739-1757},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.043684},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823006549},
author = {Tariq Qayyum and Zouheir Trabelsi and Asadullah Tariq and Muhammad Ali and Kadhim Hayawi and Irfan {Ud Din}},
keywords = {IoT, Federated Learning, sensors, IoV, OMNeT++, edge computing},
abstract = {Federated Learning (FL) enables collaborative and privacy-preserving training of machine learning models within the Internet of Vehicles (IoV) realm. While FL effectively tackles privacy concerns, it also imposes significant resource requirements. In traditional FL, trained models are transmitted to a central server for global aggregation, typically in the cloud. This approach often leads to network congestion and bandwidth limitations when numerous devices communicate with the same server. The need for Flexible Global Aggregation and Dynamic Client Selection in FL for the IoV arises from the inherent characteristics of IoV environments. These include diverse and distributed data sources, varying data quality, and limited communication resources. By employing dynamic client selection, we can prioritize relevant and high-quality data sources, enhancing model accuracy. To address this issue, we propose an FL framework that selects global aggregation nodes dynamically rather than a single fixed aggregator. Flexible global aggregation ensures efficient utilization of limited network resources while accommodating the dynamic nature of IoV data sources. This approach optimizes both model performance and resource allocation, making FL in IoV more effective and adaptable. The selection of the global aggregation node is based on workload and communication speed considerations. Additionally, our framework overcomes the constraints associated with network, computational, and energy resources in the IoV environment by implementing a client selection algorithm that dynamically adjusts participants according to predefined parameters. Our approach surpasses Federated Averaging (FedAvg) and Hierarchical FL (HFL) regarding energy consumption, delay, and accuracy, yielding superior results.}
}
@incollection{GOMILA20121,
title = {1 - Introduction: Language as the Key Factor to Human Singularity},
editor = {Antoni Gomila},
booktitle = {Verbal Minds},
publisher = {Elsevier},
address = {London},
pages = {1-4},
year = {2012},
isbn = {978-0-12-385200-7},
doi = {https://doi.org/10.1016/B978-0-12-385200-7.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852007000011},
author = {Antoni Gomila},
keywords = {Cognitive architecture, verbal minds, cognitive control, flexibility, language},
abstract = {Publisher Summary
This chapter explains language as a distinctive human trait characterized by flexibility and creativity of human brains. Language is the sole symbol of communication and representation of individuality and sociality. The role of language on human thinking is to define the cultural and behavioral novelties of human thoughts. Lately, language is going through pendulum dynamics from past 30 years because the communicative approaches are becoming hegemonic. There has been a lot of new evidence to support the constitutive approach and its becoming mainstream, however, the modern critics of the cognitive view of language react in a paradoxical manner and do not support a cognitive role of language. This chapter aims at providing a defined role of language in human cognition to analyze the different ways, in which the relation between language and cognition has been conceived, to review the evidence amassed in recent years on this relationship, and to conclude multiple ways to conceive of the relationship at its best accounts for the facts.}
}
@article{KANSELAAR2001123,
title = {Computer supported collaborative learning Computer supported collaborative learning: cognitive and computational approaches: P. Dillenbourg (Ed.); Pergamon, Elsevier Science Ltd., Oxford, 1999, 246pp., ISBN 0-08-043073-2},
journal = {Teaching and Teacher Education},
volume = {17},
number = {1},
pages = {123-129},
year = {2001},
issn = {0742-051X},
doi = {https://doi.org/10.1016/S0742-051X(00)00042-1},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X00000421},
author = {Gellof Kanselaar and Gijsbert Erkens and Jos Jaspers and Hermi (Tabachneck-) Schijf}
}
@article{ASEMI2025106795,
title = {Improving EEG signal-based emotion recognition using a hybrid GWO-XGBoost feature selection method},
journal = {Biomedical Signal Processing and Control},
volume = {99},
pages = {106795},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106795},
url = {https://www.sciencedirect.com/science/article/pii/S174680942400853X},
author = {Hanie Asemi and Nacer Farajzadeh},
keywords = {Emotion recognition, Brain signals, EEG, Prediction, Feature selection, Machine learning},
abstract = {Emotion plays a crucial role in daily life, influencing cognitive functions such as language comprehension, decision-making, attention, and concentration. With the growing integration of computer systems into our everyday activities, it is essential to understand and detect emotional states accurately. Emotion detection through EEG signals allows direct assessment of the human’s internal state and is considered an important factor in the interaction between humans and external devices. In this paper, we introduce a novel feature selection algorithm proposed to improve the accuracy of emotion classification using EEG signals, aligned with decreasing the input dimension to reduce computations, making it more suitable for real-time applications. We performed two experiments utilizing the DEAP and the MAHNOB-HCI datasets. Various features were extracted and employed for emotion classification using SVM, KNN, and XGBoost classifiers. Initially, the highest accuracy for binary emotion classification in the DEAP dataset was achieved with statistical features and the XGBoost model, reaching 78.85% for arousal and 79.02% for valence. In the MAHNOB-HCI dataset, the highest accuracy with statistical features and the XGBoost model was 67.08% for arousal and 62.24% for valence. Subsequently, we applied the grey wolf optimization algorithm as a feature selection method, optimizing the cost function based on XGBoost accuracy. This approach significantly enhanced the classification performance. For the DEAP dataset, accuracy increased to 89.63% for arousal and 89.08% for valence using statistical features. For the MAHNOB-HCI dataset, accuracy improved to 84.94% for arousal and 82.29% for valence using statistical features.}
}
@article{KRELLENSTEIN1987155,
title = {A reply to ”parallel computation and the mind-body problem”},
journal = {Cognitive Science},
volume = {11},
number = {2},
pages = {155-157},
year = {1987},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(87)80003-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021387800034},
author = {Marc Krellenstein}
}
@incollection{DEBEUKELAER2018455,
title = {Chapter 21 - Relating movements in aesthetic spaces: Immersing, distancing, and remembering},
editor = {Julia F. Christensen and Antoni Gomila},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {237},
pages = {455-469},
year = {2018},
booktitle = {The Arts and The Brain},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2018.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0079612318300141},
author = {Sophie {De Beukelaer} and Ruben Azevedo and Manos Tsakiris},
keywords = {Aesthetic experience, Embodied simulation, Associative processing, Constructive memory, Aesthetic spaces},
abstract = {According to Aby Warburg, the aesthetic experience is informed by a pendulum-like movement of the observer's mind that allows him to immerse as well as to take distance from the artwork's composing elements. To account for Warburg's definition, we are proposing embodied simulation and associative processing as constitutive mechanisms of this pendulum-like movement within the aesthetic experience that enable the observer to relate to the displayed artistic material within aesthetic spaces. Furthermore, we suggest that associative processing elicits constructive memory processes that permit the development of a knowledge within which the objects of art become part of memory networks, potentially informing future ways of thinking, feeling, and behaving in real-world situations, as an individual or collectively.}
}
@article{AUCONI2020856,
title = {Computer-aided heuristics in orthodontics},
journal = {American Journal of Orthodontics and Dentofacial Orthopedics},
volume = {158},
number = {6},
pages = {856-867},
year = {2020},
issn = {0889-5406},
doi = {https://doi.org/10.1016/j.ajodo.2019.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0889540620304248},
author = {Pietro Auconi and James A. McNamara and Lorenzo Franchi},
abstract = {Introduction
During the decision-making process, physicians rely on heuristics that consist of simple, useful procedures for solving problems, intuitive shortcuts that produce reliable decisions based on limited information. In clinical situations characterized by a high degree of uncertainty such as those encountered in orthodontics, cognitive biases and judgment errors related to heuristics are not uncommon. This study aimed at promoting trust in the effective interface between the intuitive reasoning of the orthodontic practitioner and the computational heuristics emerging from simple statistical models.
Methods
We propose an integrative model based on the interaction between clinical reasoning and 2 computational tools, cluster analysis and fast-and-frugal trees, to extract a structured craniofacial representation of untreated subjects with Class III malocclusion and to forecast the worsening of the malocclusion over time.
Results
Cluster analysis of cephalometric values from 144 growing subjects with Class III malocclusion followed longitudinally (T1: mean age, 10.2 ± 1.9 years; T2: mean age, 13.8 ± 2.7 years) produced 3 morphologic subgroups with predominant sagittal, vertical, and slight maxillomandibular imbalances. Fast-and-frugal trees applied to different subgroups extracted heuristics that improved the prediction of key features associated with adverse craniofacial growth.
Conclusions
Provided that cephalometric values are placed in the appropriate framework, the matching between simple and fast computational approaches and clinical reasoning could help the intuitive logic, perception, and cognitive inferences of orthodontic practitioners on the outcome of patients affected by Class III disharmony, decreasing errors associated with flawed judgments and improving the accuracy of decision making.}
}
@article{DAEMS2019101110,
title = {Building communities. Presenting a model of community formation and organizational complexity in southwestern Anatolia},
journal = {Journal of Anthropological Archaeology},
volume = {56},
pages = {101110},
year = {2019},
issn = {0278-4165},
doi = {https://doi.org/10.1016/j.jaa.2019.101110},
url = {https://www.sciencedirect.com/science/article/pii/S027841651830237X},
author = {Dries Daems},
keywords = {Social complexity, Community formation, Sagalassos, Anatolian archaeology, Social interaction, Organizational complexity},
abstract = {In this paper, a model of community formation and organizational complexity is presented, focusing on the fundamental role of social interactions and information transmission for the development of complex social organisation. The model combines several approaches in complex systems thinking which has garnered increasing attention in archaeology. It is then outlined how this conceptual model can be applied in archaeology. In the absence of direct observations of constituent social interactions, archaeologists study the past through material remnants found in the archaeological record. People used their material surroundings to shape, structure and guide social interactions and practices in various ways. The presented framework shows how dynamics of social organisation and community formation can be inferred from these material remains. The model is applied on a case study of two communities, Sagalassos and Düzen Tepe, located in southwestern Anatolia during late Achaemenid to middle Hellenistic times (fifth to second centuries BCE). It is suggested that constituent interactions and practices can be linked to the markedly different forms of organizational structures and material surroundings attested in both communities. The case study illustrates how the presented model can help understand trajectories of socio-political structures and organizational complexity on a community level.}
}
@article{KARIM2024742,
title = {Repetitive Negative Thoughts and the Brain as a Resource-Limited Machine},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {9},
number = {8},
pages = {742-743},
year = {2024},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2024.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S2451902224001691},
author = {Helmet T. Karim}
}
@article{CASTILLO2018165,
title = {In search of missing time: A review of the study of time in leadership research},
journal = {The Leadership Quarterly},
volume = {29},
number = {1},
pages = {165-178},
year = {2018},
issn = {1048-9843},
doi = {https://doi.org/10.1016/j.leaqua.2017.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1048984317300632},
author = {Elizabeth A. Castillo and Mai P. Trinh},
keywords = {Leadership, Time, Process, Computational science, Agent-based model},
abstract = {Many studies describe leadership as a dynamic process. However, few examine the passage of time as a critical dimension of that dynamism. This article illuminates this knowledge gap by conducting a systematic review of empirical studies on temporal effects of leadership to identify if and how time has been considered as a factor. After synthesizing key findings from the review, the article discusses methodological implications. We propose that a computational science approach, particularly agent-based modeling, is a fruitful path for future leadership research. This article contributes to leadership scholarship by shedding light on a missing variable (time) and offering a novel way to investigate the temporal, dynamic, emergent, and recursive aspects of leadership. We demonstrate the usefulness of agent-based modeling with an example of leader-member exchange relationship development.}
}
@article{CHERNYSHOV20117408,
title = {System Identification Technique Application to Revealing Human-Operator Skills},
journal = {IFAC Proceedings Volumes},
volume = {44},
number = {1},
pages = {7408-7413},
year = {2011},
note = {18th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20110828-6-IT-1002.00077},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016447968},
author = {K.R. Chernyshov},
keywords = {Human factors and errors, Identification, Information correlation, Sampled data, Skills, Stochastic systems},
abstract = {Abstract
A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human-operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is utilized. Such an approach is based on involving the notion of consistency of measures of dependence of random variables. Within the approach, a set of the so called information correlations has been proposed to serve as a quantitative performance index of human-operator skills.}
}
@article{WANG2024104116,
title = {Revealing association rules within intricate ecosystems: A spatial co-location mining method based on Geo-Eco knowledge graph},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {133},
pages = {104116},
year = {2024},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104116},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224004709},
author = {Jinghan Wang and Guangyue Li and Tinghua Ai},
keywords = {Geo-eco knowledge graph, Spatial co-location pattern, Environmental similarity, Neo4j graph database},
abstract = {The analysis of association rules within ecosystems is crucial for monitoring, managing, and conserving natural resources. As widely adopted approaches for this task, geospatial methods involving spatial co-location pattern mining can reveal distribution rules and inherent associations among diverse geographical elements. Rooted in Tobler’s first law of geography, these methods focus on the impact of spatial proximity. However, apart from proximity, heterogeneity of environmental attributes such as elevation, temperature and precipitation are also essential for the formation of associations. For environmental co-location (Eco-location) pattern detection, we propose a method based on the Geo-Eco Knowledge Graph (GEKG) to mine multi-impact association rules. Firstly, we introduce the Adaptive Threshold (AT) to constrain the Delaunay triangular network, dynamically regulating adjacency relationships to generate geo-eco knowledge graph’s skeleton. For comprehensive ecosystem representation, various environmental attributes are integrated as semantic information into GEKG. In the reasoning of Eco-location patterns, we innovate beyond the traditional co-location paradigm by considering both spatial proximity and semantic similarity. Under the impact of various environmental information, sub-sets of geographically proximate entities are extracted to detect Eco-location patterns. For effective management and efficient computation, we utilize the Neo4j graph database to manage large-scale GEKG and mine Eco-location patterns with its graph search function. Experiments conducted on simulated and real-world ecological datasets show that, compared to existing techniques, our GEKG-based method can detect Eco-location patterns with greater accuracy and efficiency.}
}
@article{NAARANOJA2015611,
title = {Multi-ontology Sense Making – Decision Making of Project Core Team},
journal = {Procedia Manufacturing},
volume = {3},
pages = {611-617},
year = {2015},
note = {6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2015.07.280},
url = {https://www.sciencedirect.com/science/article/pii/S2351978915002814},
author = {Marja Naaranoja},
keywords = {Sense making, Decision making, Ontology, Project, Core team, Construction industry},
abstract = {In order to understand core team's management task this paper studies the landscape of the decision making of the construction project core team. This paper uses multi-ontology sense making framework developed by Snowden. The four described situation illustrate the use of this framework. Firstly, a project core team create a project plan –timetable and cost estimate, that is supposed to be followed (rules and order) when making investment decision. Secondly, a project core team uses the plan but since the plan cannot be followed due to an unexpected situation the team changes the plan by calculating an optimal solution. In other words the team uses heuristic thinking when they change the rule (heuristics and order). Thirdly, the design group guides the design process by rules to get information for designing new facilities (rules and un-order). Fourthly, there are situations when the stakeholders have different kind of opinions in crisis and team cannot follow the preset orderly way of working (heuristics and un-order).}
}
@article{AYERS201883,
title = {The axiomatic approach to chemical concepts},
journal = {Computational and Theoretical Chemistry},
volume = {1142},
pages = {83-87},
year = {2018},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2018.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X18304237},
author = {Paul W. Ayers and Stijn Fias and Farnaz Heidar-Zadeh},
abstract = {Many concepts that are central to chemical language and thought emerge from the wealth of chemists’ historical experience and cannot be precisely defined mathematically from the underlying physics. In such cases, it is useful to take an axiomatic approach: list the chemical, mathematical and computational properties that one desires for a concept to possess, and then find the rigorous (and, if possible, elegant) mathematical formulation of the concept that satisfies those desiderata. This mathematical formulation is most useful if it relies on fundamental quantities—quantum-mechanical observables, reduced density matrices, or the N-electron wavefunction—rather than method-dependent quantities (e.g., orbitals) that are not defined for some computational approaches to the molecular electronic structure problem. This ensures that the pursuit of chemical intuition does not lead one too far from the underlying physics. It also ensures that one can interpret the results of any computational method, even methods (e.g., quantum Monte Carlo) that make no reference to any molecular-orbital or valence-bond model.}
}
@article{NOUIOUA2023104,
title = {The quantum computer for accelerating image processing and strengthening the security of information systems},
journal = {Chinese Journal of Physics},
volume = {81},
pages = {104-124},
year = {2023},
issn = {0577-9073},
doi = {https://doi.org/10.1016/j.cjph.2022.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0577907322002763},
author = {Tarek Nouioua and Ahmed Hafid Belbachir},
keywords = {Quantum computer, Quantum physics, Quantum image processing, Quantum edge detection, RSA algorithm, Information security, Post-quantum-cryptography},
abstract = {Many researchers and laboratories have been involved for many years in the development of the quantum computer. In 2019, Google has announced that they have reached quantum supremacy with their quantum computer Sycamore using a 53 qubits processor. On November 2021, IBM also announced that they have built a quantum computer with the highest number of 127 qubits and revealed their ambitious goal of building a 1000 qubits processor by 2023. According to these two giants of the quantum computing field, such a machine can perform an astronomical quantity of calculations significantly faster than any other conventional computer. This technology could be a real revolution in many fields such as computing, artificial intelligence, medicine, chemistry, banking, and experimental techniques, …etc. Since this technology is still in its infancy in hardware and software, its progress may be slow. However, many working in the field predict that 2,000 to 5,000 quantum computers of a first generation will be operational by 2030, but quantum computers needed to deal with more complex problems may not exist until 2035 or beyond. In this paper, we will go over some of the basic aspects of a quantum computer, in particular the concept of the qubit or the quantum bit and the quantum computer itself. Then we will see how a quantum computer can effectively speed up the processing of large images, reduce the amount of memory needed for computation and storage and even, strengthen the security of information systems. Lastly, we will present and discuss a real hardware implementation of the well-known quantum edge detection, as well as a spy hunter simulation.}
}
@article{ANGIONE2015102,
title = {Analysis and design of molecular machines},
journal = {Theoretical Computer Science},
volume = {599},
pages = {102-117},
year = {2015},
note = {Advances in Computational Methods in Systems Biology},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2015.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S0304397515000663},
author = {C. Angione and J. Costanza and G. Carapezza and P. Lió and G. Nicosia},
keywords = {Pareto optimality,  modelling, Turing machine, Molecular machine, Biological complexity, Petri nets, Register machines, Von Neumann architectures, Trade-off genetic strategies, Flux-balance analysis},
abstract = {Biologically inspired computation has been recently used with mathematical models towards the design of new synthetic organisms. In this work, we use Pareto optimality to optimize these organisms in a multi-objective fashion. We infer the best knockout strategies to perform specific tasks in bacteria, which involve concurrent maximization/minimization of multiple functions (codomain) and optimization of several decision variables (domain). Furthermore, we propose and exploit a mapping between the metabolism and a register machine. We show that optimized bacteria have computational capability and act as molecular Turing machines programmed using a Pareto optimal solution. Finally, we investigate communication between bacteria as a means to evaluate their computational capability. We report that the density and gradient of the Pareto curve are useful tools to compare models and understand their structure, while modelling organisms as computers proves useful to carry out computation using biological machines with specific input–output conditions, as well as to estimate the bacterial computational effort for specific tasks.}
}
@article{1989N1,
title = {Newsletter on computational and applied mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {25},
number = {2},
pages = {N1-N18},
year = {1989},
issn = {0377-0427},
doi = {https://doi.org/10.1016/0377-0427(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0377042789900502}
}
@article{OLTEANU20161,
title = {Opportunity to communicate: The coordination between focused and discerned aspects of the object of learning},
journal = {The Journal of Mathematical Behavior},
volume = {44},
pages = {1-12},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2016.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S073231231630116X},
author = {Lucian Olteanu},
keywords = {Algebra, Communication, Experience, Critical aspects, Opportunity to communicate},
abstract = {There are extensive concerns pertaining to the idea that students do not develop sufficient communication abilities in algebra and in mathematics more generally. This problem is at least partially related to their algebraic thinking. Although teaching should give students the opportunity to develop their ability to communicate, there are limited research insights as to why some forms of communication work better than others, and how and why instruction influences such communication. Two case studies are reported on in this article. The analysis of the opportunity to communicate was grounded in variation theory. Differences between focused aspects and discerned aspects of the object of learning are described. The results show that the coordination between the aspects focused on by the teacher and discerned by the students provides students with the opportunity to successfully communicate the content in algebra. In addition, the structure of the lesson influences the opportunity to communicate aspects of the content.}
}
@article{BOWLER2021104535,
title = {Children perform extensive information gathering when it is not costly},
journal = {Cognition},
volume = {208},
pages = {104535},
year = {2021},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2020.104535},
url = {https://www.sciencedirect.com/science/article/pii/S0010027720303541},
author = {Aislinn Bowler and Johanna Habicht and Madeleine E. Moses-Payne and Niko Steinbeis and Michael Moutoussis and Tobias U. Hauser},
keywords = {Cognitive development, Information gathering, Computational modelling},
abstract = {Humans often face decisions where little is known about the choice options. Gathering information prior to making a choice is an important strategy to improve decision making under uncertainty. This is of particular importance during childhood and adolescence, when knowledge about the world is still limited. To examine how much information youths gather, we asked 107 children (8–9 years, N = 30), early (12–13 years, N = 41) and late adolescents (16–17 years, N = 36) to perform an information sampling task. We find that children gather significantly more information before making a decision compared to adolescents, but only if it does not come with explicit costs. Using computational modelling, we find that this is because children have reduced subjective costs for gathering information. Our findings thus demonstrate how children overcome their limited knowledge and neurocognitive constraints by deploying excessive information gathering, a developmental feature that could inform aberrant information gathering in psychiatric disorders.}
}
@article{HEMMATIAN202469,
title = {The utilitarian brain: Moving beyond the Free Energy Principle},
journal = {Cortex},
volume = {170},
pages = {69-79},
year = {2024},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2023.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010945223003076},
author = {Babak Hemmatian and Lav R. Varshney and Frederick Pi and Aron K. Barbey},
keywords = {Free Energy Principle, Subjective utility, Extended cognition, Decision-making, Cognitive neuroscience, Bayesian Brain Hypothesis},
abstract = {The Free Energy Principle (FEP) is a normative computational framework for iterative reduction of prediction error and uncertainty through perception–intervention cycles that has been presented as a potential unifying theory of all brain functions (Friston, 2006). Any theory hoping to unify the brain sciences must be able to explain the mechanisms of decision-making, an important cognitive faculty, without the addition of independent, irreducible notions. This challenge has been accepted by several proponents of the FEP (Friston, 2010; Gershman, 2019). We evaluate attempts to reduce decision-making to the FEP, using Lucas' (2005) meta-theory of the brain's contextual constraints as a guidepost. We find reductive variants of the FEP for decision-making unable to explain behavior in certain types of diagnostic, predictive, and multi-armed bandit tasks. We trace the shortcomings to the core theory's lack of an adequate notion of subjective preference or “utility”, a concept central to decision-making and grounded in the brain's biological reality. We argue that any attempts to fully reduce utility to the FEP would require unrealistic assumptions, making the principle an unlikely candidate for unifying brain science. We suggest that researchers instead attempt to identify contexts in which either informational or independent reward constraints predominate, delimiting the FEP's area of applicability. To encourage this type of research, we propose a two-factor formal framework that can subsume any FEP model and allows experimenters to compare the contributions of informational versus reward constraints to behavior.}
}
@article{GHABOUSSI201275,
title = {Unifying Principles for Sudden Transitions in All Systems},
journal = {Procedia Computer Science},
volume = {8},
pages = {75-80},
year = {2012},
note = {Conference on Systems Engineering Research},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912000178},
author = {Jamshid Ghaboussi},
keywords = {Complex systems, Sudden transitions, System properties, Tipping points},
abstract = {All physical, natural, biological and socio-economic systems – also referred to as complex systems - have system-level properties that result from the interactions between their components. In most cases it is not possible to determine the complete system-level properties with the current state of our knowledge. Where there are system-level properties, the uncoupled form of those properties is the eigen-system consisting of system eigenvalues and eigenfunctions, even though at the present we are not able to determine them through modelling or observation. All systems operate in equilibrium states; small perturbations cause small changes. While these systems normally undergo gradual changes in their system-level properties, they can also undergo sudden transitions to new equilibrium states. New insights into these important transitions are proposed in this paper. In some mechanical systems transition occur when the smallest system eigenvalue goes to zero. It is proposed that the same principles apply to all systems. Transitions in all systems occur when at least one system eigenvalue goes to zero. Generalization of these principles to all systems will encourage new ways of thinking about systems and will suggest new research directions in studying these important major transitions, potentially leading to reliable methods for predicting their onset.}
}
@article{YEE1991249,
title = {Dynamical approach study of spurious steady-state numerical solutions of nonlinear differential equations. I. The dynamics of time discretization and its implications for algorithm development in computational fluid dynamics},
journal = {Journal of Computational Physics},
volume = {97},
number = {2},
pages = {249-310},
year = {1991},
issn = {0021-9991},
doi = {https://doi.org/10.1016/0021-9991(91)90001-2},
url = {https://www.sciencedirect.com/science/article/pii/0021999191900012},
author = {H.C Yee and P.K Sweby and D.F Griffiths},
abstract = {The goal of this paper is to utilize the theory of nonlinear dynamics approach to investigate the possible sources of errors and slow convergence and nonconvergence of steady-state numerical solutions when using the time-dependent approach for nonlinear hyperbolic and parabolic partial differential equations terms. This interdisciplinary research belongs to a subset of a new field of study in numerical analysis sometimes referred to as “ the dynamics of numerics and the numerics of dynamics.” At the present time, this new interdisciplinary topic is still the property of an isolated discipline with all too little effort spent in pointing out an underlying generality that could make it adaptable to diverse fields of applications. This is the first of a series of research papers under the same topic. Our hope is to reach researchers in the fields of computational fluid dynamics (CFD) and, in particular, hypersonic and combustion related CFD. By simple examples (in which the exact solutions of the governing equations are known), the application of the apparently straightforward numerical technique to genuinely nonlinear problems can be shown to lead to incorrect or misleading results. One striking phenomenon is that with the same initial data, the continuum and its discretized counterpart can asymptotically approach different stable solutions. This behavior is especially important for employing a time-dependent approach to the steady state since the initial data are usually not known and a freestream condition or an intelligent guess for the initial conditions is often used. With the unique property of the different dependence of the solution on initial data for the partial differential equation and the discretized counterpart, it is not easy to delineate the true physics from numerical artifacts when numerical methods are the sole source of solution procedure for the continuum. Part I concentrates on the dynamical behavior of time discretization for scalar nonlinear ordinary differential equations in order to motivate this new yet unconventional approach to algorithm development in CFD and to serve as an introduction for parts 11 and III of the same series of research papers.}
}
@incollection{KERN20241,
title = {Chapter 1 - Introduction and overview},
editor = {Eugene Barton Kern and Oren Friedman},
booktitle = {Empty Nose Syndrome},
publisher = {Elsevier},
pages = {1-31},
year = {2024},
isbn = {978-0-443-10715-3},
doi = {https://doi.org/10.1016/B978-0-443-10715-3.00001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443107153000019},
author = {Eugene Barton Kern and Oren Friedman},
keywords = {Empty nose syndrome (ENS), American Rhinologic Society (ARS), secondary atrophic rhinitis, “approximate temporary truth,” on-urgical urbinate eductive djunctive rocedure (n-sTRAP), evidence-based medicine (EBM), randomized controlled trials (RCTs), total inferior turbinectomy, nasal crime, conservative submucosal inferior turbinoplasty, authorized research, clustered regularly interspaced short palindromic repeats (CRISPER), “genetic engineering,” solidated tandards f eporting rials (CONSORT statement), propensity score matching (PSM), clinical practice guidelines (CPGs), conflicts of interest (COI), computational fluid dynamics (CFD), medical journals, peer reviewers, nasal cripple, nasal physiology, “organ of the nose,” primary functions of the nose, nasal cycle, and the autonomic nervous system},
abstract = {This chapter presents the introduction and overview of the empty nose syndrome (ENS), highlighting subjects we will consider in detail with corresponding citations from the literature (included in the broad bibliography of 376 references), besides providing complete commentary regarding the fundamental features of ENS along with a review of pertinent nasal physiology, a comprehensive differential diagnosis and an analysis of the various medical, surgical, and psychological treatment options for these desperately distraught patients, some of whom have committed suicide because of their horrific torment. ENS was initially recognized and formally presented to the profession by the Mayo Clinic team in 1994. With over a quarter of a century experience treating hundreds of patients devastated by ENS, we reexamined the existing thinking concerning the etiology, differential diagnosis, diagnosis, treatment, and ultimately preventing this crippling disorder.}
}
@article{BAYDOUN2021100026,
title = {Auto-contouring FDG-PET/MR images for cervical cancer radiation therapy: An intelligent sequential approach using focally trained, shallow U-Nets},
journal = {Intelligence-Based Medicine},
volume = {5},
pages = {100026},
year = {2021},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2021.100026},
url = {https://www.sciencedirect.com/science/article/pii/S2666521221000028},
author = {Atallah Baydoun and Ke Xu and Latoya A. Bethell and Feifei Zhou and Jin Uk Heo and Kaifa Zhao and Elisha T. Fredman and Rodney J. Ellis and Pengjiang Qian and Raymond F. Muzic and Bryan J. Traughber},
keywords = {Cervical cancer, Deep learning, Image segmentation, PET/MR Based radiation therapy, U-net},
abstract = {Background
Manual contouring for radiation therapy planning remains the most laborious and time consuming part in the radiation therapy workflow. Particularly for cervical cancer, this task is complicated by the complex female pelvic anatomy and the concomitant dependence on 18F-labeled Fluorodeoxyglucose (FDG) positron emission tomography (PET) and magnetic resonance (MR) images. Using deep learning, we propose a new auto-contouring method for FDG-PET/MR based cervical cancer radiation therapy by combining the high level anatomical topography and radiological properties, to the low-level pixel wise deep-learning based semantic segmentation.
Materials/methods
The proposed method: 1) takes advantage of PET data and left/right anatomical symmetry, creating sub-volumes that are centered on the structures to be contoured. 2) Uses a 3D shallow U-Net (sU-Net) model with an encoder depth of 2.3) Applies the successive training of 3 consecutive sU-Nets in a feed forward strategy. 4) Employs, instead of the usual generalized dice loss function (GDL), a patch dice loss function (PDL) that takes into account the Dice similarity index (DSI) at the level of each training patch. Experimental analysis was conducted on a set of 13 PET/MR images was using a leave-one-out strategy.
Results
Despite the limited data availability, 5 anatomical structures - the gross tumor volume, bladder, anorectum, and bilateral femurs - were accurately (DSI ​= ​0.78), rapidly (1.9 ​s/structure), and automatically delineated by our algorithm. Overall, PDL achieved a better performance than GDL and DSI was higher for organs at risk (OARs) with solid tissue (e.g. femurs) than for OARs with air-filled soft tissues (e.g. anorectum).
Conclusion
The presented workflow successfully addresses the challenge of auto-contouring in FDG-PET/MR based cervical cancer. It is expected to expedite the cervical cancer radiation therapy workflow in both, conventional and adaptive radiation therapy settings.}
}
@article{SALIS202320,
title = {An Edge-Cloud based Reference Architecture to support cognitive solutions in Process Industry},
journal = {Procedia Computer Science},
volume = {217},
pages = {20-30},
year = {2023},
note = {4th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.198},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922022761},
author = {Antonio Salis and Angelo Marguglio and Gabriele {De Luca} and Silvia Razzetti and Walter Quadrini and Sergio Gusmeroli},
keywords = {Industry 4.0, process industry, smart manufacturing, reference architecture, cloud, edge computing, cognitive computing, artificial intelligence, big data analytics},
abstract = {Process Industry is one of the leading sectors of the world economy, characterized however by intense environmental impact, and very high-energy consumption. Despite a traditional low innovation pace in PI, in the recent years a strong push at worldwide level towards the dual objective of improving the efficiency of plants and the quality of products, significantly reducing the consumption of electricity and CO2 emissions has taken momentum. Digital Technologies (namely Smart Embedded Systems, IoT, Data, AI and Edge-to-Cloud Technologies) are enabling drivers for a Twin Digital-Green Transition, as well as foundations for human centric, safe, comfortable and inclusive workplaces. Currently, digital sensors in plants produce a large amount of data, which in most cases constitutes just a potential and not a real value for Process Industry, often locked-in in close proprietary systems and seldomly exploited. Digital technologies, with process modelling-simulation via digital twins, can build a bridge between the physical and the virtual worlds, bringing innovation with great efficiency and drastic reduction of waste. In accordance with the guidelines of Industrie 4.0 this work proposes a modular and scalable Reference Architecture, based on open source software, which can be implemented both in brownfield and greenfield scenarios. The ability to distribute processing between the edge, where the data have been created, and the cloud, where the greatest computational resources are available, facilitates the development of integrated digital solutions with cognitive capabilities. The reference architecture is being validated in the three pilot plants, paving the way to the development of integrated planning solutions, with scheduling and control of the plants, optimizing the efficiency and reliability of the supply chain, and balancing energy efficiency.}
}
@article{OBIEKE2020373,
title = {Supporting Design Problem-exploring with Emergent Technologies},
journal = {Procedia CIRP},
volume = {91},
pages = {373-381},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.189},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308362},
author = {Chijioke Obieke and Jelena Milisavljevic-Syed and Ji Han},
keywords = {Creativity, Design Process, Industry 4.0, Problem-exploring},
abstract = {The goal in this study is to highlight the value of using emergent technologies to support human effort in identifying creative design problems. First, we explore the relationship between design and creativity - a popular concept and an important requirement in engineering design process. A search is conducted across repositories. This includes search in Google, Google Scholar and Google Books databases in addition to others. Findings show that the extent to which the design process requires creativity is somewhat obscure and not generally perceptible. We observe that creativity consists of two aspects: problem-solving and problem-exploring. We also observe that creativity drives the design process, not by the way of problem-solving but by the way of problem-exploring. However, currently, focus is on problem-solving than the equally important problem-exploring. For every 135 studies on problem-solving, there is only one on problem-exploring. Study on problem-exploring is limited. We research further and identify some determinants of the neglect in problem-exploring in design. These determinants are lack of motivation, significant level of difficulty and the presence of many problems yet unsolved. Using the X-Design Process model and Problem-dependent Solution model we show the importance and benefits of problem-exploring in design and why it deserves attention. Consequently, we illustrate the use of emergent technologies to support problem-exploring in design and give reasons why this is possible in Industry 4.0. These technologies include data mining, natural language processing, machine learning, duplication recognition, and so on. We indicate that these technologies will only play subordinate role to humans towards inspiring problem-exploring in design. Also, we state that a precondition to applying these technologies is a study of the human problem-exploring cognition process for subsequent simulation. Success in computational problem-exploring would lead to breakthroughs in global problem-exploring and trigger more creative solutions in coming years.}
}
@article{HONG2015671,
title = {Free will: A case study in reconciling phenomenological philosophy with reductionist sciences},
journal = {Progress in Biophysics and Molecular Biology},
volume = {119},
number = {3},
pages = {671-727},
year = {2015},
note = {Integral Biomathics: Life Sciences, Mathematics, and Phenomenological Philosophy},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2015.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0079610715001212},
author = {Felix T. Hong},
keywords = {Free will, Determinism, Quantum indeterminacy, Downward causation, Naturalizing phenomenology, Visual thinking},
abstract = {Phenomenology aspires to philosophical analysis of humans' subjective experience while it strives to avoid pitfalls of subjectivity. The first step towards naturalizing phenomenology — making phenomenology scientific — is to reconcile phenomenology with modern physics, on the one hand, and with modern cellular and molecular neuroscience, on the other hand. In this paper, free will is chosen for a case study to demonstrate the feasibility. Special attention is paid to maintain analysis with mathematical precision, if possible, and to evade the inherent deceptive power of natural language. Laplace's determinism is re-evaluated along with the concept of microscopic reversibility. A simple and transparent version of proof demonstrates that microscopic reversibility is irreconcilably incompatible with macroscopic irreversibility, contrary to Boltzmann's claim. But the verdict also exalts Boltzmann's statistical mechanics to the new height of a genuine paradigm shift, thus cutting the umbilical cord linking it to Newtonian mechanics. Laplace's absolute determinism must then be replaced with a weaker form of causality called quasi-determinism. Biological indeterminism is also affirmed with numerous lines of evidence. The strongest evidence is furnished by ion channel fluctuations, which obey an indeterministic stochastic phenomenological law. Furthermore, quantum indeterminacy is shown to be relevant in biology, contrary to the opinion of Erwin Schrödinger. In reconciling phenomenology of free will with modern sciences, three issues — alternativism, intelligibility and origination — of free will must be accounted for. Alternativism and intelligibility can readily be accounted for by quasi-determinism. In order to account for origination of free will, the concept of downward causation must be invoked. However, unlike what is commonly believed, there is no evidence that downward causation can influence, shield off, or overpower low-level physical forces already known to physicists. Quasi-determinism offers an escape route: The possibility that downward causation arising from hierarchical organization of biological structures can modify dispersions of physical laws remains open. Empirical evidence in support of downward causation is scanty but nevertheless exists. Still, origination of free will must be considered an unsolved problem at present. It is demonstrated that objectivity does not guarantee scientific rigor in the study of complex phenomena, such as human creativity. In its replacement, universality and overall consistency between a theory and empirical evidence must be maintained. Visual thinking is proposed as a reasoning tool to ensure universality and overall consistency through inference to the best explanation.}
}
@article{JADHAV2022127935,
title = {Scale-up of the bioelectrochemical system: Strategic perspectives and normalization of performance indices},
journal = {Bioresource Technology},
volume = {363},
pages = {127935},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2022.127935},
url = {https://www.sciencedirect.com/science/article/pii/S0960852422012688},
author = {Dipak A. Jadhav and Ashvini D. Chendake and Vandana Vinayak and Abdulaziz Atabani and Mohammad {Ali Abdelkareem} and Kyu-Jung Chae},
keywords = {Energy balance, Microbial electrochemical technology, Net energy recovery, Normalization of performance, Resource recovery, Techno-economic feasibility},
abstract = {Electrochemists and ecological engineers find environmental bioelectrochemistry appealing; however, there is a big gap between expectations and actual progress in bioelectrochemical system (BES). Implementing such technology opens new opportunities for novel electrochemical reactions for resource recovery and effective wastewater treatment. Loopholes of BES exist in its scaling-up applications, and numerous attempts toward practical applications (200, 1000, and 1500 L) are key successive indicators toward its commercialization. This review emphasized the critical rethinking of standardization of performance indices i.e. current generation (A/m2), net energy recovery (kWh/kg·COD), product/resource yield (mM), and economic feasibility ($/kWh) to make fair comparison with the existing treatment system. Therefore, directional perspectives, including modularity, energy-cost balance, energy and resource recovery, have been proposed for the sustainable market of BES. The current state of the art and up-gradation in resource recovery and contaminant removal warrants a systematic rethinking of functional worth and niches of BES for practical applications.}
}
@article{CHU2023106290,
title = {A data-driven meta-learning recommendation model for multi-mode resource constrained project scheduling problem},
journal = {Computers & Operations Research},
volume = {157},
pages = {106290},
year = {2023},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2023.106290},
url = {https://www.sciencedirect.com/science/article/pii/S0305054823001545},
author = {Xianghua Chu and Shuxiang Li and Fei Gao and Can Cui and Forest Pfeiffer and Jianshuang Cui},
keywords = {Data-driven decision making, Meta-learning, Feature extraction, Meta-heuristics},
abstract = {Meta-heuristics widely proposed in addressing multi-mode resource constrained project scheduling problem (MRCPSP) are problem-dependent. This paper first proposes an adaptive data-driven meta-learning Meta-heuristic Recommendation Model (MRM) to solve MRCPSP intelligently and efficiently. By learning the association between problem meta-features and algorithm performance, MRM can identify the most appropriate algorithm for different MRCPSPs. Multiclass Support Vector Machine (MCSVM) are integrated to train the classifiers for predicting the performance of the candidate meta-heuristics. To validate the proposed MRM, the performance is evaluated and compared in terms of accuracy, precision, sensitivity, and comprehensive evaluation index. In the experiments of 4 scenarios with 2 strategies, the average optimization and prediction accuracies are higher than 90% without increase in computational complexity. Comprehensive experiments and numerical results demonstrate the outperforming performance of the proposed MRM across various MRCPSP.}
}
@incollection{TVERSKY197817,
title = {2 - Judgment under Uncertainty: Heuristics and Biases: Biases in judgments reveal some heuristics of thinking under uncertainty},
editor = {PETER DIAMOND and MICHAEL ROTHSCHILD},
booktitle = {Uncertainty in Economics},
publisher = {Academic Press},
pages = {17-34},
year = {1978},
isbn = {978-0-12-214850-7},
doi = {https://doi.org/10.1016/B978-0-12-214850-7.50008-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780122148507500085},
author = {Amos Tversky and Daniel Kahneman},
abstract = {Publisher Summary
Many decisions are based on beliefs concerning the likelihood of uncertain events such as the outcome of an election, the guilt of a defendant, or the future value of the dollar. Occasionally, beliefs concerning uncertain events are expressed in numerical form as odds or subjective probabilities. In general, the heuristics are quite useful, but sometimes they lead to severe and systematic errors. The subjective assessment of probability resembles the subjective assessment of physical quantities such as distance or size. These judgments are all based on data of limited validity, which are processed according to heuristic rules. However, the reliance on this rule leads to systematic errors in the estimation of distance. This chapter describes three heuristics that are employed in making judgments under uncertainty. The first is representativeness, which is usually employed when people are asked to judge the probability that an object or event belongs to a class or event. The second is the availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development, and the third is adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available.}
}
@incollection{MILLER2020205,
title = {Chapter 10 - AI, autonomous machines and human awareness: Towards shared machine-human contexts in medicine},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {205-220},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000109},
author = {D. Douglas Miller and Elena A. Wood},
keywords = {Medicine, Health care, Artificial intelligence, Medical education, Applications, Challenges},
abstract = {Medical curricula trend to integrate clinical skills training and to create efficiencies in preclinical medical sciences, but the rapid emergence big data-intensive health care has led to initiating collaborations among data scientists, computer engineers, and medical educators that might generate novel educational high-technology platforms and innovative AI practice applications. The preprocessing of big data improves neural network feature recognition, improving the speed and accuracy of AI diagnostics and permitting chronic disease predictions. Applications of generative adversarial networks to create virtual patient phenotypes and image sets exposes medical learners to endless illness presentations, improving system-1 critical thinking for differential diagnosis development. AI offers great potential for education data managers working in support of medical educators and learners. These opportunities to build a shared context, in keeping with these themes of this book, include emerging data-driven AI applications for medical education and provider training include individual aptitude-based career advising, early identification of learners with academic difficulties, highly focused e-tutoring interventions, and natural language processing of standardized exam questions.}
}
@article{ZHAO2023100521,
title = {Toward parallel intelligence: An interdisciplinary solution for complex systems},
journal = {The Innovation},
volume = {4},
number = {6},
pages = {100521},
year = {2023},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2023.100521},
url = {https://www.sciencedirect.com/science/article/pii/S2666675823001492},
author = {Yong Zhao and Zhengqiu Zhu and Bin Chen and Sihang Qiu and Jincai Huang and Xin Lu and Weiyi Yang and Chuan Ai and Kuihua Huang and Cheng He and Yucheng Jin and Zhong Liu and Fei-Yue Wang},
abstract = {The growing complexity of real-world systems necessitates interdisciplinary solutions to confront myriad challenges in modeling, analysis, management, and control. To meet these demands, the parallel systems method rooted in the artificial systems, computational experiments, and parallel execution (ACP) approach has been developed. The method cultivates a cycle termed parallel intelligence, which iteratively creates data, acquires knowledge, and refines the actual system. Over the past two decades, the parallel systems method has continuously woven advanced knowledge and technologies from various disciplines, offering versatile interdisciplinary solutions for complex systems across diverse fields. This review explores the origins and fundamental concepts of the parallel systems method, showcasing its accomplishments as a diverse array of parallel technologies and applications while also prognosticating potential challenges. We posit that this method will considerably augment sustainable development while enhancing interdisciplinary communication and cooperation.}
}
@article{PRASAD2023104,
title = {Irrigation development under uncertainty: A call for adaptive investment pathways},
journal = {Environmental Science & Policy},
volume = {140},
pages = {104-110},
year = {2023},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122003653},
author = {Pooja Prasad and Annelieke Duker and Charlotte {de Fraiture} and Pieter {van der Zaag}},
keywords = {Adaptation pathways, Irrigation, Investments, Uncertainty, Development, Sub-Saharan Africa},
abstract = {There is an urgent need in sub-Saharan Africa (SSA) to enhance irrigation access to meet the challenges of growing population and climate risk. To achieve this, big investments are currently planned in large irrigation infrastructure. We believe there is danger in following this conventional approach, which requires big lumpsum investments, locking large capital into projects that do not adapt to deep uncertainties from climatic or socio-political factors. Instead, in this Perspective article, we propose an alternate “adaptive investment pathways” (AdIP) approach for planning step-wise investments towards desired objectives, implemented progressively depending on how the future unfolds, in order to gain flexibility. AdIP extends the adaptation pathways concept, which refers to a sequence of actions to be taken in response to a changing reality, and applies it to the context of development under uncertainty. Monitoring and learning is at the heart of this approach, which ensures that the plan adapts as new knowledge becomes available. Thus, AdIP internalizes risk and reduces chances of failures. For financial institutions backing development projects, following a pathway of smaller de-centralized investments lowers risk and incorporates a learning approach that allows re-thinking and adapting along the path. We illustrate the AdIP approach using the case of ephemeral sand river based small-scale irrigation in the drylands of SSA. We conclude that in face of deep uncertainties, the path to successful irrigation development in SSA requires a shift from making few large upfront investments in large-scale projects to making large numbers of smaller investments that assure flexibility.}
}
@article{WU2020242,
title = {Mentalizing during social InterAction: A four component model},
journal = {Cortex},
volume = {126},
pages = {242-252},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2019.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0010945220300277},
author = {Haiyan Wu and Xun Liu and Cindy C. Hagan and Dean Mobbs},
keywords = {Metacognition, Mentalizing, Vicarious mentalizing, Co-mentalizing, Social inference},
abstract = {Mentalizing, conventionally defined as the process in which we infer the inner thoughts and intentions of others, is a fundamental component of human social cognition. Yet its role, and the nuanced layers involved, in real world social interaction are rarely discussed. To account for this lack of theory, we propose the interactive mentalizing theory (IMT) -to emphasize the role of metacognition in different mentalizing components. We discuss the connection between mentalizing, metacognition, and social interaction in the context of four elements of mentalizing: (i) Metacognition–inference of our own thought processes and social cognitions and which is central to all other components of mentalizing including: (ii) first-order mentalizing–inferring the thoughts and intentions of an agent's mind; (iii) personal second-order mentalizing–inference of other's mentalizing of one's own mind; (iv) Collective mentalizing: which takes at least two forms (a) vicarious mentalizing: adopting another's mentalizing of an agent (i.e., what we think others think of an agent) and (b) co-mentalizing: mentalizing about an agent in conjunction with others' mentalizing of that agent (i.e., conforming to others beliefs about another agent's internal states). The weights of these four elements is determined by metacognitive insight and confidence in one's own or another's mentalizing ability, yielding a dynamic interaction between these circuits. To advance our knowledge on mentalizing during live social interaction, we identify how these subprocesses can be organized by different target agents and facilitated by combining computational modeling and interactive brain approaches.}
}
@incollection{MCCALL20231025,
title = {Chapter 57 - Advances in ethics for the neuroscience agenda∗},
editor = {Michael J. Zigmond and Clayton A. Wiley and Marie-Francoise Chesselet},
booktitle = {Neurobiology of Brain Disorders (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {1025-1045},
year = {2023},
isbn = {978-0-323-85654-6},
doi = {https://doi.org/10.1016/B978-0-323-85654-6.00053-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856546000538},
author = {Iris Coates McCall and Veljko Dubljević},
keywords = {Animal models, Biomedical science, Data sharing, Ethics, Health, Incidental finding, Neuroscience, Public policy, Science communication},
abstract = {Critical thinking about ethics in neuroscience can be a powerful force in enabling research and translating results meaningfully for society. In this chapter, we strive to give those new to neuroscience investigation, as well as more experienced investigators, an introduction to the field of neuroethics such that they may begin to incorporate it into their future work from its very inception. We begin with an overview of the regulatory and oversight mechanisms currently in place that guide the ethical conduct of neuroscience research, followed by an introduction to four of the most salient neuroethics topics relevant to neuroscience research—research with animals, data sharing, incidental findings, and neuroscience communication. First, we discuss how upfront consideration of the societal implications of advances in neuroscience can shape the use of animal models. We situate ethical thinking in this era of big science and big data, reflecting on strategies for sharing databases while protecting contributors and users. Next, we highlight how collaboration among neuroscientists, ethicists, and others can produce positive measures to resolve the problem of incidental discoveries in brain imaging research, as one example of debates on incidental findings more broadly. Third, we discuss the importance of effective and responsible communication of neuroscience research and information. Finally, the mandate of neuroscience research as public service and ethical imperative is addressed by describing opportunities for neuroscientists to engage with societal issues emerging from their research and how this deepens the discourse and adds value to the research enterprise.}
}
@article{THOMPSON2013256,
title = {The role of answer fluency and perceptual fluency in the monitoring and control of reasoning: Reply to Alter, Oppenheimer, and Epley (2013)},
journal = {Cognition},
volume = {128},
number = {2},
pages = {256-258},
year = {2013},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2013.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0010027713000553},
author = {Valerie A. Thompson and Rakefet Ackerman and Yael Sidi and Linden J. Ball and Gordon Pennycook and Jamie A. {Prowse Turner}},
keywords = {Perceptual fluency, Answer fluency, Dual process theories, Metacognition, Intuition, Analytic thinking},
abstract = {In this reply, we provide an analysis of Alter et al. (2013) response to our earlier paper (Thompson et al., 2013). In that paper, we reported difficulty in replicating Alter, Oppenheimer, Epley, and Eyre’s (2007) main finding, namely that a sense of disfluency produced by making stimuli difficult to perceive, increased accuracy on a variety of reasoning tasks. Alter, Oppenheimer, and Epley (2013) argue that we misunderstood the meaning of accuracy on these tasks, a claim that we reject. We argue and provide evidence that the tasks were not too difficult for our populations (such that no amount of “metacognitive unease” would promote correct responding) and point out that in many cases performance on our tasks was well above chance or on a par with Alter et al.’s (2007) participants. Finally, we reiterate our claim that the distinction between answer fluency (the ease with which an answer comes to mind) and perceptual fluency (the ease with which a problem can be read) is genuine, and argue that Thompson et al. (2013) provided evidence that these are distinct factors that have different downstream effects on cognitive processes.}
}
@article{TANTILLO2021n/a,
title = {Dynamic effects on organic reactivity—Pathways to (and from) discomfort},
journal = {Journal of Physical Organic Chemistry},
volume = {34},
number = {6},
pages = {n/a},
year = {2021},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4202},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022006889},
author = {Dean J. Tantillo},
keywords = {bifurcation, dynamics, entropy},
abstract = {Recent computational studies highlighting the importance of accounting for dynamic effects on organic reactivity are discussed, accompanied by descriptions of the factors that led the author to pursue these projects.}
}
@article{MACLENNAN2015410,
title = {Living science: Science as an activity of living beings},
journal = {Progress in Biophysics and Molecular Biology},
volume = {119},
number = {3},
pages = {410-419},
year = {2015},
note = {Integral Biomathics: Life Sciences, Mathematics, and Phenomenological Philosophy},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2015.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0079610715001224},
author = {Bruce J. MacLennan},
keywords = {Philosophy of science, Phenomenology, Embodied cognition, Causality, Analytical psychology, Goethe},
abstract = {The philosophy of science should accommodate itself to the facts of human existence, using all aspects of human experience to adapt more effectively, as individuals, species, and global ecosystem. This has several implications: (1) Our nature as sentient beings interacting with other sentient beings requires the use of phenomenological methods to investigate consciousness. (2) Our embodied, situated, purposeful physical interactions with the world are the foundation of scientific understanding. (3) Aristotle's four causes are essential for understanding living systems and, in particular, the final cause aids understanding the role of humankind, and especially science, in the global ecosystem. (4) In order to fulfill this role well, scientists need to employ the full panoply of human faculties. These include the consciousness faculties (thinking, sensation, feeling, intuition), and therefore, as advocated by many famous scientists, we should cultivate our aesthetic sense, emotions, imagination, and intuition. Our unconscious faculties include archetypal structures common to all humans, which can guide scientific discovery. By striving to engage the whole of human nature, science will fulfill better its function for humans and the global ecosystem.}
}