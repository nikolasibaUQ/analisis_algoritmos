@incollection{CLEEREMANS200581,
title = {Computational correlates of consciousness},
editor = {Steven Laureys},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {150},
pages = {81-98},
year = {2005},
booktitle = {The Boundaries of Consciousness: Neurobiology and Neuropathology},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(05)50007-4},
url = {https://www.sciencedirect.com/science/article/pii/S0079612305500074},
author = {Axel Cleeremans},
abstract = {Over the past few years numerous proposals have appeared that attempt to characterize consciousness in terms of what could be called its computational correlates: Principles of information processing with which to characterize the differences between conscious and unconscious processing. Proposed computational correlates include architectural specialization (such as the involvement of specific regions of the brain in conscious processing), properties of representations (such as their stability in time or their strength), and properties of specific processes (such as resonance, synchrony, interactivity, or information integration). In exactly the same way as one can engage in a search for the neural correlates of consciousness, one can thus search for the computational correlates of consciousness. The most direct way of doing is to contrast models of conscious versus unconscious information processing. In this paper, I review these developments and illustrate how computational modeling of specific cognitive processes can be useful in exploring and in formulating putative computational principles through which to capture the differences between conscious and unconscious cognition. What can be gained from such approaches to the problem of consciousness is an understanding of the function it plays in information processing and of the mechanisms that subtend it. Here, I suggest that the central function of consciousness is to make it possible for cognitive agents to exert flexible, adaptive control over behavior. From this perspective, consciousness is best characterized as involving (1) a graded continuum defined over quality of representation, such that availability to consciousness and to cognitive control correlates with properties of representation, and (2) the implication of systems of meta-representations.}
}
@article{BOELSENROBINSON2021102032,
title = {Mapping factors associated with a successful shift towards healthier food retail in community-based organisations: A systems approach},
journal = {Food Policy},
volume = {101},
pages = {102032},
year = {2021},
issn = {0306-9192},
doi = {https://doi.org/10.1016/j.foodpol.2021.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0306919221000105},
author = {Tara Boelsen-Robinson and Miranda R. Blake and Andrew D. Brown and Oliver Huse and Claire Palermo and Neetu A. George and Anna Peeters},
keywords = {Food retail, Systems mapping, Intervention, Community, Implementation, START map, Nutrition, Policy, Qualitative, Interviews},
abstract = {Background
Food retailers in community settings are gatekeepers to the crucial food systems changes needed to improve population nutrition. Evidence-based models of change are needed to enable shifts in these complex retail environments. Systems thinking offers unique insights by capturing potential unintended consequences and multiple pathways to success. This study sought to create a systems map for retailers, public health practitioners and other stakeholders seeking to implement healthy food retail policies. It aimed to identify (i) points of intervention through which community-based organisations can shift to healthier food provision, and (ii) key feedback loops that could drive potential unintended consequences of such policies in a complex system.
Methods
Semi-structured interviews (n = 26) were conducted, from 2015 to 2018, across four community food retail settings where healthy food retail policies had been implemented in Victoria, Australia. Interviews were coded by identifying causal relationships and their direction between factors. Vensim software was used to merge interview results and then reduce the map to the strongest and most frequent factors and relationships. Illustrative implementation stories and points of intervention were identified.
Findings
The resulting map is titled the Systems Thinking Approach for Retail Transformation (START) map. Five prominent implementation stories incorporating 17 factors highlighted that: 1) retailer resistance to change is strongest in the beginning but decreases with the demonstration of favourable initiative outcomes; 2) successive changes tend to be increasingly complex, and therefore harder for retailers to implement; 3) organisational resourcing can be influenced through multiple pathways; 4) customer acceptability of healthy changes and retailers' willingness to engage in changes influence each other; and 5) challenges in accessing healthy supply options make retailers more resistant to implementing healthy changes.
Conclusions
The application of systems thinking to the challenge of unhealthy food retail creates novel and practical insights for retailers and health promotion practitioners into what actions are most likely to promote healthy changes in complex retail environments.}
}
@article{SKOWRON20115939,
title = {Information systems in modeling interactive computations on granules},
journal = {Theoretical Computer Science},
volume = {412},
number = {42},
pages = {5939-5959},
year = {2011},
note = {Rough Sets and Fuzzy Sets in Natural Computing},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2011.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S0304397511004634},
author = {Andrzej Skowron and Piotr Wasilewski},
keywords = {Interactive computing, Interactive systems, Multi-agent systems, Rough sets, Granular computing, Wisdom technology},
abstract = {In this paper, we discuss the importance of information systems in modeling interactive computations performed on (complex) granules and we propose a formal approach to interactive computations based on generalized information systems and rough sets which can be combined with other soft computing paradigms such as fuzzy sets or evolutionary computing, but also with machine learning and data mining techniques. Information systems are treated as dynamic granules used for representing the results of the interaction of attributes with the environment. Two kinds of attributes are distinguished, namely, the perception attributes, including sensory attributes, and the action attributes. Sensory attributes are the basic perception attributes, other perception attributes are constructed on the basis of the sensory ones. Actions are activated when their guards, being often complex and vague concepts, are satisfied to a satisfactory degree. The guards can be approximated on the basis of measurements performed by sensory attributes rather than defined exactly. Satisfiability degrees for guards are results of reasoning called the adaptive judgment. The approximations are induced using hierarchical modeling. We show that information systems can be used for modeling more advanced forms of interactions in hierarchical modeling. The role of hierarchical interactions is emphasized in the modeling of interactive computations. Some illustrative examples of interactions used in the ACT-R 6.0 system are reported. ACT-R 6.0 is based on a cognitive architecture and can be treated as an example of a highly interactive complex granule which can be involved in hierarchical interactions. For modeling of interactive computations, we propose much more general information systems than the studied dynamic information systems (see, e.g., Ciucci (2010) [8] and Pałasiński and Pancerz (2010) [32]). For example, the dynamic information systems are making it possible to consider incremental changes in information systems. However, they do not contain the perception and action attributes necessary for modeling interactive computations, in particular for modeling intrastep interactions.}
}
@article{MARTINEZMINGO2023101154,
title = {Quantum projections on conceptual subspaces},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101154},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101154},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000827},
author = {Alejandro Martínez-Mingo and Guillermo Jorge-Botana and José Ángel Martinez-Huertas and Ricardo {Olmos Albacete}},
keywords = {Quantum similarity model, Semantic-vector space models, Computational linguistics, Similarity},
abstract = {One of the main challenges of cognitive science is to explain the representation of conceptual knowledge and the mechanisms involved in evaluating the similarities between these representations. Theories that attempt to explain this phenomenon should account for the fact that conceptual knowledge is not static. In line with this thinking, many studies suggest that the representation of a concept changes depending on context. Traditionally, concepts have been studied as vectors within a geometric space, sometimes called Semantic-Vector Space Models (S-VSMs). However, S-VSMs have certain limitations in emulating human biases or context effects when the similarity of concepts is judged. Such limitations are related to the use of a classical geometric approach that represents a concept as a point in space. Recently, some theories have proposed the use of sequential projections of subspaces based on Quantum Probability Theory (Busemeyer and Bruza, 2012; Pothos et al., 2013). They argue that this theoretical approach may facilitate accounting for human similarity biases and context effects in a more natural way. More specifically, Pothos and Busemeyer (2011) proposed the Quantum Similarity Model (QSM) to determine expectation in conceptual spaces in a non-monotonic logic frame. To the best of our knowledge, previous data-driven studies have used the QSM subspaces in a unidimensional way. In this paper, we present a data-driven method to generate these conceptual subspaces in a multidimensional manner using a traditional S-VSM. We present an illustration of the method taking Tversky’s classical examples to explain the effects of Asymmetry, Triangular Inequality, and the Diagnosticity by means of sequential projections of those conceptual subspaces.}
}
@article{MARIS2022131391,
title = {Structure and dynamics of methacrylamide, a computational and free-jet rotational spectroscopic study},
journal = {Journal of Molecular Structure},
volume = {1248},
pages = {131391},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131391},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021015192},
author = {Assimo Maris and Sonia Melandri and Luca Evangelisti and Annalisa Vigorito and Silvia Sigismondi and Camilla Calabrese and Imanol Usabiaga},
keywords = {Amide, Gas-phase structure, Large amplitude motions, Nuclear quadrupole hyperfine structure, Rotational spectroscopy, Quantum mechanical calculations},
abstract = {The conformational space of methacrylamide was explored by quantum mechanical modeling and surveyed in the 59.6–104.0 GHz frequency range using a millimeter-wave Stark-modulated free-jet absorption spectrometer. According to the relative orientation of the two unsaturated bonds, two conformers were observed, namely s-trans (A=5234.360(1), B=3364.9717(8) and C=2173.099(1) MHz) and s-cis (A=5207.292(1), B=3470.930(1) and C=2113.496(1) MHz). The s-trans conformation is the global minimum, with relative energy 4(2) kJ mol−1 and calculated isomerization barrier 15 kJ mol−1. Except for the methyl hydrogen atoms, s-cis-methacrylamide is planar and its methyl internal rotation barrier is 10.2(1) kJ mol−1. In s-trans-methacrylamide the allyl and amino frames form a dihedral angle of about 30° and the methyl internal rotation barrier is 7.4 kJ mol−1. This different behaviour is explained in terms of attractive and repulsive intramolecular interactions between groups: CH2/CO and CH3/NH2 for s-cis, CH2/NH2 and CH3/CO for s-trans. The tunneling splitting related to the double-well potential describing the interconversion between the two equivalent s-trans forms is 837.97(2) MHz and was reproduced by a one-dimensional flexible model using a 3.6 kJ mol−1 interconversion barrier.}
}
@incollection{HOLCOMBE2005407,
title = {30 Computational modelling of creativity in abstract art},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {407-424},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80058-3},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800583},
author = {Mike Holcombe and Samantha Smith and Rowan Merewood and Andy Swingeford},
abstract = {Artistic creativity is studied through the construction of computational models of a number of well-known modern artists. In particular, the work of Piet Mondrian, M.C. Escher and Paul Klee are suitable vehicles for investigation since their work is accompanied by extensive writings describing the ideas and motivation behind their compositions. In particular, we have tried to abstract from their theories, rules that describe the construction process or the properties that their finished artefacts posses in order to create software programs that can articulate these rules. In this way, we are able to simulate either automatically or with user interaction, the process of creating works of art of a similar genre and satisfying the properties desired by the artist. Since the rules are bound to be considerably more complex than those currently exposed, we are looking to use machine-learning techniques to develop more sophisticated agents, which may behave more closely like the actual artist.}
}
@article{LIU2000261,
title = {Creativity or novelty?: Cognitive-computational versus social-cultural},
journal = {Design Studies},
volume = {21},
number = {3},
pages = {261-276},
year = {2000},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(99)00013-7},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X99000137},
author = {Yu-Tung Liu},
keywords = {creativity, design cognition, computer-aided design, problem-solving, artificial intelligence},
abstract = {This paper proposes a broader framework for understanding creativity by distinguishing different levels of creativity, namely personal and social-cultural creativity, and their interaction. Within this framework, the possible role that computer-aided design systems can play is discussed by analyzing the procedure of rule formation and the phenomena of seeing emergent subshapes.}
}
@article{CLERJUSTE2024105922,
title = {Unpacking the challenges and predictors of elementary–middle school students’ use of the distributive property},
journal = {Journal of Experimental Child Psychology},
volume = {244},
pages = {105922},
year = {2024},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2024.105922},
url = {https://www.sciencedirect.com/science/article/pii/S0022096524000626},
author = {Sarah N. Clerjuste and Claire Guang and Dana Miller-Cotto and Nicole M. McNeil},
keywords = {Distributive property, Cognitive reflection, Multiplication, Worked examples},
abstract = {The distributive property plays a pivotal role in advancing students’ understanding of multiplication, enabling the decomposition of problems and the acquisition of new facts. However, this property of multiplication is difficult for students to understand. We used two unique data sets to explore middle school students’ use of the distributive property. Study 1 involved data from 1:1 structured interviews of students (N = 24) discussing worked examples and solving associated practice problems. We examined whether or not students used the distributive property to solve the problems and whether or not interviewers followed the recommended distributive property prompts or defaulted to more conventional methods. Despite exposure to worked examples using the distributive property and a protocol calling for attention to it, students and interviewers favored methods like PEMDAS (parentheses, exponents, multiplication, division, addition, subtraction) or long multiplication. Study 2 used a data set with middle school students’ (N = 131) item-level responses on Kirkland’s (2022; doctoral dissertation, University of Notre Dame) Brief Assessment of Mature Number Sense along with several related measures of domain-general and domain-specific skills. We extracted problems involving the distributive property for analysis. Surprisingly, there was no evidence that students’ use of the distributive property improved from sixth grade to eighth grade. However, both grade-level mathematics achievement and cognitive reflection uniquely predicted the correct use of the distributive property. Results suggest that middle school students who exhibit stronger reflective thinking tend to perform better on distributive property problems. Findings highlight cognitive reflection as a potentially important construct involved in the understanding and use of the distributive property.}
}
@incollection{GARDNER2024129,
title = {Chapter 6 - Smart design for sustainable behaviors},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {129-151},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000070},
author = {Nicole Gardner},
keywords = {Behavior change, Cyber-physical system, Interaction, Physical computing, Persuasive technology, Nudge theory, Responsibilization, Smart city, Sustainability, Transition design, Urban design, Urban technology},
abstract = {While smart city initiatives have netted energy savings and carbon reductions, many cities and nations are still falling short of their sustainability targets and climate goals. This chapter draws on transitions concepts and behavior change theory to explore how smaller-scale and localized examples of existing and speculative urban technology projects that combine spatial design thinking and physical computing can help to anchor sustainability culture within everyday citizen's lives. It discusses the ethical significance of designing interactive urban technology projects that aim to nudge behavior change in relation to sustainability awareness.}
}
@article{ZHOU2022105384,
title = {Informed speculation with k-level reasoning},
journal = {Journal of Economic Theory},
volume = {200},
pages = {105384},
year = {2022},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105384},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121002015},
author = {Hang Zhou},
keywords = {Level- thinking, Investors' sophistication, Market instability},
abstract = {This paper investigates the effect of strategic reasoning on financial markets with a level-k thinking framework. A level-k speculator performs k rounds of iterative reasoning to infer information from asset prices. In contrast to the static rational expectations equilibrium, the level-k framework produces a unified theory of momentum and contrarian trading strategies. Besides, this paper discusses how the distribution of sophistication levels affects several market variables and it sheds new light on empirical patterns such as: (1) overreaction of asset prices, (2) the excess volatility puzzle, and (3) the excessive trading volume puzzle. Moreover, this paper explores whether the level-k strategy converges to the rational expectations equilibrium.}
}
@article{SNYDER2022100852,
title = {The role of heat resistance in yeast spoilage of thermally processed foods: highlighting the need for a probabilistic, systems-based approach to microbial quality},
journal = {Current Opinion in Food Science},
volume = {46},
pages = {100852},
year = {2022},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2022.100852},
url = {https://www.sciencedirect.com/science/article/pii/S2214799322000546},
author = {Abigail B Snyder},
abstract = {The relationship between stress-tolerance mechanisms (cell-wall structure, metabolism, morphology, etc.) of individual fungi and the physiochemistry of their food environment selects for a small group of specific spoilage organisms (SSOs). However, common process deviations and post-processing contamination widen the lens of potentially relevant spoilage fungi. For example, although heat-resistant molds are considered the SSOs in thermally processed foods, unintended events (deviations, post-processing contamination) lead to spoilage by other propagules, notably yeast. The frequency of these unintended events changes our assessments of which spoilage fungi are relevant to a given food system. Consequently, a framework using probabilistic and systems-based thinking is needed to understand spoilage risk. Toward that goal, simple molecular tools for identification and subtyping are required.}
}
@article{EAMES2021100864,
title = {The finite-to-finite strand of a learning progression for the concept of function: A research synthesis and cognitive analysis},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100864},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100864},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000250},
author = {Cheryl L. Eames and Edith Aurora Graf and Peter W. {van Rijn} and Greg Budzban and Tammy Voepel},
keywords = {Learning progressions, Concept of function, Representation, Secondary students},
abstract = {In this paper we report validation efforts around the finite-to-finite strand of a provisional learning progression (LP) for the concept of function. We regard an LP as an empirically-verified account of how student understandings form over time and in response to instruction. The finite-to-finite strand of the LP was informed by literature on students’ thinking and learning related to functions as well as the Algebra Project’s curricular approach, which is designed for students who are traditionally underserved by mathematics education. Developing and validating an LP is a multi-step, cyclic process. Here we report on one step in this process, an item and response analysis. Data sources include 680 students’ responses to 13 multipart computer-delivered tasks. Results suggest that revisions to the items, associated scoring rubrics, and in some instances the LP are warranted. We illustrate this task, rubric, and LP revision process through an item analysis for a selected task.}
}
@article{SONOBE2022101560,
title = {Development and validation of machine learning prediction model for post-rehabilitation functional outcome after intracerebral hemorrhage},
journal = {Interdisciplinary Neurosurgery},
volume = {29},
pages = {101560},
year = {2022},
issn = {2214-7519},
doi = {https://doi.org/10.1016/j.inat.2022.101560},
url = {https://www.sciencedirect.com/science/article/pii/S2214751922000743},
author = {Shinya Sonobe and Tetsuo Ishikawa and Kuniyasu Niizuma and Eiryo Kawakami and Takuya Ueda and Eichi Takaya and Carlos {Makoto Miyauchi} and Junya Iwazaki and Ryuzaburo Kochi and Toshiki Endo and Arun Shastry and Vijayananda Jagannatha and Ajay Seth and Atsuhiro Nakagawa and Masahiro Yoshida and Teiji Tominaga},
keywords = {Intracerebral hemorrhage, Machine learning prediction, Post-rehabilitation functional outcome, Design thinking},
abstract = {Objective
Predicting outcomes after intracerebral hemorrhage (ICH) may help improve patient outcomes. We developed and validated a machine learning prediction model for post-rehabilitation functional outcomes after ICH. Patient selection and explanatory variable settings were based on clinical significance. Functional outcomes were predicted using ternary classification.
Methods
The subjects were patients aged > 18 years without pre-onset severe disability who developed primary putaminal and/or thalamic hemorrhage and underwent an inpatient rehabilitation program. As explanatory variables, 43 values related to patient background, imaging-related findings, systemic conditions, neurological findings, and blood tests were acquired within 10 days of onset. As an objective variable, the functional outcome at discharge to home or nursing home was acquired using a ternary classification. The dataset consisting of the collected information was split into a training dataset and a test dataset with a ratio of 2:1. A predictive model using a balanced random forest algorithm was created using supervised learning from the training dataset. The predictive performance was validated using a test dataset.
Results
Between January 2018 and June 2019, 100 consecutive patients were included in the study. The areas under the receiver operating characteristic curves for predictions of good, moderate, and poor outcomes were 0.952, 0.790, and 0.921, respectively.
Conclusions
The predictive performance of the model was comparable to that of previous models. Patient selection and variable settings from a clinical perspective may contribute to accurate and detailed predictions. These study designs are based on design thinking and may meet the needs of clinical practice.}
}
@article{GREIF2024126,
title = {Selection, growth and form. Turing’s two biological paths towards intelligent machinery},
journal = {Studies in History and Philosophy of Science},
volume = {106},
pages = {126-135},
year = {2024},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0039368124000657},
author = {Hajo Greif and Adam P. Kubiak and Paweł Stacewicz},
keywords = {Universal computing machines, Mechanism, Connectionism, Morphogenesis, D’Arcy Thompson, Darwinian evolution, Cellular automata},
abstract = {We inquire into the role of Turing’s biological thought in the development of his concept of intelligent machinery. We trace the possible relations between his proto-connectionist notion of ‘organising’ machines in Turing (1948) on the one hand and his mathematical theory of morphogenesis in developmental biology (1952) on the other. These works were concerned with distinct fields of inquiry and followed distinct paradigms of biological theory, respectively postulating analogues of Darwinian selection in learning and mathematical laws of form in organic pattern formation. Still, these strands of Turing’s work are related, first, in terms of being amenable in principle to his (1936) computational method of modelling. Second, they are connected by Turing’s scattered speculations about the possible bearing of learning processes on the anatomy of the brain. We argue that these two theories form an unequal couple that, from different angles and in partial fashion, point towards cognition as a biological and embodied phenomenon while, for reasons inherent to Turing’s computational approach to modelling, not being capable of directly addressing it as such. We explore ways in which these two distinct-but-related theories could be more explicitly and systematically connected, using von Neumann’s contemporaneous and related work on Cellular Automata and more recent biomimetic approaches as a foil. We conclude that the nature of ‘initiative’ and the mode of material realisation are the key issues that decide on the possibility of intelligent machinery in Turing.}
}
@article{TESFATSION2001281,
title = {Introduction to the special issue on agent-based computational economics},
journal = {Journal of Economic Dynamics and Control},
volume = {25},
number = {3},
pages = {281-293},
year = {2001},
note = {Agent-based Computational Economics (ACE)},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(00)00027-0},
url = {https://www.sciencedirect.com/science/article/pii/S0165188900000270},
author = {Leigh Tesfatsion},
keywords = {Agent-based computational economics},
abstract = {A brief overview of agent-based computational economics (ACE) is given, followed by a synopsis of the articles included in this special issue on ACE and in a companion special issue on ACE scheduled to appear in Computational Economics.}
}
@article{MACHKROL2023259,
title = {An ML-extended conceptual framework for implementing temporal big data analytics in organizations to support their agility},
journal = {Procedia Computer Science},
volume = {225},
pages = {259-268},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011687},
author = {Maria Mach-Król and Bartłomiej Hadasik},
keywords = {temporal big data analytics, temporal knowledge, machine learning, organizational agility, feedback loop},
abstract = {The main aim of this paper is to present the machine learning (ML) extension to the authors’ original conceptual framework for implementing temporal big data analytics (TBDA) in organizations. The framework has been also supplemented with a ML-supported feedback loop aimed at ongoing verification of the organization's maturity for TBDA in light of changing needs, requirements, and the company's environment. Such extension is needed to make the TBDA more flexible and adaptable to market environment, thus augmenting organizational agility. The research has been carried following the Design Science Research in Information Systems (DSRIS) methodological approach with the addition of creative thinking. As a result, the extended framework is elaborated, and further improvements and research directions are identified.}
}
@article{LIU2019678,
title = {A review of the smart world},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {678-691},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17319532},
author = {Hong Liu and Huansheng Ning and Qitao Mu and Yumei Zheng and Jing Zeng and Laurence T. Yang and Runhe Huang and Jianhua Ma},
keywords = {Smart world, Ubiquitous computing, Ambient intelligence, Cyber–physical–social-thinking, Internet of Things},
abstract = {Smart world is an attractive prospect with comprehensive development of ubiquitous computing involving penetrative intelligence into ubiquitous things, including physical objects (e.g., wearable devices), cyber entities (e.g., cloud services), social people (e.g., social networking) and human thinking (e.g., brain cognition). This work systematically overviews related works in the field of the smart world, and explains prospects in emerging areas. The smart world evolutions are discussed through four progressive phases, and the representative projects are accordingly introduced. Meanwhile, smart world elements and the smart world driven applications are respectively analyzed in the contexts of cyber–physical–social-thinking hyperspace. Moreover, enabling technologies including ubiquitous intelligence, web intelligence, brain informatics, social computing, big data, and security and privacy are respectively discussed. Finally, perspectives referring to ubiquitous sensing, ubiquitous object modeling, smart services, and philosophical, ethical and legal issues, are presented for identifying trends and challenges in the smart world.}
}
@article{RADU2023100008,
title = {Charting opportunities and guidelines for augmented reality in makerspaces through prototyping and co-design research},
journal = {Computers & Education: X Reality},
volume = {2},
pages = {100008},
year = {2023},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2023.100008},
url = {https://www.sciencedirect.com/science/article/pii/S2949678023000028},
author = {Iulian Radu and Josia Yuan and Xiaomeng Huang and Bertrand Schneider},
keywords = {Augmented reality, Makerspaces, Co-design, STEM, Classroom integration},
abstract = {Makerspace environments are becoming popular project-based learning spaces where students interact with physical objects and peer collaboration, while developing 21st century skills and engaging with science, technology, engineering, and math (STEM) topics. At the same time, augmented reality (AR) technology, which combines physical objects with digital visualizations, is becoming increasingly applicable for makerspace activities and has potential to address challenges for student learning in makerspaces. However, there is a lack of understanding of how to use and integrate AR in real makerspace environments. In this research we use a co-design methodology to address the following questions: (1) How can AR be useful for education in makerspaces? (2) How are students impacted by the process of co-designing AR technology? and (3) What are practical considerations for integrating AR in makerspaces? We engaged in a co-design process in a semester-long makerspace course attended by 18 students in a graduate school of education. Through this process, we generated six prototypes with seven student co-designers, exploring AR use in design, fabrication, programming, electronics, and training. We also identified areas where AR technology can benefit makerspaces, such as teaching STEM skills, facilitating construction activities, enhancing contextualization of learning, and debugging. We observed that students participating in co-design demonstrated improved understanding of technology design, enthusiasm for engaging with makerspaces and AR, and increased critical thinking about AR technology. These results suggest considerations and guidelines for integrating AR technology into makerspace environments.}
}
@article{MYCKA2006103,
title = {Analog computation beyond the Turing limit},
journal = {Applied Mathematics and Computation},
volume = {178},
number = {1},
pages = {103-117},
year = {2006},
note = {Special Issue on Hypercomputation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2005.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S0096300305008386},
author = {Jerzy Mycka},
abstract = {The main purpose of this paper is quite uncontroversial. First, we recall some models of analog computations (including these allowed to perform Turing uncomputable tasks). Second, we support the suggestions that such hypercomputable capabilities of such systems can be explained by the use of infinite limits. Additionally, the inner restrictions of analog models of computations are indicated.}
}
@article{LINDELL2024103428,
title = {The dialectics of digitalisation: A critique of the modernistic imperative for the development of digital technology},
journal = {Futures},
volume = {162},
pages = {103428},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103428},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001113},
author = {Rikard Lindell},
keywords = {Dialectics, Digital transformation, Digitalisation, Postdigital},
abstract = {This text discusses today’s digital transformation through the lens of Horkheimer and Adornos’ study of the enlightenment. Policy and public discourse around digitalisation embrace and adhere to the narrow tenets enlightenment thinking; the idea that rationality, individual freedom, and a society free from superstition are necessary and attainable goals. The costs of what has come to be called ‘Modernity’ are many. Through the application of rationality to all spheres of life, married with disruptive technological advancement, humanity has diminished its’ imagination – its ability to seek new directions. To paraphrase Horkheimer and Adorno, Modernism fights against nature, of which we are a part, and thus, paradoxically, sets us in a fight against ourselves. Environmental degradation, the price of progress, being just one example of this – deadening work, consumerism and severed social connections being amongst others. In this framing, digitalisation itself comes to be understood itself as akin to a force of nature – one that we can do little about, other than adjust and adapt or be swept away. But this by no means a foregone conclusion, there is light at the end of the optical fibre. Albeit that recent technical developments around artificial intelligence appears to be pushing policy makers into hasty decisions, the pace of the technical development is not as fast as we believe, and in comparison with the Reformation – we have time. If we can restrain ourselves from the resist, adapt or die responses promoted in popular discourse in face of the shock of large language models and rising threat of automation, then we create room to consider economic, social, and ecological alignment and accord, in the decision making and design of future interactive artefacts and digital services. The article argues that through postdigital aesthetics, technology makers can embrace materiality and the inherent qualities of digital technology to formulate a critique of existing trajectories in digital transformation, with consequences for a more sustainable future.}
}
@article{ROBERTS201648,
title = {Mathematical and computational models of the retina in health, development and disease},
journal = {Progress in Retinal and Eye Research},
volume = {53},
pages = {48-69},
year = {2016},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1350946216300106},
author = {Paul A. Roberts and Eamonn A. Gaffney and Philip J. Luthert and Alexander J.E. Foss and Helen M. Byrne},
keywords = {Oxygen, Neuroglobin, Photoreceptors, Angiogenesis, Retinitis pigmentosa, Choroidal neovascularisation},
abstract = {The retina confers upon us the gift of vision, enabling us to perceive the world in a manner unparalleled by any other tissue. Experimental and clinical studies have provided great insight into the physiology and biochemistry of the retina; however, there are questions which cannot be answered using these methods alone. Mathematical and computational techniques can provide complementary insight into this inherently complex and nonlinear system. They allow us to characterise and predict the behaviour of the retina, as well as to test hypotheses which are experimentally intractable. In this review, we survey some of the key theoretical models of the retina in the healthy, developmental and diseased states. The main insights derived from each of these modelling studies are highlighted, as are model predictions which have yet to be tested, and data which need to be gathered to inform future modelling work. Possible directions for future research are also discussed. Whilst the present modelling studies have achieved great success in unravelling the workings of the retina, they have yet to achieve their full potential. For this to happen, greater involvement with the modelling community is required, and stronger collaborations forged between experimentalists, clinicians and theoreticians. It is hoped that, in addition to bringing the fruits of current modelling studies to the attention of the ophthalmological community, this review will encourage many such future collaborations.}
}
@article{ZHOU2024108310,
title = {The neuroanatomical correlates of daily habitual tendencies and mediating effect on the association between daily habitual tendencies and symptoms of behavioral addictions},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108310},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108310},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400178X},
author = {Xinqi Zhou and Qi Liu and Lan Wang and Xianyang Gan and Ran Zhang and Xiqin Liu and Guojuan Jiao and Christian Montag and Weihua Zhao and Benjamin Becker},
keywords = {Habit, Gray matter, vmPFC, Precuneus, Internet gaming disorder, Smartphone use},
abstract = {Habitual behaviors significantly shape our daily actions. Furthermore, habit formation is proposed as a key mechanism contributing to the development and maintenance of addiction. However, the neural substrates underlying daily habitual tendencies and their contribution to behavioral addiction symptoms in everyday life remain poorly understood. To explore these questions, we conducted a comprehensive analysis of data from 219 individuals who underwent neuroimaging (structural MRI) assessments alongside evaluations of their daily habitual tendencies and symptoms of Internet Gaming Disorder (IGD) and Problematic Smartphone Use (PSU). Using voxel-based morphometry, meta-analytic decoding, and mediation analysis, we found that daily habitual tendencies were positively correlated with larger gray matter volumes in the ventromedial prefrontal cortex (vmPFC), precuneus, superior frontal gyrus (SFG), inferior temporal gyrus (ITG), and supplementary motor area (SMA). Notably, the midline regions, including the vmPFC and precuneus, play a crucial role in value-based computation, emotional regulation, social cognition, and self-referential thinking. Individual variations in gray matter volumes within these regions served as mediators, influencing the bidirectional relationship between daily habitual tendencies and IGD symptoms. However, vmPFC variations were specifically found to mediate the pathway from PSU to daily habitual tendencies. Our findings suggest that the morphological architecture of the vmPFC and precuneus is associated with habitual tendencies in daily life and may mediate the development of addictive behaviors. This study contributes to a more nuanced understanding of the neuroanatomical basis of daily habitual tendencies and their role in addictive behaviors.}
}
@article{SCHULTEMECKLENBECK2013242,
title = {A lack of appetite for information and computation. Simple heuristics in food choice},
journal = {Appetite},
volume = {71},
pages = {242-251},
year = {2013},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0195666313003668},
author = {Michael Schulte-Mecklenbeck and Matthias Sohn and Emanuel {de Bellis} and Nathalie Martin and Ralph Hertwig},
keywords = {Food choice, Heuristics, Process tracing, Rational choice, MouselabWeb},
abstract = {The predominant, but largely untested, assumption in research on food choice is that people obey the classic commandments of rational behavior: they carefully look up every piece of relevant information, weight each piece according to subjective importance, and then combine them into a judgment or choice. In real world situations, however, the available time, motivation, and computational resources may simply not suffice to keep these commandments. Indeed, there is a large body of research suggesting that human choice is often better accommodated by heuristics—simple rules that enable decision making on the basis of a few, but important, pieces of information. We investigated the prevalence of such heuristics in a computerized experiment that engaged participants in a series of choices between two lunch dishes. Employing MouselabWeb, a process-tracing technique, we found that simple heuristics described an overwhelmingly large proportion of choices, whereas strategies traditionally deemed rational were barely apparent in our data. Replicating previous findings, we also observed that visual stimulus segments received a much larger proportion of attention than any nutritional values did. Our results suggest that, consistent with human behavior in other domains, people make their food choices on the basis of simple and informationally frugal heuristics.}
}
@article{MINGERS201767,
title = {Back to the future: A critique of Demetis and Lee's “Crafting theory to satisfy the requirements of systems science”},
journal = {Information and Organization},
volume = {27},
number = {1},
pages = {67-71},
year = {2017},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1471772717300118},
author = {John Mingers},
abstract = {Demetis and Lee's paper outlines criteria for constructing theory in accordance with systems science. This is a laudable aim but in this comment I suggest that their view of systems thinking is both narrow and somewhat dated. Demetis and Lee equate systems science with only one aspect of it – General Systems Thinking (GST) – and they discuss in detail only one theorist – Niklas Luhmann. I draw attention to a range of other systems approaches including system dynamics, soft systems methodology, complexity theory, critical systems thinking, critical realism and multimethodology. I conclude with tentative guidelines of my own.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{GUR2015207,
title = {Space reconstruction by primary visual cortex activity: a parallel, non-computational mechanism of object representation},
journal = {Trends in Neurosciences},
volume = {38},
number = {4},
pages = {207-216},
year = {2015},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2015.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223615000351},
author = {Moshe Gur},
keywords = {vision, object representation, recognition, conscious perception, parallel processing},
abstract = {The current view posits that objects, despite changes in appearance, are uniquely encoded by ‘expert’ cells. This view is untenable. First, even if cell ensemble responses are invariant and unique, we are consciously aware of all of the objects’ details. Second, in addition to detail preservation, data show that the current hypothesis fails to account for uniqueness and invariance. I present an alternative view whereby objects’ representation and recognition are based on parallel representation of space by primary visual cortex (V1) responses. Information necessary for invariance and other attributes is handled in series by other cortical areas through integration, interpolation, and hierarchical convergence. The parallel and serial mechanisms combine to enable our flexible space perception. Only in this alternative view is conscious perception consistent with the underlying architecture.}
}
@incollection{ROMO2020150,
title = {Metaphor},
editor = {Steven Pritzker and Mark Runco},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {150-156},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23529-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245235293},
author = {Manuela Romo},
keywords = {Analogical thought, Combinatory process, Computational creativity, Constitutive metaphor, Darwin, Einstein, Lorca, Pedagogical metaphor, Poetry, Scientific discovery},
abstract = {The subject of metaphors is introduced with a definition, stressing its role as a universal process in the development of thinking and language in human beings. A discussion follows on the differences between metaphor and analogy in this thinking process. The classification of metaphors is then addressed, while the body of the text is dedicated to reviewing explanations given from the standpoint of Psychology of Creativity on the nature of this process and its role in creative output. Lastly, the usefulness of metaphors and their dependence on domain specificity is analysed.}
}
@article{JONES2015e38,
title = {Complexity and forensic pathology},
journal = {Forensic Science International},
volume = {257},
pages = {e38-e43},
year = {2015},
issn = {0379-0738},
doi = {https://doi.org/10.1016/j.forsciint.2015.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0379073815003709},
author = {Richard Martin Jones},
keywords = {Complexity, Chaos, Nonlinear, Pathophysiology, Forensic pathology, Forensic medicine},
abstract = {It has become increasingly apparent that nonlinearity and complexity are the norm in human physiological systems, the relevance of which is informing an enhanced understanding of basic pathological processes such as inflammation, the host response to severe trauma, and critical illness. This article will explore how an understanding of nonlinear systems and complexity might inform the study of the pathophysiology of deaths of medicolegal interest, and how ‘complexity thinking’ might usefully be incorporated into modern forensic medicine and forensic pathology research, education and practice.}
}
@article{DALLAGO2016150,
title = {Computation by interaction for space-bounded functional programming},
journal = {Information and Computation},
volume = {248},
pages = {150-194},
year = {2016},
note = {Development on Implicit Computational Complexity (DICE 2013)},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S089054011500142X},
author = {Ugo {Dal Lago} and Ulrich Schöpp},
keywords = {Implicit computational complexity, Logarithmic space, Type system, Geometry of interaction, Functional programming},
abstract = {When programming with sublinear space constraints one often needs to use special implementation techniques even for simple tasks, such as function composition. In this paper, we study how such implementation techniques can be supported in a functional programming language. Our approach is based on modelling computation by interaction using the Int construction of Joyal, Street & Verity. We apply this construction to a term model of a first-order programming language and use the resulting structure to derive the functional programming language intml. Intml can be understood as a programming language simplification of Stratified Bounded Affine Logic. We formulate intml by means of a type system inspired by Baillot & Terui's Dual Light Affine Logic. We show that it captures the complexity classes flogspace and nflogspace. We illustrate its expressiveness by showing how typical graph algorithms, such a test for acyclicity in undirected graphs, can be represented.}
}
@article{CHUI201337,
title = {Simulation Method for Developing Multiple-Use Medical Devices from Re-using and Enhancing Design of Single-Use Device},
journal = {Procedia CIRP},
volume = {5},
pages = {37-41},
year = {2013},
note = {First CIRP Conference on BioManufacturing},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2013.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827113000085},
author = {Chee-Kong Chui and Han-Tong Loh and Jun-Fung Yam},
keywords = {Medical device design, Simulation, Single port access surgery},
abstract = {Single port access surgery requires several specialized and one-time use devices to perform the surgery. By making the specialized devices suitable for multiple use may reduce surgical cost and increase the popularity of single port access surgery. However, this requires a new design thinking that emphasize on modular design and sterilization. We are exploiting simulation and computational intelligence methods to aid the design process that includes splitting an existing single use device design into modules and identifying the parts from the modules for manufacturing. Linking the design of the device with manufacturing can be achieved using feature graphs. This paper relates the development of a multiple use hand instrument for single port access surgery by re- using and enhancing the design of single-use devices with the proposed simulation-based methodology.}
}
@article{BARA2001839,
title = {Model theory of deduction: a unified computational approach},
journal = {Cognitive Science},
volume = {25},
number = {6},
pages = {839-901},
year = {2001},
issn = {0364-0213},
url = {https://www.sciencedirect.com/science/article/pii/S0364021301000568},
author = {Bruno G. Bara and Monica Bucciarelli and Vincenzo Lombardo},
keywords = {Mental models, Deduction, Computational model, Development},
abstract = {One of the most debated questions in psychology and cognitive science is the nature and the functioning of the mental processes involved in deductive reasoning. However, all existing theories refer to a specific deductive domain, like syllogistic, propositional or relational reasoning. Our goal is to unify the main types of deductive reasoning into a single set of basic procedures. In particular, we bring together the microtheories developed from a mental models perspective in a single theory, for which we provide a formal foundation. We validate the theory through a computational model (UNICORE) which allows fine-grained predictions of subjects’ performance in different reasoning domains. The performance of the model is tested against the performance of experimental subjects—as reported in the relevant literature—in the three areas of syllogistic, relational and propositional reasoning. The computational model proves to be a satisfactory artificial subject, reproducing both correct and erroneous performance of the human subjects. Moreover, we introduce a developmental trend in the program, in order to simulate the performance of subjects of different ages, ranging from children (3–6) to adolescents (8–12) to adults (>21). The simulation model performs similarly to the subjects of different ages. Our conclusion is that the validity of the mental model approach is confirmed for the deductive reasoning domain, and that it is possible to devise a unique mechanism able to deal with the specific subareas. The proposed computational model (UNICORE) represents such a unifying structure.}
}
@article{ZHANG2023100528,
title = {Foreign language effect in accounting uncertainty expressions: Interpretation and probabilistic estimation},
journal = {Journal of International Accounting, Auditing and Taxation},
volume = {50},
pages = {100528},
year = {2023},
issn = {1061-9518},
doi = {https://doi.org/10.1016/j.intaccaudtax.2023.100528},
url = {https://www.sciencedirect.com/science/article/pii/S1061951823000071},
author = {Yuqian Zhang and Anura {De Zoysa} and Corinne Cortese},
keywords = {Foreign language effect, Uncertainty expressions, Probability estimation, Accounting judgement, Interpretation},
abstract = {The foreign language effect, or thinking in a foreign language, reduces judgment bias under uncertainty. This study investigates how language use (native versus foreign) affects accounting judgment on uncertainty expressions. We conducted two separate experiments: between-subjects and within-subjects, both of which included tasks requiring interpretations and probability estimations based on accounting standard uncertainty expressions. The results demonstrated that foreign language use affected the interpretation of uncertainty expressions and reduced judgment bias in probability estimation, particularly in the context of asset recognition. These findings have important implications for accounting research and reporting.}
}
@article{LEVYGARBOUA2024102438,
title = {Creative cognition as a bandit problem},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102438},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102438},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000311},
author = {Louis Lévy-Garboua and Marco Gazel and Noémi Berlin and Jan Dul and Todd Lubart},
keywords = {Creative cognition, Multi-armed bandit problem, Education and creativity, Individual differences in creative potential, Adolescents' behavior},
abstract = {This paper draws a parallel between creative cognition and a multi-armed bandit problem involving learning from experience in an uncertain environment. Special emphasis is put on the optimal sequencing of divergent and convergent behavior by showing that divergence must be inhibited at one point to converge toward creative behavior so that excessive divergence is counterproductive. We test this hypothesis with a behavioral experiment, using measures of individual divergence and convergence components of creative potential in high school students. Results confirmed that a mix of divergence and convergence predicted high performance in a bandit task but not in a purely random task or in a simple repetitive task. These predictions are maintained after controlling for sex, personality, incentives, and other factors. As hypothesized, creative cognition was necessary for high performance under the appropriate conditions. However, it was not necessary to get high grades in a traditional school system.
Educational relevance statement
Relating to the goal of educators and public policies in the 21st century to make children and adolescents more creative, and schools more receptive to creative thinking, this research focuses on the creative potential and behavior of high school students. It provides an evidence-based policy argument in support of the screening and development by the educational sector of the creative potential of students.}
}
@incollection{KARACA2022149,
title = {Chapter 9 - Computational fractional-order calculus and classical calculus AI for comparative differentiability prediction analyses of complex-systems-grounded paradigm},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {149-168},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000067},
author = {Yeliz Karaca and Dumitru Baleanu},
keywords = {Complexity, Artificial neural network, Classical calculus, Computational complexity, Data-driven fractional modeling, Differentiability prediction analyses, Fractional calculus, Mathematical biology and neuroscience, Mittag-Leffler function, Optimized fractional-order calculus},
abstract = {Modern science having embarked on the thorough and accurate interpretation of natural and physical phenomena has proven to provide successful models for the analysis of complex systems and harnessing of control over the various processes therein. Computational complexity, in this regard, comes to the foreground by providing applicable sets of ideas or integrative paradigms to recognize and understand the complex systems' intricate properties. Thus, while making the appropriate, adaptable and evolutive decisions in complex dynamic systems, it is essential to acknowledge different degrees of acceptance of the problems and construct the model it to account for its inherent constraints or limits. In this respect, while hypothesis-driven research has its inherent limitations regarding the investigation of multifactorial and heterogeneous diseases, a data-driven approach enables the examination of the way variables impact one another, which paves the way for the interpretation of dynamic and heterogeneous mechanisms of diseases. Fractional Calculus (FC), in this scope characterized by complexity, provides the applicable means and methods to solve integral, differential and integro-differential equations so FC enables the generalization of integration and differentiation possible in a flexible and consistent manner owing to its capability of reflecting the systems' actual state properties, which exhibit unpredictable variations. The fractional integration and differentiation of fractional-order is capable of providing better characterization of nonstationary and locally self-similar attributes in contrast to constant-order fractional calculus. It becomes possible to model many complex systems by fractional-order derivatives based on fractional calculus so that related syntheses can be realized in a robust and effective way. To this end, our study aims at providing an intermediary facilitating function both for the physicians and individuals by establishing accurate and robust model based on the integration of fractional-order calculus and Artificial Neural Network (ANN) for the diagnostic and differentiability predictive purposes with the diseases which display highly complex properties. The integrative approach we have proposed in this study has a multistage quality the steps of which are stated as follows: first of all, the Caputo fractional-order derivative, one of the fractional-order derivatives, has been used with two-parametric Mittag-Leffler function on the stroke dataset and cancer cell dataset, manifesting biological and neurological attributes. In this way, new fractional models with varying degrees have been established. Mittag-Leffler function, with its distributions of extensive application domains, can address irregular and heterogeneous environments for the solution of dynamic problems; thus, Mittag-Leffler function has been opted for accordingly. Following this application, the new datasets (mlf_stroke dataset and mlf_cancer cell dataset) have been obtained by employing Caputo fractional-order derivative with the two-parametric Mittag-Leffler function (α,β). In addition, classical derivative (calculus) was applied to the raw datasets; and cd_stroke dataset and cd_cancer cell dataset were obtained. Secondly, the performance of the new datasets as obtained from the Caputo fractional derivative with the two-parametric Mittag-Leffler function, the datasets obtained from the classical derivative application and the raw datasets have been compared by using feed forward back propagation (FFBP) algorithm, one of the algorithms of ANN (along with accuracy rate, sensitivity, precision, specificity, F1-score, multiclass classification (MCC), ROC curve). Based on the accuracy rate results obtained from the application with FFBP, the Caputo fractional-order derivative model that is most suitable for the diseases has been generated. The experimental results obtained demonstrate the applicability of the complex-systems-grounded paradigm scheme as proposed through this study, which has no existing counterpart. The integrative multi-stage method based on mathematical-informed framework with comparative differentiability prediction analyses can point toward a new direction in the various areas of applied sciences to address formidable challenges of critical decision making and management of chaotic processes in different complex dynamic systems.}
}
@article{MONAT2024103429,
title = {The self-awareness of the forest},
journal = {Futures},
volume = {163},
pages = {103429},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103429},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001125},
author = {Jamie P. Monat},
keywords = {Forest, Emergence, Systems thinking, Self-awareness, Neural network},
abstract = {Systems Thinking theorist J. P. Monat has hypothesized that human-level organismal self-awareness will emerge spontaneously in a well-connected neural network as the number of interconnected nodes exceeds ∼70 billion; he speculates that computer networks may achieve self-awareness as the number of nodes approaches this figure. Forests have historically not been perceived as interconnected networks of trees; recently however, researchers have described the “wood-wide web” in which underground fungi interconnect large numbers of trees and plants via chemical and electrical signals. Some of earth’s forests number many billions of trees, and some of the world’s prairies and seagrass meadows also contain billions of individual plants. These plant ecosystems may thus be self-aware, and in fact there may be a multitude of self-aware plant-based ecosystems on earth already. The speed of signal transmission via fungi within each ecosystem is much slower than that in humans, and therefore their organismal self-awareness may be of a different nature than the self-awareness that we associate with humans and upper primates. However, the possibility that our plant systems may be aware of the environmental insults that are being wrought upon them should make us reconsider our anthropocentric activities, as well as the possibility that humanity may need to collaborate with other intelligent non-human earth-based life forms to ensure mutual survival.}
}
@article{SHIVHARE2016243,
title = {On the Cognitive Process of Abstraction},
journal = {Procedia Computer Science},
volume = {89},
pages = {243-252},
year = {2016},
note = {Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.06.051},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916311164},
author = {Radhika Shivhare and Ch. Aswani Kumar},
keywords = {Abstraction, Cognitive Informatics, Concept Algebra, Formal Concept Analysis.},
abstract = {Concepts are the basic elements of propositions. Concepts can be best understood as constituted by its subset of objects (Extent) and subset of attributes (Intent). Psychological capacities of human mind for example, learning, thinking, memorizing can be performed by concepts and their association. In this paper, we will explain how human will be able to generalize concrete concepts of Formal Concept Analysis into abstract concepts. In particular, we model the functionalities of concept algebra by making use of Formal Concept Analysis; we illustrate the proposed model with experiments on sample context. This model simulates the thinking process of human mind.}
}
@article{CHIEN2009965,
title = {An efficient computational procedure for determining the container-loading pattern},
journal = {Computers & Industrial Engineering},
volume = {56},
number = {3},
pages = {965-978},
year = {2009},
note = {Intelligent Manufacturing and Logistics},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2008.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S036083520800226X},
author = {Chen-Fu Chien and Chia-Yen Lee and Yi-Chao Huang and Wen-Ting Wu},
keywords = {Global logistics, Container-loading, Cutting and packing, Three-dimension knapsack, Decision support system},
abstract = {Supply chain and global logistics are driven by strategically focusing on core competences, outsourcing manufacturing to pursue higher value proposition in the supply chain, radically improving the return of capital investments and providing total solutions to targeted customers. The container-loading research has important industrial and commercial application for global logistics. In practice, loading pooled shipment into containers is a complex procedure that has relied largely on the workers’ experience. We developed an efficient computational procedure involving three-dimensional cutting for determining near-optimal container-loading patterns to minimize the waste of container space. We used numerical examples from a motor company that imports key components from Japan, produces parts in Taiwan, and assembles cars in China to estimate its validity and discussed the effectiveness of the proposed solution. This study concludes with a discussion of future research.}
}
@incollection{MEDINAFRANCO2015455,
title = {Chapter 21 - Discovery and Development of Lead Compounds from Natural Sources Using Computational Approaches},
editor = {Pulok K. Mukherjee},
booktitle = {Evidence-Based Validation of Herbal Medicine},
publisher = {Elsevier},
address = {Boston},
pages = {455-475},
year = {2015},
isbn = {978-0-12-800874-4},
doi = {https://doi.org/10.1016/B978-0-12-800874-4.00021-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128008744000210},
author = {José L. Medina-Franco},
keywords = {Chemical space, Chemoinformatics, Computer-aided drug design, Dietary components, Drug discovery, Molecular diversity, Pharmacological profiling, Structure–activity relationships, Target fishing, Virtual screening},
abstract = {This chapter discusses the synergy between natural product-based drug discovery and methods used in computer-aided drug design. For centuries, Nature has been the source of compounds that are currently in the clinic or that have been used as molecular probes to identify therapeutic targets. In addition, Nature has inspired the development of a significant number of pharmaceutical agents. In contrast, computational approaches applied to drug discovery date back to only a few decades. Nonetheless, computational methods are evolving at an impressive speed and are making significant contributions to identifying and developing bioactive compounds of therapeutic relevance. Computational methods have a broad range of applications in natural product research including the organization and comprehensive analysis of molecular databases, systematic screening of natural products libraries, computer-aided optimization of lead compounds, and identification of biological activities for natural products of dietary origin.}
}
@incollection{HANSKORTELING2022610,
title = {Cognitive Biases},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {610-619},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.24105-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245241059},
author = {J.E. {(Hans) Korteling} and Alexander Toet},
keywords = {Cognitive biases, Cognitive neuroscience, Decision making, Dual process theory, Expertise, Evolutionary psychology, Heuristics, Information processing capacity, Intuition, Neural networks, Rationality},
abstract = {Cognitive biases are systematic cognitive dispositions or inclinations in human thinking and reasoning that often do not comply with the tenets of logic, probability reasoning, and plausibility. These intuitive and subconscious tendencies are at the basis of human judgment, decision making, and the resulting behavior. Psychological frameworks consider biases as resulting from the use of (inappropriate) cognitive heuristics that people apply to deal with data-limitations, from information processing limitations, or from a lack of expertise. Neuro-evolutionary frameworks provide a more profound explanation of biases as originating from the inherent design characteristics of our brain as a neural network that was primarily developed to perform basic physical, perceptual and motor functions, and which also had to promote the survival of our hunter-gatherer ancestors.}
}
@article{PEREZ2008755,
title = {A computational evaluation of the effect of intramedullary nail material properties on the stabilization of simulated femoral shaft fractures},
journal = {Medical Engineering & Physics},
volume = {30},
number = {6},
pages = {755-760},
year = {2008},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2007.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1350453307001567},
author = {Angel Perez and Andrew Mahar and Charles Negus and Peter Newton and Tom Impelluso},
keywords = {Finite element method, Simulated pediatric femur fractures, Intramedullary nails, Biomechanical stability},
abstract = {Titanium flexible intramedullary nails have become far more prevalent for stabilization of pediatric femur fractures in recent years. While steel may be expected to have superior fracture stability due to its higher elastic modulus; titanium alloy has experimentally demonstrated improved biomechanical stability, as measured by gap closure and nail slippage. The purpose of this study was to verify these observations computationally, and thus, explain why titanium alloy may be better suited for surgical fixation of fractured femurs. A finite element model of a femur with complete mid-diaphyseal fracture and having two 3.5mm nails in a retrograde “C” pattern was created. Static analyses were run in which the nail material properties were titanium alloy or stainless steel, respectively. Gap closure for the stainless steel nails was 1.03mm; while the titanium alloy nails had 0.69mm of closure. Titanium alloy nails slipped slightly less at each loading increment than stainless steel nails. The titanium alloy nails distributed stress more evenly along the nail axis, resulting in lower peak magnitudes. These results agree with previously published clinical and biomechanical studies that reported increased gap closure and nail slippage with stainless steel nails. The increased deformation of the titanium alloy nail likely increases the contact area with the intramedullary canal wall, thus, increasing stability. Additionally, stainless steel nails had higher curve apex von Mises stresses, potentially inducing a stress-shielding effect which could hamper remodeling and consequently increase risk of re-fracture.}
}
@article{FU2024107632,
title = {Dissecting behavioral inertia in shaping different resident participation behaviors in neighborhood regeneration: A quantitative behavioral experiment},
journal = {Environmental Impact Assessment Review},
volume = {109},
pages = {107632},
year = {2024},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2024.107632},
url = {https://www.sciencedirect.com/science/article/pii/S0195925524002191},
author = {Xinyue Fu and Guiwen Liu and Hongjuan Wu and Taozhi Zhuang and Ruopeng Huang and Fanning Yuan and Yuhang Zhang},
keywords = {Neighborhood regeneration, Resident participation, Behavioral inertia, Behavioral experiment},
abstract = {Research on resident participation in neighborhood regeneration provides valuable insights for urban policymakers in environmental governance. While previous studies have extensively examined various influencing factors, they often neglect the impact of behavioral inertia. To address this gap, this study conducts a behavioral experiment to quantitatively assess the presence and impact of behavioral inertia on residents' governance and financial participation behaviors. A total of 576 valid survey questionnaires were collected, and conditional logit model and ordered logit model were utilized for analysis. The study reveals that behavioral inertia is indeed observable in residents' governance participation and financial participation behaviors. Furthermore, the findings underscore distinct drivers of behavioral inertia for these two types of participation behaviors, with emotional reactions predominantly influencing governance participation, while short-term thinking largely shapes financial participation. Theoretically, this study uses the innovative concept of “behavioral inertia” to offer a new explanatory framework for aspects of behavior that cannot be solely explained by the attributes of regeneration plans. Furthermore, the behavioral experiments utilized in this study exemplify how the research framework of behavioral science can be applied to the study of urban governance in a broad context internationally. Practically, the research findings provide valuable insights for urban policymakers to tailor measures aimed at promoting resident participation and fostering sustainable urban development.}
}
@article{PAUSELLI201874,
title = {Computational linguistic analysis applied to a semantic fluency task to measure derailment and tangentiality in schizophrenia},
journal = {Psychiatry Research},
volume = {263},
pages = {74-79},
year = {2018},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2018.02.037},
url = {https://www.sciencedirect.com/science/article/pii/S0165178117309824},
author = {Luca Pauselli and Brooke Halpern and Sean D. Cleary and Benson S. Ku and Michael A. Covington and Michael T. Compton},
keywords = {Automatic Data Processing, Formal Thought Disorder, Psychosis, Schizophrenia, Semantics, Semantic Fluency Tasks},
abstract = {Although rating scales to assess formal thought disorder exist, there are no objective, high-reliability instruments that can quantify and track it. This proof-of-concept study shows that CoVec, a new automated tool, is able to differentiate between controls and patients with schizophrenia with derailment and tangentiality. According to ratings from the derailment and tangentiality items of the Scale for the Assessment of Positive Symptoms, we divided the sample into three groups: controls, patients without formal thought disorder, and patients with derailment/tangentiality. Their lists of animals produced during a one-minute semantic fluency task were processed using CoVec, a newly developed software that measures the semantic similarity of words based on vector semantic analysis. CoVec outputs were Mean Similarity, Coherence, Coherence-5, and Coherence-10. Patients with schizophrenia produced fewer words than controls. Patients with derailment had a significantly lower mean number of words and lower Coherence-5 than controls and patients without derailment. Patients with tangentiality had significantly lower Coherence-5 and Coherence-10 than controls and patients without tangentiality. Despite the small samples of patients with clinically apparent thought disorder, CoVec was able to detect subtle differences between controls and patients with either or both of the two forms of disorganization.}
}
@article{CEKMIS2014115,
title = {A computational model for accommodating spatial uncertainty: Predicting inhabitation patterns in open-planned spaces},
journal = {Building and Environment},
volume = {73},
pages = {115-126},
year = {2014},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2013.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S0360132313003430},
author = {Aslı Çekmiş and Işıl Hacıhasanoğlu and Michael J. Ostwald},
keywords = {Fuzzy logic, Fuzzy set, Spatial uncertainty, Occupancy prediction, Open-planned spaces},
abstract = {In the past, a range of computational models have been developed for analysing the social implications of spatial patterns and types. While such models are typically focussed on macro-patterns, often in cellular or linearly-organised spaces, few models exist for predicting where people will cluster within complex environments. One reason for this relates to the inherent uncertainty associated with spatial attributes and consequently of human spatial behaviours. The present paper draws on the concept of fuzzy spatial objects to develop an approach to handle such uncertainty in architecture. Focussing on large, open plan spaces, where the configuration of space does not define strict patterns of usage, the paper proposes a computational model for predicting patterns of spatial inhabitation. This new model relies on the theory of fuzzy sets to propose the existence of a “fuzzy architectural spatial object, (FASO)” which is comprised of spatial units with degrees of membership that reflect the possibility of a person being present in a sub-space or involved in a sub-function within a larger space. This model calculates and visualises the FASOs using a fuzzy inference engine and represents the space as distributed possibilities of presence according to the given data. After describing the model the paper demonstrates its application in the prediction of patterns of usage within a major exhibition space, and then presents a check of the efficacy of this prediction against the actual inhabitation of the space.}
}
@article{HAN2020106264,
title = {A new computational model based on Archimedean copula for probabilistic unbalanced linguistic term set and its application to multiple attribute group decision making},
journal = {Computers & Industrial Engineering},
volume = {140},
pages = {106264},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.106264},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219307338},
author = {Bing Han and Zhifu Tao and Huayou Chen and Ligang Zhou and Jinpei Liu},
keywords = {Multiple attribute group decision making, Probabilistic unbalanced linguistic term set, Archimedean copula, Weighted average aggregation operator},
abstract = {This paper proposes the concept of the probabilistic unbalanced linguistic term set which considers not only the probability of linguistic variables but also the non-uniform and non-symmetric distribution of linguistic labels. A new computational model on basis of Archimedean copula and corresponding co-copula is developed to deal with probabilistic unbalanced linguistic information. The most advantage of the model is that it can keep the closure of the operation. Some operational properties and particular cases are further investigated. We present the concepts of Archimedean copula weighted probabilistic unbalanced linguistic arithmetic average aggregation operator and Archimedean copula weighted probabilistic unbalanced linguistic geometric average aggregation operator, some properties are also discussed. Finally, the effectiveness and universality of the developed approach are illustrated by a hospital selection and comparison analysis. A sensitivity analysis is also performed to test the robustness of proposed methods.}
}
@article{MINOZZI2020101498,
title = {Direct response and the strategy method in an experimental cheap talk game},
journal = {Journal of Behavioral and Experimental Economics},
volume = {85},
pages = {101498},
year = {2020},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2019.101498},
url = {https://www.sciencedirect.com/science/article/pii/S2214804319300230},
author = {William Minozzi and Jonathan Woon},
keywords = {Strategic information transmission, Sender-receiver games, Strategy method, Laboratory experiment},
abstract = {In cheap talk games, equilibrium analysis predicts extreme limits on the information that can be transmitted when senders and receivers have different goals. Yet experimental evidence suggests that senders overcommunicate relative to this baseline, revealing more information than predicted in equilibrium. We propose that overcommunication may be due in part to limited cognitive engagement by subjects, captured by level-k thinking. To test this conjecture, we compare two elicitation methods, direct response and the strategy method, holding other elements of the game fixed. Existing experimental studies of cheap talk games use the standard direct response method, while the strategy method—in which subjects make selections for all contingent choices—is believed to encourage more thoughtful decisionmaking. We therefore expect senders to transmit less information with the strategy method than with direct response. In contrast, we find the reverse: the strategy method increased overcommunication. Further examination suggests that this occurred because senders played more naïvely with the strategy method than with direct response. Our findings suggest that the strategy method and direct response do not elicit the same choices in cheap talk games.}
}
@article{CHARPENTIER20163365,
title = {Sensitivity computations in higher order continuation methods},
journal = {Applied Mathematical Modelling},
volume = {40},
number = {4},
pages = {3365-3380},
year = {2016},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2015.10.033},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X15006952},
author = {Isabelle Charpentier and Komlanvi Lampoh},
keywords = {Continuation, Homotopy, Sensitivity, Automatic differentiation, Diamant, Complex nonlinear eigenvalue problem,},
abstract = {Sensitivity analysis is a key tool in the study of the relationships between the input parameters of a model and the output solution. Although sensitivity analysis is extensively addressed in the literature, little attention has been brought to the methodological aspects of the sensitivity of nonlinear parametric solutions computed through a continuation technique. This paper proposes four combinations of sensitivity analysis with continuation and homotopy methods, including sensitivity analysis along solution branches or at a particular point. Theoretical aspects are discussed in the higher order continuation framework Diamant. The sensitivity methods are applied to a thermal ignition problem and some free vibration problems. Remarkable eigenvalue maps are produced for the complex nonlinear eigenvalue problems.}
}
@article{WIECHERT20031363,
title = {The role of modeling in computational science education},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1363-1374},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00093-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000931},
author = {W. Wiechert},
keywords = {Computational science education, Modeling and simulation, Modeling education},
abstract = {Modeling and simulation skills are two core competences of computational science and thus should be a central part of any curriculum. While there is a well-founded methodology for the design of simulation algorithms today the teaching of modeling skills carries some intrinsic problems. The reason is that modeling is still partly an art and partly a science. As an important consequence for university education, the concepts for teaching modeling must be quite different from those for teaching simulation algorithms. Experiences made with the courses on ‘Modeling and Simulation’ at the University of Siegen are summarized and some general concepts for the teaching of modeling skills are presented. In particular, three practical approaches to modeling education are discussed with several examples.}
}
@article{MCCREADY2010274,
journal = {Journal of Pragmatics},
volume = {42},
number = {1},
pages = {274-278},
year = {2010},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2009.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0378216609001532},
author = {Elin McCready}
}
@article{FERNANDEZCABALLERO2003341,
title = {Lateral interaction in accumulative computation: a model for motion detection},
journal = {Neurocomputing},
volume = {50},
pages = {341-364},
year = {2003},
issn = {0925-2312},
doi = {https://doi.org/10.1016/S0925-2312(02)00571-4},
url = {https://www.sciencedirect.com/science/article/pii/S0925231202005714},
author = {Antonio Fernández-Caballero and José Mira Mira and Ana E. Delgado and Miguel A. {Fernández Graciani}},
keywords = {Accumulative computation, Lateral interaction, Double time scale, Motion detection, Image sequences},
abstract = {Some of the major computer vision techniques make use of neural nets. In this paper we present a novel model based on neural networks denominated lateral interaction in accumulative computation (LIAC). This model is based on a series of neuronal models in one layer, namely the local accumulative computation model, the double time scale model and the recurrent lateral interaction model. The LIAC model usefulness in the general task of motion detection may be appreciated by means of some significant examples of object detection in indefinite sequences of synthetic and real images.}
}
@article{LOU2022100247,
title = {Two-additive fuzzy measure-based information integration approach to product design alternative evaluation},
journal = {Journal of Industrial Information Integration},
volume = {25},
pages = {100247},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100247},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000467},
author = {Shanhe Lou and Yixiong Feng and Zhiwu Li and Jianrong Tan},
keywords = {Multi-criteria decision-making, Two-additive fuzzy measure, Information integration, Intuitionistic linguistic number},
abstract = {Conceptual design is a pivotal stage of new product development in manufacturing industries. Since multiple design alternatives are put forward at this stage, developing advanced evaluation methods is of great importance. Existing methods adopt additive models to integrate evaluation data. They face some inconsistency issues, e.g. inconsistency in the independent assumption and interdependent data, since evaluation criteria are interactional. Fuzzy measure that replaces the additivity with monotonicity has enabled advances in addressing such issues. This work proposes a two-additive fuzzy measure-based information integration approach to product design alternative evaluation for the first time. The evaluation data given by experts are in the form of intuitionistic linguistic numbers. They are more in accordance with the thinking habits of experts because the hesitation degree in linguistic assessment can be revealed. In order to reduce the subjective bias, the decision-making trial and evaluation laboratory method combining with grey relational analysis is applied to adjust evaluation data. Then monotonous two-additive fuzzy measure is identified by nonlinear programming using these data. It makes a good trade-off between computational complexity and presentation capability. Hence, evaluation data can be integrated by non-additive Choquet integral for ranking design alternatives. In comparison to additive model-based methods, the extra effect on the simultaneous satisfaction of criteria can be effectively revealed by the proposed approach. And the robustness of it is demonstrated by the sensitivity analysis. A case study on an elevator's design alternative evaluation is conducted to illustrate the feasibility and practicability of the proposed approach.}
}
@article{QUAN20196515,
title = {Smart Design for Sustainable Neighborhood Development},
journal = {Energy Procedia},
volume = {158},
pages = {6515-6520},
year = {2019},
note = {Innovative Solutions for Energy Transitions},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.01.108},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219301183},
author = {Steven Jige Quan},
keywords = {Smart Design, Sustainable Neighborhood Development, Design Decision Making, Multi-objective Optimization, Genetic Algorithms, Pareto optimal},
abstract = {This study proposes the Smart Design method to support the design decision making in the sustainable neighborhood development with multiple objectives. Instead of the “creative design” approach in the scenario making in traditional PSS and recent Geodesign frameworks, the Smart Design method applies the optimization algorithms to search for optimal design solutions in the design space. It integrates the design thinking, computational performance modeling and optimization techniques to efficiently and effectively approximate optimal designs. This method is applied to a hypothetical residential neighborhood design case study with three sustainability objectives: to maximize FAR, to minimize building energy use, and to minimize outdoor human discomfort. Based on the form parameterization, the Nondominated Sorting Genetic Algorithm II (NSGA-II) algorithm is utilized to guide the evolution of the neighborhood design throughout 80 generations, with neighborhood performance modeling tools. The Smart Design method is able to identify 38 representative design solutions as Pareto optimal which are equally optimal. Those solutions set a basis for discussions and negotiations among stake holders to make design decisions with the three objectives. Further research will be focused on addressing the challenges such as recursive objective definitions, parametrization of complex forms, quantification of performances and optimization uncertainties, from simple cases to more realistic and complex designs for sustainable neighborhood development.}
}
@article{REGGIO2002459,
title = {Computational analysis of the process for manufacturing seamless tubes},
journal = {Applied Thermal Engineering},
volume = {22},
number = {4},
pages = {459-470},
year = {2002},
issn = {1359-4311},
doi = {https://doi.org/10.1016/S1359-4311(01)00093-X},
url = {https://www.sciencedirect.com/science/article/pii/S135943110100093X},
author = {M. Reggio and F. McKenty and Luc Gravel and J. Cortes and G. Morales and M.-A. {Ladron de Guevara}},
keywords = {Seamless tube, Heat transfer, Computational simulation, CFD},
abstract = {A computer simulation of the transient three-dimensional heat transfer process occurring during the manufacturing of seamless tubes carried out by TAMSA, Tubos de Acero de Mexico, is reported. The work was performed by a team which combines Canadian and Mexican researchers and comprises both experimental and computational aspects. The Mexican team concentrated its efforts on experimentally investigating the metallurgical pattern of the mandrel, while the Canadian team devoted its time to the computer simulation and analysis of heat transfer and flow processes. In this paper, only the latter part is presented. The numerical simulation uses the Star-CD commercial CFD software package which is based on the finite volume methodology. The results show the importance of the cooling water channel configuration in relation to the mandrel temperature distribution and resulting metallurgical structure.}
}
@article{SWANSON201854,
title = {How failure is productive in the creative process: Refining student explanations through theory-building discussion},
journal = {Thinking Skills and Creativity},
volume = {30},
pages = {54-63},
year = {2018},
note = {The Role of Failure in Promoting Thinking Skills and Creativity},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187117301785},
author = {Hillary Swanson and Allan Collins},
keywords = {Knowledge in pieces, Microgenetic learning analysis, Knowledge construction, Constructivist instruction, Science learning, Creative thinking, Critical thinking, Creative problem solving},
abstract = {We argue that failure can play a productive role in students’ creative knowledge-construction process. As evidence, we present a fine-grained analysis of a whole-class theory-building discussion with 8th grade students. The goal of the discussion was to construct a theoretical account for why a glass of cold milk warmed quickly at first and then more slowly as it approached room temperature. Though they initially produced scientifically non-normative explanations, by the end of the discussion the class had refined their ideas into an explanation of difference drives rate – a relationship at the heart of Newton’s law of heating and other equilibration phenomena. The students’ flawed initial explanations were productive in the knowledge-construction process, as the raw material they ultimately refined into a more scientific explanation. We argue that the theory-building discussion supported both creative and critical thinking and that this pedagogical approach has the power, more generally, to leverage failure productively for science learning.}
}
@incollection{ROZINAJOVA201823,
title = {Chapter 2 - Computational Intelligence in Smart Grid Environment},
editor = {Arun Kumar Sangaiah and Michael Sheng and Zhiyong Zhang},
booktitle = {Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications},
publisher = {Academic Press},
pages = {23-59},
year = {2018},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-12-813314-9},
doi = {https://doi.org/10.1016/B978-0-12-813314-9.00002-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128133149000025},
author = {Viera Rozinajová and Anna Bou Ezzeddine and Marek Lóderer and Jaroslav Loebl and Róbert Magyar and Petra Vrablecová},
keywords = {Smart grid, Intelligent data analysis, Computational intelligence, Power load prediction, Optimization, Bio-inspired algorithms, Ensemble models, Support vector regression},
abstract = {This chapter presents one way of incorporating computational intelligence into smart grid environment. We introduce an energy ecosystem, where contemporary technologies are used and by involving advanced methods of data analysis and optimization, we aim to ensure its effective operation. In order to schedule reliable energy supply, the prediction models for power load consumption and for energy spot prices are inevitable. We provide an overview of forecasting and optimization methods and propose solutions, which deal with stream and online processing as well as adaptivity of the proposed solutions. Several different prediction methods including statistical methods and computational intelligence methods, as well as our proposed ensemble and online SVR method are compared. We take into account the current trends of distributed energy generation from renewable sources and anticipate massive usage of electro vehicles in the near future, where the optimization of the whole environment is needed.}
}
@article{SHAHID2019638,
title = {Computational intelligence techniques for medical diagnosis and prognosis: Problems and current developments},
journal = {Biocybernetics and Biomedical Engineering},
volume = {39},
number = {3},
pages = {638-672},
year = {2019},
issn = {0208-5216},
doi = {https://doi.org/10.1016/j.bbe.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0208521619300452},
author = {Afzal Hussain Shahid and M.P. Singh},
keywords = {Computational intelligence, Disease diagnosis, Prediction, Detection, Uncertainty, Medical data},
abstract = {Diagnosis, being the first step in medical practice, is very crucial for clinical decision making. This paper investigates state-of-the-art computational intelligence (CI) techniques applied in the field of medical diagnosis and prognosis. The paper presents the performance of these techniques in diagnosing different diseases along with the detailed description of the data used. This paper includes basic as well as hybrid CI techniques that have been used in recent years so as to know the current trends in medical diagnosis domain. The paper presents the merits and demerits of different techniques in general as well as application specific context. This paper discusses some critical issues related to the medical diagnosis and prognosis such as uncertainties in the medical domain, problems in the medical data especially dealing with time-stamped (temporal) data, and knowledge acquisition. Moreover, this paper also discusses the features of good CI techniques in medical diagnosis. Overall, this review provides new insight for future research requirements in the medical diagnosis domain.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@article{RIZZI20131,
title = {Introduction: Core computational principles in natural language syntax},
journal = {Lingua},
volume = {130},
pages = {1-13},
year = {2013},
note = {SI: Syntax and cognition: core ideas and results in syntax},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0024384112002756},
author = {Luigi Rizzi}
}
@incollection{JOHNSON2009137,
title = {Embodied cognition of movement decisions: a computational modeling approach},
editor = {Markus Raab and Joseph G. Johnson and Hauke R. Heekeren},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {174},
pages = {137-150},
year = {2009},
booktitle = {Mind and Motion: The Bidirectional Link between Thought and Action},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(09)01312-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079612309013120},
author = {Joseph G. Johnson},
keywords = {attention, decision making, motor system},
abstract = {This chapter presents a cognitive computational view of decision making as the search for, and accumulation of, evidence for options under consideration. It is based on existing models that have been successful in traditional decision tasks involving preferential choice. The model assumes shifting attention over time that determines momentary inputs to an evolving preference state. In this chapter, the cognitive model is extended to illustrate how links from the motor system may be incorporated. These links can basically be categorized into one of three influences: modifying the subjective evaluation of choice options, restricting attention, and altering the options that are to be found in the choice set. The implications for the formal model are introduced and preliminary evidence is drawn from the extant literature.}
}
@article{SAMARASINGHE2013188,
title = {Mixed-method integration and advances in fuzzy cognitive maps for computational policy simulations for natural hazard mitigation},
journal = {Environmental Modelling & Software},
volume = {39},
pages = {188-200},
year = {2013},
note = {Thematic Issue on the Future of Integrated Modeling Science and Technology},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2012.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364815212001909},
author = {Sandhya Samarasinghe and Graham Strickert},
keywords = {Fuzzy cognitive maps, Auto-Associative Neural Networks, Self-organizing maps, Natural hazard mitigation, Earthquakes, Mixed-method triangulation, Policy simulation},
abstract = {Human systems need to be adaptive to the consequences of natural hazards. Public policy decisions on natural hazard mitigation can benefit from computational models that embody a comprehensive view of the system. Such models need to be transparent and integrate both expert and lay expert knowledge and experience in an efficient manner. By integrating hard and soft sciences within an overall systems framework, scientists, policy makers and communities can better understand how to improve adaptive capacity. We present a fuzzy cognitive map based Auto-Associative Neural Networks framework generated from a development mixed method integration (triangulation) for adaptive policy formulations. The specific policies relate to preparation for, response to, and recovery from earthquakes in mountainous ski-field environments – a case study chosen to highlight the framework. Three different data collection techniques – expert geomorphic assessments, semi-structured qualitative interviews with three stakeholder groups (experts and lay experts), and fuzzy cognitive maps (FCM) (node and arc maps of stakeholder perceptions) were employed. FCM were first analysed using Graph theory indices to determine map structure. Special attention was paid to subsequent processing of fuzzy cognitive maps (e.g., condensation and aggregation) with qualitative followed by quantitative means to simplify the FCM from the original total of 300 variables to 5 high-level themes to improve the efficacy of subsequent policy simulations. Specifically, the use of Self Organising Maps (SOM) to group concepts (condensation) and individual stakeholders (aggregation) into social group FCMs is a novel contribution to advancing FCM. In the process, SOM also enabled the embedment of nonlinear relationships inherent in the system in the simplified FCM allowing a platform for realistic and meaningful policy simulations based on collective perceptions. Specifically, each of the three simplified stakeholder group FCM and a total social group FCM was represented by Auto-Associative Neural Networks (AANN) which converts an FCM into a dynamical system that allows policy scenario simulations based on input from both expert and lay expert stakeholders. A policy scenario is the level of importance given to a set of concepts and their effects on the system behaviour as revealed by the simulations. We present the results from one of several policy simulations to highlight the effectiveness of the mixed-method integration leading to simplified-FCM based ANNN simulations. Results revealed the similarities and differences between stakeholder group responses in relation to the scenario analysed and how these formed collective responses in the total social group map. Furthermore, outcomes of group and total social group simulations could be interpreted from individual and group stakeholder FCMs giving credibility to the mixed-method approach.}
}
@article{MAIRAL202262,
title = {What should the university of the future look like?},
journal = {On the Horizon},
volume = {31},
number = {1},
pages = {62-70},
year = {2022},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-08-2022-0050},
url = {https://www.sciencedirect.com/science/article/pii/S1074812122000239},
author = {Ricardo Mairal},
keywords = {Employment, Internationalization, Higher education, Quality, Artificial intelligence, Online and distance education},
abstract = {Purpose
In this paper, the author has tried to outline the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general.
Design/methodology/approach
The author has revised some of the major issues that are going to determine the direction of the university of the future, i.e. the employment opportunities of tomorrow; the role of new technologies, especially the impact of artificial intelligence (AI); quality in higher education; and internationalization.
Findings
The author has also pointed out the importance of the technologies and the great role they indisputably play in present and future education at all levels, a fact that has been particularly and hugely enhanced and promoted by the COVID-19 pandemic situation, thereby facilitating and fostering distance learning. This is very much connected to the application of AI to higher education, another unavoidable issue of utmost importance for the university of the future. While these technological advances present a challenge to universities, which must determine which are necessary and desirable and how to implement them, it is, ultimately, our responsibility to use them, in an ethical way, to the benefit of our students. The university of the future also has to be of high quality, and this involves carrying out important and decisive action having to do with matters of inclusion, hiring policies and the expansion of international opportunities for all parties involved.
Originality/value
This paper outlines the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general. Moreover, the role of new technologies (especially the impact of AI), quality and internationalization are also discussed as relevant factors in this view of the university of the future.}
}
@article{KONOPKA200391,
title = {Selected dreams and nightmares about computational biology},
journal = {Computational Biology and Chemistry},
volume = {27},
number = {2},
pages = {91-92},
year = {2003},
issn = {1476-9271},
doi = {https://doi.org/10.1016/S1476-9271(03)00024-0},
url = {https://www.sciencedirect.com/science/article/pii/S1476927103000240},
author = {Andrzej K Konopka}
}
@article{LASAPONARA202460,
title = {Temperament and probabilistic predictive coding in visual-spatial attention},
journal = {Cortex},
volume = {171},
pages = {60-74},
year = {2024},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2023.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010945223002599},
author = {Stefano Lasaponara and Gabriele Scozia and Silvana Lozito and Mario Pinto and David Conversi and Marco Costanzi and Tim Vriens and Massimo Silvetti and Fabrizio Doricchi},
keywords = {Attention, Temperament, Personality, Posner task, Neurotransmitters},
abstract = {Cholinergic (Ach), Noradrenergic (NE), and Dopaminergic (DA) pathways play an important role in the regulation of spatial attention. The same neurotransmitters are also responsible for inter-individual differences in temperamental traits. Here we explored whether biologically defined temperamental traits determine differences in the ability to orient spatial attention as a function of the probabilistic association between cues and targets. To this aim, we administered the Structure of Temperament Questionnaire (STQ-77) to a sample of 151 participants who also performed a Posner task with central endogenous predictive (80 % valid/20 % invalid) or non-predictive cues (50 % valid/50 % invalid). We found that only participants with high scores in Plasticity and Intellectual Endurance showed a selective abatement of attentional costs with non-predictive cues. In addition, stepwise regression showed that costs in the non-predictive condition were negatively predicted by scores in Plasticity and positively predicted by scores in Probabilistic Thinking. These results show that stable temperamental characteristics play an important role in defining the inter-individual differences in attentional behaviour, especially in the presence of different probabilistic organisations of the sensory environment. These findings emphasize the importance of considering temperamental and personality traits in social and professional environments where the ability to control one's attention is a crucial functional skill.}
}
@incollection{LEBARON20061187,
title = {Chapter 24 Agent-based Computational Finance},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1187-1233},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02024-1},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020241},
author = {Blake LeBaron},
keywords = {learning, evolutionary finance, financial time series, asset pricing, efficient markets, behavioral finance, market microstructure, genetic algorithms, neural networks, artificial financial markets, evolutionary computation},
abstract = {This chapter surveys research on agent-based models used in finance. It will concentrate on models where the use of computational tools is critical for the process of crafting models which give insights into the importance and dynamics of investor heterogeneity in many financial settings.}
}
@article{CRONIN2022100987,
title = {Analysis of tutors’ responses to students’ queries in a second linear algebra course at a mathematics support center},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100987},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100987},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000554},
author = {Anthony Cronin and Sepideh Stewart},
keywords = {Mathematics tutors, Second courses in linear algebra, Mathematics support center, Feedback, Tutors’ tactics, Advanced mathematical thinking},
abstract = {This paper analyses six years of tutor feedback produced after inquiries made by students in a second linear algebra course at a university mathematics support center (MSC). We utilized Mason’s (2002) pedagogical tactics to build a model to analyze MSC tutors' feedback responding to these students’ queries. The aim of this research was to investigate the nature of students’ difficulties with concepts in a second linear algebra course that emphasizes theories and proof, in addition to examining the tactics employed by tutors to resolve student difficulties. We analyzed 227 feedback comments from 44 tutors based on their interactions with 82 students over six years. Our findings indicated that the most common areas of difficulty were basis, vector space, subspace, span, and proof. Tutor tactics deployed included ‘being mathematical’, ‘simplifying and complexifying’, and ‘worked examples’. We also discuss some implications for linear algebra tutor training.}
}
@article{CASTRO20242377,
title = {Product Customization based on Digital Twin and Cloud Manufacturing within a Decentralized Production System},
journal = {Procedia Computer Science},
volume = {239},
pages = {2377-2384},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924016752},
author = {Hélio Castro and Fernando Câmara and Paulo Ávila and Luís Ferreira and Manuela Cruz-Cunha},
keywords = {Industry 4.0, Digital Twin, Cyber-Physical System, Smart Factory, Product Customization, Cloud Manufacturing},
abstract = {Industry 4.0 represents a turning point in the thinking of the production model since it is based on digitalized production systems with the aim of improving productivity, product quality, and delivery time to the customer. The digitalization and evolution of information technology allowed the emulation of production system virtual models, namely in the concept of Digital Twin (DT), with the ability to simulate different scenarios providing support for better decision making. This concept not only represents a virtual copy of the physical world that obtains information about the state of the value chain but also illustrates a system capable of changing the development of the production activity according to the fulfillment of the intended business goals. In literature, the concept of the Digital Twin is exhaustively treated as a stand-alone factory (one digital factory represents one physical factory) and underestimates the possibility of a DT oriented to a customized product (a project) that requires decentralized production systems. This paper brings to discussion the relevance of product customized applying DT to smart customization, and the inclusion of decentralized production systems supported by Cloud Manufacturing.}
}
@article{JOHNSON1997721,
title = {Observations with regard to massively parallel computation for Monte Carlo simulation of stochastic dynamical systems},
journal = {International Journal of Non-Linear Mechanics},
volume = {32},
number = {4},
pages = {721-734},
year = {1997},
note = {Third International Stochastic Structural Dynamics Conference},
issn = {0020-7462},
doi = {https://doi.org/10.1016/S0020-7462(96)00097-2},
url = {https://www.sciencedirect.com/science/article/pii/S0020746296000972},
author = {E.A. Johnson and S.F. Wojtkiewicz and L.A. Bergman and B.F. Spencer},
abstract = {The evolution of stochastic dynamical systems is governed by Fokker-Planck equations if the response process is Markovian. Analytical solutions for the transient response of multidimensional systems exist only for the simplest dynamical systems. The evolution of the transition probability density function over the phase space has been solved numerically for various low dimensional systems subjected to additive and multiplicative white noise excitations using the finite element method. Systems of higher order, however, pose difficulty when using standard finite element formulations due to memory requirements and computational expense. Direct Monte Carlo simulation (MCS), while often regarded as less elegant than other methods, can be used to solve problems of significantly higher complexity. The number of realizations required to accurately produce the transition probability density function over the entire phase space, especially in the tails, is large, but since each realization is entirely independent of the others, the Monte Carlo simulation is easily and efficiently adapted to parallel computation. The advent of high-speed, massively-parallel computers permits a large number of realizations of a complex dynamical system to be simultaneously determined. Consequently, Monte Carlo simulation may be more efficient for higher-dimensional systems than other solution methods currently in use. This investigation will examine some of these observations and compare the performance of MCS on various platforms, in the context of a four-dimensional linear oscillator and a Duffing oscillator subjected to band-limited white noise.}
}
@incollection{RUFFONI2017169,
title = {3.10 Finite Element Analysis in Bone Research: A Computational Method Relating Structure to Mechanical Function☆},
editor = {Paul Ducheyne},
booktitle = {Comprehensive Biomaterials II},
publisher = {Elsevier},
address = {Oxford},
pages = {169-196},
year = {2017},
isbn = {978-0-08-100692-4},
doi = {https://doi.org/10.1016/B978-0-12-803581-8.09798-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128035818097988},
author = {D. Ruffoni and G.H. {van Lenthe}},
keywords = {Bone imaging, Bone research, Computational modeling, Femur, Finite element analysis, Fracture, Hierarchical structure, Micro-computed tomography, Osteoporosis, Radius, Strength, Vertebra},
abstract = {Bone is probably the most frequently investigated biological material and finite element analysis (FEA) is the computational tool most commonly used for the analysis of bone biomechanical function. FEA has been used in bone research for more than 30 years and has had a substantial impact on our understanding of the complex behavior of bone. Bone is structured in a hierarchical way covering many length scales and this chapter reflects this hierarchical organization. In particular, the focus is on the applications of FEA for understanding the relationship between bone structure and its mechanical function at specific hierarchical levels. Depending on the hierarchical level, different issues have been investigated with FEA ranging from more clinically oriented topics related to bone quality (eg, predicting bone strength and fracture risk) to more fundamental problems dealing with the mechanical aspects of biological processes (eg, stress and strain around osteocyte lacunae) as well as with the micromechanical behavior of bone at its ultrastructure. A better understanding of the relationship between structure and mechanical function is expected to be important for the current trends in (bio)materials design, where the structure of biological materials is considered as a possible source of inspiration, as well as for more successful approaches in the prevention and treatment of age- and disease-related fractures.}
}
@article{IOANNIDOU2009236,
title = {AgentCubes: Incremental 3D end-user development},
journal = {Journal of Visual Languages & Computing},
volume = {20},
number = {4},
pages = {236-251},
year = {2009},
note = {Special Issue on Best Papers from VL/HCC2008},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2009.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X09000238},
author = {Andri Ioannidou and Alexander Repenning and David C. Webb},
keywords = {Incremental 3D, Game design, Visual programming, End-user development, IT fluency, Computational thinking},
abstract = {3D game development can be an enticing way to attract K-12 students to computer science, but designing and programming 3D games is far from trivial. Students need to achieve a certain level of 3D fluency in modeling, animation, and programming to be able to create compelling 3D content. The combination of innovative end-user development tools and standards-based curriculum that promotes IT fluency by shifting the pedagogical focus from programming to design, can address motivational aspects without sacrificing principled educational goals. The AgentCubes 3D game-authoring environment raises the ceiling of end-user development without raising the threshold. Our formal user study shows that with Incremental 3D, the gradual approach to transition from 2D to 3D authoring, middle school students can build sophisticated 3D games including 3D models, animations, and programming.}
}
@article{GARFIELD198447,
title = {Artificial intelligence: Using computers to think about thinking, Part 2: Some practical applications of Al},
journal = {Computer Compacts},
volume = {2},
number = {2},
pages = {47-53},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90041-6},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900416},
author = {Eugene Garfield}
}
@article{GOMEZCARRILLO2023296,
title = {Integrating neuroscience in psychiatry: a cultural–ecosocial systemic approach},
journal = {The Lancet Psychiatry},
volume = {10},
number = {4},
pages = {296-304},
year = {2023},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(23)00006-8},
url = {https://www.sciencedirect.com/science/article/pii/S2215036623000068},
author = {Ana Gómez-Carrillo and Laurence J Kirmayer and Neil Krishan Aggarwal and Kamaldeep S Bhui and Kenneth Po-Lun Fung and Brandon A Kohrt and Mitchell G Weiss and Roberto Lewis-Fernández},
abstract = {Summary
Psychiatry has increasingly adopted explanations for psychopathology that are based on neurobiological reductionism. With the recognition of health disparities and the realisation that someone's postcode can be a better predictor of health outcomes than their genetic code, there are increasing efforts to ensure cultural and social–structural competence in psychiatric practice. Although neuroscientific and social–cultural approaches in psychiatry remain largely separate, they can be brought together in a multilevel explanatory framework to advance psychiatric theory, research, and practice. In this Personal View, we outline how a cultural–ecosocial systems approach to integrating neuroscience in psychiatry can promote social–contextual and systemic thinking for more clinically useful formulations and person-centred care.}
}
@article{DIAS2007382,
title = {Philosophical grounding and computational formalization for practice based engineering knowledge},
journal = {Knowledge-Based Systems},
volume = {20},
number = {4},
pages = {382-387},
year = {2007},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2006.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950705106001675},
author = {W.P.S. Dias},
keywords = {Practice based knowledge, Connectionist AI techniques, Tacit knowing, Shared practice},
abstract = {Michael Polanyi’s idea of tacit knowing and Martin Heidegger’s concept of pre-theoretical shared practice are presented as providing a strong rationale for the notion of practice based knowledge. Artificial Intelligence (AI) approaches such as Artificial Neural Networks (ANN), Case Based Reasoning (CBR) and Grounded Theory (with Interval Probability Theory) are able to model these philosophical concepts related to practice based knowledge. The AI techniques appropriate for modeling Polanyi’s and Heidegger’s ideas should be founded more on a connectionist rather than a cognitivist paradigm. Examples from engineering practice are used to demonstrate how the above techniques can capture, structure and make available such knowledge to practitioners.}
}
@incollection{SIEGLER20051,
title = {A computational model of conscious and unconscious strategy discovery},
editor = {Robert V. Kail},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {33},
pages = {1-42},
year = {2005},
issn = {0065-2407},
doi = {https://doi.org/10.1016/S0065-2407(05)80003-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065240705800035},
author = {Robert Siegler and Roberto Araya},
abstract = {Publisher Summary
This chapter deals with a computational model of conscious and conscious strategy discovery and advocates a triangulation strategy for attaining a better understanding of change mechanisms. This triangulation strategy involves going back and forth among traditional studies of age-related change, microgenetic studies of children's gleaming, and computer simulations that generate the changes documented in the other two approaches. The chapter describes a new computational model of conscious and unconscious strategy discovery. Apart from being a crucial component of one of the examples of the triangulation strategy, this simulation significantly extends previous models of strategy choice and discovery. A large majority of studies of cognitive development have been devoted to describe age-related changes. The studies of age-related change have succeeded in providing excellent descriptions of many aspects of cognitive growth. Each of these three approaches—descriptions of age-related change, descriptions of learning, and formal modeling—provides unique information critical to a well-grounded account of developmental change.}
}
@article{DECARVALHO2021107887,
title = {A process for designing innovative mechatronic products},
journal = {International Journal of Production Economics},
volume = {231},
pages = {107887},
year = {2021},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107887},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320302504},
author = {Rogerio Atem {de Carvalho} and Henrique {da Hora} and Rodrigo Fernandes},
keywords = {Mechatronics, Product design, Design thinking, Concurrent engineering, Agilism, Product life cycle, Intellectual property, Innovation management},
abstract = {This article presents a process for the design of innovative mechatronic products that integrates techniques of Design Thinking, Concurrent Engineering and Agilism to Intellectual Property Management activities. Design Thinking is employed in the early stages in order to better explore creativity, whereas Concurrent Engineering and Agilism are applied during the development of the product, in order to deal with emerging requirements and shrinking development times. The product development process is accompanied by Intellectual Property Management activities that address the protection of the project's intellectual assets. In this way, the proposed process represents an addition to theory and practice by smoothly integrating the three most influential product design philosophies of today, while, at the same time, introduces a direction for managing intellectual assets throughout the product lifecycle.}
}
@article{GRETREGAMEY2024104978,
title = {Key factors to enhance efficacy of 3D digital environments for transformative landscape and urban planning},
journal = {Landscape and Urban Planning},
volume = {244},
pages = {104978},
year = {2024},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2023.104978},
url = {https://www.sciencedirect.com/science/article/pii/S0169204623002979},
author = {Adrienne Grêt-Regamey and Nora Fagerholm},
abstract = {The unprecedented expansion of digital technologies has led to a rapid increase in the development and application of 3D digital environments for landscape and urban planning in the past two decades. Considering the significant challenges in guiding human societies towards sustainability, these technologies must not only assist decision-makers in adapting to changes but promote fast, transformative shifts in the relationship between human societies and nature. Based on a set of global exemplars, this Perspective Essay outlines six key factors that can enhance efficacy of 3D digital environments to guide knowledge-informed landscape and urban planning. We call for (1) explicitly representing dynamic interplay between the social, ecological, and technical systems, (2) exploring the integration of design with simulation models to address cross-scale dynamics, (3) developing features to foster imagination, (4) employing multisensory stimuli to encourage profound changes in environmentally and socially sustainable behavior, (5) tailoring the incorporation of active sensing by and with non-experts into 3D digital environments to better acknowledge indigenous and local knowledge systems, and finally, (6) carrying out a usability evaluation to facilitate participation and collaboration in an efficient co-creation process. We conclude by recommending the establishment of a collaborative knowledge platform that unites researchers, developers, and stakeholders for stimulating social-ecological-technological system thinking in the development of 3D digital environments and harnessing the technological advancements to accelerate and drive the needed transformative change within urban and landscape planning.}
}
@article{YANG2000103,
title = {Computational verb systems: a new paradigm for artificial intelligence},
journal = {Information Sciences},
volume = {124},
number = {1},
pages = {103-123},
year = {2000},
issn = {0020-0255},
doi = {https://doi.org/10.1016/S0020-0255(99)00135-8},
url = {https://www.sciencedirect.com/science/article/pii/S0020025599001358},
author = {Tao Yang},
keywords = {Verbs, Computational verbs, Computational verb systems, Chaos, Artificial intelligence, Reasoning, Knowledge representation},
abstract = {Computational verb systems can help machines to implement, understand and use verbs as human perception of dynamics. By using computational verbs we can embed dynamical experiences of human experts into artificial intelligence. Computational verbs, which are models of verbs in nature languages, are basic building blocks of computational verb systems. In this paper, computational verbs are used to represent dynamical knowledge embedded by verbs as a new framework of knowledge representation. BE-transformations are used to transform statements containing dynamical verbs into statements only containing static verb BE; namely, BE-propositions. Based on BE-transformations, the computational verb logic can be built. Furthermore, reasoning with computational verbs can be built based on BE-transformations and basic verb logic operations.}
}
@article{SCHMALZL20031021,
title = {Using standard image compression algorithms to store data from computational fluid dynamics},
journal = {Computers & Geosciences},
volume = {29},
number = {8},
pages = {1021-1031},
year = {2003},
issn = {0098-3004},
doi = {https://doi.org/10.1016/S0098-3004(03)00098-0},
url = {https://www.sciencedirect.com/science/article/pii/S0098300403000980},
author = {Jörg Schmalzl},
keywords = {Computational fluid dynamics, Data compression, Visualization, Post-processing},
abstract = {Three-dimensional numerical modeling of fluid flows is an important research tool to understand many fluid dynamical effects observed in nature. With the strong growth of available computational resources the use of such models has greatly increased over the last years. Because the available mass storage has not increased in the same order as the CPU speed many researchers nowadays face the problem of how to store and transfer the large data sets produced by the model calculations for post-processing. The use of lossy wavelet-based compression techniques on this data has been investigated in several publications. These techniques are often specialized to one problem and are not easy to implement. In the area of digital media, however, advances have been made for still image (JPEG, JPEG-2000) and motion image (MPEG) compression. In this paper we investigate the usefulness of these image compression algorithms for the storage of data from computational fluid dynamics on regular cartesian grids. We analyze both the compression ratios achieved and the error introduced by these lossy compression schemes. We found that, for our purposes, the JPEG compression scheme allows an easy-to-use, portable, robust, and computationally efficient lossy compression. For the easy use of these compression algorithms we present a simple wrapper library.}
}
@article{BYTYQIDAMONI2024137516,
title = {Synthesis, characterization, and computational study of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives as metabolic enzyme inhibitors},
journal = {Journal of Molecular Structure},
volume = {1303},
pages = {137516},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137516},
url = {https://www.sciencedirect.com/science/article/pii/S0022286024000395},
author = {Arlinda Bytyqi-Damoni and Eda Mehtap Uc and Rıfat Emin Bora and Hayriye Genc Bilgicli and Mehmet Abdullah Alagöz and Mustafa Zengin and İlhami Gülçin},
keywords = {Carvacrol, Carbonic anhydrase, α-glucosidase, Acetylcholinesterase, Butyrylcholinesterase},
abstract = {Eight new 2-aminothiols (69–96%) and three new sulfonic acids (51–76%) were synthesized and characterized by NMR and HRMS spectra. This study presents the inhibitory effects of a series of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives (3a-f,4a-c) against human carbonic anhydrase I and II isozymes (hCA I and II) acetylcholinesterase (AChE), butyrylcholinesterase (BChE) and α-glycosidase. Ki values were calculated as 12.52±3.61–335.65±60.56 nM for hCA I, 12.20±3.59–389.69±119.41 nM for hCA II, 1.79±0.56–84.86±23.34 nM for AChE, 6.57±2.54–88.05±21.05 nM for BChE and 14.63±4.76–116.39±33.70 nM α-glucosidase enzymes. Also, the inhibition effects of novel carvacrol-based 2-aminothiol (3a-h) and sulfonic acid derivatives (4a-c) were compared to standard and clinically used inhibitors of acetazolamide, Tacrine and acarbose, respectively. Molecular modeling studies of novel compounds, docking scores, and free binding energies were calculated. The activity results of the compounds were found to be compatible with the docking scores. Molecular dynamics studies were conducted with the best activity against CA I and CA II compounds, 4b (IC50: 4.76 nM) and 4a (IC50: 4.36 nM), respectively. In Dynamic Simulation studies, it was observed that the compounds remained stable at the active sites of the proteins.}
}
@article{GILROY201643,
title = {Inherently irrational? A computational model of escalation of commitment as Bayesian Updating},
journal = {Behavioural Processes},
volume = {127},
pages = {43-51},
year = {2016},
note = {SQAB 2015: Choice and Consequences},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2016.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0376635716300389},
author = {Shawn P. Gilroy and Donald A. Hantula},
keywords = {Escalation, Computer simulation, Decision-making, Bayes theorem},
abstract = {Monte Carlo simulations were performed to analyze the degree to which two-, three- and four-step learning histories of losses and gains correlated with escalation and persistence in extended extinction (continuous loss) conditions. Simulated learning histories were randomly generated at varying lengths and compositions and warranted probabilities were determined using Bayesian Updating methods. Bayesian Updating predicted instances where particular learning sequences were more likely to engender escalation and persistence under extinction conditions. All simulations revealed greater rates of escalation and persistence in the presence of heterogeneous (e.g., both Wins and Losses) lag sequences, with substantially increased rates of escalation when lags comprised predominantly of losses were followed by wins. These methods were then applied to human investment choices in earlier experiments. The Bayesian Updating models corresponded with data obtained from these experiments. These findings suggest that Bayesian Updating can be utilized as a model for understanding how and when individual commitment may escalate and persist despite continued failures.}
}
@article{LITTRELL2020109678,
title = {Not so fast: Individual differences in impulsiveness are only a modest predictor of cognitive reflection},
journal = {Personality and Individual Differences},
volume = {154},
pages = {109678},
year = {2020},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2019.109678},
url = {https://www.sciencedirect.com/science/article/pii/S0191886919306105},
author = {Shane Littrell and Jonathan Fugelsang and Evan F. Risko},
keywords = {Cognitive reflection, Impulsiveness, Intuitive thinking, Delay discounting dual process},
abstract = {The extent to which a person engages in reflective thinking while problem-solving is often measured using the Cognitive Reflection Test (CRT; Frederick, 2005). Some past research has attributed poorer performance on the CRT to impulsiveness, which is consistent with the close conceptual relation between Type I processing and dispositional impulsiveness (and the putative relation between a tendency to engage in Type I processing and poor performance on the CRT). However, existing research has been mixed on whether such a relation exists. To address this ambiguity, we report two large sample size studies examining the relation between impulsiveness and CRT performance. Unlike previous studies, we use a number of different measures of impulsiveness, as well as measures of cognitive ability and analytic thinking style. Overall, impulsiveness is clearly related to CRT performance at the bivariate level. However, once cognitive ability and analytic thinking style are controlled, these relations become small and, in some cases, non-significant. Thus, dispositional impulsiveness, in and of itself, is not a strong predictor of CRT performance.}
}
@article{KADUWELA2024105337,
title = {Application of a human-centered design for embedded machine learning model to develop data labeling software with nurses: Human-to-Artificial Intelligence (H2AI)},
journal = {International Journal of Medical Informatics},
volume = {183},
pages = {105337},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105337},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623003556},
author = {Naomi A. Kaduwela and Susan Horner and Priyansh Dadar and Renee C.B. Manworren},
keywords = {Clinical decision support software, Data labeling, Human-centered Design for Embedded Machine Learning Solutions Machine Learning, Machine learning models},
abstract = {Background
Nurses are essential for assessing and managing acute pain in hospitalized patients, especially those who are unable to self-report pain. Given their role and subject matter expertise (SME), nurses are also essential for the design and development of a supervised machine learning (ML) model for pain detection and clinical decision support software (CDSS) in a pain recognition automated monitoring system (PRAMS). Our first step for developing PRAMS with nurses was to create SME-friendly data labeling software.
Purpose
To develop an intuitive and efficient data labeling software solution, Human-to-Artificial Intelligence (H2AI).
Method
The Human-centered Design for Embedded Machine Learning Solutions (HCDe-MLS) model was used to engage nurses. In this paper, HCDe-MLS will be explained using H2AI and PRAMS as illustrative cases.
Findings
Using HCDe-MLS, H2AI was developed and facilitated labeling of 139 videos (mean = 29.83 min) with 3189 images labeled (mean = 75 s) by 6 nurses. OpenCV was used for video-to-image pre-processing; and MobileFaceNet was used for default landmark placement on images. H2AI randomly assigned videos to nurses for data labeling, tracked labelers’ inter-rater reliability, and stored labeled data to train ML models.
Conclusions
Nurses’ engagement in CDSS development was critical for ensuring the end-product addressed nurses’ priorities, reflected nurses’ cognitive and decision-making processes, and garnered nurses’ trust for technology adoption.}
}
@article{DVIR20061233,
title = {Virtual Leashing: Creating a computational foundation for software protection},
journal = {Journal of Parallel and Distributed Computing},
volume = {66},
number = {9},
pages = {1233-1240},
year = {2006},
note = {Special Issue: Security in grid and distributed systems},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2006.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S074373150600092X},
author = {Ori Dvir and Maurice Herlihy and Nir N. Shavit},
keywords = {Digital rights management, Virtual leashing},
abstract = {We introduce Virtual Leashing,11The techniques described in this paper are protected by U.S. patents, both granted and pending. a new technique for software protection and control. The leashing process removes small fragments of code, pervasive throughout the application, and places them on a secure server. The secure server provides the missing functionality, but never the missing code. Reverse engineering the missing code, even with full tracing of the program's execution and its communication with the server, is computationally hard. Moreover, the server provides the missing functionality asynchronously: the application's performance is independent (within reason) of the secure server's speed. For example, the server might reside on a slow inexpensive chip or a remote Internet server. Leashing makes only modest demands on communication bandwidth, space, and computation.}
}
@article{MANSILHA2019190,
title = {Environmental externalities in broiler production: An analysis based on system dynamics},
journal = {Journal of Cleaner Production},
volume = {209},
pages = {190-199},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.10.179},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618331950},
author = {Ricardo Brandão Mansilha and Dalila Cisco Collatto and Daniel Pacheco Lacerda and Maria Isabel {Wolf Motta Morandi} and Fabio Sartori Piran},
keywords = {Broiler, Environmental externalities, Energy sources, Systems thinking, System dynamics},
abstract = {Broiler represents approximately 1.5% of the Brazilian Gross Domestic Product (GDP). Brazil is one of the world's largest producers and exporters of chicken. Aiming to improve and sustain a competitive advantage, producers have invested in improvements in production systems in general, in particular aviary heating systems. However, producers need to choose the best among several alternatives of energy sources for heating. This decision impacts the environment to a greater or a lesser extent depending on the energy source chosen. The aim of this study is to develop a computational model to understand systemically and dynamically the environmental externalities based on the choice of energy source for aviary heating. The identification of criteria that influence the choice for heating systems was possible through a multiple case-study in the southern region of Brazil. By designing a computational model of system dynamics, it was possible to visualize scenarios using different energy sources and their respective negative environmental externalities. From the analysis of four scenarios, we sought to identify the one with the best relation to environmental and economic performance. It was evidenced that the scenario with the best relation was that using pellets as an energy source for aviary heating. The developed model may be applied to solve similar decision-making problems.}
}
@incollection{CLEMENTI200589,
title = {Chapter 6 - Computational chemistry: Attempting to simulate large molecular systems},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {89-114},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50049-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500494},
author = {Enrico Clementi},
abstract = {Publisher Summary
Computational chemistry is a very vast field dealing with atomic and molecular systems, considered at different complexity levels either as discretized quantum mechanical systems, or as statistical ensembles, amenable to Monte Carlo and Molecular Dynamic treatments, or as continuous matter fluid-dynamical distributions, modeled with Navier– Stokes equations. The mainstream computational chemistry was bent to fully solve the correlation problem with a single “technology.” Computational chemistry became a must for more and more chemists, even if the computer users had less and less awareness of the computational details of computer programs, and hardly understood that the computed answer could be incorrect, because of limitations of the selected method. In this computer generation and even more in the following years, internet, communications, commercial computer programs, computer servers, personal computers, desktop, graphics, Window, and Linux were common words, memory and disk space seemed unlimited, price/performance improved yearly, but faith in the computer replaced knowledge of the instrument and its software. Computational chemistry was becoming a part of the global economy.}
}
@article{GARCIASANCHO201216,
title = {From the genetic to the computer program: the historicity of ‘data’ and ‘computation’ in the investigations on the nematode worm C. elegans (1963–1998)},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {43},
number = {1},
pages = {16-28},
year = {2012},
note = {Data-Driven Research in the Biological and Biomedical Sciences On Nature and Normativity: Normativity, Teleology, and Mechanism in Biological Explanation},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2011.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1369848611000781},
author = {Miguel García-Sancho},
keywords = {, Genetics, Computer, Program, Software, Data, Genomics, Model organism},
abstract = {This paper argues that the history of the computer, of the practice of computation and of the notions of ‘data’ and ‘programme’ are essential for a critical account of the emergence and implications of data-driven research. In order to show this, I focus on the transition that the investigations on the worm C. elegans experienced in the Laboratory of Molecular Biology of Cambridge (UK). Throughout the 1980s, this research programme evolved from a study of the genetic basis of the worm’s development and behaviour to a DNA mapping and sequencing initiative. By examining the changing computing technologies which were used at the Laboratory, I demonstrate that by the time of this transition researchers shifted from modelling the worm’s genetic programme on a mainframe apparatus to writing minicomputer programs aimed at providing map and sequence data which was then circulated to other groups working on the genetics of C. elegans. The shift in the worm research should thus not be simply explained in the application of computers which transformed the project from hypothesis-driven to a data-intensive endeavour. The key factor was rather a historically specific technology—in-house and easy programmable minicomputers—which redefined the way of achieving the project’s long-standing goal, leading the genetic programme to co-evolve with the practices of data production and distribution.}
}
@article{ACAR2006993,
title = {Endowing cognitive mapping with computational properties for strategic analysis},
journal = {Futures},
volume = {38},
number = {8},
pages = {993-1009},
year = {2006},
note = {Organisational Foresight},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2005.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S0016328705002302},
author = {William Acar and Douglas Druckenmiller},
abstract = {A number of cognitive, causal mapping and simulation techniques exist for dealing with the growing importance of environmental uncertainty. After briefly commenting on some of the more salient extant approaches, this paper offers a new one for consideration by the scenario planning community. Comprehensive Situation Mapping (CSM) is a powerful analytical tool combined with a process for framing and debating strategic situations. The CSM approach combines the problem framing features of causal mapping with a dialectical inquiry process patterned after Churchman's. Like the better approaches to planning through cognitive mapping, it facilitates the “backward analysis” of the underlying strategic assumptions. Its novelty is that it also allows the “forward analysis” of a situation by computing the potential change scenarios. Initially developed for manual application, the principles of CSM were originally tested in appropriate case studies. The contribution of the present paper is to present its theory and point out that its future potential is even greater: in concluding we indicate that, by using recent distributed artificial intelligence (DAI) technology, a fully computerized and interactive prototype is now being set up for commercial applications.}
}
@incollection{MOL2015158,
title = {Chapter 5 - Computational Design of Biological Systems: From Systems to Synthetic Biology},
editor = {Zaheer Ul-Haq and Jeffry D. Madura},
booktitle = {Frontiers in Computational Chemistry},
publisher = {Bentham Science Publishers},
pages = {158-196},
year = {2015},
isbn = {978-1-60805-865-5},
doi = {https://doi.org/10.1016/B978-1-60805-865-5.50005-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781608058655500058},
author = {Milsee Mol and Shailza Singh},
keywords = {Abstraction, bioengineering, bioinspired, biological parts, computational modelling, computational tools, constructs, dynamic, infectious disease, interdisciplinary, linearization, mathematical framework, nextgen therapeutics, omics, ordinary differential equations, parameters, physical systems, reactions, regulatory circuits, simulation},
abstract = {Abstract:
Today biology is overwhelmed with ‘big data’, amassed from genomic projects carried out in various laboratories around the world using efficient high throughput technologies. Biologists are co-opting mathematical and computational techniques developed to address these data and derive meaningful interpretations. These developments have led to new disciplines: systems and synthetic biology. To explore these two evolving branches of biology one needs to be familiar with technologies such as genomics, bioinformatics and proteomics, mathematical and computational modeling techniques that help predict the dynamic behavior of the biological system, ruling out the trial-and-error methods of traditional genetic engineering. Systems and synthetic biology have developed hand-in-hand towards building artificial biological devices using engineered biological units as basic building blocks. Systems biology is an integrated approach for studying the dynamic and complex behaviors of biological components, which may be difficult to interpret and predict from properties of individual constituents making up the biological systems. While, synthetic biology aims to engineer biologically inspired devices, such as cellular regulatory circuits that do not exist in nature but are designed using well characterized genes, proteins and other biological components in appropriate combinations to perform a desired function. This is analogous to an electronic circuit board design that is fabricated using well characterized electrical components such as resistors, capacitors and so on. The in silico abstractions and predictions should be tightly linked to experimentation to be proved in vitro and in vivo systems for their successful applications in biotechnology. This chapter focuses on mathematical approaches and computational tools available to engineer biological regulatory circuits and how they can be implemented as next generation therapeutics in infectious disease.}
}
@article{ZHU2020102369,
title = {Sentiment and guest satisfaction with peer-to-peer accommodation: When are online ratings more trustworthy?},
journal = {International Journal of Hospitality Management},
volume = {86},
pages = {102369},
year = {2020},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2019.102369},
url = {https://www.sciencedirect.com/science/article/pii/S0278431918307333},
author = {Liang Zhu and Yan Lin and Mingming Cheng},
keywords = {Peer-to-peer accommodation, Guest satisfaction, Online ratings, Sentiment analysis, Analytical thinking, Authenticity},
abstract = {This study aims to decode guest satisfaction with peer-to-peer accommodations by analyzing the relationship between guests’ sentiment and online ratings and examining how analytical thinking and authenticity influence this relationship. Based on reviews of 4602 Airbnb listings in San Francisco, we empirically find that positive (negative) sentiment is linked to a high (low) rating. We further show that this link is stronger when guests manifest a higher extent of analytical thinking and authenticity. Both Tobit and ordered logit models yield consistent estimation results, showing the robustness of our findings. Our study contributes to the tourism and hospitality literature by theoretically explaining the association between sentiment and ratings. In addition, this paper enriches our knowledge regarding the trustworthiness of Airbnb ratings.}
}
@article{MATTHEWS2021100278,
title = {Reconceptualising feedback: Designing educational tangible technologies to be a creative material},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100278},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000210},
author = {Sarah Matthews and Ben Matthews},
keywords = {Tangible technologies, Feedback, Educational technologies, Creative material, Interaction design, Empirical studies},
abstract = {This paper investigates how children who are engaged in a creative project with tangible technology kits make sense of the system feedback the technology provides. A micro-analytic video study was conducted of primary school children designing their own technologies using existing educational microcontrollers. Our investigation reveals that the roles feedback plays in children’s interactions cannot easily be assimilated within the existing approaches to understand feedback that have been articulated in HCI literature. Our qualitative analysis shows how children do not make sense of feedback as semantic communication from the system, but make sense of it with respect to its embeddedness in a sequence of activities they are performing with the system and each other. The principal contribution to emerge from our study is a conception of feedback as a process, rather than as a semantic communicative event, nor a direct coupling of action and system response. Our discussion identifies how feedback participates in the institutional agendas of classrooms (e.g. discovery, computational thinking), and draws out initial implications for the design of feedback in educational tangible technologies, identifying possibilities for how feedback might be redesigned to better promote children’s diagnostic practices with open-ended technology kits.}
}
@article{CARLOZZI2022263,
title = {Daily Variation in Sleep Quality is Associated With Health-Related Quality of Life in People With Spinal Cord Injury},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {103},
number = {2},
pages = {263-273.e4},
year = {2022},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2021.07.803},
url = {https://www.sciencedirect.com/science/article/pii/S0003999321013630},
author = {Noelle E. Carlozzi and Jenna Freedman and Jonathan P. Troost and Traci Carson and Ivan R. Molton and Dawn M. Ehde and Kayvan Najarian and Jennifer A. Miner and Nicholas R. Boileau and Anna L. Kratz},
keywords = {Ecological momentary assessment, Quality of life, Rehabilitation, Sleep, Spinal cord injuries},
abstract = {Objective
Although sleep difficulties are common after spinal cord injury (SCI), little is known about how day-to-day fluctuations in sleep quality affects health-related quality of life (HRQOL) among these individuals. We examined the effect of sleep quality on same-day HRQOL using ecological momentary assessment methods over a 7-day period.
Design
Repeated-measures study involving 7 days of home monitoring; participants completed HRQOL measures each night and ecological momentary assessment ratings 3 times throughout the day; multilevel models were used to analyze data.
Setting
Two academic medical centers.
Participants
A total of 170 individuals with SCI (N=170).
Interventions
Not applicable.
Main Outcome Measures
Daily sleep quality was rated on a scale of 0 (worst) to 10 (best) each morning. Participants completed end-of-day diaries each night that included several HRQOL measures (Sleep Disturbance, Sleep-related Impairment, Fatigue, Cognitive Abilities, Pain Intensity, Pain Interference, Ability to Participate in Social Roles and Activities, Depression, Anxiety) and ecological momentary assessment ratings of HRQOL (pain, fatigue, subjective thinking) 3 times throughout each day.
Results
Multilevel models indicated that fluctuations in sleep quality (as determined by end-of-day ratings) were significantly related to next-day ratings of HRQOL; sleep quality was related to other reports of sleep (Sleep Disturbance; Sleep-related Impairment; Fatigue) but not to other aspects of HRQOL. For ecological momentary assessment ratings, nights of poor sleep were related to worse pain, fatigue, and thinking. Generally, sleep quality showed consistent associations with fatigue and thinking across the day, but the association between sleep quality and these ecological momentary assessment ratings weakened over the course of the day.
Conclusions
Findings highlight the important association between sleep and HRQOL for people with SCI. Future work targeting sleep quality improvement may have positive downstream effects for improving HRQOL in people with SCI.}
}
@incollection{LANDAUER200243,
title = {On the computational basis of learning and cognition: Arguments from LSA},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {41},
pages = {43-84},
year = {2002},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(02)80004-4},
url = {https://www.sciencedirect.com/science/article/pii/S0079742102800044},
author = {Thomas K Landauer},
abstract = {Publisher Summary
This chapter discusses the computational basis of learning and cognition. To deal with a continuously changing environment, living things have three choices: (1) evolve unvarying processes that usually succeed, (2) evolve genetically fixed effector, perceptual, and computational functions that are contingent on the environment, and (3) learn adaptive functions during their lifetimes. The theme of this chapter is the relation between (2) and (3): the nature of evolutionarily determined computational processes that support learning. The principal goal of this chapter has been to suggest that high-dimensional vector space computations based on empirical associations among very large numbers of components could be a close model of a fundamental computational basis of most learning in both verbal and perceptual domains. More powerful representational effects can be brought about by linear inductive combinations of the elements of very large vocabularies than has often been realized. Success of one such model to demonstrate many natural properties of language commonly assumed to be essentially more complex, nonlinear, and/or unlearned, along with evidence and argument that similar computations may serve similar roles in object recognition, are taken to reaffirm the possibility that a single underlying associational mechanism lies behind many more special and complex appearing cognitive phenomena.}
}
@article{GALITSKY201325,
title = {A computational simulation tool for training autistic reasoning about mental attitudes},
journal = {Knowledge-Based Systems},
volume = {50},
pages = {25-43},
year = {2013},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S095070511300138X},
author = {Boris Galitsky},
keywords = {Autistic reasoning, Rehabilitation, Theory of mind},
abstract = {It has been discovered more than a decade ago that autistic people cannot properly understand and reproduce mental states and emotions. We hypothesize that people with autism suffer from difficulties in learning social rules from examples. Many remediation strategies have not taken this into account. Therefore an appropriate remediation strategy is to teach not simply via examples but to teach the rule along with it. In this study we suggest a reasoning rehabilitation strategy, based on playing with a computer based mental simulator that is capable of modeling mental and emotional states of the real world. A model of the mental world is presented in 12 steps. We describe our implementation of a natural language multiagent system that simulates this model. In addition we describe the system’s user interface for autistic rehabilitation. This system is subject to short-term and long-term evaluation of rehabilitation of autistic reasoning. Case studies with children who used it extensively are presented. Implications specifically in terms of autistic rehabilitation as well as generally in terms of reasoning about mental states are discussed.}
}
@article{GOMEZTALAL2024108109,
title = {Understanding the disparities in Mathematics performance: An interpretability-based examination},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108109},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108109},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624002677},
author = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
keywords = {Programme for International Student Assessment, Interpretable machine learning, Shapley additive explanations, Explainable black-box models},
abstract = {Problem:
Educational disparities in Mathematics performance are a persistent challenge. This study aims to unravel the complex factors contributing to these disparities among students internationally, with a focus on the interpretability of the contributing factors.
Methodology:
Utilizing data from the Programme for International Student Assessment (PISA), we conducted rigorous preprocessing and variable selection to prepare for applying binary classification interpretability models. These models were trained using the Stratified K-Fold technique to ensure balanced representation and assessed using six key metrics.
Solution:
By applying interpretability models such as Shapley Additive Explanations (SHAP) analysis, we identified critical factors impacting student performance, including reading accessibility, critical thinking skills, gender, and geographical location.
Results:
Our findings reveal significant disparities linked to resource availability, with students from lower socioeconomic backgrounds possessing fewer books and demonstrating lower performance in Mathematics. The geographical analysis highlighted regional educational disparities, with certain areas consistently underperforming in PISA assessments. Gender also emerged as a determinant, with females contributing differently to performance levels across the spectrum.
Conclusion:
The study provides insights into the multifaceted determinants of student Mathematics performance and suggests potential avenues for future research to explore global interpretability models and further investigate the socioeconomic, cultural, and educational factors at play.}
}
@article{LIU200548,
title = {A computational model for rare-earth ferrimagnets and antiferromagnets},
journal = {Physica B: Condensed Matter},
volume = {367},
number = {1},
pages = {48-52},
year = {2005},
issn = {0921-4526},
doi = {https://doi.org/10.1016/j.physb.2005.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S0921452605007982},
author = {Z.-S. Liu and M. Diviš and V. Sechovský},
keywords = {Intermetallic compounds, Crystal field},
abstract = {A computational model for the calculation of the bulk magnetic properties of rare-earth ferrimagnets and antiferromagnets was developed and justified theoretically in the framework of mean-field theory. To demonstrate its utility, the model was applied to calculate the anisotropic Heisenberg exchange constants of CeTe2 by fitting magnetization curves numerically, and to derive analytical expressions for the spontaneous magnetization as well as the Neél temperature by considering only the crystal-field (CF) ground-state doublet. It turns out that the temperature dependencies of the magnetization and the specific heat calculated with the formulas in absence of an external field are identical with the plots obtained directly with the full lowest CF J-multiplet, manifesting the strong role of the Kramers doublet in the magnetic process at low temperatures. Finally, the model was applied to investigate the effects of the quadrupolar and magneto-elastic (QM) interactions on the magnetic properties of the system.}
}
@article{PALKOVICS2016144,
title = {Exploration of cognition–affect and Type 1–Type 2 dichotomies in a computational model of decision making},
journal = {Cognitive Systems Research},
volume = {40},
pages = {144-160},
year = {2016},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2016.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041715300115},
author = {Michael Anton Palkovics and Martin Takáč},
keywords = {Affective computing, Dual process theory, Decision-making},
abstract = {This paper studies the role of cognition and affect in decision-making as well as notions of Type 1 and 2 processes and behaviors typically used in dual process theories. In order to demonstrate that there is no 1:1 correspondence between types of observed behavior and internal processes causing them, and that Type 1 and Type 2 processes can be produced by a single system, we implemented a computational model integrating affective and cognitive processing. Our model is based on the model of Marinier, Laird, and Lewis (2009). We modified it by increasing the agent’s visual field, adding a GOFAI-style cognitive module (sub-goal management) and expanding the environment by a high-threat tile, to which the agent responds with a hard-wired automatic reaction. This allowed us to generate and observe different types of behavior and study interesting interactions between cognitive and affective control. By comparing our re-implementation to the modified agent, we demonstrated clear cases of Type 1 (fast, automatic) and Type 2 (slow, deliberative) behavior, providing further evidence for the “single-system, two processes” hypothesis.}
}
@incollection{DERINGER201359,
title = {9.02 - Computational Methods for Solids},
editor = {Jan Reedijk and Kenneth Poeppelmeier},
booktitle = {Comprehensive Inorganic Chemistry II (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Amsterdam},
pages = {59-87},
year = {2013},
isbn = {978-0-08-096529-1},
doi = {https://doi.org/10.1016/B978-0-08-097774-4.00902-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780080977744009025},
author = {V.L. Deringer and R. Dronskowski},
keywords = {Ab initio calculations, Band structure, Bonding indicators, Chemical bonding, Computational chemistry, Crystal orbitals, Density-functional theory, Electronic-structure calculations, Magnetism, Materials science, Plane-wave basis sets, Pseudopotentials, Quantum chemistry, Solid-state chemistry, Theoretical chemistry, Thermochemistry},
abstract = {Today's scientific progress would be unthinkable without theoretical and computational assistance. This holds true also for the solid-state sciences – which are without doubt a fundamental part of modern inorganic chemistry. This chapter is concerned mainly with first principles or ab initio quantum-chemical methods; the fundamental goal of solving Schrödinger's equation does not change upon going to extended systems, but there are some very important new ideas to consider. First, we describe these essential concepts; however, we do not, nor attempt to, provide an exhaustive overview of electronic-structure theory. Subsequently, we deal with simplifications, which are necessary to make quantum-chemical computations tractable and which possess special importance in the solid state. Simplifying ‘well’ is thus a vital part of any theorist's work. Finally, we describe applications – how chemists ‘see’ bonds in complicated structures, and how the computational toolkit may complement and enhance chemical concepts. They illustrate our most important message: how beautifully rock-solid theories and chemists' ingenious models blend in the solid state.}
}
@article{VARTIAINEN2021100281,
title = {Machine learning for middle schoolers: Learning through data-driven design},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100281},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100281},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000222},
author = {Henriikka Vartiainen and Tapani Toivonen and Ilkka Jormanainen and Juho Kahila and Matti Tedre and Teemu Valtonen},
keywords = {AI, Machine learning, K-12, Computational thinking, Design-oriented pedagogy, Design-based research},
abstract = {An entire generation of children is growing up with machine learning (ML) systems that are greatly disrupting job markets as well as changing people’s everyday lives. Yet, that development and its societal effects have been given minor attention in computing education in schools, which mainly focuses on rule-based programming. This article presents a pedagogical framework for supporting middle schoolers to become co-designers and makers of their own machine learning applications. It presents a case study conducted in the 6th grade of a Finnish elementary school and analyzes students’ (N=34) evolving ML ideas and explanations. Data consists of a children’s artwork, students’ design ideas and co-designed applications, and structured group interviews organized at the end of the ML project. The qualitative content analysis revealed how hands-on exploration with ML-based technologies supported students in developing various kinds of design ideas that harnessed face recognition, gestures, or voice recognition for solving real-life problems. The results of the study further indicated that co-designing ML applications provided a promising entry point for students to develop their conceptual understanding of ML principles, its workflows, and its role in their everyday practices. The article concludes with a discussion on how to support students to become innovators and software designers in the age of machine learning.}
}
@article{VARGO2017260,
title = {A systems perspective on markets – Toward a research agenda},
journal = {Journal of Business Research},
volume = {79},
pages = {260-268},
year = {2017},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2017.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S014829631730098X},
author = {Stephen L. Vargo and Kaisa Koskela-Huotari and Steve Baron and Bo Edvardsson and Javier Reynoso and Maria Colurcio},
keywords = {Markets, Systems thinking, Marketing, Complex systems, Research agenda},
abstract = {This paper addresses the implications of an emerging, increasingly important way of thinking about markets: systems thinking. A market is one of the most founational abstractions in marketing and business research; yet, it often receives too little attention. As a result, the taken-for-granted assumptions about markets spur from over-simplified conceptualizations of neoclassical economics that depict markets as static and mechanistic. Systems thinking represents a major change in perspective that involves transcending this mechanistic worldview and thinking instead in terms of wholes, relationships, processes, and patterns. We argue that building a theory of markets based on systems thinking, would enable scholars to develop more realistic models that correspond with fast-changing business environment and therefore, increase both the rigor and relevance of future research. To further this aim, we identify the main implications of systems thinking and formulate them into a research agenda to further the systemic understanding of markets.}
}
@article{BJORNE2005193,
title = {A model of attentional impairments in autism: first steps toward a computational theory},
journal = {Cognitive Systems Research},
volume = {6},
number = {3},
pages = {193-204},
year = {2005},
note = {Epigenetic Robotics},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2004.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041704000749},
author = {Petra Björne and Christian Balkenius},
keywords = {Autism, Attention, Computational model},
abstract = {A computational model with three interacting components for context sensitive reinforcement learning, context processing and automation can autonomously learn a focus attention and a shift attention task. The performance of the model is similar to that of normal children, and when a single parameter is changed, the performance on the two tasks approaches that of autistic children.}
}
@article{COSTA20221810,
title = {Multicriteria analysis by PROMETHEE-SAPEVO-M1 method: choice of Brazilian sugar and ethanol plants for biomethane production},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {1810-1815},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.09.661},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322019796},
author = {Wallace L.T. Costa and Igor P.A. Costa and Adilson V. Terra and Miguel Â.L. Moreira and Carlos, F.S. Gomes and Marcos Santos},
keywords = {Multicriteria, PROMETHEE, SAPEVO, Energy, Biomethane},
abstract = {Given the need for cleaner energy sources associated with the ESG (Environmental, social and corporate governance) policy, the work in question is a case study referring to the project to expand biomethane production in national territory, especially for industrial commercialization. By applying the Value Focused Thinking (VFT) methodology, the study initially seeks the approach based on the values of decision-makers, these being three professionals in the energy sector. After the central objective of supporting decision-making, the hybrid method PROMETHEE-SAPEVO-M1 was used, characterized by the possibility of evaluating quantitative data and qualitative variables. To this end, the modeling occurred through the software of the PROMETHEE-SAPEVO-M1 method to clarify the best plants, because of the range of possibilities in the national territory, for project implementation and subsequent production of biomethane for industrial use. As a result, we verified that São Paulo is the best alternative for applying the investment in biomethane production.}
}
@article{FELLOWS2013541,
title = {Towards fully multivariate algorithmics: Parameter ecology and the deconstruction of computational complexity},
journal = {European Journal of Combinatorics},
volume = {34},
number = {3},
pages = {541-566},
year = {2013},
note = {Combinatorial Algorithms and Complexity},
issn = {0195-6698},
doi = {https://doi.org/10.1016/j.ejc.2012.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0195669812001400},
author = {Michael R. Fellows and Bart M.P. Jansen and Frances Rosamond},
abstract = {The aim of this article is to motivate and describe the parameter ecology program, which studies how different parameters contribute to the difficulty of classical problems. We call for a new type of race in parameterized analysis, with the purpose of uncovering the boundaries of tractability by finding the smallest possible parameterizations which admit FPT-algorithms or polynomial kernels. An extensive overview of recent advances on this front is presented for the Vertex Cover problem. Moving even beyond the parameter ecology program we advocate the principle of model enrichment, which raises the challenge of generalizing positive results to problem definitions with greater modeling power. The computational intractability which inevitably emerges can be deconstructed by introducing additional parameters, leading towards a theory of fully multivariate algorithmics.}
}