@article{KRINGELBACH2020108128,
title = {Brain States and Transitions: Insights from Computational Neuroscience},
journal = {Cell Reports},
volume = {32},
number = {10},
pages = {108128},
year = {2020},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2020.108128},
url = {https://www.sciencedirect.com/science/article/pii/S2211124720311177},
author = {Morten L. Kringelbach and Gustavo Deco},
abstract = {Summary
Within the field of computational neuroscience there are great expectations of finding new ways to rebalance the complex dynamic system of the human brain through controlled pharmacological or electromagnetic perturbation. Yet many obstacles remain between the ability to accurately predict how and where best to perturb to force a transition from one brain state to another. The foremost challenge is a commonly agreed definition of a given brain state. Recent progress in computational neuroscience has made it possible to robustly define brain states and force transitions between them. Here, we review the state of the art and propose a framework for determining the functional hierarchical organization describing any given brain state. We describe the latest advances in creating sophisticated whole-brain computational models with interacting neuronal and neurotransmitter systems that can be studied fully in silico to predict and design novel pharmacological and electromagnetic interventions to rebalance them in disease.}
}
@article{FUCHS2023103688,
title = {A post-Cartesian economic and Buddhist view on tourism},
journal = {Annals of Tourism Research},
volume = {103},
pages = {103688},
year = {2023},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2023.103688},
url = {https://www.sciencedirect.com/science/article/pii/S0160738323001615},
author = {Matthias Fuchs},
keywords = {Economic growth ideology, Post-Cartesian ontology, Post-mechanistic economic theory, Buddhist philosophy, Transformative tourism},
abstract = {Insuperable socio-economic and ecological crises demonstrate the need to challenge economic growth ideology that is often embedded in contemporary tourism science. By borrowing from Buddhist philosophy this essay describes inconsistencies in economic theorizing due to its adoption of the Cartesian ontology implying a mechanistic thinking form. Following philosopher Brodbeck (2014), economic science is neither an empirically exact science nor value-free but represents an implicit ethics. To build on this, the elements of a post-mechanistic economic theory are sketched (Brodbeck, 2001). The applicability of this concept is corroborated by instances of current tourism research. After reinterpreting the homo economicus and the nature of money an agenda for a transformative tourism science building upon post-Cartesian economic thinking and Buddhist philosophy is elaborated.}
}
@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@article{SUI2022377,
title = {Data-driven based four examinations in TCM: a survey},
journal = {Digital Chinese Medicine},
volume = {5},
number = {4},
pages = {377-385},
year = {2022},
issn = {2589-3777},
doi = {https://doi.org/10.1016/j.dcmed.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S258937772200074X},
author = {Dong SUI and Lei ZHANG and Fei YANG},
keywords = {Traditional Chinese medicine (TCM), Four examinations, Data-driven, Machine learning, Computational intelligence},
abstract = {Traditional Chinese medicine (TCM) diagnosis is a unique disease diagnosis method with thousands of years of TCM theory and effective experience. Its thinking mode in the process is different from that of modern medicine, which includes the essence of TCM theory. From the perspective of clinical application, the four diagnostic methods of TCM, including inspection, auscultation and olfaction, inquiry, and palpation, have been widely accepted by TCM practitioners worldwide. With the rise of artificial intelligence (AI) over the past decades, AI based TCM diagnosis has also grown rapidly, marked by the emerging of a large number of data-driven deep learning models. In this paper, our aim is to simply but systematically review the development of the data-driven technologies applied to the four diagnostic approaches, i.e. the four examinations, in TCM, including data sets, digital signal acquisition devices, and learning based computational algorithms, to better analyze the development of AI-based TCM diagnosis, and provide references for new research and its applications in TCM settings in the future.}
}
@article{FERGUSON2024286,
title = {Social uncertainty in the digital world},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {4},
pages = {286-289},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000329},
author = {Amanda M. Ferguson and Georgia Turner and Amy Orben},
keywords = {Bayesian inference, digital affordances, social media, social uncertainty},
abstract = {The social world is inherently uncertain. We present a computational framework for thinking about how increasingly popular online environments modulate the social uncertainty we experience, depending on the type of social inferences we make. This framework draws on Bayesian inference, which involves combining multiple informational sources to update our beliefs.}
}
@article{SCOTT2020107269,
title = {CPC’s 50th Anniversary: Celebrating 50 years of open-source software in computational physics},
journal = {Computer Physics Communications},
volume = {252},
pages = {107269},
year = {2020},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2020.107269},
url = {https://www.sciencedirect.com/science/article/pii/S0010465520300886},
author = {N.S. Scott and A. Hibbert and J. Ballantyne and S. Fritzsche and A.L. Hazel and D.P. Landau and D.W. Walker and Z. Was},
keywords = {Computer Physics Communications, CPC Program Library, Collaborative Computational Project, Mendeley Data repository, Platform for Advanced Scientific Computing, Code Ocean},
abstract = {To celebrate the leading role Computer Physics Communications (CPC) has played in publishing open-source software in computational physics for over 50 years the editors are delighted to announce this Virtual Special Issue. Since 2018, coinciding with the 50th anniversary of the start of the CPC venture, thirty-two invited articles have been published. Each has been peer reviewed and each bears the header ‘CPC 50th anniversary article’. The special issue is in keeping with CPC’s ethos: it is focused on computational physics software and is accompanied by twenty-five software systems. The introduction to the collection also includes a personal reflection on Phil Burke, CPC’s founder, by Alan Hibbert, a lifelong colleague, who joined Queen’s University with Phil in the autumn of 1967. The distinctive feature of CPC is its Program Library which houses and distributes over 3500 open-source programs in computational physics. The introduction concludes with a description of key events in the history of the Program Library, its association with Queen’s University Belfast and its transfer to Elsevier’s Mendeley Data repository.}
}
@article{TAUB201510,
title = {The effect of computer science on physics learning in a computational science environment},
journal = {Computers & Education},
volume = {87},
pages = {10-23},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2015.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360131515000913},
author = {Rivka Taub and Michal Armoni and Esther Bagno and Mordechai (Moti) Ben-Ari},
keywords = {Interdisciplinary projects, Programming and programming languages, Secondary education, Simulations, Teaching/learning strategies},
abstract = {College and high-school students face many difficulties when dealing with physics formulas, such as a lack of understanding of their components or of the physical relationships between the two sides of a formula. To overcome these difficulties some instructors suggest combining simulations' design while learning physics, claiming that the programming process forces the students to understand the physical mechanism activating the simulation. This study took place in a computational-science course where high-school students programmed simulations of physical systems, thus combining computer science (CS) and mathematics with physics learning. The study explored the ways in which CS affected the students' conceptual understanding of the physics behind formulas. The major part of the analysis process was qualitative, although some quantitative analysis was applied as well. Findings revealed that a great amount of the time was invested by the students on representing their physics knowledge in terms of computer science. Three knowledge domains were found to be applied: structural, procedural and systemic. A fourth domain which enabled reflection on the knowledge was found as well, the domain of execution. Each of the domains was found to promote the emergence of knowledge integration processes (Linn & Eylon, 2006, 2011), thus promoting students’ physics conceptual understanding. Based on these findings, some instructional implications are discussed.}
}
@article{CHANG2014335,
title = {Computational architecture: Connecting the physical and virtual worlds},
journal = {Frontiers of Architectural Research},
volume = {3},
number = {4},
pages = {335-336},
year = {2014},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2014.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263514000624},
author = {Teng-Wen Chang and Weixin Huang}
}
@article{SAHA2021113452,
title = {Hierarchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational science and engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113452},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113452},
url = {https://www.sciencedirect.com/science/article/pii/S004578252030637X},
author = {Sourav Saha and Zhengtao Gan and Lin Cheng and Jiaying Gao and Orion L. Kafka and Xiaoyu Xie and Hengyang Li and Mahsa Tajdari and H. Alicia Kim and Wing Kam Liu},
keywords = {Deep learning, Machine learning, Reduced order model, Data-driven discovery, Multiscale simulation, Artificial intelligence},
abstract = {In this work, a unified AI-framework named Hierarchical Deep Learning Neural Network (HiDeNN) is proposed to solve challenging computational science and engineering problems with little or no available physics as well as with extreme computational demand. The detailed construction and mathematical elements of HiDeNN are introduced and discussed to show the flexibility of the framework for diverse problems from disparate fields. Three example problems are solved to demonstrate the accuracy, efficiency, and versatility of the framework. The first example is designed to show that HiDeNN is capable of achieving better accuracy than conventional finite element method by learning the optimal nodal positions and capturing the stress concentration with a coarse mesh. The second example applies HiDeNN for multiscale analysis with sub-neural networks at each material point of macroscale. The final example demonstrates how HiDeNN can discover governing dimensionless parameters from experimental data so that a reduced set of input can be used to increase the learning efficiency. We further present a discussion and demonstration of the solution for advanced engineering problems that require state-of-the-art AI approaches and how a general and flexible system, such as HiDeNN-AI framework, can be applied to solve these problems.}
}
@article{LIU2024100642,
title = {A systematic review on how educators teach AI in K-12 education},
journal = {Educational Research Review},
volume = {45},
pages = {100642},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100642},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000514},
author = {Xiaofan Liu and Baichang Zhong},
keywords = {K-12 education, AI education, AI literacy, Research design, Teaching practice},
abstract = {Developing Artificial Intelligence (AI) education in K-12 contexts, i.e., teaching students about AI, is critical to promote students' AI literacy. However, the state-of-the-art of AI education is not clear enough. To this end, this study reviewed 45 high-quality empirical studies on K-12 AI education over the past decade from both research and instruction perspectives. Regarding the research design, this study revealed the relationship between publication year, sample size, learning stage, educational setting, research method, research focus and duration. Regarding the instruction design, this study revealed the relationship between learning stage, pedagogical strategy, learning tool, learning activity, learning content, assessment method and learning effect. Besides, this study also derived recommendations for research (i.e., time allocation, samples selection, longitudinal design, rigorous methodology and technical democracy) and instruction (i.e., group learning, authentic context, teacher involvement, triangular evidence and learning scaffolding). Overall, the main findings indicate that K-12 AI education has the potential to develop students’ AI literacy, which contains AI knowledge, AI affectivity, and AI thinking. However, deficiencies in research and instructional design still remain, including short durations, small sample sizes, non-standardized research methods, lack of long-term and cross-age AI curriculum, etc. This study also discussed several critical topics for future research and instruction.}
}
@article{CESARI2017361,
title = {Frailty and Multimorbidity: Different Ways of Thinking About Geriatrics},
journal = {Journal of the American Medical Directors Association},
volume = {18},
number = {4},
pages = {361-364},
year = {2017},
issn = {1525-8610},
doi = {https://doi.org/10.1016/j.jamda.2016.12.086},
url = {https://www.sciencedirect.com/science/article/pii/S1525861017300348},
author = {Matteo Cesari and Mario Ulises Pérez-Zepeda and Emanuele Marzetti},
keywords = {Diseases, comprehensive geriatric assessment, aging, public health},
abstract = {The terms multimorbidity and frailty are increasingly used in the medical literature to measure the risk profile of an older individual in order to support clinical decisions and design ad hoc interventions. The construct of multimorbidity was initially developed and used in nongeriatric settings. It generates a monodimensional nosological risk profile, grounding its roots in the somewhat inadequate framework of disease. On the other hand, frailty is a geriatric concept that implies a more exhaustive and comprehensive assessment of the individual and his/her environment, facilitating the implementation of multidimensional and tailored interventions. This article aims to promote among geriatricians the use of terms that may better enhance their background and provide more value to their unrivaled expertise in caring for biologically aged persons.}
}
@article{GRIGORIADIS2022618,
title = {Computational and conceptual blends: Material considerations and agency in a multi-material design workflow},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {4},
pages = {618-629},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095263522000449},
author = {Kostas Grigoriadis},
keywords = {Digital design, Multi-materials, Computer simulation, Material agency, Materially anchored conceptual blends},
abstract = {The assimilation of functionally graded (or multi-) materials into architecture is deemed to enable the rethinking of current architectural design practice and bring back material considerations at the heart of the early design process. In response, the paper outlines a functionally graded material (FGM) design workflow that departs from standard early-stage CAD, which is typically performed via computer elements devoid of materiality. It then analyses this workflow from a theoretical perspective, namely through Edwin Hutchins' materially anchored conceptual blending, Lambros Malafouris' Material Engagement Theory (MET) and John Searle's concepts of intentionality. The aim is to demonstrate that due to the superimposition of material considerations that precede and succeed the CAD operation, working with material-less entities during early-stage FGM design is not logically sustainable. Additionally, multi-materiality allows for the questioning of authorship in the design process and leads to a repositioning of agency from the subject to the locus of engagement with digital materials and their affordances.}
}
@article{SMITH1990121,
title = {Writing, thinking, computing},
journal = {Poetics},
volume = {19},
number = {1},
pages = {121-142},
year = {1990},
issn = {0304-422X},
doi = {https://doi.org/10.1016/0304-422X(90)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0304422X90900332},
author = {John B. Smith and Catherine F. Smith},
abstract = {The computer has become the preferred tool for many writers. Over the next few years, it is likely to become the predominant tool. Since writing is fundamentally a mediated activity and since the tool inevitably affects the tool user, we need to consider how a tool as powerful as the computer is affecting writers. To address this issue, we consider the following questions: &#x02022;- What are writers saying about computers?&#x02022;- How are writers using computers?&#x02022;- What does this mean for the teaching of writing?&#x02022;- What does this mean for designers of future writing systems?&#x02022;- How does the computer affect writer's thinking? We are led to the conclusion that new, comprehensive writing environments are both needed and inevitable, and they, in turn, will lead to a form of enhanced, or amplified, thinking. But using these environments and developing this kind of thinking will also require new forms of instruction. Adapting to these changes will pose practical as well as intellectual challenges for the composition community. To meet these challenges tomorrow, we must begin considering the relationships among writing, thinking, and computing today.}
}
@article{SRIHARI20141083,
title = {Role of automation in the examination of handwritten items},
journal = {Pattern Recognition},
volume = {47},
number = {3},
pages = {1083-1095},
year = {2014},
note = {Handwriting Recognition and other PR Applications},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2013.09.032},
url = {https://www.sciencedirect.com/science/article/pii/S0031320313004044},
author = {Sargur N. Srihari and Kirsten Singer},
keywords = {Handwriting examination, Forensic document examination, Writer verification, Writer identification, Computational forensics, Expert system validation},
abstract = {Several automation tools have been developed over the years for forensic document examination (FDE) of handwritten items. Integrating the developed tools into a unified framework is considered and the essential role of the human in the process is discussed. The task framework is developed by considering the approach of computational thinking whose components are abstraction, algorithms, mathematical models and ability to scale. Beginning with the human FDE procedure expressed in algorithmic form, mathematical and software implementations of individual steps of the algorithm are described. Advantages of the framework are discussed, including efficiency (ability to scale to tasks with many handwritten items), reproducibility and validation/improvement of existing manual procedures. It is indicated that as with other expert systems, such as for medical diagnosis, current automation tools are useful only as part of a larger manually intensive procedure. This viewpoint is illustrated with a well-known FDE case, concerning the Lindbergh kidnapping with a new hypothesis – in this case, there are multiple questioned documents, possibility of multiple writers of the same document, determining whether the writing is disguised, known writing is formal while questioned writing is informal, etc. Observations are made for future developments, where human examiners provide handwriting characteristics while computational methods provide the necessary statistical analysis.}
}
@article{LI2024108089,
title = {Population characteristic exploitation-based multi-orientation multi-objective gene selection for microarray data classification},
journal = {Computers in Biology and Medicine},
volume = {170},
pages = {108089},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108089},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524001732},
author = {Min Li and Rutun Cao and Yangfan Zhao and Yulong Li and Shaobo Deng},
keywords = {Gene selection, Microarray data, Multi-orientation, Multi-objective, Reverse thinking},
abstract = {Gene selection is a process of selecting discriminative genes from microarray data that helps to diagnose and classify cancer samples effectively. Swarm intelligence evolution-based gene selection algorithms can never circumvent the problem that the population is prone to local optima in the process of gene selection. To tackle this challenge, previous research has focused primarily on two aspects: mitigating premature convergence to local optima and escaping from local optima. In contrast to these strategies, this paper introduces a novel perspective by adopting reverse thinking, where the issue of local optima is seen as an opportunity rather than an obstacle. Building on this foundation, we propose MOMOGS-PCE, a novel gene selection approach that effectively exploits the advantageous characteristics of populations trapped in local optima to uncover global optimal solutions. Specifically, MOMOGS-PCE employs a novel population initialization strategy, which involves the initialization of multiple populations that explore diverse orientations to foster distinct population characteristics. The subsequent step involved the utilization of an enhanced NSGA-II algorithm to amplify the advantageous characteristics exhibited by the population. Finally, a novel exchange strategy is proposed to facilitate the transfer of characteristics between populations that have reached near maturity in evolution, thereby promoting further population evolution and enhancing the search for more optimal gene subsets. The experimental results demonstrated that MOMOGS-PCE exhibited significant advantages in comprehensive indicators compared with six competitive multi-objective gene selection algorithms. It is confirmed that the “reverse-thinking" approach not only avoids local optima but also leverages it to uncover superior gene subsets for cancer diagnosis.}
}
@article{KAUFFMAN201525,
title = {Infinite computations and the generic finite},
journal = {Applied Mathematics and Computation},
volume = {255},
pages = {25-35},
year = {2015},
note = {Special issue devoted to the international conference ‘‘Numerical computations: Theory and Algorithms’’ June 17–23, 2013, Falerna, Italy},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2014.06.054},
url = {https://www.sciencedirect.com/science/article/pii/S009630031400890X},
author = {Louis H. Kauffman},
keywords = {Grossone, , Finite, Infinite, Generic finite, Category},
abstract = {This paper introduces the concept of a generic finite set and points out that a consistent and significant interpretation of the grossone, ① notation of Sergeyev is that ① takes the role of a generic natural number. This means that ① is not itself a natural number, yet it can be treated as one and used in the generic expression of finite sets and finite formulas, giving a new power to algebra and algorithms that embody this usage. In this view,N={1,2,3,…,①-2,①-1,①}is not an infinite set, it is a symbolic structure representing a generic finite set. We further consider the concept of infinity in categories. An object A in a given category C is infinite relative to that category if and only if there is a injection J:A⟶A in C that is not a surjection. In the category of sets this recovers the usual notion of infinity. In other categories, an object may be non-infinite (finite) while its underlying set (if it has one) is infinite. The computational methodology due to Sergeyev for executing numerical calculations with infinities and infinitesimals is considered from this categorical point of view.}
}
@incollection{LOURDUSAMY202091,
title = {7 - Computational intelligence using ontology—A case study on the knowledge representation in a clinical decision support system},
editor = {Jitendra Kumar Verma and Sudip Paul and Prashant Johri},
booktitle = {Computational Intelligence and Its Applications in Healthcare},
publisher = {Academic Press},
pages = {91-104},
year = {2020},
isbn = {978-0-12-820604-1},
doi = {https://doi.org/10.1016/B978-0-12-820604-1.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128206041000078},
author = {Ravi Lourdusamy and Xavierlal J. Mattam},
keywords = {Clinical decision support systems, Knowledge representation, Computational semantics, Ontology, Ontological engineering},
abstract = {Computational intelligence has been traditionally associated with neural networks, fuzzy systems, and genetic algorithms. Over the years there have been many developments in computational intelligence. At present, many other fields are part of the study and research in computational intelligence. With advances in cognitive sciences, more techniques of information processing by machines that show characteristics closely associated with human intelligence are being found. Some of these techniques have been studied for a long time, but in recent years there has been some maturity in the understanding and use of these techniques. One such technique is the use of semantics in computational intelligence. There has been a long-drawn-out philosophical debate between lingualism, which claims that there is no human thought without language, and “language of thought” theories, which believe that natural language is inessential to private thought. In an attempt to create intelligent machines, the use of semantics for knowledge representation and knowledge-based creation in a system follows the philosophy of lingualism. Different knowledge representations are used in a knowledge-based clinical decision support system. This chapter makes a study of various knowledge representations. The different theories behind the techniques used in the knowledge representations are discussed. The philosophy of lingualism and the use of semantics in computational intelligence are explained, while a study on semantic knowledge representation in clinical decision support systems is made. The conclusion is the explanation as to how ontological engineering can be used to create computational intelligence.}
}
@article{ZAROUALI2024108024,
title = {Personality and susceptibility to political microtargeting: A comparison between a machine-learning and self-report approach},
journal = {Computers in Human Behavior},
volume = {151},
pages = {108024},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003758},
author = {Brahim Zarouali and Tom Dobber and Jurrian Schreuder},
keywords = {Political microtargeting, Persuasion, Personality, Social media, Algorithms},
abstract = {Based on recent technological advances, campaigners and political actors can use psychographic-based political marketing. Yet, empirical evidence about its effectiveness is still very limited. Based on self-congruity theory, a pre-registered experiment (N = 280) investigated the persuasion effects of personality-congruent political microtargeting on the attitude toward the political party and voting intentions of citizens. More precisely, the focus was on the thinking vs feeling personality dimension (MBTI), and it was tested whether this personality “interacts” with exposure to a matching advertising appeal: rational vs. emotional political ad. To do so, two different methodological approaches were used: 1) a machine learning approach; 2) a self-report survey measure of personality. Results revealed significant “congruence effects” between personality and ad appeal, and showed that perceived ad relevance was serving as the underlying mechanism (mediator). However, these results were only found when the self-report measure of personality was used. When the algorithmic approach was used, no significant results were found. These findings feed into timely societal, methodological, and theoretical contributions.}
}
@incollection{BYRNE1997105,
title = {Cognitive Processes in Counterfactual Thinking about what Might Have Been},
editor = {Douglas L. Medin},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {37},
pages = {105-154},
year = {1997},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60501-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108605010},
author = {Ruth M.J. Byrne}
}
@article{NITYANANDA2020R159,
title = {Insect Neurobiology: Divergent Neural Computations in Predatory Insects},
journal = {Current Biology},
volume = {30},
number = {4},
pages = {R159-R161},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.12.035},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219316689},
author = {Vivek Nityananda},
abstract = {Summary
A comparative approach to neuroscience can greatly increase our understanding of how mechanisms map onto behaviour. A new study comparing two predatory insects demonstrates how neurons that are homologous can nonetheless mediate different computations and behaviour.}
}
@article{KOKOLAKIS2023110732,
title = {Bounded rational Dubins vehicle coordination for target tracking using reinforcement learning},
journal = {Automatica},
volume = {149},
pages = {110732},
year = {2023},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2022.110732},
url = {https://www.sciencedirect.com/science/article/pii/S0005109822005982},
author = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis},
keywords = {Game theory, Target tracking, Bounded rationality, Reinforcement learning, Switched systems, Target allocation},
abstract = {In this paper, we address the problem of cooperative tracking of multiple heterogeneous targets by deploying multiple and heterogeneous pursuers exhibiting different decision-making capabilities. Initially, under infinite resources, we formulate a game between the evader and the pursuing team, with an evader being the maximizing player and the pursuing team being the minimizing one. Subsequently, we relax the perfect rationality assumption via the use of a level-k thinking framework that allows the evaders to not exhibit the same levels of rationality. Such rationality policies are computed by using a reinforcement learning-based architecture and are proven to form Nash policies as the thinking levels increase. Finally, in the case of multiple pursuers against multiple targets, we develop a switched learning scheme with multiple convergence sets by assigning the most intelligent pursuers to the most intelligent evaders.}
}
@article{JONCZYK2024120752,
title = {Operating in a second language lowers cognitive interference during creative idea generation: Evidence from brain oscillations in bilinguals},
journal = {NeuroImage},
volume = {297},
pages = {120752},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120752},
url = {https://www.sciencedirect.com/science/article/pii/S1053811924002490},
author = {Rafał Jończyk and Iga Krzysik and Olga Witczak and Katarzyna Bromberek-Dyzman and Guillaume Thierry},
keywords = {Creativity, Bilingualism, EEG, Alternate uses task, Alpha frequency, Beta frequency},
abstract = {Tasks measuring human creativity overwhelmingly rely on both language comprehension and production. Although most of the world's population is bilingual, few studies have investigated the effects of language of operation on creative output. This is surprising given that fluent bilinguals master inhibitory control, a mechanism also at play in creative idea evaluation. Here, we compared creative output in the two languages of Polish(L1)-English(L2) bilinguals engaged in a cyclic adaptation of the Alternative Uses Task increasing the contribution of idea evaluation (convergent thinking). We show that Polish-English bilinguals suffer less cognitive interference when generating unusual uses for common objects in the L2 than the L1, without incurring a significant drop in idea originality. Right posterior alpha oscillation power, known to reflect creative thinking, increased over cycles. This effect paralleled the increase in originality ratings over cycles, and lower alpha power (8–10 Hz) was significantly greater in the L1 than the L2. Unexpectedly, we found greater beta (16.5–28 Hz) desynchronization in the L2 than the L1, suggesting that bilingual participants suffered less interference from competing mental representations when performing the task in the L2. Whereas creative output seems unaffected by language of operation overall, the drop in beta power in the L2 suggests that bilinguals are not subjected to the same level of semantic flooding in the second language as they naturally experience in their native language.}
}
@article{WINITZKY19921,
title = {Structure and process in thinking about classroom management: An exploratory study of prospective teachers},
journal = {Teaching and Teacher Education},
volume = {8},
number = {1},
pages = {1-14},
year = {1992},
issn = {0742-051X},
doi = {https://doi.org/10.1016/0742-051X(92)90036-3},
url = {https://www.sciencedirect.com/science/article/pii/0742051X92900363},
author = {Nancy Winitzky},
abstract = {Current research on teaching centers on teachers' thinking. What teachers know and, especially, how they reflect on their practice are considered central to understanding teaching. Part of the research on teachers' knowledge concerns cognitive structure (schemata), how teachers organize their knowledge; it is thought that complex, highly structured schemata are related to skillful teaching performance. While it is sensible to assume that schemata and reflection, structure and process, are linked, no data exist to support that assumption. In the present study, cognitive structure and reflection data were collected from 15 prospective teachers. The strength of the correlation between those variables was .48 (p = .05). Implications for theory, research, and practice are discussed.}
}
@article{SOSA2018157,
title = {Innovation Teams and Organizational Creativity: Reasoning with Computational Simulations},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {4},
number = {2},
pages = {157-170},
year = {2018},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2018.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S240587261730076X},
author = {Ricardo Sosa and Andy Connor},
keywords = {Organizational climate, Agent-based simulation, Creative teams, Leadership},
abstract = {A computational social simulation encourages systematic reasoning about the management of innovation teams and organizational creativity. This article draws upon historical literature to identify a potential dilemma faced by business organizations: Is it better to promote creative behavior across a whole organization or focus on the development of small and highly creative teams? We formulate the dilemma from the literature on organizational creativity, and explore it using a multi-agent simulation. Our study models creative behavior abstractly, as the ability to introduce novelty. By varying the scale and scope of non-conformist behavior in the simulation, our research supports the systematic study of the breadth vs. depth dilemma. The results of this study invite an informed examination of strategies to sustain innovation based on the introduction of either a small number of significantly novel ideas, or a large number of novel but more familiar ideas. Results from this study on change agency also indicate that there is a possible trade-off between a highly creative team and its creative efficiency, drawing attention to the importance of a creative critical mass in an organization. We also discuss the implications of these results and our research approach.}
}
@article{GJORGJIEVA2021iii,
title = {Editorial overview: Theoretical and computational approaches to decipher brain function from molecules to behavior},
journal = {Current Opinion in Neurobiology},
volume = {70},
pages = {iii-vii},
year = {2021},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2021.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438821001379},
author = {Julijana Gjorgjieva and Ila Fiete}
}
@article{LEE20152858,
title = {The Benin experience: How computational modeling can assist major vaccine policy changes in low and middle income countries},
journal = {Vaccine},
volume = {33},
number = {25},
pages = {2858-2861},
year = {2015},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2015.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X15004752},
author = {Bruce Y. Lee and Benjamin Schreiber and Angela R. Wateska and Diana L. Connor and Hamadou M. Dicko and Philippe Jaillard and Mercy Mvundura and Carol Levin and Mélanie Avella and Leila A. Haidari and Shawn T. Brown},
keywords = {Benin, Vaccine, Supply chain, Computational modeling},
abstract = {While scientific studies can show the need for vaccine policy or operations changes, translating scientific findings to action is a complex process that needs to be executed appropriately for change to occur. Our Benin experience provided key steps and lessons learned to help computational modeling inform and lead to major policy change. The key steps are: engagement of Ministry of Health, identifying in-country “champions,” directed and efficient data collection, defining a finite set of realistic scenarios, making the study methodology transparent, presenting the results in a clear manner, and facilitating decision-making and advocacy. Generating scientific evidence is one component of policy change. Enabling change requires orchestration of a coordinated set of steps that heavily involve key stakeholders, earn their confidence, and provide them with relevant information. Our Benin EVM+CCEM+HERMES Process led to a decision to enact major changes and could serve as a template for similar approaches in other countries.}
}
@article{ANDREJCZUK2019104799,
title = {Synergistic team composition: A computational approach to foster diversity in teams},
journal = {Knowledge-Based Systems},
volume = {182},
pages = {104799},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119302746},
author = {Ewa Andrejczuk and Filippo Bistaffa and Christian Blum and Juan A. Rodríguez-Aguilar and Carles Sierra},
keywords = {Team composition, Exact algorithms, Heuristic algorithms, Optimisation, Coalition formation},
abstract = {Co-operative learning in heterogeneous teams refers to learning methods in which teams are organised both to accomplish academic tasks and for individuals to gain knowledge. Competencies, personality and the gender of team members are key factors that influence team performance. Here, we introduce a team composition problem, the so-called synergistic team composition problem (STCP), which incorporates such key factors when arranging teams. Thus, the goal of the STCP is to partition a set of individuals into a set of synergistic teams: teams that are diverse in personality and gender and whose members cover all required competencies to complete a task. Furthermore, the STCP requires that all teams are balanced in that they are expected to exhibit similar performances when completing the task. We propose two efficient algorithms to solve the STCP. Our first algorithm is based on a linear programming formulation and is appropriate to solve small instances of the problem. Our second algorithm is an anytime heuristic that is effective for large instances of the STCP. Finally, we thoroughly study the computational properties of both algorithms in an educational context when grouping students in a classroom into teams using actual-world data.}
}
@article{GHAVANLOO20231,
title = {Experimental and computational physics of fullerenes and their nanocomposites: Synthesis, thermo-mechanical characteristics and nanomedicine applications},
journal = {Physics Reports},
volume = {996},
pages = {1-116},
year = {2023},
note = {Experimental and computational physics of fullerenes and their nanocomposites: Synthesis, thermo-mechanical characteristics and nanomedicine applications},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2022.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0370157322003775},
author = {Esmaeal Ghavanloo and Hashem Rafii-Tabar and Ayesha Kausar and Georgios I. Giannopoulos and S. Ahmad Fazelzadeh},
keywords = {Fullerene molecules, Nanocomposites, Synthesis, Computational modeling, Thin films, Mechanical properties, Thermal properties, Vibrational properties, Molecular dynamics, Molecular mechanics, Micromechanics, Nanomedicine, Nanoneuroscience application},
abstract = {It is an established paradigm in the emerging fields of nanoscience, nanotechnology and molecular engineering that a very important domain of fundamental research is associated with carbon-based materials. Ever since the discovery of the first member of the fullerene family (C60) in 1985, and the subsequent discovery of the other members, fullerenes as a nanoscopic allotrope of carbon with anticipated extensive applications in all areas of nanoscience and nanotechnology (both industrial and medical), materials science and engineering, condensed matter physics and chemistry have occupied a central position in research activities across the globe. Detailed investigations, both experimental and theoretical/computational, into their morphology, mechanical, thermal, chemical, biological, electronic, optical and structural properties have led to the emergence of a well-established and independent science of fullerenes, providing very valuable information both in basic and applied sciences. A comprehensive review of these properties of fullerenes, particularly their applications in the above fields will provide valuable up-to-date and essential background information for engaging in new research in this field and also be able to develop new concepts and applications of these exotic carbon structures. For instance, a recent development is their applications in the emerging field of nanoneuroscience, a field interfacing nanoscience and neuroscience. In this extensive, albeit selective survey, related mainly to the C60 fullerenes, the processes involving their experimental synthesis, theoretical formulation of their geometrical structures, their mechanical and thermal properties and nanomedical applications have been reviewed and summarized both within the experimental and theoretical/computational domains. Essential theoretical concepts, ranging from discrete atomistic molecular dynamics and molecular mechanics methods to continuum-based methods have been expounded in order to facilitate the pursuance of the reviewed literature and also to aid in the development of further research in this field.}
}
@article{TEZDUYAR19971349,
title = {Parallel computational methods for 3D simulation of a parafoil with prescribed shape changes},
journal = {Parallel Computing},
volume = {23},
number = {9},
pages = {1349-1363},
year = {1997},
note = {Parallel computing methods in applied fluid mechanics},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(97)00057-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167819197000574},
author = {T. Tezduyar and V. Kalro and W. Garrard},
keywords = {Parallel finite elements, Parafoil dynamics, Space-time formulation, 3D simulation},
abstract = {In this paper we describe parallel computational methods for 3D simulation of the dynamics and fluid dynamics of a parafoil with prescribed, time-dependent shape changes. The mathematical model is based on the time-dependent, 3D Navier-Stokes equations governing the incompressible flow around the parafoil and Newton's law of motion governing the dynamics of the parafoil, with the aerodynamic forces acting on the parafoil calculated from the flow field. The computational methods developed for these 3D simulations include a stabilized space-time finite element formulation to accommodate for the shape changes, special mesh generation and mesh moving strategies developed for this purpose, iterative solution techniques for the large, coupled nonlinear equation systems involved, and parallel implementation of all these methods on scalable computing systems such as the Thinking Machines CM-5. As an example, we report 3D simulation of a flare maneuver in which the parafoil velocity is reduced by pulling down the flaps. This simulation requires solution of over 3.6 million coupled, nonlinear equations at every time step of the simulation.}
}
@article{MCCLELLAND1993209,
title = {Computational approaches to cognition: top-down approaches},
journal = {Current Opinion in Neurobiology},
volume = {3},
number = {2},
pages = {209-216},
year = {1993},
issn = {0959-4388},
doi = {https://doi.org/10.1016/0959-4388(93)90212-H},
url = {https://www.sciencedirect.com/science/article/pii/095943889390212H},
author = {James L. McClelland and David C. Plaut},
abstract = {Computational models are useful tools for exploring the nature of human cognitive processes. In particular, connectionist models are providing researchers with new ways of thinking about the basic nature of cognition and its implementation in the brain. They support novel explanations of important aspects of perception, memory, language, thought and cognitive development, and allow cognitive processes to be linked with the underlying physiological mechanisms. The models also aid our understanding of how disorders of brain function lead to disorders of cognition.}
}
@article{HIBERTY1998237,
title = {Thinking and computing valence bond in organic chemistry1Dedicated to the memory of Professor Joseph Gerratt, in appreciation of his outstanding contributions to modern ab initio valence bond methodology.1},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {451},
number = {3},
pages = {237-261},
year = {1998},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(98)00208-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128098002085},
author = {Philippe C. Hiberty},
keywords = {Valence bond, Hybridization, Symmetry breaking, Resonance energy, Breathing orbitals},
abstract = {This paper presents a short survey of some recent ab initio valence bond methods and their applications, and is aimed at justifying and encouraging a valence bond view of organic chemistry, as complementary to the molecular orbital approach. In the first section, the qualitative VB description of the elementary interactions is recalled and compared to the MO model. It is shown that the VB picture is fundamentally correct, even for the well-known cases of the low-lying states of dioxygen and the 4n/4n+2 aromaticity rule. The second section briefly discusses the classical VB method, which deals with atomic orbitals that are optimized for the free atoms and kept unchanged in molecules, then describes modern ab initio VB methods that all perform orbital optimization in molecular calculations. The generalized valence bond and spin-coupled theories both provide a one-configuration wavefunction. While the former is generally used with some time-saving restrictions such as the strong-orthogonality restriction and the perfect-pairing approximation, the latter releases any orthogonality constraint and allows all possible spin couplings. Multiconfiguration methods are also discussed, as well as methods using different orbitals for different structures. Some computational applications of these methods are presented in the last section. It is shown that if given full freedom to optimize its shape with the variational principle as a unique criterion, a one-configuration wavefunction spontaneously takes the form of a VB wavefunction displaying localized orbitals, and presents a picture in terms of hybrid orbitals and/or resonance between limiting structures, very close to the traditional qualitative picture. The concept of hybridization is firmly supported, as the unique outcome of the highest computational level still compatible with the orbital picture. The description of conjugated systems in terms of resonating Kekulé structures is also fully justified and shown to be the best framework for discussing questions such as the distortive tendencies of conjugated π-electronic systems, or violations of Hund's rules. The ab initio VB approach can be used for quantifying some traditional paradigms such as the role of the delocalization energy in the acidity of carboxylic acids and enols, or in the properties of the amide/thioamide functional group. It is also shown to be an elegant solution to some difficult computational problems like the symmetry-breaking artefact or the inclusion of dynamical correlation in the description of the chemical bond. Lastly, some of the methods presented here are shown to be appropriate for the calculation of diabatic potential surfaces, with applications to the Shaik–Pross reactivity model of the VB curve-crossing correlation diagrams.}
}
@article{IDEKER2009820,
title = {The Thinking Man's Cell},
journal = {Cell},
volume = {138},
number = {5},
pages = {820-821},
year = {2009},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2009.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0092867409010411},
author = {Trey Ideker}
}
@article{KONG2023100126,
title = {Complementary role of large language models in educating undergraduate design of distillation column: Methodology development},
journal = {Digital Chemical Engineering},
volume = {9},
pages = {100126},
year = {2023},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2023.100126},
url = {https://www.sciencedirect.com/science/article/pii/S2772508123000443},
author = {Zong Yang Kong and Vincentius Surya Kurnia Adi and Juan Gabriel Segovia-Hernández and Jaka Sunarso},
keywords = {ChatGPT, Chemical engineering education, Large language models, Distillation, Industry 4.0, Mass transfer},
abstract = {This paper explores the integration of large language models (LLMs), such as ChatGPT, in chemical engineering education, departing from conventional practices that may not be universally accepted. While there is ongoing debate surrounding the acceptance of LLMs, driven by concerns over computational instability and potential inconsistencies, their inevitability in shaping our communication and interaction with technology cannot be ignored. As educators, we are positioned to play a vital role in guiding students toward the responsible, effective, and synergetic use of LLMs. Focusing specifically on distillation column design in undergraduate mass-transfer courses, this study demonstrates how ChatGPT can be utilized as an auxiliary tool to create interactive learning environments and simulate real-world engineering thinking processes. It emphasizes the need for students to develop critical thinking skills and a thorough understanding of LLM principles, taking responsibility for their use and creations. While ChatGPT should not be solely relied upon, its integration with fundamental principles of chemical engineering is crucial. The effectiveness and limitations of ChatGPT are exemplified through two case studies, showcasing the importance of manual calculations and established simulation software as primary tools for guiding and validating engineering results and analyses. This paper also addresses the pedagogical implications of integrating LLMs into mass transfer courses, encompassing curriculum integration, facilitation, guidance, and ethical considerations. Recommendations are provided for incorporating LLMs effectively into the curriculum. Overall, this study contributes to the advancement of chemical engineering education by examining the benefits and limitations of LLMs as educational aids in the design process.}
}
@article{STAHL199833,
title = {Is step-j thinking an arbitrary modelling restriction or a fact of human nature?},
journal = {Journal of Economic Behavior & Organization},
volume = {37},
number = {1},
pages = {33-51},
year = {1998},
issn = {0167-2681},
doi = {https://doi.org/10.1016/S0167-2681(98)00075-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167268198000754},
author = {Dale O. Stahl},
abstract = {In `Boundedly Rational Rule Learning in a Guessing Game,' Games and Economic Behavior, 16 (1996), we combined Nagel's (1995) model of boundedly rational players with a `law of effect' learning model, and the synthesis outperformed alternative theories when confronting Nagel's data. In that model, there were four boundedly rational behavioral rules (step-j, j=0, 1, 2, 3), each corresponding to an integer level of depth of reasoning. It is legitimate to ask for a justification of the restriction to these `integer' rules. Why is it not reasonable to suppose that some player believes that 50% of the population is step-0, and 50% is step-1, and so himself adopts something like a step-1.5 rule? This paper constructs a tractable model with potentially infinitely many non-integer rules and conducts comparison tests. The main conclusion is that allowing for non-integer rules does not help to explain the data. Therefore, by Occam's Razor, the integer rule model is preferred. These results suggest that step-j thinking is a fact of human nature rather that an arbitrary modelling restriction.}
}
@incollection{SHARMA202353,
title = {Chapter 2 - Computational approaches in drug discovery and design},
editor = {Rupesh Kumar Gautam and Mohammad Amjad Kamal and Pooja Mittal},
booktitle = {Computational Approaches in Drug Discovery, Development and Systems Pharmacology},
publisher = {Academic Press},
pages = {53-93},
year = {2023},
isbn = {978-0-323-99137-7},
doi = {https://doi.org/10.1016/B978-0-323-99137-7.00009-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991377000095},
author = {Priyanka Sharma and Kalicharan Sharma and Mukesh Nandave},
keywords = {Molecular modeling, Molecular docking, Molecular dynamics simulation, QSAR, Bioinformatics},
abstract = {Drug development is a costly and time-consuming procedure. The medicine must meet certain characteristics such as nontoxicity, bioavailability, and potency. Establishing a better drug-like compound has now become a difficult and error-prone endeavor in light of ever-increasing expectations for effectiveness, intensity, and stability. The emergence of conformations of chemical therapeutic targets, as well as developments in computational techniques and bioinformatics, have accelerated the use of molecular modeling in pharmaceutical research. Numerous molecular modeling methodologies used in recent pharmacological studies are reviewed in this chapter. Structure- and ligand-based drug design, protein modeling and visualization molecular docking, virtual screening, molecular dynamics simulation, pharmacophore modeling, and QSAR techniques have all been discussed. In addition, we make key database resources and tools available to the researchers and scientists for future prospects.}
}
@article{TIRADORAMOS2010855,
title = {Fourth Workshop on Teaching Computational Science (WTCS 2010)},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {855-856},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.093},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910000943},
author = {A. Tirado-Ramos and A.B. Shiflet},
keywords = {Teaching, Computational science, Modeling, Simulation},
abstract = {The Workshop on Teaching Computational Science (WTCS), taking place within the International Conference on Computational Science (ICCS), is a platform for discussing innovations in teaching computational science in its various aspects, e.g. modeling and simulation, at all levels and contexts. Innovations may cover the context of formal courses or self-directed learning, involving, for example, curriculum development, introductory programming, service courses, specialist undergraduate and postgraduate topics, as well as industry-related short courses. This editorial provides an introduction to the work presented during the sessions in Amsterdam.}
}
@article{YOUSEF2024137753,
title = {Biological and computational assessment of new synthesized nicotinamides as potential immunomodulatory VEGFR-2 inhibitors},
journal = {Journal of Molecular Structure},
volume = {1305},
pages = {137753},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137753},
url = {https://www.sciencedirect.com/science/article/pii/S002228602400276X},
author = {Reda G. Yousef and Alaa Elwan and Abdallah E. Abdallah and Hazem Elkady and Ahmed B.M. Mehany and Mariam Ali Abo-Saif and Mohamed M. Radwan and Mahmoud A. ElSohly and Ibrahim M. Ibrahim and Mohamed A. Elkady and Mohamed Ayman El-Zahabi and Ibrahim H. Eissa},
keywords = {Nicotinamides, Anticancer, VEGFR-2, Apoptosis, Immunomodulatory, Computational studies},
abstract = {As an extension to our preceding studies on nicotinamide derivatives as anticancer agents, new nicotinamide-based candidates were designed and synthesized as VEGFR-2 inhibitors. The in vitro cytotoxic activity of the synthesized compounds was evaluated against three human cancer cell lines (MCF-7, HepG-2 and HCT-116). The IC50 values for compound 17 were 2.61± 0.01, 3.20 ± 0.02, and 2.46 ± 0.01 µM, respectively, compared to sorafenib (4.21±0.03, 3.40 ± 0.02, and 5.30 ± 0.04 µM) against MCF-7, HePG-2, and HCT-116. This indicated that compound 17 possess double strength relative to sorafenib against both MCF-7 and HCT-116. Compound 17 was the most promising VEGFR-2 inhibitor with IC50 value of 0.34 μM that was slightly better than that of sorafenib (0.38 μM). Further studies displayed the ability of compound 17 to arrest the growth of HCT-116 cells at the Pre-G1 and S phases. Additionally, compound 17 induced a significant increase in the total apoptosis rate of HCT-116 cells from 1.82 % to 26.69 %. Moreover, it showed high selectivity indices against HCT-116, HepG2, and MCF-7 cancer cells. Furthermore, compound 17 showed potent inhibitory activities on TNF-α and IL-6 and showed a notable rise in caspase-3 level. In addition, the potentiality of the designed derivatives to bind with and inhibit the VEGFR-2 enzyme was indicated by molecular docking assessments. MD simulation studies revealed the stability of compound 17 in the active site of VEGFR-2 for 100 ns. Based on the previous findings, compound 17 appears to be a promising apoptotic VEGFR-2 inhibitor and could potentially direct future efforts towards the development of novel anticancer medications.}
}
@article{COSTA201227,
title = {Systems pathology: A critical review},
journal = {Molecular Oncology},
volume = {6},
number = {1},
pages = {27-32},
year = {2012},
issn = {1574-7891},
doi = {https://doi.org/10.1016/j.molonc.2011.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S1574789111001438},
author = {Jose Costa},
keywords = {Systems biology, Systems pathology, Translational research},
abstract = {The technological advances of the last twenty years together with the dramatic increase in computational power have injected new life into systems-level thinking in Medicine. This review emphasizes the close relationship of Systems Pathology to Systems Biology and delineates the differences between Systems Pathology and Clinical Systems Pathology. It also suggests an algorithm to support the application of systems-level thinking to clinical research, proposes applying systems-level thinking to the health care systems and forecasts an acceleration of preventive medicine as a result of the coupling of personal genomics with systems pathology.}
}
@article{CHAPLESKI2020101435,
title = {A Molecular-Scale Approach to Rare-Earth Beneficiation: Thinking Small to Avoid Large Losses},
journal = {iScience},
volume = {23},
number = {9},
pages = {101435},
year = {2020},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2020.101435},
url = {https://www.sciencedirect.com/science/article/pii/S2589004220306258},
author = {Robert C. Chapleski and Azhad U. Chowdhury and Anna K. Wanhala and Vera Bocharova and Santanu Roy and Philip C. Keller and Dylan Everly and Santa Jansone-Popova and Alexander Kisliuk and Robert L. Sacci and Andrew G. Stack and Corby G. Anderson and Benjamin Doughty and Vyacheslav S. Bryantsev},
keywords = {Chemical Engineering, Spectroscopy, Physical Inorganic Chemistry, Surface Chemistry},
abstract = {Summary
Separating rare-earth-element-rich minerals from unwanted gangue in mined ores relies on selective binding of collector molecules at the interface to facilitate froth flotation. Salicylhydroxamic acid (SHA) exhibits enhanced selectivity for bastnäsite over calcite in microflotation experiments. Through a multifaceted approach, leveraging density functional theory calculations, and advanced spectroscopic methods, we provide molecular-level mechanistic insight to this selectivity. The hydroxamic acid moiety introduces strong interactions at metal-atom surface sites and hinders subsurface-cation stabilization at vacancy-defect sites, in calcite especially. Resulting from hydrogen-bond-induced interactions, SHA lies flat on the bastnäsite surface and shows a tendency for multilayer formation at high coverages. In this conformation, SHA complexation with bastnäsite metal ions is stabilized, leading to advanced flotation performance. In contrast, SHA lies perpendicular to the calcite surface due to a difference in cationic spacing. We anticipate that these insights will motivate rational design and selection of future collector molecules for enhanced ore beneficiation.}
}
@article{LERON2014126,
title = {Functions via everyday actions: Support or obstacle?},
journal = {The Journal of Mathematical Behavior},
volume = {36},
pages = {126-134},
year = {2014},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S073231231400056X},
author = {Uri Leron and Tamar Paz},
keywords = {Functions, Composition of functions, Intuitive thinking, Analytical thinking, Dual-process theory, Actions on objects, Changing-the-input misconception},
abstract = {The general context of this paper is the power of intuitive thinking, and how it can help or hinder analytical thinking. The research literature in cognitive psychology teems with tasks where intuitive thinking leads subjects to “non-normative” answers, including tasks for which they have all the knowledge necessary for the normative answer. The best explanation to date for such phenomena is dual-process theory, which stipulates the activation of a quick automatic intuitive process (System 1), together with the failure of the heavy, lazy, and computationally expensive analytical process (System 2) to intervene and correct the intuitive response. In an earlier paper, we have documented a clash between intuitive and analytical thinking concerning functions, which we have termed the changing-the-input phenomenon. The discovery of the changing-the-input phenomenon, however, left us with a puzzle: Why has this phenomenon concerning functions – a purely mathematical concept – been observed in computer science classes but not in mathematics ones? The purpose of the present paper is to address this puzzle. More generally we ask, under what conditions the changing-the-input phenomenon will or will not be manifested? Still more generally, in learning about functions, when is the intuitive scaffolding of functions via actions-on-tangible-objects helpful, and when does it get in the way of deeper understanding?}
}
@article{HAN20241,
title = {Ground threat prediction-based path planning of unmanned autonomous helicopter using hybrid enhanced artificial bee colony algorithm},
journal = {Defence Technology},
volume = {32},
pages = {1-22},
year = {2024},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2023.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S2214914723001071},
author = {Zengliang Han and Mou Chen and Haojie Zhu and Qingxian Wu},
keywords = {UAH, Path planning, Ground threat prediction, Hybrid enhanced, Collaborative thinking},
abstract = {Unmanned autonomous helicopter (UAH) path planning problem is an important component of the UAH mission planning system. Aiming to reduce the influence of non-complete ground threat information on UAH path planning, a ground threat prediction-based path planning method is proposed based on artificial bee colony (ABC) algorithm by collaborative thinking strategy. Firstly, a dynamic threat distribution probability model is developed based on the characteristics of typical ground threats. The dynamic no-fly zone of the UAH is simulated and established by calculating the distribution probability of ground threats in real time. Then, a dynamic path planning method for UAH is designed in complex environment based on the real-time prediction of ground threats. By adding the collision warning mechanism to the path planning model, the flight path could be dynamically adjusted according to changing no-fly zones. Furthermore, a hybrid enhanced ABC algorithm is proposed based on collaborative thinking strategy. The proposed algorithm applies the leader-member thinking mechanism to guide the direction of population evolution, and reduces the negative impact of local optimal solutions caused by collaborative learning update strategy, which makes the optimization performance of ABC algorithm more controllable and efficient. Finally, simulation results verify the feasibility and effectiveness of the proposed ground threat prediction path planning method.}
}
@article{FORD200437,
title = {Electrophysiological evidence of corollary discharge dysfunction in schizophrenia during talking and thinking},
journal = {Journal of Psychiatric Research},
volume = {38},
number = {1},
pages = {37-46},
year = {2004},
issn = {0022-3956},
doi = {https://doi.org/10.1016/S0022-3956(03)00095-5},
url = {https://www.sciencedirect.com/science/article/pii/S0022395603000955},
author = {Judith M. Ford and Daniel H. Mathalon},
keywords = {Schizophrenia, Corollary discharge, N1, EEG coherence},
abstract = {Failure of corollary discharge, a mechanism for distinguishing self-generated from externally-generated percepts, has been posited to underlie certain positive symptoms of schizophrenia, including auditory hallucinations. Although originally described in the visual system, corollary discharge may exist in the auditory system, whereby signals from motor speech commands prepare auditory cortex for self-generated speech. While associated with sensorimotor systems, it might also apply to inner speech or thought, regarded as our most complex motor act. We had four aims in the studies summarized in this paper: (1) to demonstrate the corollary discharge phenomenon during talking and inner speech in human volunteers using event-related brain potentials (ERPs), (2) to demonstrate that the corollary discharge is abnormal in patients with schizophrenia, (3) to demonstrate the role of frontal speech areas in the corollary discharge during talking, and (4) to relate the dysfunction of the corollary discharge in schizophrenia to auditory hallucinations. Using EEG and ERP measures, we addressed each aim in patients with schizophrenia (DSM IV) and healthy control subjects. The N1 component of the ERP reflected dampening of auditory cortex responsivity during talking and inner speech in control subjects but not in patients. EEG measures of coherence indicated inter-dependence of activity in the frontal speech production and temporal speech reception areas during talking in control subjects, but not in patients, especially those who hallucinated. These data suggest that a corollary discharge from frontal areas where thoughts are generated fails to alert auditory cortex that they are self-generated, leading to the misattribution of inner speech to external sources and producing the experience of auditory hallucinations.}
}
@article{HALPERN2015246,
title = {Algorithmic rationality: Game theory with costly computation},
journal = {Journal of Economic Theory},
volume = {156},
pages = {246-268},
year = {2015},
note = {Computer Science and Economic Theory},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2014.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0022053114000611},
author = {Joseph Y. Halpern and Rafael Pass},
keywords = {Costly computation, Bounded rationality},
abstract = {We develop a general game-theoretic framework for reasoning about strategic agents performing possibly costly computation. In this framework, many traditional game-theoretic results (such as the existence of a Nash equilibrium) no longer hold. Nevertheless, we can use the framework to provide psychologically appealing explanations of observed behavior in well-studied games (such as finitely repeated prisoner's dilemma and rock–paper–scissors). Furthermore, we provide natural conditions on games sufficient to guarantee that equilibria exist.}
}
@incollection{KAUFMANN1993123,
title = {Chapter 5 Mental Imagery: Fixed or Multiple Meanings? Nature and Function of Imagery in Creative Thinking},
editor = {Beverly Roskos-Ewoldsen and Margaret Jean Intons-Peterson and Rita E. Anderson},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {98},
pages = {123-150},
year = {1993},
booktitle = {Imagery, Creativity, and Discovery},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)60141-7},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508601417},
author = {Geir Kaufmann and Tore Helstrup},
abstract = {Publisher Summary
This chapter presents the composition of mental imagery and elucidates the processes involved in imaging and the ways in which the processes interact. The work of Kosslyn, aimed at clarifying the basic process components and the general mechanics of the imaging process and Finke's probing of the levels of equivalence between imagery and perception, also belong to the conceptual category of research where the focus is on the nature and properties of imagery. Experimental evidence from a task devised by Finke indicates an important role of visual imagery in the integration of initially unrelated elements of experience into new combinations. This experimental evidence lends support to theories of symbolic representations that emphasize the potential of visual imagery as a vehicle for creative thought. Even if Chambers and Reisberg have overstated their case in their distinction between perceiving and imaging, they have, nevertheless, been able to demonstrate an important dimension of difference between two types of activities.}
}
@article{KU2021114105,
title = {Computational linguistic analysis applied to a semantic fluency task: A replication among first-episode psychosis patients with and without derailment and tangentiality},
journal = {Psychiatry Research},
volume = {304},
pages = {114105},
year = {2021},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2021.114105},
url = {https://www.sciencedirect.com/science/article/pii/S0165178121004029},
author = {Benson S. Ku and Luca Pauselli and Michael A. Covington and Michael T. Compton},
keywords = {Derailment, First-episode psychosis, Formal thought disorder, Loose associations, Psychosis, Schizophrenia, Semantic fluency tasks},
abstract = {Automated tools do not yet exist to measure formal thought disorder, including derailment and tangentiality, both of which can be subjectively rated using the Scale for the Assessment of Positive Symptoms after a clinical research interview. CoVec, a new automated tool, measures the semantic similarity among words averaged in a five- and ten-word window (Coherence-5 and Coherence-10, respectively). One prior report demonstrated that this tool was able to differentiate between patients with those types of thought disorder and patients without them (and controls). Here, we attempted a replication of the initial findings using data from a different sample of patients hospitalized for initial evaluation of first-episode psychosis. Participants were administered a semantic fluency task and the animal lists were analyzed with CoVec. In this study, we partially replicated the prior findings, showing that first-episode patients with derailment had significantly lower Coherence-5 and Coherence-10 compared with patients without derailment. Further research is warranted on this and other highly reliable and objective methods of detecting formal thought disorder through simple assessments such as semantic fluency tasks.}
}
@article{FABRY2018793,
title = {Turing redux: Enculturation and computation},
journal = {Cognitive Systems Research},
volume = {52},
pages = {793-808},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2018.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041718301724},
author = {Regina E. Fabry},
keywords = {Enculturation, Mathematical cognition, Computation, Hybrid cognition, Neural plasticity, Embodied cognition},
abstract = {Many of our cognitive capacities are shaped by enculturation. Enculturation is the acquisition of cognitive practices such as symbol-based mathematical practices, reading, and writing during ontogeny. Enculturation is associated with significant changes to the organization and connectivity of the brain and to the functional profiles of embodied actions and motor programs. Furthermore, it relies on scaffolded cultural learning in the cognitive niche. The purpose of this paper is to explore the components of symbol-based mathematical practices. Phylogenetically, these practices are the result of concerted organism-niche interactions that have led from approximate number estimations to the emergence of discrete, symbol-based mathematical operations. Ontogenetically, symbol-based mathematical practices are associated with plastic changes to neural circuitry, action schemata, and motor programs. It will be suggested that these practices rely on previously acquired capacities such as subitizing and counting. With these considerations in place, I will argue that computations, understood in the sense of Turing (1936), are a specific kind of symbol-based mathematical practices that can be realized by human organisms, machines, or by hybrid organism-machine systems. In sum, this paper suggests a new way to think about mathematical cognition and computation.}
}
@article{20167,
title = {What Is the Key Best Practice for Collaborating with a Computational Biologist?},
journal = {Cell Systems},
volume = {3},
number = {1},
pages = {7-11},
year = {2016},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2016.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S240547121630223X}
}
@article{BRYANT201034,
title = {Thinking inside the box: A participatory, computer-assisted approach to scenario discovery},
journal = {Technological Forecasting and Social Change},
volume = {77},
number = {1},
pages = {34-49},
year = {2010},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2009.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S004016250900105X},
author = {Benjamin P. Bryant and Robert J. Lempert},
keywords = {Scenario Discovery, Scenario planning, Robust decision making},
abstract = {Scenarios provide a commonly used and intuitively appealing means to communicate and characterize uncertainty in many decision support applications, but can fall short of their potential especially when used in broad public debates among participants with diverse interests and values. This paper describes a new approach to participatory, computer-assisted scenario development that we call scenario discovery, which aims to address these challenges. The approach defines scenarios as a set of plausible future states of the world that represent vulnerabilities of proposed policies, that is, cases where a policy fails to meet its performance goals. Scenario discovery characterizes such sets by helping users to apply statistical or data-mining algorithms to databases of simulation-model-generated results in order to identify easy-to-interpret combinations of uncertain model input parameters that are highly predictive of these policy-relevant cases. The approach has already proved successful in several high impact policy studies. This paper systematically describes the scenario discovery concept and its implementation, presents statistical tests to evaluate the resulting scenarios, and demonstrates the approach on an example policy problem involving the efficacy of a proposed U.S. renewable energy standard. The paper also describes how scenario discovery appears to address several outstanding challenges faced when applying traditional scenario approaches in contentious public debates.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{WATFORD2019114707,
title = {Progress in data interoperability to support computational toxicology and chemical safety evaluation},
journal = {Toxicology and Applied Pharmacology},
volume = {380},
pages = {114707},
year = {2019},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2019.114707},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X19303151},
author = {Sean Watford and Stephen Edwards and Michelle Angrish and Richard S. Judson and Katie {Paul Friedman}},
keywords = {Data Interoperability, Computational Toxicology, Bioinformatics, Databases, Applications},
abstract = {New approach methodologies (NAMs) in chemical safety evaluation are being explored to address the current public health implications of human environmental exposures to chemicals with limited or no data for assessment. For over a decade since a push toward “Toxicity Testing in the 21st Century,” the field has focused on massive data generation efforts to inform computational approaches for preliminary hazard identification, adverse outcome pathways that link molecular initiating events and key events to apical outcomes, and high-throughput approaches to risk-based ratios of bioactivity and exposure to inform relative priority and safety assessment. Projects like the interagency Tox21 program and the US EPA ToxCast program have generated dose-response information on thousands of chemicals, identified and aggregated information from legacy systems, and created tools for access and analysis. The resulting information has been used to develop computational models as viable options for regulatory applications. This progress has introduced challenges in data management that are new, but not unique, to toxicology. Some of the key questions require critical thinking and solutions to promote semantic interoperability, including: (1) identification of bioactivity information from NAMs that might be related to a biological process; (2) identification of legacy hazard information that might be related to a key event or apical outcomes of interest; and, (3) integration of these NAM and traditional data for computational modeling and prediction of complex apical outcomes such as carcinogenesis. This work reviews a number of toxicology-related efforts specifically related to bioactivity and toxicological data interoperability based on the goals established by Findable, Accessible, Interoperable, and Reusable (FAIR) Data Principles. These efforts are essential to enable better integration of NAM and traditional toxicology information to support data-driven toxicology applications.}
}
@article{THEODOROPOULOS2021100335,
title = {Augmented Reality and programming education: A systematic review},
journal = {International Journal of Child-Computer Interaction},
volume = {30},
pages = {100335},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100335},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000544},
author = {Anastasios Theodoropoulos and George Lepouras},
keywords = {Augmented Reality (AR), Programming learning, Coding learning, CS education, Review study},
abstract = {In recent years, Augmented Reality (AR) usage in the learning process has been growing. AR tools and environments lead to a variety of positive outcomes and impacts for educational purposes. Similarly, AR is changing the learning process in the Computer Science (CS) Education domain. There are numerous studies that adopt the immersive AR technology in order to improve Computational Thinking (CT) or programming skills, in several contexts. However, there are not sufficient studies that analyze the meaningful characteristics or the advantages and disadvantages of AR in the field. In order to better understand the impact of AR in programming education we performed a systematic literature review. This review analyzes 31 studies in the field. It explores the evolution of this developing technology, the challenges and issues that AR offers and discusses how this work can benefit student learning and further research.}
}
@article{LIU2021107410,
title = {A new computational method for acquiring effect knowledge to support product innovation},
journal = {Knowledge-Based Systems},
volume = {231},
pages = {107410},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107410},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121006729},
author = {Hongwei Liu and Wenqiang Li and Yan Li},
keywords = {TRIZ, Product innovation design, Effect knowledge representation, Functional Basis, IPC},
abstract = {Effect provides a scientific principle-level means for product function realization. The unexpected or new application of effects can create high-level innovations enabling products long-term technical advantages and market competitiveness. Acquiring design knowledge is the vital first step of conducting product innovation activities. In order to capture the effect knowledge that can efficiently aid high-level product innovation, this article proposes a new computational method. The method stems from a novel effect knowledge representation considering both functional and technical area features, and utilizes functional-flow terms of Functional Basis and technical area categories of international patent classification (IPC) respectively to standardize the modelling of the two kinds of features. Based on such representation, the method reasonably combines syntactic analysis, WordNet and word vector technologies to extract the desired effect knowledge from IPC text. To evaluate the method, this article first compares the acquired knowledge with those in a comprehensive human-compiled effect database, and then applies the knowledge to aid the innovation design of several mechanical products with different technical backgrounds. Evaluation results and the discussion based on them suggest the feasibility and potential of the proposed method in automatically acquiring well-organized effect knowledge system, as well as in aiding high-level product innovation.}
}
@article{ARFE2020103807,
title = {The effects of coding on children's planning and inhibition skills},
journal = {Computers & Education},
volume = {148},
pages = {103807},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103807},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300099},
author = {Barbara Arfé and Tullio Vardanega and Lucia Ronconi},
keywords = {Coding, Computational thinking, Executive function, Primary school children, Problem-solving},
abstract = {Computational thinking (CT) and the coding element of it are progressively entering in the primary school curriculum worldwide. Yet, little is known about the effects of these skills on children's cognitive development. In a cluster-randomized controlled trial, we examined how 1st-grade children's gains in coding skills that follow instructional intervention transfer to two important executive functions (EFs): planning and response inhibition. One-hundred seventy-nine (179) first graders from 5 schools and 10 class groups, with no prior experience of coding, were randomly assigned to an experimental (coding, 5 classes) or control (standard STEM, 5 classes) instructional condition. The experimental intervention involved 8 h of coding activities (two weekly lessons for 4 weeks), through the Code.org platform. Children in the control group were exposed to standard STEM instruction. Four coding tasks drawn from Code.org, two standardized planning tasks (Elithorn maze test and Tower of London, ToL, test) and two standardized response inhibition tasks (NEPSY-II inhibition subtest and numerical Stroop), were used to assess children's skills at the pretest and posttest (after the instructional intervention). To measure retention, the same skills were also assessed for 44 children from the experimental group 5 weeks from the posttest (follow up). The results show that practice with coding through Code.org not only improved measurably children's ability to solve coding problems, but also their EFs, increasing the time children spent planning, their ability to solve standardized planning tasks, and to inhibit prepotent responses. Such findings add to the still limited literature on the cognitive effects of coding, deepening our understanding of the positive implications of introducing Computational Thinking early in the school curriculum.}
}
@article{WANG2020106763,
title = {Fuzzy Linear regression based on approximate Bayesian computation},
journal = {Applied Soft Computing},
volume = {97},
pages = {106763},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106763},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620307018},
author = {Ning Wang and Marek Reformat and Wen Yao and Yong Zhao and Xiaoqian Chen},
keywords = {Fuzzy linear regression, Bayes statistics, Approximate Bayesian computation},
abstract = {Fuzzy linear regression with crisp inputs and fuzzy output data constitutes an important modeling problem. Basic strategies used to solve this problem, i.e., the possibilistic method and the least squares method, together with their extensions, have some drawbacks. The possibilistic methods put emphasis on an inclusion property while the least squares methods focus on a central tendency property. Therefore, many researchers work on combining these two methods to obtain a better performance. In this paper, in contrast to most existing techniques which treat fuzzy linear regression as an optimization problem, we set the problem of constructing a fuzzy linear regression model in Bayesian statistics and propose a new fuzzy linear regression method based on approximate Bayesian computation (ABC). The method applies the likelihood-free inference algorithm ABC to generate independent samples of unknown model coefficients from Bayesian posterior distribution. This overcomes difficulty of defining likelihood function in fuzzy environment. By adjusting a prior distribution and a threshold of the ABC algorithm, the proposed approach can flexibly balance the inclusion property of the possibilistic methods and the central tendency property of the least squares methods. The convergence property of the proposed ABC algorithm is verified by a numerical example. Two measuring criteria, i.e., a distance metric and a degree of fitting index, which indicate the central tendency property and the inclusion property, respectively, are introduced to evaluate the quality of regression results. Three numerical examples are applied to show the performances of the proposed method. The numerical results are also compared with those obtained by some classical and recently proposed approaches. Additionally, a practical engineering application example is used to illustrate effectiveness of the proposed method.}
}
@article{KITA202021,
title = {Computational design of generalized centrifugal puzzles},
journal = {Computers & Graphics},
volume = {90},
pages = {21-28},
year = {2020},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S009784932030056X},
author = {Naoki Kita and Takafumi Saito},
keywords = {Computational design, Digital fabrication, Puzzles},
abstract = {Mechanical puzzles have fascinated many people for a long time. While some puzzles require complex procedures to solve, there are puzzles that can be solved easily if the solver understands the underlying mechanism. In this paper, we focus on mechanical puzzles that can be solved by spin such that centrifugal force is applied to the internal mechanical core to unlock the locked state. While traditional centrifugal puzzles are limited to simple shapes, we propose a computational design method to generalize such puzzles by embedding the mechanical core into 3D models. We parameterize the internal core mechanism and optimize the design under several design constraints, and we generate a support structure that helps users solve puzzles easily because generalized puzzles cannot always be spun steadily and easily due to complex surfaces and non-flat contact areas. Additionally, we embed multiple cores into a model. To solve a multi-core puzzle, the user must follow certain orders to unlock each locking mechanism. We fabricate a variety of designed puzzles and demonstrate whether they can be physically unlocked.}
}
@article{WINTER20181,
title = {The art of the Wunderlich cube and the development of spatial abilities},
journal = {International Journal of Child-Computer Interaction},
volume = {18},
pages = {1-7},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917301010},
author = {Victor Winter and Betty Love and Cindy Corritore},
keywords = {Spatial reasoning, Mathematical analysis, Coding, 3D printing},
abstract = {This paper advocates for a future where the teaching of math and art are harmoniously intertwined as they were in the days of da Vinci. In this future, code provides the “brush” that enables the expression of artistic ideas and mathematical structures in digital and digitally-fabricated mediums. This educational idea is motivated by (1) literature supporting the position that visual thinking and spatial reasoning significantly impact STEAM disciplines, and (2) Piaget’s theory of cognitive development in which children, in the concrete operational stage, solve problems relating to physical objects (i.e., they learn-by-making). A project is then described involving the creation of a 3D artifact we call a Wunderlich cube — a mathematical artifact that embodies numerous spatial reasoning puzzles. An understanding of the properties of the Wunderlich cube is developed through manual construction using LEGO®, mathematical analysis, computational thinking, coding, and 3D printing.}
}
@article{MOTOMURA20103,
title = {Multi-aspect data analysis for investigating human computation mechanism},
journal = {Cognitive Systems Research},
volume = {11},
number = {1},
pages = {3-15},
year = {2010},
note = {Brain Informatics},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000521},
author = {Shinichi Motomura and Ning Zhong},
keywords = {Multi-aspect data analysis, Brain informatics methodology, Human computation mechanism, EEG and fMRI},
abstract = {In the paper, we present a multi-aspect data analysis approach for investigating human computation mechanism. Multi-aspect analysis in multiple human brain data sources is an important methodology in Brain Informatics, which emphasizes on a systematic way for investigating human information processing mechanisms, including measuring, collecting, modeling, transforming, managing, and mining multiple human brain data obtained from various cognitive experiments by using powerful equipments, such as fMRI and EEG. After giving an outline of Brain Informatics methodology, we describe how to design cognitive experiments of mental arithmetic task with multiple difficulty levels for obtaining multiple EEG and fMRI data sources, and how to analyze such data for investigating the spatiotemporal characteristics and flow of human computation processing. Such an investigation can be regarded as a case study using Brain Informatics methodology. Experimental results show the usefulness of our approach.}
}
@article{VANCOUVER201456,
title = {Change one can believe in: Adding learning to computational models of self-regulation},
journal = {Organizational Behavior and Human Decision Processes},
volume = {124},
number = {1},
pages = {56-74},
year = {2014},
issn = {0749-5978},
doi = {https://doi.org/10.1016/j.obhdp.2013.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0749597813001180},
author = {Jeffrey B. Vancouver and Justin M. Weinhardt and Ronaldo Vigo},
keywords = {Computational model, Motivation, Dynamics, Learning},
abstract = {Theories of self-regulation describe motivation as a dynamic process of goal choice and goal striving. To facilitate those processes, individuals learn about themselves and their environment, which is an internal dynamic process. However, the precise nature of the relationship between these learning and motivational processes is not well specified. This article integrates formal models of learning, goal choice, and goal striving using a single information processing structure found in self-regulatory models of motivation. Results from two published studies (DeShon and Rench, 2009, Schmidt and DeShon, 2007) validate the model. In both cases, the integrated model accounts for findings that previous theories of self-regulation could not explain. Discussion focuses on additional tests to validate the model and on the value of incorporating formal models from the cognitive, learning, and motivational literatures to account for behavior in complex settings and over time.}
}
@article{COONS2015126,
title = {Grease pencils and the persistence of individuality in computationally produced custom objects},
journal = {Design Studies},
volume = {41},
pages = {126-136},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000599},
author = {ginger “all-lower-case” coons and Matt Ratto},
keywords = {computer aided design, design tools, participatory design, social design, computational craft},
abstract = {This article explores the relationship between an established craft production method and a computational adaptation of that method. In looking at a specific tool, the grease pencils used in the fitting and production of prosthetic limbs, we examine the ways in which complexity, tacit understandings, and human movement are translated into a collection of variables and considerations manipulable in a digital environment. We discuss, briefly, the persistent individuality of objects like prosthetic sockets, and the ways in which their materiality and necessarily custom nature push back against assumptions that computational production is generalizing, disembodied, and abstract.}
}
@article{KARSAKOV2015730,
title = {Improving Visualization Courses in Russian Higher Education in Computational Science and High Performance Computing},
journal = {Procedia Computer Science},
volume = {66},
pages = {730-739},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034328},
author = {Andrey Karsakov and Anna Bilyatdinova and Alexey Bezgodov},
keywords = {Visualization course, Computational science, Higher education},
abstract = {In order to keep up with the fast-paced and widespread technologies and applications of visualization, worldwide education community is actively implementing visualization courses in curricula of undergraduate and graduate programs. A study of the state of the art in the teaching visualization in Russian higher education shows the necessity to improve the quality and breadth of knowledge of the visualization courses. In this paper we propose our approach to overcome the national and historical challenges in teaching visualization in Russian STEM higher education on the example of Computational Science and High Performance Computing double degree Master's programs in ITMO University. We offer a smooth transition to the modern relevant syllabus content by presenting two courses’ designs with same width but with various depth in knowledge that should to be studied. At the end of the paper we give some discussions about future works in development visualization courses in Russia.}
}
@incollection{COUCLELIS2009245,
title = {Computational Human Geography},
editor = {Rob Kitchin and Nigel Thrift},
booktitle = {International Encyclopedia of Human Geography},
publisher = {Elsevier},
address = {Oxford},
pages = {245-250},
year = {2009},
isbn = {978-0-08-044910-4},
doi = {https://doi.org/10.1016/B978-008044910-4.00669-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080449104006696},
author = {H. Couclelis},
keywords = {Agent-based models, Cellular automata, Geocomputation, Geo(infor)matics, GIS, Location-based services, Models/modeling, Public participation GIS, Spatial analysis},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. Geographic information systems (GIS) and science are a big part of computational human geography but the notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, most aspects of spatial analysis, and an increasing number of other areas. Computation in human geography goes back to the beginnings of the quantitative revolution and is philosophically related though methodologically distinct from it. Two major thrusts have persisted through the years: the use of numerical techniques to solve large, complex quantitative problems; and the development of models of complex spatial processes expressed directly in computational terms. Typical exponents of the latter kinds of applications are cellular automata models of urban and environmental processes, and agent-based models of spatial decision and behavior. More recent developments involve applications of mobile and portable computing. Critiques of computational human geography originate from both within the field and from the humanistic and social theory perspectives. The former address a number of epistemological and methodological problems while the latter tend to focus on issues of ontology and representation.}
}
@article{PETZSCHNER2017421,
title = {Computational Psychosomatics and Computational Psychiatry: Toward a Joint Framework for Differential Diagnosis},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {421-430},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2017.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0006322317315846},
author = {Frederike H. Petzschner and Lilian A.E. Weber and Tim Gard and Klaas E. Stephan},
keywords = {Allostasis, Cybernetics, Hierarchical Bayesian model, Homeostasis, Inference, Metacognition, Prediction error},
abstract = {This article outlines how a core concept from theories of homeostasis and cybernetics, the inference-control loop, may be used to guide differential diagnosis in computational psychiatry and computational psychosomatics. In particular, we discuss 1) how conceptualizing perception and action as inference-control loops yields a joint computational perspective on brain-world and brain-body interactions and 2) how the concrete formulation of this loop as a hierarchical Bayesian model points to key computational quantities that inform a taxonomy of potential disease mechanisms. We consider the utility of this perspective for differential diagnosis in concrete clinical applications.}
}
@article{BYSTRITSKY2012428,
title = {Computational non-linear dynamical psychiatry: A new methodological paradigm for diagnosis and course of illness},
journal = {Journal of Psychiatric Research},
volume = {46},
number = {4},
pages = {428-435},
year = {2012},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2011.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0022395611002615},
author = {A. Bystritsky and A.A. Nierenberg and J.D. Feusner and M. Rabinovich},
keywords = {Phenomenology, Mathematical models, Non-linear dynamics, Winner less competition, Psychopathology},
abstract = {The goal of this article is to highlight the significant potential benefits of applying computational mathematical models to the field of psychiatry, specifically in relation to diagnostic conceptualization. The purpose of these models is to augment the current diagnostic categories that utilize a “snapshot” approach to describing mental states. We hope to convey to researchers and clinicians that non-linear dynamics can provide an additional useful longitudinal framework to understand mental illness. Psychiatric phenomena are complex processes that evolve in time, similar to many other processes in nature that have been successfully described and understood within deterministic chaos and non-linear dynamic computational models. Dynamical models describe mental processes and phenomena that change over time, more like a movie than a photograph, with multiple variables interacting over time. The use of these models may help us understand why and how current diagnostic categories are insufficient. They may also provide a new, more descriptive and ultimately more predictive approach leading to better understanding of the interrelationship between psychological, neurobiological, and genetic underpinnings of mental illness.}
}
@article{PAPAVLASOPOULOU2020105939,
title = {Coding activities for children: Coupling eye-tracking with qualitative data to investigate gender differences},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105939},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219300950},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Coding, Computational thinking, Eye-tracking, Gender differences, Learning strategies},
abstract = {Computational thinking and coding are becoming an integral part of K-12 education, with female students being underrepresented in such subjects. The proliferation of technological tools and programming environments offers the opportunity for creative coding activities for children and increases the need for appropriate instructional practices. In this study, we design and evaluate a coding workshop for children. Our goal is to examine differences between boys and girls using eye-tracking as an objective measure and triangulating the findings with qualitative data coming from children's interviews. The results show no statistically significant difference between female and male gaze and learning gain during the coding activity; interestingly, the qualitative data show differences in the strategies and implemented practices during coding, and in perceptions about those coding activities. Our results highlight that further studies need to utilize objective measures and unveil necessary differences in the design and implementation of coding activities. Furthermore, our results provide objective evidence that female students do not lack in competences compared to boys, but simply that they have a different approach during coding activities and different perspectives about coding, an approach that needs to be cultivated and nurtured.}
}
@article{FLETCHER1998747,
title = {Computational fluid dynamics modelling of an entrained flow biomass gasifier},
journal = {Applied Mathematical Modelling},
volume = {22},
number = {10},
pages = {747-757},
year = {1998},
issn = {0307-904X},
doi = {https://doi.org/10.1016/S0307-904X(98)10025-2},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X98100252},
author = {D.F. Fletcher and B.S. Haynes and J. Chen and S.D. Joseph},
abstract = {A mathematical model, based on the Computational Fluid Dynamics package CFX4, has been developed to study the flow within an entrained flow biomass gasifier. The gasifier is designed to convert sawdust and chopped cotton gin trash into a low calorific value gas which can be burned in a modified engine to run a generator. Calculations of the flowfield are performed using the standard k–ϵ model and a Differential Reynolds Stress Model (DSM). In line with current thinking, it is shown that the k–ϵ model gives unphysical results for complex swirling flows, whereas the DSM model performs well. Particle tracking was performed to determine typical trajectories for the biomass and char and the results used to determine means of avoiding slagging in the gasifier base. The simulations have proved to be very useful to the designers who are now using the model to optimise the design.}
}
@article{KUMAR20223122,
title = {Experimental Spectroscopic, Quantum Computational, Hirshfeld Surface, Molecular Docking, and Electronic Excitation Studies on an Antibiotic Agent: SDZ},
journal = {Polycyclic Aromatic Compounds},
volume = {43},
number = {4},
pages = {3122-3146},
year = {2022},
issn = {1040-6638},
doi = {https://doi.org/10.1080/10406638.2022.2063909},
url = {https://www.sciencedirect.com/science/article/pii/S1040663822010284},
author = {Mukesh Kumar and Aysha Fatima and Meenakshi Singh and Indresh Verma and Ghazala Khanum and S. Muthu and Khaled Althubeiti and khamael M. Abualnaja and Musheer Ahmad and Nazia Siddiqui and Saleem Javed},
keywords = {DFT, NBO, EDD and HDD, molecular docking},
abstract = {In this report sulfadiazine (SDZ) has been experimentally and quantum chemically investigated. Computational analysis was carried out theoretically using the density functional theory (DFT) approach/B3LYP and 6-311++G(d,p) level to obtain optimized geometrical structure and vibrational modes analysis and other various calculations. A detailed description of the intermolecular interactions of the crystal surface were carried out by means of Hirshfeld surface analysis and fingerprint plots. Exploration of electron excitation from occupied to unoccupied orbitals in a single electron pair occurs, with dimethyl sulfoxide (DMSO) and MeOH as solvents and electron density distribution (EDD) and hole density distribution (HDD) maps were drawn in an excited state. The molecule reactivity region MEP, molecular stability, natural bond orbital (NBO), HOMO–LUMO, dipole moment (μ), polarizability (α), and hyperpolarizability (β) nonlinear optical (NLO), have all been taken into account. NBO analysis was carried out and the hybridization of atoms that form bonds was evaluated. The charge transfer of the title molecule has been examined by TD-DFT method The UV–Vis spectrum was obtained by employing the TDDFT/PCM method and compared with experimental spectra. Calculated HOMO→LUMO energy gap and charge transfer in the molecule was investigated. Chemical descriptors indicate the reactivity of the molecule as a whole, and Fukui function calculations were used to examine the reactive locations of the compound. The electrophilicity index was calculated and the bio-activity of the molecule was studied. However, biological research like drug-likeness and molecular docking are also done on the molecule.}
}
@article{FINDLAY1988165,
title = {Thinking creatively about creative thinking},
journal = {Journal of Social and Biological Structures},
volume = {11},
number = {1},
pages = {165-175},
year = {1988},
issn = {0140-1750},
doi = {https://doi.org/10.1016/0140-1750(88)90059-0},
url = {https://www.sciencedirect.com/science/article/pii/0140175088900590},
author = {C.Scott Findlay and Charles J. Lumsden}
}
@article{VARGASROJAS2022110093,
title = {Prescriptive comprehensive approach for the engineering of products made with composites centered on the manufacturing process and structured design methods: Review study performed on filament winding},
journal = {Composites Part B: Engineering},
volume = {243},
pages = {110093},
year = {2022},
issn = {1359-8368},
doi = {https://doi.org/10.1016/j.compositesb.2022.110093},
url = {https://www.sciencedirect.com/science/article/pii/S1359836822004693},
author = {Erik Vargas-Rojas},
keywords = {Composites thinking, Design method, Filament winding, Product engineering, TRIZ},
abstract = {At first, this research seeks to develop the technology required to fabricate two surfaces of revolution via filament winding: a concavity and a convexity. Concerning mandrels technology, the detachable mandrel concept is chosen among others. Their engineering is conducted conventionally based on free-thinking design approaches, as well as expertise and overconfidence. Consequently, the demoulding process of the concave surface is inefficient due to the lack of adequate dismantling functions of the respective mandrel, leading to damage of the composite material during demoulding, mandrel rework and delays. These inconveniences motivated a reexamination of the mandrels design process. Thus, three structured design methods were incorporated: Design for Manufacturing and Assembly (DFMA), Functional Analysis (FA) and Theory of Inventive Problem Solving (TIPS, a.k.a. TRIZ). Their synergistic implementation allowed the correct demoulding of the concave surface of revolution. In a second stage, this experience serves as reference for proposing a comprehensive, iterative, prescriptive and unified approach aimed at filament-wound products. It focuses on the base material (composites) and the manufacturing process (filament winding), being applicable to other fabrication processes of composite products. It is based on three models reported in the literature: one for metals, one for composites and one for filament-wound composites. Each of its steps is carried out with well-known structured design methods employed in products and systems engineering, including but not limited to DFMA, FA and TRIZ. As regards results, at the level of the design problem of the mandrels, the importance of the correct establishment of mechanical functions – dismantling in this case – is observed. In particular, how the lack of demoulding functions impacts unfavorably the quality of the final product. As respects the comprehensive approach, a significant outcome is the “filament winding thinking,” as an evolution of other schemes such as “metals” or “composites thinking” followed to generically develop products according to the nature of their base material.}
}
@incollection{SEJNOWSKI2015480,
title = {Computational Neuroscience},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {480-484},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.55011-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868550119},
author = {Terrence J. Sejnowski},
keywords = {Algorithms, Computational models, Neural systems},
abstract = {The goal of computational neuroscience is to understand how brains generate behaviors using computational approaches. Computational models of the brain explore how populations of highly interconnected neurons are formed during development and how they represent, process, store, act upon, and become altered by information present in the body and the environment. Techniques from physics, computer science, and mathematics are used to simulate and analyze these computational models and provide links between the wide range of levels that brains are investigated, from molecular interactions to large-scale systems. Models are also used for interpreting experimental data and providing a conceptual framework for the dynamical properties of neural systems, which should lead to more comprehensive theories of brain function.}
}
@article{RICHARDSON2005615,
title = {The hegemony of the physical sciences: an exploration in complexity thinking},
journal = {Futures},
volume = {37},
number = {7},
pages = {615-653},
year = {2005},
note = {Complexity and the limits of knowledge},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2004.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0016328704001855},
author = {Kurt Richardson},
abstract = {Traditionally the natural sciences, particularly physics, have been regarded as the Gatekeepers of Truth. As such the legitimacy of others forms of knowledge have been called into question, particularly those methods that characterise the ‘softer’ sciences, and even the arts. This paper begins with an extended discussion concerning the main features of a complex system, and the nature of the boundaries that emerge within such systems. Subsequent to this discussion, and by assuming that the Universe at some level can be well-described as a complex system, the paper explores the notion of ontology, or existence, from a complex systems perspective. It is argued that none of the traditional objects of science, or any objects from any discipline, formal or not, can be said to be real in any absolute sense although a substantial realism may be temporarily associated with them. The limitations of the natural sciences is discussed as well as the deep connection between the ‘hard’ and the ‘soft’ sciences. As a result of this complex systems analysis, an evolutionary philosophy referred to as quasi-‘critical pluralism’ is outlined, which is more sensitive to the demands of complexity than contemporary reductionistic approaches.}
}
@incollection{WARE2004351,
title = {Chapter 11 - Thinking with visualizations},
editor = {Colin Ware},
booktitle = {Information Visualization (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {351-386},
year = {2004},
series = {Interactive Technologies},
isbn = {978-1-55860-819-1},
doi = {https://doi.org/10.1016/B978-155860819-1/50014-5},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608191500145},
author = {Colin Ware},
abstract = {Publisher Summary
The best visualizations are not static images to be printed in books, but fluid, dynamic artifacts that respond to the need for a different view or for more detailed information. Visualization can be an interface to a simulation of a complex system; the visualization, combined with the simulation, can create a powerful cognitive augmentation. The visualization is a two-way interface, although highly asymmetric, with far higher bandwidth communication from the machine to the human than in the other direction. The high-bandwidth visualization channel is then used to deliver the results of modeling exercises and database searches. One way to approach the design of an information system is to consider the cost of knowledge. The result of this approach is a kind of cognitive information economics. Activities are analyzed according to the value of what is gained and the cost incurred. There are two kinds of costs: resource costs and opportunity costs. The chapter explores both of these and the economics of cognition and the cognitive cost of knowledge.}
}
@article{HAO20231,
title = {A Commentary on Towards autonomous artificial agents with an active self: Modeling sense of control in situated action},
journal = {Cognitive Systems Research},
volume = {79},
pages = {1-3},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001085},
author = {Chenxu Hao and Nele Russwinkel and Daniel F.B. Haeufle and Philipp Beckerle},
keywords = {Human–robot interaction, Unified models of HRI, Anticipatory thinking},
abstract = {Kahl et al., (2022) present a computational model of an autonomous agent implemented with an active self. With ideas based on the Free Energy Principle (Friston and Kiebel, 2009), their model tackles the challenge to unify higher-level cognitive activities and lower-level sensorimotor control as the autonomous agent maintains situational awareness while interacting with the environment. While Kahl et al., (2022) focus on modeling a single agent, we argue that this challenge similarly appears in modeling human–robot interaction (HRI). In this commentary, we discuss how the conceptual framework from Kahl et al., (2022) could inspire unified models of physical and cognitive HRI and how the modeling approach from Kahl et al., (2022) can potentially be applied to anticipatory thinking in robotics to support the human in daily life.}
}
@article{ANDREWS2019102188,
title = {Black hole as a model of computation},
journal = {Results in Physics},
volume = {13},
pages = {102188},
year = {2019},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2019.102188},
url = {https://www.sciencedirect.com/science/article/pii/S2211379719304036},
author = {G.R. Andrews},
keywords = {Black hole computation, Kerr/CFT correspondence, Holographic principle, Information theory, Gamma-ray spectroscopy, Shannon entropy},
abstract = {This paper focuses on an alternative, more physically realistic model of computation than Etesi and Németi’s relativistic computer in a Malament-Hogarth spacetime (2002) that uses the black hole itself combined with an external observer equipped with a source and some method of measurement of gamma-rays, as opposed to sending a classical computer into a black hole and exploiting the properties of the spacetime to achieve hypercomputation. The source of output, Hawking radiation, is considered along with the constraints imposed by the holographic principle which limit the number of degrees of freedom in the system and consequently the maximum usable information. The Bekenstein-Hawking entropy is converted from the traditional form in terms of the horizon area to that of the Shannon entropy, establishing an analogy between the physical and computational perspectives of the system. Next examples are considered to establish the approximate order of the necessary excitation energy and the resulting gamma-ray interactions which form the input from the observer. Finally, the Turing completeness of the language for this model is considered through a simulation of the Turing machine. The goal is to introduce a model of computation that can later be used to study the relationship between computability and physical systems.}
}
@article{JAY201976,
title = {Intensional computation with higher-order functions},
journal = {Theoretical Computer Science},
volume = {768},
pages = {76-90},
year = {2019},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519301227},
author = {Barry Jay},
keywords = {Intensional computation, Higher-order functions, SF-calculus, Foundations of computation},
abstract = {Intensional computations are those that query the internal structure of their arguments. In a higher-order setting, such queries perform program analysis. This is beyond the expressive power of traditional term rewriting systems, such as lambda-calculus or combinatory logic, as they are extensional. In such settings it has been necessary to encode or quote the program before analysis. However, there are intensional calculi, specifically confluent term rewriting systems, that can analyse higher-order programs within the calculus proper, without quotation; there are even programs that produce the Goedel numbers of their program argument. This paper summarizes the current situation. Highlights include the following observations. We have known since 2011 that the simplest intensional calculus, SF-calculus, supports arbitrary queries of closed normal forms, including equality, pattern-matching, searching and self-interpretation. Recent work, verified using the Coq proof assistant, has shown that all recursive programs can be represented as closed normal forms in SF-calculus, and even in combinatory logic. Thus, we can here deduce that SF-calculus (but not combinatory logic) can define queries of programs. These results are compatible with direct support for lambda-abstraction. Although these results conflict with the traditional understanding of expressive power of combinatory logic and λ-calculus, as developed by Church and Kleene, our recent publication has shown that their approach is compromised by its reliance on encodings. To drive the point home, this paper uses a non-standard encoding to lambda-define a trivial solution of the Halting Problem.}
}
@article{DEV2015232,
title = {Unsolved problems in biology—The state of current thinking},
journal = {Progress in Biophysics and Molecular Biology},
volume = {117},
number = {2},
pages = {232-239},
year = {2015},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079610715000115},
author = {Sukhendu B. Dev},
keywords = {Unsolved biological problems, Millennium Prize, Origin of life},
abstract = {Many outstanding problems have been solved in biology and medicine for which scientists have been awarded prestigious prizes including the Nobel Prize, Lasker Award and Breakthrough Prizes in life sciences. These have been the fruits of years of basic research. From time to time, publications have appeared listing “unsolved” problems in biology. In this article, I ask the question whether it is possible to have such a list, if not a unique one, at least one that is analogous to the Millennium Prize in mathematics. My approach to finding an answer to this question was to gather views of leading biologists. I have also included my own views. Analysis of all the responses received over several years has convinced me that it is difficult, but not impossible, to have such a prize. Biology is complex and very interdisciplinary these days at times involving large numbers of teams, unlike mathematics, where Andrew Wiles spent seven years in complete isolation and secrecy solving Fermat's last theorem. Such an approach is simply not possible in biology. Still I would like to suggest that a similar prize can be established by a panel of distinguished scientists. It would be awarded to those who solved one of the listed problems in biology that warrant a verifiable solution. Despite many different opinions, I found that there is some commonality in the responses I received – I go on to discuss what these are and how they may impact future thinking.}
}
@article{GURSOY201529,
title = {Visualizing making: Shapes, materials, and actions},
journal = {Design Studies},
volume = {41},
pages = {29-50},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000617},
author = {Benay Gürsoy and Mine Özkar},
keywords = {material computing, computational models, design activity, parametric design, reasoning},
abstract = {The increasing interest in materiality currently challenges the long existing traditions that consider visual thinking as the primary actor in design creativity. Shape grammars offer a formalism to represent visual reasoning in design, which is never purely limited to the visual aspects of design processes. Aiming to develop ways to explicitly include material manipulation in a computational formalism, we report on an ongoing exploration of how shape computation extends beyond abstract visual shapes to incorporate material shapes that have a physical existence. We present a materially informed process with shape rules and show that we can apply these rules creatively to explore the physical character of the material.}
}
@article{KACERJA2023101035,
title = {Values in preservice mathematics teachers’ discussions of the Body Mass Index - A critical perspective},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101035},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101035},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000056},
author = {Suela Kacerja and Cyril Julie},
keywords = {Values, Critical thinking, Preservice teachers, Mathematics in society, Critical mathematics education},
abstract = {This article explores the values that come to the fore when preservice mathematics teachers (PTs) 11In the remaining parts of the text, we will refer to preservice teachers as PTs. engage in critical discussions about the role of mathematical models in society. The specific model that was discussed was the Body Mass Index (BMI) 22From now on, the Body Mass Index will be referred to as BMI and is calculated as mass (m) divided by the square of height (h).. From the analysis of the PTs’ discussions of the BMI from a mathematical and societal point of view several mathematical and mathematics educational values were identified such as openness, rationalism, progress, reasoning, evaluating, and problematizing the instrumental understanding of mathematics. In addition, critical thinking about mathematics in society as emphasized in curricula in the three countries involved in the study, was identified with four categories of complementary pairs. Knowing the mathematical and mathematics educational values underpinning PTs’ discussions and their connection to critical thinking is important for successfully engaging with the role of mathematics in society.}
}
@article{VELUPILLAI201440,
title = {Computable and computational complexity theoretic bases for Herbert Simon’s cognitive behavioral economics},
journal = {Cognitive Systems Research},
volume = {29-30},
pages = {40-52},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000405},
author = {K.Vela Velupillai and Ying-Fang Kao},
keywords = {Bounded rationality, Satisficing, Heuristics, Computability, Computational complexity},
abstract = {This paper aims to interpret and formalize Herbert Simon’s cognitive notions of bounded rationality, satisficing and heuristics in terms of computability theory and computational complexity theory. Simon’s theory of human problem solving is analyzed in the light of Turing’s work on Solvable and Unsolvable Problems. It is suggested here that bounded rationality results from the fact that the deliberations required for searching computationally complex spaces exceed the actual complexity that human beings can handle. The immediate consequence is that satisficing becomes the general criterion of decision makers and heuristics are the procedures used for achieving their goals. In such decision problems, it is demonstrated that bounded rationality and satisficing are more general than orthodox, non-cognitive, Olympian rationality and optimization, respectively, and not the other way about.}
}
@article{MAYER2017107,
title = {Understanding scientists’ computational modeling decisions about climate risk management strategies using values-informed mental models},
journal = {Global Environmental Change},
volume = {42},
pages = {107-116},
year = {2017},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016306197},
author = {Lauren A. Mayer and Kathleen Loa and Bryan Cwik and Nancy Tuana and Klaus Keller and Chad Gonnerman and Andrew M. Parker and Robert J. Lempert},
keywords = {Values-informed mental models, Climate change, Risk management, Decision making under uncertainty},
abstract = {When developing computational models to analyze the tradeoffs between climate risk management strategies (i.e., mitigation, adaptation, or geoengineering), scientists make explicit and implicit decisions that are influenced by their beliefs, values and preferences. Model descriptions typically include only the explicit decisions and are silent on value judgments that may explain these decisions. Eliciting scientists’ mental models, a systematic approach to determining how they think about climate risk management, can help to gain a clearer understanding of their modeling decisions. In order to identify and represent the role of values, beliefs and preferences on decisions, we used an augmented mental models research approach, namely values-informed mental models (ViMM). We conducted and qualitatively analyzed interviews with eleven climate risk management scientists. Our results suggest that these scientists use a similar decision framework to each other to think about modeling climate risk management tradeoffs, including eight specific decisions ranging from defining the model objectives to evaluating the model’s results. The influence of values on these decisions varied between our scientists and between the specific decisions. For instance, scientists invoked ethical values (e.g., concerns about human welfare) when defining objectives, but epistemic values (e.g., concerns about model consistency) were more influential when evaluating model results. ViMM can (i) enable insights that can inform the design of new computational models and (ii) make value judgments explicit and more inclusive of relevant values. This transparency can help model users to better discern the relevance of model results to their own decision framing and concerns.}
}
@article{HUIJSER2018170,
title = {The wandering self: Tracking distracting self-generated thought in a cognitively demanding context},
journal = {Consciousness and Cognition},
volume = {58},
pages = {170-185},
year = {2018},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2017.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1053810017301927},
author = {Stefan Huijser and Marieke K. {van Vugt} and Niels A. Taatgen},
keywords = {Self-generated thought, Mind wandering, Self-referential processing, Task demand, Computational cognitive modeling, Eye-tracking},
abstract = {We investigated how self-referential processing (SRP) affected self-generated thought in a complex working memory task (CWM) to test the predictions of a computational cognitive model. This model described self-generated thought as resulting from competition between task- and distracting processes, and predicted that self-generated thought interferes with rehearsal, reducing memory performance. SRP was hypothesized to influence this goal competition process by encouraging distracting self-generated thinking. We used a spatial CWM task to examine if SRP instigated such thoughts, and employed eye-tracking to examine rehearsal interference in eye-movement and self-generated thinking in pupil size. The results showed that SRP was associated with lower performance and higher rates of self-generated thought. Self-generated thought was associated with less rehearsal and we observed a smaller pupil size for mind wandering. We conclude that SRP can instigate self-generated thought and that goal competition provides a likely explanation for how self-generated thoughts arises in a demanding task.}
}
@article{SUN2009124,
title = {Theoretical status of computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {10},
number = {2},
pages = {124-140},
year = {2009},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000429},
author = {Ron Sun},
keywords = {Cognitive modeling, Cognitive architecture, Theory, Simulation, Validation},
abstract = {This article explores the view that computational models of cognition may constitute valid theories of cognition, often in the full sense of the term “theory”. In this discussion, this article examines various (existent or possible) positions on this issue and argues in favor of the view above. It also connects this issue with a number of other relevant issues, such as the general relationship between theory and data, the validation of models, and the practical benefits of computational modeling. All the discussions point to the position that computational cognitive models can be true theories of cognition.}
}
@incollection{YERPUDE2022335,
title = {CHAPTER FOURTEEN - Computational analysis of nanofluids-based drug delivery system: Preparation, current development and applications of nanofluids},
editor = {Shriram S. Sonawane and Hussein A. Mohammed and Arvind Kumar Mungray and Shirish H. Sonawane},
booktitle = {Applications of Nanofluids in Chemical and Bio-medical Process Industry},
publisher = {Elsevier},
pages = {335-364},
year = {2022},
isbn = {978-0-323-90564-0},
doi = {https://doi.org/10.1016/B978-0-323-90564-0.00014-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323905640000143},
author = {S.T. Yerpude and A.K. Potbhare and P.R. Bhilkar and Parag Thakur and Pratiksha Khiratkar and Martin F. Desimone and P.R. Dhongle and Shriram S. Sonawane and Clara Goncalves and R.G. Chaudhary},
keywords = {CFD, Computational analysis, Drug delivery, Mathematical modeling, Nanofluids, Nano-drugs},
abstract = {Nanoparticles have been widely employed as a drug delivery carrier and a direct targeting agent. Off course, nanoparticles have been precisely and accurately designed to improve their therapeutical efficacy. Nowadays, computational modeling is frequently used to design novel and smart nanoparticles. In this chapter, we provide an overview and general idea about nanofluids in association with computational applications aimed at the improvement of nano-drug delivery coordination. Nanotechnology and nanobiotechnology-based conceptual innovations in combination with computational modeling are extensively employed in various areas of basic and applied sciences. On the same line, these technologies have a greater impact in the field of medicine and biology. We intended to look upon different aspects regarding nano-drugs and nanofluids comprising their preparation and stabilization methods and also focusing on mathematical modeling, stability mechanism, and biomedical applications of nanofluids. Similarly, imperative and special concern was given to the topic of computational fluid dynamics (CFD).}
}
@article{OERS199051,
title = {The development of mathematical thinking in school: a comparison of the action- psychological and information-processing approaches},
journal = {International Journal of Educational Research},
volume = {14},
number = {1},
pages = {51-66},
year = {1990},
issn = {0883-0355},
doi = {https://doi.org/10.1016/0883-0355(90)90016-2},
url = {https://www.sciencedirect.com/science/article/pii/0883035590900162},
author = {Bert Van Oers},
abstract = {The learning and teaching of mathematics can be analyzed from different psychological points of view. Information-processing theories focus on the various information-processing mechanisms underlying mathematical competence and try to foster the development of these mechanisms in order to stimulate the growth of mathematical competence. In the action-psychological approach of the cultural-historical school, mathematics is viewed as a kind of culturally developed human activity governed by the rules that mathematicians themselves follow while doing their job. Consequently, the development of mathematical competence is regarded as the formation of a system of meaningful mathematical actions that constitute that activity. At a general theoretical level these approaches can be shown to be basically different and even incompatible. With regard to mathematics education the differences are illustrated with respect to several themes such as task-analysis, automatization, and the learning of elementary arithmetic. Considering insight and meaningful and sophisticated problem-solving as the core of mathematical thinking, the action-psychological approach appears to be the more promising candidate as an aid in the design of future mathematics education.}
}
@article{ADAMATZKY2017469,
title = {East-West paths to unconventional computing},
journal = {Progress in Biophysics and Molecular Biology},
volume = {131},
pages = {469-493},
year = {2017},
note = {Integral Biomathics 2017: The Necessary Conjunction of Western and Eastern Thought Traditions for Exploring the Nature of Mind and Life},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717301177},
author = {Andrew Adamatzky and Selim Akl and Mark Burgin and Cristian S. Calude and José Félix Costa and Mohammad Mahdi Dehshibi and Yukio-Pegio Gunji and Zoran Konkoli and Bruce MacLennan and Bruno Marchal and Maurice Margenstern and Genaro J. Martínez and Richard Mayne and Kenichi Morita and Andrew Schumann and Yaroslav D. Sergeyev and Georgios Ch. Sirakoulis and Susan Stepney and Karl Svozil and Hector Zenil},
keywords = {Unconventional computing, East, West, Spirituality},
abstract = {Unconventional computing is about breaking boundaries in thinking, acting and computing. Typical topics of this non-typical field include, but are not limited to physics of computation, non-classical logics, new complexity measures, novel hardware, mechanical, chemical and quantum computing. Unconventional computing encourages a new style of thinking while practical applications are obtained from uncovering and exploiting principles and mechanisms of information processing in and functional properties of, physical, chemical and living systems; in particular, efficient algorithms are developed, (almost) optimal architectures are designed and working prototypes of future computing devices are manufactured. This article includes idiosyncratic accounts of ‘unconventional computing’ scientists reflecting on their personal experiences, what attracted them to the field, their inspirations and discoveries.}
}
@article{THANATIPANONDA202138,
title = {A multi-computational exploration of some games of pure chance},
journal = {Journal of Symbolic Computation},
volume = {104},
pages = {38-68},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2020.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717120300183},
author = {Thotsaporn “Aek” Thanatipanonda and Doron Zeilberger},
keywords = {Experimental mathematics, Games of pure chance, Symbolic computation},
abstract = {In the spirit of “multi-culturalism”, we use four kinds of computations: simulation, numeric, symbolic, and “conceptual”, to explore some “games of pure chance” inspired by children board games like “Snakes and Ladders” (aka “Chutes and Ladders”) and “gambler's ruin with unlimited credit”. Even more interesting than the many computer-generated specific results described in this paper and its web-site extension, is our broad-minded, ecumenical approach, not favoring, a priori, any one of the above four kinds of computation, but showing that, a posteriori, symbolic computation is the most important one, since (except for simulation) numerics can be made more efficient with the help of symbolics (in the “downward” direction), and, (in the “upward” direction) the mere existence of certain symbolic-computational algorithms imply interesting “qualitative” results, that certain numbers are always rational, or always algebraic, and certain sequences are always polynomial, or C-recursive, or algebraic, or holonomic. This article is accompanied by four Maple packages, and numerous input and output files, that readers can use as templates for their own investigations.}
}
@article{KELLER2018424,
title = {Predictive Processing: A Canonical Cortical Computation},
journal = {Neuron},
volume = {100},
number = {2},
pages = {424-435},
year = {2018},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2018.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0896627318308572},
author = {Georg B. Keller and Thomas D. Mrsic-Flogel},
keywords = {predictive processing, predictive coding, sensory processing, cortex, canonical microcircuit},
abstract = {This perspective describes predictive processing as a computational framework for understanding cortical function in the context of emerging evidence, with a focus on sensory processing. We discuss how the predictive processing framework may be implemented at the level of cortical circuits and how its implementation could be falsified experimentally. Lastly, we summarize the general implications of predictive processing on cortical function in healthy and diseased states.}
}
@article{NIKOLIC2023107820,
title = {Where is the mind within the brain? Transient selection of subnetworks by metabotropic receptors and G protein-gated ion channels},
journal = {Computational Biology and Chemistry},
volume = {103},
pages = {107820},
year = {2023},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2023.107820},
url = {https://www.sciencedirect.com/science/article/pii/S1476927123000117},
author = {Danko Nikolić},
keywords = {Scaling problem, Explanatory gap, Connectionism, Metabotropic receptors, G protein-gated ion channels, Practopoiesis},
abstract = {Perhaps the most important question posed by brain research is: How the brain gives rise to the mind. To answer this question, we have primarily relied on the connectionist paradigm: The brain’s entire knowledge and thinking skills are thought to be stored in the connections; and the mental operations are executed by network computations. I propose here an alternative paradigm: Our knowledge and skills are stored in metabotropic receptors (MRs) and the G protein-gated ion channels (GPGICs). Here, mental operations are assumed to be executed by the functions of MRs and GPGICs. As GPGICs have the capacity to close or open branches of dendritic trees and axon terminals, their states transiently re-route neural activity throughout the nervous system. First, MRs detect ligands that signal the need to activate GPGICs. Next, GPGICs transiently select a subnetwork within the brain. The process of selecting this new subnetwork is what constitutes a mental operation – be it in a form of directed attention, perception or making a decision. Synaptic connections and network computations play only a secondary role, supporting MRs and GPGICs. According to this new paradigm, the mind emerges within the brain as the function of MRs and GPGICs whose primary function is to continually select the pathways over which neural activity will be allowed to pass. It is argued that MRs and GPGICs solve the scaling problem of intelligence from which the connectionism paradigm suffers.}
}
@article{PINE2017385,
title = {Clinical Advances From a Computational Approach to Anxiety},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {385-387},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2016.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0006322316328669},
author = {Daniel S. Pine}
}
@article{1999209,
title = {99/02041 Strategic thinking about nuclear energy: implications of the emerging market structure in electric generation: Bodde, D. L. Energy Policy, 1998, 26, (12), 957–962},
journal = {Fuel and Energy Abstracts},
volume = {40},
number = {3},
pages = {209},
year = {1999},
issn = {0140-6701},
doi = {https://doi.org/10.1016/S0140-6701(99)97811-6},
url = {https://www.sciencedirect.com/science/article/pii/S0140670199978116}
}
@article{GIORGI2023101151,
title = {Conceptual development from the perspective of a brain-inspired robotic architecture},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101151},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000797},
author = {Ioanna Giorgi and Bruno Golosio and Massimo Esposito and Angelo Cangelosi and Giovanni Luca Masala},
keywords = {Brain-inspired model, Cognitive architecture, Robotic model, High-level cognition, Human language, Concepts, Categorisation, Conceptual development, Understanding},
abstract = {Concepts are central to reasoning and intelligent behaviour. Scientific evidence shows that conceptual development is fundamental for the emergence of high-cognitive phenomena. Here, we model such phenomena in a brain-inspired cognitive robotic model and examine how the robot can learn, categorise, and abstract concepts to voluntary control behaviour. The paper argues that such competence arises with sufficient conceptual content from physical and social experience. Hence, senses, motor abilities and language, all contribute to a robot’s intelligent behaviour. To this aim, we devised a method for attaining concepts, which computationally reproduces the steps of the inductive thinking strategy of the Concept Attainment Model (CAM). Initially, the robot is tutor-guided through socio-centric cues to attain concepts and is then tested consistently to use these concepts to solve complex tasks. We demonstrate how the robot uses language to create new categories by abstraction in response to human language-directed instructions. Linguistic stimuli also change the representations of the robot’s experiences and generate more complex representations for further concepts. Most notably, this work shows that this competence emerges from the robot’s ability to understand the concepts similarly to human understanding. Such understanding was also maintained when concepts were expressed in multilingual lexicalisations showing that labels represent concepts that allowed the model to adapt to unfamiliar contingencies in which it did not have directly related experiences. The work concludes that language is an essential component of conceptual development, which scaffolds the cognitive continuum of a robot from low-to-high cognitive skills, including its skill to understand.}
}
@article{LIU2023340,
title = {Research on the standardization strategy of granular computing},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {4},
pages = {340-348},
year = {2023},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666307423000323},
author = {Donghang Liu and Xuekui Shangguan and Keyu Wei and Chensi Wu and Xiaoying Zhao and Qifeng Sun and Yaoyu Zhang and Ruijun Bai},
keywords = {Granular computing, Standardization strategy, Methodology, Standard system},
abstract = {As intelligent systems continue to evolve, problems are becoming increasingly complex. The constant abundance of data puts a higher demand on the value of data utilization. Granular computing is a new computational paradigm for complex problem-solving. It takes structured thinking, structured problem-solving methods, and structured information processing patterns as its research objects and belongs to the scope of higher-level human cognitive mechanism research. The development and application of granular computing must be more standardized and unified. The granular computing standardization strategy is the most direct means to promote the regularization of granular computing. In this paper, we first sort out the main applications of granular computing in standards. According to the characteristics of granular computing, a framework of its standard system is proposed to provide a reference for the subsequent research of granular computing standards. The next direction of the granular computing standards strategy is discussed, and solutions are given.}
}
@article{BERNARD20153982,
title = {Developing a Capability to Elicit and Structure Psychosocial Decision Information within Computational Models},
journal = {Procedia Manufacturing},
volume = {3},
pages = {3982-3989},
year = {2015},
note = {6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2015.07.945},
url = {https://www.sciencedirect.com/science/article/pii/S2351978915009464},
author = {Michael L. Bernard},
keywords = {Knowledge elicitation, Knowledge structure, Cognitive modeling, Social modeling, Systems modeling, Country assessments},
abstract = {There is a recognized need to develop computational models that can represent and simulate the decision making process of various groups across socio-cultural domains [5]. Yet, developing such models can be greatly hampered by the need to acquire and represent information pertaining to the psychological and social aspects of decision-making within these groups. Currently, there are numerous techniques and tools to help facilitate the elicitation and structuring of knowledge within expert-type systems—particularly those that focus on technical processes such as mechanical troubleshooting [3]. However, few techniques and tools have been developed for models that are intended to represent and assess the decision making of groups within different societies—particularly including cultural elements within these societies. This paper seeks to help address this challenge by discussing an approach to eliciting and structuring cross-cultural psychosocial and behavioral-economic elements within a theory-based assessment model. This work was developed to address the needs of Sandia National Laboratories’ Behavioral Influence Assessment modeling capability, which assesses decision-making within societies. The main component of the knowledge engineering effort is what we call the “knowledge structure.” The knowledge structure acts as scaffolding for the organization of psychosocial processes underlying decision-making, as well as the actual content of that knowledge with respect to a modeled society.}
}
@article{ROWAN2024171672,
title = {Digital technologies to unlock safe and sustainable opportunities for medical device and healthcare sectors with a focus on the combined use of digital twin and extended reality applications: A review},
journal = {Science of The Total Environment},
volume = {926},
pages = {171672},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.171672},
url = {https://www.sciencedirect.com/science/article/pii/S004896972401814X},
author = {Neil J. Rowan},
keywords = {Medical devices, Digital transformation, Design thinking, Sterilization, Sustainability, Circularity},
abstract = {Medical devices have increased in complexity where there is a pressing need to consider design thinking and specialist training for manufacturers, healthcare and sterilization providers, and regulators. Appropriately addressing this consideration will positively inform end-to-end supply chain and logistics, production, processing, sterilization, safety, regulation, education, sustainability and circularity. There are significant opportunities to innovate and to develop appropriate digital tools to help unlock efficiencies in these important areas. This constitutes the first paper to create an awareness of and to define different digital technologies for informing and enabling medical device production from a holistic end-to-end life cycle perspective. It describes the added-value of using digital innovations to meet emerging opportunities for many disposable and reusable medical devices. It addresses the value of accessing and using integrated multi-actor HUBs that combine academia, industry, healthcare, regulators and society to help meet these opportunities. Such as cost-effective access to specialist pilot facilities and expertise that converges digital innovation, material science, biocompatibility, sterility assurance, business model and sustainability. It highlights the marked gap in academic R&D activities (PRISMA review of best publications conducted between January 2010 and January 2024) and the actual list of U.S. FDA's approved and marketed artificial intelligence/machine learning (AI/ML), and augmented reality/virtual reality (AR/VR) enabled-medical devices for different healthcare applications. Bespoke examples of benefits underlying future use of digital tools includes potential implementation of machine learning for supporting and enabling parametric release of sterilized products through efficient monitoring of critical process data (complying with ISO 11135:2014) that would benefit stakeholders. This paper also focuses on the transformative potential of combining digital twin with extended reality innovations to inform efficiencies in medical device design thinking, supply chain and training to inform patient safety, circularity and sustainability.}
}
@article{20161,
title = {Credit for Computation},
journal = {Cell Systems},
volume = {3},
number = {1},
pages = {1-2},
year = {2016},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2016.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S2405471216302289}
}
@article{MORLEY20131221,
title = {Fragment-based hit identification: thinking in 3D},
journal = {Drug Discovery Today},
volume = {18},
number = {23},
pages = {1221-1227},
year = {2013},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2013.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S1359644613002456},
author = {Andrew D. Morley and Angelo Pugliese and Kristian Birchall and Justin Bower and Paul Brennan and Nathan Brown and Tim Chapman and Martin Drysdale and Ian H. Gilbert and Swen Hoelder and Allan Jordan and Steven V. Ley and Andy Merritt and David Miller and Martin E. Swarbrick and Paul G. Wyatt},
abstract = {The identification of high-quality hits during the early phases of drug discovery is essential if projects are to have a realistic chance of progressing into clinical development and delivering marketed drugs. As the pharmaceutical industry goes through unprecedented change, there are increasing opportunities to collaborate via pre-competitive networks to marshal multifunctional resources and knowledge to drive impactful, innovative science. The 3D Fragment Consortium is developing fragment-screening libraries with enhanced 3D characteristics and evaluating their effect on the quality of fragment-based hit identification (FBHI) projects.}
}
@article{HAN2020382,
title = {A computational approach for using social networking platforms to support creative idea generation},
journal = {Procedia CIRP},
volume = {91},
pages = {382-387},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.190},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308374},
author = {Ji Han and Dongmyung Park and Hannah Forbes and Dirk Schaefer},
keywords = {Creativity, Social Media, Idea Generation, Social Networking, Ideation},
abstract = {Good design relies upon the generation of good ideas, but producing ideas, especially creative ones, is increasingly challenging. This may be due to limited relevant information, lack of creative skills, design fixation, or as a result of too many previously existing ideas. Conventional creativity tools, such as brainstorming and TRIZ, as well as advanced methods, such as design-by-analogy, are often employed by designers for idea generation to alleviate some of these challenges. In recent years, computational creativity tools have emerged to support creative idea generation. However, most of these computational tools are data-driven, and thereby employ various databases, for example, existing databases such as the ConceptNet containing past common-sense knowledge, and customized ones containing limited information. The limitations of these databases have constrained the capability of the computational creativity tools. Social media platforms, such as Twitter and Wikipedia, which allow users to create web-based content, have been reported to have billions of users. It can be considered a huge ‘unorganized’ database of information created by a crowd. However, to date little work has been done on the utilization of such crowd-generated knowledge from social media to support actual design activities, especially during the early stages of the design process. In this paper, the authors propose a computational approach to retrieve, process, and reuse the textual knowledge from social networks to prompt designers’ creative mind in producing ideas for new product design and development. They also propose a novel approach to construct crowd knowledge databases, which can be employed by computational tools, as well as used individually, for supporting creative idea generation. A case study involving the use of an existing social media analysis tool to construct a crowd database for helping designers produce ideas has been conducted to provide insights on implementing the proposed approach for creative idea generation.}
}
@article{SINGH20212537,
title = {Resources and computational strategies to advance small molecule SARS-CoV-2 discovery: Lessons from the pandemic and preparing for future health crises},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {2537-2548},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S2001037021001719},
author = {Natesh Singh and Bruno O. Villoutreix},
abstract = {There is an urgent need to identify new therapies that prevent SARS-CoV-2 infection and improve the outcome of COVID-19 patients. This pandemic has thus spurred intensive research in most scientific areas and in a short period of time, several vaccines have been developed. But, while the race to find vaccines for COVID-19 has dominated the headlines, other types of therapeutic agents are being developed. In this mini-review, we report several databases and online tools that could assist the discovery of anti-SARS-CoV-2 small chemical compounds and peptides. We then give examples of studies that combined in silico and in vitro screening, either for drug repositioning purposes or to search for novel bioactive compounds. Finally, we question the overall lack of discussion and plan observed in academic research in many countries during this crisis and suggest that there is room for improvement.}
}
@article{DECAROLIS2011145,
title = {Using modeling to generate alternatives (MGA) to expand our thinking on energy futures},
journal = {Energy Economics},
volume = {33},
number = {2},
pages = {145-152},
year = {2011},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2010.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0140988310000721},
author = {Joseph F. DeCarolis},
keywords = {Mathematical methods (JEL: C02), Optimization, Uncertainty, Modeling},
abstract = {Energy-economy optimization models – encoded with a set of structured, self-consistent assumptions and decision rules – have emerged as a key tool for the analysis of energy and climate policy at the national and international scale. Given the expansive system boundaries and multi-decadal timescales involved, addressing future uncertainty in these models is a critical challenge. The approach taken by many modelers is to build larger models with greater complexity to deal with structural uncertainty, and run a few highly detailed scenarios under different input assumptions to address parametric uncertainty. The result is often large and inflexible models used to conduct analysis that offers little insight. This paper introduces a technique borrowed from the operations research literature called modeling to generate alternatives (MGA) as a way to flex energy models and systematically explore the feasible, near-optimal solution space in order to develop alternatives that are maximally different in decision space but perform well with regard to the modeled objectives. The resultant MGA alternatives serve a useful role by challenging preconceptions and highlighting plausible alternative futures. A simple, conceptual model of the U.S. electric sector is presented to demonstrate the utility of MGA as an energy modeling technique.}
}
@incollection{PALANIAPPAN2019789,
title = {Computational Systems Biology},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {789-795},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20287-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338202872},
author = {Sucheendra K. Palaniappan and Ayako Yachie-Kinoshita and Samik Ghosh},
keywords = {Analytics, Automated pathway curation, Computational systems biology, Data analytics, Mathematical modeling, Network analysis, NLP, Pathway curation, Simulation, Systems biology, Text mining},
abstract = {The unprecedented development in novel and high throughput techniques to understand biology at multiple dimensions has opened unique challenges and opportunities for computational methodologies to harness “big data in biology” and extract actionable insights. New models and methodologies are need for systems biology-based approaches to reconcile data from different spatio-temporal scales, connecting diverse set of computational techniques towards a systems-level understand of living organisms. Current tools and techniques in computational systems biology have demonstrated their usage in various application areas. At the same time, paradigm shifts in experimental techniques, powerful data analytics, modeling and visualization methodologies, have resulted in empowering computational systems biology models and methodologies. These developments will leverage on the advancements in machine learning models, big data management and analysis as well as large scale modeling and simulations. This topic article endeavors to provide key areas of modeling and methodologies– highlighting new directions and developments, to enable computational systems biology to address the new challenges in biology and medicine.}
}
@article{NAGURNEY19953,
title = {Massively parallel computation of spatial price equilibrium problems as dynamical systems},
journal = {Journal of Economic Dynamics and Control},
volume = {19},
number = {1},
pages = {3-37},
year = {1995},
issn = {0165-1889},
doi = {https://doi.org/10.1016/0165-1889(93)00772-V},
url = {https://www.sciencedirect.com/science/article/pii/016518899300772V},
author = {Anna Nagurney and Takashi Takayama and Ding Zhang},
keywords = {Spatial price equilibrium, Dynamical systems, Variational inequalities, Massively parallel computation},
abstract = {In this paper we introduce a dynamical system for the formulation and computation of spatial price equilibrium problems in quantity variables. The set of stationary points of the system corresponds to the set of solutions of the variational inequality problem governing the problem. We propose the Euler-type method for the computation of the equilibrium pattern and provide convergence results. We then demonstrate that the algorithm can be implemented on a massively parallel architecture and illustrate its performance on the Thinking Machine's CM-2 architecture. This research represents the first implementation of a massively parallel approach for the computation of either dynamical systems or variational inequality problems arising in economics.}
}