@article{FRANCIS2022103521,
title = {A framework for dynamic life cycle sustainability assessment and policy analysis of built environment through a system dynamics approach},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103521},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103521},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007873},
author = {Ann Francis and Albert Thomas},
keywords = {Sustainability assessment, System dynamics, Dynamic life cycle sustainability assessment (D-LCSA), Computational modelling, Life cycle assessment},
abstract = {Sustainability is gaining attention, particularly in the building sector, owing to its significant influence on economy, society and environment. However, most assessment methods/frameworks available for this sector focus solely or dominantly on the environmental dimension of sustainability. Hence, a sustainability assessment framework for buildings that accounts for the interdependencies amongst social, economic and environmental aspects is essential. Further, buildings also undergo several time-induced changes in their characteristics, such as changes in electricity consumption, material properties, surrounding infrastructure and energy mix that can influence their sustainability. Therefore, this paper introduces a system dynamics-based methodological framework for Dynamic Life Cycle Sustainability Assessment (D-LCSA) capable of incorporating the dynamic changes in the building characteristics with time and capturing the interactions amongst different sustainability indicators. The usability and utility of the framework is demonstrated using a case study residential project in India. The case study results show that ignoring time-dependant dynamic aspects in sustainability assessment of buildings leads to underestimating the overall sustainability impacts by about 50 per cent and specific environmental impacts by about 12 per cent. Therefore, the study reinforces the need to adopt dynamic thinking through modelling and simulation to predict sustainability performance in the built environment.}
}
@article{CORCORAN2020158,
title = {Language as a biomarker for psychosis: A natural language processing approach},
journal = {Schizophrenia Research},
volume = {226},
pages = {158-166},
year = {2020},
note = {Biomarkers in the Attenuated Psychosis Syndrome},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2020.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0920996420302474},
author = {Cheryl M. Corcoran and Vijay A. Mittal and Carrie E. Bearden and Raquel {E. Gur} and Kasia Hitczenko and Zarina Bilgrami and Aleksandar Savic and Guillermo A. Cecchi and Phillip Wolff},
keywords = {Psychosis, Automated language analysis, Natural language processing, Machine learning, Semantic coherence, Discourse coherence, Referential coherence, Semantic density, Latent semantic analysis, Digital phenotyping, Psychosis risk, Clinical high risk, Ultra high risk, Schizophrenia},
abstract = {Human ratings of conceptual disorganization, poverty of content, referential cohesion and illogical thinking have been shown to predict psychosis onset in prospective clinical high risk (CHR) cohort studies. The potential value of linguistic biomarkers has been significantly magnified, however, by recent advances in natural language processing (NLP) and machine learning (ML). Such methodologies allow for the rapid and objective measurement of language features, many of which are not easily recognized by human raters. Here we review the key findings on language production disturbance in psychosis. We also describe recent advances in the computational methods used to analyze language data, including methods for the automatic measurement of discourse coherence, syntactic complexity, poverty of content, referential coherence, and metaphorical language. Linguistic biomarkers of psychosis risk are now undergoing cross-validation, with attention to harmonization of methods. Future directions in extended CHR networks include studies of sources of variance, and combination with other promising biomarkers of psychosis risk, such as cognitive and sensory processing impairments likely to be related to language. Implications for the broader study of social communication, including reciprocal prosody, face expression and gesture, are discussed.}
}
@article{LIBEROS2019319,
title = {Phase singularity point tracking for the identification of typical and atypical flutter patients: A clinical-computational study},
journal = {Computers in Biology and Medicine},
volume = {104},
pages = {319-328},
year = {2019},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518303901},
author = {A. Liberos and M. Rodrigo and I. Hernandez-Romero and A. Quesada and F. Fernandez-Aviles and F. Atienza and A.M. Climent and M.S. Guillem},
keywords = {Atrial flutter, Phase map, Cardiac model, Body surface potential mapping},
abstract = {Atrial Flutter (AFL) termination by ablating the path responsible for the arrhythmia maintenance is an extended practice. However, the difficulty associated with the identification of the circuit in the case of atypical AFL motivates the development of diagnostic techniques. We propose body surface phase map analysis as a noninvasive tool to identify AFL circuits. Sixty seven lead body surface recordings were acquired in 9 patients during AFL (i.e. 3 typical, 6 atypical). Computed body surface phase maps from simulations of 5 reentrant behaviors in a realistic atrial structure were also used. Surface representation of the macro-reentrant activity was analyzed by tracking the singularity points (SPs) in surface phase maps obtained from band-pass filtered body surface potential maps. Spatial distribution of SPs showed significant differences between typical and atypical AFL. Whereas for typical AFL patients 70.78 ± 16.17% of the maps presented two SPs simultaneously in the areas defined around the midaxialliary lines, this condition was only satisfied in 5.15 ± 10.99% (p < 0.05) maps corresponding to atypical AFL patients. Simulations confirmed these results. Surface phase maps highlights the reentrant mechanism maintaining the arrhythmia and appear as a promising tool for the noninvasive characterization of the circuit maintaining AFL. The potential of the technique as a diagnosis tool needs to be evaluated in larger populations and, if it is confirmed, may help in planning ablation procedures.}
}
@article{JOHNSON20013201,
title = {Methods for 3D computation of fluid–object interactions in spatially periodic flows},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {24},
pages = {3201-3221},
year = {2001},
note = {Advances in Computational Methods for Fluid-Structure Interaction},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00389-3},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500003893},
author = {Andrew Johnson and Tayfun Tezduyar},
abstract = {We present computational methods for 3D simulation of fluid–object interactions in spatially periodic flows. These methods include a stabilized space-time finite element formulation for incompressible flows with spatial periodicity, automatic mesh generation and update techniques for fluid–object mixtures with spatial periodicity, and parallel implementations. The methods can be applied to uni-periodic (i.e., periodic in one direction), bi-periodic, or tri-periodic flows. The methods are described here in the context of tri-periodic flows with fluid–object interactions, and are applied to the simulation of sedimentation of particles in a fluid. We present several case studies where the results obtained provide notable insight into the behavior of fluid–particle mixtures during sedimentation.}
}
@incollection{ALIPPI2019245,
title = {Chapter 12 - Computational Intelligence in the Time of Cyber-Physical Systems and the Internet of Things},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing},
publisher = {Academic Press},
pages = {245-263},
year = {2019},
isbn = {978-0-12-815480-9},
doi = {https://doi.org/10.1016/B978-0-12-815480-9.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154809000128},
author = {Cesare Alippi and Seiichi Ozawa},
keywords = {Brain computing, Cyber-physical systems, Cybersecurity, Embedded systems, Neurodynamics, IoT, Machine learning, Neural networks},
abstract = {The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available energy and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate occurrence of faults, and provide shields against cyberattacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, and the smart world generation whose footprint is already around us.}
}
@article{HARTMANN2021112902,
title = {Model development for evidence-based prioritisation of policy action on emerging chemical and microbial drinking water risks},
journal = {Journal of Environmental Management},
volume = {295},
pages = {112902},
year = {2021},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2021.112902},
url = {https://www.sciencedirect.com/science/article/pii/S0301479721009646},
author = {Julia Hartmann and Juan Carlos Chacon-Hurtado and Eric Verbruggen and Jack Schijven and Emiel Rorije and Susanne Wuijts and Ana Maria {de Roda Husman} and Jan Peter {van der Hoek} and Lisa Scholten},
keywords = {Multi criteria analysis, MCA, Stakeholder consultation, Water contaminants, Pathogen},
abstract = {While the burden of disease from well-studied drinking water contaminants is declining, risks from emerging chemical and microbial contaminants arise because of social, technological, demographic and climatological developments. At present, emerging chemical and microbial drinking water contaminants are not assessed in a systematic way, but reactively and incidence based. Furthermore, they are assessed separately despite similar pollution sources. As a result, risks might be addressed ineffectively. Integrated risk assessment approaches are thus needed that elucidate the uncertainties in the risk evaluation of emerging drinking water contaminants, while considering risk assessors’ values. This study therefore aimed to (1) construct an assessment hierarchy for the integrated evaluation of the potential risks from emerging chemical and microbial contaminants in drinking water and (2) develop a decision support tool, based on the agreed assessment hierarchy, to quantify (uncertain) risk scores. A multi-actor approach was used to construct the assessment hierarchy, involving chemical and microbial risk assessors, drinking water experts and members of responsible authorities. The concept of value-focused thinking was applied to guide the problem-structuring and model-building process. The development of the decision support tool was done using Decisi-o-rama, an open-source Python library. With the developed decision support tool (uncertain) risk scores can be calculated for emerging chemical and microbial drinking water contaminants, which can be used for the evidence-based prioritisation of actions on emerging chemical and microbial drinking water risks. The decision support tool improves existing prioritisation approaches as it combines uncertain indicator levels with a multi-stakeholder approach and integrated the risk assessment of chemical and microbial contaminants. By applying the concept of value-focused thinking, this study addressed difficulties in evidence-based decision-making related to emerging drinking water contaminants. Suggestions to improve the model were made to guide future research in assisting policy makers to effectively protect public health from emerging drinking water risks.}
}
@article{LOURIDAS1999517,
title = {Design as bricolage: anthropology meets design thinking},
journal = {Design Studies},
volume = {20},
number = {6},
pages = {517-535},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00044-1},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000441},
author = {Panagiotis Louridas},
keywords = {aesthetics, design activity, design cognition, metaphor, psychology of design},
abstract = {We identify a metaphor for the design activity: we view design as bricolage. We start from describing bricolage, and we proceed to the relationship of design to art. We obtain a characterisation of design that enables us to show that both traditional and contemporary design are forms of bricolage. We examine the consequences of `design as bricolage' for the relationship between design and science and for the extent of the design activity.}
}
@article{LIN2021103499,
title = {Informational cues or content? Examining project funding decisions by crowdfunders},
journal = {Information & Management},
volume = {58},
number = {7},
pages = {103499},
year = {2021},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103499},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621000732},
author = {Yan Lin and Wai Fong Boh},
keywords = {Experience, Elaboration Likelihood Model, Information Asymmetry, Crowdfunding},
abstract = {We examine how crowdfunder experience affects their reliance on information available on projects. Drawing on elaboration likelihood model and using data from Kickstarter, we apply machine learning techniques and choice modeling to examine the information provided by creators, investigating not only the descriptions, but also the pictures and the videos. We found that more experienced crowdfunders react positively to descriptions exhibiting higher analytical thinking, while less experienced crowdfunders rely more on cues that arouse attention (e.g., number of pictures and positive emotions in videos). We highlight the importance of considering how experience influences crowdfunders’ interpretation of different types of information.}
}
@incollection{PARRY2016255,
title = {Chapter Ten - Using Data Mining and Computational Approaches to Study Intermediate Filament Structure and Function},
editor = {M. Bishr Omary and Ronald K.H. Liem},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {568},
pages = {255-276},
year = {2016},
booktitle = {Intermediate Filament Proteins},
issn = {0076-6879},
doi = {https://doi.org/10.1016/bs.mie.2015.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0076687915004152},
author = {David A.D. Parry},
keywords = {IF chain assembly, Sequence periodicities, Heptad and hendecad substructure, Interchain ionic interactions, IF secondary and tertiary structure, Structural/functional motifs, Mutations},
abstract = {Experimental and theoretical research aimed at determining the structure and function of the family of intermediate filament proteins has made significant advances over the past 20 years. Much of this has either contributed to or relied on the amino acid sequence databases that are now available online, and the data mining approaches that have been developed to analyze these sequences. As the quality of sequence data is generally high, it follows that it is the design of the computational and graphical methodologies that are of especial importance to researchers who aspire to gain a greater understanding of those sequence features that specify both function and structural hierarchy. However, these techniques are necessarily subject to limitations and it is important that these be recognized. In addition, no single method is likely to be successful in solving a particular problem, and a coordinated approach using a suite of methods is generally required. A final step in the process involves the interpretation of the results obtained and the construction of a working model or hypothesis that suggests further experimentation. While such methods allow meaningful progress to be made it is still important that the data are interpreted correctly and conservatively. New data mining methods are continually being developed, and it can be expected that even greater understanding of the relationship between structure and function will be gleaned from sequence data in the coming years.}
}
@article{KOLACHEV2023101756,
title = {General intelligence in middle school students from different Russian regions: Results of PISA-like tests},
journal = {Intelligence},
volume = {98},
pages = {101756},
year = {2023},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2023.101756},
url = {https://www.sciencedirect.com/science/article/pii/S0160289623000375},
author = {Nikita Kolachev and Galina Kovaleva},
keywords = {Intelligence, G-factor, General cognitive ability, Bifactor model, PISA},
abstract = {This study is aimed at investigating the contribution of the general intelligence factor if six PISA domains (reading, mathematical, scientific, financial literacies, global competence, and creative thinking) are combined in one measurement instrument. For achieving our goal, items based on the PISA frameworks are developed, students in grades 5–8 from three different Russian regions are assessed, and three IRT models (unidimensional, multidimensional, and bifactor) are applied to process the data. In addition, the correlations from the multidimensional model are estimated to examine the degree of cognitive specificity and mixture modeling is implemented to investigate ability differentiation across grades. Statistical analysis reveals that the bifactor model comprising one general and six specific factors, has a better fit in each grade. Based on this model, we compute the variance explained by the general factor, with the estimates varying between 60% and 70%. In general, the pure variance explained by specific factors does not exceed 10%. The correlations are above 0.40 in each grade and the averaged associations tend to increase from 6th to 8th grade, although they are smaller in years 6 and 7 compared to year 5. The general ability differentiation effect is observed in grades 6 to 8 and is not present in grade 5. Specific ability differentiation is more pronounced in reading literacy, especially in grade 5 to 7. The results obtained are discussed from the perspective of the ability and developmental differentiation/dedifferentiation problem.}
}
@article{LEWIS2018491,
title = {How Memory Replay in Sleep Boosts Creative Problem-Solving},
journal = {Trends in Cognitive Sciences},
volume = {22},
number = {6},
pages = {491-503},
year = {2018},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2018.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661318300706},
author = {Penelope A. Lewis and Günther Knoblich and Gina Poe},
keywords = {sleep, memory, creativity, reactivation, replay, consolidation},
abstract = {Creative thought relies on the reorganisation of existing knowledge. Sleep is known to be important for creative thinking, but there is a debate about which sleep stage is most relevant, and why. We address this issue by proposing that rapid eye movement sleep, or ‘REM’, and non-REM sleep facilitate creativity in different ways. Memory replay mechanisms in non-REM can abstract rules from corpuses of learned information, while replay in REM may promote novel associations. We propose that the iterative interleaving of REM and non-REM across a night boosts the formation of complex knowledge frameworks, and allows these frameworks to be restructured, thus facilitating creative thought. We outline a hypothetical computational model which will allow explicit testing of these hypotheses.}
}
@article{NEWMAN2024101778,
title = {Misinformed by images: How images influence perceptions of truth and what can be done about it},
journal = {Current Opinion in Psychology},
volume = {56},
pages = {101778},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2023.101778},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X23002233},
author = {Eryn J. Newman and Norbert Schwarz},
keywords = {Visual misinformation, Truthiness, Cognitive fluency, Artificial intelligence (AI), Memory, Truth assessment},
abstract = {We organize image types by their substantive relationship with textual claims and discuss their impact on attention, comprehension, memory, and judgment. Photos do not need to be false (altered or generated) to mislead; real photos can create a slanted representation or be repurposed from different events. Even semantically related non-probative photos, merely inserted to attract eyeballs, can increase message acceptance through increased fluency. Messages with images receive more attention and reach a wider audience. Text-congruent images can scaffold the comprehension of true and false claims and support the formation of correct and false memories. Standard laboratory procedures may underestimate the impact of images in natural media contexts: by drawing all participants' attention to a message that may be ignored without an image, they inflate message effects in the control condition. Misleading images are difficult to identify and their influence often remains outside of awareness, making it hard to curb their influence through critical-thinking interventions. Current concerns about deep fakes may reduce trust in all images, potentially limiting their power to mislead as well as inform. More research is needed to understand how knowing that an image is misleading influences inferences, impressions, and judgments beyond immediate assessments of the image's credibility.}
}
@article{LLOYD2019167,
title = {You make it and you try it out: Seeds of design discipline futures},
journal = {Design Studies},
volume = {65},
pages = {167-181},
year = {2019},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2019.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X19300675},
author = {Peter Lloyd},
keywords = {design methods, design studies, design research, design process, design thinking},
abstract = {This paper takes a narrative seam through the design discipline, attempting to explain how design methodology, one of the three types of Nigel Cross' designerly ways of knowing, has changed over the 40 years of Design Studies. Specifically, the paper identifies the point when a ‘social turn’ in the discipline occurred, allowing more nuanced and critical studies of designing, and shifting the balance from an objective (‘scientific’) perspective to one more based on relativist approaches. The paper concludes by noting the plurality of present-day study, arguably enabled by design thinking, and sketches what this holds for the future of the discipline. The references in the paper are mainly restricted to those published in, or strongly relating to, Design Studies.}
}
@article{MIRA2009793,
title = {Sensory representation spaces in neuroscience and computation},
journal = {Neurocomputing},
volume = {72},
number = {4},
pages = {793-805},
year = {2009},
note = {Brain Inspired Cognitive Systems (BICS 2006) / Interplay Between Natural and Artificial Computation (IWINAC 2007)},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2008.04.054},
url = {https://www.sciencedirect.com/science/article/pii/S0925231208004682},
author = {J. Mira and A.E. Delgado},
keywords = {Representation space, Perception, Cortical maps, Semantic gap},
abstract = {Physics, Neuroscience and Computation are concerned with finding the most appropriate representation spaces to describe the interaction of a dynamic system with its environment. In this work first we review the two basic conceptual approaches to the problem of representing an environment, Marr's ascending “constructivism” and Gibson's “direct perception” hypothesis. Later we review the basic neural mechanisms associated with creating meaning in both approaches: lateral inhibition and the creation of cortical maps by resonance to patterns of stimuli of families of spatially ordered neurons. We end by considering the usefulness in artificial intelligence of knowledge about the way in which biological systems construct their representation spaces. We stress the idea regarding events as representation entities and, consequently, using an event time, different from physical time. Semantics emerges from the mechanisms that detect these relevant events in each organisational level and their composition rules to specify the constitutive entities of the next level. This semantic is distributed in the cortical maps of the neuron groups that resound to the corresponding events.}
}
@article{MCDERMOTT20071183,
title = {Level-headed},
journal = {Artificial Intelligence},
volume = {171},
number = {18},
pages = {1183-1186},
year = {2007},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2007.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0004370207001488},
author = {Drew McDermott},
keywords = {Speculation, Methodology, Natural language},
abstract = {I don't believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more about thinking and computation, the mileposts will keep changing in ways that we can't predict, as will the esteem we assign to past accomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusing on such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understand hardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus, when we can talk to machines, will we understand each other?}
}
@article{GRANDE2022105470,
title = {Nursing competency inventory and professional competence of graduating students in six Asian countries: A cross-sectional study},
journal = {Nurse Education Today},
volume = {116},
pages = {105470},
year = {2022},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2022.105470},
url = {https://www.sciencedirect.com/science/article/pii/S0260691722002064},
author = {Rizal Angelo N. Grande and Daniel Joseph E. Berdida and Tantut Susanto and Anwar Khan and Wanpen Waelveerakup and Zahrah Saad},
keywords = {Asian countries, Competency, Graduating nursing students, Nursing competency inventory, Professional competence},
abstract = {Aims
To investigate graduating nursing students' nursing and professional competencies and the predictors of their competencies.
Background
Across Asian countries, there is a paucity of literature that explores graduating nursing students' competency and professional competence during the ongoing COVID-19 pandemic.
Design
Descriptive, cross-sectional, and predictive approaches.
Method
Convenience sampling was used among graduating nursing students from the six Asian countries (n = 375). The STROBE guidelines for cross-sectional studies were used. Two self-report instruments were utilized to collect data. We conducted multiple linear regression analyses to assess the predictors of nursing competency and professional competence domains.
Results
Country of residence and general point average (GPA) showed statistically significant multivariate effects. Value-based nursing care and critical thinking and reasoning domains recorded the highest in professional competence and competency inventory for nursing students, respectively. Country of residence, GPA, and preferred nursing major were significant predictors of graduating nursing students' nursing competency and professional competence domains.
Conclusion
Our study's findings revealed a high level of diversity among nursing students regarding ethical care obligations, caring pedagogies, and lifelong learning, all of which may be ascribed to their distinct culture, background, and belief systems.}
}
@article{MEHMOOD2023100122,
title = {A multi-stage optimisation-based decision-making framework for sustainable hybrid energy system in the residential sector},
journal = {Sustainable Futures},
volume = {6},
pages = {100122},
year = {2023},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2023.100122},
url = {https://www.sciencedirect.com/science/article/pii/S2666188823000187},
author = {Aamir Mehmood and Long Zhang and Jingzheng Ren},
keywords = {Hybrid energy system, System thinking approach, Genetic algorithm, Multi-criteria decision-making, Energy sustainability},
abstract = {Integrating renewables into existing energy infrastructure to construct hybrid energy systems (HES) plays a vital role for advancing energy sustainability. While various approaches, such as energy systems analysis and linear or non-linear optimisation, have been employed to achieve energy sustainability mainly at the national or city level, there has been a lack of focus on achieving energy sustainability in the residential sector through a holistic optimal decision-making approach for efficient HES design. This study focuses on developing a multi-stage optimisation-based decision-making framework that models, quantifies, and optimises the performance indicators of HES, allowing for an assessment of the trade-off between benefits and systems costs under various design scenarios. The initial step involves designing the HES model and constructing scenarios that cater to the electrification requirements of water, energy, and food elements in the residential sector by using a systematic thinking approach. Then, a preliminary evaluation of the modelled scenarios is conducted to assess energy sustainability in terms of technical and economic aspects. Afterwards, an optimal decision-making setup is established by integrating a multi-objective HES model into the NSGA-II algorithm, which approximates the Pareto optimal solutions. These solutions are then ranked by using a multi-criteria decision-making method. According to the findings, the Quetta region in Pakistan contains the best optimal solution. The results underscore the utility of the developed framework in facilitating the optimal design of renewables-integrated HES for the residential sector. Furthermore, intergovernmental organizations can leverage this framework to formulate effective policies aimed at encouraging residents to invest in HES installation.}
}
@article{BRENNAN2023100070,
title = {Generalised Kuramoto models with time-delayed phase-resetting for k-dimensional clocks},
journal = {Brain Multiphysics},
volume = {4},
pages = {100070},
year = {2023},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2023.100070},
url = {https://www.sciencedirect.com/science/article/pii/S2666522023000084},
author = {Martin Brennan and Peter Grindrod CBE},
keywords = {Kuramoto models, Range-dependent networks, High dimensional clocks, Phase-resetting maps, The human cortex, Consciousness},
abstract = {We consider a class of Kuramoto models, with an array of N individual k-dimensional clocks (k>1), coupled within a directed, range dependent, network. For each directed connection, a signal triggered at the sending clock incurs a (real valued) time delay before arriving at the receiving clock, where it induces an instantaneous phase reset affecting all k-phases. Instantaneous phase resetting maps (PRMs) for k-dimensional clocks have received little attention. The system may be treated as open and subject to periodic, or other types of, PRM forcing at any individual clock, as a result of external forcing stimuli. We show how the full system, with Nk phase variables, responds to such stimuli, as the impact spreads across the entire network. Beyond simulations, we employ methods to reverse engineer the dynamical behaviour of the whole: estimating the intrinsic dimensions of the responses to different experiments; and by analysing pairwise comparisons between those responses. This shows that the system’s responses are governed by a hierarchy of internal dynamical modes, existing across both the Nk phases and over time. We argue that this Kuramoto system is a model for the human cortex, where each k-dimensional clock models the dynamics of a single neural column, which contains 10,000 densely inter-connected neurons. The Kuramoto model exploits the natural network of networks architecture of the human cortex. An array of N=1M such columns/clocks is at the 10B neuron scale of the human cortex. However its simulation is far more accessible than very large scale (VLS) simulations of neuron-to-neuron systems on supercomputers. The latent modes may have important implications for cognition (information processing) and for consciousness (the existence of internal phenomenological experiences). We argue that the existence of the latter plays a key role in preconditioning the former, reducing the decision sets and the cognitive load, and thus enabling a fast-thinking evolutionary advantage. This is the first time that systems of k-dimensional clocks (k> 1), coupled via time-lagged PRMs, within range dependent networks, have been deployed to demonstrate the basic internal phenomenological elements (of consciousness) and their potential role within immediate cognition. Statement of Significance: We argue that this Kuramoto system is a model for the human cortex, where each of 1M k-dimensional clocks models the dynamics of a single neural column (containing 10,000 densely inter-connected neurons). This Kuramoto model exploits the natural network of networks architecture of the human cortex. Large scale human cortex simulations, with 10B neutrons, usually require a super computer. We show that similar results, using this model, can be obtained on a laptop. In particular we show that such dynamical can support internal phenomenological elements (of conscious experience) and we discuss their potential role in preconditioning immediate cognition, furnishing a “fast thinking” evolutionary advantage to the human brain.}
}
@article{DUAN2024100234,
title = {Making waves: Knowledge and data fusion in urban water modelling},
journal = {Water Research X},
volume = {24},
pages = {100234},
year = {2024},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2024.100234},
url = {https://www.sciencedirect.com/science/article/pii/S2589914724000240},
author = {Haoran Duan and Jiuling Li and Zhiguo Yuan},
keywords = {Modelling, Data-driven, Machine learning, Hybrid model, Urban water systems},
abstract = {Mathematical modeling plays a crucial role in understanding and managing urban water systems (UWS), with mechanistic models often serving as the foundation for their design and operations. Despite the wide adoptions, mechanistic models are challenged by the complexity of dynamic processes and high computational demands. Data-driven models bring opportunities to capture system complexities and reduce computational cost, by leveraging the abundant data made available by recent advance in sensor technologies. However, the interpretability and data availability hinder their wider adoption. This paper advocates for a paradigm shift in the application of data-driven models within the context of UWS. Integrating existing mechanistic knowledge into data-driven modeling offers a unique solution that reduces data requirements and enhances model interpretability. The knowledge-informed approach balances model complexity with dataset size, enabling more efficient and interpretable modeling in UWS. Furthermore, the integration of mechanistic and data-driven models offers a more accurate representation of UWS dynamics, addressing lingering uncertainties and advancing modelling capabilities. This paper presents perspectives and conceptual framework on developing and implementing knowledge-informed data-driven modeling, highlighting their potential to improve UWS management in the digital era.}
}
@article{SALMON2022105511,
title = {Bicycle crash contributory factors: A systematic review},
journal = {Safety Science},
volume = {145},
pages = {105511},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105511},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521003544},
author = {Paul M. Salmon and Mitch Naughton and Adam Hulme and Scott McLean},
keywords = {Cyclists, Cyclist crashes, Systems thinking, Road safety, Crash causation},
abstract = {There is a growing body of road safety research that seeks to identify crash contributory factors beyond road users, their vehicles, and the immediate road environment. Although cyclist safety represents a critical research area, this ‘systems thinking’ approach has received less attention in bicycle crash analysis. This article presents the findings from a systematic literature review which aimed to synthesise the peer reviewed literature regarding bicycle crash contributory factors (defined as factors which play a contributory role in bicycle crashes, as opposed to risk factors which are factors which may increase the probability of crashes). Crash contributory factors were extracted from included articles and mapped onto a systems thinking framework comprising seven hierarchical road transport system levels. The findings show that a majority of the included studies identified contributory factors relating to the road environment, cycling infrastructure, and cyclist and driver behaviour. No studies identified contributory factors outside of cyclists and road users, bicycles and vehicles, and the road environment and few specifically examined causal relationships between contributory factors. It is concluded that there are gaps in the knowledge base regarding the broader transport system features that play a role in bicycle crashes and how contributory factors interact to create crashes. We argue that more expansive research into the systemic factors involved in bicycle crashes is required and that initial work should focus on the development of new data sources and analysis methods.}
}
@article{TEEPLE2023102847,
title = {Level-k predatory trading},
journal = {Journal of Mathematical Economics},
volume = {106},
pages = {102847},
year = {2023},
issn = {0304-4068},
doi = {https://doi.org/10.1016/j.jmateco.2023.102847},
url = {https://www.sciencedirect.com/science/article/pii/S030440682300040X},
author = {Keisuke Teeple},
keywords = {Behavioral finance, Level- models, Front running, Price overshooting},
abstract = {I incorporate the level-k thinking solution concept into a simplified (Brummermeier and Pedersen, 2005) predatory trading model to investigate the possibility of arbitraging arbitrageurs. While naive financial predators prey upon a single distressed investor, higher-level thinkers best respond to this and prey upon fellow predators. For some parameter values, sophisticated predators are able to reason their way to the Nash equilibrium strategy, and prices do not oscillate. As parameter values are perturbed, the system undergoes a bifurcation and predators select strategies from a mean-preserving spread of the Nash equilibrium strategy. In these settings, prices display excess volatility and a single shock can send predators into an oscillatory trading frenzy.}
}
@article{YIN2015655,
title = {Automating design with intelligent human–machine integration},
journal = {CIRP Annals},
volume = {64},
number = {2},
pages = {655-677},
year = {2015},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2015.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S000785061500147X},
author = {Yue H. Yin and Andrew Y.C. Nee and S.K. Ong and Jian Y. Zhu and Pei H. Gu and Lien J. Chen},
keywords = {Design automation, Human–machine integration, Intelligent design, Imaginal thinking, Ontology},
abstract = {This paper reviews the state-of-the-art methodologies for automating design with intelligent human–machine integration from the perspectives of ontology and epistemology. The human–machine integrated automating design paradigm is reviewed systematically based on a proposed prototype of human–machine integrated design, from the aspects of ontology-based knowledge management with local-to-global ontology transitions, and epistemology-based upward-spiral cognitive process of coupled design ideation. Particularly, imaginal thinking frame is proposed as the foundation of intelligent human–machine interaction that puts human and machine on an equal platform. Further, this paper presents implementations and applications of the automating design paradigm and concludes with the identification of future trend.}
}
@article{GEORGIEV20181,
title = {Enhancing user creativity: Semantic measures for idea generation},
journal = {Knowledge-Based Systems},
volume = {151},
pages = {1-15},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118301394},
author = {Georgi V. Georgiev and Danko D. Georgiev},
keywords = {Creativity, Divergence, Semantic networks, Similarity, WordNet},
abstract = {Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC Sánchez–Batet) and semantic similarity (Lin/Sánchez–Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.}
}
@article{JURISICA2024102006,
title = {Explainable biology for improved therapies in precision medicine: AI is not enough},
journal = {Best Practice & Research Clinical Rheumatology},
pages = {102006},
year = {2024},
issn = {1521-6942},
doi = {https://doi.org/10.1016/j.berh.2024.102006},
url = {https://www.sciencedirect.com/science/article/pii/S1521694224000779},
author = {I Jurisica},
keywords = {Precision medicine, Rheumatoid arthritis, Artificial intelligence, Integrative computational biology},
abstract = {Technological advances and high-throughput bio-chemical assays are rapidly changing ways how we formulate and test biological hypotheses, and how we treat patients. Most complex diseases arise on a background of genetics, lifestyle and environment factors, and manifest themselves as a spectrum of symptoms. To fathom intricate biological processes and their changes from healthy to disease states, we need to systematically integrate and analyze multi-omics datasets, ontologies, and diverse annotations. Without proper management of such complex biological and clinical data, artificial intelligence (AI) algorithms alone cannot be effectively trained, validated, and successfully applied to provide trustworthy and patient-centric diagnosis, prognosis and treatment. Precision medicine requires to use multi-omics approaches effectively, and offers many opportunities for using AI, “big data” analytics, and integrative computational biology workflows. Advances in optical and biochemical assay technologies including sequencing, mass spectrometry and imaging modalities have transformed research by empowering us to simultaneously view all genes expressed, identify proteome-wide changes, and assess interacting partners of each individual protein within a dynamically changing biological system, at an individual cell level. While such views are already having an impact on our understanding of healthy and disease conditions, it remains challenging to extract useful information comprehensively and systematically from individual studies, ensure that signal is separated from noise, develop models, and provide hypotheses for further research. Data remain incomplete and are often poorly connected using fragmented biological networks. In addition, statistical and machine learning models are developed at a cohort level and often not validated at the individual patient level. Combining integrative computational biology and AI has the potential to improve understanding and treatment of diseases by identifying biomarkers and building explainable models characterizing individual patients. From systematic data analysis to more specific diagnostic, prognostic and predictive biomarkers, drug mechanism of action, and patient selection, such analyses influence multiple steps from prevention to disease characterization, and from prognosis to drug discovery. Data mining, machine learning, graph theory and advanced visualization may help identify diagnostic, prognostic and predictive biomarkers, and create causal models of disease. Intertwining computational prediction and modeling with biological experiments leads to faster, more biologically and clinically relevant discoveries. However, computational analysis results and models are going to be only as accurate and useful as correct and comprehensive are the networks, ontologies and datasets used to build them. High quality, curated data portals provide the necessary foundation for translational research. They help to identify better biomarkers, new drugs, precision treatments, and should lead to improved patient outcomes and their quality of life. Intertwining computational prediction and modeling with biological experiments, efficiently and effectively leads to more useful findings faster.}
}
@article{BAKER2022942,
title = {Three aspects of representation in neuroscience},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {11},
pages = {942-958},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002108},
author = {Ben Baker and Benjamin Lansdell and Konrad P. Kording},
keywords = {representation, information, coding, explanation, function, teleology, philosophy},
abstract = {Neuroscientists often describe neural activity as a representation of something, or claim to have found evidence for a neural representation, but there is considerable ambiguity about what such claims entail. Here we develop a thorough account of what ‘representation’ does and should do for neuroscientists in terms of three key aspects of representation. (i) Correlation: a neural representation correlates to its represented content; (ii) causal role: the representation has a characteristic effect on behavior; and (iii) teleology: a goal or purpose served by the behavior and thus the representation. We draw broadly on literature in both neuroscience and philosophy to show how these three aspects are rooted in common approaches to understanding the brain and mind. We first describe different contexts that ‘representation’ has been closely linked to in neuroscience, then discuss each of the three aspects in detail.}
}
@article{TEZDUYAR199997,
title = {CFD methods for three-dimensional computation of complex flow problems},
journal = {Journal of Wind Engineering and Industrial Aerodynamics},
volume = {81},
number = {1},
pages = {97-116},
year = {1999},
issn = {0167-6105},
doi = {https://doi.org/10.1016/S0167-6105(99)00011-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167610599000112},
author = {Tayfun E. Tezduyar},
keywords = {CFD methods, T*AFSM, Three-dimensional flow simulations},
abstract = {This paper provides an overview of some of the CFD methods developed by the Team for Advanced Flow Simulation and Modeling (T*AFSM) [http://www.mems.rice.edu/TAFSM/]. The paper also provides many examples of three-dimensional flow simulations carried out with these CFD methods and advanced parallel supercomputers. The methods and tools described in this paper include: stabilized finite element formulations; formulations for flows with moving boundaries and interfaces; mesh update methods; iterative solution techniques for large nonlinear equation systems; and parallel implementation of these methods. Our target is to be able to address effectively certain classes of flow simulation problems. These include: unsteady flows with interfaces; fluid–object interactions; fluid–structure interactions; airdrop systems; aerodynamics of complex shapes; and contaminant dispersion.}
}
@article{SUPPES201295,
title = {Phase-oscillator computations as neural models of stimulus–response conditioning and response selection},
journal = {Journal of Mathematical Psychology},
volume = {56},
number = {2},
pages = {95-117},
year = {2012},
issn = {0022-2496},
doi = {https://doi.org/10.1016/j.jmp.2012.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S002224961200003X},
author = {P. Suppes and J. Acacio {de Barros} and G. Oas},
keywords = {Learning, Neural oscillators, Three-oscillator Kuramoto model, Stability points of the Kuramoto model, Stimulus–response theory, Phase representation, Continuum of responses},
abstract = {The activity of collections of synchronizing neurons can be represented by weakly coupled nonlinear phase oscillators satisfying Kuramoto’s equations. In this article, we build such neural-oscillator models, partly based on neurophysiological evidence, to represent approximately the learning behavior predicted and confirmed in three experiments by well-known stochastic learning models of behavioral stimulus–response theory. We use three Kuramoto oscillators to model a continuum of responses, and we provide detailed numerical simulations and analysis of the three-oscillator Kuramoto problem, including an analysis of the stability points for different coupling conditions. We show that the oscillator simulation data are well-matched to the behavioral data of the three experiments.}
}
@incollection{KATZ2016123,
title = {Chapter 6 - Development of Counting Ability: An Evolutionary Computation Point of View},
editor = {Avishai Henik},
booktitle = {Continuous Issues in Numerical Cognition},
publisher = {Academic Press},
address = {San Diego},
pages = {123-145},
year = {2016},
isbn = {978-0-12-801637-4},
doi = {https://doi.org/10.1016/B978-0-12-801637-4.00006-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128016374000068},
author = {Gali Barabash Katz and Amit Benbassat and Moshe Sipper},
keywords = {numerical cognition, size perception, counting, evolutionary algorithms, genetic algorithms, artificial neural networks},
abstract = {Examination of numerical cognition encompasses multiple facets (eg, discrete vs. continuous properties, subitizing, estimation, counting, etc.). Many models have been suggested to explain these features. By looking into the basic ability to perceive size, against the complex one of counting, we hypothesize that counting system evolved on the basis of a primitive size perception system rather than the two systems evolved separately. In this chapter, we present a novel way of using evolutionary computation techniques to evolve artificial neural networks (ANNs) first to perceive size and then to count, and compare their counting skills to a different group of ANNs who evolved to count from scratch. The results revealed better counting skills when evolving first to perceive size (or other classification task) and then to count over those who evolved just to count. In addition, ANNs who evolved with continuous stimuli presented better counting skills than those evolved with discrete stimuli.}
}
@article{RONG20121462,
title = {Computational performance of basic state reduction based dynamic programming algorithms for bi-objective 0–1 knapsack problems},
journal = {Computers & Mathematics with Applications},
volume = {63},
number = {10},
pages = {1462-1480},
year = {2012},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2012.03.057},
url = {https://www.sciencedirect.com/science/article/pii/S0898122112002623},
author = {Aiying Rong and José Rui Figueira},
keywords = {Multi-objective optimization, Bi-objective knapsack problem, Dynamic programming, Basic state reduction techniques},
abstract = {This paper studies a group of basic state reduction based dynamic programming (DP) algorithms for the multi-objective 0–1 knapsack problem (MKP), which are related to the backward reduced-state DP space (BRDS) and forward reduced-state DP space (FRDS). The BRDS is widely ignored in the literature because it imposes disadvantage for the single objective knapsack problem (KP) in terms of memory requirements. The FRDS based DP algorithm in a general sense is related to state dominance checking, which can be time consuming for the MKP while it can be done efficiently for the KP. Consequently, no algorithm purely based on the FRDS with state dominance checking has ever been developed for the MKP. In this paper, we attempt to get some insights into the state reduction techniques efficient to the MKP. We first propose an FRDS based algorithm with a local state dominance checking for the MKP. Then we evaluate the relative advantage of the BRDS and FRDS based algorithms by analyzing their computational time and memory requirements for the MKP. Finally different combinations of the BRDS and FRDS based algorithms are developed on this basis. Numerical experiments based on the bi-objective KP instances are conducted to compare systematically between these algorithms and the recently developed BRDS based DP algorithm as well as the existing FRDS based DP algorithm without state dominance checking.}
}
@article{WOOD199740,
title = {Thinking about Networks in the Control of Male Hamster Sexual Behavior},
journal = {Hormones and Behavior},
volume = {32},
number = {1},
pages = {40-45},
year = {1997},
issn = {0018-506X},
doi = {https://doi.org/10.1006/hbeh.1997.1403},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X97914033},
author = {Ruth I. Wood},
abstract = {Motivated social behaviors such as mating are controlled by a complex network of limbic nuclei. Concepts of network organization derived from computational neuroscience may aid our understanding of the links between the neuroanatomical circuitry and what is represented by the anatomy. Research in my laboratory uses mating behavior in the male Syrian hamster as a model to elucidate how chemosensory and steroid cues are integrated in the brain. An interaction of odors and hormones is required for mating in this species. These two essential stimuli are transmitted through separate parallel pathways in the limbic system. The functional organization of the hamster mating behavior circuit is characterized by distributed representation, divergent and convergent neural pathways, and recurrent feedback. Odors and hormones have different modes of action on this neural network. While chemosensory cues stimulate the input units of the network, steroids facilitate behavior through the hidden units. In this manner, steroids appear to create a permissive environment for subsequent activation by odor cues.}
}
@article{BUCKER20031309,
title = {Parallel programming in computational science: an introductory practical training course for computer science undergraduates at Aachen University},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1309-1319},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00089-X},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X0300089X},
author = {H.M. Bücker and B. Lang and C.H. Bischof},
keywords = {Parallel programming, Java, Computational science and engineering, Education},
abstract = {Parallel programming of high-performance computers has emerged as a key technology for the numerical solution of large-scale problems arising in computational science and engineering (CSE). The authors believe that principles and techniques of parallel programming are among the essential ingredients of any CSE as well as computer science curriculum. Today, opinions on the role and importance of parallel programming are diverse. Rather than seeing it as a marginal beneficial skill optionally taught at the graduate level, we understand parallel programming as crucial basic skill that should be taught as an integral part of the undergraduate computer science curriculum. A practical training course developed for computer science undergraduates at Aachen University is described. Its goal is to introduce young computer science students to different parallel programming paradigms for shared and distributed memory computers as well as to give a first exposition to the field of computational science by simple, yet carefully chosen sample problems.}
}
@article{EGUCHI2016692,
title = {RoboCupJunior for promoting STEM education, 21st century skills, and technological advancement through robotics competition},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {692-699},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001281},
author = {Amy Eguchi},
keywords = {Educational robotics, Robotics competitions, STEM education, Computational thinking, Engineering skills, 21st century skills},
abstract = {RoboCupJunior is an international educational robotics initiative, aiming to promote STEM content and skill learning among participating youth through educational robotics competition inaugurated in 2000. What makes RoboCupJunior quite unique is its relationship with RoboCup which aims to promote robotics and AI research, by offering a publicly appealing, but formidable challenge including development of soccer robots, search and rescue robots, and robots functions at home and at work. This paper introduces a case of RoboCupJunior and the effectiveness of its practice for enhancing learning of STEM contents and skills for innovation and creativity among participating students. It presents the survey results from one of the World Championships held in 2012, the anecdotal and personal account of participating US students on their learning experience from their participation in 2013 World Championship, and participating students’ technological and innovative contributions to highlight the impacts RoboCupJunior has had through over a decade of its practice.}
}
@incollection{VALLERO2024613,
title = {Chapter 20 - Future},
editor = {Daniel A. Vallero and Trevor M. Letcher},
booktitle = {Unraveling Environmental Disasters (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {613-634},
year = {2024},
isbn = {978-0-443-18651-6},
doi = {https://doi.org/10.1016/B978-0-443-18651-6.00004-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443186516000044},
author = {Daniel A. Vallero and Trevor M. Letcher},
keywords = {Deconstructing disasters, Failure, Integrated pest management (IPM), Land use, Maslow's hierarchy of needs, Information technology, Interoperability, Systems thinking, Spills, Life-cycle analysis, Design for the environment (DfE), Design for disassembly (DfD), Aesop's fables, Tragedy of the Commons, Triple bottom line, Categorical imperative},
abstract = {This chapter revisits the concept of disasters as failures introduced in Chapter 2. This entails approaches to consider the many factors and causes. System thinking is introduced as a means of preventing or reducing the damage of disasters. Systematic approaches must make use of various tools, including regulatory measures; economic incentives; property rights; infrastructure installment; public education; for international projects, international inspections; and cooperation. Disaster prevention and mitigation must integrate planning and engineering approaches, especially thoughtful land use. This also requires an understanding of how people expect to meet basic and advanced needs, as exemplified by Maslow's hierarchy. Other tools include optimizing information technologies and interoperability. The good news is that with education and consideration of past disasters, the implementation of rules and regulations there can be a reduction of number and severity of disasters; e.g., decrease in oil tanker spills over the past half century.}
}
@incollection{MEDEIROS2023275,
title = {Chapter 19 - Promises and realities of artificial creativity},
editor = {Roni Reiter-Palmon and Sam Hunter},
booktitle = {Handbook of Organizational Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {275-289},
year = {2023},
isbn = {978-0-323-91841-1},
doi = {https://doi.org/10.1016/B978-0-323-91841-1.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323918411000105},
author = {Kelsey E. Medeiros and Rebecca L. Marrone and Srecko Joksimovic and David H. Cropley and George Siemens},
keywords = {Creativity, Artificial intelligence, Cognition},
abstract = {Proponents of artificial intelligence boast its many promises, including the potential for creativity. Whether the realities of artificial cognition align with these promises, however, remains hotly debated. In this chapter, we explore the role of artificial intelligence in creative problem-solving through the lens of cognition. Through this lens, we advance the argument that, at present, creative problem-solving remains a distinctly human capability. Specifically, we examine how artificial cognition can and cannot engage in each stage of creative problem-solving, as well as the underlying mechanisms of divergent and convergent thinking. Although we find little evidence to support the creativity of artificial cognition, we advance several ways in which artificial cognition can augment human cognition to enhance creative problem-solving.}
}
@article{LAING2011306,
title = {Computational approaches to RNA structure prediction, analysis, and design},
journal = {Current Opinion in Structural Biology},
volume = {21},
number = {3},
pages = {306-318},
year = {2011},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2011.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X11000674},
author = {Christian Laing and Tamar Schlick},
abstract = {RNA molecules are important cellular components involved in many fundamental biological processes. Understanding the mechanisms behind their functions requires RNA tertiary structure knowledge. Although modeling approaches for the study of RNA structures and dynamics lag behind efforts in protein folding, much progress has been achieved in the past two years. Here, we review recent advances in RNA folding algorithms, RNA tertiary motif discovery, applications of graph theory approaches to RNA structure and function, and in silico generation of RNA sequence pools for aptamer design. Advances within each area can be combined to impact many problems in RNA structure and function.}
}
@article{SHARIF2022104090,
title = {Robotic sheet metal folding: Tool vs. material programming},
journal = {Automation in Construction},
volume = {134},
pages = {104090},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104090},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005410},
author = {Shani Sharif and Russell Gentry},
keywords = {Robotic fabrication, Mass-customization, Dieless sheet metal folding},
abstract = {This research explores how deductive engineering thinking, as opposed to an abductive design rationale, can influence how robotic methods of fabricating building components are developed. The goal of this research is to demonstrate how creative thinking can introduce alternative robotic fabrication techniques targeted for the architectural mass-customization process. For this purpose, we chose robotic dieless sheet metal folding as the main fabrication technique, due to its wide range of applications in both the architectural construction and manufacturing industries. Two robotic sheet metal folding projects were developed. The first, an example of tool programming, took advantage of an engineering approach and was focused on the affordances of the tool (an industrial robotic arm). The second project, one of material programming, employed a design methodology and was directed towards the affordances of the material (i.e., stainless steel sheet metal). By discussing the advantages and disadvantages of each approach, this research argues that both engineering and design should be considered required and complementary processes in the development of new creative fabrication solutions, allowing them to and make the overall production process more efficient.}
}
@incollection{GLENBERG199977,
title = {4 Why mental models must be embodied},
editor = {Gert Rickheit and Christopher Habel},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {128},
pages = {77-90},
year = {1999},
booktitle = {Mental Models in Discourse Processing and Reasoning},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(99)80048-X},
url = {https://www.sciencedirect.com/science/article/pii/S016641159980048X},
author = {Arthur Glenberg},
abstract = {Publisher Summary
Mental models are related to the concept of meaning and language comprehension; in other words, comprehending a linguistic message means that an appropriate mental model has been formed. The manipulation of mental models corresponds to thinking, and it is the manipulation that generates emergent ideas. The chapter discusses the importance of considering the ways ideas combine and presents the data from two experiments that illustrate the combination of ideas. The chapter illustrates the major implications for the theories of mental models. The first implication is that the computational theories cannot account for the data. The second implication is that something like embodiment is needed, and the chapter outlines one account of embodied mental models. The third implication is the most important and most controversial. It is that the human cognition is not a computational phenomenon.}
}
@article{STEPHENS200833,
title = {What “counts” as algebra in the eyes of preservice elementary teachers?},
journal = {The Journal of Mathematical Behavior},
volume = {27},
number = {1},
pages = {33-47},
year = {2008},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000594},
author = {Ana C. Stephens},
keywords = {Algebra, Elementary mathematics, Teacher conceptions},
abstract = {This study examined conceptions of algebra held by 30 preservice elementary teachers. In addition to exploring participants’ general “definitions” of algebra, this study examined, in particular, their analyses of tasks designed to engage students in relational thinking or a deep understanding of the equal sign as well as student work on these tasks. Findings from this study suggest that preservice elementary teachers’ conceptions of algebra as subject matter are rather narrow. Most preservice teachers equated algebra with the manipulation of symbols. Very few identified other forms of reasoning – in particular, relational thinking – with the algebra label. Several participants made comments implying that student strategies that demonstrate traditional symbol manipulation might be valued more than those that demonstrate relational thinking, suggesting that what is viewed as algebra is what will be valued in the classroom. This possibility, along with implications for mathematics teacher education, will be discussed.}
}
@incollection{VARGAS201945,
title = {Cell Adhesion: Basic Principles and Computational Modeling},
editor = {Roger Narayan},
booktitle = {Encyclopedia of Biomedical Engineering},
publisher = {Elsevier},
address = {Oxford},
pages = {45-58},
year = {2019},
isbn = {978-0-12-805144-3},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99930-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383999306},
author = {Diego A. Vargas and Hans {Van Oosterwyck}},
keywords = {Adherens junction, Adhesion dynamics, Bond lifetime, Cell adhesion, Cellularized material, Focal adhesion, Force spectroscopy, Mathematical modeling, Mechanotransduction, Multiscale modeling, Rate constant, Vertex model},
abstract = {A cell interacts with its environment through adhesion complexes. These are protein complexes that form through noncovalent interactions between adhesion receptors in the cell membrane and similar receptors in neighboring cells or ligand molecules in the surrounding extracellular matrix. Cell adhesions are crucial to maintain tissue integrity and cellular communication. Communication and sensing occur through the transmittal of forces through adhesions. This relevant role motivated researchers to develop theoretical models of adhesion. Initial models were based on studies of association kinetics of proteins, which later were expanded to explicitly include the role of force in determining bond strength. The introduction of techniques that allowed measurements of force in the range of a single adhesion produced models that describe the inner workings of the adhesion molecules themselves. Despite the relative simplicity of these models, they are still relevant. Not only were these studies novel and creative, they have been integrated into models describing larger cellular aggregates, unraveling the role of mechanics in biology. These models have been used in the study of cell migration, developmental biology, and cancer biology.}
}
@article{DUCH1996136,
title = {Computational physics of the mind},
journal = {Computer Physics Communications},
volume = {97},
number = {1},
pages = {136-153},
year = {1996},
note = {High-Performance Computing in Science},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(96)00027-6},
url = {https://www.sciencedirect.com/science/article/pii/0010465596000276},
author = {Włodzisław Duch},
abstract = {In the XIX century and earlier physicists such as Newton, Mayer, Hooke, Helmholtz and Mach were actively engaged in the research on psychophysics, trying to relate psychological sensations to intensities of physical stimuli. Computational physics allows to simulate complex neural processes giving a chance to answer not only the original psychophysical questions but also to create models of the mind. In this paper several approaches relevant to modeling of the mind are outlined. Since direct modeling of the brain functions is rather limited due to the complexity of such models a number of approximations is introduced. The path from the brain, or computational neurosciences, to the mind, or cognitive sciences, is sketched, with emphasis on higher cognitive functions such as memory and consciousness. No fundamental problems in understanding of the mind seem to arise. From a computational point of view realistic models require massively parallel architectures.}
}
@article{FORTHMANN201959,
title = {Creative ideation, broad retrieval ability, and processing speed: A confirmatory study of nested cognitive abilities},
journal = {Intelligence},
volume = {75},
pages = {59-72},
year = {2019},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0160289618301211},
author = {Boris Forthmann and David Jendryczko and Jana Scharfen and Ruben Kleinkorres and Mathias Benedek and Heinz Holling},
keywords = {Divergent thinking, Broad retrieval ability, Processing speed, Structural equation modeling},
abstract = {Divergent thinking (DT) ability (i.e., the ability to come up with creative ideas) is a complex cognitive construct that has been associated with several specific components of the Cattel-Horn-Carroll (CHC) model. In this study, we employed a nested latent variable approach to examine the specific role of mental speed (Gs) and general retrieval ability (Gr) in DT ability, which was assessed by DT tasks that instructed to be creative and were scored for creative quality. Specifically, Gs was assumed to facilitate both Gr and DT, and Gr was assumed to contribute to DT. Successive latent variable models with orthogonal factors were tested to reflect these nested cognitive basic abilities. The proposed model of nested factors fit the data well: Latent Gs accounted for variation in Gs, Gr, and DT creative quality scores, latent Gr predicted performance in Gr and DT scores beyond Gs, and latent DT explained variation in DT scores beyond Gs and Gr. In addition, we related the resulting orthogonal latent variables to the external criteria of school grades to illustrate the explanatory power of the modeling approach. This study provides evidence that divergent thinking performance relies on mental speed and retrieval ability, as well as cognitive abilities unique to divergent thinking. We discuss consequences for the understanding of divergent thinking ability in the context of the CHC model.}
}
@article{ZORARPACI2024108162,
title = {A fast intrusion detection system based on swift wrapper feature selection and speedy ensemble classifier},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108162},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108162},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003208},
author = {Ezgi Zorarpaci},
keywords = {Data mining, Ensemble classifier, Feature selection, Intrusion detection system},
abstract = {Due to the widespread use of the internet, computer network systems may be exposed to different types of attacks. For this reason, the intrusion detection systems (IDSs) are often used to protect the network systems. Network traffic data (i.e., network packets) includes many features. However, most of them are irrelevant and can lead to a decrease in the runtime and/or the detection performance of the IDS. Although various data mining methods have been applied to improve the effectiveness of IDS, research regarding IDSs having high detection rates and better runtime performance (i.e., lower computational cost) is ongoing. On the other hand, the dimensionality reduction techniques help to eliminate unnecessary features and reduce the computation time of a classification algorithm. In the literature, the feature selection methods (i.e., filter and wrapper) have been widely used for the dimensionality reduction in IDSs. Although the wrapper feature selection techniques outperform the filters, they are time-consuming. Again, the ensemble classifiers can achieve higher detection rates for IDSs compared to the stand-alone classifiers, but they require more computation time to build the model. In order to improve the runtime performance and the detection rate of IDS, a swift wrapper feature selection and a speedy ensemble classifier are proposed in this study. For the dimensionality reduction, the swift wrapper feature selection (i.e., DBDE-QDA) is used, which consists of dichotomous binary differential evolution (DBDE) and quadratic discriminant analysis (QDA). For attack detection, the speedy ensemble classifier is used, which combines Holte's 1R, random tree, and reduced error pruning tree. In the experiments, the NSL-KDD, UNSW-NB15, and CICDDoS2019 datasets are used. According to the experimental results, the proposed IDS reaches 95%–97.4%, 82.7%, and 99.5%–99.9% detection rates for the NSL-KDD, UNSW-NB15, and CICDDoS2019 datasets. In this way, the proposed IDS competes with the state-of-the-art methods in terms of detection rate and false alarm rate. In addition, the proposed IDS has a lower computational cost than the state-of-the-art methods. Moreover, DBDE-QDA reduces the dimension by 60.97%–82.92%, 73.46%, and 96.55%–98.85% for the NSL-KDD, UNSW-NB15, and CICDoS2019 datasets.}
}
@article{INAL2024101338,
title = {Current clinical status of IC/BPS and what the future holds in basic & translational science},
journal = {Continence},
volume = {11},
pages = {101338},
year = {2024},
issn = {2772-9737},
doi = {https://doi.org/10.1016/j.cont.2024.101338},
url = {https://www.sciencedirect.com/science/article/pii/S2772973724002716},
author = {Guldal Inal and Dick Janssen and Naside Mangir and Francisco Cruz and Ana Charrua},
keywords = {IC/BPS, Biomarkers, Bioinformatics, Artificial intelligence, Animal models},
abstract = {The present review summarizes the scientific content in the workshop “Current clinical status of IC/BPS and what the future holds in basic & translational science” at the International Continence Society (ICS) 2023, Toronto. In the workshop, clinicians and scientists from different disciplines and nationalities discussed the current clinical status of IC/BPS diagnostic and treatment. They defined the available trends in biomarker search and translational medicine. The recent contribution of computational science and bioinformatics, together with artificial intelligence and the recent improvements in the use of animal models were also explored. The search for diagnostic and predictive biomarkers for IC/BPS patients is important. The use of well-refined and characterized animal models and the use of bioinformatics and artificial intelligence will be useful in this search.}
}
@article{OSINGA2022103298,
title = {Big data in agriculture: Between opportunity and solution},
journal = {Agricultural Systems},
volume = {195},
pages = {103298},
year = {2022},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2021.103298},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X21002511},
author = {Sjoukje A. Osinga and Dilli Paudel and Spiros A. Mouzakitis and Ioannis N. Athanasiadis},
keywords = {Big data solutions, Precision Agriculture, Case study, Stakeholders, Technological maturity level, Mixed-method approach},
abstract = {CONTEXT
Big data applications in agriculture evolve fast, as more experience, applications, good practices and computational power become available. Actual solutions to real-life problems are scarce. What characterizes the adoption of big data problems to solutions and to what extent is there a match between them?
OBJECTIVE
We aim to assess the conditions of the adoption of big data technologies in agricultural applications, based on the investigation of twelve real-life practical use cases in the precision agriculture and livestock domain.
METHODS
We use a mixed method approach: a case study research around the twelve use cases of Horizon 2020 project CYBELE, varying from precision arable and livestock farming to fishing and food security, and a stakeholder survey (n = 56). Our analysis focuses on four perspectives: (1) the drivers of change that initiated the use cases; (2) the big data characteristics of the problem; (3) the technological maturity level of the solution both at start and end of the project; (4) the stakeholder perspective.
RESULTS AND CONCLUSIONS
Results show that the use cases’ drivers of change are a combination of data-, technology, research- and commercial interests; most have at least a research drive. The big data characteristics (volume, velocity, variety, veracity) are well-represented, with most emphasis on velocity and variety. Technology readiness levels show that the majority of use cases started at experimental or lab environment stage and aims at a technical maturity of real-world small-scale deployment. Stakeholders’ main concern is cost, user friendliness and to embed the solution within their current work practice. The adoption of better-matching big data solutions is modest. Big data solutions do not work out-of-the-box when changing application domains. Additional technology development is needed for addressing the idiosyncrasies of agricultural applications.
SIGNIFICANCE
We add a practical, empirical assessment of the current status of big data problems and solutions to the existing body of mainly theoretical knowledge. We considered the CYBELE research project as our laboratory for this. Our strength is that we interviewed the use case representatives in person, and that we included the stakeholders’ perspective in our results. Large-scale deployments need effective interdisciplinary approaches and long-term project horizons to address issues emerging from big data characteristics, and to avoid compartmentalization of agricultural sciences. We need both an engineering perspective – to make things work in practice – and a systems thinking perspective – to offer holistic, integrated solutions.}
}
@article{BEHARA2009195,
title = {Parallel finite element computation of incompressible flows},
journal = {Parallel Computing},
volume = {35},
number = {4},
pages = {195-212},
year = {2009},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2008.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167819108001348},
author = {Suresh Behara and Sanjay Mittal},
keywords = {Navier–Stokes equations, Parallel computing, Superlinear speedup, Wake, Transition, Wake instabilities},
abstract = {A stabilized finite element formulation for three-dimensional unsteady incompressible flows is implemented on a distributed memory parallel computer. A matrix-free version of the GMRES algorithm is utilized to solve the equation systems in an implicit manner. The scalability of the computations on a 64-processor Linux cluster is evaluated for moderate to large size problems. A method for estimating the speedup for large-scale problems, where computations on a single processor is not possible, is proposed. Superlinear speedup is observed, perhaps for the first time, for a large-scale problem that is associated with more than 44 million nodes and 176 million equations. The performance of the various subactivities of the program is monitored to investigate the cause. It is found that the formation of the RHS vector and the preconditioner achieves a very high level of superlinear speedup as the number of processors increase. As a result, even though the network time for interprocessor communication increases with increase in processors, an overall superlinear speedup is realized for large-scale problems. The superlinear speedup is attributed to cache related effects. A comparison between the performance of matrix and matrix-free versions of the GMRES algorithm is carried out. It is found that for large-scale applications the matrix-free version outperforms its counterpart for reasonable dimensions of the Kyrylov subspace. The effect of mesh partitioning on the scalability is also studied. A significant reduction in communication time is observed with partitioning that leads to an overall improvement of speedup. The parallel implementation is utilized to study the wake instabilities in flow past a stationary circular cylinder at Re=150, 200 and 300. The Re=150 flow is found to be two-dimensional while mode-A and mode-B instabilities are observed at Re=200 and 300, respectively. The Re=300 flow is associated with a low frequency modulation in addition to the vortex shedding frequency.}
}
@article{CHENG2013267,
title = {Shape-anisotropic particles at curved fluid interfaces and role of Laplace pressure: A computational study},
journal = {Journal of Colloid and Interface Science},
volume = {402},
pages = {267-278},
year = {2013},
issn = {0021-9797},
doi = {https://doi.org/10.1016/j.jcis.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021979713003056},
author = {Tian-Le Cheng and Yu U. Wang},
keywords = {Capillary forces, Surface tension, Laplace pressure, Diffuse interface field approach, Gibbs–Duhem relation, Shape anisotropy, Pickering emulsions},
abstract = {The self-assembly behavior of shape-anisotropic particles at curved fluid interfaces is computationally investigated by diffuse interface field approach (DIFA). A Gibbs–Duhem-type thermodynamic formalism is introduced to treat heterogeneous pressure within the phenomenological model, in agreement with Young–Laplace equation. Computer simulations are performed to study the effects of capillary forces (interfacial tension and Laplace pressure) on particle self-assembly at fluid interfaces in various two-dimensional cases. For isolated particles, it is found that the equilibrium liquid interface remains circular and particles of different shapes do not disturb the homogeneous curvature of liquid interface, while the equilibrium position, orientation and stability of a particle at the liquid interface depend on its shape and initial location with respect to the liquid interface. For interacting particles, the curvature of local liquid interfaces is different from the apparent curvature of the particle shell; nevertheless, irrespective of the particle shapes, a particle-coated droplet always tends to deform into a circular morphology under positive Laplace pressure, loses mechanical stability and collapses under negative Laplace pressure, while adapts to any morphology and stays in neutral equilibrium under zero Laplace pressure. Finally, the collective behaviors of particles and Laplace pressure evolution in bicontinuous interfacially jammed emulsion gels (bijels) are investigated.}
}
@incollection{GARDNER202477,
title = {Chapter 4 - Smart design for urban activation and placemaking},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {77-102},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000082},
author = {Nicole Gardner},
keywords = {Cyber-physical systems, Design, Digital placemaking, Interaction, Placemaking, Smart design, Urban activation, Urban amenitization},
abstract = {This chapter charts out the distinction between the concepts of digital placemaking and smart placemaking. It examines existing and speculative urban technology projects that combine spatial design thinking and physical computing to address placemaking design goals such as urban activation, amenitization, and safety and security. In ways different from conventional smart city initiatives that surveil urban dynamics en masse to imperceptibly calibrate large-scale urban services and infrastructural systems, the projects discussed in this chapter engage sensor-based technologies to create localized, responsive, and interactive urban environments to address the social, cultural, and aesthetic dimensions of urban livability.}
}
@article{VAHLDICK2020100037,
title = {A blocks-based serious game to support introductory computer programming in undergraduate education},
journal = {Computers in Human Behavior Reports},
volume = {2},
pages = {100037},
year = {2020},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2020.100037},
url = {https://www.sciencedirect.com/science/article/pii/S2451958820300373},
author = {Adilson Vahldick and Paulo Roberto Farah and Maria José Marcelino and António José Mendes},
keywords = {Computer programming learning, Blocks-based approach, Serious games},
abstract = {Blocks-based environments have been used to promote computational thinking (CT) and programming learning mostly in elementary and middle schools. In many countries, like Brazil and Portugal, isolated initiatives have been launched to promote CT learning, but until now there is no evidence of a widespread use of this type of environments. Consequently, it is not common that students that reach higher education nowadays are familiar with CT and programming. This paper presents the development of a serious game to support the learning of basic computer programming. It is a blocks-based environment including also resources that allow the teacher to follow the student’s progress and customize in-game tasks. Four cycles of experiments were conducted, improving both the game and how it was used. Based on the results of these experiences, the key contribution of this paper is a set of fourteen findings and recommendations to the creation and use of a game-based approach to support introductory computer programming learning for novices.}
}
@article{AIZENBERG199987,
title = {One computational approach in support of the Riemann hypothesis},
journal = {Computers & Mathematics with Applications},
volume = {37},
number = {1},
pages = {87-94},
year = {1999},
issn = {0898-1221},
doi = {https://doi.org/10.1016/S0898-1221(98)00244-2},
url = {https://www.sciencedirect.com/science/article/pii/S0898122198002442},
author = {L. Aizenberg and V. Adamchik and V.E. Levit},
keywords = {ς-function, Riemann Hypothesis, Analytic continuation of a function given on a part of its boundary, Holomorphic functions, Conformal mappings, Unit disk, Computational experiments},
abstract = {Some of the results on the criteria for the existence of an analytic continuation into a domain of a function given on a part of its boundary obtained by one of the authors are applied to the Riemann Hypothesis on the zeta-function zeroes. We include all of the basic structural information needed on the previous results on analytic continuation. Some comprehensive numerical experiments have been performed. We have found two important trends in the associated numerical results. The first one is that these findings favor the view that the Riemann Hypothesis is valid. The second one corresponds to a new conjecture on monotonic behavior of some sequences of integrals. The computational experiments have been performed with the Mathematica V3.0.}
}
@article{KUHN202428,
title = {A landscape of consciousness: Toward a taxonomy of explanations and implications},
journal = {Progress in Biophysics and Molecular Biology},
volume = {190},
pages = {28-169},
year = {2024},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2023.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0079610723001128},
author = {Robert Lawrence Kuhn},
keywords = {Consciousness, Mind-body problem, Materialism, Monism, Dualism, Idealism},
abstract = {Diverse explanations or theories of consciousness are arrayed on a roughly physicalist-to-nonphysicalist landscape of essences and mechanisms. Categories: Materialism Theories (philosophical, neurobiological, electromagnetic field, computational and informational, homeostatic and affective, embodied and enactive, relational, representational, language, phylogenetic evolution); Non-Reductive Physicalism; Quantum Theories; Integrated Information Theory; Panpsychisms; Monisms; Dualisms; Idealisms; Anomalous and Altered States Theories; Challenge Theories. There are many subcategories, especially for Materialism Theories. Each explanation is self-described by its adherents, critique is minimal and only for clarification, and there is no attempt to adjudicate among theories. The implications of consciousness explanations or theories are assessed with respect to four questions: meaning/purpose/value (if any); AI consciousness; virtual immortality; and survival beyond death. A Landscape of Consciousness, I suggest, offers perspective.}
}
@article{NIKIFORIDOU20124830,
title = {Risk Literacy in Early Childhood Education Under a Lifelong Perspective},
journal = {Procedia - Social and Behavioral Sciences},
volume = {46},
pages = {4830-4833},
year = {2012},
note = {4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.343},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812020794},
author = {Zoi Nikiforidou and Jenny Pange and Theodore Chadjipadelis},
keywords = {First keywords, second keywords, third keywords, forth keywords},
abstract = {Risk entails every action, every level and every perspective of our lives. The ability to make advantageous decisions, to deal with uncertainties, to infer and estimate more or less probable outcomes, to manage risky or riskless situations compose the wider notion of risk literacy and may be inserted from formal preschool education. The current paper aims to enlighten the notion of risk literacy and safety education as a necessity in establishing pupils ready to accept failure, to achieve success, to take initiatives, to become self-competent, to develop probabilistic and statistical thinking, to confront uncertainty and in turn to face the challenges of modern risk society. It is argued that within the formal settings of preschool education, through developmentally appropriate activities, opportunities may be implemented in order to encourage children as future citizens to construct risk literate personalities. It is concluded that risk perception and management imply awareness, assessment, avoidance and adaptation and are connected with growth, maturity, practice, experiences, intuitions and computations.}
}
@article{YANG20242009,
title = {Maximum Power Point Tracking Technology for PV Systems: Current Status and Perspectives},
journal = {Energy Engineering},
volume = {121},
number = {8},
pages = {2009-2022},
year = {2024},
issn = {0199-8595},
doi = {https://doi.org/10.32604/ee.2024.049423},
url = {https://www.sciencedirect.com/science/article/pii/S0199859524000708},
author = {Bo Yang and Rui Xie and Zhengxun Guo},
keywords = {PV systems, MPPT, partial shading condition, DC-DC converter},
abstract = {Maximum power point tracking (MPPT) technology plays a key role in improving the energy conversion efficiency of photovoltaic (PV) systems, especially when multiple local maximum power points (LMPPs) occur under partial shading conditions (PSC). It is necessary to modify the operating point efficiently and accurately with the help of MPPT technology to maximize the collected power. Even though a lot of research has been carried out and impressive progress achieved for MPPT technology, it still faces some challenges and dilemmas. Firstly, the mathematical model established for PV cells is not precise enough. Second, the existing algorithms are often optimized for specific conditions and lack comprehensive adaptability to the actual operating environment. Besides, a single algorithm may not be able to give full play to its advantages. In the end, the selection criteria for choosing the suitable MPPT algorithm/converter combination to achieve better performance in a given scenario is very limited. Therefore, this paper systematically discusses the current research status and challenges faced by PV MPPT technology around the three aspects of MPPT models, algorithms, and hardware implementation. Through in-depth thinking and discussion, it also puts forward positive perspectives on future development, and five forward-looking solutions to improve the performance of PV systems MPPT are suggested.}
}
@article{SONG2023100812,
title = {Robert Mare’s legacy: Multi-generational processes},
journal = {Research in Social Stratification and Mobility},
volume = {88},
pages = {100812},
year = {2023},
note = {Robert D. Mare’s Legacy},
issn = {0276-5624},
doi = {https://doi.org/10.1016/j.rssm.2023.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0276562423000562},
author = {Xi Song},
abstract = {This paper summarizes some of Robert Mare’s major contributions as a sociologist, demographer, and social statistician; as a pioneer who advanced the multi-generational perspective in social science research; as a leader who introduced demographic thinking to social mobility studies; and as a trailblazer who developed new approaches to studying multi-generational processes}
}
@article{TETEWSKY1986202,
title = {Conceptual and lexical determinants of nonentrenched thinking},
journal = {Journal of Memory and Language},
volume = {25},
number = {2},
pages = {202-225},
year = {1986},
issn = {0749-596X},
doi = {https://doi.org/10.1016/0749-596X(86)90030-6},
url = {https://www.sciencedirect.com/science/article/pii/0749596X86900306},
author = {Sheldon J Tetewsky and Robert J Sternberg},
abstract = {Two experiments investigating information-processing consequences of entrenched and nonentrenched concepts are reported. An attempt is made to distinguish between these two kinds of concepts by using two variables—the naturalness of the occurrence described by a concept and the familiarity of the name used to refer to that occurrence. In each experiment a given conceptual system was expressed in four alternative forms by crossing concept familiarity (naturalness) with lexical familiarity. The experiments used a concept-selection task in which subjects were required to characterize an event based on a preliminary piece of information and a final, confirmatory piece of information. The results indicated that the locus of nonentrenchment lies in using a familiar name to identify an unfamiliar occurrence or in using an unfamiliar name to identify a familiar occurrence. An information-processing model of task performance provided a very good account of the latency data and scores from the concept-selection task correlated with scores from a set of psychometric reasoning tests. The distinction between entrenched and nonentrenched concepts can be interpreted in terms of interference theory, and it also has implications for the way we think about induction and human intelligence.}
}
@incollection{ADAMS2016283,
title = {Chapter 16 - Brain Computations in Schizophrenia},
editor = {Ted Abel and Thomas Nickl-Jockschat},
booktitle = {The Neurobiology of Schizophrenia},
publisher = {Academic Press},
address = {San Diego},
pages = {283-295},
year = {2016},
isbn = {978-0-12-801829-3},
doi = {https://doi.org/10.1016/B978-0-12-801829-3.00024-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018293000240},
author = {R.A. Adams and K.J. Friston},
keywords = {Schizophrenia, Bayesian brain, precision, aberrant salience, reversal, predictive coding, NMDAR, GABA, delusions},
abstract = {Because the brain performs Bayesian inference for the causes of its sensory data, the synaptic gain could encode the precision (inverse variance) of its beliefs using a hierarchical generative model and predictive coding. Several neurobiological risk factors for schizophrenia (NMDAR and GABAergic interneuron hypofunction) reduce both synaptic and “oscillatory” gain at high hierarchical areas. This could impair the encoding of precision at higher levels of the brain’s hierarchical model and increase expected precision at lower levels. This imbalance can account for many neurobiological and phenomenological findings in schizophrenia. Striatal D2R hyperactivity may increase the precision of current policies by inhibiting behavioral or cognitive switching. This could be a (dysfunctional) consequence of or even an attempt to compensate for prefrontal or hippocampal pathology. This D2R hyperactivity may also reduce learning from positive outcomes and affect the encoding of motivational (or informational) salience.}
}
@article{ZHANG2024101587,
title = {Effects of a problem posing instructional interventions on student learning outcomes: A three-level meta-analysis},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101587},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101587},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001251},
author = {Cheng Zhang and Ying Zhou and Tommy Tanu Wijaya and Jihe Chen and Yimin Ning},
keywords = {Problem posing, Learning outcomes, Three-level meta-analysis, Instructional interventions},
abstract = {Problem posing is increasingly being considered in the field of education, with many experts exploring its positive effects on student learning outcomes. In this case, different perspectives have emerged regarding the impact of the intervention, claiming the overall effect remains uncertain. Therefore, this study aims to explore the effects of a problem posing instructional intervention on student learning outcomes at the cognitive and non-cognitive levels from 2000 to 2023, using a three-level meta-analysis. 32 studies and 4,068 participants were included to compare the classrooms with and without problem posing instructional interventions in elementary to higher education. The results showed a moderate-positive and small positive effect on students cognitive (Hedges' g = 0.681, 95 % CI [0.552, 0.810], p < 0.001) and non-cognitive (Hedges' g = 0.367, 95 % CI [0.113, 0.620], p = 0.003) levels, respectively. Based on the moderator analysis, there were differences in the learning outcomes among students across various task formats. Notably, tasks that included specific information and involved problem posing in context demonstrated significantly better performance. In conclusion, these results indicate the importance of problem posing instructional interventions in promoting student's development and their impact on cognitive and non-cognitive dimensions.}
}
@article{PANANGADEN201410,
title = {Causality in physics and computation},
journal = {Theoretical Computer Science},
volume = {546},
pages = {10-16},
year = {2014},
note = {Models of Interaction: Essays in Honour of Glynn Winskel},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2014.02.041},
url = {https://www.sciencedirect.com/science/article/pii/S0304397514001674},
author = {Prakash Panangaden},
keywords = {Causal structure, Event structure, Spacetime, Petri nets},
abstract = {Glynn Winskel has had enormous influence on the study of causal structure in computer science. In this brief note, I discuss analogous concepts in relativity where also causality plays a fundamental role. I discuss spacetime structure in a series of layers and emphasize the role of causal structure. I close with some comparisons between causality in relativity and in distributed computing systems.}
}
@article{KUDARIYAWAR2016193,
title = {Computational study of instabilities in a rectangular natural circulation loop using 3D CFD simulation},
journal = {International Journal of Thermal Sciences},
volume = {101},
pages = {193-206},
year = {2016},
issn = {1290-0729},
doi = {https://doi.org/10.1016/j.ijthermalsci.2015.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1290072915003440},
author = {Jayaraj Yallappa Kudariyawar and Abhijeet Mohan Vaidya and Naresh Kumar Maheshwari and Polepalle Satyamurthy},
keywords = {Natural circulation loop, 3D CFD simulation, Instability},
abstract = {Steady state and transient characteristics of a natural circulation loop working with water are obtained. For this purpose, 3D steady state and transient CFD simulations are performed. The CFD model includes pipe thickness as well as secondary side coolant passage apart from primary side. Steady state and transient characteristics are computed for various configurations i.e. Vertical Heater Vertical Cooler (VHVC), Horizontal Heater Horizontal Cooler (HHHC), etc. Steady state data was compared with available correlations. Flow initiation transients were compared with experimental data. Both the steady state and transient results are found to be in good agreement with previously published data. The reason for formation of unidirectional and bi-directional pulsing in HHHC configuration at different powers is explained with the help of temperature fields at different instants of time. Effect of sudden power rise/power step back on instability in HHHC configuration is estimated using CFD simulations.}
}
@article{SANCHEZTORRUBIA201212177,
title = {An approach to automatic learning assessment based on the computational theory of perceptions},
journal = {Expert Systems with Applications},
volume = {39},
number = {15},
pages = {12177-12191},
year = {2012},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0957417412006665},
author = {M. Gloria Sánchez-Torrubia and Carmen Torres-Blanc and Gracian Trivino},
keywords = {Automatic learning assessment, Computing with words and perceptions, Granular linguistic model of a phenomenon},
abstract = {E-learning systems output a huge quantity of data on a learning process. However, it takes a lot of specialist human resources to manually process these data and generate an assessment report. Additionally, for formative assessment, the report should state the attainment level of the learning goals defined by the instructor. This paper describes the use of the granular linguistic model of a phenomenon (GLMP) to model the assessment of the learning process and implement the automated generation of an assessment report. GLMP is based on fuzzy logic and the computational theory of perceptions. This technique is useful for implementing complex assessment criteria using inference systems based on linguistic rules. Apart from the grade, the model also generates a detailed natural language progress report on the achieved proficiency level, based exclusively on the objective data gathered from correct and incorrect responses. This is illustrated by applying the model to the assessment of Dijkstra’s algorithm learning using a visual simulation-based graph algorithm learning environment, called GRAPHs.}
}
@article{NIKNAM20112805,
title = {Non-smooth economic dispatch computation by fuzzy and self adaptive particle swarm optimization},
journal = {Applied Soft Computing},
volume = {11},
number = {2},
pages = {2805-2817},
year = {2011},
note = {The Impact of Soft Computing for the Progress of Artificial Intelligence},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2010.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S1568494610002875},
author = {Taher Niknam and Hasan Doagou Mojarrad and Hamed Zeinoddini Meymand},
keywords = {Economic dispatch, New adaptive particle swarm optimization (NAPSO), Mutation operator, Multi-fuel effects, Self-adaptive parameter control},
abstract = {Economic dispatch (ED) problem is a nonlinear and non-smooth optimization problem when valve-point effects, multi-fuel effects and prohibited operating zones (POZs) have been considered. This paper presents an efficient evolutionary method for a constrained ED problem using the new adaptive particle swarm optimization (NAPSO) algorithm. The original PSO has difficulties in premature convergence, performance and the diversity loss in optimization process as well as appropriate tuning of its parameters. In the proposed algorithm, to improve the global searching capability and prevent the convergence to local minima, a new mutation is integrated with adaptive particle swarm optimization (APSO). In APSO, the inertia weight is tuned by using fuzzy IF/THEN rules and the cognitive and the social parameters are self-adaptively adjusted. The proposed NAPSO algorithm is validated on test systems consisting of 6, 10, 15, 40 and 80 generators with the objective functions possessing prohibited zones, multi-fuel effects and valve-point loading effects. The research results reveal the effectiveness and applicability of the proposed algorithm to the practical ED problem.}
}
@article{CASH2023101219,
title = {Method in their madness: Explaining how designers think and act through the cognitive co-evolution model},
journal = {Design Studies},
volume = {88},
pages = {101219},
year = {2023},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2023.101219},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X23000601},
author = {Philip Cash and Milene Gonçalves and Kees Dorst},
keywords = {co-evolution, design process(es), design cognition, design thinking, creativity},
abstract = {Designers often face situations where the only way forward is through the exploration of possibilities. However, there is a critical disconnect between understanding of how designer’s think and act in such situations. We address this disconnect by proposing and testing (via protocol analysis) the cognitive co-evolution model. Our model comprises a new approach to co-evolutionary design theory by explaining both the progression of the process itself and the creation of design outputs via an interplay between metacognitive perceived uncertainty, cognition, and the external world. We thus connect explanations of how designers think with descriptions of how they act. We provide a foundation for connecting to other theories, models, and questions in design research via common links to cognition and metacognition.}
}
@article{THOMPSON1983161,
title = {Thinking about thinking},
journal = {Trends in Neurosciences},
volume = {6},
pages = {161-163},
year = {1983},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(83)90076-0},
url = {https://www.sciencedirect.com/science/article/pii/0166223683900760},
author = {I.D. Thompson},
abstract = {The Cognitive Neuroscience Institute held its first conference in September 1982, in Kusadasi, Turkey. The institute was recently established in New York to promote research in cognitive neuroscience, and in December 1982 it presented the Hermann von Helmholtz Award to Vernon Mountcastle (see TINS, January 1983, Vol. 6, p. 9). The meeting was attended by individuals whose specialities range from molecular biology to philosophy. Their common aim was to investigate the role of cognitive neuroscience in establishing a theory of mental processing which combines the knowledge derived from cognitive psychology and from neuroscience. How this synthesis is to be achieved, and indeed the extent to which it is possible, was the subject of wide-ranging and often vigorous debate. But, as many disciplines begin to converge on common problems, the prospects for cognitive neuroscience appear encouraging. Thus, as neuroscientists start to unravel the molecular mechanisms of learning and memory, it is interesting to consider what constraints such mechanisms might place on the operational rules for correlating single-neuron activity and behaviour in invertebrates, it has been argued that similar progress in understanding the mammalian brain will come from the application of models, derived from cognitive psychology, to neurophysiology. Artificial intelligence provides an opportunity to model many cognitive processes, but how close do the models come to reflecting underlying mental states? Indeed, the problem or non-problem of self-awareness dominated many conversations, tantalizing some participants by its intractability and accepted by others as a naturally emergent attribute of the mechanics of the mind.}
}
@incollection{JOHNSON201435,
title = {Chapter 3 - Computational and Process Models of Decision Making in Psychology and Behavioral Economics},
editor = {Paul W. Glimcher and Ernst Fehr},
booktitle = {Neuroeconomics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {35-47},
year = {2014},
isbn = {978-0-12-416008-8},
doi = {https://doi.org/10.1016/B978-0-12-416008-8.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124160088000036},
author = {Eric J. Johnson and Roger Ratcliff},
keywords = {Computation Process Models, Decision Neuroscience, Drift-Diffusion Models, economic theory, Intertemporal Choice, Riskless Choice, Risky Choice},
abstract = {This chapter reviews models of choice on two levels: The first concerns the descriptions of choice and their evolution from normative models of how choices should be make to more behaviorally realistic models, more consistent with data showing that choice depends heavily on context. We present brief overviews of risky and riskless choice models and data and for choice over time. We then turn to computational process models, a more recent class of models that make prediction for multiple properties of the decision process beyond simply what is chosen, including predicting the distribution of errors and decision times.These models are typically applied to simpler choices, but have found great use in contemporary neuroscience.}
}
@article{JONES2000571,
title = {Unstructured mesh computations on CCMs},
journal = {Advances in Engineering Software},
volume = {31},
number = {8},
pages = {571-580},
year = {2000},
issn = {0965-9978},
doi = {https://doi.org/10.1016/S0965-9978(00)00012-0},
url = {https://www.sciencedirect.com/science/article/pii/S0965997800000120},
author = {M.T Jones and K Ramachandran},
keywords = {Configurable computing, Floating point, Finite element},
abstract = {Configurable Computing Machines (CCMs) have been able to provide orders of magnitude increases in execution rates for applications such as image processing, signal processing, and automatic target recognition. This paper describes the use of CCMs to accelerate complex, large-scale scientific computations. These applications present a challenge for CCMs because of their large size, hundreds of thousands of lines of code, and the unstructured nature of the computations. This paper describes strategies for accelerating scientific computations on CCMs and demonstrates the effectiveness of one such strategy on the Annapolis Micro Systems WildForce board. Results from this implementation are analyzed.}
}
@article{MARTINRAMOS201751,
title = {First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming},
journal = {Computers in Human Behavior},
volume = {76},
pages = {51-58},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217304193},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{ROBERTS2024100502,
title = {New approach methodologies (NAMs) in drug safety assessment: A vision of the future},
journal = {Current Opinion in Toxicology},
volume = {40},
pages = {100502},
year = {2024},
issn = {2468-2020},
doi = {https://doi.org/10.1016/j.cotox.2024.100502},
url = {https://www.sciencedirect.com/science/article/pii/S2468202024000445},
author = {Ruth A. Roberts},
keywords = {3Rs, NAMs, FTIH, Drug development, ICH, Nanobots},
abstract = {Much progress has been made in reducing and refining animal use in toxicology testing, but progress in the use of new approach methodologies (NAMs) to replace animals is disappointing. There are many highly sophisticated NAMs available, but societal, regulatory and political barriers to their implementation remain. Change requires vision, starting with imagining a future where we are successful. Specifically, this would comprise the registration of safe and effective medicines without animal tests. How do we achieve this vision? Thinking differently, in silico methods could be used to provide a detailed assessment of target- and modality-related toxicological risks, coupled with modelling of exposure. In vitro NAMs such as microphysiological systems, microelectrode array and ion channel panels could then be employed to address hypothetical risks. Finally, the safety of first time in human trials could be assessed and assured using circulating nanobots that measure conventional clinical pathology parameters alongside new biomarkers such as circulating tissue DNA. This may seem the stuff of fantasy, but imagination is key to shaping a better future and all change starts with a vision, however far-fetched it may seem today.}
}
@incollection{BARBAROSSA2018419,
title = {Chapter 16 - The Edge Cloud: A Holistic View of Communication, Computation, and Caching},
editor = {Petar M. Djurić and Cédric Richard},
booktitle = {Cooperative and Graph Signal Processing},
publisher = {Academic Press},
pages = {419-444},
year = {2018},
isbn = {978-0-12-813677-5},
doi = {https://doi.org/10.1016/B978-0-12-813677-5.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813677500016X},
author = {Sergio Barbarossa and Stefania Sardellitti and Elena Ceci and Mattia Merluzzi},
keywords = {5G networks, Wireless communications, Graph-based learning},
abstract = {The evolution of communication networks shows a clear shift of focus from just improving the communications aspects to enabling new important services, from Industry 4.0 to automated driving, virtual/augmented reality, the Internet of Things (IoT), and so on. This trend is evident in the roadmap planned for the deployment of the fifth-generation (5G) communication networks. This ambitious goal requires a paradigm shift toward a vision that looks at communication, computation, and caching (3C) resources as three components of a single holistic system. The further step is to bring these 3C resources closer to the mobile user, at the edge of the network, to enable very low latency and high reliability services. The scope of this chapter is to show that signal processing techniques can play a key role in this new vision. In particular, we motivate the joint optimization of 3C resources. Then we show how graph-based representations can play a key role in building effective learning methods and devising innovative resource allocation techniques.}
}
@article{CIRAOLO201378,
title = {A computational method for the Helmholtz equation in unbounded domains based on the minimization of an integral functional},
journal = {Journal of Computational Physics},
volume = {246},
pages = {78-95},
year = {2013},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021999113002258},
author = {Giulio Ciraolo and Francesco Gargano and Vincenzo Sciacca},
keywords = {Helmholtz equation, Transparent boundary conditions, Minimization of integral functionals},
abstract = {We study a new approach to the problem of transparent boundary conditions for the Helmholtz equation in unbounded domains. Our approach is based on the minimization of an integral functional arising from a volume integral formulation of the radiation condition. The index of refraction does not need to be constant at infinity and may have some angular dependency as well as perturbations. We prove analytical results on the convergence of the approximate solution. Numerical examples for different shapes of the artificial boundary and for non-constant indexes of refraction will be presented.}
}
@article{TEZDUYAR19992039,
title = {Methods for parallel computation of complex flow problems},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {2039-2066},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00080-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000800},
author = {Tayfun Tezduyar and Yasuo Osawa},
keywords = {Computational fluid dynamics, Flow simulation, Stabilization methods, Compressible flow, Incompressible flow, Multidomain computational methods},
abstract = {This paper is an overview of some of the methods developed by the Team for Advanced Flow Simulation and Modeling (T★AFSM) [http://www.mems.rice.edu/TAFSM/] to support flow simulation and modeling in a number of “Targeted Challenges”. The “Targeted Challenges” include unsteady flows with interfaces, fluid–object and fluid–structure interactions, airdrop systems, and air circulation and contaminant dispersion. The methods developed include special numerical stabilization methods for compressible and incompressible flows, methods for moving boundaries and interfaces, advanced mesh management methods, and multi-domain computational methods. We include in this paper a number of numerical examples from the simulation of complex flow problems.}
}
@article{AIMONE2009187,
title = {Computational Influence of Adult Neurogenesis on Memory Encoding},
journal = {Neuron},
volume = {61},
number = {2},
pages = {187-202},
year = {2009},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2008.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0896627308010192},
author = {James B. Aimone and Janet Wiles and Fred H. Gage},
keywords = {SYSNEURO, MOLNEURO, STEMCELL},
abstract = {Summary
Adult neurogenesis in the hippocampus leads to the incorporation of thousands of new granule cells into the dentate gyrus every month, but its function remains unclear. Here, we present computational evidence that indicates that adult neurogenesis may make three separate but related contributions to memory formation. First, immature neurons introduce a degree of similarity to memories learned at the same time, a process we refer to as pattern integration. Second, the extended maturation and change in excitability of these neurons make this added similarity a time-dependent effect, supporting the possibility that temporal information is included in new hippocampal memories. Finally, our model suggests that the experience-dependent addition of neurons results in a dentate gyrus network well suited for encoding new memories in familiar contexts while treating novel contexts differently. Taken together, these results indicate that new granule cells may affect hippocampal function in several unique and previously unpredicted ways.}
}
@article{MARTINRAMOS2018420,
title = {Reprint of ‘First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming’},
journal = {Computers in Human Behavior},
volume = {80},
pages = {420-427},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S074756321730691X},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{MCKELVEY2009476,
title = {Designing an electronic auction market for complex ‘smart parts’ logistics: Options based on LeBaron's computational stock market},
journal = {International Journal of Production Economics},
volume = {120},
number = {2},
pages = {476-494},
year = {2009},
note = {Special Issue on Introduction to Design and Analysis of Production Systems},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2009.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925527309000899},
author = {Bill McKelvey and Christine Wycisk and Michael Hülsmann},
keywords = {Supply chain management, Electronic auction market, I&C technologies, Complexity theory, Neural networks},
abstract = {Modern technologies, such as RFID, offer never-before seen learning abilities to parts moving in supply chains. Logistics systems may be understood as complex adaptive logistics systems (CALS). They also may be conceived as electronic auction markets as ‘smart parts’ bid for the best routing and pricing from transportation firms. To ensure the world-wide functionality and efficiency of CALS transportation markets, we suggest the utility of an agent-based computational market design based on Blake LeBaron's stock-market model. Given that parts may be more or less smart, markets more or less complex, and self-organizing CALS systems probabilistically subject to the bullwhip effect, we suggest nine different computational CALS market-design options, offering more adaptivity to unexpected environmental contingencies.}
}
@article{YOUNG201719,
title = {Technology-enhanced mathematics instruction: A second-order meta-analysis of 30 years of research},
journal = {Educational Research Review},
volume = {22},
pages = {19-33},
year = {2017},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2017.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X1730026X},
author = {Jamaal Young},
keywords = {Meta-analysis, Mathematics achievement, Technology, Calculators, Computer-assisted instruction},
abstract = {It is important to assess the cumulative effects of technology on student achievement captured in the last 30 years of technologyenhanced mathematics instruction. Synthesizing the thousands of articles and gray literature on this subject is necessary but would require a considerable commitment of academic resources. A second-order metaanalysis or meta-analysis of meta-analyses is an alternative that is reasonable and effective. Thus, a second-order meta-analysis of 19 prior meta-analyses with minimum overlap between primary studies was conducted. The results represent 663 primary studies (approximately 141,733 participants) and 1,263 effect sizes. The random effects' mean effect size of .38 was statistically significantly different from zero. The results provide a historical and contextualized summary of 30 years of meta-analytic research, which supports meta-analytic thinking and better interpretation of future effect sizes. Results indicate that technology function and study quality are major contributors to effect size variation. Specifically, computation enhancement technologies were most effective, while studies that examine combinations of enhancements were least effective. Implications for technology-enhanced mathematics instruction and meta-analytic research are provided.}
}
@article{DEBRIGARD2021104574,
title = {Perceived similarity of imagined possible worlds affects judgments of counterfactual plausibility},
journal = {Cognition},
volume = {209},
pages = {104574},
year = {2021},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2020.104574},
url = {https://www.sciencedirect.com/science/article/pii/S0010027720303930},
author = {Felipe {De Brigard} and Paul Henne and Matthew L. Stanley},
keywords = {Imagination, Counterfactual thinking, Plausibility, Similarity, Possible worlds},
abstract = {People frequently entertain counterfactual thoughts, or mental simulations about alternative ways the world could have been. But the perceived plausibility of those counterfactual thoughts varies widely. The current article interfaces research in the philosophy and semantics of counterfactual statements with the psychology of mental simulations, and it explores the role of perceived similarity in judgments of counterfactual plausibility. We report results from seven studies (N = 6405) jointly supporting three interconnected claims. First, the perceived plausibility of a counterfactual event is predicted by the perceived similarity between the possible world in which the imagined situation is thought to occur and the actual world. Second, when people attend to differences between imagined possible worlds and the actual world, they think of the imagined possible worlds as less similar to the actual world and tend to judge counterfactuals in such worlds as less plausible. Lastly, when people attend to what is identical between imagined possible worlds and the actual world, they think of the imagined possible worlds as more similar to the actual world and tend to judge counterfactuals in such worlds as more plausible. We discuss these results in light of philosophical, semantic, and psychological theories of counterfactual thinking.}
}
@article{FIORE2006S248,
title = {Multi-scale computational analysis of fluid dynamics in the Toraymyxin adsorption cartridge},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S248},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)83940-0},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006839400},
author = {G.B. Fiore and G. Guadagni and M. Soncini and S. Vesentini and A. Redaelli}
}
@article{HOWARD2006464,
title = {Cumulative semantic inhibition in picture naming: experimental and computational studies},
journal = {Cognition},
volume = {100},
number = {3},
pages = {464-482},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2005.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705001393},
author = {David Howard and Lyndsey Nickels and Max Coltheart and Jennifer Cole-Virtue},
keywords = {Semantic inhibition, Spoken word production, Picture naming, Competition, Word retrieval, Computational modelling, Priming},
abstract = {We report an experiment in which subjects named 120 pictures, consisting of series of five pictures drawn from each of 24 semantic categories (and intermixed with 45 fillers). The number of intervening trials (lag) between successive presentations of members of the same category varied from two to eight. Subjects' naming latencies were slowed by 30ms for each preceding member of the category. This effect was both cumulative and linear, and unrelated to the lag elapsing since the previous presentation of a category member. These results definitively demonstrate the occurrence of cumulative interference for word retrieval by prior retrieval of other exemplars of the same semantic category—cumulative semantic inhibition. We claim that this inhibition effect could only occur if the spoken word production system possesses three specific properties (competition, priming, and sharing of semantic activation). We provide computational-modelling evidence in support of this claim. We show that no current theory of spoken word production has all of these properties. In their current form, all these theories are falsified by these results. We briefly discuss the obstacles that may be encountered by current models were they modified to account for our findings.}
}
@article{HSU2011380,
title = {The probabilistic analysis of language acquisition: Theoretical, computational, and experimental analysis},
journal = {Cognition},
volume = {120},
number = {3},
pages = {380-390},
year = {2011},
note = {Probabilistic models of cognitive development},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2011.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010027711000734},
author = {Anne S. Hsu and Nick Chater and Paul M.B. Vitányi},
keywords = {Child language acquisition, Poverty of the stimulus, No negative evidence, Bayesian models, Minimum description length, Simplicity principle, Natural language, Probabilistic models, Identification in the limit},
abstract = {There is much debate over the degree to which language learning is governed by innate language-specific biases, or acquired through cognition-general principles. Here we examine the probabilistic language acquisition hypothesis on three levels: We outline a novel theoretical result showing that it is possible to learn the exact generative model underlying a wide class of languages, purely from observing samples of the language. We then describe a recently proposed practical framework, which quantifies natural language learnability, allowing specific learnability predictions to be made for the first time. In previous work, this framework was used to make learnability predictions for a wide variety of linguistic constructions, for which learnability has been much debated. Here, we present a new experiment which tests these learnability predictions. We find that our experimental results support the possibility that these linguistic constructions are acquired probabilistically from cognition-general principles.}
}
@article{CUMMINGS2003369,
title = {Computational challenges in high angle of attack flow prediction},
journal = {Progress in Aerospace Sciences},
volume = {39},
number = {5},
pages = {369-384},
year = {2003},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(03)00041-1},
url = {https://www.sciencedirect.com/science/article/pii/S0376042103000411},
author = {Russell M. Cummings and James R. Forsythe and Scott A. Morton and Kyle D. Squires},
abstract = {Aircraft aerodynamics have been predicted using computational fluid dynamics for a number of years. While viscous flow computations for cruise conditions have become commonplace, the non-linear effects that take place at high angles of attack are much more difficult to predict. A variety of difficulties arise when performing these computations, including challenges in properly modeling turbulence and transition for vortical and massively separated flows, the need to use appropriate numerical algorithms if flow asymmetry is possible, and the difficulties in creating grids that allow for accurate simulation of the flowfield. These issues are addressed and recommendations are made for further improvements in high angle of attack flow prediction. Current predictive capabilities for high angle of attack flows are reviewed, and solutions based on hybrid turbulence models are presented.}
}
@article{SPEISER2011271,
title = {Models for products},
journal = {The Journal of Mathematical Behavior},
volume = {30},
number = {4},
pages = {271-290},
year = {2011},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2011.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312311000307},
author = {Bob Speiser and Chuck Walter},
keywords = {Model, Representation, Presentation, Operator product, Controlled variable, Frame, Core knowledge, Analog magnitude, Parallel individuation, Shared intentionality},
abstract = {This paper explores how models can support productive thinking. For us a model is a thing, a tool to help make sense of something. We restrict attention to specific models for whole-number multiplication, hence the wording of the title. They support evolving thinking in large measure through the ways their users redesign them. They assume new forms, come to be seen and understood in different ways. We show how work that learners do with models can help them to transform, not simply their understanding of key concepts, but also how they come to view themselves as thinkers and learners, as collaborators in a social process that their work and thinking help to constitute. We draw on recent research on core knowledge, especially by Carey, Spelke, and Tomasello, to clarify how models, as we view them here, can underpin specific actions that support emerging understanding.}
}
@article{RAPAKA2025100809,
title = {Revolutionizing learning − A journey into educational games with immersive and AI technologies},
journal = {Entertainment Computing},
volume = {52},
pages = {100809},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100809},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124001770},
author = {Anuj Rapaka and S.C. Dharmadhikari and Kishori Kasat and Chinnem Rama Mohan and Kuldeep Chouhan and Manu Gupta},
keywords = {Artificial intelligence (AI), Educational games, Learning styles, Stochastic swing golf optimization (SSGOA)},
abstract = {Educational games rapidly integrate entertainment technology and learning, engaging individuals in dynamic educational experiences. These games incorporate multimedia content to encourage critical thinking, problem-solving and information retention. Educational games employ immersive technology such as virtual and augmented reality to transfer individuals to simulated worlds, hence improving learning. Furthermore, artificial intelligence (AI) technologies optimize educational experiences by adjusting information to individual learning styles, providing focused feedback as well as encouraging a more effective and entertaining learning technology. The integration of educational games with immersive and AI technology provides great potential for transforming how individuals acquire and apply information sharing. This research determined the creation of significant educational applications that are personalized and adaptive through the use of image, emotional recognition and speech, intelligent agents that replicate the effects of an individual opponent and control over the complexities of game levels along with information. The study evaluated the different tools that educators and learners could utilize to develop immersive and artificial intelligence-based instructional games without a requirement for programming knowledge. The study demonstrates that immersive technology and AI technology could represent beneficial resources for creating educational video games and entertainment technology. The research highlights the novel possibilities of stochastic swing golf optimization (SSGOA) immersive and AI technologies providing an innovative approach to developing effective as well as attractive learning environments.}
}
@article{WEHNER202387,
title = {On the ‘cognitive map debate’ in insect navigation},
journal = {Studies in History and Philosophy of Science},
volume = {102},
pages = {87-89},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S003936812300105X},
author = {Rüdiger Wehner and Thierry Hoinville and Holk Cruse},
keywords = {Insect navigation, Cognitive map, Neural network model, Path integration, Landmark guidance, Ants, Bees},
abstract = {In a historical account recently published in this journal Dhein argues that the current debate whether insects like bees and ants use cognitive maps (centralized map hypothesis) or other means of navigation (decentralized network hypothesis) largely reflects the classical debate between American experimental psychologists à la Tolman and German ethologists à la Lorenz, respectively. In this dichotomy we, i.e., the proponents of the network hypothesis, are inappropriately placed on the Lorenzian line. In particular, we argue that in contrast to Dhein's claim our concepts are not based on merely instinctive or peripheral modes of information processing. In general, on the one side our approaches have largely been motivated by the early biocybernetics way of thinking. On the other side they are deeply rooted in studies on the insect's behavioral ecology, i.e., in the ecological setting within which the navigational strategies have evolved and within which the animal now operates. Following such a bottom-up approach we are not “anti-cognitive map researchers” but argue that the results we have obtained in ants, and also the results of some decisive experiments in bees, can be explained and simulated without the need of invoking metric maps.}
}
@article{MARINIER200948,
title = {A computational unification of cognitive behavior and emotion},
journal = {Cognitive Systems Research},
volume = {10},
number = {1},
pages = {48-69},
year = {2009},
note = {Modeling the Cognitive Antecedents and Consequences of Emotion},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000302},
author = {Robert P. Marinier and John E. Laird and Richard L. Lewis},
abstract = {Existing models that integrate emotion and cognition generally do not fully specify why cognition needs emotion and conversely why emotion needs cognition. In this paper, we present a unified computational model that combines an abstract cognitive theory of behavior control (PEACTIDM) and a detailed theory of emotion (based on an appraisal theory), integrated in a theory of cognitive architecture (Soar). The theory of cognitive control specifies a set of required computational functions and their abstract inputs and outputs, while the appraisal theory specifies in more detail the nature of these inputs and outputs and an ontology for their representation. We argue that there is a surprising functional symbiosis between these two independently motivated theories that leads to a deeper theoretical integration than has been previously obtained in other computational treatments of cognition and emotion. We use an implemented model in Soar to test the feasibility of the resulting integrated theory, and explore its implications and predictive power in several task domains.}
}
@article{KARAGIANNIS2022103631,
title = {The OMiLAB Digital Innovation environment: Agile conceptual models to bridge business value with Digital and Physical Twins for Product-Service Systems development},
journal = {Computers in Industry},
volume = {138},
pages = {103631},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103631},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000264},
author = {Dimitris Karagiannis and Robert Andrei Buchmann and Wilfrid Utz},
keywords = {Digital twin, Physical twin, Smart Product-service Systems, Agile modeling method engineering, OMiLAB, Domain-specific conceptual modeling},
abstract = {OMiLAB is a community of practice which offers a digital ecosystem bringing together open technologies to investigate and apply conceptual modeling methods for varying purposes and domains. One of the core value propositions is a dedicated Digital Innovation environment comprising several toolkits and workspaces, designed to support Product-Service Systems (PSS) prototyping – a key ingredient for PSS lifecycle management. At the core of this environment is a notion of Agile Digital Twin – a conceptual representation that can be tailored with knowledge engineering means to bridge the semantic and functional gap between a business perspective (focusing on value creation) and an engineering perspective (focusing on cyber-physical proofs-of-concept). To facilitate this bridging, the hereby proposed environment orchestrates, across three abstraction layers, methods such as Design Thinking, Agile Modeling Method Engineering and Model-driven Engineering to turn Ideation into smart Product-Service Systems experiments, in a laboratory setting. The proposed environment was built following Design Science principles. It addresses the problem of historically-disconnected skills required for Digital Innovation projects and it provides a testbed for feasibility experimentation. For design-oriented, artifact building research, a higher Technology Readiness Level can thus be achieved (compared to the level that idea development methods typically attain).}
}
@article{TAGHIKHAH2022101854,
title = {Machine-assisted agent-based modeling: Opening the black box},
journal = {Journal of Computational Science},
volume = {64},
pages = {101854},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101854},
url = {https://www.sciencedirect.com/science/article/pii/S1877750322002137},
author = {Firouzeh Taghikhah and Alexey Voinov and Tatiana Filatova and J. Gareth Polhill},
keywords = {Behavioral analytics, Social communications, Interpretable artificial intelligence, Conceptual modeling, Systems thinking},
abstract = {While agent-based modeling (ABM) has become one of the most powerful tools in quantitative social sciences, it remains difficult to explain their structure and performance. We propose to use artificial intelligence both to build the models from data, and to improve the way we communicate models to stakeholders. Although machine learning is actively employed for pre-processing data, here for the first time, we used it to facilitate model development of a simulation model directly from data. Our suggested framework, ML-ABM accounts for causality and feedback loops in a complex nonlinear system and at the same time keeps it transparent for stakeholders. As a result, beside the development of a behavioral ABM, we open the ‘blackbox’ of purely empirical models. With our approach, artificial intelligence in the simulation field can open a new stream in modeling practices and provide insights for future applications.}
}
@article{YAN20158006,
title = {Trustworthiness evaluation and retrieval-based revision method for case-based reasoning classifiers},
journal = {Expert Systems with Applications},
volume = {42},
number = {21},
pages = {8006-8013},
year = {2015},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415004297},
author = {Aijun Yan and Dianhui Wang},
keywords = {Case-based reasoning classifiers, Classification accuracy, Case evaluation, Case revision},
abstract = {To achieve better classification performance using case-based reasoning classifiers, we propose a retrieval-based revision method with trustworthiness evaluation for problem solving. An improved case evaluation method is employed to evaluate the trustworthiness of the suggested solution after the reuse step, which will divide the target cases and its suggested solutions into a trustworthy set and an untrustworthy set in accordance with a threshold value of trustworthiness. The attribute weights are adjusted by running a genetic algorithm and are used in the second round of retrieval of the untrustworthy set to obtain the classification results. Experimental results demonstrate that our proposed method performs favorably compared with other methods. Also, the proposed method has less computation complexity for the trustworthiness evaluation, and enhances understanding on thinking and inference for case-based reasoning classifiers.}
}
@article{STRASS201534,
title = {Analyzing the computational complexity of abstract dialectical frameworks via approximation fixpoint theory},
journal = {Artificial Intelligence},
volume = {226},
pages = {34-74},
year = {2015},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2015.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0004370215000776},
author = {Hannes Strass and Johannes Peter Wallner},
keywords = {Abstract dialectical frameworks, Computational complexity, Approximation fixpoint theory},
abstract = {Abstract dialectical frameworks (ADFs) have recently been proposed as a versatile generalization of Dung's abstract argumentation frameworks (AFs). In this paper, we present a comprehensive analysis of the computational complexity of ADFs. Our results show that while ADFs are one level up in the polynomial hierarchy compared to AFs, there is a useful subclass of ADFs which is as complex as AFs while arguably offering more modeling capacities. As a technical vehicle, we employ the approximation fixpoint theory of Denecker, Marek and Truszczyński, thus showing that it is also a useful tool for complexity analysis of operator-based semantics.}
}
@article{ATREIDES202135,
title = {E-governance with ethical living democracy},
journal = {Procedia Computer Science},
volume = {190},
pages = {35-39},
year = {2021},
note = {2020 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: Eleventh Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012461},
author = {Kyrtin Atreides},
keywords = {mASI, AGI, e-governance, mediated artificial superintelligence, collective superintelligence, direct digital democracy, liquid democracy, EAP, Effective Altruistic Principles, Ethical Living Democracy, ELD},
abstract = {A new form of e-governance is proposed based on systems seen in biological life at all scales. This model of e-governance offers the performance of collective superintelligence, equally high ethical quality, and a substantial reduction in resource requirements for government functions. In addition, the problems seen in modern forms of government such as misrepresentation, corruption, lack of expertise, short-term thinking, political squabbling, and popularity contests may be rendered virtually obsolete by this approach. Lastly, this model of government generates a digital ecosystem of intelligent life which mirrors physical citizens, serving to bridge the emotional divide between physical and digital life, while also producing the first form of government able to keep pace with accelerating technological progress.}
}
@article{PARK20151,
title = {A Neuro-educational Study of the Development of the Creativity-based Teaching Program and its Effect},
journal = {Procedia - Social and Behavioral Sciences},
volume = {186},
pages = {1-8},
year = {2015},
note = {The Proceedings of 5th World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.200},
url = {https://www.sciencedirect.com/science/article/pii/S187704281502460X},
author = {Sun-Hyung Park and Kwang-Ki Kim and Kyung-Hwa Lee},
keywords = {Creativity-based teaching programs, Divergent thinking, The TTCT, FMRI},
abstract = {This study aims at exploring a possibility of developing a creativity-based teaching program needed for enhancing prospective teachers’ creative potentials based on the theories of Sawyer and Renzulli. Neuroimaging tools such as fMRI were used to identify effects of the program on pre-service teachers’ neural activations on divergent thinking measured primarily by the Torrance Tests of Creative Thinking (TTCT). Since the research is still in progress, we present a theoretical model for the teaching program, and preliminary test results of comparing changes of neural recruitments in students’ brain participated in fMRI with the TTCT.}
}
@article{SILVEIRA1980165,
title = {Generic masculine words and thinking},
journal = {Women's Studies International Quarterly},
volume = {3},
number = {2},
pages = {165-178},
year = {1980},
note = {The voices and words of women and men},
issn = {0148-0685},
doi = {https://doi.org/10.1016/S0148-0685(80)92113-2},
url = {https://www.sciencedirect.com/science/article/pii/S0148068580921132},
author = {Jeanette Silveira},
abstract = {Synopsis
It has been alleged that, in appropriate verbal contexts, man and he are generic, i.e. that the words include women as well as men, as for example in, Man is mortal, or One must watch his language. Many feminists argue for the elimination of this generic use of man and he and the substitution of such non-male words as people and they. Others argue on various grounds that these changes are unnecessary. This paper isolates the issues involved in such arguments and provisionally concludes that a reduction in the generic use of man and he would result in a long term reduction in sexist thinking. Recent feminist research on man and he is carefully reviewed. In its final section, the paper develops the implication that women experience more alienation than men in the presence of the generic man and he.}
}
@article{RIAUX2023130189,
title = {Riding the waves of discomforts: Reflecting on the dialogue of hydrologists with society},
journal = {Journal of Hydrology},
volume = {626},
pages = {130189},
year = {2023},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2023.130189},
url = {https://www.sciencedirect.com/science/article/pii/S0022169423011319},
author = {Jeanne Riaux and Marcel Kuper and Sylvain Massuel and Insaf Mekki},
keywords = {Socio-hydrology, Society, Hydrology, Interdisciplinarity, Reflexivity, Tunisia},
abstract = {Although there is a deep historical relationship between hydrology and society, the relationship has considerably evolved in the last three decades. Hydrologists, in particular those involved in designing of decision-support tools, are experiencing a widening gap between an academic discipline which has progressively moved away from field-based applied natural science to computational hydrology, and the multiplication of stakeholders involved in the water-related issues addressed by research. The challenge for hydrology is now to negotiate this shift and to rethink its engagement in society. This paper provides a description of a planned process designed to improve hydrology-society interactions and to foster reflexivity in socio-hydrology. Based on an interdisciplinary reflexive process undertaken in Tunisia from 2016 to 2020, we identified three types of discomforts in the dialogue with society, inviting scientists to lucidly engage with these discomforts. We formulated four key reflexive propositions to achieve a better alignment of scientific stance, research practices and discourse. The first proposition concerns the need to explain more clearly the value systems scientists engage in and with society. The second concerns the need to position hydrology in society and not outside it, by reconsidering the functions that research fulfils in society. The third is an invitation to redefine the perimeter of the research interlocutors and the way to reach them. The fourth is to revisit scientific practices to build on the strengths of the dialogue between field-based natural science and computational hydrology. The paper concludes that adopting a reflexive posture towards these four dimensions of the dialogue between hydrology and society is an effective way to overcome discomforts and to refocus research stance, practices and discourse. It is a way to renew hydrology's place in society and to contribute to the current thinking in socio-hydrology initiated by hydrologists.}
}
@incollection{MYUNG20012453,
title = {Computational Approaches to Model Evaluation},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2453-2457},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00589-1},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767005891},
author = {I.J. Myung},
abstract = {The induction problem of inferring a predictive function (i.e., model) from finite data is a central component of the scientific enterprise in cognitive science, computer science and statistics, and yet the problem is fundamentally ill posed. Many models can often provide equally good fits to a given observed data set but they may differ considerably in their ability to generalize to new, as yet unseen, data sets generated from the same underlying process. To make this inductive inference problem well posed one needs to define a justifiable measure of generalizability and then use the measure to choose among a set of competing models. Many such measures have been proposed in the past, notably by scientists in the fields of machine learning and algorithmic coding theory. A representative list of such approaches includes the structural risk minimization method and Vapnik-Chervonenkis dimension, the regularization theory, and the minimum description length principle. This article presents a review of these computational approaches to model evaluation. Also discussed are the interesting connections between the computational approaches and some of the statistical approaches to model evaluation such as the Akaike information criterion, the Bayesian information criterion and Bayesian model selection.}
}
@incollection{DEAN2014157,
title = {Chapter 7 - Decorrelation Learning in the Cerebellum: Computational Analysis and Experimental Questions},
editor = {Narender Ramnani},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {210},
pages = {157-192},
year = {2014},
booktitle = {Cerebellar Learning},
issn = {0079-6123},
doi = {https://doi.org/10.1016/B978-0-444-63356-9.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444633569000078},
author = {Paul Dean and John Porrill},
keywords = {Cerebellum, eye blink conditioning, vestibulo-ocular reflex, spike-timing dependent plasticity, avoidance learning, long-term depression, long-term potentiation, supervised learning, reafference, least mean squares},
abstract = {Many cerebellar models use a form of synaptic plasticity that implements decorrelation learning. Parallel fibers carrying signals positively correlated with climbing-fiber input have their synapses weakened (long-term depression), whereas those carrying signals negatively correlated with climbing input have their synapses strengthened (long-term potentiation). Learning therefore ceases when all parallel-fiber signals have been decorrelated from climbing-fiber input. This is a computationally powerful rule for supervised learning and can be cast in a spike-timing dependent plasticity form for comparison with experimental evidence. Decorrelation learning is particularly well suited to sensory prediction, for example, in the reafference problem where external sensory signals are interfered with by reafferent signals from the organism’s own movements, and the required circuit appears similar to the one found to mediate classical eye blink conditioning. However, for certain stimuli, avoidance is a much better option than simple prediction, and decorrelation learning can also be used to acquire appropriate avoidance movements. One example of a stimulus to be avoided is retinal slip that degrades visual processing, and decorrelation learning appears to play a role in the vestibulo-ocular reflex that stabilizes gaze in the face of unpredicted head movements. Decorrelation learning is thus suitable for both sensory prediction and motor control. It may also be well suited for generic spatial and temporal coordination, because of its ability to remove the unwanted side effects of movement. Finally, because it can be used with any kind of time-varying signal, the cerebellum could play a role in cognitive processing.}
}
@article{HEYLIGHEN2014113,
title = {Designing in the absence of sight: Design cognition re-articulated},
journal = {Design Studies},
volume = {35},
number = {2},
pages = {113-132},
year = {2014},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2013.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X13000926},
author = {Ann Heylighen and Greg Nijs},
keywords = {design cognition, design research, epistemology},
abstract = {Starting from the study of an architect who designs in the absence of sight, we question to what extent prevailing notions of design may be complemented with alternative articulations. In doing so, we point to the cognitivist understanding of human cognition underlying design researchers' strong attention to ‘visual thinking’, and contrast this with more situated understandings of human cognition. The ontological and epistemological differences between both raise questions about how design research is produced, and consequently what design can also be. By accounting for how a blind architect re-articulates prevailing notions of design, we invite researchers to keep the discussion open and call for an ontological and epistemological re-articulation in design research.}
}
@incollection{KRETZER202153,
title = {Chapter 4 - Digital crafting: a new frontier for material design},
editor = {Owain Pedgley and Valentina Rognoli and Elvin Karana},
booktitle = {Materials Experience 2},
publisher = {Butterworth-Heinemann},
pages = {53-66},
year = {2021},
isbn = {978-0-12-819244-3},
doi = {https://doi.org/10.1016/B978-0-12-819244-3.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012819244300003X},
author = {Manuel Kretzer},
keywords = {Digital, crafting, design, architecture, production, fabrication, parametric, generative, Industry 4.0},
abstract = {This chapter provides an overview of the potentials of employing computational design methods and digital fabrication tools for the creation of novel, material-based design. Just as in the early days of architecture, when the master builder was responsible for all areas of building, these new technologies allow a return to the exploration of experimental design methods and the direct exchange with different materials. Designing for and through digital production techniques thus shifts the focus from formal design representations toward the physically realized. As such, material and tectonic thinking are reintroduced as the very base of the design approach. Due to this a new type of design becomes possible with a formerly unknown degree of complexity—both on a formal and on a functional level. This chapter gives an overview of the history of design, speaks about the so-called “digital continuum,” highlights the benefits of customization and individual production, stresses the nuisance of new esthetic formalizations and the importance of education to mediate such understanding to students of design and architecture.}
}
@article{RIETMAN2003249,
title = {Analog computation with rings of quasiperiodic oscillators: the microdynamics of cognition in living machines},
journal = {Robotics and Autonomous Systems},
volume = {45},
number = {3},
pages = {249-263},
year = {2003},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2003.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0921889003001520},
author = {Edward A. Rietman and Mark W. Tilden and Manor Askenazi},
keywords = {Quasiperiodic oscillators, Microdynamics, Schmitt trigger},
abstract = {We describe experimental results to demonstrate the wide-ranging computational ability of quasiperiodic oscillators built from rings of differentiating Schmitt triggers. We describe a theoretical model based on necklace functions to compute the number of states supportable by a ring circuit of a given size. Experimental results are presented to demonstrate that probabilistic state machines can be built from these ring circuits. Other experimental results are given to demonstrate that the rings can model spiking neural network circuits.}
}
@article{GISIGER2000250,
title = {Computational models of association cortex},
journal = {Current Opinion in Neurobiology},
volume = {10},
number = {2},
pages = {250-259},
year = {2000},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(00)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/S0959438800000751},
author = {Thomas Gisiger and Stanislas Dehaene and Jean-Pierre Changeux},
abstract = {Recent computational models, or mathematical realizations of neurobiological theories, are providing insights into the organization and workings of the association cortex. Such models concern the construction of cortical maps, the neural basis of cognitive functions such as visual perception, reward-motivated learning and some aspects of consciousness.}
}
@incollection{BUCHANAN2024,
title = {Semantic Feature Production Norms},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00045-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041000454},
author = {Erin M. Buchanan},
keywords = {Datasets, Features, Knowledge, Memory, Norms, Production task, Semantics},
abstract = {Feature production norms are collected by asking participants to name the defining features of a concept, such as tail, fur, and meow for the concept cat. Collection and analysis of features should include special considerations for methodology and data processing including the task instructions, segmentation, word removal, spell checking and more. The processed data can be used to define concept similarity, control stimuli for new experimental studies, and in computational models of memory and knowledge representation.}
}
@article{PEZZULO2011275,
title = {Computational explorations of perceptual symbol systems theory},
journal = {New Ideas in Psychology},
volume = {29},
number = {3},
pages = {275-297},
year = {2011},
note = {Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2009.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X09000336},
author = {Giovanni Pezzulo and Gianguglielmo Calvi},
keywords = {Perceptual symbol systems, Schemas, Embodiment, Anticipation, Simulation},
abstract = {The aim of this paper is twofold. First, we provide a methodological pathway from theories of situated, embodied cognition to simulations with an eye to empirical evidence, and suggest a possible cross-fertilization between cognitive robotics and psychology. Psychological theories, in particular those formulated at an abstract level, include models which are often severely underspecified at the level of mechanisms. This is true in the synchronic, constructive perspective (how can the effects observed in experiments be concretely generated by the model's mechanisms?) and in the diachronic, developmental perspective (how can such mechanisms be learned and developed?). The synthetic method of artificial cognitive systems research, and in particular of cognitive robotics, can complement research in psychology (and neurosciences) by exploring the constructive and developmental aspects of theories. Our second aim is to provide an example of such a methodology by describing simulations aiming at developing a perceptual symbol system (PSS) (Barsalou, 1999). We then describe the two main theoretical constructs of the PSS, perceptual symbols and simulators, illustrate their development in an artificial system, and test the system in prediction, categorization, and abstraction tasks.}
}
@article{2004263,
title = {Computational Statistics and Data Analysis},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {73},
number = {2},
pages = {263},
year = {2004},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2004.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169743904001820}
}
@article{JIANG2023119343,
title = {Film cooling comparison of shaped holes among the pressure surface, the suction surface and the leading edge of turbine vane},
journal = {Applied Thermal Engineering},
volume = {219},
pages = {119343},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2022.119343},
url = {https://www.sciencedirect.com/science/article/pii/S135943112201273X},
author = {Yan Jiang and Haiwang Li and Runzhou Liu and Zhi Tao and Zhiyu Zhou},
keywords = {Film cooling, NHFR, Shaped holes, Turbine guide vane},
abstract = {The present study employed commercial computational fluid dynamics software ANSYS 2019R3 to explore the adiabatic film cooling effectiveness and the net heat flux reduction (NHFR) for the comparison of the five selected shaped holes and conventional cylindrical holes between the pressure surface, the suction surface and the leading edge. Amo4ng the shape parameters of shaped holes, the lateral divergence angle (β) and the forward divergence angle (δ) were fixed as 12° and 7° in all shaped holes structures, respectively. The others varied with different regions of the turbine vane. Results showed that different holes fit different positions of vanes. On the suction surface, laidback holes performed the worst net heat flux reduction in most blowing ratios conditions, which indicated the forward divergence angle was not conducive to the flow field and heat transfer characteristics on the suction surface. Whereas, the lateral divergence angle was beneficial to the film cooling and heat transfer characteristics. Laidback fan-shaped holes performed the best adiabatic film cooling effectiveness, but once simultaneously thinking about the heat transfer, fan-shaped holes performed better in net heat flux reduction due to less vortices at holes exit. On the leading edge, the divergence angle towards the upper wall (the lateral divergence angle of spanwise expansion holes) of vanes was not conducive to steady flow. And conical holes performed best, which indicated that coolant from holes with axial divergence angles (the lateral divergence angle in axial direction of conical holes) under the influence of mainstream impact could perform higher film cooling effectiveness and more stable flow fields. On the pressure surface, holes had a lateral divergence angle in the direction of vane height, which was conducive to increasing the coolant coverage area and improving the ability to attach to the pressure surface. Additionally, the laidback hole case was observed the lowest net heat flux reduction when the blowing ratio was less than 2, which revealed that holes that expanded only in flow direction was not conducive to film cooling and heat transfer characteristics.}
}