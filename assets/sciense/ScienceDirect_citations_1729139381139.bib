@article{CHEN2015247,
title = {Reinforcement learning in depression: A review of computational research},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {247-267},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001311},
author = {Chong Chen and Taiki Takahashi and Shin Nakagawa and Takeshi Inoue and Ichiro Kusumi},
keywords = {Anhedonia, Computational psychiatry, Depression, Dopamine, Incentive salience, Learning rate, ‘Liking’, Model-free, Model-based, Motivation, Prediction error, Reinforcement learning, Reward sensitivity, Stress, ‘Wanting’},
abstract = {Despite being considered primarily a mood disorder, major depressive disorder (MDD) is characterized by cognitive and decision making deficits. Recent research has employed computational models of reinforcement learning (RL) to address these deficits. The computational approach has the advantage in making explicit predictions about learning and behavior, specifying the process parameters of RL, differentiating between model-free and model-based RL, and the computational model-based functional magnetic resonance imaging and electroencephalography. With these merits there has been an emerging field of computational psychiatry and here we review specific studies that focused on MDD. Considerable evidence suggests that MDD is associated with impaired brain signals of reward prediction error and expected value (‘wanting’), decreased reward sensitivity (‘liking’) and/or learning (be it model-free or model-based), etc., although the causality remains unclear. These parameters may serve as valuable intermediate phenotypes of MDD, linking general clinical symptoms to underlying molecular dysfunctions. We believe future computational research at clinical, systems, and cellular/molecular/genetic levels will propel us toward a better understanding of the disease.}
}
@article{HUNG1997311,
title = {Meanings, contexts, and mathematical thinking: The meaning-context model},
journal = {The Journal of Mathematical Behavior},
volume = {16},
number = {4},
pages = {311-324},
year = {1997},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(97)90010-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312397900109},
author = {David Wei Loong Hung},
abstract = {The aim of this paper is to describe the meaning-context model which integrates three different levels of contextual factors that influence students' mathematical thinking and problem solving. These factors can be primarily classified according to: (1) the problem-task at hand; (2) the individual problem solver's personal epistemology of mathematics; and (3) the social and cultural influences through which the individual develops his or her mathematical disposition. We have referred to these three different contextual factors as the meaning-symbol context, meaning-interpretation context, and the meaning-intersubjectivity context respectively. The paper also discusses the implications of this model.}
}
@article{JIN2024e32590,
title = {Research hotspots and development trends of model and modelling education research: Bibliometric analysis based on CiteSpace},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e32590},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32590},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024086213},
author = {Dongxue Jin and Min Jian},
keywords = {Model-based education research, Model and modelling, Bibliometric analysis, CiteSpace},
abstract = {Model-based learning and teaching are vital for addressing real-world challenges and are gaining research traction. This study, employing CiteSpace, analyses 583 articles, uncovering trends in authors, regions, and highly cited documents. Noteworthy focuses include learning achievements, technical support, and teaching approaches. Keyword analysis emphasises thinking cultivation and interdisciplinary integration. The study discusses current and future developments in modelling and modelling education research, particularly in learning evaluation and teacher professional development. Offering an international perspective, this analysis provides stakeholders with valuable insights. In summary, model-based learning's growth and influence are evident in the identified trends and future directions, guiding the field toward effective teaching strategies and solving complex problems. This research contributes to the broader understanding of modelling education's dynamics, facilitating informed decision-making for educators and policymakers.}
}
@article{COSSENTINO2024101257,
title = {Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture},
journal = {Cognitive Systems Research},
volume = {87},
pages = {101257},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101257},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000512},
author = {Massimo Cossentino and Giovanni Pilato},
keywords = {System 1/System 2, Cognitive architectures, Goal-oriented plan, Trie},
abstract = {In the last years, the System 1/System 2 cognitive architecture, proposed by psychologist Daniel Kahneman, raised the interest of many researchers in the field. System 1 is an intuitive, automatic, and fast-thinking system working effortlessly, without conscious effort. System 2 is a deliberate, analytical, and slower-thinking system employing conscious effort and attention. This work proposes an innovative approach that exploits techniques typical of information retrieval (the trie data structure) to efficiently encode the solutions’ repository at the border between System 2 and System 1. This repository stores the solutions (successful plans) the agent has already used and can re-enact to achieve the goals. System 2 conceives new plans and delegates System 1 to execute them. If the plan is successful (and so it becomes a solution), System 1 stores that in the repository to quickly retrieve any solution that may help fulfil the goals deliberated by System 2 in the future.}
}
@article{CHANG2023100529,
title = {Management accounting system: Insights from the decision making theories},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100529},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100529},
url = {https://www.sciencedirect.com/science/article/pii/S2590291123001341},
author = {Kirk Chang and Alhashmi Aboubaker Lasyoud and Diaeldin Osman},
keywords = {Decision making, MAS, Management account system, Pre-factor, Thinking styles},
abstract = {Management accounting system (MAS) improves business growth through quality decision making process, but scholars have mixed views about MAS and constantly debate its efficacy. Drawing on the decision-making theories, the current research deviates from the debates and adopts a ‘think-outside-the-box’ approach, aiming to advance the knowledge of MAS's efficacy. Research data are gathered from the MAS literatures and cognate studies. Following the research findings, we identify a new pre-factor (thinking style) and incorporate it into the MAS. Specifically, decision makers' cognitive process is found to affect the design and implementation of MAS, as rational thinking style, administrative thinking style, and political thinking style may affect the MAS's efficacy differently. Research findings have brought valuable insights to the MAS literatures, by highlighting the strength and weakness of different thinking styles in designing management accounting system. Moreover, decision makers, such as organizational leaders and business managers, are encouraged to monitor their thinking styles: that is, with better understanding of thinking styles, decision makers can better utilize MAS and rectify the style-driven deficits in time.}
}
@article{DELANEY201839,
title = {Thinking outside the box: Innovative solutions for dairy goat management},
journal = {Small Ruminant Research},
volume = {163},
pages = {39-44},
year = {2018},
note = {Contributions of caprine agro-sylvopastoral production systems to society and environment},
issn = {0921-4488},
doi = {https://doi.org/10.1016/j.smallrumres.2017.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0921448817301074},
author = {Carol Delaney},
keywords = {Dairy goat breeding and selection, Extensive grazing, Longevity, Milk production, Efficiency, Environmental adaptation},
abstract = {For the geneticist or breeder, the individual animal is like a potential masterpiece resulting from years of attention to physical details and planned matings. The importance of culturing and nourishing this individual to not only reach its potential but to pass its selected genetics on to progeny is paramount. Thus, all the investment in genetic improvement is now at the mercy of management. Once the goats are in the herd on the farm and the responsibility of the farmer or farm manager, the expression and proliferation of the genotype will be strongly influenced by environmental factors. If maximum milk production per lactation were the real and only goal that could promise farm business and land sustainability, genetic selection would be easy. However, the real goal on farms is to have healthy goats that produce efficiently and are adapted to their environment. This places the development of the goat breeding program in the hands of farmers. To aid farmers in moving beyond the use of total milk production per goat as the feedback mechanism to farm sustainability, the integration of more appropriate progress indicators could include longevity (which, in humans, is estimated at 20% genetic and 80% environmental), the amount of milk or milk component production per body weight of goat, and the degree of involuntary culling.}
}
@article{RUIZ20221641,
title = {Computational simulation as a decision-making support tool for prefabricated pillars production},
journal = {Canadian Journal of Civil Engineering},
volume = {49},
number = {10},
pages = {1641-1654},
year = {2022},
issn = {0315-1468},
doi = {https://doi.org/10.1139/cjce-2021-0565},
url = {https://www.sciencedirect.com/science/article/pii/S0315146822000451},
author = {Phelipe Viana Ruiz and Carlos Eduardo Marmorato Gomes and Patricia Stella Pucharelli Fontanini},
keywords = {industrialized building system, simulation, decision support systems, production control, prefabricated concrete elements, système de construction industrialisé, simulation, systèmes d’aide à la décision, contrôle de la production, éléments préfabriqués en béton},
abstract = {Competitive industrialization pressures the construction sector to move activities away from the construction site, contemplating the prefabricated elements use. Companies willing to remain in the competitive market must seek new positions and developments in their production and management chains. To support the managers' decision-making about the prefabricated concrete elements production line, this article presents a computer simulation model for prefabricated pillars production line productivity scenarios creation. The data used for this model development were collected through a case study in the production line of prefabricated pillars. A simulation software modelled the production line with a dashboard that enables multiple-scenario generation. The adopted approach works with stochastic data, allowing nonprogrammer users to: manipulate and control scenarios and layout settings, analyze results through a dashboard and provide management and decision-makers with a comprehensive view of possible solutions.
L’industrialisation concurrentielle pousse le secteur de la construction à s’éloigner du chantier, en envisageant l’utilisation des éléments préfabriqués. Les entreprises désireuses de demeurer sur le marché concurrentiel doivent rechercher de nouvelles positions et de nouveaux développements dans leurs chaînes de production et de gestion. Pour aider les gestionnaires à prendre des décisions au sujet de la ligne de production d’éléments préfabriqués en béton, cet article présente un modèle de simulation informatique pour la création de scénarios de productivité de ligne de production de piliers préfabriqués. Les données utilisées pour l’élaboration de ce modèle ont été recueillies au moyen d’une étude de cas sur la chaîne de production de piliers préfabriqués. Un logiciel de simulation a modélisé la ligne de production avec un tableau de bord permettant l’élaboration de scénarios multiples. L’approche adoptée fonctionne avec des données stochastiques, permettant aux utilisateurs non-programmeurs : de manipuler et contrôler les scénarios et les paramètres de mise en page, d’analyser les résultats au moyen d’un tableau de bord et de fournir à la direction et aux décideurs une vue d’ensemble des solutions possibles. [Traduit par la Rédaction]}
}
@incollection{COMBA2021241,
title = {2.14 - Computational Coordination Chemistry},
editor = {Edwin C. Constable and Gerard Parkin and Lawrence {Que Jr}},
booktitle = {Comprehensive Coordination Chemistry III},
publisher = {Elsevier},
address = {Oxford},
pages = {241-255},
year = {2021},
isbn = {978-0-08-102689-2},
doi = {https://doi.org/10.1016/B978-0-08-102688-5.00023-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780081026885000234},
author = {Peter Comba},
keywords = {Ab-initio quantum mechanics, Catalytic cycle, Charge distribution, Complex stability, DFT, Electronic structure, Ligand field theory, Molecular magnetism, Molecular mechanics, Molecular structure, Quantum chemistry, Reaction mechanism, Redox potential, Spectroscopy, Transition state},
abstract = {The computational modeling of metal complexes has been developed to an extent where a large variety of spectroscopic properties, reactivities and stabilities of mono- and oligonuclear complexes can be efficiently and reliably computed. There is a large arsenal of computational methods for the modeling of coordination compounds, spanning a wide range of scales in terms of theoretical basis, accuracy of the data in comparison with experiment, and accessibility in terms of computer power. Relevant current approaches and their limits and possible pitfalls that are discussed include ab-initio and DFT-based quantum-chemical, molecular mechanical, ligand-field-based methods and various combinations thereof, as well as approaches related to machine-learning, artificial intelligence, molecular docking and empirical structure-property correlations.}
}
@incollection{ASPRION202257,
title = {Chapter 3 - Thinking multicriteria—A jackknife when it comes to optimization},
editor = {Michael Bortz and Norbert Asprion},
booktitle = {Simulation and Optimization in Process Engineering},
publisher = {Elsevier},
pages = {57-75},
year = {2022},
isbn = {978-0-323-85043-8},
doi = {https://doi.org/10.1016/B978-0-323-85043-8.00012-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385043800012X},
author = {Norbert Asprion and Michael Bortz},
keywords = {Multicriteria optimization, Decision support, Robust optimization, Pareto set, Adaptive scalarization, Optimal control, Sensitivity analysis},
abstract = {Multicriteria optimization (MCO) can offer insight into trade-offs between different alternatives in process design and flowsheet alternatives. This chapter highlights the practical benefit obtained by integrating MCO into an industrial flowsheet simulator. Parametric model uncertainties, model adjustment, and design of experiments are considered as well from an MCO point of view.}
}
@article{KALRO1998267,
title = {3D computation of unsteady flow past a sphere with a parallel finite element method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {151},
number = {1},
pages = {267-276},
year = {1998},
note = {Containing papers presented at the Symposium on Advances in Computational Mechanics},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(97)00120-5},
url = {https://www.sciencedirect.com/science/article/pii/S0045782597001205},
author = {V. Kalro and T. Tezduyar},
abstract = {We present parallel computation of 3D, unsteady, incompressible flow past a sphere. The Navier-Stokes equations of incompressible flows are solved using a stabilized finite element formulation. Equal-order interpolation functions are used for velocity and pressure. The second-order accurate time-marching within the solution process is carried out in an implicit fashion. The coupled, nonlinear equations generated at each time step are solved using an element-vector-based iteration technique. The computed value of the primary frequency associated with vortex shedding is in close agreement with experimental measurements. The computation was performed on the Thinking Machines CM-5.}
}
@article{BEATTIE2003909,
title = {Post-genomic technologies – thinking beyond the hype},
journal = {Drug Discovery Today},
volume = {8},
number = {20},
pages = {909-910},
year = {2003},
issn = {1359-6446},
doi = {https://doi.org/10.1016/S1359-6446(03)02862-9},
url = {https://www.sciencedirect.com/science/article/pii/S1359644603028629},
author = {John Beattie and Peter Ghazal},
keywords = {Post-genomic, Proteomics, Biochip, DNA chip, Bioinformatics, Microarrays}
}
@article{WANG2025112869,
title = {Development and validation of the long and short forms of the rest intolerance scale for college students},
journal = {Personality and Individual Differences},
volume = {233},
pages = {112869},
year = {2025},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2024.112869},
url = {https://www.sciencedirect.com/science/article/pii/S0191886924003295},
author = {Fei Wang and Haoran Song and Xiaoxuan Meng and Ting Wang and Qian Zhang and Ziying Yu and Siyuan Fan and Yibo Wu},
keywords = {Rest intolerance, Negative feelings, Obsessive thinking, Social comparison, Cognitive bias},
abstract = {With the development of Chinese society, “rest intolerance” has become a topic of great concern and discussion. The purpose of this study was to investigate the dimensions and psychological connotations of rest intolerance and to develop both short and long versions of the rest intolerance scale suitable for Chinese university students. We used three steps to development the scales. In Study 1, we first used interviews and the grounded theory to propose the psychological connotation of rest intolerance and its characteristic dimensions, i.e., negative feelings, obsessive thinking, social comparison, and cognitive bias. On this basis, the rest intolerance scale was compiled, and a four-dimensional scale containing 24 items was obtained through item analysis, exploratory factor analysis, and exploratory graph analysis. Study 2 validated the 4 characteristic dimensions of rest intolerance in a new sample through confirmatory factor analysis, content validity test, and criterion-related validity test, the results show that the 24-item rest intolerance scale (RIS-24) has good reliability and validity. Study 3 developed a short version of the 8-item Rest Intolerance Scale (RIS-8) using genetic algorithms. Overall, the present study provides two instruments for the measurement of rest intolerance that will facilitate the progress of future research.}
}
@article{MONTEJOLOPEZ20248615,
title = {Analysing the effect caused by increasing the molecular volume in M1-AChR receptor agonists and antagonists: a structural and computational study††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3ra07380g},
journal = {RSC Advances},
volume = {14},
number = {13},
pages = {8615-8640},
year = {2024},
issn = {2046-2069},
doi = {https://doi.org/10.1039/d3ra07380g},
url = {https://www.sciencedirect.com/science/article/pii/S2046206924007459},
author = {Wilber Montejo-López and Raúl Sampieri-Cabrera and María Inés Nicolás-Vázquez and Juan Manuel Aceves-Hernández and Rodrigo Said Razo-Hernández},
abstract = {M1 muscarinic acetylcholine receptor (M1-AChR), a member of the G protein-coupled receptors (GPCR) family, plays a crucial role in learning and memory, making it an important drug target for Alzheimer's disease (AD) and schizophrenia. M1-AChR activation and deactivation have shown modifying effects in AD and PD preclinical models, respectively. However, understanding the pharmacology associated with M1-AChR activation or deactivation is complex, because of the low selectivity among muscarinic subtypes, hampering their therapeutic applications. In this regard, we constructed two quantitative structure–activity relationship (QSAR) models, one for M1-AChR agonists (total and partial), and the other for the antagonists. The binding mode of 59 structurally different compounds, including agonists and antagonists with experimental binding affinity values (pKi), were analyzed employing computational molecular docking over different structures of M1-AChR. Furthermore, we considered the interaction energy (Einter), the number of rotatable bonds (NRB), and lipophilicity (ilogP) for the construction of the QSAR model for agonists (R2 = 89.64, QLMO2 = 78, and Qext2 = 79.1). For the QSAR model of antagonists (R2 = 88.44, QLMO2 = 82, and Qext2 = 78.1) we considered the Einter, the fraction of sp3 carbons fCsp3, and lipophilicity (MlogP). Our results suggest that the ligand volume is a determinant to establish its biological activity (agonist or antagonist), causing changes in binding energy, and determining the affinity for M1-AChR.}
}
@article{ZOCCA2019100,
title = {Decision-making computationally aided in the management of energy sources used in agrifood industries},
journal = {Energy Procedia},
volume = {161},
pages = {100-107},
year = {2019},
note = {Proceedings of the 2nd International Conference on Sustainable Energy and Resource Use in Food Chains including Workshop on Energy Recovery Conversion and Management;ICSEF 2018, 17 – 19 October 2018, Paphos, Cyprus},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.02.063},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219311427},
author = {Renan Zocca and Pedro D. Gaspar and Pedro D. Silva and Fernando C. Santos and Luís P. Andrade and José Nunes},
keywords = {Energy consumption, Energy management, Computational tool, decision making},
abstract = {In an increasingly competitive society with an unfavourable economic environment, it is necessary for Small and Medium Enterprises (SMEs) to update themselves, thereby increasing their efficiency. Companies increasingly use computational tools to support the development of predictive scenarios in order to facilitate decision-making. However, the tools developed for SMEs are not always expedite and simple to use. The tool presented in this article intends to support the management of energy sources used by agro-industrial companies. It aims to facilitate and promote the implementation of a new culture of business management, in this sector so important at national level. The computational part is directed to support the decision-making on the selection of fossil or renewable energy sources to be used in a particular agroindustry, by presenting the average values of the energy consumption, cost and emissions associated with each selected energy source.}
}
@article{WALSH2021143,
title = {Computational Cognitive Modeling of Human Calibration and Validity Response Scoring for the Graduate Record Examinations (GRE)},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {10},
number = {1},
pages = {143-154},
year = {2021},
note = {Culture & Memory},
issn = {2211-3681},
doi = {https://doi.org/10.1016/j.jarmac.2020.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S2211368120300747},
author = {Matthew M. Walsh and Burcu Arslan and Bridgid Finn},
keywords = {Constructed response scoring, Graduate record examinations, Predictive performance equation, Skill decay},
abstract = {Most research on skill acquisition and retention focuses on the individual being tested. Yet sometimes another person is responsible for evaluating the individual’s performance. Here, we study the acquisition and retention of rater skill using data for the Graduate Record Examinations (GRE). Our work is based on the idea that response scoring, like other cognitive skills, will gradually improve with amount of practice, and decline with elapsed time since that practice occurred. These classic findings are the focus of a computational cognitive model called the Predictive Performance Equation (PPE). However, the generalizability of these findings to response scoring and the applicability of PPE to that domain have not yet been demonstrated. To address this issue, we leveraged a naturalistic dataset containing rating performance from over 23,000 sessions. Our analyses provide empirical support for PPE and establish a basis for using a model like PPE to personalize rater training requirements.}
}
@incollection{HASS202094,
title = {Measurement: Computerized Creativity Testing and Scoring},
editor = {Steven Pritzker and Mark Runco},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {94-99},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23810-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245238108},
author = {Richard W. Hass},
keywords = {Creativity, Measurement, Assessment, Semantic memory, Computer algorithms, Divergent thinking, Remote association, Brainstorming, Domain-specificity, Creative problem solving},
abstract = {This entry discusses the use of computers in creativity measurement and assessment. Special emphasis is placed on the use of algorithms for scoring the responses generated during divergent thinking tasks. These algorithms are rooted in various theories of semantics, the details of which are also reviewed. In addition, advances in the use of computers for electronic brainstorming and for domain-specific creativity measurement beyond verbal divergent thinking are also reviewed. The objective is to provide readers with information on the various methods that are available, and a brief discussion of computational semantics.}
}
@article{VOYER2022101734,
title = {Symbols of class: A computational analysis of class distinction-making through etiquette, 1922-2017},
journal = {Poetics},
volume = {94},
pages = {101734},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101734},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001164},
author = {Andrea Voyer and Zachary D. Kline and Madison Danton},
keywords = {Social class, Status symbols, Word embeddings, Cultural sociology, Computational sociology},
abstract = {Social scientists of class and inequality have documented the rise of omnivorousness, informality, ordinariness, and emphasis on meritocracy. This apparent decline in class closure contrasts sharply with rising inequality and declining economic mobility. How are these competing developments reflected in everyday class distinction-making? In this article, we answer this question by applying Goffman's work on the symbols of class status to the analysis of unique data: a corpus of etiquette books published between 1922 and 2017. We use word embeddings to quantify the salience of six class concepts (affluence, cultivation, education, employment, morality, and status) in the corpus. We find that education and employment are increasingly salient while status, affluence, cultivation, and morality decline in their salience to class distinction-making. These results signal a decline of class operating as a status group through cultural closure, the rise of education and employment as the carriers of class in everyday life, and the corresponding legitimation of class position and class inequality based on supposedly meritocratic grounds. This research opens up new avenues for studies of class and the application of computational methods to investigations of social change.}
}
@article{NOORIGOODARZI2022105372,
title = {Subtractive genomic approach toward introduction of novel immunogenic targets against Clostridioides difficile: Thinking out of the box},
journal = {Microbial Pathogenesis},
volume = {162},
pages = {105372},
year = {2022},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2021.105372},
url = {https://www.sciencedirect.com/science/article/pii/S088240102100646X},
author = {Narjes {Noori Goodarzi} and Sepideh Fereshteh and Omid Azizi and Hamzeh Rahimi and Negin Bolourchi and Farzad Badmasti},
keywords = {, Reverse vaccinology, Immunogenic target},
abstract = {Clostridioides difficile is one of the major causatives of nosocomial infections worldwide. Antibiotic-associated diarrhea, pseudomembranous colitis, and toxic megacolon are the most common forms of C. difficile infection (CDI). Considering the high antibiotic resistance of C. difficile isolates and the low efficacy of immunization with toxin-related vaccines, we suggested that surface-exposed and secreted proteins could be considered as potential immunogenic targets against CDI. Various immuninformatics databases were used to predict antigenicity, allergenicity, B-cell epitopes, MHC-II binding sites, conserved domains, prevalence and conservation of proteins among the most common sequence types, molecular docking, and immunosimulation of immunogenic targets. Finally, 16 proteins belonging to three functional groups were identified, including proteins involved in the cell wall and peptidoglycan layer (nine proteins), flagellar assembly (five proteins), spore germination (one protein), and a protein with unknown function. Molecular docking results showed that among all the mentioned proteins, WP_009892971.1 (Acd) and WP_009890599.1 (a C40 family peptidase) had the strongest interactions with human Toll-like receptor 2 (TLR-2) and TLR-4. This study proposes a combination of C. difficile toxoid (Tcd) and surface-exposed proteins such as Acd as a promising vaccine formulation for protection against circulating clinical strains of C. difficile.}
}
@article{DERREUMAUX2023105304,
title = {Computational underpinnings of partisan information processing biases and associations with depth of cognitive reasoning},
journal = {Cognition},
volume = {230},
pages = {105304},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2022.105304},
url = {https://www.sciencedirect.com/science/article/pii/S001002772200292X},
author = {Yrian Derreumaux and Kimia Shamsian and Brent L. Hughes},
keywords = {Partisan bias, Motivated cognition, Sequential sampling, Drift diffusion modeling, Cognitive reflection},
abstract = {Despite unprecedented access to information, partisans increasingly disagree about basic facts that are backed by data, posing a serious threat to a democracy that relies on finding common ground based on objective truths. We examine the underpinnings of this phenomenon using drift diffusion modeling (DDM). Partisans (N = 148) completed a sequential sampling task where they evaluated the honesty of Democrat or Republican politicians during a debate based on fact-check scores. We found that partisans required less and weaker evidence to correctly categorize the ingroup as more honest, and were more accurate on trials when the ingroup candidate was more honest, compared to the outgroup. DDM revealed that such tendencies arise from both a prior preference for categorizing the ingroup as more honest (i.e., biased starting point) and more precise accumulation of information favoring the ingroup candidate compared to the outgroup (i.e., biased drift rate). Moreover, individual differences in cognitive reasoning moderated task performance for the most devoted partisans and maintained divergent associations with the DDM parameters. This suggests that partisans may reach biased conclusions via different pathways depending on their depth of cognitive reasoning. These findings provide key insights into the mechanisms driving partisan divides in polarized environments, and can inform interventions that reduce impasse and conflict.}
}
@article{BELIK2023113555,
title = {Link on, Link off: Data-driven management of organizational networks for ambidexterity},
journal = {Journal of Business Research},
volume = {157},
pages = {113555},
year = {2023},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.113555},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322010207},
author = {Ivan Belik and Eirik Sjåholm Knudsen},
keywords = {Organizational networks, Ambidexterity, Social networks, Knowledge flows, Network analysis, Data-driven},
abstract = {We examine how firms can intentionally design and manage their organizational networks to balance exploration and exploitation when a new exploration unit is established within an organization. We combine insights from the literature on social networks and structural ambidexterity and make two main arguments. First, a firm needs to ensure that the exploration unit is sufficiently connected to other parts of the organization where key complementary assets reside while minimizing the number of linkages to reduce the influence of the “old” way of thinking on new exploration efforts, to reduce coordination costs, and to increase adaptive ability. Second, the “ideal” level of connectedness for structural ambidexterity ultimately depends on the number of valuable complementary assets in a firm’s possession. We also show how managers can combine analytical methods from the computational literature on network analysis with managerial adjustments to do so in practice.}
}
@article{MORTOLA201628,
title = {Thinking about breathing: Effects on respiratory sinus arrhythmia},
journal = {Respiratory Physiology & Neurobiology},
volume = {223},
pages = {28-36},
year = {2016},
issn = {1569-9048},
doi = {https://doi.org/10.1016/j.resp.2015.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569904815300963},
author = {Jacopo P. Mortola and Domnica Marghescu and Rosemarie Siegrist-Johnstone},
keywords = {Neural control of breathing, Parasympathetic control, Vagal tone},
abstract = {Respiratory sinus arrhythmia (RSA), the increase and decrease in instantaneous heart rate (HR) with inspiration and expiration, is commonly evaluated as function of breathing frequency f. However, to the extent that RSA plays a role in the efficiency of gas exchange, it may be expected to correlate better with HR/f (‘breathing specific heart rate’) than with f, because the former is a better reflection of the cardio-respiratory coupling. We measured RSA breath-by-breath in 209 young men and women during spontaneous breathing and during volitional breathing under auditory cues at vastly different f. In either case, and for both genders, RSA correlated better with HR/f than with f. As HR/f increased so did RSA, in a linear manner. When compared on the basis of HR/f, RSA did not differ significantly between spontaneous and volitional breathing. It is proposed that RSA is a central mechanism that ameliorates the matching between the quasi-continuous pulmonary blood flow and the intermittent airflow, irrespective of the type of ventilatory drive (cortical or autonomic).}
}
@article{RYU2021107857,
title = {An efficient computational algorithm for Hausdorff distance based on points-ruling-out and systematic random sampling},
journal = {Pattern Recognition},
volume = {114},
pages = {107857},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.107857},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321000443},
author = {Jegoon Ryu and Sei-ichiro Kamata},
keywords = {Hausdorff distance, Computational complexity, Point matching, 3-D point sets},
abstract = {This paper proposes a novel algorithm for fast and accurate Hausdorff distance (HD) computation. The Hausdorff distance is used to measure the similarity between two point sets in various applications. However, it is hard to compute the HD algorithm efficiently between very large-scale point sets while ensuring the accuracy of the HD. The directed HD algorithm has two loops (called the outer loop and the inner loop) for calculating MAX-MIN distance, and the state-of-the-art algorithms, such as the Early break method and the Diffusion search method, focused on reducing the iterations of the inner loop. Our algorithm, however, concentrates on reducing the iterations of the outer loop. The proposed method simultaneously computes the temporary HD and temporary minimum distances of points corresponding to the outer loop using the opposite HD computation with very small systematic samples. Thereafter, a strategy of ruling out is employed to exclude non-contributing points. The new approach reduces the problems of different grid sizes and highly overlapping point sets as well as the very large-scale point sets. 3-D point clouds and real brain tumor segmentation (MRI 3-D volumes) are used for comparing the performance of the proposed algorithm and the state-of-the-art HD algorithms. In experimental results with 3-D point clouds, the proposed method is more than at least 1.5 times as faster as the compared algorithms. And, in experimental results with MRI 3-D volumes, the proposed method achieves a better performance than the compared algorithms over all pairs regardless of the grid size. Thus, as a whole, the proposed algorithm outperforms the compared algorithms.}
}
@article{YANG2024112150,
title = {Demand response strategy of user-side energy storage system and its application to reliability improvement},
journal = {Journal of Energy Storage},
volume = {92},
pages = {112150},
year = {2024},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2024.112150},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X24017365},
author = {Hejun Yang and Qiang Chen and Yue Liu and Yinghao Ma and Dabo Zhang},
keywords = {Power system reliability, Electricity pricing strategy, User-side energy storage system, Demand management},
abstract = {The time of use (TOU) strategy is being carried out in the power system for shifting load from peak to off-peak periods. For economizing the electricity bill of industry users, the trend on configuring user-side energy storage system (UES) by users will increase continuously. On the base of currently implemented TOU environment, designing an efficient and non-utility-dispatched guidance strategy for UES to realize the peak-shaving and valley-filling will have a great significance. Therefore, this paper firstly proposes a thinking based on a linear piecewise-shape pricing strategy for guiding UES to decrease the peak-valley difference although storage has not been dispatched by utility and always operates in its maximum benefit. In addition, benefit of user with UES has been guaranteed to be non-decreased compared to traditional TOU. Then, this paper establishes a planning-operation co-optimization model for UES to pursue its maximum net benefit, in which the proposed electricity pricing strategy has been incorporated. Thirdly, a linearized reliability improvement calculation method contributed by storage has been presented. Finally, the numerical results have verified the effectiveness of the proposed strategy, and in the designed case condition, there is an obvious improvement in the percentage of peak-valley difference and the reliability level.}
}
@article{TREUR2013449,
title = {Conceptual and Computational Analysis of the Role of Emotions and Social Influence in Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {93},
pages = {449-467},
year = {2013},
note = {3rd World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.09.220},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813033235},
author = {Jan Treur and Arlette {van Wissen}},
keywords = {emotion, learning, social influence, reflection.},
abstract = {In this paper, it is analyzed how emotions and social environment affect people's active and reflective learning processes. First, a conceptual analysis is made using recent insights from Cognitive, Affective and Social Neuroscience on the roles of emotions and social interactions on learning. Next, a computational analysis is made using a computational model of learning processes following these insights. In this analysis, neural mechanisms for the impact of both a person's own emotions and the emotions of others are taken into account. In particular, it is considered how these impacts influence different learning types, such as active or reflective learners. The analysis shows how the impacts of emotions and social interaction strengthen the learning process. It is discussed how from these insights indicators can be obtained that can be used to design technology-enhanced learning environments able to exploit these impacts.}
}
@article{KLIMOVA20231,
title = {Strategic Trends in Artificial Intelligence Through Impact of Computational Science: What Young Scientists Should Expect},
journal = {Procedia Computer Science},
volume = {229},
pages = {1-7},
year = {2023},
note = {12th International Young Scientists Conference in Computational Science, YSC2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019919},
author = {Alexandra Klimova and Denis Nasonov and Alexander Hvatov and Nikolay O. Nikitin and Sergey V. Ivanov and Anna V. Kalyuzhnaya and Alexander Boukhanovsky},
keywords = {Artificial Intelligence, Computational Science, Trends, Impact, Young Scientists},
abstract = {This volume presents selected papers of the 12th Young Scientists Conference in Computational Science (YSC'2023). ITMO University annually organises the event with various academic partners to disseminate current trends in Artificial Intelligence and Computational science among young researchers. In this paper, we present our view on major trends and challenges today in front of scientific and industrial society in this promising area.}
}
@article{JOHNSONLAIRD1994189,
title = {Mental models and probabilistic thinking},
journal = {Cognition},
volume = {50},
number = {1},
pages = {189-209},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90028-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900280},
author = {Philip N. Johnson-Laird},
abstract = {This paper outlines the theory of reasoning based on mental models, and then shows how this theory might be extended to deal with probabilistic thinking. The same explanatory framework accommodates deduction and induction: there are both deductive and inductive inferences that yield probabilistic conclusions. The framework yields a theoretical conception of strength of inference, that is, a theory of what the strength of an inference is objectively: it equals the proportion of possible states of affairs consistent with the premises in which the conclusion is true, that is, the probability that the conclusion is true given that the premises are true. Since there are infinitely many possible states of affairs consistent with any set of premises, the paper then characterizes how individuals estimate the strength of an argument. They construct mental models, which each correspond to an infinite set of possibilities (or, in some cases, a finite set of infinite sets of possibilities). The construction of models is guided by knowledge and beliefs, including lay conceptions of such matters as the “law of large numbers”. The paper illustrates how this theory can account for phenomena of probabilistic reasoning.}
}
@article{MURILLO2020119,
title = {Confronting the Challenges of Computational and Social Perspectives of the Data Continuum},
journal = {Data and Information Management},
volume = {4},
number = {2},
pages = {119-126},
year = {2020},
issn = {2543-9251},
doi = {https://doi.org/10.2478/dim-2020-0008},
url = {https://www.sciencedirect.com/science/article/pii/S2543925122000559},
author = {Angela P. Murillo and Renata G. Curty and Wei Jeng and Daqing He},
keywords = {data acumen, data stewardship, agricultural data, biomedical data, archaeological data},
abstract = {As the availability of data is increasing everyday, the need to reflect on how to make these data meaningful and impactful becomes vital. Current data paradigms have provided data life cycles that often focus on data acumen and data stewardship approaches. In an effort to examine the convergence, tensions, and harmonies of these two approaches, a group of researchers participated in an interactive panel session at the Association of Information Science and Technology Annual meeting in 2019. The panel presenters described their various research activities in which they confront the challenges of the computational and social perspectives of the data continuum. This paper provides a summary of this interactive panel.}
}
@article{FONTES2024101470,
title = {“Viewing puzzles as two-faced: theoretical and practical implications for Puzzle-based Learning”},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101470},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101470},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000099},
author = {Mario Madureira Fontes and Leonel Caseiro Morgado and Pedro Pestana and Daniela Pedrosa and José Paulo Cravino},
keywords = {Puzzle-based Learning, Puzzle Triggers, Creativity skills, Critical thinking, Puzzle-Solving},
abstract = {The Puzzle-based Learning approach has been applied to several fields of knowledge. In education research papers, the instructional usage of puzzles is considered to improve learners' motivation and engagement and help them to develop critical skills but difficulties concerning learners' interaction with puzzles have also been pointed out. Our paper investigates the dynamics of the concept of a puzzle and its interface to provide a better understanding of its form and functions, and help learners interact with puzzles. We consider Puzzle-based Learning tenets as well as their educational impacts on both critical thinking and learner engagement and provide an original proposal concerning the understanding of puzzles. Our proposal centered on the dynamics of puzzles bears conceptual and educational facets. Conceptually, puzzle dynamics is viewed as composed of two elements: a mechanism, the Puzzle Trigger, and a process, the Puzzle-Solving. From an educational point of view, the rationale for integrating Puzzle Triggers in Puzzle-based Learning is meant to help learners interact with puzzles and consequently become motivated and engaged in the Puzzle-Solving process. This way, learners' critical thinking skills are reinforced and focused on finding solutions to challenges. We illustrate the implementation of Puzzle Triggers and Puzzle-Solving by considering two instructional activities in a Software Development undergraduate course of an online learning Informatics Engineering Program.}
}
@article{LI2022175260,
title = {Deep learning and machine intelligence: New computational modeling techniques for discovery of the combination rules and pharmacodynamic characteristics of Traditional Chinese Medicine},
journal = {European Journal of Pharmacology},
volume = {933},
pages = {175260},
year = {2022},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2022.175260},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922005210},
author = {Dongna Li and Jing Hu and Lin Zhang and Lili Li and Qingsheng Yin and Jiangwei Shi and Hong Guo and Yanjun Zhang and Pengwei Zhuang},
keywords = {AI technology, Drug discovery, Virtual screening, Traditional Chinese medicine},
abstract = {It has been increasingly accepted that Multi-Ingredient-Based interventions provide advantages over single-target therapy for complex diseases. With the growing development of Traditional Chinese Medicine (TCM) and continually being refined of a holistic view, “multi-target” and “multi-pathway” integration characteristics of which are being accepted. However, its effector substances, efficacy targets, especially the combination rules and mechanisms remain unclear, and more powerful strategies to interpret the synergy are urgently needed. Artificial intelligence (AI) and computer vision lead to a rapidly expanding in many fields, including diagnosis and treatment of TCM. AI technology significantly improves the reliability and accuracy of diagnostics, target screening, and new drug research. While all AI techniques are capable of matching models to biological big data, the specific methods are complex and varied. Retrieves literature by the keywords such as “artificial intelligence”, “machine learning”, “deep learning”, “traditional Chinese medicine” and “Chinese medicine”. Search the application of computer algorithms of TCM between 2000 and 2021 in PubMed, Web of Science, China National Knowledge Infrastructure (CNKI), Elsevier and Springer. This review concentrates on the application of computational in herb quality evaluation, drug target discovery, optimized compatibility and medical diagnoses of TCM. We describe the characteristics of biological data for which different AI techniques are applicable, and discuss some of the best data mining methods and the problems faced by deep learning and machine learning methods applied to Chinese medicine.}
}
@article{GIRARD202297,
title = {Computational analysis of spoken language in acute psychosis and mania},
journal = {Schizophrenia Research},
volume = {245},
pages = {97-115},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421002528},
author = {Jeffrey M. Girard and Alexandria K. Vail and Einat Liebenthal and Katrina Brown and Can Misel Kilciksiz and Luciana Pennant and Elizabeth Liebson and Dost Öngür and Louis-Philippe Morency and Justin T. Baker},
keywords = {Language, Schizophrenia, Bipolar disorder, Positive symptoms, Negative symptoms},
abstract = {Objectives
This study aimed to (1) determine the feasibility of collecting behavioral data from participants hospitalized with acute psychosis and (2) begin to evaluate the clinical information that can be computationally derived from such data.
Methods
Behavioral data was collected across 99 sessions from 38 participants recruited from an inpatient psychiatric unit. Each session started with a semi-structured interview modeled on a typical “clinical rounds” encounter and included administration of the Positive and Negative Syndrome Scale (PANSS).
Analysis
We quantified aspects of participants' verbal behavior during the interview using lexical, coherence, and disfluency features. We then used two complementary approaches to explore our second objective. The first approach used predictive models to estimate participants' PANSS scores from their language features. Our second approach used inferential models to quantify the relationships between individual language features and symptom measures.
Results
Our predictive models showed promise but lacked sufficient data to achieve clinically useful accuracy. Our inferential models identified statistically significant relationships between numerous language features and symptom domains.
Conclusion
Our interview recording procedures were well-tolerated and produced adequate data for transcription and analysis. The results of our inferential modeling suggest that automatic measurements of expressive language contain signals highly relevant to the assessment of psychosis. These findings establish the potential of measuring language during a clinical interview in a naturalistic setting and generate specific hypotheses that can be tested in future studies. This, in turn, will lead to more accurate modeling and better understanding of the relationships between expressive language and psychosis.}
}
@article{CUI20226,
title = {Green biomanufacturing promoted by automatic retrobiosynthesis planning and computational enzyme design},
journal = {Chinese Journal of Chemical Engineering},
volume = {41},
pages = {6-21},
year = {2022},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2021.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S1004954121004286},
author = {Ziheng Cui and Shiding Zhang and Shengyu Zhang and Biqiang Chen and Yushan Zhu and Tianwei Tan},
keywords = {Biomanufacturing, Retrobiosynthesis, Computational enzyme design, Biobased chemicals},
abstract = {Biomanufacturing, which uses renewable resources as raw materials and uses biological processes to produce energy and chemicals, has long been regarded as a production model that replaces the unsustainable fossil economy. The construction of non-natural and efficient biosynthesis routes of chemicals is an important goal of green biomanufacturing. Traditional methods that rely on experience are difficult to support the realization of this goal. However, with the rapid development of information technology, the intelligence of biomanufacturing has brought hope to achieve this goal. Retrobiosynthesis and computational enzyme design, as two of the main technologies in intelligent biomanufacturing, have developed rapidly in recent years and have made great achievements and some representative works have demonstrated the great value that the integration of the two fields may bring. To achieve the final integration of the two fields, it is necessary to examine the information, methods and tools from a bird's-eye view, and to find a feasible idea and solution for establishing a connection point. For this purpose, this article briefly reviewed the main ideas, methods and tools of the two fields, and put forward views on how to achieve the integration of the two fields.}
}
@article{POULOVA20151996,
title = {Education in Computational Sciences},
journal = {Procedia Computer Science},
volume = {51},
pages = {1996-2005},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.464},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012727},
author = {Petra Poulova and Blanka Klimova},
keywords = {Computational education, Key competences, Study programmes},
abstract = {The last two decades have witnessed an enormously rapid development of computational technologies which have undoubtedly affected all the fields of human activities, including education. In fact, computational science is one of the most evolving profile study programmes at technical universities nowadays. This article thus focuses on the description of the key content courses, curricula and degrees offered within the study programmes at the Faculty of Informatics and Management of the University of Hradec Kralove, Czech Republic. Moreover, this study characterizes teaching and learning of university undergraduate computational professionals with a special focus on core competences such as an ability to identify and solve problems, knowledge of analytical methods, or operating systems, but also on active and passive knowledge of English since English as lingua franca can help these professionals together with other core competences succeed in the job market after their graduation.}
}
@article{POON2006177,
title = {Lay personality knowledge and dispositionist thinking: A knowledge-activation framework},
journal = {Journal of Experimental Social Psychology},
volume = {42},
number = {2},
pages = {177-191},
year = {2006},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2005.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S002210310500051X},
author = {Connie S.K. Poon and Derek J. Koehler},
keywords = {Lay theories, Dispositional inferences, Knowledge activation},
abstract = {We explicate a knowledge-activation framework depicting the link between lay personality knowledge and dispositional judgments, building on work by Dweck et al., 1995a, Dweck et al., 1995b. According to this framework, most people possess knowledge consistent with an entity theory (personality is fixed) and incremental theory (personality is malleable), which operates according to knowledge-activation principles. Consistent with this claim, we find that people render more confident dispositional judgments when their entity knowledge is made relatively more accessible through priming manipulations that activate aspects of their existing knowledge. Findings also illustrate the usefulness of incorporating both specific and general knowledge in our analysis. The present framework enhances and complements the individual-differences approach to the study of person theories prevalent in the literature.}
}
@article{YILDIRIM201973,
title = {An integrative computational architecture for object-driven cortex},
journal = {Current Opinion in Neurobiology},
volume = {55},
pages = {73-81},
year = {2019},
note = {Machine Learning, Big Data, and Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438818301995},
author = {Ilker Yildirim and Jiajun Wu and Nancy Kanwisher and Joshua Tenenbaum},
abstract = {Computational architecture for object-driven cortex Objects in motion activate multiple cortical regions in every lobe of the human brain. Do these regions represent a collection of independent systems, or is there an overarching functional architecture spanning all of object-driven cortex? Inspired by recent work in artificial intelligence (AI), machine learning, and cognitive science, we consider the hypothesis that these regions can be understood as a coherent network implementing an integrative computational system that unifies the functions needed to perceive, predict, reason about, and plan with physical objects—as in the paradigmatic case of using or making tools. Our proposal draws on a modeling framework that combines multiple AI methods, including causal generative models, hybrid symbolic-continuous planning algorithms, and neural recognition networks, with object-centric, physics-based representations. We review evidence relating specific components of our proposal to the specific regions that comprise object-driven cortex, and lay out future research directions with the goal of building a complete functional and mechanistic account of this system.}
}
@article{SHEARER1996465,
title = {Computational optimization of finite difference methods on the CM5},
journal = {Parallel Computing},
volume = {22},
number = {3},
pages = {465-481},
year = {1996},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(95)00009-7},
url = {https://www.sciencedirect.com/science/article/pii/0167819195000097},
author = {M.M. Shearer},
keywords = {Finite-difference method, Partial differential equation, CM5, Distributed memory multiprocessor, Optimization, Data partitioning, Performance},
abstract = {Techniques used to optimize a finite-difference program on a Thinking Machines' CM5 parallel processing system are presented. These techniques are discussed within several categories: vector unit optimization, separation of communications and computations, and optimal data partitioning. A simplified model is employed to illustrate these concepts. The results of applying these techniques to a more complicated finite-difference calculation are also reported.}
}
@article{SHENHAV2022,
title = {Using Community Ecology Theory and Computational Microbiome Methods To Study Human Milk as a Biological System},
journal = {mSystems},
volume = {7},
number = {1},
year = {2022},
issn = {2379-5077},
doi = {https://doi.org/10.1128/msystems.01132-21},
url = {https://www.sciencedirect.com/science/article/pii/S2379507722000873},
author = {Liat Shenhav and Meghan B. Azad and Jack A. Gilbert},
keywords = {computational methods, human microbiome, human milk, chronobiology, community ecology theory, system biology, lactation, breastfeeding},
abstract = {Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation.” We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology).
ABSTRACT
Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation” (P. Christian et al., Am J Clin Nutr 113:1063–1072, 2021, https://doi.org/10.1093/ajcn/nqab075). We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology). This undermines our ability to develop comprehensive representations of the interactions between these elements and study their response to external perturbations. (ii) Multiomics studies are often cross-sectional, presenting a snapshot of milk composition, largely ignoring the temporal variability during lactation. The lack of temporal resolution precludes the characterization and inference of robust interactions between the dynamic subsystems of the triad. (iii) We lack computational methods to represent and decipher the complex ecosystem of the mother-milk-infant triad and its environment. In this review, we advocate for longitudinal multiomics data collection and demonstrate how incorporating knowledge gleaned from microbial community ecology and computational methods developed for microbiome research can serve as an anchor to advance the study of human milk and its many components as a “system within a system.”}
}
@article{CAKIROGLU2021100888,
title = {Understanding students’ abstractions in block-based programming environments: A performance based evaluation},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100888},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100888},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001036},
author = {Ünal Çakıroğlu and İsak Çevik and Engin Köşeli and Merve Aydın},
keywords = {Abstraction, Block-based programming, Computational thinking, Computer science education},
abstract = {Providing computational problems for enhancing students’ abstraction skills and monitoring how students make abstractions is difficult in block-based programming environments (BBPEs). Thus, concrete examples and principles are needed to guide computer science teachers about understanding and enhancing students’ abstractions. This study aims to examine the effect of using block-based coding environments on enhancing secondary school students’ abstraction skills. Referring to the programming knowledge, a rubric was created to analyze the data from screen recordings, observation and interviews were used together to reveal the students’ abstraction performances. The results suggested that students performed high in elimination, focusing and generalization; however, students’ performances were relatively low in customization. Students’ explanations were mostly related the nature of the problems, affordances of BBPE and the programming constructs used in coding. We hope the study will provide insights for the efforts on instructional designs for successful abstraction experiences for young students.}
}
@article{IGLESIAS2011744,
title = {Re-thinking water policy priorities in the Mediterranean region in view of climate change},
journal = {Environmental Science & Policy},
volume = {14},
number = {7},
pages = {744-757},
year = {2011},
note = {Adapting to Climate Change: Reducing Water-related Risks in Europe},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1462901111000207},
author = {Ana Iglesias and Luis Garrote and Agustin Diz and Jeremy Schlickenrieder and Francisco Martin-Carrasco},
keywords = {Mediterranean, Climate change, Water policy, Adaptation and assessment},
abstract = {Water is scarce in Mediterranean countries: cities are crowded with increasing demand; food is produced with large amounts of water; ecosystems demand more water that is often available; drought affects all. As climate change impacts become more noticeable and costlier, some current water management strategies will not be useful. According to the findings of CIRCE, the areas with limited water resources will increase in the coming decades with major consequences for the way we produce food and we protect ecosystems. Based on these projections this paper discusses water policy priorities for climate change adaptation in the Mediterranean. We first summarise the main challenges to water resources in Mediterranean countries and outline the risks and opportunities for water under climate change based on previous studies. Recognising the difficulty to go from precipitation to water policy, we then present a framework to evaluate water availability in response to natural and management conditions, with an example of application in the Ebro basin that exemplifies other Mediterranean areas. Then we evaluate adaptive capacity to understand the ability of Mediterranean countries to face, respond and recover from climate change impacts on water resources. Social and economic factors are key drivers of inequality in the adaptive capacity across the region. Based on the assessment of impacts and adaptive capacity we suggest thresholds for water policy to respond to climate change and link water scarcity indicators to relevant potential adaptation strategies. Our results suggest the need to further prioritise socially and economically sensitive policies.}
}
@incollection{ZHENG202483,
title = {Chapter Five - Middle vision: Computational Knowledge Vision for visual translation},
editor = {Wenbo Zheng and Fei-Yue Wang},
booktitle = {Computational Knowledge Vision},
publisher = {Academic Press},
pages = {83-113},
year = {2024},
isbn = {978-0-443-21619-0},
doi = {https://doi.org/10.1016/B978-0-44-321619-0.00012-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216190000121},
author = {Wenbo Zheng and Fei-Yue Wang},
keywords = {Computational Knowledge Vision, Visual computing, Just noticeable difference, Domain adaptation, Generative adversarial network},
abstract = {Based on the principles and paradigms of computational knowledge-based vision discussed in this chapter, we practice at the representational and algorithmic levels for the take of image-to-image translation. The image-to-image translation aims to learn the mapping between two visual domains. At the beginning of designing the existing image-to-image translation method, it was not considered whether the generated image is realistic or not. In this work, we present a novel approach to address the problem of generating fidelity in the area of image-to-image translation. In particular, humans judge whether an image is realistic or not with unique human vision's feeling rather than paying attention to the real-world semantics. Inspired by this, we propose an effective network loss to capture the pixel-level representations and human vision system information for verisimilar image-to-image translation. To enforce both structural and translation-model consistency during adaptation, we propose a novel Just-Noticeable-Difference loss based on a visual recognition task. The Just-Noticeable-Difference loss not only guides the overall representation to be discriminative but also enforces our cycle loss before and after mapping between domains. Experimental results show that our approach is able to generate realistic images using unpaired training data, on a wide range of tasks. Besides, we measure realism with Fréchet Inception Distance and diversity with the number of statistically-different bins, Jensen–Shannon divergence, and a perceptual distance metric. We also apply our approach to domain adaptation and show competitive performance when compared to others on several datasets.}
}
@article{MELHAM2013129,
title = {Modelling, abstraction, and computation in systems biology: A view from computer science},
journal = {Progress in Biophysics and Molecular Biology},
volume = {111},
number = {2},
pages = {129-136},
year = {2013},
note = {Conceptual Foundations of Systems Biology},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2012.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0079610712000892},
author = {Tom Melham},
keywords = {Algorithmic biological modelling, Abstraction, Multi-scale modelling, Biological computation},
abstract = {Systems biology is centrally engaged with computational modelling across multiple scales and at many levels of abstraction. Formal modelling, precise and formalised abstraction relationships, and computation also lie at the heart of computer science—and over the past decade a growing number of computer scientists have been bringing their discipline's core intellectual and computational tools to bear on biology in fascinating new ways. This paper explores some of the apparent points of contact between the two fields, in the context of a multi-disciplinary discussion on conceptual foundations of systems biology.}
}
@article{ELLIS2022581,
title = {Comparison of apnoeic oxygen techniques in term pregnant subjects: a computational modelling study},
journal = {British Journal of Anaesthesia},
volume = {129},
number = {4},
pages = {581-587},
year = {2022},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2022.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0007091222003221},
author = {Reena Ellis and Marianna Laviola and Daniel Stolady and Rebecca L. Valentine and Arani Pillai and Jonathan G. Hardman},
keywords = {apnoea, computer simulation, high-flow nasal oxygenation, low-flow nasal oxygenation, obesity in pregnancy, obstetrics},
abstract = {Background
Hypoxaemia during general anaesthesia can cause harm. Apnoeic oxygenation extends safe apnoea time, reducing risk during airway management. We hypothesised that low-flow nasal oxygenation (LFNO) would extend safe apnoea time similarly to high-flow nasal oxygenation (HFNO), whilst allowing face-mask preoxygenation and rescue.
Methods
A high-fidelity, computational, physiological model was used to examine the progression of hypoxaemia during apnoea in virtual models of pregnant women in and out of labour, with BMI of 24–50 kg m−2. Subjects were preoxygenated with oxygen 100% to reach end-tidal oxygen fraction (FE'O2) of 60%, 70%, 80%, or 90%. When apnoea started, HFNO or LFNO was commenced. To simulate varying degrees of effectiveness of LFNO, periglottic oxygen fraction (FgO2) of 21%, 60%, or 100% was configured. HFNO provided FgO2 100% and oscillating positive pharyngeal pressure.
Results
Application of LFNO (FgO2 100%) after optimal preoxygenation (FE'O2 90%) resulted in similar or longer safe apnoea times than HFNO FE'O2 80% in all subjects in labour. For BMI of 24, the time to reach SaO2 90% with LFNO was 25.4 min (FE'O2 90%/FgO2 100%) vs 25.4 min with HFNO (FE'O2 80%). For BMI of 50, the time was 9.9 min with LFNO (FE'O2 90%/FgO2 100%) vs 4.3 min with HFNO (FE'O2 80%). A similar finding was seen in subjects with BMI ≥40 kg m−2 not in labour.
Conclusions
There is likely to be clinical benefit to using LFNO, given that LFNO and HFNO extend safe apnoea time similarly, particularly when BMI ≥40 kg m−2. Additional benefits to LFNO include the facilitation of rescue face-mask ventilation and ability to monitor FE'O2 during preoxygenation.}
}
@article{HOLROYD2021316,
title = {The Best Laid Plans: Computational Principles of Anterior Cingulate Cortex},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {4},
pages = {316-329},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000103},
author = {Clay B. Holroyd and Tom Verguts},
keywords = {anterior cingulate cortex, computational models, artificial intelligence, hierarchical model-based hierarchical reinforcement learning, distributed representations, cognitive control},
abstract = {Despite continual debate for the past 30 years about the function of anterior cingulate cortex (ACC), its key contribution to neurocognition remains unknown. However, recent computational modeling work has provided insight into this question. Here we review computational models that illustrate three core principles of ACC function, related to hierarchy, world models, and cost. We also discuss four constraints on the neural implementation of these principles, related to modularity, binding, encoding, and learning and regulation. These observations suggest a role for ACC in hierarchical model-based hierarchical reinforcement learning (HMB-HRL), which instantiates a mechanism motivating the execution of high-level plans.}
}
@article{MCANDREW2020300,
title = {Re-Thinking the Role of Statistics in Informing Heart Team Decisions: A Consensus Distribution Approach},
journal = {Structural Heart},
volume = {4},
number = {4},
pages = {300-301},
year = {2020},
issn = {2474-8706},
doi = {https://doi.org/10.1080/24748706.2020.1782550},
url = {https://www.sciencedirect.com/science/article/pii/S2474870622004997},
author = {Thomas McAndrew and Bjorn Redfors}
}
@article{VAEVER2005137,
title = {Thinking within the spectrum: schizophrenic thought disorder in six Danish pedigrees},
journal = {Schizophrenia Research},
volume = {72},
number = {2},
pages = {137-149},
year = {2005},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2004.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S092099640400132X},
author = {Mette S. Væver and Deborah M. Licht and Lise Møller and Dorthe Perlt and Åge Jørgensen and Peter Handest and Josef Parnas},
keywords = {Formal thought disorder, TDI, Schizophrenia spectrum, Pedigree},
abstract = {Formal thought disorder (FTD), a major symptom of schizophrenia, is known to aggregate in families. Our aim was to examine the specificity of FTD in the schizophrenia spectrum disorders and the hypothesized linear aggregation of FTD within pedigrees. Six individuals with a diagnosis of schizophrenia were identified in the Copenhagen High-Risk study and each pedigree was centered on one of the six original schizophrenic probands' nuclear families. The 329 pedigree members in the study were considered at risk for schizophrenia spectrum disorders because most were genetically related to the originating schizophrenic probands. The participants were administered the Copenhagen Interview of Functional Illness to determine diagnoses and the Thought Disorder Index (TDI) was used to assess FTD. Individuals with a schizophrenia diagnosis had higher global levels of FTD, exhibited more severe types of FTD, and had a qualitatively different type of FTD than did participants with other diagnoses or no mental illness. Individuals with Cluster A diagnoses exhibited more FTD and FTD similar in quality to participants with schizophrenia. These results support the construct of a spectrum of schizophrenia conditions. There was a generally high level of FTD in the pedigrees, in part due to assortative mating in this sample. However, there was no apparent pattern of linear aggregation of FTD within the families.}
}
@article{CAETANO2020287,
title = {Computational design in architecture: Defining parametric, generative, and algorithmic design},
journal = {Frontiers of Architectural Research},
volume = {9},
number = {2},
pages = {287-300},
year = {2020},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2019.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S2095263520300029},
author = {Inês Caetano and Luís Santos and António Leitão},
keywords = {Algorithmic design, Computer-aided design, Computational design, Generative design, Parametric design},
abstract = {Computation-based approaches in design have emerged in the last decades and rapidly became popular among architects and other designers. Design professionals and researchers adopted different terminologies to address these approaches. However, some terms are used ambiguously and inconsistently, and different terms are commonly used to express the same concept. This paper discusses computational design (CD) and proposes an improved and sound taxonomy for a set of key CD terms, namely, parametric, generative, and algorithmic design, based on an extensive literature review from which different definitions by various authors were collected, analyzed, and compared.}
}
@article{DAI2024292,
title = {Facilitating Students’ Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
journal = {Procedia CIRP},
volume = {128},
pages = {292-297},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006735},
author = {Yun Dai and Ziyan Lin and Ang Liu},
keywords = {help-seeking, peer support, learning analytics, design thinking, engineering education},
abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year’s course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students’ focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students’ design thinking and collaborative design.}
}
@article{BERNAL2015163,
title = {On the role of computational support for designers in action},
journal = {Design Studies},
volume = {41},
pages = {163-182},
year = {2015},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000551},
author = {Marcelo Bernal and John R. Haymaker and Charles Eastman},
keywords = {design knowledge, computer aided design, design automation, computer supported design, design technology},
abstract = {Designers' actions are high-level mechanisms based on heuristics and assumptions learned from professional experience. Significant research has been devoted to understanding these actions as well as finding ways to aid, automate, or augment them with computational support. However, representing and manipulating such tacit knowledge in computational environments remains an open area of research. In this paper, we map designers' actions and relationships to compare them with computational approaches for the generation, evaluation, and selection of design alternatives, and attempt to integrate all of the above. The analysis provides a more thorough understanding of the role of computational approaches in supporting designer actions and identifies challenges and areas of future research.}
}
@article{IGAMBERDIEV2021104395,
title = {Mathematics in biological reality: The emergence of natural computation in living systems},
journal = {Biosystems},
volume = {204},
pages = {104395},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2021.104395},
url = {https://www.sciencedirect.com/science/article/pii/S0303264721000526},
author = {Abir U. Igamberdiev and Joseph E. Brenner},
keywords = {Biological evolution, Biological code, Complexification, Computation, Epistemic cut, Hypercycle, Internal measurement, Relational biology, Univalent foundations},
abstract = {Mathematics is a powerful tool to express the computable part of the reality of the physical world. For living systems, mathematical relations emerge internally as an abstracting capacity in the course of development and adaptation to the external world. All living systems possess internal coding structures which represent their embedded description. They are anticipatory in the sense that the embedded description generates deterministic model of their behavior. If the model does not provide a correct result, they can evolve through the acquisition of new statements inside the embedded description that overcome limitations of the existing model. The newly generated statements acquire meaning in and from the changing environment. The growth of complexity, being a consequence of the internal active adaptation to externality performed by the systems, increases the amount of external work and generates the observed patterns of spatiotemporal structures of evolving systems. In living systems, the symbolic memory constraints are dynamic processes in themselves, co-evolving with the other components of biological systems. Separation of the symbolic memory and the dynamic laws (defined as the epistemic cut), required for self-replication of biological systems, forms the basis for their onto-epistemic relation to reality. In this regard, living systems possess their own internal abstracting capacity and invent mathematics. The digital structure of the genetic code is a manifestation of this mathematics.}
}
@article{JOSHI2018740,
title = {Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects},
journal = {NeuroImage},
volume = {172},
pages = {740-752},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918300582},
author = {Anand A. Joshi and Minqi Chong and Jian Li and Soyoung Choi and Richard M. Leahy},
abstract = {We describe BrainSync, an orthogonal transform that allows direct comparison of resting fMRI (rfMRI) time-series across subjects. For this purpose, we exploit the geometry of the rfMRI signal space to propose a novel orthogonal transformation that synchronizes rfMRI time-series across sessions and subjects. When synchronized, rfMRI signals become approximately equal at homologous locations across subjects. The method is based on the observation that rfMRI data exhibit similar connectivity patterns across subjects, as reflected in the pairwise correlations between different brain regions. We show that if the data for two subjects have similar correlation patterns then their time courses can be approximately synchronized by an orthogonal transformation. This transform is unique, invertible, efficient to compute, and preserves the connectivity structure of the original data for all subjects. Analogously to image registration, where we spatially align structural brain images, this temporal synchronization of brain signals across a population, or within-subject across sessions, facilitates cross-sectional and longitudinal studies of rfMRI data. The utility of the BrainSync transform is illustrated through demonstrative simulations and applications including quantification of rfMRI variability across subjects and sessions, cortical functional parcellation across a population, timing recovery in task fMRI data, comparison of task and resting state data, and an application to complex naturalistic stimuli for annotation prediction.}
}
@article{ALONSOSANCHEZ202397,
title = {Language network self-inhibition and semantic similarity in first-episode schizophrenia: A computational-linguistic and effective connectivity approach},
journal = {Schizophrenia Research},
volume = {259},
pages = {97-103},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422001608},
author = {María Francisca Alonso-Sánchez and Roberto Limongi and Joseph Gati and Lena Palaniyappan},
keywords = {Psychosis, Lexical access, fMRI, Spectral dynamic causal modelling, Broca's area, Disorganization, Formal thought disorder},
abstract = {Introduction
A central feature of schizophrenia is the disorganization and impoverishment of language. Recently, we observed higher semantic similarity in first-episode-schizophrenia (FES) patients. In this study, we investigate if this aberrant similarity relates to the ‘causal’ connectivity between two key nodes of the word production system: inferior frontal gyrus (IFG) and the semantic-hub at the ventral anterior temporal lobe (vATL).
Methods
Resting-state fMRI scans were collected from 60 participants (30 untreated FES and 30 healthy controls). The semantic distance was measured with the CoVec semantic tool based on GloVe. A spectral dynamic causal model with Parametrical Empirical Bayes was constructed modelling the intrinsic self-inhibitory and extrinsic-excitatory connections within the brain regions. We estimated the parameters of a fully connected model with the semantic distance as a covariate.
Results
FES patients chose words with higher semantic similarity when describing the pictures compared to the HC group. Among patients, an increased semantic similarity was related with an increase in intrinsic connections within both the vATL and IFG, suggesting that reduced ‘synaptic gain’ in these regions likely contribute to aberrant sampling of the semantic space during discourse in schizophrenia.
Conclusions
Lexical impoverishment relates to increased self-inhibition in both the IFG and vATL. The associated reduction in synaptic gain may relate to reduced precision of locally generated neural activity, forcing the choice of words that are already ‘activated’ in a lexical network. One approach to improve word sampling may be via promoting synaptic gain via supra-physiological stimulation within the Broca's-vATL network; this proposal needs verification.}
}
@article{SEWING2008e9,
title = {Evolution in thinking and processes?},
journal = {Drug Discovery Today: Technologies},
volume = {5},
number = {1},
pages = {e9-e14},
year = {2008},
note = {HTS revisted},
issn = {1740-6749},
doi = {https://doi.org/10.1016/j.ddtec.2008.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1740674908000140},
author = {Andreas Sewing},
abstract = {Pharmaceutical R&D transforms scientific ideas into drugs on the market. Owing to the complexity and low overall success rate, Drug Discovery needs to be as much about science as about operational excellence. In vitro screening groups, underwriting early discovery from exploratory to candidate selection, are trying to combine the search for new scientific concepts with a production-like focus on logistics, reproducibility and delivery on time. Moving beyond high-throughput technologies, we begin to ask how to improve processes and work more seamlessly across functional lines. In this context lean methods have become a front runner in discussions at drug discovery meetings. What are these methods and are they delivering what is promised, or are we looking at yet another management initiative?}
}
@incollection{BAXTER20033,
title = {On the Foundations of Computational Mathematics},
series = {Handbook of Numerical Analysis},
publisher = {Elsevier},
volume = {11},
pages = {3-34},
year = {2003},
booktitle = {Handbook of Numerical Analysis},
issn = {1570-8659},
doi = {https://doi.org/10.1016/S1570-8659(02)11001-5},
url = {https://www.sciencedirect.com/science/article/pii/S1570865902110015},
author = {B.J.C. Baxter and A. Iserles},
abstract = {Publisher Summary
This chapter discusses the interaction of computational numerical with pure mathematics.. As far as computer scientists are concerned, their genuine “interface of interaction” with numerical thinking is in two distinct areas: complexity theory and high-performance computing. While complexity theory has always been a glamourous activity in theoretical computer science, it has only recently emerged as a focus of concerted activity in numerical circles, occasionally leading to a measure of acrimony. It is to be hoped that, eventually, computer scientists will find complexity issues involving real-number computations to be challenging, worthwhile, and central to the understanding of theoretical computation. Likewise, the ongoing development of parallel computer architectures and the computational grid is likely to lead to considerably better numerical/computational interaction at the more practical, engineering-oriented end.}
}
@article{BOOKER2004331,
title = {Solving black box computation problems using expert knowledge theory and methods},
journal = {Reliability Engineering & System Safety},
volume = {85},
number = {1},
pages = {331-340},
year = {2004},
note = {Alternative Representations of Epistemic Uncertainty},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2004.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0951832004000705},
author = {Jane M Booker and Laura A McNamara},
keywords = {Expert judgment, Elicitation, Probability theory, Epistemic uncertainty},
abstract = {The challenge problems for the Epistemic Uncertainty Workshop at Sandia National Laboratories provide common ground for comparing different mathematical theories of uncertainty, referred to as General Information Theories (GITs). These problems also present the opportunity to discuss the use of expert knowledge as an important constituent of uncertainty quantification. More specifically, how do the principles and methods of eliciting and analyzing expert knowledge apply to these problems and similar ones encountered in complex technical problem solving and decision making? We will address this question, demonstrating how the elicitation issues and the knowledge that experts provide can be used to assess the uncertainty in outputs that emerge from a black box model or computational code represented by the challenge problems. In our experience, the rich collection of GITs provides an opportunity to capture the experts' knowledge and associated uncertainties consistent with their thinking, problem solving, and problem representation. The elicitation process is rightly treated as part of an overall analytical approach, and the information elicited is not simply a source of data. In this paper, we detail how the elicitation process itself impacts the analyst's ability to represent, aggregate, and propagate uncertainty, as well as how to interpret uncertainties in outputs. While this approach does not advocate a specific GIT, answers under uncertainty do result from the elicitation.}
}
@incollection{SCHLESINGER2020337,
title = {Computational Models of Development},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {337-346},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23615-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236158},
author = {Matthew Schlesinger},
keywords = {Computational model, Connectionist model, Artificial neural network, Learning algorithm, Symbolic versus sub-symbolic representations, Adaptive versus static, Learning mechanism, Rule-based model, Dynamic field theory model, Bayesian model, Developmental pattern},
abstract = {Conventional research methods for investigating development are powerful and diverse, but they also have their limits. Many of these limitations can be overcome or addressed through computer modeling. To help make this argument, the current chapter provides a broad, accessible overview to the study of computational models of learning and development. First, we explore the technical vocabulary of computational modeling research by reviewing a set of basic concepts, including the different kinds of representations that are employed by computational models, as well as the array of learning algorithms that are typically used. Next, we review four major types of models: connectionist models, dynamic field theory models, rule-based models, and Bayesian models. In the final section, we put these concepts and approaches into practice by surveying findings from models that simulate the development of object knowledge, language learning, and motor-skill acquisition.}
}
@article{WOLFENGAGEN2016306,
title = {Computational Model of the Tangled Web},
journal = {Procedia Computer Science},
volume = {88},
pages = {306-311},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.440},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316969},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey Kosikov},
keywords = {event-driven computations, scripts, vulnerability, information security, computational model, tangled web},
abstract = {In this paper we attempt to build computational models of entanglement among the event-driven computations. The proposed model operates on the notion of dynamics of the events. This allows selection of entanglement zone that characterizes the area of risks where possible vulnerability and, as a consequence, security violations of web application arise. All constructions for objects are treated as virtual objects. The stated range of issues focuses on computational technologies used scripts, though other explanatory systems are admissible as well but within other appropriate contexts.}
}
@incollection{COUCLELIS2020357,
title = {Computational Human Geography},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {357-363},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10619-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955106195},
author = {Helen Couclelis},
keywords = {Agent-based models, Ambient computing, Cellular automata, Computer modeling, Data revolution, GIS, Geocomputation, Simulation, Urban informatics, Visualization},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. The approach goes back to the beginnings of the quantitative revolution in geography and is philosophically related though methodologically distinct from it. Geographic information systems (GIS) and science are a big part of computational human geography, but the latter notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, spatial analysis, and an increasing number of new research areas and methods enabled by the most recent technological developments. The latter are discussed under the rubrics of The Data Revolution, Urban (Spatial) Informatics, and Ambient Computing. Two major thrusts have persisted throughout the years: the use of numerical techniques to solve large, complex quantitative problems; the development of models of complex spatial processes expressed directly in computational terms. Both have evolved with the times and continue to be central to computational human geography. Critiques originate from both within the field and from the humanities and social theory perspectives. These address epistemological and methodological problems as well as issues of ontology and representation.}
}
@article{ROLLWAGE2019820,
title = {What Underlies Political Polarization? A Manifesto for Computational Political Psychology},
journal = {Trends in Cognitive Sciences},
volume = {23},
number = {10},
pages = {820-822},
year = {2019},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661319301810},
author = {Max Rollwage and Leor Zmigrod and Lee de-Wit and Raymond J. Dolan and Stephen M. Fleming},
keywords = {political psychology, computational modeling, cognitive styles, behavioral tasks, radicalism, polarization},
abstract = {Polarization is one of the biggest societal challenges of our time, yet its drivers are poorly understood. Here we propose a novel approach – computational political psychology – which uses behavioral tasks in combination with formal computational models to identify candidate cognitive processes underpinning susceptibility to polarized beliefs about political and societal issues.}
}
@incollection{AHAMED2017163,
title = {Chapter 12 - From Primal Thinking to Potential Computing},
editor = {Syed V. Ahamed},
booktitle = {Evolution of Knowledge Science},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {163-185},
year = {2017},
isbn = {978-0-12-805478-9},
doi = {https://doi.org/10.1016/B978-0-12-805478-9.00012-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128054789000121},
author = {Syed V. Ahamed},
keywords = {Philosophic approaches and their limitations, Digital inroads into Knowledge, Positive and negative shifts of knowledge, Oscillations in knowledge domain},
abstract = {Chapter Summary
In this chapter, we investigate the generic representations of human functions and machine operations in the same framework for execution on the current computers, i.e., how a machine would execute human functions and conversely how a human would execute machine functions. This approach would facilitate the encoding of the (common) human functions as precisely as the machine language instructions for a computer. Conversely, the approach would facilitate the transfer of the lower-level intelligence of a human being into the adaptation of the HW, SW, and FW modules of an intelligent machine. Though not entirely feasible, the approach digs deep inroads in how human intelligent-machines can be and conversely, how robotic mundane-human beings can be. The later situation occurs in prisoner-, slave-, military-camps. The methodology is practical since machines have already started to imitate human behavior and some of the human tasks are routine and programmable into the robots. The challenge lies when some of the higher levels functions (such as conceptualize, hypothesize, optimize, generalize, axiomize, etc.) of human beings need to be programed into intelligent machines, even though middle level functions (such as summarize, generalize, rationalize, etc.) can be forced by appropriate knowledge-ware (KW) into intelligent machines. These middle level functions are encoded into the KW by searching for embedded knowledge centric objects (KCOs) in human beings, cultures, societies, and other contributing objects. Related and pertinent knowledge is found by exploring the local and the Internet knowledge bases (KBs) and selecting the attributes of these objects and or related objects. The Chapter outlines and elaborates the proposed approach.}
}
@incollection{JUNG2023198,
title = {Design-based education in STEM: for learners of the 21st century},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {198-206},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13077-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130775},
author = {Yong Ju Jung and Gi Woong Choi and Soo Hyeon Kim},
keywords = {Design-based education, Design thinking, Digital media creation, Engineering design, Makerspaces, STEM+C education, STEM education, 21st century learning},
abstract = {This article aims to conceptualize design-based education (DBE) in STEM educational settings and provide examples of current DBE practices followed by discussing the gaps of current DBE. We define DBE as educational theory and practice that integrate and transform design processes and design thinking into learning experiences. DBE is well-aligned with the 21st century STEM education because it can enhance learner-centered pedagogy, learners' critical thinking, collaboration, interest-driven learning, and integrative STEM learning. More attention to concrete strategies for the integrative STEM education in DBE and systems of preparing educators for DBE is needed for better learning experiences.}
}
@article{BAGGIO2020100005,
title = {Computational modelling and simulations in tourism: A primer},
journal = {Annals of Tourism Research Empirical Insights},
volume = {1},
number = {1},
pages = {100005},
year = {2020},
issn = {2666-9579},
doi = {https://doi.org/10.1016/j.annale.2020.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2666957920300057},
author = {Rodolfo Baggio},
keywords = {Complex systems, Modelling, Simulations, Numerical and computational methods},
abstract = {The aim of this contribution is to briefly sketch and discuss the main issues that concern the activities of modelling and simulating complex phenomena and systems. The focus is on numerical and computational techniques. We discuss the validity of these methods and examine the different steps to be taken for ensuring a correct, accurate and reliable implementation. The approach is essentially of general methodological nature, regardless of specific techniques or tools.}
}
@article{CHUNG200896,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}
@article{AUGELLO201674,
title = {Artwork creation by a cognitive architecture integrating computational creativity and dual process approaches},
journal = {Biologically Inspired Cognitive Architectures},
volume = {15},
pages = {74-86},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X1500050X},
author = {Agnese Augello and Ignazio Infantino and Antonio Lieto and Giovanni Pilato and Riccardo Rizzo and Filippo Vella},
keywords = {Computational creativity, Cognitive architecture, Dual process theory, PSI model},
abstract = {The paper proposes a novel cognitive architecture (CA) for computational creativity based on the Psi model and on the mechanisms inspired by dual process theories of reasoning and rationality. In recent years, many cognitive models have focused on dual process theories to better describe and implement complex cognitive skills in artificial agents, but creativity has been approached only at a descriptive level. In previous works we have described various modules of the cognitive architecture that allows a robot to execute creative paintings. By means of dual process theories we refine some relevant mechanisms to obtain artworks, and in particular we explain details about resolution level of the CA dealing with different strategies of access to the Long Term Memory (LTM) and managing the interaction between S1 and S2 processes of the dual process theory. The creative process involves both divergent and convergent processes in either implicit or explicit manner. This leads to four activities (exploratory, reflective, tacit, and analytic) that, triggered by urges and motivations, generate creative acts. These creative acts exploit both the LTM and the WM in order to make novel substitutions to a perceived image by properly mixing parts of pictures coming from different domains. The paper highlights the role of the interaction between S1 and S2 processes, modulated by the resolution level which focuses the attention of the creative agent by broadening or narrowing the exploration of novel solutions, or even drawing the solution from a set of already made associations. An example of artificial painter is described in some experimentations by using a robotic platform.}
}
@article{LANDAU2024101463,
title = {Young children’s copying of block constructions: Significant constraints in a highly complex task},
journal = {Cognitive Development},
volume = {71},
pages = {101463},
year = {2024},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2024.101463},
url = {https://www.sciencedirect.com/science/article/pii/S0885201424000480},
author = {Barbara Landau and E. Emory Davis and Cathryn S. Cortesa and Zihan Wang and Jonathan D. Jones and Amy L. Shelton},
keywords = {Skilled action, Spatial skills, Spatial cognition, Development, Block construction, Intuitive physics},
abstract = {Block construction is ubiquitous in early development, yet is surprisingly complex, involving step-by-step sequenced actions to create specific structures. Here, we use novel analytic methods to characterize these action sequences in detail, including which individual parts of the structure (‘states’) are built and how these structures are combined, creating a fully specified build path towards the final structure. We find that, like adults tested in a previous study, 4- to 8-year-olds build by creating a small subset of possible individual states and full build paths, and that they prioritize building layer-by-layer. The individual states and build paths that children produce are strikingly similar to those of adults, resulting in structures that are more stable than other possible (but not attested) states and paths. Our approach serves as a lens into the cognitive processes underlying block building and suggests that children’s building is guided by significant cognitive constraints consistent with “computational thinking”.}
}
@article{BACELARALMEIDA2022100736,
title = {A formal treatment of the role of verified compilers in secure computation},
journal = {Journal of Logical and Algebraic Methods in Programming},
volume = {125},
pages = {100736},
year = {2022},
issn = {2352-2208},
doi = {https://doi.org/10.1016/j.jlamp.2021.100736},
url = {https://www.sciencedirect.com/science/article/pii/S2352220821000997},
author = {José Carlos {Bacelar Almeida} and Manuel Barbosa and Gilles Barthe and Hugo Pacheco and Vitor Pereira and Bernardo Portela},
keywords = {Secure multiparty computation, Secure compilation, Certified compilation, Formal verification, EasyCrypt, Computer-aided cryptography},
abstract = {Secure multiparty computation (SMC) allows for complex computations over encrypted data. Privacy concerns for cloud applications makes this a highly desired technology and recent performance improvements show that it is practical. To make SMC accessible to non-experts and empower its use in varied applications, many domain-specific compilers are being proposed. We review the role of these compilers and provide a formal treatment of the core steps that they perform to bridge the abstraction gap between high-level ideal specifications and efficient SMC protocols. Our abstract framework bridges this secure compilation problem across two dimensions: 1) language-based source- to target-level semantic and efficiency gaps, and 2) cryptographic ideal- to real-world security gaps. We link the former to the setting of certified compilation, paving the way to leverage long-run efforts such as CompCert in future SMC compilers. Security is framed in the standard cryptographic sense. Our results are supported by a machine-checked formalisation carried out in EasyCrypt.}
}
@article{CHRISTOU2001321,
title = {Mapping and development of intuitive proportional thinking},
journal = {The Journal of Mathematical Behavior},
volume = {20},
number = {3},
pages = {321-336},
year = {2001},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00077-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302000779},
author = {Constantinos Christou and George Philippou},
keywords = {Multiplicative problems, Conceptual field, Cardinalities},
abstract = {The purpose of this study was two-fold. First, to find out students’ informal understanding of proportional problems, and discuss their solution strategies. Second, to investigate how the intuitions developed by students influence their strategies to solve proportional problems. To this end, we interviewed 16 students in Grades 4 and 5, while they were solving proportional problems. It was found that students intuitively used the unit-rate strategy indicating an attempt to transfer the knowledge resulted by their experience with solving simple multiplicative problems. Fourth and fifth graders tended to shift from the unit-rate strategy to other strategies if there was no easy way to calculate the unit-value directly from the context of the problems. Since fifth graders were more comfortable than fourth graders in calculating the unit-value, they felt less the need to invent other solution strategies.}
}
@article{YAGHINI2022124525,
title = {Computational study of the structural properties of recycled low-density polyethylene},
journal = {Polymer},
volume = {241},
pages = {124525},
year = {2022},
issn = {0032-3861},
doi = {https://doi.org/10.1016/j.polymer.2022.124525},
url = {https://www.sciencedirect.com/science/article/pii/S003238612200012X},
author = {Nazila Yaghini and Remco Tuinier and Jaap {den Doelder}},
keywords = {Branching distribution, Kinetics, Molecular modeling, Molecular weight distribution, Thermal degradation},
abstract = {We present a comprehensive model to computationally study molecular structure development in the recycling extrusion process of low-density polyethylene (LDPE) and provide initial results versus reported experiments as guidance. Molecular weight distribution (MWD) and branching distribution (BD) are modeled by applying a combination of population balance modeling, the method of moments and branching pseudo distributions. Special cares have been taken to incorporate the effects of scission and crosslinking reactions. Further, effective strategies have been provided to mitigate the computational complexity of solving balance equations. The models have been applied to the case of increasing residence time in a recycling extruder. The simulated MWD of the recycled LDPE exhibits a shift towards lower chain lengths for residence times up to 400s, while for higher residence times the high MW tail forms. The evolution of the simulated BD during recycling reveals important modifications versus the original virgin LDPE with implications for derived properties.}
}
@article{SHKLOVSKIYKORDI2022104719,
title = {Editorial: Fundamental principles of biological computation: From molecular computing to evolutionary complexity},
journal = {Biosystems},
volume = {219},
pages = {104719},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104719},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722001034},
author = {Nikita E. Shklovskiy-Kordi and Koichiro Matsuno and Pedro C. Marijuán and Abir U. lgamberdiev}
}
@article{KAUFFMAN1999256,
title = {Thinking combinatorially},
journal = {Current Opinion in Chemical Biology},
volume = {3},
number = {3},
pages = {256-259},
year = {1999},
issn = {1367-5931},
doi = {https://doi.org/10.1016/S1367-5931(99)80040-4},
url = {https://www.sciencedirect.com/science/article/pii/S1367593199800404},
author = {Stuart Kauffman and Andrew D Ellington},
abstract = {Biopolymers and chemical compounds with novel functions can be selected or screened from randomized libraries. Recently, it has become possible to augment the functions of biopolymers via the conjugation or incorporation of unnatural chemical moieties. In the future, it should prove possible to engineer systems that can self-evolve and thereby reveal unexpected emergent properties.}
}
@article{ARBELAEZOSSA2023102458,
title = {A smarter perspective: Learning with and from AI-cases},
journal = {Artificial Intelligence in Medicine},
volume = {135},
pages = {102458},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102458},
url = {https://www.sciencedirect.com/science/article/pii/S093336572200210X},
author = {Laura {Arbelaez Ossa} and Michael Rost and Giorgia Lorenzini and David M. Shaw and Bernice Simone Elger},
keywords = {Medical education, Artificial intelligence, Case-based learning, Critical thinking, Ethics},
abstract = {Artificial intelligence (AI) has only partially (or not at all) been integrated into medical education, leading to growing concerns regarding how to train healthcare practitioners to handle the changes brought about by the introduction of AI. Programming lessons and other technical information into healthcare curricula has been proposed as a solution to support healthcare personnel in using AI or other future technology. However, integrating these core elements of computer science knowledge might not meet the observed need that students will benefit from gaining practical experience with AI in the direct application area. Therefore, this paper proposes a dynamic approach to case-based learning that utilizes the scenarios where AI is currently used in clinical practice as examples. This approach will support students' understanding of technical aspects. Case-based learning with AI as an example provides additional benefits: (1) it allows doctors to compare their thought processes to the AI suggestions and critically reflect on the assumptions and biases of AI and clinical practice; (2) it incentivizes doctors to discuss and address ethical issues inherent to technology and those already existing in current clinical practice; (3) it serves as a foundation for fostering interdisciplinary collaboration via discussion of different views between technologists, multidisciplinary experts, and healthcare professionals. The proposed knowledge shift from AI as a technical focus to AI as an example for case-based learning aims to encourage a different perspective on educational needs. Technical education does not need to compete with other essential clinical skills as it could serve as a basis for supporting them, which leads to better medical education and practice, ultimately benefiting patients.}
}
@article{SPREVAK2010260,
title = {Computation, individuation, and the received view on representation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {260-270},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000403},
author = {Mark Sprevak},
keywords = {Computation, Representation, Computational identity, Explanation, Narrow content, Physical computation},
abstract = {The ‘received view’ about computation is that all computations must involve representational content. Egan and Piccinini argue against the received view. In this paper, I focus on Egan’s arguments, claiming that they fall short of establishing that computations do not involve representational content. I provide positive arguments explaining why computation has to involve representational content, and how that representational content may be of any type (distal, broad, etc.). I also argue (contra Egan and Fodor) that there is no need for computational psychology to be individualistic. Finally, I draw out a number of consequences for computational individuation, proposing necessary conditions on computational identity and necessary and sufficient conditions on computational I/O equivalence of physical systems.}
}
@incollection{SHARMA2020123,
title = {Chapter 6 - Application of hybrid computational intelligence in health care},
editor = {Siddhartha Bhattacharyya and Václav Snášel and Deepak Gupta and Ashish Khanna},
booktitle = {Hybrid Computational Intelligence},
publisher = {Academic Press},
pages = {123-148},
year = {2020},
series = {Hybrid Computational Intelligence for Pattern Analysis and Understanding},
isbn = {978-0-12-818699-2},
doi = {https://doi.org/10.1016/B978-0-12-818699-2.00007-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012818699200007X},
author = {Moolchand Sharma and Suyash Agrawal and Suman Deswal},
keywords = {Computational intelligence, hybrid computational intelligence, healthcare systems, neural networks, genetic algorithms},
abstract = {The use of hybrid computational intelligence is currently broadening in the field of healthcare applications and research. Computational intelligence has played a vital role in health care for a significant period of time, but with the increased popularity and extensive use of these hybrid computational intelligent systems, a shift has been seen also in the field of health care. Hybrid computational intelligence can be implied in the field of decision making, remote monitoring, healthcare logistics, and modern information systems. Hybrid computational intelligence synergizes different computational intelligence techniques, such as the neural network, the fuzzy logic, the genetic algorithms, the evolutionary computation and the support vector machines, and have their application in the field of pattern recognition, system modeling, etc. In this chapter, we focus on the need for healthcare information technology, improvement of healthcare delivery systems, healthcare safety issues, and also various areas where it can be used.}
}
@article{ZHA2022104623,
title = {A mixed-method cluster analysis of physical computing and robotics integration in middle-grade math lesson plans},
journal = {Computers & Education},
volume = {190},
pages = {104623},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104623},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522001944},
author = {Shenghua Zha and Yi Jin and Rebecca Wheeler and Erin Bosarge},
keywords = {Applications in subject areas, Improving classroom teaching, Secondary education},
abstract = {This study analyzed 281 lesson plans collected from the producers’ websites of 12 educational physical computing and robotics (ePCR) devices. We extracted and coded five variables from each lesson. They were ePCR functionality, coding skills, computational thinking skills, math knowledge, and activity design. First, a two-step cluster analysis was administered to find how three ePCR-related knowledge: ePCR functionality, coding skills, and computational thinking skills, were integrated to teach students ePCR technology in middle-grade math lessons. Results showed three types of lesson plans, including lessons to use basic ePCR functionality to teach students lower-level CT skills, lessons to teach students basic to intermediate coding skills, and lessons to use the technology at the advanced level. Next, we applied the Technological Pedagogical Content Knowledge (TPACK) framework and conducted a second two-step cluster analysis to identify how the technology (ePCR technology), content (math knowledge), and pedagogy (activity design) were integrated into those lesson plans. Results suggested ten clusters of lesson plans with distinct features. We summarized those ten lesson clusters into five categories: 1) ePCR technology lessons, 2) transdisciplinary problem-based learning lessons, 3) technology-assisted lessons, 4) lessons without real-world connections, and 5) lessons integrating middle-grade math learning into ePCR projects. Implications for educators and researchers were discussed at the end of the article.}
}
@article{TUTHILL2020R739,
title = {What we think about when we think about thinking},
journal = {Current Biology},
volume = {30},
number = {13},
pages = {R739-R740},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2020.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0960982220306734},
author = {John Tuthill}
}
@article{WOLFRAM2020101132,
title = {What We’ve built Is a computational language (and that’s very important!)},
journal = {Journal of Computational Science},
volume = {46},
pages = {101132},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101132},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320304336},
author = {Stephen Wolfram}
}
@article{PREISIG201259,
title = {Thinking Towards Synergistic Green Refineries},
journal = {Energy Procedia},
volume = {20},
pages = {59-67},
year = {2012},
note = {Technoport 2012 - Sharing Possibilities and 2nd Renewable Energy Research Conference (RERC2012)},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2012.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1876610212007382},
author = {Heinz A. Preisig and Bernd Wittgens},
keywords = {Bioreﬁnery, Green reﬁnery, Biobased Economy},
abstract = {The switch from a mined-carbon-based society to a bio-carbon based society requires a major shift not only of the resources,but alsoin the typeof processes that produce the products on which ourcivilizationbuilds;a richer approach to handling and production is required. Natural products from renewable sources will substitute today'spurely synthetic products from fossil resources, associated waste streams will have to be utilized for the production of usable materials, with chemical processing being one of the main options.Fuel represents a main class of chemicals that we increasingly rely on. They have to be substituted as quick as possible as they represent the largest use of mined carbon. The paper presents some of the stumbling blocks which prohibit the transfer and high lights the most needed research objectives.}
}
@article{DINOV2008284,
title = {Pedagogical utilization and assessment of the statistic online computational resource in introductory probability and statistics courses},
journal = {Computers & Education},
volume = {50},
number = {1},
pages = {284-300},
year = {2008},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2006.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131506001059},
author = {Ivo D. Dinov and Juana Sanchez and Nicolas Christou},
keywords = {Education research, Teaching with technology, Java applets, Online course materials, Probability and statistics},
abstract = {Technology-based instruction represents a new recent pedagogical paradigm that is rooted in the realization that new generations are much more comfortable with, and excited about, new technologies. The rapid technological advancement over the past decade has fueled an enormous demand for the integration of modern networking, informational and computational tools with classical pedagogical instruments. Consequently, teaching with technology typically involves utilizing a variety of IT and multimedia resources for online learning, course management, electronic course materials, and novel tools of communication, engagement, experimental, critical thinking, and assessment. The NSF-funded Statistics Online Computational Resource (SOCR) provides a number of interactive tools for enhancing instruction in various undergraduate and graduate courses in probability and statistics. These resources include online instructional materials, statistical calculators, interactive graphical user interfaces, computational and simulation applets, tools for data analysis and visualization. The tools provided as part of SOCR include conceptual simulations and statistical computing interfaces, which are designed to bridge between the introductory and the more advanced computational and applied probability and statistics courses. In this manuscript, we describe our designs for utilizing SOCR technology in instruction in a recent study. In addition, present the results of the effectiveness of using SOCR tools at two different course intensity levels on three outcome measures: exam scores, student satisfaction and choice of technology to complete assignments. Learning styles assessment was completed at baseline. We have used three very different designs for three different undergraduate classes. Each course included a treatment group, using the SOCR resources, and a control group, using classical instruction techniques. Our findings include marginal effects of the SOCR treatment per individual classes; however, pooling the results across all courses and sections, SOCR effects on the treatment groups were exceptionally robust and significant. Coupling these findings with a clear decrease in the variance of the quantitative examination measures in the treatment groups indicates that employing technology, like SOCR, in a sound pedagogical and scientific manner enhances overall the students’ understanding and suggests better long-term knowledge retention.}
}
@article{PATON199363,
title = {Some computational models at the cellular level},
journal = {Biosystems},
volume = {29},
number = {2},
pages = {63-75},
year = {1993},
issn = {0303-2647},
doi = {https://doi.org/10.1016/0303-2647(93)90084-P},
url = {https://www.sciencedirect.com/science/article/pii/030326479390084P},
author = {Ray C. Paton},
keywords = {Computational models of the cell, Levels of organisation, Systemic metaphors},
abstract = {A number of viewpoints on how a cell can be modelled are discussed in this paper in light of the ability it has to process information. The paper begins with a very brief summary of four general types of computation: sequential, parallel, distributed, and emergent. These form the general framework from which a number of comparisons are made. Several metaphors are introduced to enable reflections to be made about cellular computational properties. The most important metaphor, namely the cell as a machine, is discussed, and then a number of other ideas are introduced that complement much current thinking in this area. The idea of networks or circuits in the cell is then developed, as this provides a means of describing the mechanisms within a machine. Following on from this, three further metaphors are applied in order to overcome certain limitations in current machine thinking, cell-as-society, cell-as-text, and cell-as-field.}
}
@article{HASSANNEZHAD2022116338,
title = {Virtual Net Propagator: A cloud-based computational tool for systemic decision propagation analysis},
journal = {Expert Systems with Applications},
volume = {191},
pages = {116338},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116338},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421016365},
author = {Mohammad Hassannezhad and Behzad Farahany and Fatemeh Barzegar},
keywords = {Change propagation, Complex networks, Computational intelligence, Systems design and analysis, Socio-technical systems, Web-based decision support system},
abstract = {Today’s organizations are witnessing a growing complexity in making interconnected decisions. Where individuals have a wider range of decisions to influence, the consequence of decisions far more propagate across the system, and the business environment continually influences the status of the system. Predicting the cascading effects of decisions in such situations would be very problematic yet can have several implications for managers and executives to think beyond organizational silos and make local decision with a bigger picture of emergent consequences in mind. A prominent challenge within this realm is the ever-increasing complexity of decision propagations, especially when incorporating the role and influence of people involved in decision-making. This paper tackles this challenge from an engineering change perspective, with the focus on computing the compound risk of decisions when their consequences concurrently propagate across the system. We introduce an interactive tool called Virtual Net Propagator, which incorporates organizational dynamics into decision analysis, with the aim to identify change opportunities and effective set of interventions. Illustrated by a field engineering case study, it is demonstrated that the proposed tool can provide detailed knowledge on how decisions are interconnected and how systemic (cascading) effects of a decision propagate through causal pathways, so highlighting key influencers along with role and influence of interfacing (hidden) players.}
}
@article{MARUYAMA20181037,
title = {Investigation into Parents’ Concerns about the Introduction of Programming Education into Japanese Primary School},
journal = {Procedia Computer Science},
volume = {126},
pages = {1037-1045},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918313188},
author = {Yukiko Maruyama},
keywords = {Programming education, primary school, parents’ concerns, computing thinking},
abstract = {The introduction of computational thinking into primary/secondary or K-12 education has been widely attempted. In Japan, programming education will be introduced into primary school in 2020. The role of parents in primary education is highly important, and their attitude towards education has a considerable influence on children’s attitudes. To investigate parents’ concerns regarding programming education in primary school, a preliminary questionnaire survey has been conducted as a first step of the study.}
}
@article{FLETCHER2023100061,
title = {Narrative creativity training: A new method for increasing resilience in elementary students},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100061},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100061},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000201},
author = {Angus Fletcher and Patricia Enciso and Mike Benveniste},
keywords = {Narrative, Creativity, Education, Resilience, Self-efficacy, Counterfactual thinking},
abstract = {Narrative creativity training has recently shown promise as a tool for increasing self-efficacy and resilience in adult learners. The training employs dramatic and literary techniques such as perspective-shifting, counterfactual (i.e., what-if) thinking, and causal (i.e., why) thinking to improve real-world problem solving. To explore whether narrative creativity training could have similar benefits for younger populations, this study piloted a test on elementary students. A five-minute randomized controlled trial conducted with 32 third, fourth, and fifth grade students yielded increased self-efficacy and creative problem-solving, and a five-day longitudinal trial conducted with 28 students from the same population was associated with increased resilience. The results suggest the potential practical benefits of incorporating theater, literature, comics, and other story-based art into elementary school curricula.}
}
@article{SUN2022102991,
title = {Lake algal bloom monitoring via remote sensing with biomimetic and computational intelligence},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {113},
pages = {102991},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102991},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001820},
author = {Zhibin Sun and Ni-Bin Chang and Chi-Farn Chen and Wei Gao},
keywords = {Eutrophication, Biomimetic intelligence, Computational intelligence, Ensemble learning, Food-water nexus, Decision level fusion, Water quality monitoring},
abstract = {Traditional supervised classifications for remote sensing-based water quality monitoring count on a set of classifiers to retrieve features and improve their prediction accuracies based on ground truth samples. However, many existing feature extraction methods in remote sensing are unable to exhibit multiple-instance nonlinear spatial pattern recognition at scales via ensemble learning. This paper designed for lake algal bloom monitoring presents intelligent feature extraction for harmonizing local and global features via tensor flow-based ensemble learning with integrated biomimetic and computational intelligence. To explore such complexity, an Integrated Biomimetic and Ensemble Learning Algorithm (IBELA) was developed to synthesize the contribution from different classifiers associated with the biomimetic philosophy of integrated bands. It leads to strengthened multiple-instance spatial pattern recognition in lake algal bloom monitoring via image fusion at the decision level. With the implementation of IBELA, a case study of a eutrophic freshwater lake, Lake Managua, for water quality monitoring leads to demonstrate six input visual senses showing different impacts on retrieving Chl-a concentrations in the dry and wet season, respectively. The input of total nitrogen from the watershed plays the most important role in water quality variations in both seasons in a watershed-based food–water nexus. Although ultraviolet and microwave bands are important in the dry season, Secchi disk depth is critical in the wet season for water quality monitoring.}
}
@article{TIKHONOV199898,
title = {The Sensing and Control Strategies of Thin-Film Growth Process Based on Visual Thinking Prototyping Cellular Neural Network},
journal = {IFAC Proceedings Volumes},
volume = {31},
number = {29, Supplement 1},
pages = {98-99},
year = {1998},
note = {7th IFAC Symposium on Artificial Intelligence in Real Time Control 1998. Extended Abstracts, Grand Canyon National Park, USA, 5-8 October},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)38368-4},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017383684},
author = {Nikolai I. Tikhonov}
}
@incollection{SHAW2004295,
title = {Chapter 22 - The Spatial-Temporal Thinking Machine},
editor = {Gordon L. Shaw},
booktitle = {Keeping Mozart in Mind (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {295-299},
year = {2004},
isbn = {978-0-12-639061-2},
doi = {https://doi.org/10.1016/B978-012639061-2/50026-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780126390612500264},
author = {Gordon L. Shaw},
abstract = {Publisher Summary
This chapter discusses ideas and dreams of building a computer that can think and reason based on the spatial-temporal reasoning methods used in the brain. The enormous impact that electronic computers have had on our lives is well known. If one could combine the speed of the present computer with the ability of the brain to think using families of symmetry patterns developing in space and time, a whole new era would be here. Moreover, cortical columns are organized in a very highly structured manner to form a cortical area. It is this higher-level architecture that has been examined in order to explore the further consequences of the concepts concerning computation by symmetry operations. It is suggested that a hardware analog-digital implementation of this higher-level cortical area architecture of trion cortical columns should be “straightforward” owing to the localized and structured connectivity, and the discreteness of the firing levels. It is noted that, high-speed parallel computations would allow one to look for symmetry operations in a cortical area.}
}
@article{AHMADI201627,
title = {Computational cognitive assistants for futures studies: Toward vision based simulation},
journal = {Futures},
volume = {81},
pages = {27-39},
year = {2016},
note = {Modelling and Simulation in Futures Studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0016328716300829},
author = {Meisam Ahmadi and Mohammadreza {Jahed Motlagh} and Adel Torkaman Rahmani and Mohammad Mahdi Zolfagharzadeh and Peyman Shariatpanahi},
keywords = {Futures studies, Quantitative and qualitative methods, HCI design, Cognitive architecture, Artificial intelligent agents},
abstract = {Many foresight researchers believe that quantitative simulations have a very restricted contribution in futures studies due to their simplicity and lack of creativity. While qualitative methods, taking advantage of the human cognitive system, have a great potential in addressing a wide range of problems in futures studies, this potential is mostly due to the human visual logic that can handle the task of imagining future scenarios much better than mathematical logic. On the other hand, computational methods benefit from the advantages of silicon-based systems namely speed, large memory, rapid networking, and communication. Hence, it would be extremely beneficial to come up with a solution that combines the positive sides of both qualitative and computational approaches. Cognitive artificial agents are computational units that make use of the human cognitive system. Their interaction with foresight and futures researchers can result in promising solutions for the problems addressed in futures studies. In addition, these agents can serve as a great source of inspiration for taking the first step towards vision based computers that can simulate humans’ imaginations of the future. This paper reviews some of the previous attempts in this field and finally sheds light on the main issues where methods in futures studies can play a key role in the future of Human Computer Interaction systems. Our suggested architecture for a future studies interactions-based system along with its justifications and specifications is provided in the form of a request for proposal.}
}
@article{DEPASQUALE2023631,
title = {The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks},
journal = {Neuron},
volume = {111},
number = {5},
pages = {631-649.e10},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322010807},
author = {Brian DePasquale and David Sussillo and L.F. Abbott and Mark M. Churchland},
keywords = {artificial neural networks, factor models, population dynamics, dimensionality reduction, spiking networks, recurrent neural networks, network training, FORCE learning, motor system, dynamical systems},
abstract = {Summary
Neural activity is often described in terms of population-level factors extracted from the responses of many neurons. Factors provide a lower-dimensional description with the aim of shedding light on network computations. Yet, mechanistically, computations are performed not by continuously valued factors but by interactions among neurons that spike discretely and variably. Models provide a means of bridging these levels of description. We developed a general method for training model networks of spiking neurons by leveraging factors extracted from either data or firing-rate-based networks. In addition to providing a useful model-building framework, this formalism illustrates how reliable and continuously valued factors can arise from seemingly stochastic spiking. Our framework establishes procedures for embedding this property in network models with different levels of realism. The relationship between spikes and factors in such networks provides a foundation for interpreting (and subtly redefining) commonly used quantities such as firing rates.}
}
@article{CHIARAMONTI2013101,
title = {Review of energy balance in raceway ponds for microalgae cultivation: Re-thinking a traditional system is possible},
journal = {Applied Energy},
volume = {102},
pages = {101-111},
year = {2013},
note = {Special Issue on Advances in sustainable biofuel production and use - XIX International Symposium on Alcohol Fuels - ISAF},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2012.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0306261912005624},
author = {David Chiaramonti and Matteo Prussi and David Casini and Mario R. Tredici and Liliana Rodolfi and Niccolò Bassi and Graziella Chini Zittelli and Paolo Bondioli},
keywords = {Microalgae, Biofuel, Raceway ponds, Head losses, Energy, Mixing},
abstract = {The present work addresses energy consumption in raceway ponds (RWPs). This kind of systems are today the most utilized industrial plant for outdoor algae cultivation. The problem has been addressed combining theoretical correlations and experimental data. Head losses for conventional raceway ponds were evaluated, and the results were compared with data available in literature. Computational fluid dynamics was used to support the theoretical analysis. This study suggested possible improvements to the traditional RWP design: an Innovative Raceway Pond (IRP II) was therefore designed, built and operated in parallel with a reference pilot RWP in a test site. Several modifications to traditional RWP design were implemented in the IRP II: the paddle wheel was substituted by a propeller, the water head was reduced and baffle boards were installed in the curves. To validate the new design, head losses and therefore energy consumption in the different systems were evaluated, during cultivation experiments, with two microalgae strains. The theoretical and experimental study allowed a validated calculation, which showed the importance of concentrated head losses towards distributed ones. The analysis highlighted how these losses weight at different pond scales, suggesting possible improvements of the RWP energy performance – as achieved in the IRP II – through revised design for optimized mixing.}
}
@article{WALTERS199115,
title = {Critical thinking, rationality, and the vulcanization of students},
journal = {Journal of Accounting Education},
volume = {9},
number = {1},
pages = {15-31},
year = {1991},
issn = {0748-5751},
doi = {https://doi.org/10.1016/0748-5751(91)90020-R},
url = {https://www.sciencedirect.com/science/article/pii/074857519190020R},
author = {Kerry S. Walters}
}
@article{PATTON2022107263,
title = {Community implications for gun violence prevention during co-occurring pandemics; a qualitative and computational analysis study},
journal = {Preventive Medicine},
volume = {165},
pages = {107263},
year = {2022},
note = {Epidemiology and Prevention of Gun Violence},
issn = {0091-7435},
doi = {https://doi.org/10.1016/j.ypmed.2022.107263},
url = {https://www.sciencedirect.com/science/article/pii/S0091743522003127},
author = {Desmond U. Patton and Nathan Aguilar and Aviv Y. Landau and Chris Thomas and Rachel Kagan and Tianai Ren and Eric Stoneberg and Timothy Wang and Daniel Halmos and Anish Saha and Amith Ananthram and Kathleen McKeown},
keywords = {Gun violence, COVID-19, Black lives matter, Defund the police, Social media, Qualitative and computational analysis},
abstract = {This study provides insight into New York City residents' perceptions about violence after the outbreak of Coronavirus disease (COVID-19) based on information from communities in New York City Housing Authority (NYCHA) buildings. In this novel analysis, we used focus group and social media data to confirm or reject findings from qualitative interviews. We first used data from 69 in-depth, semi-structured interviews with low-income residents and community stakeholders to further explore how violence impacts New York City's low-income residents of color, as well as the role of city government in providing tangible support for violence prevention during co-occurring health (COVID-19) and social (anti-Black racism) pandemics. Residents described how COVID-19 and the Black Lives Matter movement impacted safety in their communities while offering direct recommendations to improve safety. Residents also shared recommendations that indirectly improve community safety by addressing long term systemic issues. As the recruitment of interviewees was concluding, researchers facilitated two focus groups with 38 interviewees to discuss similar topics. In order to assess the degree to which the themes discovered in our qualitative interviews were shared by the broader community, we developed an integrative community data science study which leveraged natural language processing and computer vision techniques to study text and images on public social media data of 12 million tweets generated by residents. We joined computational methods with qualitative analysis through a social work lens and design justice principles to most accurately and holistically analyze the community perceptions of gun violence issues and potential prevention strategies. Findings indicate valuable community-based insights that elucidate how the co-occurring pandemics impact residents' experiences of gun violence and provide important implications for gun violence prevention in a digital era.}
}
@article{LIU1996435,
title = {Is designing one search or two? A model of design thinking involving symbolism and connectionism},
journal = {Design Studies},
volume = {17},
number = {4},
pages = {435-449},
year = {1996},
note = {Special Issue: Design Cognition and Computation},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(96)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X9600018X},
author = {Yu-Tung Liu},
keywords = {design cognition, design process, symbolism, connectionism},
abstract = {In this paper, designing is interpreted as a combination of two searches: a shape restructuring search and a knowledge transforming search. During the first phase, designers or computer-aided design systems search for alternative ways to interpret for the current design state by restructuring shapes in terms of emergent subshapes; it is close to the connectionist processing which we can only slightly sense. During the second phase, designers or computer systems search for alternative rule applications in order to transform the interpreted current state into the next one that matches the formal and functional requirements; it is close to symbolic processing which we can sense, clearly and cognitively.}
}
@incollection{MAYER2023229,
title = {Problem solving},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {229-234},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.14023-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305140230},
author = {Richard E. Mayer},
keywords = {Cognitive processing, Higher-order cognition, Insight, Problem representation, Problem solving, Reasoning, Rigidity in thinking, Solution plan, Thinking, Transfer},
abstract = {A problem occurs when a situation is in one state, the problem solver wants it to be in another state, and there are obstacles preventing a smooth transition from the given state to the goal state. Problem solving refers to cognitive processing aimed at overcoming a problem. This entry examines the definitions of key terms, types of problems, phases in problem solving, and types of knowledge involved in problem solving. This entry also explores findings about problem solving that are most relevant to education including research on rigidity in thinking, problem solving transfer, productive thinking, insight, computer simulation of problem solving, problem solving in realistic situations, and teaching of thinking.}
}
@article{CANBALOGLU202251,
title = {Computational modeling of organisational learning by self-modeling networks},
journal = {Cognitive Systems Research},
volume = {73},
pages = {51-64},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041721000978},
author = {Gülay Canbaloğlu and Jan Treur and Peter H.M.P. Roelofsma},
keywords = {Organisational learning, Network model, Mental model, Second-order adaptive, Control of adaptation},
abstract = {Within organisational learning literature, mental models are considered a vehicle for both individual learning and organizational learning. By learning individual mental models (and making them explicit), a basis for formation of shared mental models for the level of the organization is created, which after its formation can then be adopted by individuals. This provides mechanisms for organizational learning. These mechanisms have been used as a basis for an adaptive computational network model. The model is illustrated by a not too complex but realistic case study.}
}
@article{KVISTBORG2015591,
title = {Thinking Outside the Gate: Single-Cell Assessments in Multiple Dimensions},
journal = {Immunity},
volume = {42},
number = {4},
pages = {591-592},
year = {2015},
issn = {1074-7613},
doi = {https://doi.org/10.1016/j.immuni.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1074761315001351},
author = {Pia Kvistborg and Cécile Gouttefangeas and Nima Aghaeepour and Angelica Cazaly and Pratip K. Chattopadhyay and Cliburn Chan and Judith Eckl and Greg Finak and Sine Reker Hadrup and Holden T. Maecker and Dominik Maurer and Tim Mosmann and Peng Qiu and Richard H. Scheuermann and Marij J.P. Welters and Guido Ferrari and Ryan R. Brinkman and Cedrik M. Britten}
}
@article{YAO2022113,
title = {Symbols-Meaning-Value (SMV) space as a basis for a conceptual model of data science},
journal = {International Journal of Approximate Reasoning},
volume = {144},
pages = {113-128},
year = {2022},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2022.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X2200024X},
author = {Yiyu Yao},
keywords = {Three-way decision, Thinking in threes, Triadic thinking, Trilelvel thinking, Data science, Granular computing},
abstract = {By applying the principles of three-way decision as thinking in threes, in this paper I introduce a conceptual model of data science in three steps. First, I examine examples of triadic thinking in general and trilevel thinking in specific in data science. Then, based on Weaver's trilevel categorization of communications problems, I propose the concept of the symbols-meaning-value (SMV) space and discuss three perspectives on the SMV space from the viewpoints of information science and management science, cognitive science, and computer science. I label the operations on the SMV three levels metaphorically as seeing, knowing, and doing. Finally, I put forward a SMV-space-based conceptual model of data science, in which data are a resource, the power of data is the knowledge embedded in data, and the value of data is the wise decision and the best course of action supported by data. The goals and functions of data science at the SMV three levels are, respectively, making data available, making data meaningful, and making data valuable. To demonstrate the potential contributions of the conceptual model, I comment on some of its practical values and implications.}
}
@article{LOCKWOOD2020100783,
title = {A case for combinatorics: A research commentary},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100783},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100783},
url = {https://www.sciencedirect.com/science/article/pii/S073231232030047X},
author = {Elise Lockwood and Nicholas H. Wasserman and Erik S. Tillema},
keywords = {Research commentary, Combinatorics, Discrete mathematics, Curricula},
abstract = {In this commentary, we make a case for the explicit inclusion of combinatorial topics in mathematics curricula, where it is currently essentially absent. We suggest ways in which researchers might inform the field’s understanding of combinatorics and its potential role in curricula. We reflect on five decades of research that has been conducted since a call by Kapur (1970) for a greater focus on combinatorics in mathematics education. Specifically, we discuss the following five assertions: 1) Combinatorics is accessible, 2) Combinatorics problems provide opportunities for rich mathematical thinking, 3) Combinatorics fosters desirable mathematical practices, 4) Combinatorics can contribute positively to issues of equity in mathematics education, and 5) Combinatorics is a natural domain in which to examine and develop computational thinking and activity. Ultimately, we make a case for the valuable and unique ways in which combinatorics might effectively be leveraged within K-16 curricula.}
}
@article{PSYCHARIS201490,
title = {The impact of the computational inquiry based experiment on metacognitive experiences, modelling indicators and learning performance},
journal = {Computers & Education},
volume = {72},
pages = {90-99},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513002789},
author = {Sarantos Psycharis and Evi Botsari and Panagiotis Mantas and Dionisios Loukeris},
keywords = {Metacognition, Modelling, Computational experiment, Inquiry based science education},
abstract = {Computational experiment approach considers modelling as the essential feature of Inquiry Based Science Education (IBSE), where the model and the computer take the place of the “classical” experimental set-up and simulation replaces the experiment (Landau, Pαez, & Bordeianu, 2008). Modelling, as a pedagogical tool, involves the model construction, the exploration of model characteristics and the model application to a specific problem, resembling authentic activities of scientists and mathematicians (Herbert, 2003). Recent developments in strategy instruction research suggest that learning in a particular discipline is enhanced by guiding students through the development of content-relevant metacognitive strategies (Wosnitza & Volet, 2009). Problem-solving is a complex process, which involves several cognitive operations such as collecting and selecting information, heuristic strategy and metacognition (De Corte, 2003, Garofalo and Lester, 1985, Schoenfeld, 1994). The purpose of this study was to explore the impact of the Computational Experiment Methodology on learners' cognitive performance, use of modelling indicators and shift of the metacognitive experiences during problem solving using computational models. Sixty prospective primary school teachers volunteered to participate in the study. Students were exposed by the Instructor to a number of computational experiments, while during the course they developed their own models of simulation. The results of the experiment show that the use of the computational experiment approach has a substantial effect on the metacognitive experiences and the use of modelling indicators.}
}
@article{GARCIA201325,
title = {A constructivist computational platform to support mathematics education in elementary school},
journal = {Computers & Education},
volume = {66},
pages = {25-39},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S036013151300033X},
author = {I. Garcia and C. Pacheco},
keywords = {Elementary education, Constructivist theory, Interactive computational tools, Simulated environments, Process improvement},
abstract = {Many courses for elementary school are based upon teacher presentation and explanation of basic topics, rather than allowing students to develop their own knowledge. This traditional model may turn elementary-level lessons into an extremely theoretical, boring and non-effective process. In this context, research in mathematics elementary education in Mexico indicates the need to analyze alternative pedagogic practices and to find different ways to make mathematics education in early ages less difficult and more attractive. Constructivist theory can provide an alternative for developing pedagogic proposals. The objectives of this research were: (1) develop a computational platform to support the traditional Mexican method of education with practical mathematics problems simulated as part of the daily world environment and to increase the level of students' social involvement through direct collaboration, and (2) analyze how this computational tool affects student motivation, collaboration and discussion. An exploratory case study concerning dimensions of mathematics problem-solving using computer simulations was conducted with 6–8 year old elementary school children. After a theoretical class the children were involved in solving a series of verbal problems, using our computational platform. Sixty third-grade children participated in this case study and data were collected from their responses to questions and interviews in order to explore attitudes toward learning mathematics and assess self-efficacy in this area. The results obtained in this research indicate that the integration of computational tools into conventional method courses provides elements to improve student motivation, collaboration and discussion based on their own exploratory experiences. These results can assist other education programs to incorporate positive attitudes and their own knowledge creation from a constructivist approach using technology.}
}
@article{MCMILLAN2024101154,
title = {Connecting student development of use of grouping and mathematical properties},
journal = {The Journal of Mathematical Behavior},
volume = {74},
pages = {101154},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101154},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000312},
author = {Brandon G. McMillan},
keywords = {Algebraic properties, Children’s mathematical thinking, Grouping, Multiplication and division},
abstract = {Understanding algebraic properties is a key component of building mathematical thinking across grades K-8, yet less is known about the development of students' use of mathematical properties within their strategies. This article presents results from four conversations with 24 5th-grade students over a school year, that focus on examining the development of students grouping within strategies for multiplication and division problems. Findings add to previous research on student strategies within multiplication and division by detailing some of the nuances in students' use of grouping. Additionally, a focus on student strategies reveals students' progression in more explicit use of grouping underlies the development of more planful use of the distributive and associative properties of multiplication.}
}
@article{BATZIAS20121889,
title = {Thinking by Analogy for Technology Transfer from Catalysts to Biosensors and Vice versa–a Knowledge-based Approach},
journal = {Procedia Engineering},
volume = {42},
pages = {1889-1896},
year = {2012},
note = {CHISA 2012},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.07.585},
url = {https://www.sciencedirect.com/science/article/pii/S187770581202992X},
author = {F.A. Batzias and Ch. G. Siontorou},
keywords = {Catalytic biosensors, Regeneration, Modeling, Case based reasoning, Industrial catalysis, Enzyme fuel cells},
abstract = {This work presents a methodological framework for facilitating knowledge transfer between process engineering to biosensing, employing case based reasoning to match successfully solved problems in industrial catalysts with biosensor drawbacks, adapted to the latter through their common scientific background, where ‘compatibility’ and ‘comparability’ are more prominent. The proposed framework has been implemented in mediator-based electrochemical biosensors, where the inability to recycle the cofactors in situ without compromising the functionality of the whole system remains a pending issue. The opening of technology channels between the two domains may, also, contribute to solving the problem of enzyme stability in industrial catalysis.}
}
@article{BIAN2019136,
title = {Statistical thinking, machine learning},
journal = {Journal of Clinical Epidemiology},
volume = {116},
pages = {136-137},
year = {2019},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2019.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895435619304950},
author = {Jiang Bian and Iain Buchan and Yi Guo and Mattia Prosperi}
}
@article{GOOD201778,
title = {Programming language, natural language? Supporting the diverse computational activities of novice programmers},
journal = {Journal of Visual Languages & Computing},
volume = {39},
pages = {78-92},
year = {2017},
note = {Special Issue on Programming and Modelling Tools},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16301963},
author = {Judith Good and Kate Howland},
keywords = {Novice programming languages, Natural language, Design, Empirical evaluation},
abstract = {Given the current focus on teaching computational concepts to all from an early age, combined with the growing trend to empower end users to become producers of technology rather than mere consumers, we consider the issue of “computational notation”. Specifically, where the goal is to help individuals develop their understanding of computation and/or use computation in real world settings, we question whether natural language might be a preferred notation to traditional programming languages, given its familiarity and ubiquity. We describe three empirical studies investigating the use of natural language for computation in which we found that although natural language provides support for understanding computational concepts, it introduces additional difficulties when used for coding. We distilled our findings into a set of design guidelines for novice programming environments which consider the ways in which different notations, including natural language, can best support the various activities that comprise programming. These guidelines were embodied in Flip, a bi-modal programming language used in conjunction with the Electron toolset, which allows young people to create their own commercial quality, narrative based role- playing games. Two empirical studies on the use of Flip in three different real world contexts considered the extent to which the design guidelines support ease of use and an understanding of computation. The guidelines have potential to be of use both in analysing the use of natural language in existing novice programming environments, and in the design of new ones.}
}