@INPROCEEDINGS{5941592,
  author={Menghal, P. M. and Laxmi, A. Jaya},
  booktitle={2011 3rd International Conference on Electronics Computer Technology}, 
  title={Real time simulation: A novel approach in engineering education}, 
  year={2011},
  volume={1},
  number={},
  pages={215-219},
  abstract={Today, with the advent of computers and various easily accessible software packages, computer aided teaching tools have become an essential part of both classroom lectures and laboratory experiments in any kind of education curriculum. Real Time Simulation tools, as a part of Electrical Machine Drives laboratory experiments, enhance lab experience by providing students with the opportunity to judge the performance of Electrical Machines in real time situations. This interactive learning environment, consisting of simulations, demonstrations and exercises, can fulfill the role of a bridge from passive learning to active engagement and thus stimulate deeper thinking; grounding a problem based-learning environment. The applications are also very important for relating theory to practice, so that the students can develop engineering judgment and understand how process behavior can be captured using real time simulations. Due to advancement of the software tools like MATLAB/SEVIULINK with its Real Time Workshop(RTW) and Real Time Windows Target (RTWT), real time simulators are used extensively in many engineering fields, such as industry, education and research institutions. As a consequence, inclusion of the real time simulation applications in academic curriculum provides great learning value to the students. A case is made to present overview of the Real Time Simulations of Electrical Machines Drives possibility of including these techniques in modern engineering educational curriculum. This paper will review the various real time simulation techniques such as Real Time Laboratory (RT Lab), Rapid Control Prototyping (RCP) and Hardware in the Loop (HIL), which can be used in a modern engineering education.},
  keywords={Real time systems;Computational modeling;Mathematical model;Motor drives;Power electronics;Education;Testing;Real Time Simulation;Real Time Lab(RT Lab);Hardware in the Loop (HIL);Real Time Workshop;Education Tools},
  doi={10.1109/ICECTECH.2011.5941592},
  ISSN={},
  month={April},}@ARTICLE{192924,
  author={Alvarado, F.L. and Liu, Y.},
  journal={IEEE Transactions on Power Systems}, 
  title={General purpose symbolic simulation tools for electric networks}, 
  year={1988},
  volume={3},
  number={2},
  pages={689-697},
  abstract={Research results on the use of computers to solve simulation problems in a way closer to human thinking are reported. With the aid of techniques in artificial intelligence, database systems, and computer graphics, a set of general-purpose Lisp and Pascal based simulation tools have been developed. Each of these tools solves a specific problem in some stage of simulation. Rule-based and object oriented symbolic manipulations are extensively used. The tools provide more powerful and accurate modeling capability for complex objects, and permit simplicity and flexibility in implementation. They are used to study electrical transient problems, optimal load flow problems, linear control systems, and other simulation problems.<>},
  keywords={Object oriented modeling;Computational modeling;Computer simulation;Humans;Artificial intelligence;Database systems;Computer graphics;Power system modeling;Load flow;Control system synthesis},
  doi={10.1109/59.192924},
  ISSN={1558-0679},
  month={May},}@INPROCEEDINGS{9710781,
  author={Chen, Shoufa and Sun, Peize and Xie, Enze and Ge, Chongjian and Wu, Jiannan and Ma, Lan and Shen, Jiajun and Luo, Ping},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Watch Only Once: An End-to-End Video Action Detection Framework}, 
  year={2021},
  volume={},
  number={},
  pages={8158-8167},
  abstract={We propose an end-to-end pipeline, named Watch Once Only (WOO), for video action detection. Current methods either decouple video action detection task into separated stages of actor localization and action classification or train two separated models within one stage. In contrast, our approach solves the actor localization and action classification simultaneously in a unified network. The whole pipeline is significantly simplified by unifying the backbone network and eliminating many hand-crafted components. WOO takes a unified video backbone to simultaneously extract features for actor location and action classification. In addition, we introduce spatial-temporal action embeddings into our framework and design a spatial-temporal fusion module to obtain more discriminative features with richer information, which further boosts the action classification performance. Extensive experiments on AVA and JHMDB datasets show that WOO achieves state-of-the-art performance, while still reduces up to 16.7% GFLOPs compared with existing methods. We hope our work can inspire re-thinking the convention of action detection and serve as a solid baseline for end-to-end action detection. Code is available at https://github.com/ShoufaChen/WOO.},
  keywords={Location awareness;Computer vision;Computational modeling;Pipelines;Detectors;Predictive models;Feature extraction;Video analysis and understanding},
  doi={10.1109/ICCV48922.2021.00807},
  ISSN={2380-7504},
  month={Oct},}@ARTICLE{7529075,
  author={Cao, Bin and Wang, Jiaxing and Fan, Jing and Yin, Jianwei and Dong, Tianyang},
  journal={IEEE Transactions on Services Computing}, 
  title={Querying Similar Process Models Based on the Hungarian Algorithm}, 
  year={2017},
  volume={10},
  number={1},
  pages={121-135},
  abstract={The structural similarity between two process models is usually considered as the main measurement for ranking the process models for a given query model. Current process query methods are inefficient since too many expensive computations of the graph edit distance are involved. To address this issue, using Petri-net as the modeling method, this paper presents the Hungarian algorithm based similarity query method. Unlike previous work where the non-task nodes (i.e., place nodes in the Petri-net) were lightly studied or even ignored, we think these non-task nodes also play an essential role in measuring the structural similarity between process models. First, we extract the context for each place and define the similarity for a pair of place nodes that are from different process models from two perspectives: commonality and the graph edit distance. Then, the place mapping is transformed to classical assignment problem that can be solved by Hungarian algorithm efficiently. Furthermore, we propose a new process similarity measurement on the basis of the place similarity. The extensive experimental evaluation shows that our Hungarian based methods outperform the baseline algorithm in both retrieval quality and query response time.},
  keywords={Context;Computational modeling;Petri nets;Context modeling;Query processing;Companies;Process models;hungarian algorithm;structural similarity;query processing;petri net},
  doi={10.1109/TSC.2016.2597143},
  ISSN={1939-1374},
  month={Jan},}@INPROCEEDINGS{10205335,
  author={Lin, Haojia and Zheng, Xiawu and Li, Lijiang and Chao, Fei and Wang, Shanshan and Wang, Yan and Tian, Yonghong and Ji, Rongrong},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Meta Architecture for Point Cloud Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={17682-17691},
  abstract={Recent advances in 3D point cloud analysis bring a diverse set of network architectures to the field. However, the lack of a unified framework to interpret those networks makes any systematic comparison, contrast, or analysis challenging, and practically limits healthy development of the field. In this paper, we take the initiative to explore and propose a unified framework called PointMeta, to which the popular 3D point cloud analysis approaches could fit. This brings three benefits. First, it allows us to compare different approaches in a fair manner, and use quick experiments to verify any empirical observations or assumptions summarized from the comparison. Second, the big picture brought by PointMeta enables us to think across different components, and revisit common beliefs and key design decisions made by the popular approaches. Third, based on the learnings from the previous two analyses, by doing simple tweaks on the existing approaches, we are able to derive a basic building block, termed PointMetaBase. It shows very strong performance in efficiency and effectiveness through extensive experiments on challenging benchmarks, and thus verifies the necessity and benefits of high-level interpretation, contrast, and comparison like PointMeta. In particular, PointMetaBase surpasses the previous state-of-the-art method by 0.7%/1.4/%2.1% mIoU with only 2%/11%/13% of the computation cost on the S3DIS datasets. The code and models are available at https://github.com/linhaojia13/PointMetaBase.},
  keywords={Point cloud compression;Analytical models;Three-dimensional displays;Systematics;Computational modeling;Architecture;Search methods;3D from multi-view and sensors},
  doi={10.1109/CVPR52729.2023.01696},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{7580833,
  author={Bellini, Emanuele and Nesi, Paolo and Pantaleo, Gianni and Venturi, Alessandro},
  booktitle={2016 IEEE International Smart Cities Conference (ISC2)}, 
  title={Functional resonance analysis method based-decision support tool for urban transport system resilience management}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={Today, managing critical infrastructure resilience in smart city is a challenge that can be undertaken by adopting a new class of smart tools, which are able to integrate modeling capability with evidence driven decision support. The Resilience Decision Support tool, as presented in this article, is an innovative and powerful tool that aims at managing critical infrasctructure resilience through a more complex and expressive model based on the Functional Resonance Analysis Method and through the connection of such a model with a system thinking based decision support tool exploiting smart city data. Thanks to ResilienceDS, FRAM model becomes computable and the functional variability that is at the core of the resilience analysis can be quantified. Such quantification allows the decision support tool to compute specific strategies and recommendations for variability dampening at strategic, tactic and operational stage. The solution has been developed in the context of RESOLUTE H2020 project of the European Commission.},
  keywords={Random access memory;Ferroelectric films;Nonvolatile memory;Computational modeling;Resilience;Analytical models;Decision support systems;smart city;Functional Resonance Analysis Method;Decision Support System;Resilience;Urban Stransport System},
  doi={10.1109/ISC2.2016.7580833},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{1261500,
  author={Riley and Riley},
  booktitle={Proceedings of the 2003 Winter Simulation Conference, 2003.}, 
  title={SPADES - a distributed agent simulation environment with software-in-the-loop execution}, 
  year={2003},
  volume={1},
  number={},
  pages={817-825 Vol.1},
  abstract={Simulations are used extensively for studying artificial intelligence. However, the simulation technology in use by and designed for the artificial intelligence community often fails to take advantage of much of the work by the larger simulation community to produce distributed, repeatable, and efficient simulations. We present the system for parallel agent discrete event simulation, (SPADES), which is a simulation environment for the artificial intelligence community. SPADES focuses on the agent as a fundamental simulation component. The thinking time of an agent is tracked and reflected in the results of the agents' actions by using a software-in-the-loop mechanism. SPADES supports distributed execution of the agents across multiple systems, while at the same time producing repeatable results regardless of network or system load. We discuss the design of SPADES and give experimental results. SPADES is flexible enough for a variety of application domains in the artificial intelligence research community.},
  keywords={Computational modeling;Artificial intelligence;Discrete event simulation;Computer simulation;Design engineering;Concurrent computing;Distributed computing;Computer science;Machine learning;Educational institutions},
  doi={10.1109/WSC.2003.1261500},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{894685,
  author={Traver, V.J. and del Pobil, A.P. and Perez-Francisco, M.},
  booktitle={Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113)}, 
  title={Making service robots human-safe}, 
  year={2000},
  volume={1},
  number={},
  pages={696-701 vol.1},
  abstract={This paper first reviews the literature about the very important but neglected issue of safety in service-robots applications. Most of the few existing approaches are limited because they lack flexibility. We argue that human-tailored safety schemes are greatly needed, and propose two strategies in the line we think human-safe robots should be conceived. A fast method to derive the robot's incremental movements given a workspace force applied to the robot constitutes the basis of the robot behaviors that underlie the proposed strategies. Our simulations show that our strategies are safe, human-friendly and exhibit real-time performance. Finally, we discuss the many ways in which our work can be extended.},
  keywords={Service robots;Safety;Humans;Intelligent robots;Industrial accidents;Machinery;Laboratories;Computational modeling;Computer science;Injuries},
  doi={10.1109/IROS.2000.894685},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9725687,
  author={Gupta, Ashulekha and Parmar, Rishabh and Suri, Pradeep and Kumar, Rajiv},
  booktitle={2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Determining Accuracy Rate of Artificial Intelligence Models using Python and R-Studio}, 
  year={2021},
  volume={},
  number={},
  pages={889-894},
  abstract={Research investigation in this study, an Artificial-Neural-Network (ANN) castoff to conjecture monetary market conduct. Our primary objective is to build up a neural system to see whether a stock pays a profit or not utilizing RStudio and Python. We propose and execute Artificial Neural Network to estimate monetary market conduct. This apparatus can be utilized for top to bottom examination of the securities exchange. Utilizing ANN, we foresee the reliance of the needy variable profit on the other autonomous factors like free income per share (fcfps), profit development, obligation to value proportion (de), showcase capitalization (mcap), and current proportion. We have prepared the neural system utilizing the neuralnet library and tried the precision of the model. We make the perplexity framework to think about the true/false positives and negatives. We yield an exactness rate of the neural system that estimate in deciding if a stock pays a profit or not.},
  keywords={Computational modeling;Artificial neural networks;Data models;Libraries;Security;Artificial intelligence;Logistics;Artificial neural network;stock market;machine learning;BSE},
  doi={10.1109/ICAC3N53548.2021.9725687},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{215383,
  author={Barrington, D.A.M.},
  booktitle={[1992] Proceedings of the Seventh Annual Structure in Complexity Theory Conference}, 
  title={Quasipolynomial size circuit classes}, 
  year={1992},
  volume={},
  number={},
  pages={86-93},
  abstract={Circuit complexity theory has tried to understand which problems can be solved by 'small' circuits of constant depth. Normally 'small' has meant 'polynomial in the input size', but a number of recent results have dealt with circuits of size 2 to the log n/sup 0(1)/ power, or quasipolynomial size. The author summarizes the reasons for thinking about the complexity classes so introduced, surveys these results and gives an overview of these classes. He also shows that the Barrington-Immerman-Straubing uniformity definition for polynomial-size classes can easily be extended to quasipolynomial size as well, with most of the key results remaining true in the uniform setting.<>},
  keywords={Polynomials;Turing machines;Computer science;Testing;Robustness;Computational modeling;Automata;Logic circuits},
  doi={10.1109/SCT.1992.215383},
  ISSN={},
  month={June},}@INPROCEEDINGS{5429423,
  author={Tako, Antuela A. and Robinson, Stewart},
  booktitle={Proceedings of the 2009 Winter Simulation Conference (WSC)}, 
  title={Comparing model development in Discrete Event Simulation and System Dynamics}, 
  year={2009},
  volume={},
  number={},
  pages={979-991},
  abstract={This paper provides an empirical study on the comparison of model building in Discrete-Event Simulation (DES) and System Dynamics (SD). Verbal Protocol Analysis (VPA) is used to study the model building process of ten expert modellers (5 SD and 5 DES). Participants are asked to build a simulation model based on a prison population case study and to think aloud while modelling. The generated verbal protocols are divided into 7 modelling topics: problem structuring, conceptual modelling, data inputs, model coding, validation & verification, results & experimentation and implementation and then analyzed. Our results suggest that all modellers switch between modelling topics, however DES modellers follow a more linear progression compared to SD modellers. DES modellers focus significantly more on model coding and verification & validation, whereas SD modellers on conceptual modelling. This quantitative analysis of the processes followed by expert modellers contributes towards the comparison of DES and SD modelling.},
  keywords={Discrete event simulation;Protocols;Computational modeling;Switches;Buildings;Analytical models;Computer simulation;Stochastic processes;Statistical distributions;Problem-solving},
  doi={10.1109/WSC.2009.5429423},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6883402,
  author={Xu, Chuan and Zhao, Guofeng and Xie, Gaogang and Yu, Shui},
  booktitle={2014 IEEE International Conference on Communications (ICC)}, 
  title={Detection on application layer DDoS using random walk model}, 
  year={2014},
  volume={},
  number={},
  pages={707-712},
  abstract={Application Layer Distributed Denial of Service (ALDDoS) attacks have been increasing rapidly with the growth of Botnets and Ubiquitous computing. Differentiate to the former DDoS attacks, ALDDoS attacks cannot be efficiently detected, as attackers always adopt legitimate requests with real IP address, and the traffic has high similarity to legitimate traffic. In spite of that, we think, the attackers' browsing behavior will have great disparity from that of the legitimate users'. In this paper, we put forward a novel user behavior-based method to detect the application layer asymmetric DDoS attack. We introduce an extended random walk model to describe user browsing behavior and establish the legitimate pattern of browsing sequences. For each incoming browser, we observe his page request sequence and predict subsequent page request sequence based on random walk model. The similarity between the predicted and the observed page request sequence is used as a criterion to measure the legality of the user, and then attacker would be detected based on it. Evaluation results based on real collected data set has demonstrated that our method is very effective in detecting asymmetric ALDDoS attacks.},
  keywords={Computer crime;Vectors;Probability distribution;Predictive models;Educational institutions;Computational modeling;Information systems;Asymmetric application layer DDoS attack;anomaly detection;random walk model;similarity},
  doi={10.1109/ICC.2014.6883402},
  ISSN={1938-1883},
  month={June},}@ARTICLE{895188,
  author={Goel, A. and Baker, C.A. and Shaffer, C.A. and Grossman, B. and Mason, W.H. and Watson, L.T. and Haftka, R.T.},
  journal={Computing in Science & Engineering}, 
  title={VizCraft: a problem-solving environment for aircraft configuration design}, 
  year={2001},
  volume={3},
  number={1},
  pages={56-66},
  abstract={The VizCraft problem-solving environment aids aircraft designers during conceptual design of a high-speed civil transport (HSCT). It integrates simulation codes that evaluate a design with visualizations for analyzing a design individually or in contrast to other designs. VizCraft provides a graphical user interface to a widely used suite of simulation and analysis codes for HSCT design, and it provides tools for visualizing the outputs of these codes. So, VizCraft provides an environment that combines visualization and computation, encouraging the designer to think in terms of the overall problem-solving task, not simply using the visualization to view the computation's results.},
  keywords={Problem-solving;Aerodynamics;Data visualization;Computational modeling;Analytical models;Geometry;Aircraft propulsion;Graphical user interfaces;Solid modeling;Multidimensional systems},
  doi={10.1109/5992.895188},
  ISSN={1558-366X},
  month={Jan},}@ARTICLE{9666041,
  author={Yang, Howard H. and Chen, Zihan and Quek, Tony Q. S. and Poor, H. Vincent},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Revisiting Analog Over-the-Air Machine Learning: The Blessing and Curse of Interference}, 
  year={2022},
  volume={16},
  number={3},
  pages={406-419},
  abstract={We study a distributed machine learning problem carried out by an edge server and multiple agents in a wireless network. The objective is to minimize a global function that is a sum of the agents’ local loss functions. And the optimization is conducted by analog over-the-air model training. Specifically, each agent modulates its local gradient onto a set of waveforms and transmits to the edge server simultaneously. From the received analog signal the edge server extracts a noisy aggregated gradient which is distorted by the channel fading and interference, and uses it to update the global model and feedbacks to all the agents for another round of local computing. Since the electromagnetic interference generally exhibits a heavy-tailed intrinsic, we use the $\alpha$-stable distribution to model its statistic. In consequence, the global gradient has an infinite variance that hinders the use of conventional techniques for convergence analysis that rely on second-order moments’ existence. To circumvent this challenge, we take a new route to establish the analysis of convergence rate, as well as generalization error, of the algorithm. We also show that the training algorithm can be run in tandem with the momentum scheme to accelerate the convergence. Our analyses reveal a two-sided effect of the interference on the overall training procedure. On the negative side, heavy tail noise slows down the convergence rate of the model training: the heavier the tail in the distribution of interference, the slower the algorithm converges. On the positive side, heavy tail noise has the potential to increase the generalization power of the trained model: the heavier the tail, the better the model generalizes. This perhaps counterintuitive conclusion implies that the prevailing thinking on interference – that it is only detrimental to the edge learning system – is outdated and we shall seek new techniques that exploit, rather than simply mitigate, the interference for better machine learning in wireless networks.},
  keywords={Servers;Interference;Training;Convergence;Computational modeling;Machine learning;Fading channels;Distributed machine learning;analog over-the-air computing;heavy-tailed interference;convergence rate;generalization error},
  doi={10.1109/JSTSP.2021.3139231},
  ISSN={1941-0484},
  month={April},}@INPROCEEDINGS{9667644,
  author={Durgapal, Ayushman and Vimal, Vrince},
  booktitle={2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Prediction of Stock Price Using Statistical and Ensemble learning Models: A Comparative Study}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Prediction of the stock price has always been a challenging task due to irregular patterns of the market. Uncertainty has made researchers think of some new and robust predictive methods. Many studies are available in the literature, with many models to predict the stock price accurately. Statistical, machine learning, deep learning, and other related approaches can create a predictive model. ARIMA model is the most commonly used statistical model for time series prediction. But ensemble learning techniques have not been explored much to predict future stock price. So, the present study stresses comparing statistical methods with ensemble learning methods. This paper compares the ARIMA, Random Forest, and Extreme Gradient Boosting models based on root mean squared error (RMSE) and mean absolute percentage error (MAPE). The subject chosen is Google’s stocks, and the data used is from NASDAQ stock exchange. The analysis results show that the ARIMA model performed fairly well for short-term predictions but relatively high MAPE value. The extreme gradient boosting model gave the best performance with the lowest RMSE and MAPE value. Hence, it is evident that after proper hyperparameter tuning, ensemble learning techniques can be used to create robust stock price-prediction models.},
  keywords={Uncertainty;Computational modeling;Time series analysis;Predictive models;Boosting;Task analysis;Stock markets;Ensemble learning Models;ARIMA;Random Forest Model;Extreme gradient Boosting Model;Stock Price Prediction},
  doi={10.1109/UPCON52273.2021.9667644},
  ISSN={2687-7767},
  month={Nov},}@INPROCEEDINGS{7004261,
  author={Jindal, Alekh and Madden, Samuel},
  booktitle={2014 IEEE International Conference on Big Data (Big Data)}, 
  title={GRAPHiQL: A graph intuitive query language for relational databases}, 
  year={2014},
  volume={},
  number={},
  pages={441-450},
  abstract={Graph analytics is becoming increasingly popular, driving many important business applications from social network analysis to machine learning. Since most graph data is collected in a relational database, it seems natural to attempt to perform graph analytics within the relational environment. However, SQL, the query language for relational databases, makes it difficult to express graph analytics operations. This is because SQL requires programmers to think in terms of tables and joins, rather than the more natural representation of graphs as collections of nodes and edges. As a result, even relatively simple graph operations can require very complex SQL queries. In this paper, we present GRAPHiQL, an intuitive query language for graph analytics, which allows developers to reason in terms of nodes and edges. GRAPHiQL provides key graph constructs such as looping, recursion, and neighborhood operations. At runtime, GRAPHiQL compiles graph programs into efficient SQL queries that can run on any relational database. We demonstrate the applicability of GRAPHiQL on several applications and compare the performance of GRAPHiQL queries with those of Apache Giraph (a popular `vertex centric' graph programming language).},
  keywords={Database languages;Relational databases;Aggregates;Engines;Computational modeling;Vectors},
  doi={10.1109/BigData.2014.7004261},
  ISSN={},
  month={Oct},}@ARTICLE{9507307,
  author={Hoque, Md Naimul and Mueller, Klaus},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Outcome-Explorer: A Causality Guided Interactive Visual Interface for Interpretable Algorithmic Decision Making}, 
  year={2022},
  volume={28},
  number={12},
  pages={4728-4740},
  abstract={The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this article, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.},
  keywords={Predictive models;Artificial intelligence;Data models;Biological system modeling;Computational modeling;Machine learning;Decision making;Human computer interaction;Explainable AI;causality;visual analytics;human-computer interaction},
  doi={10.1109/TVCG.2021.3102051},
  ISSN={1941-0506},
  month={Dec},}@ARTICLE{5978202,
  author={Yu, Yuanlong and Mann, George K. I. and Gosine, Raymond G.},
  journal={IEEE Transactions on Autonomous Mental Development}, 
  title={A Goal-Directed Visual Perception System Using Object-Based Top–Down Attention}, 
  year={2012},
  volume={4},
  number={1},
  pages={87-103},
  abstract={The selective attention mechanism is employed by humans and primates to realize a truly intelligent perception system, which has the cognitive capability of learning and thinking about how to perceive the environment autonomously. The attention mechanism involves the top-down and bottom-up ways that correspond to the goal-directed and automatic perceptual behaviors, respectively. Rather than considering the automatic perception, this paper presents an artificial system of the goal-directed visual perception by using the object-based top-down visual attention mechanism. This cognitive system can guide the perception to an object of interest according to the current task, context and learned knowledge. It consists of three successive stages: preattentive processing, top-down attentional selection and post-attentive perception. The preattentive processing stage divides the input scene into homogeneous proto-objects, one of which is then selected by the top-down attention and finally sent to the post-attentive perception stage for high-level analysis. Experimental results of target detection in the cluttered environments are shown to validate this system.},
  keywords={Computational modeling;Visualization;Visual perception;Feature extraction;Probabilistic logic;Integrated circuits;Context;Cognitive visual perception;goal-directed;integrated competition hypothesis;object-based visual attention;top–down visual attention},
  doi={10.1109/TAMD.2011.2163513},
  ISSN={1943-0612},
  month={March},}@ARTICLE{87598,
  author={Kravitz, S.A. and Bryant, R.E. and Rutenbar, R.A.},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Massively parallel switch-level simulation: a feasibility study}, 
  year={1991},
  volume={10},
  number={7},
  pages={871-894},
  abstract={The feasibility of mapping the COSMOS switch-level simulator onto a computer with thousands of simple processors is addressed. COSMOS preprocesses transistor networks into Boolean behavioral models, capturing the switch-level behavior of a circuit in a set of Boolean formulas. A class of massively parallel computers and a mapping of COSMOS onto these computers are described. The factors affecting the performance of such a massively parallel simulator are discussed, including: the amount of parallelism in the simulation model, performance measures for massively parallel machines, and the impact of event scheduling on simulator performance. Compilation tools that automatically map a MOS circuit onto a massively parallel computer have been developed. Techniques for restructuring Boolean expressions for greater parallelism and mapping Boolean expressions for evaluation on massively parallel machines are described. Massively parallel switch-level simulation is illustrated by a pilot implementation on a 32k-processor Thinking Machines Connection Machine system.<>},
  keywords={Computational modeling;Concurrent computing;Circuit simulation;Discrete event simulation;Logic;Computer simulation;Parallel processing;Parallel machines;Communication switching;Switching circuits},
  doi={10.1109/43.87598},
  ISSN={1937-4151},
  month={July},}@ARTICLE{9911763,
  author={Sharma, Geetanjali and Joshi, Amit M.},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={SzHNN: A Novel and Scalable Deep Convolution Hybrid Neural Network Framework for Schizophrenia Detection Using Multichannel EEG}, 
  year={2022},
  volume={71},
  number={},
  pages={1-9},
  abstract={In the field of neuroscience, brain activity measurement and analysis are considered crucial areas. Schizophrenia (Sz) is a brain disorder that severely affects the thinking, behavior, and feelings of people worldwide. Thus, an accurate and rapid detection method is needed for proper care and quality treatment of the patients. Electroencephalography (EEG) is proved to be an efficient biomarker in Sz detection as it records brain activities. This article aims to improve the performance of EEG-based Sz detection using a deep-learning approach in remote applications. A hybrid deep-learning model identified as schizophrenia hybrid neural network (SzHNN), which is a combination of convolutional neural networks (CNNs) and long short-term memory (LSTM), has been proposed wherein the CNN for local feature extraction and LSTM for classification is utilized. In this article, the proposed model has been compared with several deep-learning and machine-learning-based models. All the models have been evaluated on two different datasets wherein dataset 1 consists of 19 subjects and dataset 2 consists of 16 subjects. The proposed model is also implemented with the Internet-of-Medical-Things (IoMT) framework for smart healthcare and remote-based applications. Several experiments have been conducted using various parametric settings on different frequency bands and different sets of electrodes on the scalp. Based on all the experiments, it is evident that the proposed hybrid model (SzHNN) provides the highest classification accuracy of 99.9% compared to other implemented models and existing models of previous papers. The proposed model overcomes the influence of different frequency bands and shows a better accuracy of 96.10% (dataset 1) and 91.00% (dataset 2) with only five electrodes. Subject-wise testing is also done for SzHNN, which proposes an accuracy of 90.11% and 89.60% for datasets 1 and 2, respectively.},
  keywords={Electroencephalography;Brain modeling;Feature extraction;Convolutional neural networks;Deep learning;Computational modeling;Medical services;Abnormal brain activity;electroencephalography (EEG);hybrid neural network;Internet of Medical Things (IoMT);schizophrenia (Sz)},
  doi={10.1109/TIM.2022.3212040},
  ISSN={1557-9662},
  month={},}@INPROCEEDINGS{4117798,
  author={Talcott, Carolyn},
  booktitle={Proceedings of the 2006 Winter Simulation Conference}, 
  title={Symbolic Modeling of Signal Transduction in Pathway Logic}, 
  year={2006},
  volume={},
  number={},
  pages={1656-1665},
  abstract={Pathway logic is a step towards a vision of symbolic systems biology. It is an approach to modeling cellular processes based on formal methods. In particular, formal executable models of processes such as signal transduction, metabolic pathways, and immune system cell-cell signaling are developed using the rewriting logic language Maude and a variety of formal tools are used to query these models. An important objective of Pathway Logic is to reflect the ways that biologists think about problems using informal models, and to provide bench biologists with tools for computing with and analyzing these models that are natural. In this paper we describe the pathway logic approach to the modeling and analysis of signal transduction, and the use of the pathway logic assistant tool to browse and query these models. The Rac1 signaling pathway is used to illustrate the concepts},
  keywords={Logic;Biological system modeling;Biological processes;Proteins;Systems biology;Signal processing;Biology computing;Predictive models;Cognitive science;Computational modeling},
  doi={10.1109/WSC.2006.322940},
  ISSN={1558-4305},
  month={Dec},}@ARTICLE{9459713,
  author={García-Holgado, Alicia and Vázquez-Ingelmo, Andrea and García-Peñalvo, Francisco J. and Conde, MªJosé Rodríguez},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Improvement of Learning Outcomes in Software Engineering: Active Methodologies Supported Through the Virtual Campus}, 
  year={2021},
  volume={16},
  number={2},
  pages={143-153},
  abstract={There are some subjects that are seen as a challenge by both students and teachers. One of these subjects is Software Engineering, where the novelty of its concepts and the need of applying abstract thinking need major efforts to understand new paradigms of design and development of information systems. Due to these difficulties, students face the subject with low motivation. The present work describes a series of teaching methodology changes carried out during the last three academic years, specially the implementation carried out during the 2017-18 year. The analysis of the results shows a high correlation between the students' participation and the success ratio of the subject by comparing the results obtained by students studying the active methodology in 2017-18 and the results for the academic year 2013-14.},
  keywords={Software engineering;Collaborative work;Software;Education;Conferences;Proposals;Computational modeling;Active methodology;collaborative learning;virtual campus;software engineering;PBL;technological ecosystem},
  doi={10.1109/RITA.2021.3089926},
  ISSN={1932-8540},
  month={May},}@INPROCEEDINGS{10075649,
  author={Brown, Eli T. and Yarlagadda, Sriram and Cook, Kristin A. and Chang, Remco and Endert, Alex},
  booktitle={2018 IEEE Workshop on Machine Learning from User Interaction for Visualization and Analytics (MLUI)}, 
  title={ModelSpace: Visualizing the Trails of Data Models in Visual Analytics Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-11},
  abstract={User interactions with visualization systems have been shown to encode a great deal of information about the the users’ thinking processes, and analyzing their interaction trails can teach us more about the users, their approach, and how they arrived at insights. This deeper understanding is critical to improving their experience and outcomes, and there are tools available to visualize logs of interactions. It can be difficult to determine the structurally interesting parts of interaction data, though, like what set of button clicks constitutes an action that matters. In the case of visual analytics systems that use machine learning models, there is a convenient marker of when the user has significantly altered the state of the system via interaction: when the model is updated based on new information. We present a method for numerical analytic provenance using high-dimensional visualization to show and compare the trails of these sequences of model states of the system. We evaluate this approach with a prototype tool, ModelSpace, applied to two case studies on experimental data from model-steering visual analytics tools. ModelSpace reveals individual user’s progress, the relationships between their paths, and the characteristics of certain regions of the space of possible models.},
  keywords={Human computer interaction;Analytical models;Visual analytics;Computational modeling;Conferences;Data visualization;Prototypes;Human-centered computing;Visualization;Visualization design and evaluation methods},
  doi={10.1109/MLUI52768.2018.10075649},
  ISSN={},
  month={Oct},}@ARTICLE{6579596,
  author={Salako, Kizito and Strigini, Lorenzo},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={When Does "Diversity"' in Development Reduce Common Failures? Insights from Probabilistic Modeling}, 
  year={2014},
  volume={11},
  number={2},
  pages={193-206},
  abstract={Fault tolerance via diverse redundancy, with multiple "versions"' of a system in a redundant configuration, is an attractive defence against design faults. To reduce the probability of common failures, development and procurement practices pursue "diversity"' between the ways the different versions are developed. But difficult questions remain open about which practices are more effective to this aim. About these questions, probabilistic models have helped by exposing fallacies in "common sense" judgements. However, most make very restrictive assumptions. They model well scenarios in which diverse versions are developed in rigorous isolation from each other: A condition that many think desirable, but is unlikely in practice. We extend these models to cover nonindependent development processes for diverse versions. This gives us a rigorous way of framing claims and open questions about how best to pursue diversity, and about the effects--negative and positive--of commonalities between developments, from specification corrections to the choice of test cases. We obtain three theorems that, under specific scenarios, identify preferences between alternative ways of seeking diversity. We also discuss nonintuitive issues, including how expected system reliability may be improved by creating intentional "negative"' dependences between the developments of different versions.},
  keywords={Phase frequency detector;Software;Reliability;Random variables;Computational modeling;Correlation;Probabilistic logic;Common-mode failure;software diversity;fault tolerance;multiversion software;probability of failure on demand;reliability},
  doi={10.1109/TDSC.2013.32},
  ISSN={1941-0018},
  month={March},}@INPROCEEDINGS{6328190,
  author={Cocco, Luisanna and Mannaro, Katiuscia and Concas, Giulio},
  booktitle={2012 38th Euromicro Conference on Software Engineering and Advanced Applications}, 
  title={A Model for Global Software Development with Cloud Platforms}, 
  year={2012},
  volume={},
  number={},
  pages={446-452},
  abstract={Cloud Computing (CC) is a technological phenomenon that is becoming more and more important. Also Small and Medium Enterprises (SMEs) can increase their competitiveness by taking advantage of CC. This new computing approach promises to provide many advantages, and many SMEs are encouraged to use it. However, CC is still in its early stage - for this reason we think that it is very important to study and assess its impact on SMEs' management processes. In this paper we propose a model for studying how Global Software Development can be facilitated using Cloud development environments, compared to a more traditional development environment. We use system dynamics to model and simulate how effective Cloud-based software development environments are for Global Software Development performed by a SMEs. Both studied environments assume a development process based on Scrum agile methodology. The proposed model could be used as a tool by the project managers to understand how Cloud Development Environments might facilitate Global Software Development.},
  keywords={Analytical models;Planning;Computational modeling;Cloud computing;Delay;Hardware;System Dynamics;Modeling;Simulation;Cloud System;Scrum;Global Software Development},
  doi={10.1109/SEAA.2012.67},
  ISSN={2376-9505},
  month={Sep.},}
