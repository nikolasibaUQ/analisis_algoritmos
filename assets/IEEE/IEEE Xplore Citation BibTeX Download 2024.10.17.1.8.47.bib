@INPROCEEDINGS{10238919,
  author={Walmsley, Robert and Ahmed, Rishad and Klumpner, Christian and Saleh, Beeond M.},
  booktitle={2023 IEEE International Electric Machines & Drives Conference (IEMDC)}, 
  title={An Optimisation Tool for Hybrid-Electric Aircraft Propulsion Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The requirement for reductions in CO2, NOX and noise emissions from aviation have come under great assiduity. The use of electric and hybrid-electric propulsion systems within aircraft offer potential performance and efficiency improvements, through reduced fuel consumption, reduced emissions, and reduction in noise. This work proposes a novel multidisciplinary simulation tool, capable of determining optimised propulsion system parameters for various measures of merit (MoM), based on preliminary or conceptual aircraft specifications. Overall power, control and drive system which is to be used within the propulsion systems of hybrid and / or all electric aircraft applications can be determined from the simulation tool. Using an initial sizing algorithm to consider aircraft with hybrid-electric propulsion systems, taking power-to-weight ratio (P/W), wing loading (W/S), and hybridisation of power, as inputs to a mission analysis, and performing an optimisation study to determine a MoM, it has been possible to expand on work in this field with the addition of a supplementary branch in the sizing methodology to include a sizing analysis for the components of an aircraft’s electric propulsion system. The designed program enables accurate sizing of powertrain, optimises overall masses, and allows rapid sizing with minimal computational expense.},
  keywords={Electric potential;Power control;Loading;Mechanical power transmission;Hybrid power systems;Fuels;Aircraft propulsion;Hybrid;Electric;Aircraft;Optimisation},
  doi={10.1109/IEMDC55163.2023.10238919},
  ISSN={},
  month={May},}@ARTICLE{6960872,
  author={Guruswami, Venkatesan and Xia, Patrick},
  journal={IEEE Transactions on Information Theory}, 
  title={Polar Codes: Speed of Polarization and Polynomial Gap to Capacity}, 
  year={2015},
  volume={61},
  number={1},
  pages={3-16},
  abstract={We prove that, for all binary-input symmetric memoryless channels, polar codes enable reliable communication at rates within an additive gap  $ \varepsilon > 0$  to the Shannon capacity with a block length, construction complexity, and decoding complexity, all bounded by a polynomial in  $1/ \varepsilon $ . Polar coding gives the first known explicit construction with rigorous proofs of all these properties; previous constructions were not known to achieve capacity with less than  $\exp (1/ \varepsilon )$  decoding complexity except for erasure channels. We establish the capacity-achieving property of polar codes via a direct analysis of the underlying martingale of conditional entropies, without relying on the martingale convergence theorem. This step gives rough polarization (noise levels  $\approx \varepsilon $  for the good channels), which can then be adequately amplified by tracking the decay of the channel Bhattacharyya parameters. Our effective bounds imply that polar codes can have block length (and encoding/decoding complexity) bounded by a polynomial in  $1/ \varepsilon $ . The generator matrix of such polar codes can be constructed in polynomial time by algorithmically computing an adequate approximation of the polarization process.},
  keywords={Decoding;Error probability;Polynomials;Entropy;Convergence;Complexity theory;Capacity planning;Information theory;error-correction codes;linear codes;Channel polarization;entropy;maximum likelihood decoding;symmetric capacity},
  doi={10.1109/TIT.2014.2371819},
  ISSN={1557-9654},
  month={Jan},}@ARTICLE{7365445,
  author={Cheraghchi, Mahdi and Guruswami, Venkatesan},
  journal={IEEE Transactions on Information Theory}, 
  title={Capacity of Non-Malleable Codes}, 
  year={2016},
  volume={62},
  number={3},
  pages={1097-1118},
  abstract={Non-malleable codes, introduced by Dziembowski et al., encode messages s in a manner, so that tampering the codeword causes the decoder to either output s or a message that is independent of s. While this is an impossible goal to achieve against unrestricted tampering functions, rather surprisingly non-malleable coding becomes possible against every fixed family P of tampering functions that is not too large (for instance, when I≤I 22αn for some α <; 1, where n is the number of bits in a codeword). In this paper, we study the capacity of non-malleable codes, and establish optimal bounds on the achievable rate as a function of the family size, answering an open problem from Dziembowski et al. Specifically, We prove that for every family P with IFI I≤I 22αn, there exist non-malleable codes against P with rate arbitrarily close to 1-α [this is achieved with high probability (w.h.p.) by a randomized construction]. We show the existence of families of size exp(nO(1)2αn) against which there is no non-malleable code of rate 1 - α (in fact this is the case w.h.p for a random family of this size). We also show that 1 - α is the best achievable rate for the family of functions, which are only allowed to tamper the first αn bits of the codeword, which is of special interest. As a corollary, this implies that the capacity of non-malleable coding in the split-state model (where the tampering function acts independently but arbitrarily on the two halves of the codeword, a model which has received some attention recently) equals 1/2. We also give an efficient Monte Carlo construction of codes of rate close to 1 with polynomial time encoding and decoding that is non-malleable against any fixed c > 0 and family P of size 2nc, in particular tampering functions with, say, cubic size circuits.},
  keywords={Encoding;Decoding;Monte Carlo methods;Computer science;Cryptography;Electronic mail;Probabilistic logic;Cryptography;cryptographic protocols;codes;privacy;data security;Cryptography;cryptographic protocols;codes;privacy;data security},
  doi={10.1109/TIT.2015.2511784},
  ISSN={1557-9654},
  month={March},}@INPROCEEDINGS{9576399,
  author={Broll, Brian and Lédeczi, Ákos and Stein, Gordon and Jean, Devin and Brady, Corey and Grover, Shuchi and Catete, Veronica and Barnes, Tiffany},
  booktitle={2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Removing the Walls Around Visual Educational Programming Environments}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={Many block-based programming environments have proven to be effective at engaging novices in learning programming. However, most restrict access to the outside world, limiting learners to commands and computing resources built in to the environment. Some allow learners to drag and drop files, connect to sensors and robots locally or issue HTTP requests. But in a world where most of the applications in our daily lives are distributed (i.e., their functionality depends on communicating with other programs or accessing resources and data on the internet), the lack of support for beginners to envision and create such distributed programs is a lost opportunity. This paper argues that it is not only feasible, but crucial, to create environments with simple yet powerful abstractions that open up distributed computing and other widely used but advanced computing concepts including networking, the Internet of Things, and cybersecurity to novices. By thus removing the walls around our environments, we can expand opportunities for learning considerably: programs can access a wealth of online data and web services, and communicate with other projects. Moreover, these changes can enable young learners to collaborate with each other during program construction whether they share their physical location or study remotely. Importantly, providing access to the wider world will also help counter widespread student perceptions that block-based environments are mere toys, and show that they are capable of creating compelling applications. The paper presents NetsBlox, a programming environment that supports these ideas and shows that tools can be designed to democratize access to powerful ideas in computing.},
  keywords={COVID-19;Visualization;Codes;Educational robots;Web services;Toy manufacturing industry;Distributed databases},
  doi={10.1109/VL/HCC51201.2021.9576399},
  ISSN={1943-6106},
  month={Oct},}@INPROCEEDINGS{8285247,
  author={Nembhard, Fitzroy and Carvalho, Marco and Eskridge, Thomas},
  booktitle={2017 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={A hybrid approach to improving program security}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={The security of computer programs and systems is a very critical issue. With the number of attacks launched on computer networks and software, businesses and IT professionals are taking steps to ensure that their information systems are as secure as possible. However, many programmers do not think about adding security to their programs until their projects are near completion. This is a major mistake because a system is as secure as its weakest link. If security is viewed as an afterthought, it is highly likely that the resulting system will have a large number of vulnerabilities, which could be exploited by attackers. One of the reasons programmers overlook adding security to their code is because it is viewed as a complicated or time-consuming process. This paper presents a tool that will help programmers think more about security and add security tactics to their code with ease. We created a model that learns from existing open source projects and documentation using machine learning and text mining techniques. Our tool contains a module that runs in the background to analyze code as the programmer types and offers suggestions of where security could be included. In addition, our tool fetches existing open source implementations of cryptographic algorithms and sample code from repositories to aid programmers in adding security easily to their projects.},
  keywords={Tools;Static analysis;Testing;Frequency measurement;Application security;Data models;Cybersecurity;hybrid;machine learning;text mining;code analysis},
  doi={10.1109/SSCI.2017.8285247},
  ISSN={},
  month={Nov},}@INBOOK{6299808,
  author={Thagard, Paul},
  booktitle={Computational Philosophy of Science}, 
  title={Pseudoscience}, 
  year={1993},
  volume={},
  number={},
  pages={157-173},
  abstract={This chapter contains sections titled: The Problem of Demarcation, Verifiability and Falsifiability, Resemblance Thinking, Resemblance Thinking and Pseudoscience, Progressiveness, Profiles of Science and Pseudoscience, Are the Cognitive Sciences Scientific?},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262284837},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/6299808},}@ARTICLE{9163107,
  author={Li, Jing and Yu, Ning},
  journal={IEEE Access}, 
  title={Key Technology of Virtual Roaming System in the Museum of Ancient High-Imitative Calligraphy and Paintings}, 
  year={2020},
  volume={8},
  number={},
  pages={151072-151086},
  abstract={To show the traditional Chinese painting and the spiritual culture of universities, highlight the artistic accumulation and cultural heritage, analyze the value and significance of digitalizing the Museum of Ancient High-Imitative Calligraphy and Painting, Qingdao Agricultural University (QAU) is regarded as the research object. The design principles of the digital museum are clarified by understanding the specific user needs, and the 3DS Max is utilized to develop a roaming system for the Museum of Ancient High-Imitative Calligraphy and Painting of QAU through Unity3d, a Virtual Reality (VR) software platform. Besides, the perspective control, collision detection of virtual characters and scenes, and control of pop-up information display windows are realized to achieve the interactive design of users and the QAU digital museum system. Finally, from the four aspects of resource content, information presentation, resource presentation, and learning effect, a comprehensive evaluation is conducted. The research results show that more than 80% of people think that the content satisfaction of virtual system resources is high, which is more scientific and accurate; more than 65% think that the information is presented better, and 87% think that the system is open enough; in addition, nearly one-third of the visitors believe that using the system can initiate their interest and motivation in learning. This shows that the learning and cultural communication effects of the virtual system are more obvious. This system realizes the objective of disseminating traditional classic art culture and values by new technical means, which has reference significance for research in other fields.},
  keywords={Solid modeling;Computational modeling;Painting;Three-dimensional displays;Data models;Cultural differences;Virtual reality;Virtual roaming;high-imitative calligraphy and painting;digital museum;digital system},
  doi={10.1109/ACCESS.2020.3015318},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9190872,
  author={Bhandari, Ayush and Krahmer, Felix},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, 
  title={HDR Imaging From Quantization Noise}, 
  year={2020},
  volume={},
  number={},
  pages={101-105},
  abstract={Quantization is an integral part of image acquisition but also a major performance bottleneck due to the trade-off between dynamic range and resolution. As we discuss in this paper, in contrast, quantization noise can be acquired reliably even beyond the dynamic range by re-purposing recent hardware development. In this paper, we introduce and mathematically analyze an algorithm to recover images from this information, thus giving rise to a novel, single-shot, high-dynamic-range (HDR) imaging approach. Our method directly works with a refined model for sensor outputs at the digitization stage and crucially exploits smoothing anti-aliasing artifacts. We derive recovery guarantees and demonstrate the validity of our approach via computer experiments. Our work suggests re-thinking of the imaging pipeline as seeming sensing artifacts can lead to improved reconstruction when combined with proper computational methodology.},
  keywords={Quantization (signal);Analog-to-digital;computational imaging;high-dynamic-range imaging;quantization;sampling;shift-invariant spaces.},
  doi={10.1109/ICIP40778.2020.9190872},
  ISSN={2381-8549},
  month={Oct},}@INPROCEEDINGS{9360881,
  author={Bauspieß, Pia and Kolberg, Jascha and Demmler, Daniel and Krämer, Juliane and Busch, Christoph},
  booktitle={2020 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Post-Quantum Secure Two-Party Computation for Iris Biometric Template Protection}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Thinking about the protection of biometric data, future attacks using a quantum computer call for adequate resistance of biometric verification systems. Such systems are often deployed on a long-term basis and deserve strong protection due to the sensitive nature and persistence property of the data they contain. To achieve efficient template protection, we combine post-quantum secure two-party computation with secret sharing and apply the first practically implemented post-quantum secure two-party computation protocol for the purpose of biometric template protection. The proposed system ensures permanent protection of the biometric data as templates are stored and compared in the encrypted domain. For the verification, we present two options which can be achieved as real-time transactions: A well-established classical two-party computation scheme or a recent post-quantum upgrade of that scheme. Both methods maintain full biometric performance. For the database of reference templates, which is a target for attacks in a biometric system, post-quantum security is maintained throughout both verification options. Regarding the computational efficiency of our proposed system, we offer real-time computational transaction times, making our solution relevant for practical applications.},
  keywords={Quantum computing;Protocols;Databases;Real-time systems;Computational efficiency;Secure storage;Iris recognition},
  doi={10.1109/WIFS49906.2020.9360881},
  ISSN={2157-4774},
  month={Dec},}@INPROCEEDINGS{6127523,
  author={From, Jeffrey and Perrin, Patrick and O'Neill, Daniel and Yen, John},
  booktitle={2011 - MILCOM 2011 Military Communications Conference}, 
  title={Supporting the Commander's information requirements: Automated support for Battle Drill processes using R-CAST}, 
  year={2011},
  volume={},
  number={},
  pages={1523-1528},
  abstract={This paper discusses a novel approach that addresses the problem of supporting the Commander's dynamic information requirements through automation of the Military Decision-Making Process (MDMP) for time-constrained environments and training purposes, as part of the Tactical Human Integration of Networked Knowledge (THINK) Army Technology Objective - Research (ATO-R) initiative. We demonstrate this capability with automated user support for the execution of battle drills. Our approach is based on adapting the R-CAST cognitively-inspired agent architecture towards a context-aware anticipation of information requirements. R-CAST is a computational model of the Recognition-Primed Decision (RPD) model, which models human decision making under time stress. R-CAST agents support and collaborate with human decision making teams as both “smart aids” and “effective teammates” by anticipating, investigating, seeking, and interpreting information relevant to decision making. A key feature of R-CAST is that the proactive sharing of information relevant to decision making is automatically generated by the computational RPD model. The fundamental research question being addressed is whether the inclusion of R-CAST in Army staff processes improves said staff understanding and execution of battle tasks. We adapted R-CAST to Battle Drill #26 (i.e., responding to an IED event) as a proof of concept for team decision making under stress and constant switching of modalities. We demonstrate that the use of R-CAST cognitive agents effectively assists the Battle Manager in the S3 cell with auto-filling certain forms required by doctrine in response to the dynamism of the current state of the environment, improving cognitive performance in this task. Our novel approach integrates relevant context in communication, information, and socio-cognitive networks, coupled with cognitive modeling. We report initial findings that we can use the R-CAST cognitive framework to effectively and efficiently develop individual intelligent training tools that understand and support the dynamic information requirements of Commanders.},
  keywords={Stress;User interfaces;Context;Humans;Decision making;Computer architecture;Computational modeling;MDMP automation;Battle Drill;R-CAST;Recognition-Primed Decision;Cognitive Agents;Information Requirements;Cognitive Performance},
  doi={10.1109/MILCOM.2011.6127523},
  ISSN={2155-7586},
  month={Nov},}@INPROCEEDINGS{6721999,
  author={Gaeta, Angelo and Ritrovato, Pierluigi and Salerno, Saverio and Loia, Vincenzo},
  booktitle={2013 IEEE International Conference on Systems, Man, and Cybernetics}, 
  title={Identifying Consonance Relationships between Worker and Organization for Fostering Creativity: A Knowledge Based Approach}, 
  year={2013},
  volume={},
  number={},
  pages={1425-1431},
  abstract={We present our preliminary results in the definition of a model and knowledge based techniques to support creativity by establishing consonance relationships between a worker and the organization. The model is based on the Viable Systems Approach (VSA) and links this theory with Creativity and Open innovation via the definition of proper consonance and resonance relationships. VSA is an interdisciplinary approach grounded on systems thinking and resource-based theory, and focused on methodologies to govern relations among supra-systems and subsystems. Leveraging on the systems perspective of the creativity proposed by Csikszentmihalyi, we defined a way to analyse and understand how the variety introduced by workers in organization can lead to novel and useful products and services. We present also our preliminary results on how a well-defined set of knowledge based methodologies and techniques, resulting from the ARISTOTELE research project, can be applied to this purpose in the context of a Gene lore model. We believe our proposal, i.e. the application of VSA methods combined with knowledge based techniques, can lead to substantial advantages in several areas of Computational Creativity.},
  keywords={Organizations;Technological innovation;Context;Knowledge based systems;Production facilities;Industries;Ontologies;creativity;knowledge discovery;Service Science;Viable System Approach;computational creativity},
  doi={10.1109/SMC.2013.246},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{10440725,
  author={Bangroo, Ishan Shivansh and Kumar, Ravi},
  booktitle={2023 9th International Conference on Signal Processing and Communication (ICSC)}, 
  title={Zérosdetect: Phishing URL Detection with Quantum-Driven Zero-shot Learning}, 
  year={2023},
  volume={},
  number={},
  pages={498-503},
  abstract={Phishing, a prevalent cyber danger in contemporary times, involves the fraudulent impersonation of legitimate websites with the intention of deceiving users into divulging confidential information. The insufficiency of classic phishing detection tools has become apparent as fraudsters continue to develop new strategies; these approaches mostly depend on variables such as URL character sequences, site content, and visual resemblance. The present study highlights the “Zérosdetect” approach, a quantum-powered technique for detecting phishing URLs using zero-shot learning, a robust model that makes use of both the zero-shot learning’s adaptability and the computational advantageous nature of quantum computing, it mitigates the need for extensive previous knowledge of phishing URL attributes. In order to detect previously undiscovered phishing attacks, quantum neural network have been deployed to convert URL data into quantum spaces, therefore using the computational benefits of quantum systems. Quantum layers embedded inside Qnodes are a key part of the present system, calculating gradients at a faster pace, optimizing the network performance by rapidly calculating gradients, making the solution both efficient and forward-thinking. The present study lays the groundwork for future cybersecurity initiatives in the era of quantum computing, enhancing the potential to predict new cases of phishing.},
  keywords={Uniform resource locators;Quantum system;Visualization;Quantum computing;Zero-shot learning;Phishing;Computational modeling;Quantum Computing •;Natural Language Processing •;Zero-Shot Learning •;Quantum Language Models •;Cybersecurity frameworks},
  doi={10.1109/ICSC60394.2023.10440725},
  ISSN={2643-444X},
  month={Dec},}@ARTICLE{10669809,
  author={Lang, Qi and Tian, Shengjing and Wang, Mo and Wang, Jianan},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Exploring the Answering Capability of Large Language Models in Addressing Complex Knowledge in Entrepreneurship Education}, 
  year={2024},
  volume={17},
  number={},
  pages={2107-2116},
  abstract={Entrepreneurship education is critical in encouraging students' innovation, creativity, and entrepreneurial spirit. It provides essential skills and knowledge, enabling them to open their creative potential and apply innovative thinking across diverse professional fields. With the widespread application of large language models in education, intelligent-assisted teaching in entrepreneurship education is stepping into a new learning phase anytime and anywhere. Entrepreneurship education extends across interdisciplinary knowledge fields, incorporating subjects like finance and risk management, which require advanced mathematical computational skills. This complexity presents new challenges for artificial-intelligence-assisted question-and-answer models. The study explores how students can maximize the knowledge repository of current large language models to improve learning efficiency and experimentally validates the performance differences between large language models and graph convolutional reasoning models regarding the complex semantic reasoning and mathematical computational demands in entrepreneurship education questions. Based on case studies, it is found that despite the broad prospects of large language models in entrepreneurship education, they still need to improve in practical applications. Especially in tasks within entrepreneurship education that demand precision, such as mathematical computations and risk assessment, the accuracy and efficiency of existing models still need improvement. Therefore, further exploration into algorithm optimization, model fusion, and other technical enhancements can improve the processing capabilities of intelligent question-and-answer systems for specific domain issues, aiming to meet the practical needs of entrepreneurship education.},
  keywords={Entrepreneurship;Education;Mathematical models;Large language models;Biological system modeling;Cognition;Computational modeling;Entrepreneurship education;intelligence-assisted teaching;large language models;math word problem;question-and-answer models},
  doi={10.1109/TLT.2024.3456128},
  ISSN={1939-1382},
  month={},}@ARTICLE{9906546,
  author={Lin, Jiali and Li, Qiaomei and Lin, Guangsheng and He, Zhihui and Jiang, Dazhi and Liu, Hao},
  journal={Complex System Modeling and Simulation}, 
  title={An Evolutionary Adaptive System for Prediction of Strategy Influence: A Case Study of Government Regulation Guided Brand Innovation}, 
  year={2022},
  volume={2},
  number={3},
  pages={197-212},
  abstract={Decision making is one of the common human activities. But in complex, interactive, and dynamic systems, it is extremely important to make decisions scientifically because the influence of the behavior after decision making is generally irreversible. The predictability of behavior influence is an effective way to improve the scientific decision making. As a new branch of computing, computational experiment is an emerging management method for research on complex systems. In this paper, based on particle swarm intelligence, an evolutionary adaptive system model of brand innovation in the toy industry cluster is constructed. By imitating the evolution process of the complex adaptive system, this method is helpful to analyze the impact of the management behavior brought to simulation system, predict the management behavior in real world, and finally choose the best management strategy. This simulation tried to figure out the affection of government regulation strategies and provide corresponding assessments and recommendations, which gives a new solution to assist the government to effectively judge the influence of the macro policy, as well as provides a new way of thinking of the related intelligent decision making.},
  keywords={Adaptation models;Technological innovation;Adaptive systems;Decision making;Government;Predictive models;Regulation;decision making;behavior influence;computational experiment;evolution adaptive system;brand innovation},
  doi={10.23919/CSMS.2022.0011},
  ISSN={2097-3705},
  month={Sep.},}@INPROCEEDINGS{5154064,
  author={Ono, Kenji and Nonaka, Jorji},
  booktitle={2008 Workshop on Ultrascale Visualization}, 
  title={Design of cooperative visualization environment with intensive data management in project lifecycle}, 
  year={2008},
  volume={},
  number={},
  pages={55-61},
  abstract={Scientific data processing and visualization of computational simulation data have played an important role in knowledge creation, and its transfer for the benefit of society, through scientific discovery and understanding of physical and chemical phenomena. Massively parallel processing architecture has greatly contributed to increase the computational power and to enlarge the scale of computation. This facilitated the generation of larger and larger amounts of data. To tackle this oncoming tsunami of data, we propose a post-processing system for large-scale data focusing on the idea that a post-processing system needs to be an assistant of the researchers thinking process. We present a probable design solution targeting continuous development, and the technologies for productivity improvement such as collaborative work and visualization. This paper describes the current development status of a post-processing system designed for the next-generation 10-petaflop supercomputer under development in Japan.},
  keywords={Data visualization;Environmental management;Project management;Concurrent computing;Data processing;Physics computing;Computational modeling;Chemical processes;Parallel processing;Computer architecture},
  doi={10.1109/ULTRAVIS.2008.5154064},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6113213,
  author={Yuen, Man-Ching and King, Irwin and Leung, Kwong-Sak},
  booktitle={2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing}, 
  title={A Survey of Crowdsourcing Systems}, 
  year={2011},
  volume={},
  number={},
  pages={766-773},
  abstract={Crowd sourcing is evolving as a distributed problem-solving and business production model in recent years. In crowd sourcing paradigm, tasks are distributed to networked people to complete such that a company's production cost can be greatly reduced. In 2003, Luis von Ahn and his colleagues pioneered the concept of "human computation", which utilizes human abilities to perform computation tasks that are difficult for computers to process. Later, the term "crowdsourcing" was coined by Jeff Howe in 2006. Since then, a lot of work in crowd sourcing has focused on different aspects of crowd sourcing, such as computational techniques and performance analysis. In this paper, we give a survey on the literature on crowd sourcing which are categorized according to their applications, algorithms, performances and datasets. This paper provides a structured view of the research on crowd sourcing to date.},
  keywords={Humans;Games;Production;Internet;Algorithm design and analysis;Computers;Encyclopedias;crowdsourcing;survey},
  doi={10.1109/PASSAT/SocialCom.2011.203},
  ISSN={},
  month={Oct},}@ARTICLE{9446528,
  author={Sandhu, Muhammad Moid and Khalifa, Sara and Jurdak, Raja and Portmann, Marius},
  journal={IEEE Internet of Things Journal}, 
  title={Task Scheduling for Energy-Harvesting-Based IoT: A Survey and Critical Analysis}, 
  year={2021},
  volume={8},
  number={18},
  pages={13825-13848},
  abstract={The Internet of Things (IoT) has important applications in our daily lives, including health and fitness tracking, environmental monitoring, and transportation. However, sensor nodes in IoT suffer from the limited lifetime of batteries resulting from their finite energy availability. A promising solution is to harvest energy from environmental sources, such as solar, kinetic, thermal, and radio-frequency (RF) waves, for perpetual and continuous operation of IoT sensor nodes. In addition to energy generation, recently energy harvesters have been used for context detection, eliminating the need for conventional activity sensors (e.g., accelerometers), saving space, cost, and energy consumption. Using energy harvesters for simultaneous sensing and energy harvesting enables energy positive sensing-an important and emerging class of sensors, which harvest more energy than required for context detection and the additional energy can be used to power other components of the system. Although simultaneous sensing and energy harvesting is an important step forward toward autonomous self-powered sensor nodes, the energy and information availability can be still intermittent, unpredictable, and temporally misaligned with various computational tasks on the sensor node. This article provides a comprehensive survey on task scheduling algorithms for the emerging class of energy harvesting-based sensors (i.e., energy positive sensors) to achieve the sustainable operation of IoT. We discuss inherent differences between conventional sensing and energy positive sensing and provide an extensive critical analysis for devising revised task scheduling algorithms incorporating this new class of sensors. Finally, we outline future research directions toward the implementation of autonomous and self-powered IoT.},
  keywords={Task analysis;Sensors;Internet of Things;Energy harvesting;Scheduling algorithms;Batteries;Solar heating;Energy harvesting;energy prediction;Internet of Things (IoT);sensing;task scheduling;ubiquitous computing;wearables},
  doi={10.1109/JIOT.2021.3086186},
  ISSN={2327-4662},
  month={Sep.},}@INPROCEEDINGS{8100058,
  author={Jain, Unnat and Zhang, Ziyu and Schwing, Alexander},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Creativity: Generating Diverse Questions Using Variational Autoencoders}, 
  year={2017},
  volume={},
  number={},
  pages={5415-5424},
  abstract={Generating diverse questions for given images is an important task for computational education, entertainment and AI assistants. Different from many conventional prediction techniques is the need for algorithms to generate a diverse set of plausible questions, which we refer to as creativity. In this paper we propose a creative algorithm for visual question generation which combines the advantages of variational autoencoders with long short-term memory networks. We demonstrate that our framework is able to generate a large set of varying questions given a single input image.},
  keywords={Visualization;Hidden Markov models;Training;Creativity;Artificial intelligence;Transforms},
  doi={10.1109/CVPR.2017.575},
  ISSN={1063-6919},
  month={July},}@ARTICLE{6389686,
  author={Schreck, Tobias and Keim, Daniel},
  journal={Computer}, 
  title={Visual Analysis of Social Media Data}, 
  year={2013},
  volume={46},
  number={5},
  pages={68-75},
  abstract={The application of visual analytics, which combines the advantages of computational knowledge discovery and interactive visualization, to social media data highlights the many benefits of this integrated approach. The Web extra at http://youtu.be/nhoq71gqyXE is a video demonstrating a prototype system for visual-interactive analysis of large georeferenced microblog datasets, describing the design of the system, and detailing its application to the VAST 2011 Challenge dataset. The dataset models an epidemic outbreak in a fictitious metropolitan area. The video shows how the system can detect the epidemic and analyze its development over time. The system was implemented by Juri Buchmueller, Fabian Maass, Stephan Sellien, Florian Stoffel, and Matthias Zieker at the University of Konstanz (they also produced this video). Further information on the system and the VAST challenge dataset can be found in E. Bertini et al., "Visual Analytics of Terrorist Activities Related to Epidemics," Proc. IEEE Conf. Visual Analytics Science and Technology (VAST 11), IEEE CS, pp. 329-330, 2011.},
  keywords={Media;Data visualization;Visual analytics;Data analysis;Data mining;Social network services;visual analytics;knowledge discovery;interactive data visualization;social media;text visualization;complex data},
  doi={10.1109/MC.2012.430},
  ISSN={1558-0814},
  month={May},}@ARTICLE{8759874,
  author={Ciani, Lorenzo and Guidi, Giulia and Patrizi, Gabriele},
  journal={IEEE Access}, 
  title={A Critical Comparison of Alternative Risk Priority Numbers in Failure Modes, Effects, and Criticality Analysis}, 
  year={2019},
  volume={7},
  number={},
  pages={92398-92409},
  abstract={Risk priority number (RPN) is a widely used approach, and it is a powerful means to assess the criticality of modes in a failure modes, effects, and criticality analysis (FMECA) worksheet. In the application of the traditional FMECA, the RPN is determined to rank the failure modes; however, the method has been criticized several times for having many drawbacks and weaknesses, such as the presence of gaps in the range of admissible values, the duplicates value provided by different combinations of the base factors, and the high sensitivity to small changes. This paper analyses and compares some alternative RPN formulation proposed in the literature to overcome these limits. This paper takes into account only the alternative RPN, which proposes a powerful solution without increasing the computational complexity and remaining coherent to the classical idea included in the international standard IEC 60812. In order to compare the advantages and disadvantages of these alternative RPNs, an FMECA was developed for a heating, ventilation, and air condition (HVAC) system in railway application. The critical analysis of the comparison can provide recommendations and suggestions regarding the choice of the alternative RPN based on the type of application. Finally, this paper takes into account the scales reduction of possible values related to the parameters (i.e., occurrence, severity, and detection), which influence the assessment of the RPN. This approach allows the designers to mitigate the drawbacks related to the full scale and provide an easier and faster assessment of the scores to evaluate the criticality analysis and prioritization.},
  keywords={Dispersion;Sensitivity;Histograms;IEC Standards;Indexes;FMECA;railway engineering;reliability theory;risk priority number},
  doi={10.1109/ACCESS.2019.2928120},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{1265259,
  author={Forte, A. and Guzdial, M.},
  booktitle={37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the}, 
  title={Computers for communication, not calculation: media as a motivation and context for learning}, 
  year={2004},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={As the skills that constitute literacy evolve to accommodate digital media, computer science education finds itself in a sorry state. While students are more in need of computational skills than ever, computer science suffers dramatically low retention rates and a declining percentage of women and minorities. Studies of the problem point to the overemphasis in computer science classes on abstraction over application, technical details instead of usability, and the stereotypical view of programmers as loners lacking creativity. In spring 2003, Georgia Institute of Technology trialed a new course, Introduction to Media Computation, which teaches programming and computation in the context of media creation and manipulation. Students implement PhotoShop-style filters and digital video special effects, splice sounds, and search Web pages. The course is open only to noncomputer science and nonengineering majors at Georgia Tech, such as liberal arts, management and architecture students. The course is supported through the use of a Web-based collaboration environment where students actively share and discuss their digital creations. The results have been dramatic. 120 students enrolled, 2/3 female, and only three students withdrew. By the end of the semester, the combined withdrawal, failure and D-grade rate had reached 11.5% - compared to 42.9% in the traditional introductory computer science course. 60% of the students who took media computation reported that they would be interested in taking an advanced version of the course; only 6% reported that they would otherwise be interested in taking more computer science. Results of the trial indicate that media computation motivates and engages an audience that is poorly served by traditional computer science courses.},
  keywords={Context;Computer science;Programming profession;Computer science education;Application software;Usability;Springs;Digital filters;Information filtering;Information filters},
  doi={10.1109/HICSS.2004.1265259},
  ISSN={},
  month={Jan},}@ARTICLE{6850242,
  author={Zoran, Amit and Shilkrot, Roy and Goyal, Pragun and Maes, Pattie and Paradiso, Joseph A.},
  journal={IEEE Pervasive Computing}, 
  title={The Wise Chisel: The Rise of the Smart Handheld Tool}, 
  year={2014},
  volume={13},
  number={3},
  pages={48-57},
  abstract={Smart handheld tools epitomize a mythical and technological quest for personal mastery of skill, delivering both might and mind in the hands of their holders. A recent spur of academic and industrial efforts has given rise to a new field of research in HCI, one devoted to smart handheld tools. Here, the authors offer a definition for smart handheld tools, discuss the tools' origins and motivation, and present a survey of prominent work by themselves and others in disciplines such as fabrication, painting, printing, and maintenance. They also discuss their experiences operating in this new territory and conclude with a vision of a hybrid creative practice: smart handheld instruments that enable synergetic cooperation with human skill, personal style, and computational assistance that results in accuracy, guidance, and protection for users. This article is part of a special issue on printing and fabrication.},
  keywords={Fabrication;Three-dimensional displays;Printing;Virtual manufacturing;Intelligent structures;Instruments;Handheld computers;handheld tools;digital fabrication;printing;craft;human-computer interaction (HCI);design;manual skill;pervasive computing;3D printing;graphics},
  doi={10.1109/MPRV.2014.59},
  ISSN={1558-2590},
  month={July},}@ARTICLE{7393831,
  author={Batrinca, Ligia and Mana, Nadia and Lepri, Bruno and Sebe, Nicu and Pianesi, Fabio},
  journal={IEEE Transactions on Multimedia}, 
  title={Multimodal Personality Recognition in Collaborative Goal-Oriented Tasks}, 
  year={2016},
  volume={18},
  number={4},
  pages={659-673},
  abstract={Incorporating research on personality recognition into computers, both from a cognitive as well as an engineering perspective, would facilitate the interactions between humans and machines. Previous attempts on personality recognition have focused on a variety of different corpora (ranging from text to audiovisual data), scenarios (interviews, meetings), channels of communication (audio, video, text), and different subsets of personality traits (out of the five ones from the Big Five Model). Our study uses simple acoustic and visual nonverbal features extracted from multimodal data, which have been recorded in previously uninvestigated scenarios, and consider all five personality traits and not just a subset. First, we look at the human-machine interaction scenario, where we introduce the display of different “collaboration levels.” Second, we look at the contribution of the human-human interaction (HHI) scenario on the emergence of personality traits. Investigating the HHI scenario creates a stronger basis for future human-agents interactions. Our goal is to study, from a computational approach, the emergence degree of the five personality traits in these two scenarios. The results demonstrate the relevance of each of the two scenarios when it comes to the degree of emergence of certain traits and the feasibility to automatically recognize personality under different conditions.},
  keywords={Feature extraction;Collaboration;Man machine systems;Context;Acoustics;Visualization;Data mining;Personality recognition;non-verbal behavior analysis;human-machine interaction;human-human interaction;Map Task;Human–human interaction (HHI);human–machine interaction;map task;non-verbal behavior analysis;personality recognition},
  doi={10.1109/TMM.2016.2522763},
  ISSN={1941-0077},
  month={April},}@ARTICLE{9453769,
  author={Catelani, Marcantonio and Ciani, Lorenzo and Galar, Diego and Guidi, Giulia and Matucci, Serena and Patrizi, Gabriele},
  journal={IEEE Access}, 
  title={FMECA Assessment for Railway Safety-Critical Systems Investigating a New Risk Threshold Method}, 
  year={2021},
  volume={9},
  number={},
  pages={86243-86253},
  abstract={This paper develops a Failure Mode, Effects and Criticality Analysis (FMECA) for a heating, ventilation and air conditioning (HVAC) system in railway. HVAC is a safety critical system which must ensure emergency ventilation in case of fire and in case of loss of primary ventilation functions. A study of the HVAC's critical areas is mandatory to optimize its reliability and availability and consequently to guarantee a low operation and maintenance cost. The first part of the paper describes the FMECA which is performed and reported to highlight the main criticalities of the HVAC system under analysis. Secondly, the paper deals with the problem of the evaluation of a threshold risk value, which can distinguish negligible and critical failure modes. Literature barely considers the problem of an objective risk threshold estimation. Therefore, a new analytical method based on finite difference is introduced to find a univocal risk threshold value. The method is then tested on two Risk Priority Number datasets related to the same HVAC. The threshold obtained in both cases is a good tradeoff between the risk mitigation and the cost investment for the corrective actions required to mitigate the risk level. Finally, the threshold obtained with the proposed method is compared with the methods available in literature. The comparison shows that the proposed finite difference method is a well-structured technique, with a low computational cost. Furthermore, the proposed approach provides results in line with the literature, but it completely deletes the problem of subjectivity.},
  keywords={HVAC;Rail transportation;Ventilation;Reliability;Safety;Maintenance engineering;Standards;Failure analysis;HVAC;railway safety;reliability;risk analysis},
  doi={10.1109/ACCESS.2021.3088948},
  ISSN={2169-3536},
  month={},}@ARTICLE{9613752,
  author={Angara, Prashanti Priya and Stege, Ulrike and MacLean, Andrew and Müller, Hausi A. and Markham, Tom},
  journal={IEEE Transactions on Quantum Engineering}, 
  title={Teaching Quantum Computing to High-School-Aged Youth: A Hands-On Approach}, 
  year={2022},
  volume={3},
  number={},
  pages={1-15},
  abstract={Quantum computing is aninterdisciplinary field that lies at the intersection of mathematics, quantum physics, and computer science, and finds applications in areas including optimization, machine learning, and simulation of chemical, physical, and biological systems. It has the potential to help solve problems that so far have no satisfying method solving them, and to provide significant speedup to solutions when compared with their best classical approaches. In turn, quantum computing may allow us to solve problems for inputs that so far are deemed practically intractable. With the computational power of quantum computers and the proliferation of quantum development kits, quantum computing is anticipated to become mainstream, and the demand for a skilled workforce in quantum computing is expected to increase significantly. Therefore, quantum computing education is ramping up. This article describes our experiences in designing and delivering quantum computing workshops for youth (Grades 9–12). We introduce students to the world of quantum computing in innovative ways, such as newly designed unplugged activities for teaching basic quantum computing concepts. We also take a programmatic approach and introduce students to the IBM Quantum Experience using Qiskit and Jupyter notebooks. Our contributions are as follows. First, we present creative ways to teach quantum computing to youth with little or no experience in science, technology, engineering, and mathematics areas; second, we discuss diversity and highlight various pathways into quantum computing from quantum software to quantum hardware; and third, we discuss the design and delivery of online and in-person motivational, introductory, and advanced workshops for youth.},
  keywords={Quantum computing;Quantum mechanics;Conferences;Qubit;Programming profession;Industries;Software;Computer science (CS) unplugged (CS Unplugged);education;entanglement;high-school-aged youth;measurement;qiskit;quantum computing;quantum computing games;quantum gates;quantum teleportation;qubit systems;superposition;teachers;training;workforce development},
  doi={10.1109/TQE.2021.3127503},
  ISSN={2689-1808},
  month={},}
