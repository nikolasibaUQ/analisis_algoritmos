@ARTICLE{8164418,
  author={Chen, Bo and Frank, Joachim},
  journal={Microscopy}, 
  title={Two promising future developments of cryo-EM: capturing short-lived states and mapping a continuum of states of a macromolecule}, 
  year={2016},
  volume={65},
  number={1},
  pages={69-79},
  abstract={The capabilities and application range of cryogenic electron microscopy (cryo-EM) method have expanded vastly in the last two years, thanks to the advances provided by direct detection devices and computational classification tools. We take this review as an opportunity to sketch out promising developments of cryo-EM in two important directions: (i) imaging of short-lived states (10–1000 ms) of biological molecules by using time-resolved cryo-EM, particularly the mixing-spraying method and (ii) recovering an entire continuum of coexisting states from the same sample by employing a computational technique called manifold embedding. It is tempting to think of combining these two methods, to elucidate the way the states of a molecular machine such as the ribosome branch and unfold. This idea awaits further developments of both methods, particularly by increasing the data yield of the time-resolved cryo-EM method and by developing the manifold embedding technique into a user-friendly workbench.},
  keywords={classification;manifold embedding;microfluidics;ribosome;time-resolved imaging;translation},
  doi={10.1093/jmicro/dfv344},
  ISSN={1477-9986},
  month={Feb},}@INPROCEEDINGS{8826801,
  author={Guo, Yida and Zhang, Cheng and Lu, Shaofeng},
  booktitle={IET Doctoral Forum on Biomedical Engineering, Healthcare, Robotics and Artificial Intelligence 2018 (BRAIN 2018)}, 
  title={A decision-making approach for semi-decentralized rail transit control system}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={At present, the primary control system in the field of rail transit is in the form of centralised control, which is based on the communication of the ground side system and the on-board side system. A central controller will play the role of information flow centre and has to afford a lot of computational loads when it needs to manage a large number of trains simultaneously. It is believed that with the development of artificial intelligence algorithms, the control system could be built based on a semi-decentralised multi-agent system (MAS). This paper proposes an innovative MAS system to enhance the decision-making of the rail transit control system. This proposed MAS includes several agents, e.g., train agents, station agents, and a central agent. A train agent can exchange information with other agents directly and make decisions based on the collected data. A case study is carried out to build a preliminary MAS for a rail transit control in Suzhou Metro. Compared with the centralised control system, this MAS can reduce the computational pressure of the central controller and improve the information exchange efficiency. The proposed method is expected to advance the thinking of how to achieve fully automated train control in the future.},
  keywords={Medical services;Safety;Artificial intelligence;Rails;Optimization;Rail transportation;Biomedical engineering;MULTI-AGENT;RAIL TRANSIT;DECISION APPROACH},
  doi={10.1049/cp.2018.1732},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9622328,
  author={},
  booktitle={2021 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={Hot Topic Day}, 
  year={2021},
  volume={},
  number={},
  pages={17-17},
  abstract={Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. RTSS 2021 features the Hot Topics Day (HTD) that highlights emerging research topics related to realtime systems. The HTD features a combination of workshops, special sessions, and tutorials. Unfortunately the uncertainties due to COVID-19 affected the number of proposed events during the HTD. Still, the 2021 HTD will welcome the following very interesting special session "Self-Adaptive Safety- and Mission-critical CPS: Wishful Thinking or Absolute Necessity?" Due to the increasing performance demands of mission- and safety-critical Cyber Physical Systems (CPS), these systems exhibit a rapidly growing complexity, manifested by an increasing number of (distributed) computational cores and application components connected via complex networks. However, with the growing complexity and interconnectivity of these systems, the chances of hardware failures as well as disruptions due to cyber-attacks will also quickly increase. System adaptivity, for example in the form of dynamically remapping of application components to processing cores, represents a promising technique to handle this challenging scenario. In this session, we address the (consequences of the) idea of deploying runtime adaptivity to mission and safety-critical CPS, yielding dynamically morphing systems, to establish robustness against computational hurdles, component failures, and cyberattacks. This special session reports some of the research findings of the European Union's Horizon 2020 research and innovation project ADMORPH (http://admorph.eu/).},
  keywords={Complexity theory;Uncertainty;Tutorials;Technological innovation;Runtime;Robustness;Real-time systems},
  doi={10.1109/RTSS52674.2021.00009},
  ISSN={2576-3172},
  month={Dec},}@INPROCEEDINGS{10343283,
  author={Walker, Justice T. and Barany, Amanda and Acquah, Alex and Reza, Sayed Mohsin and Barrera, Alan and Del Rio Guzman, Karen and Johnson, Michael A.},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Coding Like a Data Miner: A Sandbox Approach to Computing-Based Data Science for High School Student Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Personal health tracking devices and internet-based digital platforms with the capacity to collect, aggregate, and store data at massive scales are examples of tools that have broadened priorities in computing to include data science. In response, there has been growing attention in research and practice emphasizing pre-college groups. This is partly because of the growing recognition-reflected in initiatives like CS4ALL, Code.org, Bootstrap: Data Science, Exploring Computer Science-that learning experiences before college are consequential in sustaining a robust pipeline of computer scientists and engineers. Despite these inroads, there is justifiable concern that existing efforts might not fully support learner development in the necessary conceptual, epistemological, and heuristic styles needed to productively parse and understand “big data.” This is because computing-based curricula that include data science often involve data curated by others (rather than learners directly), which results in simulated versions of practice instead of engagement that is realistically discursive and messy. This is further complicated by the persistent shortage of K-12 computer science teachers in general and even fewer who can design and implement curricula that support authentic engagement with data science. To address these issues, we leverage culturally relevant and constructionist perspectives in a sandbox (i.e., open-ended) science where tools like Scratch and electronic textiles (E-textiles) have had success expanding possibilities in computing to also include activities where learners can engage broadly along varied pursuits-and encounter challenges that spur computational thinking and problem-solving. The literature suggests that learning activities framed in this way encourage knowledge construction, practice literacies, and seriously impact learner attitudes, interest, and perceptions of growth in the field. This latter set of self-concept measures represents a few of many related key predictors of long-term field participation and persistence. In this work-in-progress scholarship of discovery research, we co-develop, with youth and educators, “Coding Like a Data Miner” (CLDM)-a sandbox approach to computing-based data science wherein learners access a social media platform, Twitter, to mine, analyze, and understand quantitative and qualitative data sources. In this preliminary work, we assess affordances in co-developing a curriculum that leverages sandbox approaches to data science. Ultimately (and what will be presented in our final submission), we aim to study learning outcomes when high school students' access, analyze and make sense of “big data” sets of their own. We collaborated with high school teachers in a West Texas/Paso Del Norte region where computer science educators are exceptionally scarce and where there is an urgent and persistent need to support underrepresented learner access to burgeoning areas of computing. Using mixed-methodological approaches (e.g., quantitative analysis of learner pre- and post-survey responses along with qualitative assessments of semi-structured interview data), we address the following research questions: (1) What affordances exist using co-design approaches to develop sandbox data science for pre-college learners? (2) Which computational concepts do students learn when carrying out CLDM activities, (3) Which computational practices do high school students enact when mining, processing, and analyzing big data sets in CLDM? (4) How do learner knowledge and perceptions about data science shift after participating in CLDM? We use contemporary perspectives in computing education, constructionism, and equity to discuss how open-ended sandbox approaches to computing-based data science support learner computational thinking, practice literacies, and field perceptions.},
  keywords={Computer science;Smart textiles;Social networking (online);Statistical analysis;Affordances;Soft sensors;Scholarships;Computer Science Education;Data Science Education;Constructionism;Curriculum Design;Computer Science Learning},
  doi={10.1109/FIE58773.2023.10343283},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{88101,
  author={Ayache, N. and Faugeras, O.D.},
  journal={IEEE Transactions on Robotics and Automation}, 
  title={Maintaining representations of the environment of a mobile robot}, 
  year={1989},
  volume={5},
  number={6},
  pages={804-819},
  abstract={A description is given of current ideas related to the problem of building and updating three-dimensional representations of the environment of a mobile robot that uses passive vision as its main sensory modality. The authors attempt to represent both geometry and uncertainty. The authors motivate their approach by defining the problems they are trying to solve and then give some simple didactic examples. They then present a tool they think is extremely well adapted to solving most of these problems: the extended Kalman filter (EKF). The authors discuss the notions of minimal geometric representations for three-dimensional lines, planes, and rigid motions. They show how the EKF and the representations can be combined to provide solutions for some of the problems. A number of experimental results on real data are given.<>},
  keywords={Mobile robots;Computational geometry;Uncertainty;Noise reduction;Position measurement;Information geometry;Computer vision;Stereo vision;Motion analysis;Sonar},
  doi={10.1109/70.88101},
  ISSN={2374-958X},
  month={Dec},}@ARTICLE{499793,
  author={Tani, J.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  title={Model-based learning for mobile robot navigation from the dynamical systems perspective}, 
  year={1996},
  volume={26},
  number={3},
  pages={421-436},
  abstract={This paper discusses how a behavior-based robot can construct a "symbolic process" that accounts for its deliberative thinking processes using models of the environment. The paper focuses on two essential problems; one is the symbol grounding problem and the other is how the internal symbolic processes can be situated with respect to the behavioral contexts. We investigate these problems by applying a dynamical system's approach to the robot navigation learning problem. Our formulation, based on a forward modeling scheme using recurrent neural learning, shows that the robot is capable of learning grammatical structure hidden in the geometry of the workspace from the local sensory inputs through its navigational experiences. Furthermore, the robot is capable of generating diverse action plans to reach an arbitrary goal using the acquired forward model which incorporates chaotic dynamics. The essential claim is that the internal symbolic process, being embedded in the attractor, is grounded since it is self-organized solely through interaction with the physical world. It is also shown that structural stability arises in the interaction between the neural dynamics and the environmental dynamics, which accounts for the situatedness of the internal symbolic process, The experimental results using a mobile robot, equipped with a local sensor consisting of a laser range finder, verify our claims.},
  keywords={Mobile robots;Navigation;Robot sensing systems;Grounding;Solid modeling;Computational geometry;Chaos;Structural engineering;Laser stability;Laser theory},
  doi={10.1109/3477.499793},
  ISSN={1941-0492},
  month={June},}@ARTICLE{8585034,
  author={Cao, Y. and Romero, J. and Aspuru-Guzik, A.},
  journal={IBM Journal of Research and Development}, 
  title={Potential of quantum computing for drug discovery}, 
  year={2018},
  volume={62},
  number={6},
  pages={6:1-6:20},
  abstract={Quantum computing has rapidly advanced in recent years due to substantial development in both hardware and algorithms. These advances are carrying quantum computers closer to their impending commercial utility. Drug discovery is a promising area of application that will find a number of uses for these new machines. As a prominent example, quantum simulation will enable faster and more accurate characterizations of molecular systems than existing quantum chemistry methods. Furthermore, algorithmic developments in quantum machine learning offer interesting alternatives to classical machine learning techniques, which may also be useful for the biochemical efforts involved in early phases of drug discovery. Meanwhile, quantum hardware is scaling up rapidly into a regime where an exact simulation is difficult even using the world’s largest supercomputers. We review how these recent advances can shift the paradigm with which one thinks about drug discovery, focusing on both the promises and caveats associated with each development. In particular, we highlight how hybrid quantum-classical approaches to quantum simulation and quantum machine learning could yield substantial progress using noisy-intermediate scale quantum devices, whereas fault-tolerant, error-corrected quantum computers are still in their development phase.},
  keywords={Quantum computing;Drugs;Proteins;Computers;Machine learning;Computational modeling},
  doi={10.1147/JRD.2018.2888987},
  ISSN={0018-8646},
  month={Nov},}@ARTICLE{8726069,
  author={Zeng, Deze and Gu, Lin and Pan, Shengli and Cai, Jingjing and Guo, Song},
  journal={IEEE Network}, 
  title={Resource Management at the Network Edge: A Deep Reinforcement Learning Approach}, 
  year={2019},
  volume={33},
  number={3},
  pages={26-33},
  abstract={With the advent of edge computing, it is highly recommended to extend some cloud services to the network edge such that the services can be provisioned in the proximity of end users, with better performance efficiency and cost efficiency. Compared to cloud computing, edge computing has high dynamics, and therefore the resources shall be correspondingly managed in an adaptive way. Traditional model-based resource management approaches are limited in practical application due to the involvement of some assumptions or prerequisites. We think it is desirable to introduce a model-free approach that can fit the network dynamics well without any prior knowledge. To this end, we introduce a model-free DRL approach to efficiently manage the resources at the network edge. Following the design principle of DRL, we design and implement a mobility- aware data processing service migration management agent. The experiments show that our agent can automatically learn the user mobility pattern and accordingly control the service migration among the edge servers to minimize the operational cost at runtime. Some potential future research challenges are also presented.},
  keywords={Resource management;Edge computing;Dynamic scheduling;Servers;Task analysis;Computational modeling},
  doi={10.1109/MNET.2019.1800386},
  ISSN={1558-156X},
  month={May},}@INPROCEEDINGS{6623561,
  author={Fuhr, Thomas and Jaulmes, Eliane and Lomné, Victor and Thillard, Adrian},
  booktitle={2013 Workshop on Fault Diagnosis and Tolerance in Cryptography}, 
  title={Fault Attacks on AES with Faulty Ciphertexts Only}, 
  year={2013},
  volume={},
  number={},
  pages={108-118},
  abstract={Classical Fault Attacks often require the ability to encrypt twice the same plaintext, in order to get one or several pairs of correct and faulty cipher texts corresponding to the same message. This observation led some designers to think that a randomized mode of operation may be sufficient to protect block cipher encryption against this kind of threat. In this paper, we consider the case where the adversary neither chooses nor knows the input messages, and has only access to the faulty cipher texts. In this context, we are able to describe several attacks against AES-128 by using non uniform fault models. Our attacks target the last 4 rounds and allow to recover the correct key with practical time complexity, using a limited number of faulty cipher texts. This work highlights the need for dedicated fault attack countermeasures in secure embedded systems.},
  keywords={Ciphers;Encryption;Mathematical model;Context;Computational modeling;Protocols;Fault Attacks;AES},
  doi={10.1109/FDTC.2013.18},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9123060,
  author={Qiu, Meikang and Qiu, Han},
  booktitle={2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)}, 
  title={Review on Image Processing Based Adversarial Example Defenses in Computer Vision}, 
  year={2020},
  volume={},
  number={},
  pages={94-99},
  abstract={Recent research works showed that deep neural networks are vulnerable to adversarial examples, which are usually maliciously created by carefully adding deliberate and imperceptible perturbations to examples. Several states of the art defense methods are proposed based on the existing image processing methods like image compression and image denoising. However, such approaches are not the final optimal solution for defense adversarial perturbations in DNN models. In this paper, we reviewed two main approaches to deploying image processing methods as a defense. By analyzing and discus!sing the remaining issues, we present two open questions for future research direction including the definition of adversarial perturbations and noises, the novel defense-aware threat model. A further research direction is also given by re-thinking the impacts of adversarial perturbations on all frequency bands.},
  keywords={Deep learning;Computer vision;Image coding;Perturbation methods;Computational modeling;Conferences;Robustness;Deep learning;adversarial examples;image denoising;image compression;computer vision},
  doi={10.1109/BigDataSecurity-HPSC-IDS49724.2020.00027},
  ISSN={},
  month={May},}@ARTICLE{1510539,
  author={Naps, T.L.},
  journal={IEEE Computer Graphics and Applications}, 
  title={JHAVE: supporting algorithm visualization}, 
  year={2005},
  volume={25},
  number={5},
  pages={49-55},
  abstract={JHAVE fosters the use of algorithm visualization as an effective pedagogical tool for computer science educators, helping students to better understand algorithms. The Java-hosted algorithm visualization environment (JHAVE) is not an AV system itself but rather a support environment for a variety of AV systems (called AV engines by JHAVE). In broad terms, JHAVE gives such an engine a drawing context on which it can render its pictures in any way. In return, JHAVE provides the engine with effortless ways to synchronize its graphical displays with i) a standard set of VCR-like controls, ii) information and pseudocode windows, iii) input generators, iv) stop-and-think questions, and v) meaningful content generation tools.},
  keywords={Visualization;Computer graphics;Computer science;Animation;Computer science education;Computer displays;Uniform resource locators;Materials science and technology;Computational modeling;Computer simulation;graphics;algorithm visualization;computer science education;active learning;active engagement},
  doi={10.1109/MCG.2005.110},
  ISSN={1558-1756},
  month={Sep.},}@INPROCEEDINGS{9004659,
  author={Shao, Guodong and Jain, Sanjay and Laroque, Christoph and Lee, Loo Hay and Lendermann, Peter and Rose, Oliver},
  booktitle={2019 Winter Simulation Conference (WSC)}, 
  title={Digital Twin for Smart Manufacturing: The Simulation Aspect}, 
  year={2019},
  volume={},
  number={},
  pages={2085-2098},
  abstract={The purpose of this panel is to discuss the state of the art in digital twin for manufacturing research and practice from the perspective of the simulation community. The panelists come from the US, Europe, and Asia representing academia, industry, and government. This paper begins with a short introduction to digital twins and then each panelist provides preliminary thoughts on concept, definitions, challenges, implementations, relevant standard activities, and future directions. Two panelists also report their digital twin projects and lessons learned. The panelists may have different viewpoints and may not totally agree with each other on some of the arguments, but the intention of the panel is not to unify researchers' thinking, but to list the research questions, initiate a deeper discussion, and try to help researchers in the simulation community with their future study topics on digital twins for manufacturing.},
  keywords={Data models;Manufacturing;Analytical models;Biological system modeling;Computational modeling;Standards;Virtual manufacturing},
  doi={10.1109/WSC40007.2019.9004659},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{9711074,
  author={Zhou, Ziqi and Qiu, Xi and Xie, Jiangtao and Wu, Jianan and Zhang, Chi},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Binocular Mutual Learning for Improving Few-shot Classification}, 
  year={2021},
  volume={},
  number={},
  pages={8382-8391},
  abstract={Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes under a global view by normal pretraining, or pay more attention to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture complementary information, we naturally think of the compatibility of them for achieving further performance gains. Inspired by the mutual learning paradigm and binocular parallax, we propose a unified framework, namely Binocular Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intraview and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the local class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual interaction further promotes the collaborative learning and the implicit exploration of useful knowledge from each other. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments conducted on multiple benchmarks including cross-domain validation confirm the effectiveness of our method1.},
  keywords={Learning systems;Degradation;Computer vision;Computational modeling;Decision making;Focusing;Performance gain;Transfer/Low-shot/Semi/Unsupervised Learning;Recognition and classification},
  doi={10.1109/ICCV48922.2021.00829},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{344301,
  author={Falsafi, B. and Lebeck, A.R. and Reinhardt, S.K. and Schoinas, I. and Hill, M.D. and Larus, J.R. and Rogers, A. and Wood, D.A.},
  booktitle={Supercomputing '94:Proceedings of the 1994 ACM/IEEE Conference on Supercomputing}, 
  title={Application-specific protocols for user-level shared memory}, 
  year={1994},
  volume={},
  number={},
  pages={380-389},
  abstract={Recent distributed shared memory (DSM) systems and proposed shared-memory machines have implemented some or all of their cache coherence protocols in software. One way to exploit the flexibility of this software is to tailor a coherence protocol to match an application's communication patterns and memory semantics. This paper presents evidence that this approach can lead to large performance improvements. It shows that application-specific protocols substantially improved the performance of three application programs-appbt, em3d, and barnes-over carefully tuned transparent shared memory implementations. The speed-ups were obtained on Blizzard, a fine-grained DSM system running on a 32-node Thinking Machines CM-5.<>},
  keywords={Access protocols;Hardware;Program processors;Distributed computing;Pattern matching;Parallel languages;Computational modeling;Concurrent computing;Sun;Protection},
  doi={10.1109/SUPERC.1994.344301},
  ISSN={},
  month={Nov},}@ARTICLE{8556046,
  author={Carmean, Douglas and Ceze, Luis and Seelig, Georg and Stewart, Kendall and Strauss, Karin and Willsey, Max},
  journal={Proceedings of the IEEE}, 
  title={DNA Data Storage and Hybrid Molecular–Electronic Computing}, 
  year={2019},
  volume={107},
  number={1},
  pages={63-72},
  abstract={Moore's law may be slowing, but our ability to manipulate molecules is improving faster than ever. DNA could provide alternative substrates for computing and storage as existing ones approach physical limits. In this paper, we explore the implications of this trend in computer architecture. We present a computer systems perspective on molecular processing and storage, positing a hybrid molecular-electronic architecture that plays to the strengths of both domains. We cover the design and implementation of all stages of the pipeline: encoding, DNA synthesis, system integration with digital microfluidics, DNA sequencing (including emerging technologies such as nanopores), and decoding. We first draw on our experience designing a DNA-based archival storage system, which includes the largest demonstration to date of DNA digital data storage of over three billion nucleotides encoding over 400 MB of data. We then propose a more ambitious hybrid-electronic design that uses a molecular form of near-data processing for massive parallelism. We present a model that demonstrates the feasibility of these systems in the near future. We think the time is ripe to consider molecular storage seriously and explore system designs and architectural implications.},
  keywords={Molecular computing;Memory;Sequential analysis;Substrates;Computer architecture;Market research;Computational modeling;Data storage systems;Future computer architectures;molecular data storage and computing},
  doi={10.1109/JPROC.2018.2875386},
  ISSN={1558-2256},
  month={Jan},}@ARTICLE{1093885,
  author={Ferguson, M.},
  journal={IEEE Transactions on Communications}, 
  title={An Approximate Analysis of Delay for Fixed and Variable Length Packets in an Unslotted ALOHA Channel}, 
  year={1977},
  volume={25},
  number={7},
  pages={644-654},
  abstract={In this paper we compute the mean delay for an unslotted ALOHA random access channel for both fixed and variable length packets. The analysis is based on the concept of a user cycle and obtains steady state results. When the channel is "stable", the results seem quite accurate. The input parameters to the model are the number of users, the mean think time, and mean retransmission time. The model yields total traffic, throughput and delay but only the latter is emphasized here. Because of the steady state nature of the analysis, no information is obtained on stability. The results are verified by simulation.},
  keywords={Throughput;Delay effects;Steady-state;Traffic control;Stability analysis;Communications Society;Monitoring;NASA;US Government;Computational modeling},
  doi={10.1109/TCOM.1977.1093885},
  ISSN={1558-0857},
  month={July},}@INPROCEEDINGS{5589539,
  author={Dugan, R. C. and Arritt, R. F. and McDermott, T. E. and Brahma, S. M. and Schneider, K.},
  booktitle={IEEE PES General Meeting}, 
  title={Distribution System Analysis to support the Smart Grid}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={The “Smart Grid” refers to various efforts to modernize the power grid through the application of intelligent devices. This paper describes current thinking by members of the Distribution System Analysis Subcommittee (DSA SC) on how distribution system analysis might evolve to support the Smart Grid. Various issues related to Smart Grid and distribution system analysis are identified. The essential characteristics of distribution system analysis tools to support these issues are discussed. Relevant activities of the DSA SC are described.},
  keywords={Smart grids;Load modeling;Integrated circuit modeling;Analytical models;Computational modeling;Planning;Monitoring;Power Distribution System Analysis;Smart grid},
  doi={10.1109/PES.2010.5589539},
  ISSN={1944-9925},
  month={July},}@ARTICLE{8395028,
  author={RichardWebster, Brandon and Anthony, Samuel E. and Scheirer, Walter J.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={PsyPhy: A Psychophysics Driven Evaluation Framework for Visual Recognition}, 
  year={2019},
  volume={41},
  number={9},
  pages={2280-2286},
  abstract={By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this article, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies.},
  keywords={Visualization;Computer vision;Computational modeling;Psychology;Task analysis;Machine learning;Observers;Object recognition;visual psychophysics;neuroscience;psychology;evaluation;deep learning},
  doi={10.1109/TPAMI.2018.2849989},
  ISSN={1939-3539},
  month={Sep.},}@ARTICLE{8665896,
  author={Shah, Syed Sarmad and Ali, Muhammad and Malik, Asad Waqar and Khan, Muazzam A. and Ravana, Sri Devi},
  journal={IEEE Access}, 
  title={vFog: A Vehicle-Assisted Computing Framework for Delay-Sensitive Applications in Smart Cities}, 
  year={2019},
  volume={7},
  number={},
  pages={34900-34909},
  abstract={The inception of the smart cities concept provides a compelling platform to support innovative applications. It provides distinctive view of cities, where mobile devices, pedestrians, and electronic gadgets can communicate with each other to build an effective urban environment to further improve the living standards. Similarly, the role of the Internet of Things (IoT) and vehicular computing has emerged due to smart cities. This is further complemented by edge and fog computing architectures. The emerging concept of vehicular fog computing has enabled the platform to support delay-sensitive applications and to reduce the workload on the backend networks. Vehicular fog computing is a paradigm that touches the boundaries of thinking vehicles as an infrastructures-as-a-service. The use of vehicles to provide computation on-the-move poses various challenges. The vehicles with onboard computing equipment can facilitate delay-sensitive applications. These vehicles can act as an edge device to reduce the load from a backbone network. However, due to continuous mobility, it is difficult to use traditional frameworks to distribute the computation task among vehicles. In this paper, we propose a framework termed vFog. The vFog is designed to provide computing facilities from nearby fog vehicles. The framework utilizes the onboard computing facility of vehicles without the support of roadside units (RSUs). Moreover, the proposed framework handles churn behavior and supports multi-hop communication to improve the task delivery ratio. The proposed framework allows researchers to benchmark their own task distribution algorithms over the dynamic vehicular networks.},
  keywords={Edge computing;Task analysis;Vehicular ad hoc networks;Processor scheduling;Smart cities;Servers;Computational modeling;Vehicular fog computing;tasks scheduling policy;edge devices;multi-vehicle relay},
  doi={10.1109/ACCESS.2019.2903302},
  ISSN={2169-3536},
  month={},}@ARTICLE{4049910,
  author={Cai, Xiaodong and Wang, Xiaodong},
  journal={IEEE Signal Processing Magazine}, 
  title={Stochastic modeling and simulation of gene networks - A review of the state-of-the-art research on stochastic simulations}, 
  year={2007},
  volume={24},
  number={1},
  pages={27-36},
  abstract={This paper provides a comprehensive review of the state-of-the-art research on stochastic simulations. It stimulates the interest of tackling the problem of stochastic simulation using statistical signal processing methods, as well as innovative thinking of stochastic modeling of gene networks from the viewpoint of signal processing},
  keywords={Stochastic processes;Computational modeling;Gene expression;RNA;Biological system modeling;Polymers;Computer networks;Working environment noise;Kinetic theory;DNA},
  doi={10.1109/MSP.2007.273051},
  ISSN={1558-0792},
  month={Jan},}@INPROCEEDINGS{9578518,
  author={Chandrasegaran, Keshigeyan and Tran, Ngoc-Trung and Cheung, Ngai-Man},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection}, 
  year={2021},
  volume={},
  number={},
  pages={7196-7205},
  abstract={CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to 99% accuracy across multiple state-of-the-art GAN models.In this work, we investigate the validity of assertions claiming that CNN-generated images are unable to achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent CNN-generated images emerging from our handcrafted experiments using DCGAN, LSGAN, WGAN-GP and StarGAN, where we empirically show that this frequency discrepancy can be avoided by a minor architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection.Through this study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative models—contrary to the belief of some existing work—, and such features are not robust to perform synthetic image detection. Our results prompt re-thinking of using high frequency Fourier spectrum decay attributes for CNN-generated image detection. Code and models are available at https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/},
  keywords={Computer vision;Systematics;Codes;Forensics;Computational modeling;Detectors;Computer architecture},
  doi={10.1109/CVPR46437.2021.00712},
  ISSN={2575-7075},
  month={June},}@ARTICLE{933500,
  author={Buttazzo, G.},
  journal={Computer}, 
  title={Artificial consciousness: Utopia or real possibility?}, 
  year={2001},
  volume={34},
  number={7},
  pages={24-30},
  abstract={Since the beginnings of computer technology, researchers have speculated about the possibility of building smart machines that could compete with human intelligence. Given the current pace of advances in artificial intelligence and neural computing, such an evolution seems to be a more concrete possibility. Many people now believe that artificial consciousness is possible and that, in the future, it will emerge in complex computing machines. However, a discussion of artificial consciousness gives rise to several philosophical issues: can computers think or do they just calculate? Is consciousness a human prerogative? Does consciousness depend on the material that comprises the human brain, or can computer hardware replicate consciousness? Answering these questions is difficult because it requires combining information from many disciplines including computer science, neurophysiology, philosophy, and religion. Further, we must consider the influence of science fiction, especially science fiction films, when addressing artificial consciousness. As a product of the human imagination, such works express human desires and fears about future technologies and may influence the course of progress. At a societal level, science fiction simulates future scenarios that can help prepare us for crucial transitions by predicting the consequences of significant technological advances. The paper considers robots in science fiction, the Turing test, computer chess and artificial consciousness.},
  keywords={Humans;Artificial intelligence;Intelligent structures;Machine intelligence;Concrete;Hardware;Computer science;Neurophysiology;Computational modeling;Predictive models},
  doi={10.1109/2.933500},
  ISSN={1558-0814},
  month={July},}@INPROCEEDINGS{8675198,
  author={Hill, Mark and Janapa Reddi, Vijay},
  booktitle={2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
  title={Gables: A Roofline Model for Mobile SoCs}, 
  year={2019},
  volume={},
  number={},
  pages={317-330},
  abstract={Over a billion mobile consumer system-on-chip (SoC) chipsets ship each year. Of these, the mobile consumer market undoubtedly involving smartphones has a significant market share. Most modern smartphones comprise of advanced SoC architectures that are made up of multiple cores, GPS, and many different programmable and fixed-function accelerators connected via a complex hierarchy of interconnects with the goal of running a dozen or more critical software usecases under strict power, thermal and energy constraints. The steadily growing complexity of a modern SoC challenges hardware computer architects on how best to do early stage ideation. Late SoC design typically relies on detailed full-system simulation once the hardware is specified and accelerator software is written or ported. However, early-stage SoC design must often select accelerators before a single line of software is written. To help frame SoC thinking and guide early stage mobile SoC design, in this paper we contribute the Gables model that refines and retargets the Roofline model---designed originally for the performance and bandwidth limits of a multicore chip---to model each accelerator on a SoC, to apportion work concurrently among different accelerators (justified by our usecase analysis), and calculate a SoC performance upper bound. We evaluate the Gables model with an existing SoC and develop several extensions that allow Gables to inform early stage mobile SoC design.},
  keywords={Computer architecture;Computational modeling;Smart phones;Bandwidth;Fabrics;Software;Hardware;Accelerator architectures;Mobile computing;System-on-Chip;Processor Architecture},
  doi={10.1109/HPCA.2019.00047},
  ISSN={2378-203X},
  month={Feb},}@INPROCEEDINGS{9760970,
  author={William, P. and Badholia, Abhishek and Patel, Brijesh and Nigam, Manoj},
  booktitle={2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)}, 
  title={Hybrid Machine Learning Technique for Personality Classification from Online Text using HEXACO Model}, 
  year={2022},
  volume={},
  number={},
  pages={253-259},
  abstract={Personality refers to a person's unique collection of traits that influence their habits, behaviors, attitudes, and thinking patterns. Text accessible on social networking sites may be used to automatically identify an individual's personality characteristics. In the trials, a publicly accessible benchmark dataset from Kaggle is utilized. The major problem with the previous study was the skewness of the dataset, which was reduced by using the Re-sampling method, essentially random over-sampling, which resulted in improved performance. Although the results produced by all classifiers across all personality characteristics are acceptable, the performance of the XGBoost classifier is exceptional, reaching more than 99 percent precision and accuracy for various qualities. Individual preferences, talents, social and human values, personality variations, and human will power must all be addressed while analyzing entrepreneurial activities, intents, and performance, especially with entrepreneurship playing such an important part in the contemporary dynamic. Using the HEXACO Personality Characteristics Model, this study demonstrates a link between personality traits and entrepreneurial success, indicating that personality traits have a significant and direct effect on entrepreneurial performance.},
  keywords={Text recognition;Social networking (online);Computational modeling;Entrepreneurship;Machine learning;Benchmark testing;Data models;Personality recognition;Social Networks;HEXACO model;Individual Performance;Personality Traits},
  doi={10.1109/ICSCDS53736.2022.9760970},
  ISSN={},
  month={April},}@ARTICLE{1262477,
  author={Leski, J.M.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
  title={/spl epsiv/-insensitive fuzzy c-regression models: introduction to /spl epsiv/-insensitive fuzzy modeling}, 
  year={2004},
  volume={34},
  number={1},
  pages={4-15},
  abstract={This paper introduces a new /spl epsiv/-insensitive fuzzy c-regression models (/spl epsiv/FCRM), that can be used in fuzzy modeling. To fit these regression models to real data, a weighted /spl epsiv/-insensitive loss function is used. The proposed method make it possible to exclude an intrinsic inconsistency of fuzzy modeling, where crisp loss function (usually quadratic) is used to match real data and the fuzzy model. The /spl epsiv/-insensitive fuzzy modeling is based on human thinking and learning. This method allows easy control of generalization ability and outliers robustness. This approach leads to c simultaneous quadratic programming problems with bound constraints and one linear equality constraint. To solve this problem, computationally efficient numerical method, called incremental learning, is proposed. Finally, examples are given to demonstrate the validity of introduced approach to fuzzy modeling.},
  keywords={Statistical learning;Fuzzy sets;Error correction;Minimization methods;Computational modeling;Loss measurement;Training data;Noise robustness},
  doi={10.1109/TSMCB.2002.804371},
  ISSN={1941-0492},
  month={Feb},}
