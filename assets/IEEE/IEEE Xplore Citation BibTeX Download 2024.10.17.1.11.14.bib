@INPROCEEDINGS{1592083,
  author={Schuster, S. and Gilbert, N.},
  booktitle={First International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution (AXMEDIS'05)}, 
  title={Agent based simulation for modelling the distribution of online music}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={The online content market for music is changing rapidly with the spread of technology and innovative business models. It is difficult for suppliers of online content to anticipate these developments and the effects of their businesses. The paper describes a multi-agent simulation to model possible scenarios in this market and argues that agent-based modeling can be a useful tool in thinking about future developments in these markets. It demonstrates this by applying the model to two simple scenarios of interest in the domain, the disintermediation of the value chain in the Internet and the lock-in of consumers to Apple's iTunes download platform.},
  keywords={Multiple signal classification;Business;Production;Differential equations;Aggregates;Humans;Internet;Consumer behavior;Computational modeling;Contracts},
  doi={10.1109/AXMEDIS.2005.6},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{6685148,
  author={Martinez-Arias, Juan-Carlos and Sarria M., Gerardo M.},
  booktitle={2013 IEEE Frontiers in Education Conference (FIE)}, 
  title={Didactic and interdisciplinary experiences in a Software Engineering course}, 
  year={2013},
  volume={},
  number={},
  pages={1800-1805},
  abstract={Didactic experiences are very important in a Software Engineering course. We think they help to achieve at least six objectives of the course: to identify fundamental concepts of software engineering, to recognize software life cycles, models and methodologies of software development, to perform analysis of software products requirements, to design and develop a software product, to use the methodical processes of a real-world project, and to implement solutions following specific methodologies. In this paper we will show our didactic experiences in the Software Engineering Processes course. We developed a sequence of learning activities and their application (extracted from real requirements of clients and users) in different contexts such as environmental, medical and social, which results in higher levels of learning, interdisciplinary exercises and practices close to what students will face in their professional lives.},
  keywords={Unified modeling language;Computational modeling;Computers;Law;Security;Software Engineering;Didactic Experiences;Learning Activities;Interdisciplinary},
  doi={10.1109/FIE.2013.6685148},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6633948,
  author={Elhussein, Khalid and Babiker, Mohamed},
  booktitle={2013 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRICAL AND ELECTRONIC ENGINEERING (ICCEEE)}, 
  title={Smart phones as system integration development tools: (Android SCL simulation environment as prototype)}, 
  year={2013},
  volume={},
  number={},
  pages={280-286},
  abstract={Smart phones and cloud computing were introduced to automation industry as components of connected enterprise integration systems. The established protocols and interfacing done in that area, beside the rapid growth of the hardware specification of those devices, was behind the motivation to think of smart phones as programming and simulation devices. This paper proposes a conceptual design of a system integration work structure based on smart phones and cloud computing. The conceptual design is supported by prototype of an Android application for Siemens SCL programming and simulation. The proposal assumes a private cloud with a SAAS/PAAS/IAAS cloud model owned by an Automation solutions vendor (provider) whereas the handheld portable computing devices (e.g. smart phones) performs typical POUs (Project organization units) configuration and/or programming of preconfigured device (controller) and uploading the generated and tested-by means of simulation-code as (.prj files) or .txt files to the cloud. As part of the design, the paper will present a smart phone based automation application which will be capable of parsing the IEC 61131-3 SCL PLC programming language code, interpreting and checking validity by means of a high level simulator (Java based), generating a .txt file, this will assume a private cloud model and a coding (Engineering) management application on the server side.},
  keywords={Cloud computing;Automation;Smart phones;Research and development management;Prototypes;Computational modeling;Performance evaluation;Cloud computing;smartphones;portable engineering station terminal;portable asset management terminal},
  doi={10.1109/ICCEEE.2013.6633948},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8672686,
  author={Hamad, Ruba Mohammad Haj and Al Fayoumi, Mustafa},
  booktitle={2018 International Arab Conference on Information Technology (ACIT)}, 
  title={Modernization of a Classical Data Center (CDC) vs. Adoption in Cloud Computing Calculate Total Cost of Ownership for Both Cloud and CDC - Jordanian Case Study}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Cloud computing is a vital paradigm which has become a top priority in companies around the world. Small to medium enterprises (SMEs) are thinking about how to adopt Cloud computing with high hopes of improving efficiency, using the latest technologies, increasing agility, avoiding the headache of acquiring hardware and software in CDC and, finally, saving money by minimizing the upfront cost. However, there are currently no accurate feasibility or Total Cost of Ownership (TCO) studies to encourage them to go for the Cloud approach and stop modernizing CDC. Since Cloud cost is one of the key topics nowadays, a one-year project was conducted to modernize and innovate a Classical Data Center (CDC) owned by a Jordanian information technology company and track the associated expenses to determine whether modernization of a CDC or adoption of Cloud computing instances is more cost-effective. To achieve clear insights, this study presented the cost difference between modernization of CDC and Oracle Cloud adoption. The results of this research study revealed that Cloud Computing is highly cost effective when TCO is calculated. Moreover, this study could be useful and applicable for information technology enterprises and banking domains.},
  keywords={Cloud computing;Data centers;Hardware;Computational modeling;Companies;Software;Cloud Total Cost of Ownership;Modernization of Classical Data Center;Oracle Cloud Bare-metal;Innovating CDC;Cost Benefit Analysis;Cloud Adoption vs. CDC},
  doi={10.1109/ACIT.2018.8672686},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{184155,
  author={Ting-peng Liang},
  booktitle={Proceedings of the Twenty-Fourth Annual Hawaii International Conference on System Sciences}, 
  title={Modeling by analogy: a case-based approach to automated linear program formulation}, 
  year={1991},
  volume={iii},
  number={},
  pages={276-283 vol.3},
  abstract={Developing a user-friendly modeling environment has been a focus of recent research. One technique widely used in human modeling processes but virtually unexplored in existing model management literature is the application of analogical thinking to improve the productivity of model formulation. Modeling by analogy is a process by which model builders transform modeling knowledge obtained from previous experience to build models for new problems that share significant features with the previously formulated ones. It overcomes certain human cognitive limitations and reduces the need for repetitive trials. The author examines the process of modeling by analogy, explores how this approach can be applied to the formulation of linear programs, and discusses issues involved in supporting modeling by analogy.<>},
  keywords={Humans;Productivity;Problem-solving;Environmental management;Cybernetics;Computational modeling;Technology management;Logic;Production},
  doi={10.1109/HICSS.1991.184155},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8545355,
  author={Wang, Fuwei and Gong, Xiaolong and Huang, Linpeng},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Time-Dependent Pre-attention Model for Image Captioning}, 
  year={2018},
  volume={},
  number={},
  pages={3297-3302},
  abstract={The task of automatically generating image captions draws a lot of attention in the past few years because it shows great potential in a wide range of application scenarios. The encoder-decoder structure with attention mechanism has been extensively applied to solve this task. However, most researches apply attention mechanism only to pay attention to image features but neglect the relations between image features which we think play an important role in scene understanding. To tackle this problem, we propose a novel attention mechanism named “attention to Time-Dependent Pre-Attention” (TDPA-attention) and the TDPA-attention is combined with a hierarchical LSTM decoder to compose our captioning model (TDPA-model). Within our TDPA-attention, at every time step, every image feature pays attention to all image features according to a semantic context and the attended feature is treated as an aggregated feature that contains relations between this image feature and all image features. All these aggregated features form a new feature set that the hierarchical LSTM decoder attends to. We evaluate our model on public image caption dataset Microsoft COCO and achieve state-of-the-art performance on most evaluation metrics.},
  keywords={Decoding;Task analysis;Semantics;Visualization;Feature extraction;Computational modeling;Computer science},
  doi={10.1109/ICPR.2018.8545355},
  ISSN={1051-4651},
  month={Aug},}@INPROCEEDINGS{5446782,
  author={Visnevski, Nikita A. and Castillo-Effen, Mauricio},
  booktitle={2010 IEEE Aerospace Conference}, 
  title={Evolutionary computing for mission-based test and evaluation of unmanned autonomous systems}, 
  year={2010},
  volume={},
  number={},
  pages={1-10},
  abstract={Test and evaluation may be viewed as a technology enabler for the successful deployment of unmanned vehicles and robots in all their envisioned applications. It is however a challenging endeavor, considering that roboticists and developers are not used to thinking of comprehensive test and evaluation as an integral part of robot development. Moreover, the community who has conducted test and evaluation up to this date does not possess the tools to cope with the growing complexity of unmanned and autonomous systems. This paper proposes an approach to one of the hardest problems in testing and evaluation of robots: mission-based test planning. This approach relies on constructive simulation tools and on evolutionary computing techniques for searching in high dimensional spaces of possible test scenarios. The goal of the test planner is to generate a set of tests that make highly efficient use of resources to unveil weaknesses of the system under test in a context of a specific mission.},
  keywords={System testing;Electronic equipment testing;Humans;Embedded computing;Embedded system;Control systems;Remotely operated vehicles;Mobile robots;Orbital robotics;Computational modeling},
  doi={10.1109/AERO.2010.5446782},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10183057,
  author={Thalor, Meenakshi Anurag and Nagabhyrava, Rohith and Rajkumar, K. and Chakraborty, Abesh and Singh, Rajesh and Singh Aswal, Upendra},
  booktitle={2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Deep learning insights and methods for classifying wildlife}, 
  year={2023},
  volume={},
  number={},
  pages={403-407},
  abstract={With the introduction of low-cost and widely accessible sensors such as cellphones, drones, satellites, voice recorders, and bio-logging equipment, the amount of information collected about animals has expanded. Meanwhile, modern data processing systems prohibit them from collecting, digesting, and condensing data into usable information. We think that machine learning, especially deep learning algorithms, will be able to tackle this analytical difficulty by enhancing our understanding, monitoring capacities, and animal welfare. By merging machine learning with ecological processes, it may be feasible to expand the inputs to population and behavior models, resulting in integrated hybrid modeling tools where machine learning models give data-supported insights and ecological models act as constraints. Animal ecologists may basically profit from the quantity of data created by contemporary sensor technologies by integrating cutting-edge machine learning methods with ecological domain expertise. This will enable them to assess population abundances more precisely, research animal behavior, and reduce human-wildlife conflicts.},
  keywords={Deep learning;Satellites;Biological system modeling;Computational modeling;Wildlife;Sociology;Animal behavior;Deep Learning;wildlife classification;Data Analytics;Machine Learning},
  doi={10.1109/ICACITE57410.2023.10183057},
  ISSN={},
  month={May},}@ARTICLE{10168286,
  author={Wang, Beibei and Jiang, Bo and Tang, Jin and Luo, Bin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Generalizing Aggregation Functions in GNNs: Building High Capacity and Robust GNNs via Nonlinear Aggregation}, 
  year={2023},
  volume={45},
  number={11},
  pages={13454-13466},
  abstract={The main aspect powering GNNs is the multi-layer network architecture to learn the nonlinear representation for graph learning task. The core operation in GNNs is the message propagation in which each node updates its information by aggregating the information from its neighbors. Existing GNNs usually adopt either linear neighborhood aggregation (e.g. mean, sum) or max aggregator in their message propagation. 1) For linear aggregators, the whole nonlinearity and network's capacity of GNNs are generally limited because deeper GNNs usually suffer from the over-smoothing issue due to their inherent information propagation mechanism. Also, linear aggregators are usually vulnerable to the spatial perturbations. 2) For max aggregator, it usually fails to be aware of the detailed information of node representations within neighborhood. To overcome these issues, we re-think the message propagation mechanism in GNNs and develop the new general nonlinear aggregators for neighborhood information aggregation in GNNs. One main aspect of our nonlinear aggregators is that they all provide the optimally balanced aggregator between max and mean/sum aggregators. Thus, they can inherit both i) high nonlinearity that enhances network's capacity, robustness and ii) detail-sensitivity that is aware of the detailed information of node representations in GNNs’ message propagation. Promising experiments show the effectiveness, high capacity and robustness of the proposed methods.},
  keywords={Task analysis;Robustness;Message passing;Computer architecture;Computational modeling;Training;Smoothing methods;Graph neural networks;graph representation learning;message passing;nonlinear message aggregation},
  doi={10.1109/TPAMI.2023.3290649},
  ISSN={1939-3539},
  month={Nov},}@INPROCEEDINGS{10308238,
  author={Chandra, Jatin and B., Annappa and R., Rashmi Adyapady},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Cross-Database Facial Expression Recognition using CNN with Attention Mechanism}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Facial expression is one of the most effective and universal ways to express emotions and intentions. It reflects what a person is thinking or experiencing. Thus, the expression recognition is one of the key aspects of understanding non-verbal communication and interpreting emotions in social interactions. Some emotions are very confusing, and separating the features between them becomes difficult because they share the same feature space. For example, the distinction between fear, anger, and disgust is confusing. This work tried to improve the model’s class-wise performance to detect each class correctly. A distinct combination of deep-learning models is used to calculate the performance of the model, such as ResNet, XceptionNet, DenseNet, etc. The datasets like Real-world Affective Faces Database (RAF-DB), Japanese Female Facial Expression (JAFFE) & Facial Expression Recognition 2013 Plus (FER+) are used to evaluate the model’s performance. The proposed model achieved better results and overcame the previous work’s limitations. CDE’s performance on RAF-DB and FER+ evaluations was significantly better than the current SOTA methods, with an increase in accuracy of 5.18% and 3.98%, respectively.},
  keywords={Deep learning;Emotion recognition;Computer vision;Databases;Face recognition;Computational modeling;Buildings;Facial Expression Recognition (FER);Deep learning;DenseNet121;Attention-Based DenseNet},
  doi={10.1109/ICCCNT56998.2023.10308238},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{6572614,
  author={Wong, Chim Chwee and Alias, Emy Salfarina and Kishigami, Junichi},
  booktitle={2013 International Conference on Informatics, Electronics and Vision (ICIEV)}, 
  title={Playlist environmental analysis for the serendipity-based data mining}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={The real recommendation will involve not only unsurprised, but some surprised elements sometimes. We are constantly experiencing this serendipity element in our daily life. However, today's data mining technology cannot support this function adequately. In this paper, we hypothesize that there should be some relevant serendipity elements on a radio station's music playlist. The radio station makes the playlist for the programme by the producer or director based on his experience and huge knowledge of music. In this research, we first determine the optimal number of clusters to be used by using BIC and AIC, and then we apply EM model clustering technique for the collection of more than 3000 playlists from the radio station. By analyzing the resulting clusters obtained, significant dependency between clusters and all the playlist metadata (i.e. time, genre, music era, and popularity) are discovered. Finally, we found that the time of playing the music and the music era (composed-year of music) has a strong correlation. This implies that music in some particular music era is popular in certain particular time of the day. For example, more classical music pieces from modern era are played at the night from 18:00 until 2:00. Furthermore, more classical music from the early Baroque era has been played in the afternoon around 12.00 to 13.00. However, we think that some music, which belong to the music era that are less popular in that particular time, will contribute to the serendipity function of the playlist to certain extend. With these studies, this serendipity would be widely used for an excellent recommendation service, which will include the personal radio station for the digital music player, marketing and knowledge capital.},
  keywords={Data visualization;Music;Internet;Mathematical model;Data models;Data mining;Computational modeling;serendipity;data mining;data visualization;playlist;classical music;radio},
  doi={10.1109/ICIEV.2013.6572614},
  ISSN={},
  month={May},}@INPROCEEDINGS{4755509,
  author={Reilly, D.F. and Inkpen, K.M. and Watters, C.R.},
  booktitle={2009 42nd Hawaii International Conference on System Sciences}, 
  title={Controlling, Integrating, and Engaging Context in Urban Computing Research}, 
  year={2009},
  volume={},
  number={},
  pages={1-10},
  abstract={Understanding the interplay between technology and urban life is the basic question of urban computing research. In addition to using context to achieve realism in evaluation, urban computing studies often need to consider context of use outright as an element under study. Doing so requires new ways of thinking about context that may not fit neatly into traditional categories of experimental design. In this paper we present our experiences in attempting to manage context in studies involving urban way finding and other social spatial activities. We reflect on our attempts to treat context as a set of controllable factors, to integrate some uncontrolled aspects of context into our experiments, and to engage contextual realism outright. The paper concludes with recommendations for managing context in urban computing study design based on these experiences.},
  keywords={Design for experiments;Navigation;Control systems;Collaboration;Context modeling;Roads;Bridges;Home computing;Computational modeling;Visualization},
  doi={10.1109/HICSS.2009.132},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{7020187,
  author={Howell, Michael and Vega, David and Doore, Karen and Fishwick, Paul},
  booktitle={Proceedings of the Winter Simulation Conference 2014}, 
  title={Enhancing model interaction with immersive and tangible representations: A case study using the Lotka-Volterra model}, 
  year={2014},
  volume={},
  number={},
  pages={3572-3583},
  abstract={Dynamic computer simulations seek to engage the viewer by providing an intuitive representational mapping of common knowledge features to new knowledge concepts. Our research aims to provide enhanced understanding of complex systems through participatory interaction with our dynamic simulation models. Previous research has indicated that virtual and tangible models are well suited for use in informal education spaces, as they increase user interaction and curiosity amongst children and adults. We designed and implemented an interactive virtual environment as well as an interactive tangible “water computer” to represent the complex interspecies behavior of Lotka-Volterra predator-prey dynamic system. We designed our simulation models for use in informal STEM education settings, with a design focus on enhanced interactions and reflexive thinking.},
  keywords={Predator prey systems;Mathematical model;Biological system modeling;Equations;Computational modeling;Education;Valves},
  doi={10.1109/WSC.2014.7020187},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6235359,
  author={Zainal Abidin, Azizan and Saleh, Fatimah},
  booktitle={2011 3rd International Congress on Engineering Education (ICEED)}, 
  title={Team-based Electronic Portfolio}, 
  year={2011},
  volume={},
  number={},
  pages={48-53},
  abstract={An important aspect of engineering undergraduate learning is the assessment techniques as they determine the extent to which the expected so desired learning outcomes of a particular program can be measured. With the growing demands of industrial needs globally, the learning outcomes of most engineering programs do not just linger on technical skills, but equally important, if not more, on the communication skills, teamwork skills and other such process skills. Educationists thus seek for alternatives to the traditional pencil and paper tests as this instrument is useful and regarded a good measuring tool, but limited to measuring thinking skills only. Amongst the examples of alternative assessment methods is the portfolio. This research attempts to show how team-based electronic learning portfolio construction in the learning of Differential Equations is integrated as an assessment method at Universiti Teknologi PETRONAS, a private university located in Tronoh, Perak, Malaysia was employed to encompass a more comprehensive measure of students' learning in three learning domains; cognitive, affective and psychomotor. Involving over two hundred engineering undergraduates, the researcher with the assistance of two other colleagues uses a criterion-based scoring rubric to evaluate the construction of a randomly selected sample of fifteen from a pool of fifty one electronic Differential Equations Learning Portfolio or acronym, e-DELP. It is interesting to note the various levels of learning from the three learning domains; cognitive, affective and psychomotor domains that could be related to the activities involved in the construction of the team-based e-DELP. Time consuming it may be, but with proper planning, this alternative assessment is found to be well-worth implementing in achieving the objectives of measuring more than technical skills of students.},
  keywords={Atmospheric measurements;Particle measurements;Media;Software;Computational modeling;Accuracy;Planning;Assessment;Differential Equations;learning domains;team-based e- portfolio;engineering undergraduates;scoring rubrics},
  doi={10.1109/ICEED.2011.6235359},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10169561,
  author={Ali, Haifa Ali Saeed and Vakula Rani, J},
  booktitle={2023 International Conference on Sustainable Computing and Smart Systems (ICSCSS)}, 
  title={Internet of Things and Digital Forensics: Recent Studies and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={959-966},
  abstract={The revolution of the Internet of Things (IoT) is increasing dramatically, where everything has become smart, and this new technology has helped facilitate plenty of things for humanity and made life easier in terms of applications and machines that think like humans using artificial intelligence. Currently, many applications of the Internet of Things affect our daily lives. Although the Internet of Things has brought us ease of life, it has brought many challenges related to security. However, solving these issues and challenges requires a high degree of skills. The approach that addresses the increment of cybercrimes is IoT Forensics. IoT forensics is a call for investigating and mitigating these cybercrimes. In this study, we overview the basics of IoT and present an illustrative study of digital forensics and IoT Forensics, then discussing that with some differences between IoT Forensics, Digital Forensics, and IoT Security, and an overview of the Process of IoT Forensics have been discussed. In addition, this work focuses on recent research work from 2018 onwards in terms of IoT Forensics models, frameworks, analysis, and use cases; finally, IoT and Digital Forensics Challenges and open issues have been discussed.},
  keywords={Analytical models;Humanities;Computational modeling;Digital forensics;Internet of Things;Security;Computer crime;IoT Forensics;Cybercrimes;Digital Forensics;IoT Technology;Investigators;IoT Security},
  doi={10.1109/ICSCSS57650.2023.10169561},
  ISSN={},
  month={June},}@INPROCEEDINGS{9787590,
  author={Das, Rahul and Biswas, Chiranjit and Majumder, Swanirbhar},
  booktitle={2022 IEEE 11th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Study of Spiking Neural Network Architecture for Neuromorphic Computing}, 
  year={2022},
  volume={},
  number={},
  pages={373-379},
  abstract={Deep learning's progress has resulted in a multi-layered character in a variety of applications in this field. Artificial Neural Networks are becoming the old procedure in the wide region of computing, using fifty-year-old principal concepts and models. Scientists are now presenting 3rd generation intelligent models in this current computer era. The brain like a big computer, routes information that it receives from the senses and body, and sends communications back to the body. But the brain can do much more than a machine can: humans think and experience reactions with their brain, and are the root of human intelligence. The 3rd generation Spiking Neural Network bridges the gap between deep learning, machine learning, and neuroscience in a biological approach, allowing neuroscience and machine learning to work together to achieve high-level computing efficiency using the neuromorphic computing. Spiking Neural Networks promise to make use of spikes, which are discrete functions that occur at predictable emphases rather than continuous values so that they are hardware implementable as well.},
  keywords={Deep learning;Training;Neuroscience;Neuromorphic engineering;Computational modeling;Computer architecture;Brain modeling;Spiking Neural Network;Artificial Neural Networks;Deep Learning;Neuromorphic Computing},
  doi={10.1109/CSNT54456.2022.9787590},
  ISSN={2329-7182},
  month={April},}@ARTICLE{10246878,
  author={Ninrutsirikun, Unhawa and Pal, Debajyoti and Arpnikanondt, Chonlameth and Watanapa, Bunthit},
  journal={Journal of Web Engineering}, 
  title={Unified Model for Learning Style Recommendation}, 
  year={2021},
  volume={20},
  number={5},
  pages={1487-1526},
  abstract={Studying computer programming requires not only an understanding of theories and concepts but also coding adeptness. Success in studying or conducting such a course is definitely a challenge. This paper proposes a systematic learning style recommendation. The model is designed to evaluate students' attributes and ongoing or formative learning outcomes for suggesting the effective style-fit strategy that facilitates learners to enhance their learning performances in terms of knowledge and skill. A two-stage association analysis was designed and conducted on a dataset collected from IT major students who enrolled in the Introduction to Computer Programming course. The first stage of association rules is to analyze and discover important relationships amongst learning styles, students' attribute, and learning performance. The second stage of moderation analysis is then applied to probe the moderation effect of the different learning preferences on the relationship between student attributes and learning achievement. Experiments expose many insights, for example, mathematics and logical thinking are powerful assets of success in computer programming study. Association rules can effectively identify associations of learning styles and the learning performance in terms of knowledge or skills. By moderation analysis, students in the “Excellent” cluster have a broad learning style than other students. Two types of significant moderators, the universal and specific, exemplify how lecturers can flexibly post style-fit teaching strategies for a class-wide and specific group, respectively.},
  keywords={Analytical models;Systematics;Computational modeling;Education;Programming;Mathematics;Encoding;Association evaluation;association rules;guideline;learning styles;moderation analysis;style-fit strategy},
  doi={10.13052/jwe1540-9589.2058},
  ISSN={1544-5976},
  month={July},}@INPROCEEDINGS{344526,
  author={Akiyoshi, M. and Nishida, S.},
  booktitle={Proceedings of Phoenix Conference on Computers and Communications}, 
  title={A qualitative simulation-based learning environment: how to enhance causal understanding of complex phenomena in large-scale plants}, 
  year={1993},
  volume={},
  number={},
  pages={531-537},
  abstract={The authors describe a framework of a qualitative simulation-based learning environment that focuses on causal understanding of complex phenomena in large-scale plants. Training styles such as study with manuals and exercise with a numerical simulator have been developed. However, besides such training styles, a learning environment should provide the functions that enable operators to achieve deep understanding of target plants. The qualitative simulation-based learning environment aims at providing operators a thinking tool for understanding, where human-computer interaction is also designed based on this notion. To realize this environment in a computer, two problems on qualitative reasoning have to be resolved. One is how to construct qualitative models of adequate grain size as target plants become complex, and the other is how to prune spurious qualitative behaviors. New techniques on qualitative reasoning are proposed, which are called qualitative reasoning with association mechanisms to qualitative information. Its effectiveness is discussed through applying this framework to large-scale power plants.<>},
  keywords={Computational modeling;Large-scale systems;Computer simulation;Numerical simulation;Grain size;Power generation;Quality management;Analytical models;Information analysis;Manuals},
  doi={10.1109/PCCC.1993.344526},
  ISSN={},
  month={March},}@ARTICLE{10375936,
  author={Hull, Gordon},
  journal={Journal of Social Computing}, 
  title={Unlearning Descartes: Sentient AI is a Political Problem}, 
  year={2023},
  volume={4},
  number={3},
  pages={193-204},
  abstract={The emergence of Large Language Models (LLMs) has renewed debate about whether Artificial Intelligence (AI) can be conscious or sentient. This paper identifies two approaches to the topic and argues: (1) A “Cartesian” approach treats consciousness, sentience, and personhood as very similar terms, and treats language use as evidence that an entity is conscious. This approach, which has been dominant in AI research, is primarily interested in what consciousness is, and whether an entity possesses it. (2) An alternative “Hobbesian” approach treats consciousness as a sociopolitical issue and is concerned with what the implications are for labeling something sentient or conscious. This both enables a political disambiguation of language, consciousness, and personhood and allows regulation to proceed in the face of intractable problems in deciding if something “really is” sentient. (3) AI systems should not be treated as conscious, for at least two reasons: (a) treating the system as an origin point tends to mask competing interests in creating it, at the expense of the most vulnerable people involved; and (b) it will tend to hinder efforts at holding someone accountable for the behavior of the systems. A major objective of this paper is accordingly to encourage a shift in thinking. In place of the Cartesian question—is AI sentient?—I propose that we confront the more Hobbesian one: Does it make sense to regulate developments in which AI systems behave as if they were sentient?},
  keywords={Sociotechnical systems;Social computing;Computational modeling;Resists;Manuals;Regulation;Labeling;artificial intelligence;Large Language Model;consciousness;sentience;personhood;Descartes;Hobbes},
  doi={10.23919/JSC.2023.0020},
  ISSN={2688-5255},
  month={Sep.},}@INPROCEEDINGS{10179854,
  author={Khan, Lamia Parven and Hossain, Anika and Dey, Susmita},
  booktitle={2023 Fifth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Anomaly Detection for Beth Dataset Using Machine Learning Approaches}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Due to the advancement of technology network has become a part of our daily life. Thinking about life without network has become impossible. Sharing important and confidential information through network has become common. It is important to maintain the data integrity and confidentiality to maintain the trust on the network. Thus, network need to have strong and strict security. There are lots of criminal and unwanted ways to destroy the data integrity and confidentiality. It is import to prevent and block those illigal ways. This paper focus on Beth dataset. This analysis will give an insight of the Beth dataset. This gives researcher scientist an idea to if they can use this dataset to build strong and efficient anomaly detection model for the network.},
  keywords={Wireless communication;Machine learning algorithms;Costs;Data integrity;Computational modeling;Machine learning;Maintenance engineering;ANN;Precision;accuracy;dataset;machine learning;data pre processing},
  doi={10.1109/ICECCT56650.2023.10179854},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{1521133,
  author={Maly, P. and Woodside, C.M. and Karam, G.K. and Forrest, A.},
  booktitle={13th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems}, 
  title={Describing and visualizing the capacity of a system with behaviour uncertainties}, 
  year={2005},
  volume={},
  number={},
  pages={191-200},
  abstract={User and system behaviour is difficult to predict for novel systems, and this affects the capacity of the system (the number of active users that can be supported with acceptable response delay). This leads to a range of values, in the form of a feasible or acceptable region for the potential capacity, conditional on the uncertain parameters. This work considers uncertainties in the delay between requests (user think time), network latency, and cache behaviour due to users' locality of reference. The acceptable region is shown to be bounded approximately by linear constraints which are easy to derive. This simple result is useful for sensitivity and scalability analysis, and appears to have been overlooked. It is applied to a Web-based system for telephony, using voiceXML for service ranging from interactive voice response, to voice-based E-mail.},
  keywords={Visualization;Uncertainty;Telecommunication computing;Computational modeling;Analytical models;Computer simulation;Delay effects;Systems engineering and theory;Computer networks;Web server},
  doi={10.1109/MASCOTS.2005.24},
  ISSN={2375-0227},
  month={Sep.},}@INPROCEEDINGS{10234310,
  author={Dutta, Joy and Puthal, Deepak},
  booktitle={2023 IEEE International Conference on Edge Computing and Communications (EDGE)}, 
  title={Human-Centered Explainable AI at the Edge for eHealth}, 
  year={2023},
  volume={},
  number={},
  pages={227-232},
  abstract={Explainable Artificial Intelligence (XAI) is a new paradigm of Artificial Intelligence (AI) that is giving different AI/ Machine Learning (ML) models a boost to penetrate sectors where people are thinking about adopting AI. This work focuses on the adoption of XAI in the health sector. It portrays that careful integration of XAI in both cloud and edge could change the whole healthcare industry and make humans more aware of their present health conditions, which is the need of the hour. To demonstrate the same, we have done an experiment based on the prediction of a particular medical condition called "cardiac arrest" in a specific subject group (patients who are 70 years old). Here, based on the explanation provided by the XAI model (e.g., SHAP, LIME) at Cloud and Edge, our system can predict the chances of a "cardiac arrest" for the subject with a valid explanation. This type of model will be the next big upgrade in the healthcare industry in terms of automation and a self-explanatory system that works as a personal health assistant for individuals.},
  keywords={Industries;Medical conditions;Databases;Computational modeling;Cardiac arrest;Machine learning;Predictive models;XAI;IoMT;Edge;Machine Learning;Interpretability;eHealth},
  doi={10.1109/EDGE60047.2023.00044},
  ISSN={2767-9918},
  month={July},}@INPROCEEDINGS{9889336,
  author={Wells, Alesha and Loveys, Kate and Sagar, Mark and Billinghurst, Mark and Broadbent, Elizabeth},
  booktitle={2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={An Exploration of Eye Gaze in Women During Reciprocal Self-Disclosure: Implications for Digital Human Design}, 
  year={2022},
  volume={},
  number={},
  pages={1085-1089},
  abstract={Digital humans are a highly realistic form of conversational computer agent. Eye gaze is a salient social cue that digital humans could use to facilitate rapport-building during conversations. However, eye gaze tendencies vary by gender and incorrect gaze patterns can have negative social implications. Analysis of observational data during human conversations can help inform the development of eye gaze models for digital humans. This study aimed to identify the eye gaze patterns of women dyads during a rapport-building conversation, and to evaluate the effect of different gaze patterns on rapport, trust, and psychological outcomes. 36 adult women (18 dyads) completed the Relationship Closeness Induction Task while wearing eye tracking glasses. Subjective rapport, trust, and psychological measures were collected. Gaze patterns of women were found to change as the conversation content became more intimate; specifically, gaze aversions for thinking (p=.042), turn-taking (p=.025), and intimacy modulation increased in duration (p=.012). Furthermore, gaze patterns were associated with perceptions of the conversation partner. Displaying fewer cognitive gaze aversions was associated with greater closeness (p=.029) and trust perceptions (p=.035). Longer periods of direct gaze while speaking was associated with greater rapport (p=.040). Results will inform the development of a humanlike gaze model for female digital humans during intimate conversations and may be applicable to social robots.},
  keywords={Analytical models;Computational modeling;Social robots;Psychology;Modulation;Oral communication;Glass;Digital human;conversational agent;eye gaze;rapport;trust;stress;intimacy;social support},
  doi={10.1109/HRI53351.2022.9889336},
  ISSN={},
  month={March},}@INPROCEEDINGS{10196862,
  author={Azmee, Abm Adnan and Murikipudi, Manohar and Al Hafiz Khan, Md Abdullah and Pei, Yong},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Sentence Level Analysis for Detecting Mental Health Causes Using Social Media Posts}, 
  year={2023},
  volume={},
  number={},
  pages={1388-1393},
  abstract={Mental health is just as important as physical health. Globally, there is a growing concern due to the rise of mental health problems. Mental health problems impair individuals’ ability to think clearly, behave responsively, or express themselves. The recent pandemic has led to a spike in people using social media to express themselves. Data from these social media platforms can be used to learn more about users’ mental states and determine the causes of mental health problems. However, due to the variability and complexity of users’ language, it is very challenging for conventional machine learning and deep learning models to identify these causes. In this research, we propose a novel sentence-level analysis framework based on a hybrid deep learning model to overcome these challenges. We evaluated our model’s efficacy using data from the social media platform Reddit, and our model outperforms several baseline models. Our research findings provide a new perspective on identifying the causes behind mental health issues and would help mental health professionals develop better diagnoses and treatments for patients.},
  keywords={Deep learning;Analytical models;Social networking (online);Pandemics;Computational modeling;Mental health;Data models;Deep Learning;Mental Health;Cause Detection;Natural Language Processing;Sentence-Level Analysis},
  doi={10.1109/COMPSAC57700.2023.00211},
  ISSN={0730-3157},
  month={June},}@ARTICLE{1289316,
  author={Downing, G. and Dubois, P.F. and Cottom, T.},
  journal={Computing in Science & Engineering}, 
  title={Data sharing in scientific simulations}, 
  year={2004},
  volume={6},
  number={3},
  pages={87-96},
  abstract={Several physics processes modify the state of a scientific simulation over time. In fact, researchers often divide a simulation's development into areas - called packages - according to physics specialization. In this article, we use the word "package" primarily to mean a portion of scientific software whose components communicate internally much more than they do with outside routines, but packages can take the form of third-party libraries for common mathematical or computer science functions. Most parts of a simulation refer to the "infrastructure" portion of the state, so we can think of this portion as a package with lots of customers. How we share data within and between these packages is crucial to developer productivity. In this installment of Scientific Programming, we explore some of the pros and cons of the different ways to share data in C++ code.},
  keywords={Computational modeling;Physics;Libraries},
  doi={10.1109/MCISE.2004.1289316},
  ISSN={1558-366X},
  month={May},}
