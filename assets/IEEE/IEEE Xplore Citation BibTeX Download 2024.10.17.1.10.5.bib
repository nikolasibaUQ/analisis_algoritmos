@INPROCEEDINGS{937966,
  author={Haddow, P.C. and van Remortel, P.},
  booktitle={Proceedings Third NASA/DoD Workshop on Evolvable Hardware. EH-2001}, 
  title={From here to there : future robust EHW technologies for large digital designs}, 
  year={2001},
  volume={},
  number={},
  pages={232-239},
  abstract={Fault-tolerance may be expected to gain more and more importance in the future. Extremely harsh and changing environments, like outer space, already force us to think about this issue today, but issues like production of large-scale devices might put the same requirements on the devices of tomorrow. Imagine a mixture of chemical substances in a reservoir, together with a circuit-implementing shell that has self-repairing properties based on the maintenance of the chemical equilibrium. Could this type of solution be the basis for a robust future technology for evolvable hardware? A long term goal of evolvable hardware is to evolve large complex designs for large devices. However, both evolving large complex designs and manufacturing large reliable devices is technologically out of reach due to the resource greedy nature of GAs and low device yield rates. In this article we explore the technological requirements of digital design, design by evolution and development and the reliability issue in the light of today's digital evolvable hardware technology, FPGA and a proposed fault tolerant technology, Amorphous Computers. Considering the limitation of these platforms, we project these findings towards possible future technology platforms.},
  keywords={Robustness;Hardware;Space technology;Fault tolerance;Chemical technology;Production;Large-scale systems;Reservoirs;Circuits;Maintenance},
  doi={10.1109/EH.2001.937966},
  ISSN={},
  month={July},}@INPROCEEDINGS{9101636,
  author={Zhao, Cheng and Zhang, Zhibin and Xu, Peng and Zheng, Tianqi and Guo, Jiafeng},
  booktitle={2020 IEEE 36th International Conference on Data Engineering (ICDE)}, 
  title={Kaleido: An Efficient Out-of-core Graph Mining System on A Single Machine}, 
  year={2020},
  volume={},
  number={},
  pages={673-684},
  abstract={Graph mining is one of the most important categories of graph algorithms. However, exploring the subgraphs of an input graph produces a huge amount of intermediate data. The "think like a vertex" programming paradigm, pioneered by Pregel, cannot readily formulate mining problems, which is designed to produce graph computation problems like PageRank. Existing mining systems like Arabesque and RStream need large amounts of computing and memory resources. In this paper, we present Kaleido, an efficient single machine, out-of-core graph mining system which treats disks as an extension of memory. Kaleido treats intermediate data in graph mining tasks as a tensor and adopts a succinct data structure for the intermediate data. Kaleido implements half-memory-half-disk storage for storing large intermediate data, which treats the disk as an extension of the memory. Kaleido adopts a lightweight isomorphism checking strategy which uses an eigenvalue-based algorithm for small graphs and solves tree isomorphism for the other graphs. Comparing with two state-of-the-art mining systems, Arabesque and RStream, Kaleido outperforms them by a GeoMean 13.2× and 64.8× respectively.},
  keywords={Data mining;Programming;Memory management;Patents;Arrays;Tensile stress;graph mining;exploration;isomorphism;out-of-core},
  doi={10.1109/ICDE48307.2020.00064},
  ISSN={2375-026X},
  month={April},}@INPROCEEDINGS{6912676,
  author={Mohebbi, Abolfazl and Baron, Luc and Achiche, Sofiane and Birglen, Lionel},
  booktitle={Proceedings of the 2014 International Conference on Innovative Design and Manufacturing (ICIDM)}, 
  title={Trends in concurrent, multi-criteria and optimal design of mechatronic systems: A review}, 
  year={2014},
  volume={},
  number={},
  pages={88-93},
  abstract={Due to the inherent complexity and the dynamic coupling between subsystems of mechatronic systems, a systematic and multicriteria design thinking methodology is crucial to replace the traditionally used sequential design approach. In this paper we discuss the various aspects of current approaches within mechatronic system design to point out the most important challenges. Accordingly, a review on the most recent work on design and optimization methods and tools is presented and briefly discussed. A framework for concurrent and integrated design of mechatronic system based on separation of realtime and non-realtime system behaviours is also introduced and developed methods based on this model are presented.},
  keywords={Mechatronics;Design methodology;Software;System analysis and design;Mathematical model;Solid modeling;Systematics;KEYWORDS;Mechatronics;Multicriteria;Multi-disciplinary;Concurrent Design;Integration;Optimization},
  doi={10.1109/IDAM.2014.6912676},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9426783,
  author={Sodhi, Balwinder and Kapur, Ritu},
  booktitle={2021 IEEE 18th International Conference on Software Architecture (ICSA)}, 
  title={Quantum Computing Platforms: Assessing the Impact on Quality Attributes and SDLC Activities}, 
  year={2021},
  volume={},
  number={},
  pages={80-91},
  abstract={Practical quantum computing is rapidly becoming a reality. To harness quantum computers’ real potential in software applications, one needs to have an in-depth understanding of all such characteristics of quantum computing platforms (QCPs), relevant from the Software Engineering (SE) perspective. Restrictions on copying, deletion, the transmission of qubit states, a hard dependency on quantum algorithms are few, out of many, examples of QCP characteristics that have significant implications for building quantum software.Thus, developing quantum software requires a paradigm shift in thinking by software engineers. This paper presents the key findings from the SE perspective, resulting from an in-depth examination of state-of-the-art QCPs available today. The main contributions that we present include i) Proposing a general architecture of the QCPs, ii) Proposing a programming model for developing quantum software, iii) Determining architecturally significant characteristics of QCPs, and iv) Determining the impact of these characteristics on various Quality Attributes (QAs) and Software Development Life Cycle (SDLC) activities.We show that the nature of QCPs makes them useful mainly in specialized application areas such as scientific computing. Except for performance and scalability, most of the other QAs (e.g., maintainability, testability, and reliability) are adversely affected by different characteristics of a QCP.},
  keywords={Quantum algorithm;Software architecture;Scalability;Qubit;Buildings;Software algorithms;Computer architecture;Quantum Computing;Quantum Software Engineering;Software Development Life Cycle;Computing Platforms},
  doi={10.1109/ICSA51549.2021.00016},
  ISSN={},
  month={March},}@INPROCEEDINGS{6133162,
  author={Charalabidis, Yannis and Koussouris, Sotirios and Ramfos, Antonis},
  booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
  title={A Cloud Infrastructure for Collaborative Digital Public Services}, 
  year={2011},
  volume={},
  number={},
  pages={340-347},
  abstract={Looking back at the major developments of the previous years in the Internet and IT industry, it is more than certain that two of the most important innovations are cloud computing, which evidently takes processing power and IT provision to a whole new level, and Web2.0 service applications, that reveal the innovative thinking and development power of users, who in many cases are the architects of these applications. Despite this progress, focusing on the provision of public services reveals that until today little has been done in order to expose the real power of those two concepts. Cloud computing is in most cases regarded just as an alternative to having in premise infrastructures, while Web2.0 applications designed by third parties cannot be integrated in the public sector and are characterised as "promising initiatives that cannot go further". This paper targets the constantly increasing need for having more efficient and effective public sector services by trying to combine the benefits that derive by both the cloud computing and the open innovation concepts, and proposes a platform that could actually assist stakeholders to deploy their services towards meeting their needs, whether this refers to the exposure of public services over cloud infrastructures or to the creation of personalised composite public services.},
  keywords={Technological innovation;Cloud computing;Service oriented architecture;Europe;Collaboration;Government;Cloud Computing;Public Services;Collaboration;Open Innovation;eGovernance},
  doi={10.1109/CloudCom.2011.53},
  ISSN={},
  month={Nov},}@ARTICLE{9750858,
  author={Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for Low Latency IoT Systems}, 
  year={2022},
  volume={9},
  number={4},
  pages={2066-2083},
  abstract={Although Deep Neural Networks (DNN) have become the backbone technology of several ubiquitous applications, their deployment in resource-constrained machines, e.g., Internet of Things (IoT) devices, is still challenging. To satisfy the resource requirements of such a paradigm, collaborative deep inference with IoT synergy was introduced. However, the distribution of DNN networks suffers from severe data leakage. Various threats have been presented, including black-box attacks, where malicious participants can recover arbitrary inputs fed into their devices. Although many countermeasures were designed to achieve privacy-preserving DNN, most of them result in additional computation and lower accuracy. In this paper, we present an approach that targets the security of collaborative deep inference via re-thinking the distribution strategy, without sacrificing the model performance. Particularly, we examine different DNN partitions that make the model susceptible to black-box threats and we derive the amount of data that should be allocated per device to hide proprieties of the original input. We formulate this methodology, as an optimization, where we establish a trade-off between the latency of co-inference and the privacy-level of data. Next, to relax the optimal solution, we shape our approach as a Reinforcement Learning (RL) design that supports heterogeneous devices as well as multiple DNNs/datasets.},
  keywords={Task analysis;Collaboration;Deep learning;Servers;Privacy;Neural networks;Data models;IoT devices;resource constraints;sensitive data;black-box;distributed DNN;reinforcement learning},
  doi={10.1109/TNSE.2022.3165472},
  ISSN={2327-4697},
  month={July},}@INPROCEEDINGS{6891883,
  author={Molnárka, Gergely I. and Kovács, Szilveszter and Kóczy, László T.},
  booktitle={2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Fuzzy rule interpolation based fuzzy signature structure in building condition evaluation}, 
  year={2014},
  volume={},
  number={},
  pages={2214-2221},
  abstract={The complexity of the residential house structures makes their condition evaluation difficult. Taking the human experts' thinking into consideration the linguistic approach seems reasonable, therefore the fuzzy set theory may provide a basis for creating an expert system. In practice, the assessment of some predefined attributes of building components may give a comprehensive value about the condition of the examined building on a relative scale. The data structure of building evaluation procedure makes clear that the fuzzy signature structure is helpful in analysis. The numerous building components that determine the character of the given building can turn to an unnecessarily large rule-base. The fuzzy rule interpolation and the corresponding sparse fuzzy rule-based knowledge representation could be a reasonably efficient structure for handling the building evaluation procedure. In this paper the fuzzy rule interpolation as a novel aggregation method in fuzzy signature structures is proposed. Its application is presented with a case study of roof structure evaluation of a classic urban-type residential house located in a historic district of Budapest, Hungary.},
  keywords={Buildings;Maintenance engineering;Interpolation;Vectors;Pragmatics;Radio frequency;Standards},
  doi={10.1109/FUZZ-IEEE.2014.6891883},
  ISSN={1098-7584},
  month={July},}@INPROCEEDINGS{10084967,
  author={Abraham, Juby and Cherian, George Joseph and Jayapandian, N.},
  booktitle={2023 Second International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={Systematic Review on Humanizing Machine Intelligence and Artificial Intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1092-1097},
  abstract={In this era, Machine Learning is transforming human lives in a very different way. The need to give machines the power to make decisions or giving the moral compass is a big dilemma when humanity is more divided than it has ever been. There are two main ways in which law and AI interact. AI may be subject to legal restrictions and be employed in courtroom procedures. The world around us is being significantly and swiftly changed by AI in all of its manifestations. Public law includes important facets such as nondiscrimination law and labor law. In a manner similar to this when artificial intelligence (AI) is applied to tangible technology like robots. In certain cases, artificial intelligence (AI) might be hardly noticeable to customers but evident to those who built and are using it. The behavior research offers suggestions for how to build enduring and beneficial interactions between intelligent robots and people. The human improvement is main obstacles in the development and implementation of artificial intelligence. Best practices in this area are not governed by any one strategy that is generally acknowledged. Machine learning is about to revolutionize society as it is know it. It is crucial to give intelligent computers a moral compass now more than ever before because of how divided mankind is. Although machine learning has limitless potential, inappropriate usage might have detrimental long-term implications. It will think about how, for instance, earlier cultures built trust and improved social interactions via creative answers to many of the ethical issues that machine learning is posing now.},
  keywords={Ethics;Renewable energy sources;Systematics;Law;Machine learning;Regulation;Behavioral sciences;Artificial Intelligence;Cognitive Intelligence;Machine Learning;Humanizing;Social Interactions;},
  doi={10.1109/ICEARS56392.2023.10084967},
  ISSN={},
  month={March},}@ARTICLE{7258498,
  author={Zhao, Qiangfu and Brine, John and Filev, Dimitar P.},
  journal={IEEE Systems, Man, and Cybernetics Magazine}, 
  title={Defining Cybernetics: Reflections on the Science of Governance}, 
  year={2015},
  volume={1},
  number={2},
  pages={18-26},
  abstract={In this article, we have reconsidered the meaning of cybernetics and provided a taxonomy that can be useful for us to understand various cybernetics more clearly. We have also investigated some fundamental properties of governable or self-governable distributed systems. In particular, we believe that ontology plays a key role for a distributed system to become governable or even self-governable. We think that automatic construction of a good ontology in a distributed system is an interesting topic for further study. In fact, constructing a good ontology for a mobile communication network, a social network, a traffic control network, and any network related to our daily lives is important to make the network governable, safe, and secure. For large-scale distributed systems (e.g., the Internet), certain self-governability is also indispensable for the network to be more reliable or dependable. Of course, full self-governability of these systems may not be expected from the point of view of human beings.},
  keywords={Cybernetics;Ontologies;Governance;Internet;Control systems},
  doi={10.1109/MSMC.2015.2421325},
  ISSN={2333-942X},
  month={April},}@INPROCEEDINGS{7568426,
  author={Saxena, Gaurav and Jimack, Peter K. and Walkley, Mark A.},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={A cache-aware approach to domain decomposition for stencil-based codes}, 
  year={2016},
  volume={},
  number={},
  pages={875-885},
  abstract={Partial Differential Equations (PDEs) lie at the heart of numerous scientific simulations depicting physical phenomena. The parallelization of such simulations introduces additional performance penalties in the form of local and global synchronization among cooperating processes. Domain decomposition partitions the largest shareable data structures into sub-domains and attempts to achieve perfect load balance and minimal communication. Up to now research efforts to optimize spatial and temporal cache reuse for stencil-based PDE discretizations (e.g. finite difference and finite element) have considered sub-domain operations after the domain decomposition has been determined. We derive a cache-oblivious heuristic that minimizes cache misses at the sub-domain level through a quasi-cache-directed analysis to predict families of high performance domain decompositions in structured 3-D grids. To the best of our knowledge this is the first work to optimize domain decompositions by analyzing cache misses - thus connecting single core parameters (i.e. cache-misses) to true multicore parameters (i.e. domain decomposition). We analyze the trade-offs in decreasing cache-misses through such decompositions and increasing the dynamic bandwidth-per-core. The limitation of our work is that currently, it is applicable only to structured 3-D grids with cuts parallel to the Cartesian Axes. We emphasize and conclude that there is an imperative need to re-think domain decompositions in this constantly evolving multi-core era.},
  keywords={Optimization;Jacobian matrices;Topology;Program processors;Load modeling;Mathematical model;Computer architecture;PDEs;Domain Decomposition;Stencil;Quasi-cache-directed;Cache-oblivious},
  doi={10.1109/HPCSim.2016.7568426},
  ISSN={},
  month={July},}@INPROCEEDINGS{9590227,
  author={Chang, Carl K. and Ceravolo, Paolo and Chang, Rong N. and Helal, Sumi and Jin, Zhi and Liu, Xuanzhe and Ming, Hua},
  booktitle={2021 IEEE International Conference on Web Services (ICWS)}, 
  title={Software Services Engineering Manifesto - A Cross-Cutting Declaration}, 
  year={2021},
  volume={},
  number={},
  pages={703-709},
  abstract={As we have entered the Internet-of-Things (IoT) era, further blessed with rapid advances in several key technological areas including DevOps, AI/ML, 5G/6G/, neurocomputing, to name a few, it is imperative we think big and aim high. This new venture will require professionals in both software engineering and services computing to collaborate with an unprecedented intensity, and jointly develop the new interdisciplinary field hereby named Software Services Engineering (SSE). In SSE, the ever-deepening system dynamics emerging from both environments and humans in varying contexts are imposing steep challenges to both researchers and practitioners. Humans, both developers and the vast number of end users, are embedded ever closer to IoT environments, and are being afforded ample opportunities to continuously inject inputs during system development and after deployment. In fact, humans are increasingly playing the roles of both sensor and actuator. Traditional requirements engineering researchers are being lured more than ever into exploiting the IoT environments where human users are deeply embedded, to gather contextual information that inevitably introduces lots of ambiguity and uncertainty. Provisioning of highly adaptable and scalable microservices would be key to timely meeting ever-changing human desires and ever-evolving system requirements in the nimblest manner. As such, an ultra-agile and field-programmable development methodology and environment will be imperative to achieving such ultrafine grained microservices provisioning. Such ultra-agility and ultrafine granularity requirements imposed to the services industry obligate company executives to expect extreme manageability assurance to become the centroid of system operations and administration. The ultimate goal in pursuit of such a noble dream will be to provide genuinely individualized and trustworthy service, possibly enabled by AI, but it should be both explainable and ethical. Facing such grand challenges, this declaration samples a subset of burning issues in SSE through observations in seven themes, only meant to be starting points for the SSE community to further investigate. Through our declarations we also call for heightened attention to an assorted array of existing, barely emerging or non-existent services computing and software engineering methods for a concerted effort to research and explore.},
  keywords={Industries;Ethics;Uncertainty;Web services;System dynamics;Systems operation;Service computing;agile;AI;context-aware;DevOps;IoT;microservice;ML;requirements engineering;services computing;situation-aware;software engineering;software services engineering;uncertainty},
  doi={10.1109/ICWS53863.2021.00014},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{7757589,
  author={Martin, Christopher R. and Moore, Jacob P. and Ranalli, Joseph A.},
  booktitle={2016 IEEE Frontiers in Education Conference (FIE)}, 
  title={Teaching the foundations of thermodynamics with PYro}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the key skills developed in foundational thermodynamics courses is obtaining property and state data for various substances of interest. Typically, students are instructed to perform this task through the use of tables or computer software. In this paper, we present and evaluate modules for teaching the foundations of thermodynamics using free open-source software intended to port to students' professional lives. The approach introduces the PYro thermodynamic property calculator. PYro is implemented in Python, which is free and available on most widely used platforms. PYro is clearly documented, and all data are readily traceable to reputable sources. Most of the data describe ideal gases from the NIST JANAF database, but there is also support for mixtures (such as air) and multiphase substances (such as steam). The interface design makes the software appropriate to most tasks in introductory and intermediate thermodynamics courses without requiring proficiency in the Python language. While the idea of using software to teach thermodynamics is far from new, commercial software usually comes at a substantial price and places the implementation burden on the instructor. On the other hand, educational software rarely transitions into students' professional lives. This paper proposes a model for productively separating the development of skills (like table look-ups) from knowledge and concepts. In addition to an introduction of the tool, this paper provides results of preliminary evaluation conducted within a thermodynamics classroom. The authors developed a learning module demonstrating the use of PYro to compute states for an ideal Brayton cycle. Students were tasked with performing parametric analysis on the cycle, by varying various limiting factors (e.g. combustor pressure, turbine inlet temperature). Students were asked to compare power produced and cycle efficiency computed under these conditions. At the end of the module, students were surveyed about the experience of working with the software. Evaluation is provided in the form of instructor and student feedback from a classroom implementation. We propose that this utilization of the tool demonstrates its ability to promote higher-level cognitive thinking in problem solving, removing the time intensive task of performing table look-ups and allowing them to focus on more holistic questions of cycle performance.},
  keywords={Software;Thermodynamics;Calculators;Education;Temperature;Chemicals;Documentation},
  doi={10.1109/FIE.2016.7757589},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10283649,
  author={Bozkaya, Elif and Canberk, Berk and Schmidt, Stefan},
  booktitle={2023 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Digital Twin-Empowered Resource Allocation for 6G-Enabled Massive IoT}, 
  year={2023},
  volume={},
  number={},
  pages={727-732},
  abstract={6G technology is expected to lead to an unpredictable increase of Internet of Things (IoT) devices. The need for maintaining continuous connectivity of these devices has in turn led to re-thinking of the traditional design of wireless networks. In particular, the integration of 6G and Digital Twin (DT) is expected to reshape the network management as it offers powerful features in design, development and optimization processes. DT is a digital representation of physical entities, which are designed around a two-way information flow. Therefore, this technology not only collects data, and employs intelligent learning methods by performing complex computations, but it also can send feedback to improve system performance for 6G-enabled massive IoT. However, deploying such a technology requires addressing complex challenges such as limited resources, seamless connectivity and lack of trust between end users and network edge. To address these challenges, we formulate the resource allocation problem including edge computation and service migration in 6G-enabled massive IoT. The contributions are threefold: First, our DT-empowered architecture is proposed that uses the real-time and historical data from end users to find the best allocation at a user. Second, it studies the impact of trust relationship between computing entities to prevent the unauthorized accesses and provides an authentication procedure. Third, it describes a Multi-Agent Reinforcement Learning (MARL) algorithm that consists of cooperative agents and aims to find the best resource allocation strategy by minimizing task processing latency. We validate the proposed DT-empowered architecture to show the reduced processing latency compared to traditional benchmark methods.},
  keywords={6G mobile communication;Conferences;Wireless networks;Authentication;Computer architecture;Benchmark testing;Digital twins},
  doi={10.1109/ICCWorkshops57953.2023.10283649},
  ISSN={2694-2941},
  month={May},}@INPROCEEDINGS{7963441,
  author={Gong, Weibo and Ho, Yu-Chi},
  booktitle={2017 American Control Conference (ACC)}, 
  title={On fast retrieval of relational experiences}, 
  year={2017},
  volume={},
  number={},
  pages={3206-3211},
  abstract={Various intelligent systems are needed for cyber-physical systems. Such intelligent systems need to learn from the human intelligence about concept abstraction and analogical thinking in order to resolve complex issues using past experiences. The algorithms for abstraction and analogies are based on quick memory recall with clever information coding and processing. The quick and accurate memory recall is based on the fact that the memory mostly records the relations among the constituents of the stimulating signals, rather than the constituents themselves. Relational memories can be stored in the form of networks of neuron clusters capable of resonating to particular signal sequences. However, similarity testing for such network representations is difficult. We suggest that linear dynamic systems that relate the system matrix and the output time function can be used as a conversion mechanism between the network matrix and the temporal representations of the signals. This leads to algorithms for relational similarity testing and concept abstraction. Transient behavior based selection rules in ordinal optimization is important in achieving quickness in our development.},
  keywords={Resonant frequency;Transient analysis;Resonators;Intelligent systems;Signal processing;Computers;Neurons},
  doi={10.23919/ACC.2017.7963441},
  ISSN={2378-5861},
  month={May},}@ARTICLE{9829550,
  author={Heinonen, Henri T. and Semenov, Alexander and Veijalainen, Jari and Hämäläinen, Timo},
  journal={IEEE Access}, 
  title={A Survey on Technologies Which Make Bitcoin Greener or More Justified}, 
  year={2022},
  volume={10},
  number={},
  pages={74792-74814},
  abstract={According to recent estimates, one bitcoin transaction consumes as much energy as 1.5 million Visa transactions. Why is bitcoin using so much energy? Most of the energy is used during the bitcoin mining process, which serves at least two significant purposes: a) distributing new cryptocurrency coins to the cryptoeconomy and b) securing the Bitcoin blockchain ledger. In reality, the comparison of bitcoin transactions to Visa transactions is not that simple. The amount of transactions in the Bitcoin network is not directly connected to the amount of bitcoin mining power nor the energy consumption of those mining devices; for example, it is possible to multiply the number of bitcoin transactions per second without increasing the mining power and the energy consumption. Bitcoin is not only “digital money for hackers”. It has very promising future potential as a global reserve currency and a method to make the World Wide Web (WWW) immune to cyberattacks such as the Distributed Denial-of-Service attacks. This survey approached cryptocurrencies’ various technological and environmental issues from many different perspectives. To make various cryptocurrencies, including bitcoin (BTC) and ether (ETH), greener and more justified, what technological solutions do we have? We found that cryptocurrency mining might be cleaner than is generally expected. There is also a plan to make a vast renewable energy source available by combining Ocean Thermal Energy Conversion and Bitcoin mining. There are plans to use unconventional computing methods (quantum computing, reversible computing, ternary computing, optical computing, analog computing) to solve some of the issues regarding the vast energy consumption of conventional computing (including cryptocurrency mining). We think using spare computing cycles for grid computing efforts is justified. For example, there are billions of smartphones in the world. Many smartphones are being recharged every day. If this daily recharging period of twenty to sixty minutes would be used for grid computing, for example, finding new cures to cancer, it would probably be a significant breakthrough for medical research simulations. We call on the cryptocurrency communities to research and develop grid computing and unconventional computing methods for the most significant cryptocurrencies: bitcoin (BTC)and ether (ETH).},
  keywords={Bitcoin;Blockchains;Green products;Energy consumption;Air pollution;Peer-to-peer computing;Grid computing;Blockchain;DLT;cryptocurrency;bitcoin;green technology;sustainability;unconventional computing;climate change},
  doi={10.1109/ACCESS.2022.3190891},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{1716070,
  author={Takeuchi, J. and Shouno, O. and Tsujino, H.},
  booktitle={The 2006 IEEE International Joint Conference on Neural Network Proceedings}, 
  title={Connectionist Reinforcement Learning with Cursory Intrinsic Motivations and Linear Dependencies to Multiple Representations}, 
  year={2006},
  volume={},
  number={},
  pages={54-61},
  abstract={A significant feature of brain intelligence is flexibility. This is generally lacking in current machine intelligence We think that learning that effectively uses the combination of multiple information representations is the key to constructing flexible machine intelligence. This hypothesis is demonstrated by means of a simple connectionist model of intrinsically motivated reinforcement learning. A linear approximation of reward functions that depends on multiple representations is engaged in our model. We show preliminary results for a model network that enables a flexible learning response to several different situations. Multiple representations in our model accelerate the learning not only in complex situations that need many kinds of information, but also in simple situations.},
  keywords={Basal ganglia;Machine intelligence;Intelligent sensors;Animals;Brain modeling;Learning systems;Intelligent systems;Decision making;Machine learning;Information representation},
  doi={10.1109/IJCNN.2006.246659},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10019495,
  author={Wei, Ming-Liang and Lue, Hang-Ting and Ho, Shu-Yin and Lin, Yen-Po and Hsu, Tzu-Hsuan and Hsieh, Chih-Chang and Li, Yung-Chun and Yeh, Teng-Hao and Chen, Shih-Hung and Jhu, Yi-Hao and Li, Hsiang-Pang and Hu, Han-Wen and Hung, Chun-Hsiung and Wang, Keh-Chung and Lu, Chih-Yuan},
  booktitle={2022 International Electron Devices Meeting (IEDM)}, 
  title={Analog Computing in Memory (CIM) Technique for General Matrix Multiplication (GEMM) to Support Deep Neural Network (DNN) and Cosine Similarity Search Computing using 3D AND-type NOR Flash Devices}, 
  year={2022},
  volume={},
  number={},
  pages={33.3.1-33.3.4},
  abstract={The massively increasing data in computing world inspires the R&D of novel memory-centric computing architectures and devices. In this work, we propose a novel analog CIM technique for GEMM using 3D NOR Flash devices to support general-purpose matrix multiplication. Our analysis indicates that it’s very robust to use “billions” of memory cells with modest 4-level and large-spacing analog Icell to produce good accuracy and reliability, contrary to the past thinking to pursue many levels in each memory cell that inevitably suffers accuracy loss. We estimate that a 2.7Gb 3D NOR GEMM can provide a high-performance (frame/sec>300) image recognition inference of ResNet-50 on ImageNet dataset, using a simple flexible controller chip with 1MB SRAM without the need of massive ALU and external DRAM. The accuracy can maintain ~85% for Cifar-10 (by VGG7), and ~90% for ImageNet Top-5 (by ResNet-50) under good device control. This 3D NOR GEMM enjoys much lower system cost and flexibility than a complicated SOC. We also propose an operation and design method of “Cosine Similarity” computing using the 3D NOR. We can use a ternary similarity search algorithm with positive and negative inputs and weights to perform high-dimension feature vector (such as 512 for face recognition with FaceNet on VGGFace2 dataset) similarity computing in a high-parallelism CIM design (512 WL inputs, 1024 BL’s, at Tread=100ns). High-accuracy search (~97.8%, almost identical to 98% of software computing) and high internal search bandwidth (~5Tb/s per chip) are achieved. This in-Flash search accelerator is potential to enable new hardware-aware search algorithms in big data retrieval applications.},
  keywords={Performance evaluation;Three-dimensional displays;Software algorithms;Neural networks;Memory architecture;Random access memory;Common Information Model (computing)},
  doi={10.1109/IEDM45625.2022.10019495},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{5168916,
  author={Song, Chengqi and Zhang, Qian},
  booktitle={2009 6th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks}, 
  title={COFFEE: A Context-Free Protocol for Stimulating Data Forwarding in Wireless Ad Hoc Networks}, 
  year={2009},
  volume={},
  number={},
  pages={1-9},
  abstract={Reputation based and credit-exchange based approaches have been studied extensively to enforce cooperation among non-cooperative nodes in wireless ad hoc networks. Most of the existing solutions are fundamentally context-based ones, which need to accurately identify selfish behaviors, securely maintain the context, and appropriately punish the selfish nodes. These requirements are extremely difficult to satisfy if not impossible. From a completely new angle, this paper proposes a context-free protocol, COFFEE, to enforce cooperation among selfish nodes, which has the ability to transmit a packet over the path successfully without the dependency on the information of other packets' transmission. Considering that every node in the network is rational, during the packet forwarding stage, if the intermediate nodes can not clearly tell whether the packet is destined to them or not, they can not simply drop the packet. Thus, in our proposed COFFEE protocol, through introducing several techniques, for any packet received by any node, the node thinks the packet could be destined to it and forwards the packet to find out the answer. Detailed analysis and performance evaluation have been conducted to demonstrate the effectiveness of the proposed protocol.},
  keywords={Wireless application protocol;Mobile ad hoc networks;Peer to peer computing;Ad hoc networks;Bandwidth;Batteries;Communications Society;Context;Performance analysis;Routing},
  doi={10.1109/SAHCN.2009.5168916},
  ISSN={2155-5494},
  month={June},}@INPROCEEDINGS{6618763,
  author={Celesti, Antonio and Fazio, Maria and Villari, Massimo and Puliafito, Antonio and Mulfari, Davide},
  booktitle={2013 World Congress on Computer and Information Technology (WCCIT)}, 
  title={Remote and deep attestations to mitigate threats in Cloud Mash-Up services}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={Cloud computing is an emerging technology able to offer a plethora of new advanced services. Cloud operators can use and combine such services in order to build new Mash-up Cloud platform and applications. However, security issues have strongly limited the large-scale adoption of Cloud computing, especially in business environments and similar application scenarios, where sensitive date need to be protected. At the same time the Trusted Computing technology is bringing a new way of thinking about security of systems. This paper deals with the importance to leverage the Trusted Computing for encouraging the development of secure distributed Mash-up Cloud services. We show how the Remote and Deep Attestation protocols make secure both the physical hosts and the virtual machines in a Cloud infrastructure, providing a solid framework for the deployment of federated environments.},
  keywords={Principal component analysis;Software;Servers;Hardware;Virtual machine monitors;Malware;Cloud Computing;Trusted Computing;Deep Attestation;Virtual Machine;PaaS;Federation},
  doi={10.1109/WCCIT.2013.6618763},
  ISSN={},
  month={June},}@ARTICLE{10330580,
  author={Huang, Yuhong and Sun, Qi and Li, Nan and Chen, Ziqi and Huang, Jinri and Ding, Haiyu and Ⅰ, Chih-Lin},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Validation of Current O-RAN Technologies and Insights on the Future Evolution}, 
  year={2024},
  volume={42},
  number={2},
  pages={487-505},
  abstract={Entering the 5G era, the mobile network operators (MNO) are facing greater challenges in providing services cost effectively than any other previous generations. The potential solutions to this are lying on the emerging trend of deep convergence of information technology (IT), communication technology (CT) and data technology (DT). In particular, the O-RAN technology, the representation of such ICDT convergence and proposed by the O-RAN ALLIANCE in 2018, is transforming Radio Access Networks towards a new paradigm featuring openness, cloudification and intelligence. O-RAN has gained huge attention from both industry and academia since its inception. In this paper, we presented the recent endeavors from China Mobile, including our deployment scenarios, various test results from open fronthaul, cloud platform to the intelligent controller. Our rich and comprehensive tests have demonstrated the viability and superiority of current O-RAN technologies. Furthermore, we also provide our deep thinking on the O-RAN future evolution in order to better serve the emerging applications such as Metaverse, cloud extended-reality (XR), extensive enterprise private 5G verticals and so on.},
  keywords={Computer architecture;Hardware;5G mobile communication;Synchronization;Cloud computing;Testing;Microprocessors;O-RAN;cloudification;RAN intelligent controller;prototype;field trial},
  doi={10.1109/JSAC.2023.3336180},
  ISSN={1558-0008},
  month={Feb},}@INPROCEEDINGS{4076980,
  author={Griffith, Doug},
  booktitle={2007 40th Annual Hawaii International Conference on System Sciences (HICSS'07)}, 
  title={Neo-symbiosis: A Conceptual Tool for System Design}, 
  year={2007},
  volume={},
  number={},
  pages={294b-294b},
  abstract={In 1960 Licklider advanced the notion of symbiosis between humans and computers that would think as no human brain has ever thought. This paper updates Licklider 's vision of symbiosis and recasts it into current theories of cognition. This updated version of Licklider's vision is termed neo-symbiosis. Kahneman's notion of two processing systems provides a useful theoretical framework for capturing both expertise and information processing biases. System 1, termed intuition, is fast and effortless. It is simultaneously the source of much human expertise, while also being the locus of cognitive and perceptual illusions. System 2, termed reasoning, is the locus of rational thought. It also has the task of monitoring System 1 output. Computers need to support System 2 processing. A neo-symbiotic design philosophy is presented followed by an illustrative example. Evaluative metrics are discussed. It is concluded that even absent evaluation metrics, neo-symbiosis provides a desirable design goal},
  keywords={Symbiosis;Humans;Usability;Man machine systems;Laboratories;Information systems;Cognition;Information processing;Computerized monitoring;Process design},
  doi={10.1109/HICSS.2007.397},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{8342098,
  author={Chang, Wanli and Roy, Debayan and Hu, Xiaobo Sharon and Chakraborty, Samarjit},
  booktitle={2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Cache-aware task scheduling for maximizing control performance}, 
  year={2018},
  volume={},
  number={},
  pages={694-699},
  abstract={Embedded control applications are widely implemented on small, low-cost and resource-constrained microcontrollers, e.g., in the automotive domain. Conventionally, control algorithms are designed using model-based approaches, without considering the details of the implementation platform. This leads to inefficient utilization of the resources. With the emergence of the cyber-physical system (CPS)-oriented thinking, there has lately been a strong interest in co-design of control algorithms and their implementation platforms. Some recent efforts have shown that a schedule on multiple applications with more on-chip cache reuse is able to improve the control performance. However, it has not been studied how the control performance can be maximized for a given schedule and how an optimal schedule can be computed. In this work, we propose a two-stage framework to compute the schedule maximizing the overall control performance of all the applications. First, a holistic controller design taking all the sampling periods and sensing-to-actuation delays in a schedule into account is presented, aiming to maximize the overall control performance. Second, a hybrid search algorithm for discrete decision space is reported to efficiently compute an optimal schedule. Experimental results on a case study with multiple automotive applications show that a significant improvement of 10-20% in control performance can be achieved by the proposed cache-aware scheduling approach.},
  keywords={Schedules;Task analysis;Sensors;Optimal scheduling;Control systems;Delays;Feedback control},
  doi={10.23919/DATE.2018.8342098},
  ISSN={1558-1101},
  month={March},}@INPROCEEDINGS{8601794,
  author={bin, First Li Guo and rong, Zhou Fang and Gang, Luo and Hong, Yu and chao, Qian Guo and Liangchi, Shi and En, Yang and Xiang, Li},
  booktitle={2018 International Conference on Power System Technology (POWERCON)}, 
  title={A Research Of Drawing And Application Of Distribution Diagram Of Yunnan Ice Region Based On The Typical Ice Model Of Low Latitude Plateau Area}, 
  year={2018},
  volume={},
  number={},
  pages={3440-3447},
  abstract={The international study of ice model mainly from the perspective of meteorology fluid mechanics, thermodynamics transmission line conductor and insulator ice mechanism research study of ice prediction model has been developed from Lenhard Kuoiwa simple conceptual model development experience model to Makkonen complex concept model and glaze rime hybrid numerical calculation model of freeze. Yunnan province is located in China's southwest, rolling within the territory of mountains, rivers, topography is complex, three-dimensional climate significantly, in climate resource is rich, meteorological disaster is frequent, influenced by monsoon climate, the prevalence of micro topography and microclimate characteristics; Yunnan line ice distribution characteristics of eastern Yunnan, Yunnan north southeast Yunnan wire ice mainly for glaze rime and mixed freezing, and northwest Yunnan is mainly for adhesion wet snow Is one of the areas hit hardest by the ice. Ice distribution can reflect the grid of ice in the area of distribution, further guidance inspect heavy ice monitoring and transmission lines deicing ice design application, reduce line ice disaster accident economic loss caused by ice, improve power grid ice resistance ability and the power supply reliability,This paper comprehensive analysis the Yunnan plateau region, the transmission lines ice distribution factors such as geographic conditions, climate type and on-the-spot investigation to collect typical data grid severe ice disaster in 2008, 1983, in ice model research results at home and abroad for reference, combining with the actual situation of Yunnan in northeast Yunnan, the corresponding ice model is constructed, This paper proposes a new model of ice coating in Yunnan province, which is suitable for studying the new ice model in Yunnan province. Detected in the weather station data for statistical analysis, using the computer on hd electronic topographic map, inductive areas of Yunnan power grid ice distribution, and taken as the basis of the division of ice, ice zoning map of different return period. Through in the new 500Kv DE Maoxian gold officer lines before the field site engineering feasibility study stage, according to the project line to choose the line path, in the ”Yunnan power grid ice distribution” to the first line of the path optimization and avoid ice marked lines need to focus on the path to the investigation of the ice area, fully do sufficient preparation before departure, greatly reduced the time of field reconnaissance, time reduced by about 1/3 of the original, but also improve the working efficiency and the quality of the project. Because Yunnan province special landform, geography, weather, climate, micro topography, and micro climate is numerous, Draught place, pass, canyons, air duct, windward area can cause tiny terrain conductor ice serious increase in local area, these areas of ice thickness can't, according to a broader range of meteorological data to determine when ice districts so the two ”micro” edit, finally get reasonable ice figure. Field test comparison test with many times, think theory model calculated results and the results have some discrepancy, but after altitude elevation and atmospheric circulation, the correction ”micro” two conditions, the result basically reflects the east and northeast Yunnan, Yunnan mountainous terrain upheaval and three-dimensional climate characteristics, the theory research of ice model is more reasonable. Through typical ice model, put forward a preliminary mastered the typical transmission line low latitude plateau area in Yunnan the formation law of ice, ice in Yunnan region distribution simultaneously provide basic data and model support, increased the application of ”practicality”. But transmission lines ice cover is a and the complex of the atmospheric physical processes, at the same time and the topography distribution and climate change have bigger relationship, must continue to carry out the statistical analysis of the actual ice, perfecting the model calculation model and the distribution of its ice.},
  keywords={Analytical models;Power transmission lines;Statistical analysis;Atmospheric modeling;Surfaces;Predictive models;Ice;Ice covering model;Yunnan region;Characteristics of ice;Distribution characteristics;The practical application},
  doi={10.1109/POWERCON.2018.8601794},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{5138215,
  author={Ruiting Yang and Gray, Douglas A. and Ng, Brian W. and Mingyi He},
  booktitle={2009 4th IEEE Conference on Industrial Electronics and Applications}, 
  title={Comparative analysis of signal processing in brain computer interface}, 
  year={2009},
  volume={},
  number={},
  pages={580-585},
  abstract={Brain computer interface (BCI) systems utilise Electroencephalography (EEG) to translate specific human thinking activities into control commands. An essential part of any BCI is a pattern recognition system. In this paper, a number of different features and classifiers are compared in terms of classification accuracy and computation time. Two typical features are studied: autoregressive (AR) and spectrum components along with three different classifiers; the K-nearest neighbor, linear discriminant analysis (LDA) and Bayesian statistical classifiers. The results showed that all classifiers achieved very high accuracies and short computation times.},
  keywords={Signal analysis;Signal processing;Brain computer interfaces;Electroencephalography;Rhythm;Signal processing algorithms;Feature extraction;Frequency;Pattern recognition;Humans;Electroencephalography (EEG);brain computer interface;feature;classifier},
  doi={10.1109/ICIEA.2009.5138215},
  ISSN={2158-2297},
  month={May},}@ARTICLE{9286505,
  author={Wang, Xiaoyi and Eiselmayer, Alexander and Mackay, Wendy E. and Hornbaek, Kasper and Wacharamanotham, Chat},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Argus: Interactive a priori Power Analysis}, 
  year={2021},
  volume={27},
  number={2},
  pages={432-442},
  abstract={A key challenge HCl researchers face when designing a controlled experiment is choosing the appropriate number of participants, or sample size. A priori power analysis examines the relationships among multiple parameters, including the complexity associated with human participants, e.g., order and fatigue effects, to calculate the statistical power of a given experiment design. We created Argus, a tool that supports interactive exploration of statistical power: Researchers specify experiment design scenarios with varying confounds and effect sizes. Argus then simulates data and visualizes statistical power across these scenarios, which lets researchers interactively weigh various trade-offs and make informed decisions about sample size. We describe the design and implementation of Argus, a usage scenario designing a visualization experiment, and a think-aloud study.},
  keywords={Fatigue;Tools;Human computer interaction;Statistics;Sociology;Task analysis;History;Experiment design;power analysis;simulation},
  doi={10.1109/TVCG.2020.3028894},
  ISSN={1941-0506},
  month={Feb},}
