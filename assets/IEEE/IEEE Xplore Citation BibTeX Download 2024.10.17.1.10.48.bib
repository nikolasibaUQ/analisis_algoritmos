@INPROCEEDINGS{6051784,
  author={Moser, Dominik and Riener, Andreas and Zia, Kashif and Ferscha, Alois},
  booktitle={2011 IEEE/ACM 15th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Comparing Parallel Simulation of Social Agents Using Cilk and OpenCL}, 
  year={2011},
  volume={},
  number={},
  pages={88-97},
  abstract={Recent advances in wireless/mobile communication and body worn sensors, together with ambient intelligence and seamless integrated pervasive technology have paved the way for applications operating based on social signals, i.e., sensing and processing of group behavior, interpersonal relationships, or emotions. Thinking in large, it should be apparent that modeling social systems allowing to study crowd behavior emerging from individual entities' (agents') condition and/or characteristics is, in fact, a challenging task. To address the heterogeneity, analytical agent-based models (ABMs) are gaining popularity due to its capability of directly representing individual entities and their interactions, unfortunately, ABMs (in which each agent has unique behavior) are not very well suited for large populations, expressed by exponentially rising simulation time. To solve this problem, the questions (i) how does the parallel execution of such models scale with capabilities of both the machine (number of cores, cluster size, etc.) and agents (behavioral adaptation function, interaction extent, etc.) and (ii) what is, in comparison, the performance coefficient applying the approach of model execution on graphical processors (GPUs) with its different pipelining architecture, need answers. To this end, we have performed simulation runs with parameter variation on a real parallel and distributed hardware platform using Cilk as well as on a GPU employing OpenCL. Simulation efficiency for two realistic models with varying complexity on a scale of 107 agents has shown the usefulness of both approaches.},
  keywords={Graphics processing unit;Adaptation models;Computational modeling;Object oriented modeling;Instruction sets;Sensors;Biological system modeling;Parallel distributed simulation;Shared memory architecture;GPU execution;Multi-core cluster;Agent-based modeling;GPGPU},
  doi={10.1109/DS-RT.2011.12},
  ISSN={1550-6525},
  month={Sep.},}@INPROCEEDINGS{6405443,
  author={Kull, Andres},
  booktitle={2012 IEEE 23rd International Symposium on Software Reliability Engineering Workshops}, 
  title={Automatic GUI Model Generation: State of the Art}, 
  year={2012},
  volume={},
  number={},
  pages={207-212},
  abstract={Modeling has been one of the most significant obstacles to why model-based testing has not been taken into use by industry on a large scale. Therefore, generating models automatically is an attractive way of thinking. In well-structured application domains, such as graphical user interface (GUI), this method can be used successfully. This paper gives a state-of-the-art overview of GUI model generation methods. The paper analyzes the methods from the point of view of model-based testing of GUI applications, where generated GUI models are used for generating the tests.},
  keywords={Graphical user interfaces;Testing;Reverse engineering;Computational modeling;Analytical models;Instruments;Manuals;Model-based testing;automatic GUI model generation;GUI model},
  doi={10.1109/ISSREW.2012.23},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7033637,
  author={Zakay, Netanel and Feitelson, Dror G.},
  booktitle={2014 IEEE 22nd International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems}, 
  title={Preserving User Behavior Characteristics in Trace-Based Simulation of Parallel Job Scheduling}, 
  year={2014},
  volume={},
  number={},
  pages={51-60},
  abstract={Evaluating the performance of a computer system requires the use of representative workloads. Therefore it is customary to use recorded job traces in simulations to evaluate the performance of proposed parallel job schedulers. We argue that this practice retains unimportant attributes of the workload, at the expense of other more important attributes. Specifically, using traces in open-system simulations retains the exact timestamps at which jobs are submitted. But in a real system these times depend on how users react to the performance of previous jobs, and it is more important to preserve the logical structure of dependencies between jobs than the specific timestamps. Using dependency information extracted from traces, we show how a simulation can preserve these dependencies. To do so we also extract user behavior, in terms of sessions and think times between the termination of one batch of jobs and the submission of a subsequent batch.},
  keywords={Throughput;Load modeling;Computational modeling;Analytical models;Reliability;Measurement;Time factors;Workload trace;Feedback;Simulation},
  doi={10.1109/MASCOTS.2014.15},
  ISSN={2375-0227},
  month={Sep.},}@INPROCEEDINGS{9313119,
  author={Li, Mengze and Kuang, Kun and Zhu, Qiang and Chen, Xiaohong and Guo, Qing and Wu, Fei},
  booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={IB-M: A Flexible Framework to Align an Interpretable Model and a Black-box Model}, 
  year={2020},
  volume={},
  number={},
  pages={643-649},
  abstract={Both interpretation and accuracy are very important for a predictive model in real applications, but most of previous works, no matter interpretable models or black-box models, cannot simultaneously achieve both of them, resulting in a tradeoff between model interpretation and model accuracy. To break this trade-off, in this paper, we propose a flexible framework, named IB-M, to align an $\underline{I}$nterpretable model and a $\underline{B}$lack-box $\underline{M}$odel for simultaneously optimizing model interpretation and model accuracy. Generally, we think most of samples that are well-clustered or away from the true decision boundary can be easily interpreted by an interpretable model. Removing those samples can help to learn a more accurate black-box model by focusing on the left samples around the true decision boundary. Inspired by this, we propose a data re-weighting based framework to align an interpretable model and a black-box model, letting them focus on the samples what they are good at, hence, achieving both interpretation and accuracy. We implement our IB-M framework for a real medical problem of ultrasound thyroid nodule diagnosis. Extensive experiments demonstrate that our proposed framework and algorithm can achieve a more interpretable and more accurate diagnosis than a single interpretable model and a single black-box model.},
  keywords={Data models;Predictive models;Thyroid;Medical diagnostic imaging;Computational modeling;Deep learning;Ultrasonic imaging;Interpretable model;Black-box model;Thyroid nodules},
  doi={10.1109/BIBM49941.2020.9313119},
  ISSN={},
  month={Dec},}@ARTICLE{9230430,
  author={Zahálka, Jan and Worring, Marcel and Van Wijk, Jarke J.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={II-20: Intelligent and pragmatic analytic categorization of image collections}, 
  year={2021},
  volume={27},
  number={2},
  pages={422-431},
  abstract={In this paper, we introduce 11–20 (Image Insight 2020), a multimedia analytics approach for analytic categorization of image collections. Advanced visualizations for image collections exist, but they need tight integration with a machine model to support the task of analytic categorization. Directly employing computer vision and interactive learning techniques gravitates towards search. Analytic categorization, however, is not machine classification (the difference between the two is called the pragmatic gap): a human adds/redefines/deletes categories of relevance on the fly to build insight, whereas the machine classifier is rigid and non-adaptive. Analytic categorization that truly brings the user to insight requires a flexible machine model that allows dynamic sliding on the exploration-search axis, as well as semantic interactions: a human thinks about image data mostly in semantic terms. 11–20 brings three major contributions to multimedia analytics on image collections and towards closing the pragmatic gap. Firstly, a new machine model that closely follows the user's interactions and dynamically models her categories of relevance. II-20's machine model, in addition to matching and exceeding the state of the art's ability to produce relevant suggestions, allows the user to dynamically slide on the exploration-search axis without any additional input from her side. Secondly, the dynamic, 1-image-at-a-time Tetris metaphor that synergizes with the model. It allows a well-trained model to analyze the collection by itself with minimal interaction from the user and complements the classic grid metaphor. Thirdly, the fast-forward interaction, allowing the user to harness the model to quickly expand (“fast-forward”) the categories of relevance, expands the multimedia analytics semantic interaction dictionary. Automated experiments show that II-20's machine model outperforms the existing state of the art and also demonstrate the Tetris metaphor's analytic quality. User studies further confirm that II–20 is an intuitive, efficient, and effective multimedia analytics tool.},
  keywords={Analytical models;Semantics;Pragmatics;Computational modeling;Task analysis;Visual analytics;Multimedia analytics;image data;analytic categorization;pragmatic gap},
  doi={10.1109/TVCG.2020.3030383},
  ISSN={1941-0506},
  month={Feb},}@ARTICLE{9169672,
  author={Wang, Bo and Zhao, Mengnan and Wang, Wei and Wei, Fei and Qin, Zhan and Ren, Kui},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Are You Confident That You Have Successfully Generated Adversarial Examples?}, 
  year={2021},
  volume={31},
  number={6},
  pages={2089-2099},
  abstract={Deep neural networks (DNNs) have seen extensive studies on image recognition and classification, image segmentation, and related topics. However, recent studies show that DNNs are vulnerable in defending adversarial examples. The classification network can be deceived by adding a small amount of perturbation to clean samples. There are challenges when researchers want to design a general approach to defend against a wide variety of adversarial examples. To solve this problem, we introduce a defensive method to prevent adversarial examples from generating. Instead of designing a stronger classifier, we built a more robust classification system that can be viewed as a structural black box. After adding a buffer to the classification system, attackers can be efficiently deceived. The real evaluation results of the generated adversarial examples are often contrary to what the attacker thinks. Additionally, we do not assume a specific attack method premise. This incognizance to underlying attacks demonstrates the generalizability of the buffer to potential adversarial attacks. Extensive experiments indicate that the defense method greatly improves the security performance of DNNs.},
  keywords={Perturbation methods;Iterative methods;Computational modeling;Neural networks;Security;Training;Robustness;Deep neural networks;adversarial examples;structural black box;buffer},
  doi={10.1109/TCSVT.2020.3017006},
  ISSN={1558-2205},
  month={June},}@ARTICLE{7544618,
  author={Qi, Xiaokang and Ye, Dexin and Sun, Yongzhi and Li, Changzhi and Ran, Lixin},
  journal={IEEE Transactions on Magnetics}, 
  title={Simulations to True Animals’ Long-Distance Geomagnetic Navigation}, 
  year={2017},
  volume={53},
  number={1},
  pages={1-8},
  abstract={How animals navigate in their cross-continental migration has puzzled scientists for centuries. To date, the mechanism behind this mysterious navigation remains unclear. In this paper, a hypothesis is developed and computer simulations have been performed to investigate long-distance animal navigation. Simulation results show that animals may be able to complete their long-distance navigation by observing a spatial angle included by the geomagnetic field line and a geographic direction, without necessarily knowing any prior landmark information. Our results not only match existing observation reports in detail on the long-distance migration routes of animals, but also are able to explain the conflicting evidence on the role of geomagnetic field in animal navigation. We think our results could help reveal the actual mechanism of animal navigation. This paper also provides a potential solution for global and local area navigation of mankind and machines assisted by artificial sensors.},
  keywords={Navigation;Kalman filters;Computational modeling;Computer simulation;Birds;Prediction algorithms;Animal navigation;biological informatics;geomagnetic field;Kalman filter},
  doi={10.1109/TMAG.2016.2600540},
  ISSN={1941-0069},
  month={Jan},}@INPROCEEDINGS{7889991,
  author={Patel, Jigar and Chouhan, Ankit},
  booktitle={2016 International Conference on Communication and Electronics Systems (ICCES)}, 
  title={An approach to introduce basics of Salesforce.com: A cloud service provider}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={In a recent scenario, IT industries are growing with the help of proper Utilization of available resources. The IT giants like Microsoft, Infosys, IBM, Oracle, & TCS are switching from theirs on premises IT setups to the cloud. Cloud computing is replacing the traditional model in which software applications installed on on-premise hardware, from desktop computers to server rooms, depending on the size of the business. The proposed work is about the cloud platform which is going to change all the traditional views of software, application, and product development Technologies. Salesforce.com is one of the best cloud providers available in the recent scenario. There are number of reasons why IT industries are switching to the Cloud. And there are number of reasons why Industries have to think to adopt Salesforce.com cloud. The proposed work is about to focus on important and common features of salsforce.com. These features are common for any developer to learn and use in to software, application and product development in salesforce.com. The goal of this proposed work is to show the available resources in the salesforce.com which are still new for the developers. This an approach to make people familiar with the salesforce.com cloud provider.},
  keywords={Cloud computing;Computational modeling;Software as a service;Customer relationship management;Servers;Cloud Computing;Iaas;Paas;Saas;Salesforce.com;force.com},
  doi={10.1109/CESYS.2016.7889991},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{1574323,
  author={Andradottir, S. and Goldsman, D. and Schruben, L.W. and Schmeiser, B.W. and Yucesan, E.},
  booktitle={Proceedings of the Winter Simulation Conference, 2005.}, 
  title={Analysis methodology: are we done? [discrete-event simulation]}, 
  year={2005},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={Since 1967, the Winter Simulation Conference has been a forum for the introduction of innovative approaches to effectively analyze discrete-event simulation experiments. The goal of this panel is to bring together key contributors to analysis methodology research in order to clarify areas that they think are essentially complete, and identify areas that need more work. In doing so, we hope to help provide direction to younger researchers looking for the "right" problems to work on.},
  keywords={Computational modeling;Analytical models;Discrete event simulation;Design optimization;Industrial engineering;Analysis of variance;Computer errors;Random variables;Stochastic processes;Computer simulation},
  doi={10.1109/WSC.2005.1574323},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6957180,
  author={Li, Xiaosong and Cai, Wentong and Turner, Stephen John},
  booktitle={2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Efficient Neighbor Searching for Agent-Based Simulation on GPU}, 
  year={2014},
  volume={},
  number={},
  pages={87-96},
  abstract={This paper introduces a strategy to accelerate neighbor searching in agent-based simulations on GPU platforms. Because of their autonomous nature, agents can be processed by threads concurrently on GPU, and the overall simulation can be accelerated consequently. Each agent will simultaneously carry out a sense-think-act cycle in every time step. The neighbor searching is a crucial part in the sensing stage. Detecting and accessing neighbors is a memory intensive task and often becomes the major time consumer in an agent-based simulation. Our contribution, an enhanced neighbor sharing strategy, greatly speeds up this procedure when comparing with CPU implementations. The strategy is developed from a global-memory-only implementation, and then gradually improved by efficiently utilizing the much faster shared memory. In our case studies, speedups of 89.08 and 11.51 are obtained on an NVIDIA Tesla K20 GPU compared with the sequential implementation and OpenMP parallel implementation respectively on an Intel Xeon E5-2670 CPU.},
  keywords={Graphics processing units;Instruction sets;Arrays;Resource management;Computational modeling;Hardware;Neighbor searching;Shared memory;Speedup},
  doi={10.1109/DS-RT.2014.19},
  ISSN={1550-6525},
  month={Oct},}@INPROCEEDINGS{7561126,
  author={Agrawal, Prakash and Vutukuru, Mythili},
  booktitle={2016 Twenty Second National Conference on Communication (NCC)}, 
  title={Trace based application layer modeling in ns-3}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Ns-3 is a widely used as a the network simulator of choice by researchers. It contains many well tested and high quality models of network protocols. However, the application layer models of ns-3 are very simplistic, and do not capture all aspects of real life applications. As a result, there is often a huge gap between the results of real experiments and the corresponding simulations. This problem is particularly exacerbated for wireless simulations, where many networking phenomena like wireless channel contention crucially depend on the application traffic characteristics. One way to bridge the gap between experiments and simulations is to incorporate knowledge from network traces into simulations. To this end, our work builds a trace-based application layer simulator in ns-3. Given a network trace collected from a user, our TraceReplay application layer model automatically generates traffic that is faithful to the real application in the ns-3 simulator. TraceReplay infers and replays only application layer delays like user think times, lets the simulator control the lower layer phenomena. TraceReplay extracts application layer characteristics from a single trace, and replays this information across many users in simulation, by using suitable randomization. Our model is also generic enough to replay any application layer protocol. Validation of our simulation model shows that simulation results obtained using TraceReplay are significantly different from those using other models, and are closer to experimental observations.},
  keywords={Delays;Protocols;Servers;Wireless communication;Computational modeling;Simulation;Data transfer},
  doi={10.1109/NCC.2016.7561126},
  ISSN={},
  month={March},}@INPROCEEDINGS{1586360,
  author={Kravitz, S.A. and Bryant, R.E. and Rutenbar, R.A.},
  booktitle={26th ACM/IEEE Design Automation Conference}, 
  title={Massively Parallel Switch-Level Simulation: A Feasibility Study}, 
  year={1989},
  volume={},
  number={},
  pages={91-97},
  abstract={This work addresses the feasibility of mapping the COSMOS switch-level simulator onto a computer with thousands of simple processors. COSMOS preprocesses transistor networks into Boolean behavioral models, capturing the switch-level behavior of a circuit in a set of Boolean formulas. We describe a class of massively parallel computers and a mapping of COSMOS onto these computers. We discuss the factors affecting the performance of such a massively parallel simulator including: the amount of parallelism in the simulation model, performance measures for massively parallel machines, and the impact of event scheduling on simulator performance. We have developed compilation tools which automatically map a MOS circuit onto a massively parallel computer. Massively parallel switch-level simulation is illustrated by describing our pilot implementation on a 32k processor Thinking Machines Connection Machine System.},
  keywords={Computational modeling;Circuit simulation;Concurrent computing;Computer simulation;Discrete event simulation;Logic;Switching circuits;Parallel processing;Parallel machines;Communication switching},
  doi={10.1145/74382.74399},
  ISSN={0738-100X},
  month={June},}@INPROCEEDINGS{9842631,
  author={Khan, Lamia Parven and Anika, Tasfia Tahsin and Hanif, Suraka Iban and Rahman, Rashedur M.},
  booktitle={2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Network Intrusion Detection Using Stack-Ensemble ANN}, 
  year={2022},
  volume={},
  number={},
  pages={1104-1109},
  abstract={Network and security is connected with each other. At present days thinking about communication without the network is impossible. Since the network is a public domain and anyone can use it, some corrupted people and hackers will try to gain profit by intruding others' sensitive information. The network intrusion can be done by some hackers or the network itself. For that reason ensuring security is more challenging than ever before. The proposed model detects the intrusion types currently in the network by using deep learning ANN and stack ensemble techniques. There is no space for compromise in security so it is strongly recommended to use an intrusion detection system that is more accurate and efficient. The reason for using a stacked ensemble is that even though a single deep learning model is strong enough to detect the intrusion, yet by using the stacked ensemble combines multiple deep learning models together to get a more efficient stronger intrusion detection mechanism.},
  keywords={Deep learning;Computer hacking;Computational modeling;Conferences;Network intrusion detection;Software;Security;ANN;stack;ensemble;ReLu;softmax;overfitting},
  doi={10.1109/COMPSAC54236.2022.00173},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{8885193,
  author={Scherzinger, Stefanie and Seifert, Christin and Wiese, Lena},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={The Best of Both Worlds: Challenges in Linking Provenance and Explainability in Distributed Machine Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1620-1629},
  abstract={Machine learning experts prefer to think of their input as a single, homogeneous, and consistent data set. However, when analyzing large volumes of data, the entire data set may not be manageable on a single server, but must be stored on a distributed file system instead. Moreover, with the pressing demand to deliver explainable models, the experts may no longer focus on the machine learning algorithms in isolation, but must take into account the distributed nature of the data stored, as well as the impact of any data pre-processing steps upstream in their data analysis pipeline. In this paper, we make the point that even basic transformations during data preparation can impact the model learned, and that this is exacerbated in a distributed setting. We then sketch our vision of end-to-end explainability of the model learned, taking the pre-processing into account. In particular, we point out the potentials of linking the contributions of research on data provenance with the efforts on explainability in machine learning. In doing so, we highlight pitfalls we may experience in a distributed system on the way to generating more holistic explanations for our machine learning models.},
  keywords={Machine learning;Distributed databases;Data models;Decision trees;Computational modeling;Entropy;explainable machine learning;distributed computing;provenance},
  doi={10.1109/ICDCS.2019.00161},
  ISSN={2575-8411},
  month={July},}@INPROCEEDINGS{4581462,
  author={Essabbah, M. and Otmane, S and Mallem, M.},
  booktitle={2008 Conference on Human System Interactions}, 
  title={3D molecular modeling: from theory to applications}, 
  year={2008},
  volume={},
  number={},
  pages={350-355},
  abstract={Genomic sequences are initially known by their linear form. However, they have also a three-dimensional structure which can be useful for genomes analysis. This 3D structure representation brings a new point of view for the sequences analysis. It was established that the importance of the molecular spatial structure has created increasingly a growing interest for 3D modeling molecules. Therefore, several studies have described the design of software for 3D molecular visualization. Some of these tools offer even 3D molecular manipulation through virtual models. But these 3D models are often based on predictive methods leading to a family of so-called predictive models. This constraint has meant that biologists doubt the effectiveness of these models, thinking they lack of structural realism and therefore functional one. The solution that we propose is the confrontation between models and real data. This approach compares 3D virtual models and real microscopic images of the same molecule in order to validate and/or improve the 3D model. User interaction is possible to enhance comparison.},
  keywords={Biological system modeling;Biology;Computational modeling;Three dimensional displays;Solid modeling;Proteins;RNA;Molecular biology;3D modeling;3D visualization;3D interactive systems},
  doi={10.1109/HSI.2008.4581462},
  ISSN={2158-2254},
  month={May},}@INPROCEEDINGS{1574548,
  author={Gustavsson, P.M. and Planstedt, T.},
  booktitle={Proceedings of the Winter Simulation Conference, 2005.}, 
  title={The road towards multi-hypothesis intention simulation agents architecture - fractal information fusion modeling}, 
  year={2005},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={This paper presents the road towards multi-hypothesis intention simulation agents architecture and is focused on the fractal information fusion model (FIF) that are formed to support a systems-thinking in an agent architecture that aligns with the global information grid, NATO net enabled capabilities and Swedish armed force enterprise architecture initiatives. The Joint Directors of Laboratories information fusion model and the Observe, Orient, Decide, Act loop by John Boyd is combined and used as the foundation together with the knowledge model, level of conceptual interoperability shaping the FIF-model. The FIF-model's effect in shaping of the multi-hypothesis intention simulation agents architecture is presented},
  keywords={Fractals;Service oriented architecture;Computer architecture;Roads;Computational modeling;Computer simulation;Force control;Shape control;Communication system control;Grid computing},
  doi={10.1109/WSC.2005.1574548},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{6385704,
  author={Wagner, Alan R.},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Using cluster-based stereotyping to foster human-robot cooperation}, 
  year={2012},
  volume={},
  number={},
  pages={1615-1622},
  abstract={Psychologists note that humans regularly use categories to simplify and speed up the process of person perception [1]. The influence of categorical thinking on interpersonal expectations is commonly referred to as a stereotype. The ability to bootstrap the process of learning about a newly encountered, unknown person is critical for robots interacting in complex and dynamic social situations. This article contributes a novel cluster-based algorithm that allows a robot to create generalized models of its interactive partner. These generalized models, or stereotypes, act as a source of information for predicting the human's behavior and preferences. We show, in simulation and using real robots, that these stereotyped models of the partner can be used to bootstrap the robot's learning about the partner in spite of significant error. The results of this work have potential implications for social robotics, autonomous agents, and possibly psychology.},
  keywords={Robot kinematics;Humans;Clustering algorithms;Mathematical model;Computational modeling;Classification algorithms},
  doi={10.1109/IROS.2012.6385704},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{9028800,
  author={Wang, Dewen and Zhou, Fangfang and Li, Jiangman},
  journal={Journal of Modern Power Systems and Clean Energy}, 
  title={Cloud-based parallel power flow calculation using resilient distributed datasets and directed acyclic graph}, 
  year={2019},
  volume={7},
  number={1},
  pages={65-77},
  abstract={With the integration of distributed generation and the construction of cross-regional long-distance power grids, power systems become larger and more complex. They require faster computing speed and better scalability for power flow calculations to support unit dispatch. Based on the analysis of a variety of parallelization methods, this paper deploys the large-scale power flow calculation task on a cloud computing platform using resilient distributed datasets (RDDs). It optimizes a directed acyclic graph that is stored in the RDDs to solve the low performance problem of the MapReduce model. This paper constructs and simulates a power flow calculation on a large-scale power system based on standard IEEE test data. Experiments are conducted on Spark cluster which is deployed as a cloud computing platform. They show that the advantages of this method are not obvious at small scale, but the performance is superior to the stand-alone model and the MapReduce model for large-scale calculations. In addition, running time will be reduced when adding cluster nodes. Although not tested under practical conditions, this paper provides a new way of thinking about parallel power flow calculations in large-scale power systems.},
  keywords={Computational modeling;Cloud computing;Newton method;Power grids;Parallel programming;Convergence;Power flow calculation;Parallel programming model;Distributed memory-shared model;Resilient distributed datasets (RDDs);Directed acyclic graph (DAG)},
  doi={10.1007/s40565-018-0406-4},
  ISSN={2196-5420},
  month={January},}@ARTICLE{9677006,
  author={Chen, Fupeng and Yu, Heng and Jiang, Weixiong and Ha, Yajun},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Quality Optimization of Adaptive Applications via Deep Reinforcement Learning in Energy Harvesting Edge Devices}, 
  year={2022},
  volume={41},
  number={11},
  pages={4873-4886},
  abstract={Applications with adaptability are widely available on the edge devices with energy harvesting capabilities. For their runtime quality optimization, however, current approaches cannot tackle the variations of quality modeling and harvested energy simultaneously. Therefore, in this article, we are the first to propose a deep reinforcement learning (DRL)-based dynamic voltage frequency scaling (DVFS) method that optimizes the application execution quality of energy harvesting edge devices to mitigate the variations. First, we propose a baseline DRL formulation that novelly migrates the objective of quality maximization into a reward function and constructs a DRL quality agent. Second, we devise a long short-term memory (LSTM)-based selector that performs DRL quality agent selection based on the energy harvesting history. Third, we further propose two optimization methods to alleviate the nonnegligible overhead of DRL computations: 1) an improved thinking-while-moving concurrent DRL scheme to compromise the “state drifting” issue during the DRL decision process and 2) a variable interstate duration decision scheme that compromises the DVFS overhead incurred in each action taken. The experiments take an adaptive stereo matching application as a case study. The results show that the proposed DRL-based DVFS method on average achieves 17.9% runtime reduction and 22.05% quality improvement compared to state-of-the-art solutions.},
  keywords={Adaptation models;Energy harvesting;Uncertainty;Optimization;Task analysis;Computational modeling;Runtime;Adaptive application;deep reinforcement learning (DRL);energy harvesting;quality optimization;stereo matching},
  doi={10.1109/TCAD.2022.3142188},
  ISSN={1937-4151},
  month={Nov},}@INPROCEEDINGS{6218402,
  author={Kampichler, Wolfgang and Eier, Dieter},
  booktitle={2012 Integrated Communications, Navigation and Surveillance Conference}, 
  title={Cloud based services in air traffic management}, 
  year={2012},
  volume={},
  number={},
  pages={G5-1-G5-9},
  abstract={Air traffic management (ATM) services are migrating towards a global seamless concept. This requires new thinking not only on the necessary operational changes but also on the technological paradigms that determine our current service architectures. Driven by the availability of more and more bandwidth within wide area ground networks new technologies are emerging such as Cloud Computing. Beyond that, operational concepts of FAA's NEXTGEN and Europe's SESAR include dynamically moving the responsibility for airspace blocks from one facility to another, and ensuring continuity of operation by providing contingency operations. This contribution assesses the applicability of cloud computing in ATM, and the key differences to existing commercial applications. It presents the technical cloud computing elements necessary to achieve a truly global ATM system and addresses harmonization and interoperability aspects such as standardized working procedures and controller working positions equipment for air traffic controllers. Situational awareness is key for the decision making process of controllers and pilots in NEXTGEN. A key element different to commercial cloud applications is the necessity to communicate with aircraft and pilots as cloud participants via narrowband VHF radio communications, SATCOM, or other wireless communications technologies. Situational awareness of these participants is paramount which, in the current system, is automatically provided due to the broadcast nature of voice transmissions from controllers and pilots that can be received and heard by all listeners on a particular frequency nearly simultaneously (propagation delay of the radio signal not considered). To efficiently manage the access to this shared media and limit the access only to “relevant” participants, the concept of ATC sector within a geographical area, with boundaries (horizontal and vertical) aligned with traffic patterns exists today. This paper describes mechanisms that demonstrate how SATCOM, VHF, and various data link technologies can be integrated into a service cloud by virtualizing the sector concept and relaxing or completely removing the dependence on the underlying communications media. The advantage of this concept is that sectors can be dynamically defined based on operational ATM service needs without having to adhere to the coverage limitations of the underlying telecommunications service. The current ATM system is severely limited by the underlying telecommunications service models, most often by programmatic and contractual issues rather than their technical nature. We introduce the concept of a multi-point service within a virtual sector taking into consideration operational NEXTGEN issues and demands related to capacity, performance, and global coverage. Finally we introduce a new communications service model where selected parts of the infrastructure can be selectively and partially outsourced to certified service providers. This concept allows for smoother transition between the existing and next generation technologies, and reduces cost for the taxpayer while maintaining the safety of the flights.},
  keywords={Cloud computing;Aircraft;Computational modeling;Availability;Standards organizations;Organizations},
  doi={10.1109/ICNSurv.2012.6218402},
  ISSN={2155-4951},
  month={April},}@INPROCEEDINGS{9223464,
  author={Mayima, Amandine and Clodic, Aurélie and Alami, Rachid},
  booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}, 
  title={Toward a Robot Computing an Online Estimation of the Quality of its Interaction with its Human Partner}, 
  year={2020},
  volume={},
  number={},
  pages={291-298},
  abstract={When we perform a collaborative task with another human, we are able to tell, to a certain extent, how things are going and more precisely if things are going well or not. This knowledge allows us to adapt our behavior. Therefore, we think it is desirable to provide robots with means to measure in real-time the Quality of the Interaction with their human partners. To make this possible, we propose a model and a set of metrics targeting the evaluation of the QoI in collaborative tasks through the measure of the human engagement and the online task effectiveness. These model and metrics have been implemented and tested within the high-level controller of an entertainment robot deployed in a mall. The first results show significant differences in the computed QoI when in interaction with a fully compliant human, a confused human and a non-cooperative one.},
  keywords={Measurement;Adaptation models;Conferences;Computational modeling;Collaboration;Estimation;Entertainment industry},
  doi={10.1109/RO-MAN47096.2020.9223464},
  ISSN={1944-9437},
  month={Aug},}@ARTICLE{9927310,
  author={Li, Keyu and Wang, Nannan and Xin, Jingwei and Jiang, Xinrui and Li, Jie and Gao, Xinbo and Han, Kai and Wang, Yunhe},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Local Means Binary Networks for Image Super-Resolution}, 
  year={2024},
  volume={35},
  number={5},
  pages={6746-6756},
  abstract={The success of modern single image super-resolution (SISR) algorithms is inspired by the development of deep convolutional neural networks (CNNs). However, these CNN-based methods require considerable computation and complexity, making it impossible for these methods to perform real-time calculations in edge devices. Thus, lightweight model design has become a development trend in the super-resolution field, including pruning, quantization, and other methods. The 1-bit quantization is an extreme lightweight method which can reduce the calculation amount of the model in an extreme manner and is friendly to hardware such as edge devices. Most existing binary quantization approaches lead to a large information loss during forward propagation, especially in detailed color information (e.g., edge, texture, and contrast). The loss of color information makes modern binary methods unsuitable for SISR tasks. We think the loss occurs because these methods typically utilize a uniform threshold to quantize the weights and activations. Thus, in this article, we thoroughly analyze the difference between normal classification tasks and SISR tasks, and present a binarization scheme based on local means. The proposed method can maintain more detailed information in feature maps using dynamic thresholds during quantization. Specifically, each value in the full precision activations has a corresponding threshold during the quantization process, and those thresholds are determined by the full precision values of the surroundings. In addition, a gradient approximator is introduced to adaptively optimize the gradient for updating binary weights. We then verify the effectiveness of our method for training binary networks on several SISR benchmarks including VDSR and SRResNet. Experimental results show that the proposed method can outperform the state-of-the-art algorithms to obtain binary networks for image super-resolution with better peak signal-to-noise ratio (PSNR) values and visual quality.},
  keywords={Superresolution;Quantization (signal);Task analysis;Convolution;Training;Computational modeling;Visualization;Binary neural network (BNN);local means;super resolution (SR)},
  doi={10.1109/TNNLS.2022.3212827},
  ISSN={2162-2388},
  month={May},}@INPROCEEDINGS{7396184,
  author={Zakay, Netanel and Feitelson, Dror G.},
  booktitle={2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Semi-Open Trace Based Simulation for Reliable Evaluation of Job Throughput and User Productivity}, 
  year={2015},
  volume={},
  number={},
  pages={413-421},
  abstract={New scheduling algorithms are first evaluated using simulation. In these simulations, the workload has a huge influence on the measured performance of the simulated system. Therefore, it is customary to use workload traces recorded previously from real systems. Such open-system simulations preserve all the jobs' properties. However, preserving the jobs' arrival times actually destroys the logic of the user's workflow, especially dependencies and think times between successive jobs. Furthermore, performance in such simulations is measured by the average wait time and slowdown, under the fixed load and throughput conditions dictated by the trace. Therefore, it is impossible to evaluate the system's effect on throughput and productivity. As an alternative we propose semi-open trace based simulations that include dynamic user activity and internal feedback from the system to the users. In these simulations, like in a real system, users adjust their job-submittal behavior in response to system performance. As a result, the simulations produce different loads and throughputs for different scheduling algorithms or parametrizations. We implemented such a simulation for evaluating the schedulers of parallel job systems. We also developed a novel user-aware scheduler designed specifically to increase users' productivity. While conventional simulations cannot measure this scheduler's influence reliably, and would suggest it is useless, our simulation evaluates it realistically and shows its beneficial effect on the users' productivity and the system's throughput.},
  keywords={Load modeling;Throughput;Productivity;Uninterruptible power systems;Computational modeling;Data models;Cloud computing;simulations;discrete-event simulation;performance evlauation;trace driven simulation;parallel system;scheduling;resampling;feedback},
  doi={10.1109/CloudCom.2015.35},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{1372322,
  author={Wiedenbeck, S. and Engebretson, A.},
  booktitle={2004 IEEE Symposium on Visual Languages - Human Centric Computing}, 
  title={Comprehension Strategies of End-User Programmers in an Event-Driven Application}, 
  year={2004},
  volume={},
  number={},
  pages={207-214},
  abstract={Teachers may engage in end-user programming to support student learning or administrative activities associated with teaching. The objective of this research is to understand strategies used by teachers in program comprehension and to identify specific problems they face. A think-aloud study was conducted of teachers comprehending an event-driven application, consisting of a graphical user interface and the scripts controlling it. We found that end users followed a strongly top-down strategy and breadth-wise exploration of the application. Depth-wise exploration was observed in half the teachers. Teachers varied greatly in their motivations and persistence to dig deeply into the code. Problems of the teachers included difficulties comprehending the event-driven application, given the distributed nature of the code, choosing appropriate inputs for running the program, and reasoning about the results of their test runs.},
  keywords={Programming profession;Educational institutions;Graphical user interfaces;Education;Testing;Mathematics;Application software;Computational modeling;Writing;Web pages},
  doi={10.1109/VLHCC.2004.12},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{5718704,
  author={Kristensson, Per and Gustafsson, Anders and Witell, Lars},
  booktitle={2011 44th Hawaii International Conference on System Sciences}, 
  title={Collaboration with Customers - Understanding the Effect of Customer-Company Interaction in New Product Development}, 
  year={2011},
  volume={},
  number={},
  pages={1-9},
  abstract={Customer co-creation is becoming increasingly popular among companies, and intensive communication with the customer is generally seen as a determinant of new product success. However, there is still limited insight into what interaction with customers really is. The most recent thinking argues for an understanding of value-in-context in order to co-create value with customers. The question, then, is how value-in-context can be captured and how this knowledge can be beneficial in the development process. In essence in order to capture this type of information a company needs to interact and communicate with their customers. However, this communication process has not been properly analyzed. In the present study we analyze customer collaboration based on four separate dimensions - frequency, direction, modality, and content - in order to understand the value of customer collaboration. The data comes from a survey of 207 managers with experience of new service and product development. The paper concludes that three of the four dimensions of customer collaboration have a significant positive effect on New Product Development performance and Market Share development.},
  keywords={Collaboration;Companies;Technological innovation;Computational modeling;Product development},
  doi={10.1109/HICSS.2011.110},
  ISSN={1530-1605},
  month={Jan},}
