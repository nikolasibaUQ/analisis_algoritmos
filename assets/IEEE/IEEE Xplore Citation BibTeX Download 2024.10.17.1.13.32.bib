@INPROCEEDINGS{10000326,
  author={Díaz, Jaime and Bustamante, Ana and Ramírez V., Gabriel M. and Hochstetter, Jorge},
  booktitle={2022 41st International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Video Games Platforms: A Gateway to New Trends for Initial Programming Education}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The teaching of programming is a critical topic in our society. Given the Science and Technology initiatives, these topics are considered in different training cycles: primary, secondary and higher education. In the case of higher education, students must cultivate fundamental concepts for developing computer applications, which contribute to not only the knowledge of programming languages but also open guidelines for computational thinking. In previous research, we evaluated a set of platforms under a usability lens; on this occasion, we compare these results and their impact on the learning outcomes. We evaluated three experimental groups that used video game platforms to achieve their learning outcomes. Additionally, we will synthesize the literature regarding new paradigms of programming education under immersive environments.},
  keywords={Education;Programming profession;Codes;PROM;Visualization;Virtual reality;Video games;Serious Games;Education;Computer Programming;Immersive Learning;Virtual Reality},
  doi={10.1109/SCCC57464.2022.10000326},
  ISSN={2691-0632},
  month={Nov},}@ARTICLE{10247277,
  author={Patel, Archana and Jain, Sarika and Shandilya, Shishir K.},
  journal={Journal of Web Engineering}, 
  title={Data of Semantic Web as Unit of Knowledge}, 
  year={2018},
  volume={17},
  number={8},
  pages={647-674},
  abstract={In service to the state of the art, advances are required toward redesigning the framework over which web applications are built. The semantic web lies at the intersection of web and machine understandable meaningful data, turning it into intelligent ‘web of data’. The key requirement with any intelligent system has been to find a concrete knowledge representation that can make the inferences within time and space constraints; that is, reasoning effectively and efficiently within the resource constraints posed to the problem at one hand and with insufficient data as well as incomplete knowledge on the other hand. Various Knowledge representation schemes have been proposed in the literature, each having its limitation over the others. Ontology is the key component for semantic web engineering. Ontologies are conceptual knowledge bases providing a systematic and taxonomical description of the concepts and instances under consideration. Conceptual clarity in the computational representation of a concept is vital for holistic thinking and knowledge engineering. In order to meet the needs of an application/enterprise, knowledge should be presented taking care of all possible perspectives; and represented in a hierarchical structure with differing levels of granularity. This paper discusses about bringing all the manifestations of an ontological concept/decision under one umbrella; hence describing the resultant scheme as a unit of knowledge. By representing a concept as a knowledge unit, classical ontology is claimed to be sufficient in dealing with imprecise, vague and heterogeneous knowledge for real-world web applications; and portrays the capability to acquire fresh knowledge through its thorough interaction with the external world in a given working environment.},
  keywords={Knowledge engineering;Semantic Web;Systematics;Knowledge acquisition;Knowledge based systems;Semantics;Redundancy;Semantic Web;Ontology;Unit of Knowledge;Knowledge Representation scheme},
  doi={10.13052/jwe1540-9589.1783},
  ISSN={1544-5976},
  month={December},}@INBOOK{9085547,
  author={Pedersen, Isabel and Iliadis, Andrew and Pedersen, Isabel and Iliadis, Andrew and Lupton, Deborah and Warwick, Kevin and Michael, Katina and Michael, MG and Perakslis, Christine and Abbas, Roba and Genosko, Gary and Jethani, Suneel and O'Gorman, Marcel and Wissinger, Elizabeth and Orth, Maggie},
  booktitle={Embodied Computing: Wearables, Implantables, Embeddables, Ingestibles}, 
  title={1 Computer Guts and Swallowed Sensors: Ingestibles Made Palatable in an Era of Embodied Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-20},
  abstract={Picture the following three scenarios. You have an elderly uncle named Buck. Given his advanced age, on rare occasions, Uncle Buck forgets to take his prescribed dosages of phenytoin and azathioprine, both lifesaving medications. Stephanie, your best friend's niece, has spent the last two weeks in pain and requires risky surgery to dislodge a foreign object that has become stuck somewhere in her gastrointestinal tract. Once a week, you worry about an increased heartrate, shortness of breath, and begin to wonder whether you should slow down your run. A company, Visceral Data, begins producing smart pills to assist in each of the above three cases. Currently, numerous partners and organizations in academia, government, and the private sector are in fact building ingestible computational technologies that would feature prominently in each of the above scenarios, including the policy frameworks that govern them.1 As former Alphabet executive chair Eric Schmidt once stated, “You will—voluntarily, I might add—take a pill, which you think of as a pill but is in fact a microscopic robot, which will monitor your systems” and share information about what is happening in your body (Bilton 2013).},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262357791},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9085547},}@INBOOK{6300861,
  author={McDonnell, John R. and Reynolds, Robert G. and Fogel, David B.},
  booktitle={Evolutionary Programming IV: Proceedings of the Fourth Annual Conference on Evolutionary Programming}, 
  title={Ethnography of Artificial Culture: Specifications, Prospects, and Constraints}, 
  year={1995},
  volume={},
  number={},
  pages={319-331},
  abstract={In a recent article I discussed some of the possible research benefits for anthropology of applying the computational paradigm of artificial life (AL) to the scientific study of cultural evolution. I referred to this program as artificial culture (AC). Culture, in this view comprises not only the cognitive processes of individuals (what they think), but includes their behaviors (what they do), and the products of their labors (what they make) as well. AC comprises a population of individual agents, each with its own sensors, cognizers, and actuators interacting with other agents, with products of their own manufacture, and with an external world containing objects and limited and resources situated on a grid. All inanimate objects are given a materiality constrained by a physics, and animate objects are further constrained by a metabolism. Further specifications, potentials and constraints are discussed here for a simplified implementation called T.I.E.R.S. (Trade, Information Exchange, and Risk Sharing). Along with robot sociology, this strategy may help to clarify the role of the individual in society, the dynamics of cooperation and competition, and the general epistemology of emergence.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262290920},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/6300861},}@INPROCEEDINGS{4031205,
  author={Zuo, Lin and Liu, Shaohua and Wei, Jun},
  booktitle={2006 10th IEEE International Enterprise Distributed Object Computing Conference (EDOC'06)}, 
  title={A Fault-Tolerant Scheme for Complex Transaction Patterns in J2EE}, 
  year={2006},
  volume={},
  number={},
  pages={165-174},
  abstract={End-to-end reliability is an important issue in building large-scale distributed enterprise applications based on multi-tier architecture, but the support of reliability as adopted in conventional replication or transactions mechanisms is not enough due to their distinct objectives - replication guarantees the liveness of computational operations by using forward error recovery, while transactions guarantee the safety of application data by using backward error recovery. Combining the two mechanisms for stronger reliability is a challenging task Current solutions, however, are typically on the assumption of simple transaction pattern where a request from a single client executes in the context of exactly one transaction at the middle-tier application server, and seldom think about some complex patterns, such as client transaction enclosing multiple client requests or nested transactions. In this paper, we first identify four transaction pattern classes, and then propose a fault-tolerant scheme that can uniformly provide exactly-once semantic reliability support for these patterns. In this scheme, application servers are passively replicated to endow business logics with high reliability and high availability. In addition, by replicating transaction coordinator, the blocking problem of 2PC protocol during distributed transactions processing is eliminated. We have implemented this approach and integrated it into our own J2EE application server, OnceAS. Also, its effectiveness is discussed in different transaction patterns and the corresponding performance is evaluated},
  keywords={Fault tolerance;Buildings;Large-scale systems;Computer architecture;Distributed computing;Safety;Fault diagnosis;Logic;Availability;Protocols},
  doi={10.1109/EDOC.2006.8},
  ISSN={1541-7719},
  month={Oct},}@INPROCEEDINGS{9051523,
  author={Junaid, Mohammed Jawwad Ali and Kumar, Rajeev},
  booktitle={2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM)}, 
  title={Data Science is all Set to Revolutionize the Ultrasound Diagnosis in Medical Health Care}, 
  year={2020},
  volume={},
  number={},
  pages={73-78},
  abstract={Ultrasound (US) with CAD system imaging is a medical diagnostic tool which has become the most commonly performed cross-sectional diagnostic imaging technique in the practice of medicine, and also the one of the most common schemes in the medical diagnostic area to detect diseases in the clinical practice. It is also cheapest, non-ionizing, reliable, portable, and capable of real-time image acquisition, safety, convenience, and low risk, live display makes it acceptance worldwide. US is oldest but with the cult of computer science, data science (machine learning, deep learning) and chip level advancement in the ultrasound devices. This Ultrasound is all set to upgrade and change according to the advancement in evolving technology, information technology with significant challenges and opportunities. High inter- and intra-operator inconsistency and limited image quality management are the few trending issues which are prime focus of the researchers in present days. As mentioned earlier the US devices due to cult introduction of the computer science and data science has become smaller, enhanced computational capability, and become very advanced. Ultrasound also can contribute significantly to decrease changeability with its advanced image processing. However, reading ultrasound imaging is little tricky, in a proposal to make it little supportive to the clinicians and to reduce the load of doctors, many ultrasound computer-aided diagnosis (CAD) systems with different segmentation, classifiers techniques have been launched. In recent years, the success of data science especially deep learning in the image classification and segmentation is very successful. This led to more and more scholars and researchers to think unanimously realizing that improvement in accuracy, Specificity, and sensitivity of the disease finding can be brought by utilizing the deep learning in the ultrasound CAD system. This paper reviews the research which focuses on the ultrasound CAD system utilizing Data science in recent years. Ultrasound CAD system are mainly 1. traditional ultrasound CAD system and deep learning ultrasound CAD system. The different segmentation techniques and the classifier employed in ultrasound CAD system are discussed. Performance of the different CAD systems with different techniques has accounted in the research paper in contrast accuracy, sensitivity, and Specificity in disease finding is noted. This paper will be useful for the researchers who focus on the ultrasound CAD system more over it is the base of the academic research for the fulfillment of the PhD research work.},
  keywords={Data Science;Segmentation;Classifiers;Deep Learning;Machine Learning;Medical Ultrasound;and CAD (computer aided diagnosis)},
  doi={10.1109/ICCAKM46823.2020.9051523},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10578677,
  author={Chatzopoulos, Avraam and Xenakis, Apostolos and Papoutsidakis, Michail and Kalovrektis, Konstantinos and Kalogiannakis, Michail and Psycharis, Sarantos},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Proposing and Testing an Open - Source and Low - Cost Drone Under the Engineering Design Process for Higher Education: The Mechatronics Course Use Case}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The Engineering Design Process (EDP) is contemporary teaching method, applicable within STEM framework, and consists of a series of steps that students – as future engineers – follow, in order to design a prototype artifact and find a solution to a complex engineering problem. These steps usually include problem – solving processes, such as defining the problem, background research, specifying requirements, brainstorming, evaluating, choosing the best solution, developing a prototype, testing the prototype and finally communicating the research results. During the process, students engage themselves with all Computational Thinking (CT) dimensions. In this research, we apply EDP, within the STEM and CT Epistemology framework, in order to design and develop an open – hardware, open – source, low – cost, easy and safe to use, drown, for educational activities, in Higher education. The purpose of this work is to highly engage University students, in developing solutions for complex Mechatronic course - related problems, and evaluate how they achieved their learning objectives. We also design a use case scenario, in which students form proper engineering teams to work with the design of the UAV, to program its behavior and to understand avionics. The simple design, safe use, economic cost, and open philosophy of this drone make it suitable not only for university courses, but also for educational robotics applications, and in STEM education in general, regardless of the educational level.},
  keywords={Costs;Philosophical considerations;Mechatronics;Prototypes;Software;Robots;Programming profession;Drones;Open H/W;Open S/W;Engineering Design Process;Educational Robotics;STEM},
  doi={10.1109/EDUCON60312.2024.10578677},
  ISSN={2165-9567},
  month={May},}@INBOOK{8043524,
  author={Setoodeh, Peyman and Haykin, Simon},
  booktitle={Fundamentals of Cognitive Radio}, 
  title={Introduction}, 
  year={2017},
  volume={},
  number={},
  pages={1-24},
  abstract={This chapter begins the study of cognitive radio with the critical issue as a starting point. Cognitive radio offers a new way of thinking on how to promote efficient use of the radio spectrum by exploiting the existence of spectrum holes. In a related context, the spectrum&#x2010;utilization efficiency of cognitive radio is assessed in the context of four practical system issues: accuracy and reliability, computational speed, management of resources and coexistence of the cognitive radio network alongside the legacy radio network. A principled basis for the dynamic allocation and management of resources in a cognitive radio network is developed based on the fusion of ideas from game theory, control theory, and optimization. The chapter reviews the dominant sources of uncertainty in cognitive radio networks. It also presents an overview of the key concepts discussed in the subsequent chapters of this book.},
  keywords={Cognitive radio;Supply chains;Production facilities;Sensors;Decision making},
  doi={10.1002/9781119405818.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781119405832},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/8043524},}@INPROCEEDINGS{6625220,
  author={Sklyarov, Valery and Skliarova, Iouliia and Kruus, Margus and Mihhailov, Dmitri and Sudnitson, Alexander},
  booktitle={Eurocon 2013}, 
  title={Address-based data processing over N-ary trees}, 
  year={2013},
  volume={},
  number={},
  pages={1790-1797},
  abstract={The existing trends and growing tendency to high-performance computing strongly require traditional computational algorithms to be revised in such a way that would permit optimal hardware implementations to be found. The latter can be done if algorithms can efficiently be mapped to hardware-specific functional blocks that require different style of thinking and manipulation by different operations and memory models. Besides, concurrency (pipelining and parallelism) can be widely applied. This paper focuses on data processing algorithms that use values of incoming data items as memory addresses with one-bit flags indicating presence or absence of data. The main problem of similar known methods is an appearance of huge number of memory cells with no data items (empty holes), which, nevertheless, have to be processed involving lots of unnecessary time. It is proposed to apply N-ary tree technique that enables data items to be stored and found very fast through executing special traversal procedure. Such trees completely differ from known tree-walk tables because they have pre-established configuration that does not require explicit addresses of subsequent (child) nodes. As a result the size of memory needed to keep data items is decreased in number of times. Finally, significantly more complicated problems can be solved faster and with smaller hardware resources. The presented results of numerous experiments clearly demonstrate advantages of the proposed method compared to known implementations.},
  keywords={Hardware;Field programmable gate arrays;Data processing;Memory management;Sorting;Vectors;Encoding;data processing;N-ary tree;hardware implementation;FPGA;sort;search},
  doi={10.1109/EUROCON.2013.6625220},
  ISSN={},
  month={July},}@INPROCEEDINGS{7380623,
  author={Moses J., Sharon and Babu, L.D. Dhinesh},
  booktitle={2015 International Conference on Green Computing and Internet of Things (ICGCIoT)}, 
  title={Analysis of open source cloud infrastructures over cost incurred by closed source Cloud infrastructures}, 
  year={2015},
  volume={},
  number={},
  pages={1076-1082},
  abstract={In today's world, almost every individual uses computational machines for their day to day activities. Contribution of Cloud Computing in our day to day life is commendable. Even a common man has the privilege to use cloud services in the form of email, games, storage and etc., because of Cloud Computing. Cloud services tend to be cheaper and affordable with pay as you use policy. Scalability and on demand service is an added advantage of cloud computing. With all its benefits and simplicity in usage, clouds have earned a huge number of customers. While the growth of cloud computing looks healthy, several issues like security, cloud outages and expenses compel an user to think and analyze before converting to cloud services. This paper discusses about the hidden costs incurred by using closed source cloud services and the advantages of using open source cloud platforms available in the market.},
  keywords={Cloud computing;Security;Virtual machining;Computer architecture;Companies;Virtualization;OpenStack;OpenNebula;Eucalyptus;CloudStack;Reservoir;Nimbus;Cloud Expense},
  doi={10.1109/ICGCIoT.2015.7380623},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10079832,
  author={S J, Anisha Angel and J B, Mala},
  booktitle={2022 Second International Conference on Next Generation Intelligent Systems (ICNGIS)}, 
  title={A Review on Aspect Based Sentiment Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Sentiment analysis, otherwise called emotion AI, is the computational analysis of raw data that uses text to detect a person's sentiment. Opinions and feelings are communicated more frequently and extensively than ever before in the age of social media. The number of likes for social media opinions reveals which subjects are receiving the most attention, allowing companies and artists to better understand what their customers think of their products. As a result, the problem of picture or text sentiment categorization is of tremendous interest. Document level, phrase level, and aspect level sentiment analysis are the three ways for doing sentiment analysis. There are three major jobs at the aspect level. The most important and first objective is to recognise and extract question parts. The second goal is to identify the extremes of diverse points of view on various characteristics: positive, negative, and neutral. Next task is determined by compiling a list of terms that are similar to features. The goal of aspect-level sentiment analysis is to predict the sentiment polarity of each individual aspect term in a sentence, which is a notable challenge in natural language processing. Fine-grained sentiment analysis at the aspect level is a research hotspot.},
  keywords={Sentiment analysis;Social networking (online);Bit error rate;Companies;Feature extraction;Task analysis;Intelligent systems;Sentiment Analysis;Deep Learning;Aspect Based Sentiment Analysis;Parsing},
  doi={10.1109/ICNGIS54955.2022.10079832},
  ISSN={},
  month={July},}@ARTICLE{7339414,
  author={Ma, Jianhua and Zheng, Yumei and Ning, Huansheng and Yang, Laurence T. and Huang, Runhe and Liu, Hong and Mu, Qitao and Yau, Stephen S.},
  journal={IEEE Access}, 
  title={Top Challenges for Smart Worlds: A Report on the Top10Cs Forum}, 
  year={2015},
  volume={3},
  number={},
  pages={2475-2480},
  abstract={Smart worlds begin with smart things, such as smart objects, smart cities, smart manufacturing, and smart systems, are overlaid with sensing and actuation, many embedded in things, and eventually encompass all aspects of the cyber, physical, social, and thinking hyperspace. In the future, human beings will live in a smart environment where both life and work are well addressed by technology, whereas humans will be responsible only for providing creativity. For this purpose, we have organized the first 2015 Smart World Congress, including five IEEE International Conferences. Specifically, a variety of challenges are presented in the field of smart world. Therefore, an open forum on the top ten challenges (Top10Cs) for smart worlds was held under the congress to identify the main challenges through collecting the intelligence existing particularly in crowd wisdom. Top10Cs and related works, as a crowdsourcing approach, discuss and analyze the top challenges for smart worlds based on the selective results of the crowd and experts via an online platform. Moreover, we summarize the experiences obtained in organizing the Top10Cs forum.},
  keywords={Crowdsourcing;Electronic mail;Security;Internet of things;Big data;Organizations;smart worlds;top challenges;collective intel-ligence;crowdsourcing;crowd wisdom;Smart worlds;top challenges;collective intelligence;crowdsourcing;crowd wisdom},
  doi={10.1109/ACCESS.2015.2504123},
  ISSN={2169-3536},
  month={},}@ARTICLE{182763,
  author={},
  journal={IEEE Std 610}, 
  title={IEEE Standard Computer Dictionary: A Compilation of IEEE Standard Computer Glossaries}, 
  year={1991},
  volume={},
  number={},
  pages={1-217},
  abstract={Identifies terms currently in use in the computer field. Standard definitions for thoseterms are established. Compilation of IEEE Stds IEEE Std 1084, IEEE Std 610.2, IEEE Std 610.3, IEEE Std 610.4, IEEE Std 610.5 and IEEE Std 610.12},
  keywords={Terminology;terminology;computer;applications;glossary;definitions;dictionary;610},
  doi={10.1109/IEEESTD.1991.106963},
  ISSN={},
  month={Jan},}@ARTICLE{5733835,
  author={},
  journal={ISO/IEC/IEEE 24765:2010(E)}, 
  title={ISO/IEC/IEEE International Standard - Systems and software engineering -- Vocabulary}, 
  year={2010},
  volume={},
  number={},
  pages={1-418},
  abstract={The systems and software engineering disciplines are continuing to mature while information technology advances. This International Standard was prepared to collect and standardize terminology. Its purpose is to identify terms currently in use in the field and standard definitions for these terms. It is intended to serve as a useful reference for those in the Information Technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute (PMI). This International Standard replaces IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, which was contributed by the IEEE as a source document. The approach and lexical exactitude of IEEE Std 610.12-1990 served as a model for this International Standard. Nevertheless, approximately two thirds of the definitions in this International Standard are new since IEEE Std 610.12 was last updated in 1990, a reflection of the continued evolution in the field.},
  keywords={IEEE standards;ISO standards;IEC standards;Software engineering;Dictionaries;computer;dictionary;information technology;software engineering;systems engineering;terminology;vocabulary},
  doi={10.1109/IEEESTD.2010.5733835},
  ISSN={},
  month={Dec},}@ARTICLE{7906512,
  author={L’Heureux, Alexandra and Grolinger, Katarina and Elyamany, Hany F. and Capretz, Miriam A. M.},
  journal={IEEE Access}, 
  title={Machine Learning With Big Data: Challenges and Approaches}, 
  year={2017},
  volume={5},
  number={},
  pages={7776-7797},
  abstract={The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data.},
  keywords={Big Data;Machine learning algorithms;Data mining;Algorithm design and analysis;Data analysis;Support vector machines;Classification algorithms;Big Data;Big Data Vs;data analysis;data analytics;deep learning;distributed computing;machine learning;neural networks},
  doi={10.1109/ACCESS.2017.2696365},
  ISSN={2169-3536},
  month={},}@ARTICLE{9006805,
  author={Hussein, Mohamed K. and Mousa, Mohamed H.},
  journal={IEEE Access}, 
  title={Efficient Task Offloading for IoT-Based Applications in Fog Computing Using Ant Colony Optimization}, 
  year={2020},
  volume={8},
  number={},
  pages={37191-37201},
  abstract={The current thinking concerning computations required by Internet of Things (IoT) applications is shifting toward fog computing instead of cloud computing, thereby achieving most of the required computations at the network edge of the IoT devices. Fog computing can thus improve the quality of service of delay-sensitive applications by allowing such applications to take advantage of the low latency provided by fog computing rather than the high latency of the cloud. Therefore, tasks in various IoT applications must be effectively distributed over the fog nodes to improve the quality of service, specifically the task response time. In this paper, two nature-inspired meta-heuristic schedulers, namely ant colony optimization (ACO) and particle swarm optimization (PSO), are used to propose two different scheduling algorithms to effectively load balance IoT tasks over the fog nodes under communication cost and response time considerations. The experimental results of the proposed algorithms are compared with those of the round robin (RR) algorithm. The evaluations show that the proposed ACO-based scheduler achieves an improvement in the response times of IoT applications compared to the proposed PSO-based and RR algorithms and effectively load balances the fog nodes.},
  keywords={Task analysis;Cloud computing;Edge computing;Time factors;Quality of service;Delays;Computer architecture;Fog computing;Internet of Things;quality of service;task offloading and scheduling},
  doi={10.1109/ACCESS.2020.2975741},
  ISSN={2169-3536},
  month={},}@ARTICLE{10105236,
  author={Shoufan, Abdulhadi},
  journal={IEEE Access}, 
  title={Exploring Students’ Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={38805-38818},
  abstract={ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
  keywords={Chatbots;Education;Codes;Encoding;Performance evaluation;Oral communication;ChatGPT;students’ perceptions;education},
  doi={10.1109/ACCESS.2023.3268224},
  ISSN={2169-3536},
  month={},}@ARTICLE{9405644,
  author={Kashevnik, Alexey and Shchedrin, Roman and Kaiser, Christian and Stocker, Alexander},
  journal={IEEE Access}, 
  title={Driver Distraction Detection Methods: A Literature Review and Framework}, 
  year={2021},
  volume={9},
  number={},
  pages={60063-60076},
  abstract={Driver inattention and distraction are the main causes of road accidents, many of which result in fatalities. To reduce road accidents, the development of information systems to detect driver inattention and distraction is essential. Currently, distraction detection systems for road vehicles are not yet widely available or are limited to specific causes of driver inattention such as driver fatigue. Despite the increasing automation of driving due to the availability of increasingly sophisticated assistance systems, the human driver will continue to play a longer role as supervisor of vehicle automation. With this in mind, we review the published scientific literature on driver distraction detection methods and integrate the identified approaches into a holistic framework that is the main contribution of the paper. Based on published scientific work, our driver distraction detection framework contains a structured summary of reviewed approaches for detecting the three main distraction detection approaches: manual distraction, visual distraction, and cognitive distraction. Our framework visualizes the whole detection information chain from used sensors, measured data, computed data, computed events, inferred behavior, and inferred distraction type. Besides providing a sound summary for researchers interested in distracted driving, we discuss several practical implications for the development of driver distraction detection systems that can also combine different approaches for higher detection quality. We think our research can be useful despite - or even because of - the great developments in automated driving.},
  keywords={Vehicles;Automation;Task analysis;Monitoring;Visualization;Taxonomy;Psychology;Automotive applications;automated vehicles;data systems;distraction detection;driver distraction;driver monitoring;driving distraction;intelligent transportation;vehicle driving},
  doi={10.1109/ACCESS.2021.3073599},
  ISSN={2169-3536},
  month={},}@ARTICLE{9812604,
  author={Ahmad, Naqash and Ghadi, Yazeed and Adnan, Muhammad and Ali, Mansoor},
  journal={IEEE Access}, 
  title={Load Forecasting Techniques for Power System: Research Challenges and Survey}, 
  year={2022},
  volume={10},
  number={},
  pages={71054-71090},
  abstract={The main and pivot part of electric companies is the load forecasting. Decision-makers and think tank of power sectors should forecast the future need of electricity with large accuracy and small error to give uninterrupted and free of load shedding power to consumers. The demand of electricity can be forecasted amicably by many Machine Learning (ML), Deep Learning (DL) and Artificial Intelligence (AI) techniques among which hybrid methods are most popular. The present technologies of load forecasting and present work regarding combination of various ML, DL and AI algorithms are reviewed in this paper. The comprehensive review of single and hybrid forecasting models with functions; advantages and disadvantages are discussed in this paper. The comparison between the performance of the models in terms of Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) values are compared and discussed with literature of different models to support the researchers to select the best model for load prediction. This comparison validates the fact that the hybrid forecasting models will provide a more optimal solution.},
  keywords={Load forecasting;Load modeling;Forecasting;Predictive models;Biological system modeling;Companies;Meteorology;Load forecasting;machine learning;load shedding;root mean squared error;mean absolute percentage error},
  doi={10.1109/ACCESS.2022.3187839},
  ISSN={2169-3536},
  month={},}@ARTICLE{9583245,
  author={Ahmad, Hussain and Asghar, Muhammad Usama and Asghar, Muhammad Zubair and Khan, Aurangzeb and Mosavi, Amir H.},
  journal={IEEE Access}, 
  title={A Hybrid Deep Learning Technique for Personality Trait Classification From Text}, 
  year={2021},
  volume={9},
  number={},
  pages={146214-146232},
  abstract={Recently, Cognitive-based Sentiment Analysis with emphasis on automatic detection of user behaviour, such as personality traits, based on online social media text has gained a lot of attention. However, most of the existing works are based on conventional techniques, which are not sufficient to get promising results. In this research work, we propose a hybrid Deep Learning-based model, namely Convolutional Neural Network concatenated with Long Short-Term Memory, to show the effectiveness of the proposed model for 8 important personality traits (Introversion-Extroversion, Intuition-Sensing, Thinking-Feeling, Judging-Perceiving). We implemented our experimental evaluations on the benchmark dataset to accomplish the personality trait classification task. Evaluations of the datasets have shown better results, which demonstrates that the proposed model can effectively classify the user’s personality traits as compared to the state-of-the-art techniques. Finally, we evaluate the effectiveness of our approach through statistical analysis. With the knowledge obtained from this research, organizations are capable of making their decisions regarding the recruitment of personals in an efficient way. Moreover, they can implement the information obtained from this research as best practices for the selection, management, and optimization of their policies, services, and products.},
  keywords={Social networking (online);Deep learning;Feature extraction;Convolutional neural networks;Machine learning;Blogs;Data mining;Personality trait;deep learning;artificial intelligence;convolutional neural network;long short-term memory;social networks;machine learning},
  doi={10.1109/ACCESS.2021.3121791},
  ISSN={2169-3536},
  month={},}@ARTICLE{10190626,
  author={AlZubi, Ahmad Ali and Galyna, Kalda},
  journal={IEEE Access}, 
  title={Artificial Intelligence and Internet of Things for Sustainable Farming and Smart Agriculture}, 
  year={2023},
  volume={11},
  number={},
  pages={78686-78692},
  abstract={Technologies like AI and IoT have been employed in farming for some time now, along with other forms of cutting-edge computer science. There has been a shift in recent years toward thinking about how to put this new technology to use. Agriculture has provided a large portion of humanity’s sustenance for thousands of years, with its most notable contribution being the widespread use of effective agricultural practices for several crop types. The advent of cutting-edge IoT know-how with the ability to monitor agricultural ecosystems and guarantee high-quality production is underway. Smart Sustainable Agriculture continues to face formidable hurdles due to the widespread dispersion of agricultural procedures, such as the deployment and administration of IoT and AI devices, the sharing of data and administration, interoperability, and the analysis and storage of enormous data quantities. This work initially analyses existing Internet-of-Things technologies used in Smart Sustainable Agriculture (SSA) to discover architectural components that might facilitate the development of SSA platforms. This paper examines the state of research and development in SSA, pays attention to the current form of information, and proposes an Internet of Things (IoT) and artificial intelligence (AI) framework as a starting point for SSA.},
  keywords={Smart agriculture;Crops;Artificial intelligence;Internet of Things;Farming;Monitoring;Soil;Internet of Things;Sustainable development;Smart agriculture;Internet of Things (IoT);artificial intelligence (AI);smart sustainable agriculture (SSA);smart farming},
  doi={10.1109/ACCESS.2023.3298215},
  ISSN={2169-3536},
  month={},}@ARTICLE{8933508,
  author={Tocoglu, Mansur Alp and Ozturkmenoglu, Okan and Alpkocak, Adil},
  journal={IEEE Access}, 
  title={Emotion Analysis From Turkish Tweets Using Deep Neural Networks}, 
  year={2019},
  volume={7},
  number={},
  pages={183061-183069},
  abstract={Text data analysis of social media is becoming more and more important since it includes the most recent information on what people think about. Likewise, emotion is one of the most valuable parts of human communication, emotion analysis is a type of information extraction process which identifies the emotional states of a given text. In this study, we investigated the performance of deep neural networks on emotion analysis from Turkish tweets. For this, we examined three different deep learning architectures including artificial neural network (ANN), convolutional neural network (CNN) and recurrent neural network (RNN) with long short-term memory (LSTM). Besides, we curated a dataset of Turkish tweets and annotated each tweet automatically for six emotion categories using a lexicon-based approach. For the evaluation, we conducted a set of experiments for each architecture. The results showed that the lexicon-based automatic annotation of tweets is valid. Secondly, ANN produced the worst result as expected, and CNN resulted in the highest score of 0.74 in terms of accuracy measure. Experiments also showed that our proposed approach for emotion analysis of tweets in Turkish performs better than state-of-the-art in this topic.},
  keywords={Twitter;Tagging;Deep learning;Recurrent neural networks;Data mining;Emotion analysis; Twitter;deep learning;Turkish text analysis;text mining;machine learning;information extraction},
  doi={10.1109/ACCESS.2019.2960113},
  ISSN={2169-3536},
  month={},}@ARTICLE{8279419,
  author={He, Dazhong and Wang, Zhenhua and Liu, Jun},
  journal={IEEE Access}, 
  title={A Survey to Predict the Trend of AI-able Server Evolution in the Cloud}, 
  year={2018},
  volume={6},
  number={},
  pages={10591-10602},
  abstract={About a decade ago, people concerned about the risks of adopting cloud computing. It was an unproven new thing that raised more questions than it answered. Nowadays, we hear more about the risks of not adopting the cloud. Three of the leading cloud players, Amazon Web Services, Microsoft Azure, and Google Cloud Platform, and other participants have developed complex cloud platforms that are driving the cloud agenda and launching innovative new products to meet the needs of modern businesses. When looking at processors, core components of the cloud, there is a trend for hyperscale data centers is to move beyond the CPUs and turn to dedicated chips, such as graphics processing units, field programmable gating arrays, and application specific integrated circuits. We think it is an artificial intelligence (AI) realization process and provide a detailed survey about hardware server design in this process. After discussing and summarizing various disclosed techniques and platforms, we conceived a hybrid hardware structure for efficient AI applications.},
  keywords={Cloud computing;Hardware;Servers;Graphics processing units;Field programmable gate arrays;Artificial intelligence;Data centers;Clouds;server;artificial intelligence},
  doi={10.1109/ACCESS.2018.2801293},
  ISSN={2169-3536},
  month={},}@ARTICLE{9044856,
  author={Tian, Wei and Huang, Wei and Yi, Lei and Wu, Liguang and Wang, Chao},
  journal={IEEE Access}, 
  title={A CNN-Based Hybrid Model for Tropical Cyclone Intensity Estimation in Meteorological Industry}, 
  year={2020},
  volume={8},
  number={},
  pages={59158-59168},
  abstract={Accurate estimation of tropical cyclone (TC) intensity is the key to understanding and forecasting the behavior of TC and is crucial for initialization in forecast models and disaster management in the meteorological industry. TC intensity estimation is a challenge because it requires domain knowledge to manually extract TC cloud structure features and form various sets of parameters obtained from satellites. In this paper, a novel hybrid model is proposed based on convolutional neural networks (CNNs) for TC intensity estimation with satellite remote sensing. According to the intensity of TCs, we divide them into three types and use three different models for intensity regression, respectively. The results show that the use of piecewise thinking can improve the model's fitting speed on small samples. A classification network is provided to classify unlabeled TC samples before TC regression, whose results would determine which regression network to estimate these samples. Finally, the estimation values are sent to the backpropagation (BP) neural network to fit the suitable intensity values. Experimental results demonstrate that our model achieves high accuracy and low root-mean-square error (RMSE up to 8.91 kts) by just using inferred images.},
  keywords={Estimation;Satellites;Convolutional neural networks;Convolution;Tropical cyclones;Industries;Meteorology;Convolutional neural networks;hybrid model;tropical cyclone intensity estimation;infrared imagery},
  doi={10.1109/ACCESS.2020.2982772},
  ISSN={2169-3536},
  month={},}@ARTICLE{9388662,
  author={Yang, Rui and Ke, Fengkai and Liu, Huanping and Zhou, Mingcheng and Cao, Hui-Min},
  journal={IEEE Access}, 
  title={Exploring sMRI Biomarkers for Diagnosis of Autism Spectrum Disorders Based on Multi Class Activation Mapping Models}, 
  year={2021},
  volume={9},
  number={},
  pages={124122-124131},
  abstract={Due to the complexity of the etiology of autism spectrum disorders, the existing autism diagnosis method is still based on scales. With the continuous development of artificial intelligence, image-aided diagnosis of brain diseases has been widely studied and concerned. However, many doctors and researchers still doubt the diagnosis basis of the neural network and think that the neural network belongs to a limited interpretable black-box function approximator. They are not sure whether the neural network has learned some interpretive image features like humans. In order to solve this problem, three new models (2D CAM, 3D CAM and 3D Grad-CAM) are proposed for structural Magnetic Resonance Imaging (sMRI) data. The Regions Of Interest (ROI) of subcortical tissues among models and between groups are analyzed based on the heat maps of the three models. The experimental results show that these models mainly distinguish the autism group and the control group according to the voxel value of these ROIs. There are significant differences in mean voxel value and standard deviation of voxel value between the autism group and the control group, such as in the left amygdala, optic chiasm and right hippocampus. According to medical references, these ROIs are closely related to people's speech, cognition and behavior. This can partly explain why autistic patients have unusual symptoms such as speech communication disorder, stereotyped repetitive behavior and so on. The proposed visualization models can provide a good bridge for doctors to understand the brain features learned by the neural network. The research method of this paper may provide a new way for doctors and researchers to find the diagnostic biomarkers of autism, which can greatly speed up the process of modern medical diagnosis and treatment strategies, and liberate doctors from the traditional trial and error.},
  keywords={Brain modeling;Autism;Convolution;Biological neural networks;Biomedical imaging;Medical services;Feature extraction;Autism spectrum disorders;class activation mapping;sMRI;biomarker},
  doi={10.1109/ACCESS.2021.3069211},
  ISSN={2169-3536},
  month={},}
