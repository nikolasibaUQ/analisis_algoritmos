@INPROCEEDINGS{7739687,
  author={Xie, Benjamin and Abelson, Hal},
  booktitle={2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Skill progression in MIT app inventor}, 
  year={2016},
  volume={},
  number={},
  pages={213-217},
  abstract={This paper contributes to the growing body of research that attempts to measure online, informal learning. We analyze skill progression in MIT App Inventor, an informal online learning environment with over 5 million users and 15.9 million projects/apps created. Our objective is to understand how people learn computational thinking concepts while creating mobile applications with App Inventor. In particular, we are interested in the relationship between the progression of skill in using App Inventor functionality and in using computational thinking concepts as learners create more apps. We model skill progression along two dimensions: breadth and depth of capability. Given a sample of 10,571 random users who have each created at least 20 apps, we analyze the relationship between demonstrating domain-specific skills by using App Inventor functionality and generalizable skills by using computational thinking concepts. Our findings indicate that domain-specific and generalizable skills progress similarly; there is a common pattern of expanding breadth of capability by using new skills over the first 10 projects, then developing depth of capability by using previously introduced skills to build more sophisticated apps.},
  keywords={Trajectory;Computational modeling;Programming;Atmospheric measurements;Particle measurements;Vocabulary;Analytical models},
  doi={10.1109/VLHCC.2016.7739687},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{7926870,
  author={Wu, Lijun and Meng, Kun and Xu, Shuo and Li, Shuqin and Ding, Meng and Suo, Yanfeng},
  booktitle={2017 IEEE International Conference on Energy Internet (ICEI)}, 
  title={Democratic Centralism: A Hybrid Blockchain Architecture and Its Applications in Energy Internet}, 
  year={2017},
  volume={},
  number={},
  pages={176-181},
  abstract={Blockchain is attracting more and more attentions from many kinds of fields, such as finance, industry, and theory researchers. Rather than viewing blockchain as a novel technology, we should think it as an innovation for managing digital society, which provides fundamental principles to support democratically distributed applications. Based on the design and application of the Energy Internet, this paper analyzes the core architecture of the initial blockchain technology, and combines the security of the public chain with the efficiency of the private chain, solving the poor efficiency problem of the initial blockchain by using the high efficiency of private chain. At the same time, it inherits the security and non-tampering of initial blockchain. This paper designs a new hybrid blockchain storaging mode that is Block Static Storage(BSS, internal structure is N+X hybrid blockchain, following can be referred to as N+X HBC),for purpose that improving the overall efficiency of the Internet running, achieving decentralized supervision, and provoding a credible, safe and efficient performance of the Energy Internet in the storage of its massive data, as well as a huge business system.},
  keywords={Distributed databases;Internet;Peer-to-peer computing;Cryptography;Hybrid power systems;Online banking;energy internet;hybrid blockchain;decentralized data storage},
  doi={10.1109/ICEI.2017.38},
  ISSN={},
  month={April},}@INPROCEEDINGS{5384111,
  author={Goetz, S. M. and Weyh, Th. and Herzog, H.-G.},
  booktitle={2009 International Conference on Biomedical and Pharmaceutical Engineering}, 
  title={Analysis of a novel magnetic stimulation system: Magnetic harmonic multi-cycle stimulation (MHMS)}, 
  year={2009},
  volume={},
  number={},
  pages={1-6},
  abstract={Magnetic stimulation is nowadays a standard instrument in research as well as clinical applications. But available systems still have some vital problems; these include the extreme energetic ineffectiveness and the poor flexibility of stimulation properties. In the following text we analyse a new degree of freedom for stimulation devices in the time domain. This approach owes its high potential from the simplicity to implement this feature in existing commercial systems. A similar principle has already been applied for a stimulation device long time ago, but was intentionally overdamped to mimic a monophasic system and therefore energetically meaningless. For the current work, the alternative design was implemented into a sophisticated simulation model to predict its properties. A substantial benefit is for instance the feasibility to lower the threshold of the required current within the stimulation coil for creating nervous action potentials dramatically. Accordingly, the energetic impact with its even quadratic relation to the amplitude and especially the reduction of the coil heating are remarkable. The opportunity to control the nervous reaction more precisely and to gain access to the field of more complex spiking patterns is another special attribute. The realization of the concept seems reasonably simple, whereas the impact was found to be enormous. But this shall not block the view of the fact that the discovery and the explanation needs a change of thinking about the stimulating effect of inductive stimulation.},
  keywords={Harmonic analysis;Magnetic analysis;Magnetic stimulation;Coils;Predictive models;Heating;Pulse shaping methods;Skin;Voltage;Shape control;Magnetic Stimulation;Inductive Neurostimulation;TMS;Pulse Shape;Waveform},
  doi={10.1109/ICBPE.2009.5384111},
  ISSN={1947-1394},
  month={Dec},}@INPROCEEDINGS{6944860,
  author={Wu, Ying Choon and Jung, Melody and Lock, Derrick and Chao, Eric and Swartz, Jerome and Jung, Tzyy-Ping},
  booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society}, 
  title={Resting state and task-related brain dynamics supporting insight}, 
  year={2014},
  volume={},
  number={},
  pages={5454-5457},
  abstract={Problems can be solved in a variety of ways. One might systematically evaluate a known space of possible solutions until the right one is found. Alternatively, it may prove necessary to enlarge or restructure the expected problem space - so called “thinking outside the box.” This approach can yield an experience of unexpected insight or feeling of Aha!. Current challenges to understanding this phenomenon from a neurocognitive perspective include the vast diversity of problem domains and time scales for solutions. Whereas the subjective suddenness of an “Aha!” moment may lead to the impression that insight must be precipitated by a set of discrete, short-lived neural events, this report outlines research revealing that even before a problem is presented, scalp-recorded measures of resting or baseline brain states are linked with future performance and likelihood of experiencing insight during the search for a solution. Additionally, this study also shows that compared to more systematic problem solving approaches, insight is accompanied by differences in cortical and likely cognitive engagement that are detectable throughout much of the problem solving phase, rather than being confined to a distinct interval immediately preceding the dawn of a solution. These findings are important for the development of therapies targeting problem solving and reasoning skills, such as those used in cognitive training interventions to mitigate the effects of cognitive decline.},
  keywords={},
  doi={10.1109/EMBC.2014.6944860},
  ISSN={1558-4615},
  month={Aug},}@INPROCEEDINGS{1716123,
  author={Hecht-Nielsen, R.},
  booktitle={The 2006 IEEE International Joint Conference on Neural Network Proceedings}, 
  title={The Mechanism of Thought}, 
  year={2006},
  volume={},
  number={},
  pages={419-426},
  abstract={A fast winners-take-all competition process, termed confabulation, is proposed as the fundamental mechanism of all aspects of cognition (vision, hearing, planning, language, initiation of thought and movement, etc.). Multiple, contemporaneous, mutually interacting confabulations -in which millions of items of relevant knowledge are applied in parallel -are typically employed in thinking. At the beginning of such a multiconfabulation, billions of distinct, potentially viable, conclusion sets are considered. At the end, only one remains. This fast, massively parallel application of relevant knowledge (an alien kind of information processing with no analogue in today's computational intelligence, computational neurobiology, or computer science) is hypothesized to be the core explanation for the information processing effectiveness of thought. This paper presents a synopsis of this confabulation theory of human cortical and thalamic function.},
  keywords={Information processing;Cognition;Auditory system;Process planning;Application software;Computational intelligence;Analog computers;Concurrent computing;Computer science;Humans},
  doi={10.1109/IJCNN.2006.246712},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{7463799,
  author={Abidi, Leila and Cérin, Christophe and Fedak, Gilles and He, Haiwu},
  booktitle={2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)}, 
  title={Towards an Environment for Doing Data Science That Runs in Browsers}, 
  year={2015},
  volume={},
  number={},
  pages={662-667},
  abstract={This article proposes a path for doing Data Science using browsers as computing and data nodes. This novel idea is motivated by the cross-fertilized fields of desktop grid computing, data management in grids and clouds, Web technologies such as NoSQL tools, models of interactions and programming models in grids, cloud and Web technologies. We propose a methodology for the modeling, analyzing, implementation and simulation of a prototype able to run a MapReduce job in browsers. This work allows to better understand how to envision the big picture of Data Science in the context of the Javascript language for programming the middleware, the interactions between components and browsers as the operating system. We explain what types of applications may be impacted by this novel approach and, from a general point of view how a formal modeling of the interactions serves as a general guidelines for the implementation. Formal modeling in our methodology is a necessary condition but it is not sufficient. We also make round-trips between the modeling and the Javascript or used tools to enrich the interaction model that is the key point, or to put more details into the implementation. It is the first time to the best of our knowledge that Data Science is operating in the context of browsers that exchange codes and data for solving computational and data intensive programs. Computational and data intensive terms should be understand according to the context of applications that we think to be suitable for our system.},
  keywords={Browsers;Prototypes;Computational modeling;Context;Adaptation models;Servers;System design using formal modeling;Desktop grids;Data management;Web ecosystem},
  doi={10.1109/SmartCity.2015.145},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6974063,
  author={Li, Bin},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={A novel particle swarm optimization with small world network and group decision information}, 
  year={2014},
  volume={},
  number={},
  pages={1113-1120},
  abstract={Particle swarm optimization (PSO) is a daughter of artificial society and social learning. Hence, this paper excavates the ultimate source of PSO further, and then introduces the thinking of small world network and group decision information into it to obtain a new conceptual framework and algorithm variation for PSO, which is named PSO-WG. At the same time, the PSO-WG is discussed from the perspective of evolutionary computing to clarify the optimizing mechanism and improvement principles, which mainly includes the biological metaphor, implicit parallelism, operator mapping and feedback control analysis. Next, the computational model is proposed for achieve a self-contained optimization solution. Subsequently, a series of benchmark functions are tested and contrasted with the former representative algorithms to validate the feasibility and creditability of the new algorithm whose comprehensive performance is analyzed detailedly. Finally, the deficiency of PSO-WG and the working direction are pointed out clearly.},
  keywords={Birds;Sociology;Statistics;Particle swarm optimization;Optimization;Equations;Topology;particle swarm optimization;small world network;group decision information;evolutionary computing;swarm intelligence;metaphor;computational experiment},
  doi={10.1109/SMC.2014.6974063},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{9094300,
  author={Lathrop, Scott A. and Cahill, Katharine and Gordon, Steven I. and Houchins, Jennifer and Panoff, Robert M. and Weeden, Aaron},
  journal={Computing in Science & Engineering}, 
  title={Preparing a Computationally Literate Workforce}, 
  year={2020},
  volume={22},
  number={4},
  pages={7-16},
  abstract={There is a saying, “Everything changes, but nothing changes.” We are realizing a rapid technological revolution in the development, deployment, and application of computing technologies within every discipline and every sector of society. Yet, our ability to respond to the well-documented need for a large, diverse, computationally literate workforce remains a challenge. We summarize our 35 years of lessons learned for preparing the workforce that can inform efforts to address this challenge. We have pursued a multiprong approach to reach instructors, researchers, professionals, and students on a national scale. Our efforts in scaling up and sustaining activities range from teaching computational thinking through imparting HPC skills. We have been able to scale up these activities through community efforts to share, cooperate, and collaborate. The potential for providing life-long learning to everyone wishing to expand their computational knowledge and skills is greater than any organization can achieve on its own.},
  keywords={Scientific computing;Computational modeling;Computer science education;Program processors;Software tools},
  doi={10.1109/MCSE.2020.2994763},
  ISSN={1558-366X},
  month={July},}@ARTICLE{6882302,
  author={Subbu, Kalyan P. and Zhang, Chi and Luo, Jun and Vasilakos, Athanasios V.},
  journal={IEEE Wireless Communications}, 
  title={Analysis and status quo of smartphone-based indoor localization systems}, 
  year={2014},
  volume={21},
  number={4},
  pages={106-112},
  abstract={Over the past decade, indoor localization has been a topic of interest for both the academic and industrial communities. The need for location estimation, fueled mainly by inaccuracies of GPS indoors, has been addressed by specifically designed systems achieving a high localization accuracy but with a high deployment cost. Lately, dedicated systems are being replaced by smartphones through intelligent use of the built-in sensors. For instance, an accelerometer that can detect user activity can be combined with a wireless radio that captures wireless signal strength information to locate a user. With the advent of such technology, a myriad of systems have been proposed in the literature presenting an indefinite picture to a reader as to which systems actually work and which do not given practical considerations. This article takes up the goal of surveying state-of-the-art smartphone based indoor localization systems with critical analysis on their properties such as accuracies across various sensor designs, energy consumption and computational cost, user satisfaction and so on, thereby providing a status quo of such systems.},
  keywords={Smart phones;IEEE 802.11 Standards;Buildings;Indoor communcation;Fingerprint recognition;Magnetometers;Accelerometers},
  doi={10.1109/MWC.2014.6882302},
  ISSN={1558-0687},
  month={August},}@ARTICLE{10050860,
  author={Han, Binghui and Zahraoui, Younes and Mubin, Marizan and Mekhilef, Saad and Seyedmahmoudian, Mehdi and Stojcevski, Alex},
  journal={IEEE Access}, 
  title={Home Energy Management Systems: A Review of the Concept, Architecture, and Scheduling Strategies}, 
  year={2023},
  volume={11},
  number={},
  pages={19999-20025},
  abstract={Growing electricity demand, the deployment of renewable energy sources and the widespread use of smart home appliances provide new opportunities for home energy management systems (HEMSs), which can be defined as systems that improve the overall energy production and consumption of residential buildings by controlling and scheduling the use of household equipment. By saving energy, reducing residential electricity costs, optimizing the utilization rate and reliability of utility companies’ power systems, and reducing air pollution for society, HEMSs lead to an enhancement in the socioeconomic development of low-carbon economies. This review aims to systematically analyze and summarize the development trends and challenges of HEMSs in recent years. This paper reviews the development history of the HEMS architecture and discusses the characteristics of several major communication technologies in the current HEMS infrastructure. In addition, the common objectives and constraints related to scheduling optimization are classified, and several optimization methods in the literature, including various intelligent algorithms, have been introduced, compared, and critically analyzed. Furthermore, experimental studies and challenges in the real world are also summarized and recommendations are given. This paper reveals the trend from simple to complex in the architecture and functionality of HEMSs, discusses the challenges for future improvements in modeling and scheduling, and shows the development of various modeling and scheduling methods. Based on this review, researchers can gain a comprehensive understanding of current research trends in HEMSs and open up ideas for developing new modeling and scheduling approaches by gaining insight into the trade-offs between optimum solutions and computational complexity.},
  keywords={Optimization;Energy management systems;Home appliances;Renewable energy sources;Market research;Reliability;Optimal scheduling;Demand response;home appliances;home energy management system;optimization;renewable energy resources;smart grid},
  doi={10.1109/ACCESS.2023.3248502},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7145764,
  author={Adeel, Ahsan and Larijani, Hadi and Javed, Abbas and Ahmadinia, Ali},
  booktitle={2015 IEEE 81st Vehicular Technology Conference (VTC Spring)}, 
  title={Critical Analysis of Learning Algorithms in Random Neural Network Based Cognitive Engine for LTE Systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we critically analyze the performance of an intelligent Long-Term Evolution-Uplink (LTE-UL) system having a cognitive engine (CE) embedded in e-NodeB. Performance characterization, optimal radio parameters prediction, and inter-cell-interference coordination (ICIC) are studied. The embedded CE allocates the optimal radio parameters to serving users and suggests the acceptable transmit power to users served by adjacent cells for ICIC. The desired cognition has been achieved with a novel random neural network (RNN) based CE architecture. To achieve the best learning performance, we critically analyzed three learning algorithms, gradient descent (GD), adaptive inertia weight particle swarm optimization (AIW-PSO) and differential evolution (DE). The analysis showed that AIW-PSO was 10.57% better than GD and 8.012% better than DE in terms of learning accuracy (based on MSE), but with considerable compromise on computational time as compared to GD. Moreover, in terms of convergence time (to achieve the MSE less than 1.04E-03), AIW-PSO took 60% less iterations than GD and 50% less than DE.},
  keywords={Training;Artificial intelligence;Neurons;Decision making;Mathematical model;Cognitive radio;Neural networks},
  doi={10.1109/VTCSpring.2015.7145764},
  ISSN={1550-2252},
  month={May},}@INPROCEEDINGS{7883513,
  author={Liu, Xiaotong and Xu, Anbang and Gou, Liang and Liu, Haibin and Akkiraju, Rama and Shen, Han-Wei},
  booktitle={2016 IEEE Conference on Visual Analytics Science and Technology (VAST)}, 
  title={SocialBrands: Visual analysis of public perceptions of brands on social media}, 
  year={2016},
  volume={},
  number={},
  pages={71-80},
  abstract={Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.},
  keywords={Data visualization;Electronic mail;Companies;Twitter;Visual analytics},
  doi={10.1109/VAST.2016.7883513},
  ISSN={},
  month={Oct},}@ARTICLE{976436,
  author={Mishra, B.},
  journal={Computing in Science & Engineering}, 
  title={Comparing gnomes}, 
  year={2002},
  volume={4},
  number={1},
  pages={42-49},
  abstract={The theory behind biocomputing is to look to biological structures and processes for new ways of solving difficult computational problems. But this, need not, be a one-way street: advances in computing can feed back into the study of biology, leading to better biotechnological tools.},
  keywords={Genomics;Bioinformatics;Biology computing;Neoplasms;Quantum computing;Cancer;Biological materials;Laboratories;Springs;Genetics},
  doi={10.1109/5992.976436},
  ISSN={1558-366X},
  month={Jan},}@INPROCEEDINGS{8890176,
  author={Alfieri, L. and Bracale, A. and Varilone, P. and Leonowicz, Z. and Kostyla, P. and Sikorski, T. and Wasowski, M.},
  booktitle={2019 International Conference on Clean Electrical Power (ICCEP)}, 
  title={Methods for Assessment of Supraharmonics in Power Systems. Part I: Theoretical Issues}, 
  year={2019},
  volume={},
  number={},
  pages={110-115},
  abstract={Modern Smart Grids (SGs) are characterized by the simultaneous presence of time-varying and non-linear loads as well as distributed energy sources with power converters which contribute to wide spectra waveform distortions. Moreover, one of the crucial device of the SG architectures is the smart metering systems which utilize high frequencies for the power line communication (PLC) transmission. In particular, the presence of spectral components in the range of 2÷ 150kHz (supraharmonics) has recently become an issue of great interest due to the interaction between widespread diffusion of high-spectral emission devices (e.g., end-user devices and converter-interfaced distributed generation systems) and power line communication systems. The complexity of these waveforms distortions makes their assessment a challenge. This paper critically analyses and compares two methods proposed in recent literature which seem particularly suitable for the spectral analysis of waveforms with wide spectra. One of the methods is based on the sliding-window discrete Fourier transform (SWDFT) referring to IEC standard harmonic estimation. The second method utilizes the sliding-window wavelet-modified ESPRIT-based method (SWWMEM). This is a companion document to a paper of the same title, Part II, where the methods are tested on synthetic and measured waveforms in terms of accuracy and computational efforts.},
  keywords={Microsoft Windows;Distortion;Time-frequency analysis;Spectral analysis;IEC Standards;Discrete Fourier transforms;Discrete wavelet transforms;Power Quality;high-frequency distortions;Wavelet decomposition;ESPRIT method;IEC standard;power line communication},
  doi={10.1109/ICCEP.2019.8890176},
  ISSN={2474-9664},
  month={July},}@ARTICLE{10538326,
  author={Tan, Qian and Li, Hongxiu},
  journal={IEEE Access}, 
  title={Application of Computer Aided Design in Product Innovation and Development: Practical Examination on Taking the Industrial Design Process}, 
  year={2024},
  volume={12},
  number={},
  pages={85622-85634},
  abstract={The intersection of computer science and art has sparked a wave of innovation, particularly in digital visualizations and interactive installations. This abstract explores the symbiotic relationship between these disciplines, highlighting groundbreaking advancements and creative endeavors. Innovations in digital visualizations leverage algorithms and computational techniques to transform data into visually engaging representations. From intricate data sculptures to immersive virtual reality experiences, computer scientists and artists collaborate to push the boundaries of storytelling and communication. These visualizations not only convey complex information effectively but also evoke emotional responses, bridging the gap between technology and human perception. Interactive installations blur the lines between audience and artwork, inviting participation and engagement. Through sensors, augmented reality, and responsive environments, users become active participants in the creation of art, shaping and influencing their experiences in real-time. This dynamic interaction fosters new forms of expression and challenges traditional notions of artistic production. By exploring the intersection of computer science and art, this abstract underscores the transformative power of interdisciplinary collaboration. Through experimentation, exploration, and innovation, digital visualizations and interactive installations continue to redefine the possibilities of creative expression in the digital age.},
  keywords={Design automation;Solid modeling;Industries;Three-dimensional printing;Product development;Collaboration;Design automation;Optimization methods;Computer science;art;digital visualizations;interactive installations;innovation},
  doi={10.1109/ACCESS.2024.3404963},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6076415,
  author={Xhafa, Fatos and Poulovassilis, Alex},
  booktitle={2011 International Conference on Emerging Intelligent Data and Web Technologies}, 
  title={Awareness in P2P Groupware Systems: A Convergence of Contextual Computing, Social Media and Semantic Web}, 
  year={2011},
  volume={},
  number={},
  pages={14-21},
  abstract={P2P systems are currently considered as an important and effective alternative to web-based centric approaches of groupware systems. Decentralisation, direct and interactive communication, personalization and context are among the features of P2P systems that could be beneficial to groupware systems. In particular, such features can support monitoring, awareness, social networking and scaffolding in group collaboration. In this work we present an analysis of advantages in using P2P networks to better support group collaborative processes. In our analysis, P2P groupware systems are conceived as a convergence of several views: contextual computing, social media and semantic web. The contextual computing is an important ingredient to capture the context of the collaboration in a multi-dimension way, including workspace context, documents and information context, time and location contexts, etc. The social media is also considered important for an effective collaboration of peer group, to support members with efficient and scalable communication techniques in social interaction among members. The semantic web concepts and use of languages such as RDF/S enable the representation and reasoning with the diverse range of information required by the P2P middleware and the awareness services. We focus in particular how to achieve event-based awareness in P2P groupware systems that includes different forms of awareness. The user and technical requirements are first derived with reference to Project-Based Learning in P2P learning environments, which is the learning setting that we consider in our work. We then present our computational model for supporting group awareness in such environments and discuss how it meets the identified user and technical requirements.},
  keywords={Collaborative work;Context;Collaborative software;Peer to peer computing;Resource description framework;Availability;P2P systems;Social Networking;Awareness;Distributed Event-Processing;Event-Condition-Action rules;RDF;Project-Based Learning;Scenario-Based Learning;Collaboration},
  doi={10.1109/EIDWT.2011.42},
  ISSN={},
  month={Sep.},}@ARTICLE{4589066,
  author={Rover, Diane T. and Mercado, Ramon A. and Zhang, Zhao and Shelley, Mack C. and Helvick, Daniel S.},
  journal={IEEE Transactions on Education}, 
  title={Reflections on Teaching and Learning in an Advanced Undergraduate Course in Embedded Systems}, 
  year={2008},
  volume={51},
  number={3},
  pages={400-412},
  abstract={An integrated series of courses on embedded systems has been developed at Iowa State University, Ames, spanning early undergraduate to graduate levels. The newest course in the series is CPRE 488: Embedded Systems Design, an advanced undergraduate course that fills a gap in the curriculum by providing system-level design experiences and incorporating new technology advancements. CPRE 488 development focused on lecture-lab integration and laboratory learning. Course and lab activities were designed using a learning model that captures lower-order and higher-order cognition levels of Bloom's taxonomy. The learning experience in the laboratory is characterized using a technique to assess cognitive behavior. Results of applying the Florida Taxonomy of Cognitive Behavior are presented to summarize the depth of student learning and the opportunities for students to progress to higher-order thinking in the laboratory. After two years of experience with the new course, the authors reflect on the course design and outcomes, from both disciplinary and pedagogical viewpoints.},
  keywords={Laboratories;Education;Hardware;Embedded system;Computers;Software;Computational modeling;Cognitive behavior;curriculum integration;embedded computer systems},
  doi={10.1109/TE.2008.921792},
  ISSN={1557-9638},
  month={Aug},}@INPROCEEDINGS{7980111,
  author={Singh, Munindar P. and Chopra, Amit K.},
  booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={The Internet of Things and Multiagent Systems: Decentralized Intelligence in Distributed Computing}, 
  year={2017},
  volume={},
  number={},
  pages={1738-1747},
  abstract={Traditionally, distributed computing concentrates on computation understood at the level of information exchange and sets aside human and organizational concerns as largely to be handled in an ad hoc manner. Increasingly, however, distributed applications involve multiple loci of autonomy. Research in multiagent systems (MAS) addresses autonomy by drawing on concepts and techniques from artificial intelligence. However, MAS research generally lacks an adequate understanding of modern distributed computing. In this Blue Sky paper, we envision decentralized multiagent systems as a way to place decentralized intelligence in distributed computing, specifically, by supporting computation at the level of social meanings. We motivate our proposals for research in the context of the Internet of Things (IoT), which has become a major thrust in distributed computing. From the IoT's representative applications, we abstract out the major challenges of relevance to decentralized intelligence. These include the heterogeneity of IoT components; asynchronous and delay-tolerant communication and decoupled enactment; and multiple stakeholders with subtle requirements for governance, incorporating resource usage, cooperation, and privacy. The IoT yields high-impact problems that require solutions that go beyond traditional ways of thinking. We conclude with highlights of some possible research directions in decentralized MAS, including programming models; interaction-oriented software engineering; and what we term enlightened governance.},
  keywords={Distributed computing;Monitoring;Medical services;Temperature sensors;Multi-agent systems;Computational modeling;Governance;Multiagent systems;Decentralization;Sociotechnical systems;Norms},
  doi={10.1109/ICDCS.2017.304},
  ISSN={1063-6927},
  month={June},}@INPROCEEDINGS{7575888,
  author={Al-Ruithe, Majid and Benkhelifa, Elhadj and Hameed, Khawar},
  booktitle={2016 IEEE 4th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Key Dimensions for Cloud Data Governance}, 
  year={2016},
  volume={},
  number={},
  pages={379-386},
  abstract={Forward thinking organizations recognize that data management solutions on their own are becoming very expensive and failing cope with reality. They need to solve the data problem in a different way, through the implementation of an effective Data Governance. Data Governance needs to take a policy-centric approach to data models, data quality standards, data security and lifecycle management, and processes for defining, implementing and enforcing these policies. Until recently, data governance has largely been informal, in siloes around specific enterprise repositories, lacking structure and the wider support of the organization. In many government departments, data governance exists as a set of very ambiguous and generic regulations. The area of data governance is still under-researched, despite its importance. With the emergence of Cloud computing, and its increased adoption by businesses, public organisations and governments, as much as the potential gains from adopting the technology, businesses face new and more complex challenges. Such emphasize the need for effective data governance strategy and programs, which can ensure best returns for cloud adoption. This paper is one of very few published research, which tackles this subject domain, and attempts to lay its foundations.},
  keywords={Cloud computing;Security;Organizations;Computational modeling;Data models;Law;Data Governance;Cloud Computing;E-Government;Adoption;Data Management},
  doi={10.1109/FiCloud.2016.60},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9350788,
  author={Chen, Yini and Hou, Jun and Li, Qianmu and Long, Huaqiu},
  booktitle={2020 IEEE International Conference on Progress in Informatics and Computing (PIC)}, 
  title={DDoS Attack Detection Based on Random Forest}, 
  year={2020},
  volume={},
  number={},
  pages={328-334},
  abstract={With the development of network technology, distributed denial of service (DDoS) attacks have increasingly become an important security risk that endangers the network. It uses common protocols and services when attacking, so it is difficult to detect through traditional methods. Based on the idea of rational thinking, DDoS attack detection can be simulated as a classification problem that distinguishes between "rational" and "irrational" network flow states. This article analyzes the common TCP flood attacks, UDP flood attacks, and ICMP flood attacks in detail. Define the characteristics of data stream information entropy (DSIE) to characterize attack behavior. A DDoS attack detection method based on random forest classification (RFC) model is proposed. Establish classification models for the above three types of typical attack methods. Through training and learning, it is finally predicted whether the network traffic is normal. Experimental results show that the RFC model can more accurately distinguish between normal traffic and attack traffic, with a higher detection rate and a lower false alarm rate.},
  keywords={Computational modeling;Hidden Markov models;Denial-of-service attack;Floods;Computer crime;Information entropy;Random forests;DDoS attack;random forest classification;attack detection},
  doi={10.1109/PIC50277.2020.9350788},
  ISSN={2329-6259},
  month={Dec},}@INPROCEEDINGS{1174599,
  author={Mendonca, D. and Beroggi, G.E.G. and Wallace, W.A.},
  booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
  title={Evaluating support for improvisation in simulated emergency scenarios}, 
  year={2003},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={Technological systems involving hazards are typically managed by experienced personnel guided by well-formulated, pre-determined procedures. These procedures are designed to ensure that operations proceed in a safe and cost-effective manner. Yet normal operations in these systems are exposed to unexpected contingencies that can require personnel to develop and deploy new procedures in real-time. Creative thinking in such situations is therefore necessary in order to prevent degradation of operations, particularly when there is potential for personal injury, economic loss or environmental damage. One approach to addressing these situations is improvisation. The research described here discusses a series of studies conducted to evaluate the efficacy of a computer-based system for supporting improvisation in simulated crisis situations. The design and implementation of the system are first discussed, drawing upon prior work in blackboard-based systems. The experimental design is then reviewed, followed by a discussion of how the studies were run using groups of emergency response personnel from the Port of Rotterdam in The Netherlands. The group task was to address unexpected contingencies in a timely fashion. A number of measures of group decision effectiveness and uniqueness are presented. Results of the studies suggest that availability of decision support may have had an uneven influence on solution effectiveness and no influence on solution uniqueness. Possible implications for the design of group decision support systems for improvisation are then discussed, along with a number of observations on conducting experimentally-based research on group improvisation.},
  keywords={Personnel;Hazards;Disaster management;Technology management;Real time systems;Degradation;Injuries;Environmental economics;Computational modeling;Computer simulation},
  doi={10.1109/HICSS.2003.1174599},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9497216,
  author={Lim, Thian Li and Lee, Angela Siew Hoong},
  booktitle={2021 International Conference on Computer & Information Sciences (ICCOINS)}, 
  title={Extended TAM and TTF Model: A Framework for the 21st Century Teaching and Learning}, 
  year={2021},
  volume={},
  number={},
  pages={339-334},
  abstract={The use of Information and Communication Technology (ICT) in everyday life of an individual has expanded in recent years. The much-needed skills for 21st century are creativity, able to think critically, communication and collaboration skills. By equipping students with these skills, it will able to prepare students for the challenges in life and work environments in 21st century. The advancement of technology has led to e-learning in education. E-learning refers to online learning, which provides students with a virtual environment in which students engage in several activities. However, even with the increasingly utilise of e-learning platform, research has proven that the issues of students were not fully utilise the functions of e-learning platforms in their learning process still exist. It is just act as a supporting tool for them and lack of communication support provided by learning management system (LMS) has leads to using other platform for communication purposes. Pervasive tools in education such as mobile devices, wearable technology, and RFID has proven to have positive impact on student learning outcome, however its application in higher education settings is still relatively little. Hence with the limitations of current teaching practice with limitations of study focusing on utilizing pervasive tools, therefore the aim of this study is to investigate the important factors which affect the user behaviour of IT devices (pervasive tools). To achieve this, theories of technology acceptance model (TAM) and task technology fit (TTF) was used. Along with TAM and TTF characteristics, factors of enjoyment, usefulness, convenience, compatibility, social influence, computer self-efficacy, and mobility were also considered. This study provides a framework to better understand the factors affect the acceptance of pervasive tools in private universities in Malaysia.},
  keywords={Electronic learning;Technology acceptance model;Computational modeling;Education;Virtual environments;Tools;Mobile handsets;21st century learners;e-learning;pervasive tools;technology acceptance model;task technology fit},
  doi={10.1109/ICCOINS49721.2021.9497216},
  ISSN={},
  month={July},}@ARTICLE{5680622,
  author={Chang, Shu-Hsuan and Chen, Mei-Ling and Kuo, Yen-Kuang and Shen, Yung-Chi},
  journal={IEEE Transactions on Education}, 
  title={A Simulation-Based LED Design Project in Photonics Instruction Based on Industry–University Collaboration}, 
  year={2011},
  volume={54},
  number={4},
  pages={582-589},
  abstract={In response to the growing industrial demand for light-emitting diode (LED) design professionals, based on industry-university collaboration in Taiwan, this paper develops a novel instructional approach: a simulation-based learning course with peer assessment to develop students' professional skills in LED design as required by industry as well as to enhance cognition and metacognition in students in higher education. The simulation-based learning course enables students to understand the influences on LED performance of the variation of different parameters and to seek the best design through comparing the effectiveness of different combinations of parameters. The evaluation results of pre- and post-test knowledge maps and a photonics scoreboard indicate that this project-based instruction may help students understand the operating principles of LEDs and enhance their skill in LED design. The Constructivist Project-based Learning Environment Survey is adopted to demonstrate that the proposed project-based learning environment is beneficial in cultivating student inquiry learning, reflective thinking, teamwork, and skills in creative problem solving.},
  keywords={Light emitting diodes;Education;Photonics;Computational modeling;Physics;Software;Teamwork;Light-emitting diode (LED);peer assessment (PA);project-based learning (PBL);simulation-based learning (SBL)},
  doi={10.1109/TE.2010.2098877},
  ISSN={1557-9638},
  month={Nov},}@INPROCEEDINGS{9982358,
  author={Figueiredo, José and García-Peñalvo, Francisco José},
  booktitle={2022 International Symposium on Computers in Education (SIIE)}, 
  title={Strategies to increase success in learning programming}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Programming is a special activity, which requires very special skills. Creativity, problem solving, persistence, collaboration, communication, critical thinking, commitment, dedication and hard work are some of the skills and characteristics required of those who learn programming. They are also essential characteristics to face all the challenges of the 21st century. Learning programming is a good way to practice and develop these skills. That is why most courses, in the most diverse areas of knowledge, include programming in their curricula. However, programming courses have a bad reputation. These courses have high failure and dropout rates. It is recognized by the whole scientific community in the area that there are problems and difficulties in teaching and learning programming. With this work we want to present our set of strategies and results in the improvement of our system of teaching and learning initial programming, and with that also contribute to the development and resolution of the problem. In this work, we describe a set of activities related to the initial learning of programming with good results. We present the results of the application of a machine-learning model for predicting student failure, with excellent accuracy and precision results. Finally, we argue the improvements in our teaching system and initial learning of programming, with the final results of the course of the last 5 years.},
  keywords={Analytical models;Technological innovation;Computational modeling;Education;Neural networks;Machine learning;Programming;CSO;CS1;programming;teaching programming;learning programming;machine learning},
  doi={10.1109/SIIE56031.2022.9982358},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7016358,
  author={Jacobs, Patricia and List, Phillip and Ludin, Mobeen and Weeden, Aaron and Panoff, Robert M.},
  booktitle={2014 Workshop on Education for High Performance Computing}, 
  title={The Blue Waters Student Internship Program: Promoting Competence and Confidence for Next Generation Researchers in High-Performance Computing}, 
  year={2014},
  volume={},
  number={},
  pages={49-55},
  abstract={The Blue Waters Student Internship Program (BWSIP), a year-long program funded for three years by the National Science Foundation, motivates and trains the next generation of supercomputing researchers. A community engagement partnership of the Blue Waters Petascale Computing Facility at the National Center for Supercomputing Applications (NCSA) and Shodor, the BWSIP has developed, demonstrated, and evaluated novel lessons involving hands-on, interactive, and collaborative methodologies to teach parallel and distributed computing (PDC) and high-performance computing (HPC) topics. Students participating in the program gain experience in the application of highperformance computing to real-world problems in science, mathematics, and engineering through a year-long internship. By engaging undergraduate and graduate students in Petascale computing research and development projects, students build confidence and competence in PDC and HPC.The BWSIP recruited a large and diverse applicant pool from across the US from which 21 research interns reflecting that diversity were selected and each matched with a mentor and a project for the year-long internship. Students, many having only introductory programming experience, began their internship by attending the two-week Petascale Institute -- each day including 6.5 hours of directed, inquiry-based learning and 2 hours of open lab using the run-modify-write paradigm -- during which they were trained in PDC and HPC tools, techniques, and technologies using Blue Waters at NCSA, and by analogy other XSEDE HPC resources. Students then continued working all summer on their home campuses, or were hosted by their mentor, with on-going work expected to be continued during both Fall and Spring semesters.The project engaged an external evaluator to conduct formative and summative assessments of the program. BWSIP Interns participated in pre- and post-surveys, daily reflections/evaluation questions, as well as in a focus group during their training. Even with significant differences in background, knowledge, and with varying projects, participants stated that the two-week institute was an essential element to help them learn conceptual thinking and how to program using parallel computing. It is proposed that the curriculum and approach for the Institute could be adapted for a semester course at the undergraduate or graduate level.},
  keywords={Training;Supercomputers;Collaboration;Conferences;Computational modeling;Communities;Petascale education; Interactive; Templates; Inquiry-based Learning; Experience; Evaluation; Curriculum; Pedagogy; Parallel Computing; High-Performance Computing; Distributed Computing; Supercomputing; Programming},
  doi={10.1109/EduHPC.2014.6},
  ISSN={},
  month={Nov},}
