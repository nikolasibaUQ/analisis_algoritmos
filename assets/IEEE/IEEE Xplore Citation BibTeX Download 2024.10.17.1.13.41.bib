@ARTICLE{8701498,
  author={Wu, Huaiguang and Yang, Yang},
  journal={IEEE Access}, 
  title={Code Search Based on Alteration Intent}, 
  year={2019},
  volume={7},
  number={},
  pages={56796-56802},
  abstract={Code search is to retrieve the method according to the user needs. Many people think of the query as the only one to reflect the user needs. So they start with the query and find the synonyms, semantically similar to the query terms, for query expansion. However, they overlook a fact: the retrieved methods still need to be altered because it does not meet the user needs directly. This implies that the alteration made in the retrieved methods also reflects the user needs. In this paper, we start with the alteration intent (the possible alterations after retrieving methods) and propose to predict the alteration intent and use it for query expansion. The experiment results show that our approach outperforms CodeHow, the approach to use APIs for query expansion, by 59.8% with a precision score of 0.815.},
  keywords={Search engines;Data mining;Mathematical model;Search problems;Computer security;Industries;Code search;query expansion;alteration intent;program context},
  doi={10.1109/ACCESS.2019.2913560},
  ISSN={2169-3536},
  month={},}@ARTICLE{8653296,
  author={Wang, Xin and Qian, Zhihong and Wang, Xue and Huang, Lan},
  journal={IEEE Access}, 
  title={Robust Localization for Cognitive IoT via the Mobile Anchor Node Based on the Diameter-Varying Spiral Line}, 
  year={2019},
  volume={7},
  number={},
  pages={28487-28497},
  abstract={Research on IoT that merely aims at connecting and communicating is about to past. Thereafter, general objects should have the capability to learn, think, and understand both physical and social areas by themselves. Cognitive Internet of Things (CIoT) attempts to empower the current IoT with a “brain” for high-level intelligence, requiring networks to have the ability to bridge the physical and social worlds. This attempt means matching equipment and resources with people and their behavior. Therefore, accurate location information is crucial for equipment connecting to CIoT. This endeavor sets a higher requirement for the localization technology of wireless sensor networks in terms of accuracy, energy, and efficiency compared with that in the past. In this paper, we propose an efficient and accurate mobile anchor node assisted localization algorithm for WSNs based on diameter-varying spiral line (LDVSL), which broadcasts coordinates of the anchor node to assist localizing unknown sensor nodes. The proposed algorithm has two main innovations. First, we obtain the mobile anchor node position through a time and angle mechanism instead of GPS, given the unique characteristics of the diameter-varying spiral line. Second, the linear fitting method is adapted to select the key virtual node, which has the real maximum received signal strength indicator. Simulations indicate that the proposed LDVSL algorithm outperforms other similar algorithms in terms of average localization error and positionable node ratio. The simulations also show that the LDVSL is not affected by obstacles seriously and has good robustness. The LDVSL has a wide prospect of application in CIoT.},
  keywords={Spirals;Path planning;Directional antennas;Wireless sensor networks;Global Positioning System;Internet of Things;Received signal strength indicator;CIoT;localization;mobile anchor node;diameter-varying spiral line;linear fitting},
  doi={10.1109/ACCESS.2019.2901745},
  ISSN={2169-3536},
  month={},}@ARTICLE{8960343,
  author={Wang, Zhu and Yu, Zhiwen and Fan, Renjie and Guo, Bin},
  journal={IEEE Access}, 
  title={Correcting Biases in Online Social Media Data Based on Target Distributions in the Physical World}, 
  year={2020},
  volume={8},
  number={},
  pages={15256-15264},
  abstract={Social media is an important data source. Billions of posts, likes, and connections are created by people all around the world every day. The promises of such social media data are plentiful, including understanding “what the world thinks” about a social issue, brand, product, celebrity, or other entity, as well as enabling better decision-making in a variety of fields including public policy, transportation, healthcare, and economics. However, while the validity of these data-driven researches are largely dependent on the accuracy and representativeness of the used data, online social media data collected with common mechanisms are usually biased compared with the distribution of related features in the physical world. For example, sampling issues, especially selection bias, associated with such data sources can have far reaching implications for data analysis and interpretation. Therefore, how to calibrate biases in the online social media data set to achieve unbiased results becomes a significant and urgent problem. In this paper, we propose to address the bias calibration issue by adopting a data resampling approach. Specifically, we develop a data resampling algorithm based on the stochastic stability theory of Markov Chains to collect data samples from the given biased data set to calibrate possible biases. By regarding the data resampling process as status transitions of a stochastic variable, the algorithm leverages the stationary distribution of Markov Chains to build an acceptance matrix to control the resampling process, and thus optimize the original dataset towards target distributions in the physical world. Experimental results demonstrate that the proposed algorithm can effectively output data sets with similar distributions to the target ones.},
  keywords={Twitter;Sociology;Statistics;Markov processes;Data collection;Bias correction;data bias;data resampling;social media},
  doi={10.1109/ACCESS.2020.2966790},
  ISSN={2169-3536},
  month={},}@ARTICLE{9878097,
  author={Boutros, Andrew and Nurvitadhi, Eriko and Betz, Vaughn},
  journal={IEEE Access}, 
  title={Architecture and Application Co-Design for Beyond-FPGA Reconfigurable Acceleration Devices}, 
  year={2022},
  volume={10},
  number={},
  pages={95067-95082},
  abstract={In recent years, field-programmable gate arrays (FPGAs) have been increasingly deployed in datacenters as programmable accelerators that can offer software-like flexibility and custom-hardware-like efficiency for key datacenter workloads. To improve the efficiency of FPGAs for these new datacenter use cases and data-intensive applications, a new class of reconfigurable acceleration devices (RADs) is emerging. In these devices, the FPGA fine-grained reconfigurable fabric is a component of a bigger monolithic or multi-die system-in-package that can incorporate general-purpose software-programmable cores, domain-specialized accelerator blocks, and high-performance networks-on-chip (NoCs) for efficient communication between these system components. The integration of all these components in a RAD results in a huge design space and requires re-thinking the implementation of applications that need to be migrated from conventional FPGAs to these novel devices. In this work, we introduce RAD-Sim, an architecture simulator that allows rapid design space exploration for RADs and facilitates the study of complex interactions between their various components. We also present a case study that highlights the utility of RAD-Sim in re-designing applications for these novel RADs by mapping a state-of-the-art deep learning (DL) inference FPGA overlay to different RAD instances. Our case study illustrates how RAD-Sim can capture a wide variety of reconfigurable architectures, from conventional FPGAs to devices augmented with hard NoCs, specialized matrix-vector blocks, and 3D-stacked multi-die devices. In addition, we show that our tool can help architects evaluate the effect of specific RAD architecture parameters on end-to-end workload performance. Through RAD-Sim, we also show that novel RADs can potentially achieve  $2.6\times $  better performance on average compared to conventional FPGAs in the key DL application domain.},
  keywords={Field programmable gate arrays;Computer architecture;Fabrics;Hardware acceleration;Performance evaluation;Benchmark testing;Memory management;Deep learning;Reconfigurable logic;Deep learning;field-programmable gate arrays;hardware acceleration;network-on-chip;reconfigurable computing},
  doi={10.1109/ACCESS.2022.3204664},
  ISSN={2169-3536},
  month={},}@ARTICLE{7577724,
  author={Gao, Kun and Zhu, Yiwei},
  journal={IEEE Access}, 
  title={Deep Data Stream Analysis Model and Algorithm With Memory Mechanism}, 
  year={2017},
  volume={5},
  number={},
  pages={84-93},
  abstract={Integrated analysis is an important method for data analysis. Aimed at improving the deficiencies of traditional integrated data stream analysis, a human-like remembering and forgetting mechanism is introduced into data stream analysis, and a deep data stream analysis model based on remembering (DSAR) is proposed. Through this remembering and forgetting mechanism, the model regards basic classifiers as system-obtained knowledge and not only stores useful basic classifiers in a “remembering library” to improve prediction stability but also selects good basic classifiers to participate in integrated prediction, thus improving its ability to accommodate conceptual variations. Based on the DSAR model, an integrated deep data stream analysis (DDSA) algorithm is proposed. The algorithm uses the forgetting curve and a selective ensemble classifier to simulate human thinking. Compared with four typical data stream analysis algorithms, the DDSA algorithm has a high classification accuracy and a strong capacity for accommodating concept drift features (CDFs) within data stream analysis. The DDSA is particularly adaptable to complex CDFs in practical applications. Experiments show that the proposed algorithm can not only adapt to new concept changes quickly but also effectively resist the impact of random fluctuations on system performance.},
  keywords={Classification algorithms;Algorithm design and analysis;Prediction algorithms;Data analysis;Analytical models;Data models;Predictive models;Data stream analysis;remembering and ignoring;ignoring curve;selective ensemble},
  doi={10.1109/ACCESS.2016.2613922},
  ISSN={2169-3536},
  month={},}@ARTICLE{8906122,
  author={Youssef, Ahmed E. and Mostafa, Almetwally M.},
  journal={IEEE Access}, 
  title={Critical Decision-Making on Cloud Computing Adoption in Organizations Based on Augmented Force Field Analysis}, 
  year={2019},
  volume={7},
  number={},
  pages={167229-167239},
  abstract={Cloud Computing (CC) has become an important milestone information technology that attracts many organizations. With the potential to transform business processes, lower IT expenses, and offer access to unlimited computing resources with minimal management effort, organizations look to cloud-based solutions to achieve business efficiencies. Thus, it would seem that these organizations could easily migrate to CC. However, enterprises are still concerned about moving their business-critical applications to the cloud. Among the reasons are that it is an emerging technology that has not reached a level of maturity; the lack of industry-specific conformity to standards; and a high level of security risks. As a result, there is a big dispute among organizations on the decision of whether it is more business-efficient to embark on the cloud or remain with their interior IT infrastructures. In this paper, we aim to solve this debate by proposing a novel approach that supports decision-making on CC adoption in organizations. Unlike traditional decision-making approaches that pay little or no consideration to organizational high-level business objectives, our proposed approach is driven by the business objectives of the organization. First, we identify driving and restraining forces that influence CC adoption in organizations. Second, a formal decision-making model is proposed based on Force Field Analysis (FFA) augmented by pairwise comparison and Delphi methods, this model estimates the values of the driving and restraining forces based on their impacts on the organization's objectives. By analyzing the forces for and against CC adoption, organizations can decide whether or not to move forward with the adoption. Alternatively, organizations can use the analysis to think about how they can strengthen the forces that support the adoption and weaken the forces opposing it, so that the adoption is more successful. The proposed model is validated for usability and applicability through a use case scenario.},
  keywords={Organizations;Cloud computing;Standards organizations;Decision making;Force;Software;Cloud computing;decision making;force field analysis (FFA);pairwise comparison;Delphi method},
  doi={10.1109/ACCESS.2019.2954415},
  ISSN={2169-3536},
  month={},}@ARTICLE{8830475,
  author={Shen, Gang and Han, Dan and Liu, Peiwen},
  journal={IEEE Access}, 
  title={A Sparse Manifold Learning Approach to Robust Indoor Positioning Based on Wi-Fi RSS Fingerprinting}, 
  year={2019},
  volume={7},
  number={},
  pages={130791-130803},
  abstract={The emerging location-based applications depend on the fast and accurate positioning of mobile targets. Wi-Fi received signal strength (RSS) fingerprinting provides a promising solution to localize an object in indoor environments. Among the factors challenging the RSS fingerprinting based algorithms are the site survey cost and the time-varying environment, given the unreliable signal qualities. Here we present a novel approach to indoor object positioning using the manifold assumption on the radio map in RSS-location space. Thinking the measured RSS from one access point (AP) in different locations are randomly drawn from a nonlinear manifold (ground truth), we propose an expectation-maximization (EM) style algorithm to reconstruct the sparse representation of this manifold from the noisy RSS observations. Motivated by the observation that the radio map has a strong local correlation in the RSS-location space, we introduce a multi-scale constrained quadratic programming to approximate the manifold. Within limited iterations, we can estimate the ground truth RSS values and parameters simultaneously. As a result, the learned manifold is exploited to predict the object's position: we develop a positioning algorithm by minimizing the manifold distortion effort which integrates both measurement error and manifold shape preservation. We conducted extensive simulations and experiments in different settings, testing the datasets collected in a building in the last 8 months. The results showed that the proposed approach was adaptive to the varying environmental noise levels, presenting robust positioning performance.},
  keywords={Manifolds;Wireless fidelity;IP networks;Noise measurement;Robustness;Antenna measurements;Position measurement;Expectation-maximization;indoor positioning;manifold learning;received signal strength},
  doi={10.1109/ACCESS.2019.2940629},
  ISSN={2169-3536},
  month={},}@ARTICLE{9171234,
  author={Belwafi, Kais and Gannouni, Sofien and Aboalsamh, Hatim},
  journal={IEEE Access}, 
  title={An Effective Zeros-Time Windowing Strategy to Detect Sensorimotor Rhythms Related to Motor Imagery EEG Signals}, 
  year={2020},
  volume={8},
  number={},
  pages={152669-152679},
  abstract={Brain-computer interface (BCI) acquires, analyzes and transforms human brain activity to control commands allowing as such disabled people to communicate or control external devices. A motor imagery-based BCI enables patients to control artificial peripherals and communicate with the outside world by merely thinking of the task such as, e.g., the imagination of left-hand, right-hand, or foot movement. The mere intention of moving one of the limbs triggers neural activity, which is induced in the primary sensorimotor areas like that observed with real executed movements. Tracking generated sensorimotor rhythms (SMRs) and extracting robust and informative features from electroencephalogram (EEG) signals are challenging due to the time-varying nature of EEG signals and the inter-human variability. In this paper, we proposed an EEG-zeros-time windowing (E2ZTW) approach based on a highly decaying window function to track SMRs and identify the temporal epochs containing useful information without any prior information on the trigger. The proposed approach involves the application of the group-delay function, allowing the improvement of the spectral resolution due to the additive property of the function on individual resonances. Some algorithms were integrated into the proposed approach, such as the common spatial pattern algorithm, which is used to extract features and linear discriminant analysis and a convolutional neural network, which are used for the classification of the features. The effectiveness of the proposed approach in tracking the SMRs rhythms is evaluated in terms of accuracy. Experiments were performed on three public datasets provided by BCI competition for 17 subjects. Following experimental results, it is shown that discrimination between the left- and right-hand movements can be achieved within a few seconds with high classification accuracy. As compared to other state-of-art techniques, the proposed approach achieves an average classification accuracy and standard error values of 82% and 13, respectively, thereby outperforming existing algorithm by an accuracy mean of 2%.},
  keywords={Electroencephalography;Microsoft Windows;Feature extraction;Brain;Training;Task analysis;Tracking;Brain-computer interface (BCI);electroencephalography (EEG);motor imagery;EEG-zero-time windowing;group-delay function},
  doi={10.1109/ACCESS.2020.3017888},
  ISSN={2169-3536},
  month={},}@ARTICLE{9893785,
  author={Din, Nizam Ud and Bae, Seho and Javed, Kamran and Park, Hyunkyu and Yi, Juneho},
  journal={IEEE Access}, 
  title={Cross Modal Facial Image Synthesis Using a Collaborative Bidirectional Style Transfer Network}, 
  year={2022},
  volume={10},
  number={},
  pages={99077-99087},
  abstract={In this paper, we present a novel collaborative bidirectional style transfer network based on generative adversarial network (GAN) for cross modal facial image synthesis, possibly with large modality gap. We think that representation decomposed into content and style can be effectively exploited for cross modal facial image synthesis. However, we have observed that unidirectional application of decomposed representation based style transfer in case of large modality gap does not work well for this purpose. Unlike existing image synthesis methods that typically formulate image synthesis as an unidirectional feed forward mapping, our network utilizes mutual interaction between two opposite mappings in a collaborative way to address complex image synthesis problem with large modality gap. The proposed bidirectional network aligns shape content from two modalities and exchanges their appearance styles using feature maps of the layers in the encoder space. This allows us to effectively retain the shape content and transfer style details for synthesizing each modality. Focusing on facial images, we consider facial photo, sketch, and color-coded semantic segmentation as different modalities. The bidirectional synthesis results for the pairs of these modalities show the effectiveness of the proposed approach. We further apply our network to style-content manipulation to generate multiple photo images with various appearance styles for a same content shape. The proposed method can be adopted for solving other cross modal image synthesis tasks. The dataset and source code are available at https://github.com/kamranjaved/Bidirectional-style-transfer-network.},
  keywords={Image synthesis;Image segmentation;Face recognition;Generative adversarial networks;Bidirectional control;Collaborative work;Generative adversarial network;image synthesis;unidirectional style transfer network;bidirectional style transfer network;collaborative learning},
  doi={10.1109/ACCESS.2022.3207288},
  ISSN={2169-3536},
  month={},}@ARTICLE{8933378,
  author={Wang, Juan and Tannaz, Sirous and Cai, Changxin and Aliabadi, Amin and Mostafapour, Ehsan and Zhang, Wei},
  journal={IEEE Access}, 
  title={Performance Analysis of Wireless Adaptive Incremental Networks Under Strong FSO Link Turbulence Conditions}, 
  year={2020},
  volume={8},
  number={},
  pages={12290-12299},
  abstract={The aim of this paper is to show the problems of implementing the wireless adaptive networks with the free space optical (FSO) technology. Implementing adaptive networks with the wireless optical communication technology has several benefits and also some hindering problems. The thermal optical noise modeled with Gaussian distribution and link turbulence is two of the major problems of this implementation. In this paper, the theoretical analysis of the FSO link effects that are modeled with K-distribution and Negative exponential distributions are considered on the estimation performance of the adaptive incremental networks. These distributions arise when the FSO link is contaminated with strong optical turbulence. Experiments are designed to cover these conditions and the analysis is based on the steady state mean square deviation (MSD) and excess mean square error (EMSE) values for the incremental LMS (ILMS) algorithm and these are the metrics that show how well the adaptive network performs. Simulation results are presented for different parameters of K -distribution and negative exponential distribution and the results show perfect match with the theoretical outcomes. Based on these results, we show that implementing the incremental adaptive networks in the strong turbulence conditions is not feasible and we must think of some countermeasures for these cases.},
  keywords={Adaptive systems;Wireless communication;Optical fiber communication;Estimation;Optical transmitters;Optical receivers;Optical refraction;Free space optical communications;distributed processing;negative exponential distribution;adaptive networks;strong turbulence;estimation},
  doi={10.1109/ACCESS.2019.2960128},
  ISSN={2169-3536},
  month={},}@ARTICLE{10024282,
  author={Lee, Won Jun and Kim, Chang Hyun and Paik, Yoonah and Kim, Seon Wook},
  journal={IEEE Access}, 
  title={PISA-DMA: Processing-in-Memory Instruction Set Architecture Using DMA}, 
  year={2023},
  volume={11},
  number={},
  pages={8622-8632},
  abstract={Processing-in-memory (PIM) has attracted attention to overcome the memory bandwidth limitation, especially for computing memory-intensive DNN applications. Most PIM approaches use the CPU’s memory requests to deliver instructions and operands to the PIM engines, making a core busy and incurring unnecessary data transfer, thus, resulting in significant offloading overhead. DMA can resolve the issue by transferring a high volume of successive data without intervening CPU and polluting the memory hierarchy, thus perfectly fitting the PIM concept. However, the small computing resources of DRAM-based PIM devices allow us to transfer only small amounts of data at one DMA transaction and require a large number of descriptors, thus still incurring significant offloading overhead. This paper introduces PIM Instruction Set Architecture (ISA) using a DMA descriptor called PISA-DMA to express a PIM opcode and operand in a single descriptor. Our ISA makes PIM programming intuitive by thinking of committing one PIM instruction as completing one DMA transaction and representing a sequence of PIM instructions using the DMA descriptor list. Also, PISA-DMA minimizes the offloading overhead while guaranteeing compatibility with commercial platforms. Our PISA-DMA eliminates the opcode offloading overhead and achieves 1.25x, 1.31x, and 1.29x speedup over the baseline PIM at the sequence length of 128 with the BERT, RoBERTa, and GPT-2 models, respectively, in ONNX runtime with real machines. Also, we study how our proposed PISA affects performance in compiler optimization and show that the operator fusion of matrix-matrix multiplication and element-wise addition achieved 1.04x speedup, a similar performance gain using conventional ISAs.},
  keywords={Engines;Computer architecture;Registers;Switches;DRAM chips;Random access memory;Programming;Processing-in-DRAM;direct memory access;instruction set architecture;PIM offloading},
  doi={10.1109/ACCESS.2023.3238812},
  ISSN={2169-3536},
  month={},}@ARTICLE{9425535,
  author={Qi, Hui and Shi, Ying and Mu, Xiaofang and Hou, Mingxing},
  journal={IEEE Access}, 
  title={Knowledge Granularity for Continuous Parameters}, 
  year={2021},
  volume={9},
  number={},
  pages={89432-89438},
  abstract={In the community of Granular Computing, knowledge is interpreted as one classification ability of realistic or abstract objects. Generally, the concept of granularity is used for characterizing such an ability, which has been widely explored in literatures. To calculate the parameterized granularity, a naive approach is to find the granularity in terms of the parameter one by one. Nevertheless, such approach can only generate the single parameter based knowledge granularity, and the difference of knowledge granularities among different parameters may be slight. It follows that the knowledge granularity derived from single parameter may be lack of representativeness. In this paper, the continuous parameters based knowledge granularity is proposed, and the corresponding calculation approach is presented. Inspired by the thinking of definite integral in mathematical problems, the calculation approach is mainly implemented by following steps: firstly, the graph formed by granularity and parameter interval is divided into several small rectangles whose length of interval tends to be 0; secondly, the sum of area values of all the small rectangles is calculated; finally, the obtained area value divided by the whole length of parameter interval can be considered as the continuous parameters based knowledge granularity. This study suggests a new trend of handling problems related to knowledge from the viewpoint of continuity.},
  keywords={Knowledge representation;Data mining;Voting;Tools;Semantics;Rough sets;Continuous parameters;granular computing;granularity;knowledge},
  doi={10.1109/ACCESS.2021.3078269},
  ISSN={2169-3536},
  month={},}@ARTICLE{9032212,
  author={Hong, Xin and Lin, Rongjie and Yang, Chenhui and Cai, Chunting and Clawson, Kathy},
  journal={IEEE Access}, 
  title={ADPM: An Alzheimer’s Disease Prediction Model for Time Series Neuroimage Analysis}, 
  year={2020},
  volume={8},
  number={},
  pages={62601-62609},
  abstract={Alzheimer's Disease (AD) is a form of dementia which causes memory, thinking, and behavior disorders in humans. Effective early diagnosis and treatment of AD is of fundamental importance as it can reduce disease progression, allow more effective management of symptoms, facilitate timely patient access to advice and support, and lower associated costs of health care. Given that Alzheimer's typically progresses in stages over an extended period of time, we propose that automated analysis of time sequential data may enhance disease prediction. We present a novel time-series Alzheimer's Disease Prediction Model (ADPM) comprising Random Forest (RF) region of interest (ROI) selection and Gated Recurrent Units (GRU) prediction. Experiments show that our methodology achieves higher classification accuracy in comparison to existing algorithms, and can facilitate prediction of early onset AD. Furthermore, testing demonstrates that random forest ROI selection can identify disease-relative brain regions across different image modalities (MRI, PET, DTI).},
  keywords={Dementia;Feature extraction;Forestry;Predictive models;Diffusion tensor imaging;Alzheimer’s disease prediction;time series;random forest;GRU},
  doi={10.1109/ACCESS.2020.2979969},
  ISSN={2169-3536},
  month={},}@ARTICLE{10399808,
  author={Koru, Gülsüm Kayabaşi and Uluyol, Çelebı},
  journal={IEEE Access}, 
  title={Detection of Turkish Fake News From Tweets With BERT Models}, 
  year={2024},
  volume={12},
  number={},
  pages={14918-14931},
  abstract={As the number of people using social networks increases, more people are using social media platforms to meet their news needs. Users think that it is easier to follow the agenda by accessing news, especially on Twitter, rather than newspaper news pages. However, fake news is increasingly appearing on social media, and it is not always possible for people to obtain correct news from partial news pages or short Twitter posts. Understanding whether the news shared on Twitter is true or not is an important problem. Detecting fake tweets is of great importance in Turkish as well as in any language. In this study, fake news obtained from verification platforms on Twitter and real news obtained from the Twitter accounts of mainstream newspapers were labeled and, preprocessed using the Zemberek natural language processing tool developed for the Turkish language, and a dataset named TR_FaRe_News was created. Then, the TR_FaRe_News dataset was explored using ensemble methods and BoW, TF-IDF, and Word2Vec vectorization methods for fake news detection. Then a pre-trained BERT deep learning model was fine-tuned, and variations of the model extended with Bi-LSTM and Convolutional Neural Network (CNN) layers with the frozen and unfrozen parameters methods were explored. The performance evaluation was conducted using seven comparable datasets, namely BuzzFeedNews, GossipCop, ISOT, LIAR, Twitter15, and Twitter16, including an LLM-generated fake news dataset. Analyzing Turkish tweets and using fake news datasets generated by LLM is considered an important contribution. Accuracy values between 90 and 94% were obtained with the BERT and BERTurk + CNN models with 94% accuracy.},
  keywords={Fake news;Social networking (online);Blogs;Deep learning;Ensemble learning;Convolutional neural networks;Machine learning algorithms;Fake news;generated news;ensemble learning;deep learning;BERT},
  doi={10.1109/ACCESS.2024.3354165},
  ISSN={2169-3536},
  month={},}@ARTICLE{8700182,
  author={Ko, Chihhsiang and Liu, Yuchun},
  journal={IEEE Access}, 
  title={Old and Young Users’ White Space Preferences for Online News Web Pages}, 
  year={2019},
  volume={7},
  number={},
  pages={57284-57297},
  abstract={In the future, the importance and usage rate of the Internet will increase gradually year by year. However, in the case of frequently browsed news web pages, mass news information derived from visual design elements or different layout designs may affect the preferences of users from different demographics and socio-economic backgrounds. This is due to the dissimilarities between their physical and psychological limitations. The purpose of this study is to investigate users' white-space ratio preferences for news web pages. We tested the top ten online Chinese and English websites, 20 news web pages in total. Two statements were picked from the system usability scale (SUS) and the visual aesthetics of website inventory (VisAWI) to evaluate these samples. We took these two statements as questionnaire questions. They are the following: Q1 “I think that I would like to use this system frequently” and Q2 “Everything goes together on these web pages.” The design of the questionnaire was based on a five-point Likert scale. The research variables include age, gender, education, occupation, white-space ratio, along with the other demographic properties. Our results indicated that there are significant differences between age, white-space ratio, education, occupation, news sources, computer usage time, and computer usage history. The group aged between 31-45 years old scored all samples higher than other groups. None prefer too high (90%) or too low (50%) white-space ratio. It is necessary to accumulate more preferences from different groups prior to the coming age of AI and machine learning.},
  keywords={Web pages;Usability;White spaces;Visualization;Layout;Complexity theory;Image color analysis;White space;news web pages;user preference;user interface;usability;aesthetics},
  doi={10.1109/ACCESS.2019.2913407},
  ISSN={2169-3536},
  month={},}@ARTICLE{9751071,
  author={Zhong, Shiyu and Fu, Xinsha and Lu, Wei and Tang, Feng and Lu, Yue},
  journal={IEEE Access}, 
  title={An Expressway Driving Stress Prediction Model Based on Vehicle, Road and Environment Features}, 
  year={2022},
  volume={10},
  number={},
  pages={57212-57226},
  abstract={Driving stress is the demand for reserved cognitive space after a driver perceives changes in vehicle, road and environmental factors during driving, which has been proven to affect driving behaviour, interfering with driving safety. Traditional stress prediction relies extensively on psychological data and is limited by the unpopularity of psychological data collection technology, which cannot be applied in daily life on a large scale. In recent years, advances in high-precision visual analysis technology represented by deep learning have laid the foundation for automated and large-scale visual environment analysis. This study proposes a framework for the quantitative analysis of highway driving stress based on multiple vehicle, road, and environmental factors. A dilated residual network model and other methods were used to extract visual environmental indexes. Combined with multisource data such as traffic volume and road design parameters, the LightGBM method was used to construct an expressway driving stress prediction model with high accuracy. The MAE, RMSE and  $R^{2}$  values of the proposed model are 0.042, 0.004 and 0.881, respectively, demonstrating the usefulness for scaled and efficient assessment of expressway stress loads. The SHAP method was used to explore the relationship between different influencing factors and driving stress to quantify the mechanism of vehicle, road and environment influences on stress load, and to propose recommendations for highway design and planning from the perspective of reducing stress load. This study provides a new way of thinking to quantitatively investigate the link between multiple road traffic factors and driving stress, providing efficient and large-scale assessment of expressway driving stress, as well as proposing some suggestions for highway design and planning to enhance stress reduction.},
  keywords={Stress;Vehicles;Psychology;Roads;Task analysis;Predictive models;Load modeling;Expressway;prediction model;driving stress;LightGBM method;SHAP method},
  doi={10.1109/ACCESS.2022.3165570},
  ISSN={2169-3536},
  month={},}@ARTICLE{10403882,
  author={Nallakaruppan, M. K. and Somayaji, Siva Rama Krishnan and Fuladi, Siddhesh and Benedetto, Francesco and Ulaganathan, Senthil Kumaran and Yenduri, Gokul},
  journal={IEEE Access}, 
  title={Enhancing Security of Host-Based Intrusion Detection Systems for the Internet of Things}, 
  year={2024},
  volume={12},
  number={},
  pages={31788-31797},
  abstract={The Internet of Things (IoT) infrastructure enables smart devices to learn, think, speak and perform. The facilities of the IoT devices can be enhanced to support an intelligent application through technologies like fog computing, smart networks, federated learning or explainable artificial intelligence infrastructures. In all these cases networking of IoT devices becomes inevitable. Whereever there exists a network, a threat to the network infrastructure is also possible. The proposed work classifies various attacks on the hosts with the support of proven machine learning (ML) algorithms. This work performs the comparative analysis of all these classification parameters of the machine learning algorithms with the use of fuzzy-based recommendation systems. This work also lists out various incidents of intrusions on the IoT hosts in appropriate layers of the interface and proposes an efficient algorithm and framework to overcome the occurrences of intrusions on the host side. In particular, we propose an effective security framework to deal with the intrusions that can deteriorate the host-based systems. The ranking of the algorithms is evaluated using fuzzy-based recommendation systems such as TOPSIS, VIKOR, MORA, WASPAS. The ensemble of machine learning algorithms such as Decision Tree, Lite Gradient Boost, Xtra Gradient Boost and Random Forest provide better values of accuracy (around 99%) with higher precision, re-call and F1-scores, thus proving their efficacy for intrusion detection in IoT networks.},
  keywords={Internet of Things;Security;Intrusion detection;Machine learning algorithms;Machine learning;Deep learning;Classification algorithms;Artificial intelligence;Artificial intelligence;Internet of Things;intrusion detection systems;network security;privacy},
  doi={10.1109/ACCESS.2024.3355794},
  ISSN={2169-3536},
  month={},}@ARTICLE{8502036,
  author={Mu, Dan and Liang, Yinghui and Zhang, Wenhui and Wang, Yucheng},
  journal={IEEE Access}, 
  title={Investigation on Tree Molecular Genome of Arabidopsis Thaliana for Internet of Things}, 
  year={2018},
  volume={6},
  number={},
  pages={67688-67698},
  abstract={Research and regulation of tree growth at molecular level is a new trend in the development of forest biotechnology. However, as the limitations of wood as a research material, it is difficult to operate and compare the growth cycle in the laboratory, which greatly hinders study of the molecular biology of forest trees. Arabidopsis thaliana is the most important model plant in botanical research and is an excellent material for plant molecular biology research. Recent studies have shown that herbaceous Arabidopsis can not only provide genetic resources for tree molecular breeding but also can be used as an auxiliary means of wood molecular biology research and even can be directly used as an experimental model for the study of the molecular mechanism of tree development. This paper mainly discusses the establishment process of the tree molecular gene system platform under the background of the Internet of Things and studies the molecular genome of Arabidopsis, combining the characteristics of the tree itself and using the diversity of the frequency of different bases in the gene fragment to cluster the tree molecular genome, which is a molecular biology research and provides an important way of thinking.},
  keywords={Genomics;Bioinformatics;Vegetation;Forestry;Internet of Things;Molecular biology;Arabidopsis thaliana;forest molecular genome;cluster research;Internet of Things},
  doi={10.1109/ACCESS.2018.2877411},
  ISSN={2169-3536},
  month={},}@ARTICLE{10271339,
  author={Huang, Qian and Xia, Haibin and Zhang, Zhancheng},
  journal={IEEE Access}, 
  title={Clustering Analysis of Integrated Rural Land for Three Industries Using Deep Learning and Artificial Intelligence}, 
  year={2023},
  volume={11},
  number={},
  pages={110530-110543},
  abstract={This study employs deep learning and artificial intelligence (AI) clustering analysis techniques to evaluate the suitability of integrated rural land for three industries. Diverse datasets pertaining to rural development, encompassing land use, agricultural production, and rural tourism, are gathered and harmoniously amalgamated. An innovative land suitability assessment model, merging ResNet-50 with the k-means algorithm, is devised. Specifically, ResNet-50 is harnessed for the classification and recognition of rural land-use images, thus deriving feature vectors for each sample. These feature vectors are subsequently fed into the k-means algorithm to cluster samples with akin land-use patterns. The ensuing examination of land use composition within each cluster facilitates the evaluation of rural land’s suitability for three-industry integration. Experimental scrutiny discloses that this study achieves an accuracy rate of 88.3% in rural land-use classification and recognition, outperforming alternative algorithms by at least 3.1%. Furthermore, it yields an average intersection over union (IoU) of 67.29%. Remarkably, the k-means algorithm exhibits superior clustering outcomes. Consequently, the model introduces herein demonstrated substantial enhancements in rural land-use classification and recognition accuracy, average IoU, and clustering performance. It offers an innovative tool for policymakers to advance rural industry integration, fostering economic diversification. Additionally, this model aids decision-makers in identifying prospective opportunities and challenges, thus facilitating the formulation of forward-thinking and viable rural development strategies.},
  keywords={Deep learning;Artificial intelligence;Clustering algorithms;Classification algorithms;Agriculture;Sustainable development;Economics;Deep learning;Artificial intelligence;deep learning;integrated rural land for three industries;cluster;suitability evaluation},
  doi={10.1109/ACCESS.2023.3321894},
  ISSN={2169-3536},
  month={},}@ARTICLE{10076418,
  author={Soysal, Omurhan Avni and Guzel, Mehmet Serdar and Dikmen, Mehmet and Bostanci, Gazi Erkan},
  journal={IEEE Access}, 
  title={Common Thorax Diseases Recognition Using Zero-Shot Learning With Ontology in the Multi-Labeled ChestX-ray14 Data Set}, 
  year={2023},
  volume={11},
  number={},
  pages={27883-27892},
  abstract={Disease detection/recognition with limited data sets and labels in the medical image domain is a very costly and greatest challenge. Although open image data sets have increased recently, researches on this problem still need to be developed. Researches to diversify data sets are both costly and face the problem of subjectivity. Unseen classes can be trained with the Zero-Shot Learning (ZSL) in order to overcome this problem. In this paper, we aimed to strengthen ZSL by using ontology as an auxiliary information for class embeddings. In our approach, ZSL is supported by the image embeddings and class embeddings of the multi-labelled ChestX-ray14 data set, as well as the semantic data from DBpedia. In this paper, which we believe will be pioneering in the medical image domain, the Cosine, Hamming and Euclidean distances were taken into account in order to maximize the similarities. We trained ResNet50 neural network with different parameters on the multi-labelled ChestX-ray14 data set. 23.25% precision value in one-to-one matching and 29.59% precision value in at least one matching were obtained. We think that this paper will make a significant contribution to the medical image domain by detecting/recognizing unseen disease images.},
  keywords={Thorax;Semantics;Ontologies;Visualization;Deep learning;Biomedical imaging;Task analysis;X-ray imaging;Zero-shot learning;ResNet50;ontology;ChestX-ray14},
  doi={10.1109/ACCESS.2023.3259062},
  ISSN={2169-3536},
  month={},}@ARTICLE{10188391,
  author={Han, Lei and Zheng, Shengnan and Shi, Zhan and Xia, Mingliang},
  journal={IEEE Access}, 
  title={Exploiting Sequence Analysis for Accurate Light-Field Depth Estimation}, 
  year={2023},
  volume={11},
  number={},
  pages={74657-74670},
  abstract={Depth estimation for light field (LF) images is the cornerstone of many applications of light field cameras, such as 3D reconstruction, defects inspection, face liveness detection, and so forth. In recent years, convolutional neural network (CNN) has dominated the primary workhorse for depth estimation. However, the interpretability of the network and the accuracy of the depth estimation results still need to be improved. This paper uses the conditional random field (CRF) theory to explain and model the LF depth estimation. Further, from the perspective of sequence analysis, we extract the sequence features of epipolar plane image (EPI) patches with recurrent neural network (RNN) and serve as the unary term of the energy function in the CRF. Then, a unified neural network (called as LFRNN) is designed to solve the CRF and get the disparity map. Our LFRNN builds upon two-stage architecture, involving a local depth estimation and a depth refinement. In the first part, we design an RNN to analyze the vector sequences in EPI patches and obtain local disparity values. There are two thinking behind the design of this part. The first is the general principle that the slope of the straight line in the EPI is inversely proportional to the depth; the second is our unique observation that those straight lines are distributed in vector sequences. In the second part, continuous CRF is used to optimize the output of the first part. We train LFRNN on a synthetic LF dataset and test it on both synthetic and real-world LF datasets. Quantitative and qualitative results validate the superior performance of our LFRNN over the state-of-the-art methods.},
  keywords={Estimation;Light fields;Conditional random fields;Cameras;Lenses;Deep learning;Sequences;Computer vision;Sequential analysis;Image processing;Computer vision;depth estimation;light field imaging;deep learning;sequence analysis},
  doi={10.1109/ACCESS.2023.3296800},
  ISSN={2169-3536},
  month={},}@ARTICLE{9878123,
  author={Verma, Shanu and Pandey, Vivekanand and Pant, Millie and Snasel, Vaclav},
  journal={IEEE Access}, 
  title={A Balanced Squad for Indian Premier League Using Modified NSGA-II}, 
  year={2022},
  volume={10},
  number={},
  pages={100463-100477},
  abstract={Selecting team players is a crucial and challenging task demanding a considerable amount of thinking and hard work by the selectors. The present study formulated the selection of an IPL squad as a multi-objective optimization problem with the objectives of maximizing the batting and bowling performance of the squad, in which a player’s performance is estimated using an efficient Batting Performance Factor and Combined Bowling Rate. Also, the proposed model tries to formulate a balanced squad by constraining the number of pure batters, pure bowlers, and all-rounders. Bounds are also considered on star players to enhance the performance of the squad and also from the income prospects of IPL. The problem in itself is treated as a 0/1 knapsack problem for which two combinatorial optimization algorithms, namely, BNSGA-II and INSGA-II, are developed. These algorithms were compared with existing modified NSGA-II for IPL team selection and three other popular multi-objective optimization algorithms, NSGA-II, NSDE, and MOPSO-CD, on the basis of standard performance metrics: hypervolume, inverted generational distance, and number of Pareto optimal solutions. Both algorithms performed well, with BNSGA-II performing better than all the other algorithms considered in this study. The IPL 2020 players’ data validated the applicability of the proposed model and algorithms. The trade-off squads contained players of each expertise in appropriate proportions. Further analysis of the trade-off squads demonstrated that many theoretically selected players performed well in IPL 2020 matches.},
  keywords={Optimization;Sorting;Franchising;Optimization methods;Genetic algorithms;Costs;Data models;Sports;Cricket;twenty20;knapsack problem;combinatorial;Indian premier league;multi-objective;optimization;squad selection},
  doi={10.1109/ACCESS.2022.3204649},
  ISSN={2169-3536},
  month={},}@ARTICLE{9623457,
  author={Liu, Wenxuan and Wu, Huayi and Hu, Kai and Luo, Qing and Cheng, Xiaoqiang},
  journal={IEEE Access}, 
  title={A Scientometric Visualization Analysis of Image Captioning Research From 2010 to 2020}, 
  year={2021},
  volume={9},
  number={},
  pages={156799-156817},
  abstract={Image captioning has gradually gained attention in the field of artificial intelligence and become an interesting and challenging task for image understanding. It needs to identify important objects in images, extract attributes, tell relationships, and help the machine generate human-like descriptions. Recent works in deep neural networks have greatly improved the performance of image caption models. However, machines are still unable to imitate the way humans think, talk and communicate, so image captioning remains an ongoing task. It is thus very important to keep up with the latest research and results in the field of image captioning whereas publications on this topic are numerous. Our work aims to help researchers to have a macro-level understanding of image captioning from four aspects: spatial-temporal distribution characteristics, collaborative networks, trends in subject research, and historical evolutionary path. We employ scientometric visualization methods to achieve this goal. The results show that China has published the largest amount of publications in image captioning, but the United States has the greatest impact on research in this area. Besides, thirteen academic groups are identified in the field of image description, with institutions such as Microsoft, Google, Australian National University, and Georgia Institute of Technology being the most prominent research institutions. Meanwhile, we find that evaluation methods, datasets, novel image captioning models based on generative adversarial networks, reinforcement learning, and Transformer, as well as remote sensing image captioning, are the new research trends. Lastly, we conclude that image captioning research has gone through three major development stages from 2010 to 2020, and on this basis, we propose a more comprehensive taxonomy of image captioning.},
  keywords={Bibliometrics;Visualization;Indexes;Conferences;Remote sensing;Market research;Image recognition;Image captioning;image description generation;scientometric analysis;visualization},
  doi={10.1109/ACCESS.2021.3129782},
  ISSN={2169-3536},
  month={},}@ARTICLE{9857902,
  author={Cao, Jinxin and Xu, Weizhong and Jin, Di and Zhang, Xiaofeng and Miller, Anthony and Liu, Lu and Ding, Weiping},
  journal={IEEE Access}, 
  title={A Network Embedding-Enhanced NMF Method for Finding Communities in Attributed Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={118141-118155},
  abstract={Community detection is an extremely important task for complex network analysis. There still remains a challenge of how to improve the performance of community detection in real-world scenario. Some researchers think that the content in networks is helpful to identify communities, and also focus on combining network topology with node contents, alongside the eradication of inauspicious performance. Furthermore, network topology is often sparse, which is reflected in the lack of capability to represent communities. To address the above problems, this study identifies a novel non-negative matrix factorization method which both employs network embedding to enhance the representation power of network topology for communities and also integrates network topology and node contents for further raising the quality of community detection. Furthermore, we then obtain the parameters of the model for finding communities which is based on model inference. Alongside both synthetic and real-world networks with ground-truths, we compare the new method with the state-of-the-art methods. Experimental results show that the new method obtains significant improvement for community detection both by incorporating node contents and by enhancing network topology.},
  keywords={Network topology;Stochastic processes;Probabilistic logic;Complex networks;Topology;Social networking (online);Behavioral sciences;Community detection;network embedding;node contents;non-negative matrix factorization},
  doi={10.1109/ACCESS.2022.3198979},
  ISSN={2169-3536},
  month={},}@ARTICLE{10595088,
  author={Ito, Koya and Ishii, Yoko and Ishii, Ryo and Eitoku, Shin-Ichiro and Otsuka, Kazuhiro},
  journal={IEEE Access}, 
  title={Exploring Multimodal Nonverbal Functional Features for Predicting the Subjective Impressions of Interlocutors}, 
  year={2024},
  volume={12},
  number={},
  pages={96769-96782},
  abstract={This paper proposes models for predicting the subjective impressions of interlocutors in discussions according to multimodal nonverbal behaviors. To that end, we focus mainly on the functional aspects of head movement and facial expressions as insightful cues. For example, head movement functions include the speaker’s rhythm and the listener’s back channel and thinking processes, as well as their positive emotions. Facial expression functions include emotional expressions and communicative functions such as the speaker addressing the listener and the listener’s affirmation. In addition, our model employs synergetic functions, which are jointly performed with head movements and facial expressions, assuming that the simultaneous appearance of head and face functions could strengthen the results or lead to multiplexing. On the basis of these nonverbal functions, we define a set of functional features, including the rate of occurrence and composition balance among different functions that emerge during conversation. Then, a feature selection scheme is used to identify the best combinations of intermodal and intramodal features. In the experiments, an SA-Off corpus of 17 groups of discussions involving 4 female participants was used, including interlocutors’ self-reported scores for 16 impression items felt during the discussion, such as helpfulness and interest. The experiments confirmed that our models’ predictions were significantly correlated with the self-reported scores for more than 70% of the impression items. These results indicate the effectiveness of multimodal nonverbal functional features for predicting subjective impressions.},
  keywords={Indium tin oxide;Face recognition;Task analysis;Feature extraction;Eyebrows;Facial animation;Facial animation;Facial expression;feature selection;group meeting;head movement;multimodal recognition;nonverbal communication;social signal;subjective impression},
  doi={10.1109/ACCESS.2024.3426537},
  ISSN={2169-3536},
  month={},}
