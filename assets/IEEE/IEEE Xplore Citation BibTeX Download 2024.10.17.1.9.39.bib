@INPROCEEDINGS{10385599,
  author={Liu, Yuhang and Li, Tianhao and Wang, Zixuan and Zhu, Guiquan and Zhang, Yongqing and Zou, Quan},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Exploring Parameter-Efficient Fine-Tuning of a Large-Scale Pre-Trained Model for scRNA-seq Cell Type Annotation}, 
  year={2023},
  volume={},
  number={},
  pages={580-585},
  abstract={Accurate identification of cell types is a pivotal and intricate task in scRNA-seq data analysis. Recently, significant strides have been made in cell type annotation of scRNA-seq data using pre-trained language models (PLMs). This method has surmounted the constraints of conventional approaches regarding precision, robustness, and generalization. However, the fine-tuning process of large-scale pre-trained models incurs substantial computational expenses. To tackle this issue, a promising avenue of research has emerged, proposing parameter-efficient fine-tuning techniques for PLMs. These techniques concentrate on fine-tuning only a small portion of the model parameters while attaining comparable performance. In this study, we extensively research parameter-efficient fine-tuning methods for scRNA-seq cell type annotation, employing scBERT as the backbone. We scrutinize the performance and compatibility of various parameter-efficient fine-tuning methodologies across multiple datasets. Through comprehensive analysis, we demonstrate the remarkable performance of parameter-efficient fine-tuning methods in cell type annotation. Hopefully, this study can inspire new thinking in analyzing scRNA-seq data.},
  keywords={Data analysis;Annotations;Computational modeling;Biological system modeling;Robustness;Data models;Task analysis;Single-cell RNA-seq;Cell type annotation;Parameter-efficient fine-tuning;Pre-trained language model},
  doi={10.1109/BIBM58861.2023.10385599},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{5599732,
  author={Shi, Zhongzhi and Wang, Xiaofeng and Shi, Zhiping and Chen, Limin and Wang, Zhuxiao},
  booktitle={9th IEEE International Conference on Cognitive Informatics (ICCI'10)}, 
  title={A mind model for brain-like computer}, 
  year={2010},
  volume={},
  number={},
  pages={257-264},
  abstract={Mind is all mankind's spiritual activities, including emotion, will, perception, consciousness, representation, learning, memory, thinking, intuition, etc. Mind model is for explaining what individuals operate in the cognitive process for something in the real world. It is the internal sign or representation for external realistic world. If the neural network is a hardware of the brain system, then the mind model is the software of the brain system. The key issue in intelligence science is to construct the mind model of the brain system, which will guide the development of brain-like computer in engineering through structure, dynamics, function and behavioral reverse engineering of the brain. This paper will discuss the computational model of memory and consciousness in the mind model named Consciousness And Memory model(CAM).},
  keywords={Brain modeling;Computational modeling;Humans;Computer aided manufacturing;Biological system modeling;Computers;Computer architecture;mind model;CAM;brain-like computer;dynamic description logic;intelligence science},
  doi={10.1109/COGINF.2010.5599732},
  ISSN={},
  month={July},}@INPROCEEDINGS{5626848,
  author={Erson, E. Zeynep and Çavuşoğlu, M Çenk},
  booktitle={2010 Annual International Conference of the IEEE Engineering in Medicine and Biology}, 
  title={Design of a framework for modeling, integration and simulation of physiological models}, 
  year={2010},
  volume={},
  number={},
  pages={1485-1489},
  abstract={Modeling and simulation of physiological processes deal with the challenges of multiscale models in which coupling is very high within and among scales. Information technology approaches together with related analytical and computational tools will help to deal with these challenges. Physiological Model Simulation, Integration and Modeling Framework, Phy-SIM, provides the modeling environment which will help to cultivate various approaches to deal with the inherent problem of multiscale modeling of physiological systems. In this paper, we present the modular design of Phy-SIM. The proposed layered design of Phy-SIM, separates structure from function in physiological processes advocating modular thinking in developing and integrating physiological models. Moreover, the ontology based architecture will improve the modeling process by the mechanisms to attach anatomical and physiological ontological information to the models. The ultimate aim of the proposed approaches is to enhance the physiological model development and integration processes by providing the tools and mechanisms in Phy-SIM.},
  keywords={Computational modeling;Mathematical model;Biological system modeling;Load modeling;Atmospheric modeling;Ontologies;Analytical models},
  doi={10.1109/IEMBS.2010.5626848},
  ISSN={1558-4615},
  month={Aug},}@INPROCEEDINGS{9040012,
  author={Kireš, M. and Šveda, D. and Ješková, Z. and Lukáč, S. and Ganajová, M. and Lešková, A. and Csachová, S.},
  booktitle={2019 17th International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Key innovation concepts of STEM education driven by IT Academy project}, 
  year={2019},
  volume={},
  number={},
  pages={378-382},
  abstract={The information society places requirements on the profile of graduates, what is unreachable in the inertial education system. We aim for key changes in STEM education at primary and secondary schools through a national wide-impact project IT Academy. Active learning focusing on conceptual understanding and development of selected inquiry skills, together with formative assessment, form our didactic basis for innovation. The development of scientific literacy and computational thinking are also stimulated by changes in the content of science and mathematics curricula. We create a strong link to informatics concepts and practical use of informatics in everyday life, study, work and research. We expect the interest of young people to study computer science and STEM will increase. In this paper, we introduce key concepts of STEM education innovation, with examples of educational activities. The results of the pilot verification are formulated in recommendations to the educational professionals.},
  keywords={Education;Pupils;Mathematics;Technological innovation;Informatics;Computational modeling;Geography},
  doi={10.1109/ICETA48886.2019.9040012},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8229646,
  author={Malagon, Edwin and Rojas, Alexis},
  booktitle={2017 CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON)}, 
  title={Analysis and simulation of graphs applied to learning with parallel programming in HPC}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={Large-scale graph analysis or also called network analysis of networks is supported by different algorithms, among the most relevant are PageRank (Web page ranking), Betweenness centrality (centrality in a graph) and Community Detection, these by of their complexity and the large amount of data that process diverse applications, increasingly need to use computational resources such as processor, memory and storage, for these reasons, it is necessary to apply high performance computing or HPC (High Performance Computing) but it would not be useful to apply HPC without having designed these algorithms in parallel programming, in this part there have been many studies on its application and methodologies to do it. The purpose of this work is to create a framework that allows computer science students to abstract a computer system based on the parallel programming paradigm, which implies that students to get acquainted with the resolution of algorithmic problems in a more natural way and away from the typical sequential thinking., The development of a graph analysis design pattern oriented to parallel programming in HPC, complemented with the design of didactic learning techniques in the network such as laboratories and/or simulators are key in the development of this framework.},
  keywords={Parallel programming;High performance computing;Algorithm design and analysis;Computational modeling;Hardware;Handheld computers;Analytical models;Analysis;graphs;parallel programing;high performance computing;learning},
  doi={10.1109/CHILECON.2017.8229646},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10097957,
  author={Bistarelli, Stefano and Mancinelli, Alessio and Santini, Francesco and Taticchi, Carlo},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Arg-XAI: a Tool for Explaining Machine Learning Results}, 
  year={2022},
  volume={},
  number={},
  pages={205-212},
  abstract={The requirement of explainability is gaining more and more importance in Artificial Intelligence applications based on Machine Learning techniques, especially in those contexts where critical decisions are entrusted to software systems (think, for example, of financial and medical consultancy). In this paper, we propose an Argumentation-based methodology for explaining the results predicted by Machine Learning models. Argumentation provides frameworks that can be used to represent and analyse logical relations between pieces of information, serving as a basis for constructing human tailored rational explanations to a given problem. In particular, we use extension-based semantics to find the rationale behind a class prediction.},
  keywords={Semantics;Machine learning;Predictive models;Software systems;Computational Argumentation;Machine Learning;Explainability},
  doi={10.1109/ICTAI56018.2022.00037},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{508194,
  author={Saini, S.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={NAS experiences of porting CM Fortran codes to HPF on IBM SP2 and SGI Power Challenge}, 
  year={1996},
  volume={},
  number={},
  pages={873-880},
  abstract={Current Connection Machine (CM) Fortran codes developed for the CM-2 and the CM-5 represent an important class of parallel applications. Several users have employed CM Fortran codes in the production mode on the CM-2 and the CM-5 for the last five to six years, constituting a heavy investment in terms of cost and time. With Thinking Machines Corporation's decision to withdraw from the hardware business and with the decommissioning of many CM-2 and CM-5 machines, the best way to protect the substantial investment in CM Fortran codes is to port the codes to High Performance Fortran (HPF) on highly parallel systems. HPF is very similar to CM Fortran and thus represents a natural transition. The Numerical Aerodynamic Simulation (NAS) Program, located at NASA Ames Research Center, is a pathfinder in high-performance computing for NASA and is dedicated to advancing the science of computational aerodynamics. Their experiences with the conversion issues involved in porting CM Fortran codes on the CM-5 to HPF are presented. Several CM Fortran codes have been ported to Subset HPF on the IBM SP2 and the SGI Power Challenge. Speedup ratios versus number of processors for the linear solver and DSMC (direct simulation Monte Carlo) code are presented.},
  keywords={Investments;Aerodynamics;NASA;Production;Costs;Hardware;Protection;Computational modeling;Numerical simulation;Monte Carlo methods},
  doi={10.1109/IPPS.1996.508194},
  ISSN={},
  month={April},}@INPROCEEDINGS{1244258,
  author={Marginean, F.A.},
  booktitle={SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)}, 
  title={The cybernetics of the concept}, 
  year={2003},
  volume={3},
  number={},
  pages={2495-2500 vol.3},
  abstract={The concept of concept is central to several mathematical fields dealing with the processing and interpretation of knowledge, such as Computational Learning Theory in Machine Learning or Formal Concept Analysis in Artificial Intelligence. It has however had much less of an impact on other related mathematical fields, amongst which Data Mining and Knowledge Discovery in Databases, for which the pattern rather than the concept seems to play the role of the basic unit of knowledge. In this paper we examine the potential role of cybernetical thinking in the formal analysis of concepts with relevance to learning and performance.},
  keywords={Cybernetics;Data mining;Logic;Computational intelligence;Modems;History;Computer science;Artificial intelligence;Databases;Knowledge management},
  doi={10.1109/ICSMC.2003.1244258},
  ISSN={1062-922X},
  month={Oct},}@INPROCEEDINGS{10412418,
  author={Raeisi, Arash and Aghanasiri, Pouria and Etezadi, Hamed and Zarafshan, Payam and Dehghani, Mohammad},
  booktitle={2023 11th RSI International Conference on Robotics and Mechatronics (ICRoM)}, 
  title={Design and Analysis of a Fiber Laser Flying Robot for Cleaning Power Line Insulators}, 
  year={2023},
  volume={},
  number={},
  pages={402-407},
  abstract={It is one of humanity’s greatest needs today to be able to transmit electric current using power lines from power plants to cities, Therefore, power generation companies are always thinking about improving power transmission lines. As a result of pollution sitting on electrical insulators and making them conductive, power lines lose most of their power. Therefore, we need more effective and newer methods to wash these pollutions from electrical insulators. In this article, the cleaning of electrical insulators using a fiber laser by a hexarotor has been investigated. The control of these systems is done either by a pilot at the ground station or by an autopilot. The steps involved in construction and the parts described. Solidworks flow simulatin was used to simulate the effect of wind at a height of 50 meters near the power tower using computational fluid dynamics (CFD).},
  keywords={Computational fluid dynamics;Power lasers;Insulators;Laser modes;Cleaning;Robots;Fiber lasers;Electrical Insulator;Fiber Laser;Flying Robot;Cleaning Insulator;Hexarotor},
  doi={10.1109/ICRoM60803.2023.10412418},
  ISSN={2572-6889},
  month={Dec},}@INPROCEEDINGS{9622815,
  author={Milechin, Lauren and Lopez-Contreras, Javier and Alet, Ferran},
  booktitle={2021 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Efficiently Building a Large Scale Dataset for Program Induction}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the applications of machine learning with the most potential is speeding up expensive computational processes, i.e. learning to think. To do so, one first generates a large-scale dataset by a compute-intensive process and then trains a model to approximate the distribution. High performance computing (HPC) is a perfect fit for these processes, as one may efficiently deploy large amounts of computation to generate a dataset in a reasonable amount of time, to then learn a computationally-efficient solution. Here, we focus on generating a program synthesis dataset. Finding the program that fits a given input-output specification is very expensive, but generating the input-output pairs for a given program is a well-defined process. In this work, we show how we efficiently ran hundreds of thousands of C++ codes line-by-line and used intermediate variable states to generate a large-scale program synthesis dataset.},
  keywords={Training;Computational modeling;High performance computing;Pipelines;Distributed databases;Machine learning;Tools;AI / Machine Learning;Big Data and Distributed Computing;High Throughput Computing},
  doi={10.1109/HPEC49654.2021.9622815},
  ISSN={2643-1971},
  month={Sep.},}@INPROCEEDINGS{5334409,
  author={Kimura, Hidenori and Shimoda, Shingo and Lu Gaohua and Tanaka, Reiko J.},
  booktitle={2009 ICCAS-SICE}, 
  title={Towards a common principle of biological control — How control weaves the string of life}, 
  year={2009},
  volume={},
  number={},
  pages={5111-5116},
  abstract={This paper reviews the interplay between biology and control theory as a typical example of transdisciplinary knowledge integration. Control is a fundamental function of the living organism that works in all aspects of the life. Various control mechanisms are ubiquitously built-in at all levels of body structures of living organisms and work all the time to support the life. They are diversely different from one to another with different material bases and structures, but there are many reasons to think that have some common ground and design principles. It is argued that a unified approach is exploited by focusing on a biological way of dealing with environmental changes to investigate various control mechanisms of living organisms.The notion of compound control is proposed as a common principle of biological control based on the transdisciplinary nature of control theory.},
  keywords={Biological control systems;Organisms;Control engineering;Biology;Humans;Reliability engineering;Power engineering and energy;Control theory;Design engineering;Systems engineering and theory;biological control;feedback;transdisciplinary science;compound control;computational media},
  doi={},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9962408,
  author={Fonseca Silveira, Rodrigo and Holanda, Maristela and Ramos, Guilherme N. and Victorino, Marcio and Da Silva, Dilma},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Analysis of Student Performance and Social-economic Data in Introductory Computer Science Courses at the University of Brasília}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Computer Science 1 (CS1) courses introduce undergraduate students to computational thinking and their first programming language. As in most institutions, CS1 is a challenge for students at the University of Brasilia, one of the top 10 universities in Brazil. In 2012, the Brazilian higher education system changed with an affirmative-action policy to admit more students from the public K-12 system: the “Quota” Law was implemented at all federal public universities. This paper aims to answer two research questions: 1) What knowledge about the positive/negative impact of certain features on the success of a CS1 course can be discovered from mining educational data augmented by social-economic information? 2) Are these features different between quota and non-quota students? The analysis uses social-economic and academic performance data of undergraduate students from 2012 to 2019. Data mining algorithms such as generalized linear model, gradient boosting machine, and random forest were applied to the data. The findings include: (1) the relevance of indicators such as the consumption rate of university-subsidized meals, (2) that gender is not a determining factor in failure/success, and (3) a higher failure rate for quota students in the Computer Engineering and Mechatronics Engineering majors.},
  keywords={Computer languages;Mechatronics;Databases;Computational modeling;Education;Data models;Trajectory;Educational Data Mining;CS1;Introduction to Computer Science course;Machine Learning},
  doi={10.1109/FIE56618.2022.9962408},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10198449,
  author={Zeng, Shaoting and Lyu, Xin and Kang, Jingfan},
  journal={IEEE Access}, 
  title={Research on Innovative Method of Human–Computer Collaborative Aesthetic Education Based on Hybrid of Neuroaesthetics and Shape Grammar}, 
  year={2023},
  volume={11},
  number={},
  pages={82728-82737},
  abstract={This paper proposed an innovative method for aesthetic education by integrating shape grammar and neuroaesthetics. Aesthetic education can be divided into bottom-up aesthetic cultivation and top-down knowledge education, which correspond to the characteristics of shape grammar and neuroaesthetics, respectively. In this study, we redefined the state space of traditional shape grammar by replacing the computer-dominated label set with the affective-dominated emotion set of neuroaesthetics. This resulted in a neuroaesthetic shape grammar that is led by the designer and complementary to human intuition and algorithmic logic. We validated this method through practical design cases in the field of aesthetic education.},
  keywords={Grammar;Education;Visualization;Iterative algorithms;Transforms;Image color analysis;Design methodology;Man-machine systems;Neuroscience;Human computer interaction;Aesthetic education;design thinking;human-machine collaboration;neuroaesthetics;shape grammar},
  doi={10.1109/ACCESS.2023.3300800},
  ISSN={2169-3536},
  month={},}@ARTICLE{6843352,
  author={Fatemi, Mehdi and Haykin, Simon},
  journal={IEEE Access}, 
  title={Cognitive Control: Theory and Application}, 
  year={2014},
  volume={2},
  number={},
  pages={698-710},
  abstract={From an engineering point-of-view, cognitive control is inspired by the prefrontal cortex of the human brain; cognitive control may therefore be viewed as the overarching function of a cognitive dynamic system. In this paper, we describe a new way of thinking about cognitive control that embodies two basic components: learning and planning, both of which are based on two notions: 1) two-state model of the environment and the perceptor and 2) perception-action cycle, which is a distinctive characteristic of the cognitive dynamic system. Most importantly, it is shown that the cognitive control learning algorithm is a special form of Bellman's dynamic programming. Distinctive properties of the new algorithm include the following: 1) optimality of performance; 2) algorithmic convergence to optimal policy; and 3) linear law of complexity measured in terms of the number of actions taken by the cognitive controller on the environment. To validate these intrinsic properties of the algorithm, a computational experiment is presented, which involves a cognitive tracking radar that is known to closely mimic the visual brain. The experiment illustrates two different scenarios: 1) the impact of planning on learning curves of the new cognitive controller and 2) comparison of the learning curves of three different controllers, based on dynamic optimization, traditional  \(Q\) -learning, and the new algorithm. The latter two algorithms are based on the two-state model, and they both involve the use of planning.},
  keywords={Cognition;Heuristic algorithms;Brain modeling;Radar tracking;Dynamic programming;Complexity theory;Perception;Control systems;Cognitive dyanamic systems;cognitive control;dynamic programming;two-state model;entropic state;Shannon's entropy;explore/exploit tradeoff;learning;planning;Bayesian filtering},
  doi={10.1109/ACCESS.2014.2332333},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{5555103,
  author={Reyss, Alexandra and Balandin, Sergey},
  booktitle={2010 IEEE Region 8 International Conference on Computational Technologies in Electrical and Electronics Engineering (SIBIRCON)}, 
  title={Healthcare, medical support and consultancy applications and services for mobile devices}, 
  year={2010},
  volume={},
  number={},
  pages={300-305},
  abstract={While thinking about potential new user groups for mobile devices one can notice that the world largest clusters with low penetration of devices are people from developing countries. In the developed countries the largest groups are children and older generation people. Driven by different factors the healthcare and medical applications might create real breakthrough in demand for the new mobile devices and services, and actively involve the above mentioned user groups. The paper describes ideas of the new applications, services and mobile device extension modules which provide the user with medical support and consultancy everywhere at anytime. The paper cannot be seen as a real scientific study, instead it is the first exploration of this field, which in particular is focused on proposing and arguing healthcare and medical solutions for mobile devices targeted to fulfill needs of the above mentioned user groups.},
  keywords={Mobile handsets;Pediatrics;Monitoring;Sensors;Diseases;Mobile communication},
  doi={10.1109/SIBIRCON.2010.5555103},
  ISSN={},
  month={July},}@INPROCEEDINGS{6417292,
  author={Bouaziz, Rahma and Coulette, Bernard},
  booktitle={2012 IEEE 15th International Conference on Computational Science and Engineering}, 
  title={Applying Security Patterns for Component Based Applications Using UML Profile}, 
  year={2012},
  volume={},
  number={},
  pages={186-193},
  abstract={Today's systems require a higher consideration for the non functional requirement as security and dependability. Developers have to handle these requirements during software development lifecycle. To provide developers with security guidelines, security patterns were proposed. These patterns are a collection of expert's security knowledge and a good solution to convey security concepts. In order to encourage developers to take advantage from security solutions proposed by security patterns, we think that it is necessary to provide an appropriate mechanism to implement those patterns using UML profiles. In this paper, we propose structured UML profiles construction process based on security patterns. An illustration of the proposed profile construction process is provided using the active replication pattern. A case study of GPS system is also provided to demonstrate the application of generated UML profile using the proposed process.},
  keywords={Security;Unified modeling language;Object oriented modeling;Program processors;Context;Connectors;based approach;Security pattern;UML profile;Model Driven Development},
  doi={10.1109/ICCSE.2012.104},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6993108,
  author={Anshad, P Y Muhammed and Kumar, S. S.},
  booktitle={2014 International Conference on Control, Instrumentation, Communication and Computational Technologies (ICCICCT)}, 
  title={Recent methods for the detection of tumor using computer aided diagnosis — A review}, 
  year={2014},
  volume={},
  number={},
  pages={1014-1019},
  abstract={Computer Aided Diagnosis (CAD) is one of the trusted methods in the field of medicine. CAD system assists the doctors for the diagnosis of diseases in higher degree of perfection within a short period of time. Now CAD is the most preferable method for the initial diagnosis of cancer using X-ray, CT, mammogram or MRI images. CAD works as an intermediate in between the radiologist and the input images. The output from CAD doesn't think about as a final result however used as a reference for more tests in the relevant field. In fact CAD helps the doctors for detection of cancer more precisely and early. The combination of artificial intelligence, digital image processing technique and radiological image processing etc makes the CAD system more reliable and efficient. Sensitivity, specificity, absolute detection rate etc are the important parameters of the CAD system. Now CAD system is mostly used for breast cancer detection, lung cancer detection, colon cancer, coronary artery disease, congenital heart defect, lung cancer, bone cancer, brain tumor etc. Any part of body can affect cancer and very high possibility to spread other parts. These days CAD system developed to a great extends, however it's not reached to 100% accuracy. In this article that discusses the necessary options, motivation, findings from the early developments and future expansions of CAD systems.},
  keywords={Feature extraction;Design automation;Tumors;Cancer;Computers;Lungs;Classification algorithms;Computer Aided Diagnosis;Artificial intelligence;digital image processing technique;radiological image processing},
  doi={10.1109/ICCICCT.2014.6993108},
  ISSN={},
  month={July},}@INPROCEEDINGS{9004238,
  author={Velliangiri, S. and Karthikeyan, P. and Joseph, Iwin Thanakumar and Kumar, Satish A. P.},
  booktitle={2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Investigation of Deep Learning Schemes in Medical Application}, 
  year={2019},
  volume={},
  number={},
  pages={87-92},
  abstract={Deep learning models are equipped for thinking out how to concentrate on the correct features without anyone else's input, requiring a little direction from the software engineer. Essentially, deep learning mirrors how our brain is functioning to take decisions. Deep learning techniques are highly applied in medical imaging diagnosis. Deep learning techniques are used in medical applications in four different areas i. Detections ii. Classifications iii. Segmentations iv. Registrations. In this paper we have discussed deep learn scheme advantage, dataset, software and hardware used in medical applications. Further, we discussed the comparative analysis of medical application using deep learning techniques.},
  keywords={},
  doi={10.1109/ICCIKE47802.2019.9004238},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6799500,
  author={Chattaraj, Ritwik and Bhattacharya, Srijan and Roy, Ankur and Mazumdar, Abhra and Bepari, Bikash and Bhaumik, Subhasis},
  booktitle={2014 Recent Advances in Engineering and Computational Sciences (RAECS)}, 
  title={Gesture based control of IPMC actuated gripper}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Robotic grippers and its control is always a challenging and an interesting topic for the researcher. In the present scenario the most advanced gripping devices which are commercially available are of macro size. But the real challenge comes when we think for micro gripping or micro assembly. This paper represents a novel technique of gripping with Ionic Polymer Metal Composite (IPMC) actuated finger and advance communication process with the help of joystick and data glove. This technique gives an advantage to control a micro gripping device from a remote location. End effectors are made of IPMC. IPMC is one of the Electro Active Polymer (EAPs) which holds an excellent bending property at low actuation voltage resulting in high force output, thus it is capable of doing work as good as human finger tip when the same is employed as an actuator for micromanipulation. This device can manipulate micro object less than 1 mm in diameter as well as macro sized object within 10 mm diameter. This finger design is compliant in nature. In this article the underlying principle based on which the gripper operates and its fabrication process are explained in detail. It involves miniature part handling, integration and assembly operation.},
  keywords={Grippers;Data gloves;Thumb;Polymers;Actuators;Power supplies;Ionic Polymer Metal Composite;Electro Active Polymer;Data Glove;Joystick;Micro Gripper},
  doi={10.1109/RAECS.2014.6799500},
  ISSN={},
  month={March},}@INPROCEEDINGS{4937501,
  author={Collingsworth, Ben and Menezes, Ronaldo and Martins, Paulo},
  booktitle={2009 IEEE Symposium on Computational Intelligence for Financial Engineering}, 
  title={Assessing organizational stability via network analysis}, 
  year={2009},
  volume={},
  number={},
  pages={43-50},
  abstract={It is widely known that the email system forms a social network. Analysis of email networks reveals properties similar to classic social networks such as friendship or academic collaboration networks. Like other social networks, the properties observed in email networks are the result of patterns of human social behavior rather than the underlying technology. Hence, email social network properties correlate to the social environment in which they are generated. The overall social behavior observed in an organization may be attributed directly to organizational stability and robustness. As a result, organizational health and robustness may be discerned by examining the social network properties of the network formed by the email interaction of its employees because they certainly reflect changes in organizational mood. The fears, worries, gossips, the good and the bad, are reflected in the email activity of individuals in the organization; the challenge though is to extract his information from the network itself. In this paper we provide a first step in the process of demonstrating that email social network analysis can tell us more about the organization than we may think; we show using a case study based on the Enron corporation that problems in the organization were apparent as an emergent characteristic of social network formed by email exchange in the organization.},
  keywords={Stability analysis},
  doi={10.1109/CIFER.2009.4937501},
  ISSN={2380-8454},
  month={March},}@INPROCEEDINGS{4631237,
  author={Sheri, Guleng and Corne, David W.},
  booktitle={2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)}, 
  title={The simplest evolution/learning hybrid: LEM with KNN}, 
  year={2008},
  volume={},
  number={},
  pages={3244-3251},
  abstract={The learnable evolution model (LEM) was introduced by Michalski in 2000, and involves interleaved bouts of evolution and learning. Here we investigate LEM in (we think) its simplest form, using k-nearest neighbour as the dasialearningpsila mechanism. The essence of the hybridisation is that candidate children are filtered, before evaluation, based on predictions from the learning mechanism (which learns based on previous populations). We test the resulting dasiaKNNGApsila on the same set of problems that were used in the original LEM paper. We find that KNNGA provides very significant advantages in both solution speed and quality over the unadorned GA. This is in keeping with the original LEM paperpsilas results, in which the learning mechanism was AQ and the evolution/learning interface was more sophisticated. It is surprising and interesting to see such beneficial improvement in the GA after such a simple learning-based intervention. Since the only application-specific demand of KNN is a suitable distance measure (in that way it is more generally applicable than many other learning mechanisms), LEM methods using KNN are clearly recommended to explore for large-scale optimization tasks in which savings in evaluation time are necessary.},
  keywords={Gallium;Pediatrics;Evolution (biology);Next generation networking;Learning systems;Evolutionary computation;Prediction algorithms},
  doi={10.1109/CEC.2008.4631237},
  ISSN={1941-0026},
  month={June},}@INPROCEEDINGS{6724340,
  author={Gupta, Sonali and Bhatia, Komal Kumar},
  booktitle={2013 International Symposium on Computational and Business Intelligence}, 
  title={CrawlPart: Creating Crawl Partitions in Parallel Crawlers}, 
  year={2013},
  volume={},
  number={},
  pages={137-142},
  abstract={With the ever proliferating size and scale of the WWW [1], efficient ways of exploring content are of increasing importance. How can we efficiently retrieve information from it through crawling? And in this "era of tera" and multi-core processors, we ought to think of multi-threaded processes as a serving solution. So, even better how can we improve the crawling performance by using parallel crawlers that work independently? The paper devotes to the fundamental advantages and challenges arising from the design of parallel crawlers [4]. The paper mainly focuses on the aspect of URL distribution among the various parallel crawling processes. How to distribute URLs from the URL frontier to the various concurrently executing crawling process threads is an orthogonal problem. The paper provides a solution to the problem by designing a framework that partitions the URL frontier into a several URL queues by ordering the URLs within each of the distributed set of URLs.},
  keywords={Crawlers;Web pages;Databases;World Wide Web;Search engines;Servers;HTML;WWW;search engine;parallel crawler;Web-Partitioning;URL distribution;Scalability},
  doi={10.1109/ISCBI.2013.36},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{612297,
  author={Beigel, R. and Bin Fu},
  booktitle={Proceedings of Computational Complexity. Twelfth Annual IEEE Conference}, 
  title={Circuits over PP and PL}, 
  year={1997},
  volume={},
  number={},
  pages={24-35},
  abstract={C.B. Wilson's (1985) model of oracle gates provides a framework for considering reductions whose strength is intermediate between truth-table and Turing. Improving on a stream of results by previous authors, we prove that PL and PP are closed under NC/sub 1/ reductions. This answers an open problem of M. Ogihara (1996). More generally, we show that NC/sub k+1//sup PP/=AC/sub k//sup PP/ and NC/sub k+1//sup PL/=AC/sub k//sup PL/ for all k/spl ges/0. On the other hand, we construct an oracle A such that NC/sub k/(PP/sup A/)/spl ne/NC/sub k+1/(PP/sup A/) for all integers k/spl ges/1. Slightly weaker than NC/sub 1/ reductions are Boolean formula reductions. We ask whether PL and PP are closed under Boolean formula reductions. This is a nontrivial question despite NC/sub 1/=BF, because that equality is easily seen not to relativize. We prove that P/sub log2n/loglogn-T//sup PP//spl sube/BF/sup PP//spl sube/PrTIME(n/sup O(logn)/). Because P/sub log2n/loglogn-T//sup PP//spl nsub/PP relative to an oracle, we think it is unlikely that PP is closed under Boolean formula reductions. We also show that PL is unlikely to be closed under BF reductions.},
  keywords={Circuits;Computer science;Polynomials;NASA;Complexity theory;Upper bound},
  doi={10.1109/CCC.1997.612297},
  ISSN={1093-0159},
  month={June},}@ARTICLE{9935325,
  author={Razzak, Imran and Naz, Saeeda and Alinejad-Rokny, Hamid and Nguyen, Tu N. and Khalifa, Fahmi},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={A Cascaded Mutliresolution Ensemble Deep Learning Framework for Large Scale Alzheimer's Disease Detection Using Brain MRIs}, 
  year={2024},
  volume={21},
  number={4},
  pages={573-581},
  abstract={Alzheimer's is progressive and irreversible type of dementia, which causes degeneration and death of cells and their connections in the brain. AD worsens over time and greatly impacts patients’ life and affects their important mental functions, including thinking, the ability to carry on a conversation, and judgment and response to environment. Clinically, there is no single test to effectively diagnose Alzheimer disease. However, computed tomography (CT) and magnetic resonance imaging (MRI) scans can be used to help in AD diagnosis by observing critical changes in the size of different brain areas, typically parietal and temporal lobes areas. In this work, an integrative mulitresolutional ensemble deep learning-based framework is proposed to achieve better predictive performance for the diagnosis of Alzheimer disease. Unlike ResNet, DenseNet and their variants proposed pipeline utilizes PartialNet in a hierarchical design tailored to AD detection using brain MRIs. The advantage of the proposed analysis system is that PartialNet diversified the depth and deep supervision. Additionally, it also incorporates the properties of identity mappings which makes it powerful in better learning due to feature reuse. Besides, the proposed ensemble PartialNet is better in vanishing gradient, diminishing forward-flow with low number of parameters and better training time in comparison to its counter network. The proposed analysis pipeline has been tested and evaluated on benchmark ADNI dataset collected from 379 subjects patients. Quantitative validation of the obtained results documented our framework's capability, outperforming state-of-the-art learning approaches for both multi-and binary-class AD detection.},
  keywords={Alzheimer's disease;Diseases;Magnetic resonance imaging;Brain;Convolutional neural networks;Task analysis;Neuroimaging;Ensemble PartialNet;alzheimer disorder;dementia;early diagnosis},
  doi={10.1109/TCBB.2022.3219032},
  ISSN={1557-9964},
  month={July},}@INPROCEEDINGS{6597226,
  author={Weber, Philip and Bordbar, Behzad and Tin̂o, Peter},
  booktitle={2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)}, 
  title={A principled approach to mining from noisy logs using Heuristics Miner}, 
  year={2013},
  volume={},
  number={},
  pages={119-126},
  abstract={Noise is a challenge for process mining algorithms, but there is no standard definition of noise nor accepted way to quantify it. This means it is not possible to mine with confidence from event logs which may not record the underlying process correctly. We discuss one way of thinking about noise in process mining. We consider mining from a `noisy log' as learning a probability distribution over traces, representing the true process, from a log which is a sample from multiple distributions: the `true' process model and one or more `noise' models. We apply this using a probabilistic analysis of the Heuristics Miner algorithm, and demonstrate on a simple example. We show that for a given model it is possible to predict how much data is needed to mine the underlying model without the noise, and identify differences in the the robustness of Heuristics Miner to different types of noise.},
  keywords={Noise;Data mining;Noise measurement;Probabilistic logic;Business;Algorithm design and analysis;Joints},
  doi={10.1109/CIDM.2013.6597226},
  ISSN={},
  month={April},}
