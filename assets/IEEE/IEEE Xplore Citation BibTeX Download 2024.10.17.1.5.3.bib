@INPROCEEDINGS{9776343,
  author={Rathore, Abhiraj Singh and Sharma, Adarsh and Massoudi, Massoud},
  booktitle={2021 6th International Conference on Computing, Communication and Security (ICCCS)}, 
  title={Personalized Engineering Education Model Based on Artificial Intelligence for Learning Programming}, 
  year={2021},
  volume={},
  number={},
  pages={1-10},
  abstract={Background: Personalisation is a critical element in the learning environment of students. This is one area that our educational system falls short. Students study at varying rates and in varying contexts, and this should be considered, which most institutions do not. We need a structure that enables students of diverse background to research and learn in their own unique manner, at their own speed, in order to grasp concepts and solve problems. Today, there is something that is gaining a lot of popularity. The future is artificial intelligence, and we agree that science holds the secret to resolving the majority of the world's problems. Result: This article provides a novel model of a system that utilizes artificial intelligence and machine learning algorithms to assist students in learning to program and creates a customized system for them. The model classifies students into beginner, intermediate, and proficient ranks using Bayesian networks. Students are helped to understand ideas by the use of tools such as flowcharts. Each level of students is provided with unique instruments and materials, and the goal is to raise the comprehension level of beginner and intermediate students to a point that they can compete with proficient students, who are provided with practice questions to further their learning. Additionally, skilled students have the ability to work in industry through the model's industry-academia partnership module. Conclusion: This paper proposes a technique that helps students in customized learning as well as in improving their critical thinking capacities using a multi-agent-based flowchart development tool. It serves as an absolute and a complete tutoring aid for students learning programming.},
  keywords={Industries;Flowcharts;Machine learning algorithms;Instruments;Computational modeling;Learning (artificial intelligence);Bayes methods;Personalized learning;Engineering education;Artificial intelligence;Learning outcome},
  doi={10.1109/ICCCS51487.2021.9776343},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9643932,
  author={Imanaga, Tomohiro and Nakano, Koji and Yasudo, Ryota and Ito, Yasuaki and Kawamata, Yuya and Katsuki, Ryota and Ozaki, Shiro and Yazane, Takashi and Hamano, Kenichiro},
  booktitle={2021 Ninth International Symposium on Computing and Networking (CANDAR)}, 
  title={Solving the sparse QUBO on multiple GPUs for Simulating a Quantum Annealer}, 
  year={2021},
  volume={},
  number={},
  pages={19-28},
  abstract={Quadratic Unconstraint Binary Optimization (QUBO) is a combinatorial optimization problem such that an $n\times n$ upper triangle matrix $W$ is given and the objective is to find an n-bit vector $X$ that minimizes the energy value $E(X)=X^{T}WX$. A QUBO instance $W$ is sparse if instance $W$ has few non-zero elements. The D-Wave 2000$Q$ is a quantum annealer that can solve 2048-bit sparse QUBO instances represented as a Chimera graph topology. We present a sparse QUBO solver running on GPUs for 2048-bit sparse QUBO with a Chimera graph topology. We have evaluated the performance of our sparse QUBO solver and the D-Wave 2000Q for solving 2048-bit QUBO instances with various resolutions. The experimental results show that our sparse QUBO solver running on a GPU cloud server with 8 NVIDIA A100 GPUs can find optimal solutions in less than 3ms for all instances while the D-Wave 2000$Q$ cannot find them in 996.7ms. Hence, our QUBO solver can find better solutions than the D-Wave 2000Q in less than 1/300 running time. We can think that our QUBO solver is a quantum annealer simulator with better performance in terms of the accuracy of solutions and the running time. Our result implies that quantum annealer D-Wave 2000$Q$ does not achieve quantum supremacy yet.},
  keywords={Annealing;Shape;Computational modeling;Graphics processing units;Simulated annealing;Quantum annealing;Topology;Ising model;quantum computing;quantum supremacy;GPGPU},
  doi={10.1109/CANDAR53791.2021.00011},
  ISSN={2379-1896},
  month={Nov},}@INPROCEEDINGS{8603189,
  author={Audrito, Giorgio and Damiani, Ferruccio and Viroli, Mirko and Bini, Enrico},
  booktitle={2018 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={Distributed Real-Time Shortest-Paths Computations with the Field Calculus}, 
  year={2018},
  volume={},
  number={},
  pages={23-34},
  abstract={As the density of sensing/computation/actuation nodes is increasing, it becomes more and more feasible and useful to think at an entire network of physical devices as a single, continuous space-time computing machine. The emergent behaviour of the whole software system is then induced by local computations deployed within each node and by the dynamics of the information diffusion. A relevant example of this distribution model is given by aggregate computing and its companion language field calculus, a minimal set of purely functional constructs used to manipulate distributed data structures evolving over space and time, and resulting in robustness to changes. In this paper, we study the convergence time of an archetypal and widely used component of distributed computations expressed in field calculus, called gradient: a fully-distributed estimation of distances over a metric space by a spanning tree. We provide an analytic result linking the quality of the output of a gradient to the amount of computing resources dedicated. The resulting error bounds are then exploited for network design, suggesting an optimal density value taking broadcast interferences into account. Finally, an empirical evaluation is performed validating the theoretical results.},
  keywords={Calculus;Aggregates;Programming;Computational modeling;Real-time systems;Sensors;Wireless sensor networks;aggregate computing;field calculus;shortest path;IoT;distributed systems},
  doi={10.1109/RTSS.2018.00013},
  ISSN={2576-3172},
  month={Dec},}@INPROCEEDINGS{10254740,
  author={Pujol, Victor Casamayor and Morichetta, Andrea and Nastic, Stefan},
  booktitle={2023 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Intelligent Sampling: A Novel Approach to Optimize Workload Scheduling in Large-Scale Heterogeneous Computing Continuum}, 
  year={2023},
  volume={},
  number={},
  pages={140-149},
  abstract={Scheduling workloads on large-scale infrastructures, such as in the Edge-Cloud continuum is a challenging task. Usually, the scheduling algorithm considers only a limited sample of the infrastructure nodes, typically obtained through random sampling. The sampling reduces the number of nodes, which need to be evaluated in the scheduling pipeline, making the scheduling process more saleable. Unfortunately, current sampling approaches become largely inefficient when the infrastructure is heterogeneous and specific, scarce node characteristics are required to successfully execute a workload. Computing continuum infrastructures are heterogeneous, hence, we need to re-think the sampling process to keep it viable at scale while also being able to identify and leverage the heterogeneity of the Edge-Cloud continuum resources. In this article, we present Intelligent Sampling - a novel technique for improving sampling in large-scale and heterogeneous infrastructures. We develop a model for any heterogeneous infrastructure. Based on this model, we provide a method to sample the infrastructure nodes more accurately, considering the specific task at hand. Finally, we leverage the Alibaba PAI dataset to show that our approach is 2.5x times more accurate compared with other state-of-the-art sampling mechanisms while retaining comparable performance and scalability.},
  keywords={Service-oriented systems engineering;Scheduling algorithms;Computational modeling;Scalability;Pipelines;Heterogeneous networks;Complexity theory;Computing continuum;Intelligent sampling;Workloads scheduling;Heterogeneous infrastructure model},
  doi={10.1109/SOSE58276.2023.00024},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{6779199,
  author={Bai, Liming},
  booktitle={16th International Conference on Advanced Communication Technology}, 
  title={Techniques for system of systems engineering in construction of a smart tourism industry information system}, 
  year={2014},
  volume={},
  number={},
  pages={402-408},
  abstract={Currently, as many disciplines begin to cultivate a set of core methodologies, system of systems engineering (SoSE), which has its root in context of military programming, becomes a significant research focus and provides a new perspective to solve the emerging "system of systems" challenges in industrial analysis. Meanwhile, modern communication and information technologies have provided greater possibilities for socio-economic sectors to execute smarter decisions, and these technologies may advance the industrial application of SoSE. Therefore, targeting the rareness of government-oriented intelligent decision support system (DSS), and guided by the underlying system of systems thinking, this paper proposes a technical framework for designing a policy maker-responsive smart information system which focuses: (1) system of systems structural architecting; (2) geographical simulation using time-series remotely sensed data, GIS instrument and simulation bodies such as cellular automata (CA) and multi-agent systems (MAS); (3) SoS evolution description through network analysis and intelligent computing; (4) measurement of SoS effectiveness with two-tier and four-grade method; and (5) SoSE program for industrial optimization. Its application in tourism analysis will provide a smarter base for industrial policy-making, planning and forecasting, and will help reduce risk and cost in industrial restructuring. For this relatively new field of SoSE application, tools and methods are not perfect, so it is important to draw together academia, government, industrial organizations and enterprises to collaborate for further valuable achievement.},
  keywords={Information systems;Computational modeling;Artificial intelligence;Industries;Biological system modeling;System of systems engineering (SoSE);geographical simulation;tourism;smart industry information system;intelligent computing},
  doi={10.1109/ICACT.2014.6779199},
  ISSN={1738-9445},
  month={Feb},}@INPROCEEDINGS{6143085,
  author={Neri, Luis and Noguez, Julieta and Pérez, Iván and Aguilar, Gerardo},
  booktitle={2011 Frontiers in Education Conference (FIE)}, 
  title={Facilitating the design of physics active learning problems through authoring simulation tools: Authorphysics}, 
  year={2011},
  volume={},
  number={},
  pages={S3C-1-S3C-6},
  abstract={Active learning is an educational strategy that promotes the development of the student's critical and creative thinking through carefully designed activities. The teacher often faces challenges to design adequate physics problems because it demands a high effort to have enough variety of exercises for several students' levels. In addition, it is important to display exercises in an attractive visual and interactive environment, but this requires deep computer knowledge. Most common simulators in the literature are visually attractive, but are often designed to solve a particular or limited problem. Authoring tools have the advantage to allow building several learning environments, involving professors without computer expertise. Therefore, teachers require less effort and time to develop simulation problems. In this work we present an on line authoring simulation tool, called AuthorPhysics, aimed to facilitate the design of physics active learning problems, reducing instructors' time and effort. An initial evaluation of the usability and benefits of the system for the instructors was carried on. The results are encouraging in the sense that teachers are able to create a great variety of physical scenarios and problems, appropriate for introductory undergraduate and high-school physics courses. An evaluation with students is currently running.},
  keywords={Computational modeling;Pulleys;Mathematical model;Education;Friction;Java;Active Learning;Authoring Tools;eLearning Tools;Introductory Classical Mechanics;On line Tools;Physics Simulations},
  doi={10.1109/FIE.2011.6143085},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{4531358,
  author={Buscema, Massimo},
  booktitle={NAFIPS 2008 - 2008 Annual Meeting of the North American Fuzzy Information Processing Society}, 
  title={The general philosophy of Artificial Adaptive Systems}, 
  year={2008},
  volume={},
  number={},
  pages={1-14},
  abstract={This paper has the objective of describing the structure and placing in a taxonomy the Artificial Adaptive Systems (AAS). These systems form part of the vast world of Artificial Intelligence (AI) nowadays called more properly Artificial Sciences (AS). Artificial Sciences means those sciences for which an understanding of natural and/or cultural processes is achieved by the recreation of those processes through automatic models. In particular, Natural Computation tries to construct automatic models of complex processes, using the local interaction of elementary micro-processes, simulating the original process functioning. Such models organize themselves in space and time and connect in a non-linear way to the global process they are part of, trying to reproduce the complexity through the dynamic creation of specific and independent local rules that transform themselves in relation to the dynamics of the process. Natural Computation constitutes the alternative to Classical Computation (CC). This one, in fact, has great difficulty in facing natural/cultural processes, especially when it tries to impose external rules to understand and reproduce them, trying to formalize these processes in an artificial model. In Natural Computation ambit, Artificial Adaptive Systems are theories which generative algebras are able to create artificial models simulating natural phenomenon. The learning and growing process of the models is isomorphic to the natural process evolution, that is, it's itself an artificial model comparable with the origin of the natural process. We are dealing with theories adopting the "time of development" of the model as a formal model of "time of process" itself. Artificial Adaptive Systems comprise Evolutive Systems and Learning Systems. Artificial Neural Networks are the more diffused and best-known Learning Systems models in Natural Computation. For this reason we present in this paper an application of new Artificial Adaptive Systems to a very hard and pragmatic topic: drug trafficking. That because we think that "real world" is often the best theory.},
  keywords={Adaptive systems;Computational modeling;Artificial intelligence;Cultural differences;Learning systems;Taxonomy;Algebra;Artificial neural networks;Computer networks;Drugs},
  doi={10.1109/NAFIPS.2008.4531358},
  ISSN={},
  month={May},}@INPROCEEDINGS{9658463,
  author={Liu, Jingyi and Yu, Lina and Wu, Min and Tong, Yuerong and Xu, Jian and Li, Zhiwei and Hu, Xuan and Li, Weijun},
  booktitle={2021 International Conference on High Performance Big Data and Intelligent Systems (HPBD&IS)}, 
  title={Producing Monomial Sets with Lower Calculation Complexity for Polynomial Fitting}, 
  year={2021},
  volume={},
  number={},
  pages={52-56},
  abstract={In the physic world, exploring and discovering the mechanism behind the various phenomenon is crucial for us to know the world better. However, it is hard to discover the principle in case of enormous data and the mechanism may be too hard for a human to figure out. Data science gives us a way of knowing the world and finding the mechanism hidden in the data. Automatic tool like polynomial fitting is a useful method to fit the data well. When the variable number and degree are relatively low, the computation amount of polynomial is small. However, the number of monomials grows exponentially with the increasing variable number and degree. Problems in the real world are always in a high-dimension, and the problem may be complex that needs to use a high degree to fit data well. Plus, with the huge data, the computation complexity is high. Therefore, we think it is necessary to find a way to reduce the computation amount of fitted polynomial. In this paper, we propose to use the PSO algorithm to find the monomial sets that have lower computation amounts. Experiments show the effectiveness of our method.},
  keywords={Fitting;Data science;Computational complexity;Physics;polynomial fitting;computation complexity;optimization problem;pattern recognition},
  doi={10.1109/HPBDIS53214.2021.9658463},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10633328,
  author={Zhang, Yifan and Towey, Dave and Pike, Matthew},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Enabling Effective Metamorphic- Relation Generation by Novice Testers: A Pilot Study}, 
  year={2024},
  volume={},
  number={},
  pages={2393-2398},
  abstract={This paper presents a pilot study that examines the capacity of novice testers to generate Metamorphic Relations (MRs) for autonomous driving systems (ADSs), specifically fo-cusing on parking functions. By comparing MRs generated by human participants with those generated by artificial intelligence (AI), we seek to understand the variances in quality, particularly in terms of correctness, applicability, novelty, and utility. Our findings indicate that despite receiving only minimal training, human participants were capable of producing MRs with a wide range of effectiveness. Notably, humans exhibited a potential for creative thinking, contrasting with AI's ability to generate MRs that adhere closely to technical and applicability standards. The study underscores the need for improved educational strategies aimed at enhancing the quality and confidence of MRs produced by humans. Future research directions will explore the optimization of training approaches, particularly within a constrained timeframe to create a positive learning experience and maintain participant engagement, to fully harness the creative capabilities of human learners in the context of ADS testing.},
  keywords={Training;Computational modeling;Software;Artificial intelligence;Standards;Optimization;Autonomous vehicles;Metamorphic testing;autonomous driving system;metamorphic relation;driving scenarios;large language models;artificial intelligence},
  doi={10.1109/COMPSAC61105.2024.00384},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9443981,
  author={Li, Yang and Shi, Bing},
  booktitle={2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={A Deep Reinforcement Learning based Mobile Device Task Offloading Algorithm in MEC}, 
  year={2020},
  volume={},
  number={},
  pages={200-207},
  abstract={Nowadays, more and more compute-intensive applications begin to appear on mobile devices. However, mobile devices may not be able to satisfy the computing requirements. Mobile Edge Computing (MEC) is proposed to address these issues. Mobile devices offload the computing tasks to the edge servers which accept tasks and handle them. And we think the edge servers should accomplish tasks as many as possible while minimizing total energy cost. However, users with mobile devices are usually keeping moving. In this situation, the energy consumption of tasks are constantly changing, and we need an efficient algorithm to dynamically determine how to offload tasks to a set of edge servers, to maximize the number of completed tasks while minimizing the energy consumption. The dynamic decision of task offloading is a multi-stage decision problem, and therefore we can model this problem as a Markov decision process (MDP). Because this problem involves a huge state space with high dimension, we propose a deep reinforcement learning (DRL) based mobile device task offloading algorithm to solve this problem. We also run extensive experiments to evaluate our task offloading approach against other typical task offloading approaches. The results of experiments show that our algorithm is superior to the baseline algorithms.},
  keywords={Energy consumption;Heuristic algorithms;Computational modeling;Reinforcement learning;Markov processes;Mobile handsets;Servers;Mobile Edge Computing;Task Offloading;Deep Reinforcement Learning},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00051},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10485136,
  author={Chen, Shiyang and Zheng, Da and Ding, Caiwen and Huan, Chengying and Ji, Yuede and Liu, Hang},
  booktitle={SC23: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Tango: Rethinking Quantization for Graph Neural Network Training on GPUs}, 
  year={2023},
  volume={},
  number={},
  pages={1-15},
  abstract={Graph learning is becoming increasingly popular due to its superior performance in tackling many grand challenges. While quantization is widely used to accelerate Graph Neural Network (GNN) computation, quantized training faces remarkable roadblocks. Current quantized GNN training systems often experience longer training time than their full-precision counterparts for two reasons: (i) addressing the quantization accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quanti-zation is not adequately leveraged. This paper introduces Tango which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations to speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over the state-of-the-art approaches on various GNN models and datasets.},
  keywords={Training;Quantization (signal);High performance computing;Computational modeling;Graph neural networks;Libraries;Optimization},
  doi={10.1145/3581784.3607037},
  ISSN={2167-4337},
  month={Nov},}@INPROCEEDINGS{8802735,
  author={Di Pietro, Roberto and Jero, Leonardo and Lombardi, Flavio and Solanas, Agusti},
  booktitle={2019 IEEE Conference on Communications and Network Security (CNS)}, 
  title={GPU Algorithms for K-Anonymity in Microdata}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  abstract={GPU computing, nowadays widely and readily available on the cloud, has opened up novel opportunities for the parallelization of computationally-intensive tasks, such as data anonymization. The development of effective techniques that help to guarantee data anonymity is a critical enabler for data sharing activities, as well as to enforce compliance-think about the European GDPR. In this scenario, we focus on personal data stored in microdata sets. Before releasing such microdata to the general public, statistical agencies and the like have to sanitize them by using a variety of Microdata Protection Techniques (MPTs)that aim at keeping data utility while preserving some kind of anonymity. In particular, microaggregation is a specific MPT arisen in the field of statistical disclosure control. We analyze the microaggregation anonymization issues and propose three GPU-based parallel approaches for a well-known microaggregation technique: the Maximum Distance to Average Vector (MDAV)algorithm. The experimental results demonstrate the feasibility of our proposal and emphasize the benefits of using GPUs to speed-up the execution of privacy preserving algorithms for microdata.},
  keywords={Graphics processing units;Security;Conferences;Privacy;Computational efficiency;Java;Communication networks;Privacy;Anonymization;Cloud;Microaggre-gation;GPU;Parallelization},
  doi={10.1109/CNS.2019.8802735},
  ISSN={},
  month={June},}@INPROCEEDINGS{4141731,
  author={Imai, Yoshiro and Kaneko, Keiichi and Nakagawa, Masaki},
  booktitle={2006 7th International Conference on Information Technology Based Higher Education and Training}, 
  title={A Visual Computer Simulator and its Applications to An ICT-based Higher Education}, 
  year={2006},
  volume={},
  number={},
  pages={nil13-nil20},
  abstract={A visual computer simulator, called "VisuSim", has been developed and applied to real education for Computer Science at Kagawa University. It is one of educational tools associated with lectures on computer architecture and assembly programming. The simulator is written in the pure Java programming language, executed in several kinds of environment (free for types of OS and CPU) and invoked in the applet mode as well as in the stand-alone one. Typical usages of our simulator are two-fold. Teachers employ our simulator, "VisuSim" to demonstrate visually how a computer processes its program. Students use the simulators in class or access our Website, download "VisuSim", and invoke applet-based "VisuSim" on their browsers. After receiving feedback from users, we have provided communication support facility as a new function of "VisuSim". With such a communication facility, can send their programs, ask questions on them to their classmates and the classmates can test received programs with their "VisuSim" to think together about the questions},
  keywords={Computational modeling;Computer simulation;Application software;Computer science education;Educational programs;Computer science;Computer architecture;Assembly;Programming profession;Java;Educational tool;Collaborative learning;Visual simulator;Java programming language;Computer literacy},
  doi={10.1109/ITHET.2006.339722},
  ISSN={},
  month={July},}@INPROCEEDINGS{882454,
  author={Principe, J.C. and Erdogmus, D.},
  booktitle={Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No.00EX373)}, 
  title={From adaptive linear to information filtering}, 
  year={2000},
  volume={},
  number={},
  pages={99-104},
  abstract={Adaptive signal processing theory was born and has lived by exclusively exploiting the mean square error criterion. When we think of the goal of least squares without restrictions of Gaussianity, one has to wonder why an information theoretic error criterion is not utilized instead. After all, the goal of adaptive filtering should be to find the linear projection that best captures the information in the desired response. We summarize our efforts to extend adaptive linear filtering to information filtering. We review Renyi's (1987) entropy definition, Parzen (1967) windows and put them together in a framework to estimate entropy directly from samples (nonparametric). Once this criterion is developed we can train linear or nonlinear adaptive networks for entropy maximization or minimization. We present results on the properties of the Renyi's nonparametric entropy estimator, and show how it performs in chaotic time series prediction.},
  keywords={Information filtering;Entropy;Adaptive signal processing;Mean square error methods;Least squares methods;Gaussian processes;Adaptive filters;Maximum likelihood detection;Adaptive systems;Chaos},
  doi={10.1109/ASSPCC.2000.882454},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9381469,
  author={Michalski, Radoslaw and Pieczka, Marcin},
  booktitle={2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)}, 
  title={Dru: Studying Blockchain as a Complex Network}, 
  year={2020},
  volume={},
  number={},
  pages={929-932},
  abstract={Apart from many project design decisions that have to be made when incorporating blockchain as a trusted transactions register, it is also essential to gain a deeper understanding of the ecosystem when it already entered operational state. By looking at the way how nodes perform transactions, how they cluster, or what is the dynamics of the network, many valuable insights can be derived about the condition of the whole system. This leads to improving functionality, performance, scalability, and security. We propose a way of looking at the network of transactions as at a complex network and demonstrate that the methods and algorithms provided by network science can significantly increase our knowledge about the blockchain ecosystem. In this work, we introduce an open-source platform called Dru that is linked to this concept and simplifies performing analyses by providing a built-in storage of transactions and an API for research. We believe that the insights presented in this work will be helpful for studying blockchain-based systems. As a result, those systems supporting variety of processes will be able to move from reactive to proactive thinking and improve their functionality, availability and security.},
  keywords={Social networking (online);Scalability;Ecosystems;Blockchain;Complex networks;Cryptography;Open source software;blockchain;distributed ledger;network science;complex network;software platform},
  doi={10.1109/ASONAM49781.2020.9381469},
  ISSN={2473-991X},
  month={Dec},}@ARTICLE{9420690,
  author={Zahid, Amjad Hussain and Iliyasu, Abdullah M. and Ahmad, Musheer and Shaban, Mian Muhammad Umar and Arshad, Muhammad Junaid and Alhadawi, Hussam S. and El-Latif, Ahmed A. Abd},
  journal={IEEE Access}, 
  title={A Novel Construction of Dynamic S-Box With High Nonlinearity Using Heuristic Evolution}, 
  year={2021},
  volume={9},
  number={},
  pages={67797-67812},
  abstract={For decades, the security and privacy of data are among the major challenges faced by service providers dealing with public data. To cope with these challenges, most of the organizations rely on the adoption of cryptographic methods for protecting data against any illegitimate access and attacks. Modern day cryptographic ciphers utilize one or more substitution-boxes (S-boxes) that facilitate the realisation of strong security of plain data during encryption and legal decoding of it during decryption process. Security of ciphers is directly proportional to the cryptographic strength of S-boxes. This study proposes an efficient and simple method based on some modular operations for the construction of dynamic S-boxes with high nonlinearity using a heuristic evolution strategy. A large number of strong S-boxes can be easily constructed using slight variations in the parameters of the anticipated method. A specimen S-box is constructed and its critical performance analysis against standard security criteria including nonlinearity, strict avalanche criterion, bit independence criterion, differential uniformity, linear probability, and fixed points are reported as justification for the proposed technique's high cryptographic strength. Furthermore, the generated S-box is also applied to encrypt digital images to assess its cryptographic application performance. The performance and comparison study validates that the proposed S-box has better performance strength, which makes it a viable candidate for cryptographic applications in different areas of image security.},
  keywords={Ciphers;Security;Encryption;Matrix converters;Streaming media;Performance analysis;Computer science;Security and privacy;substitution-box;block ciphers;encryption;image security;cyber physical systems},
  doi={10.1109/ACCESS.2021.3077194},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6728496,
  author={Shen, Z. and Wang, K. and Wang, F.-Y.},
  booktitle={16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)}, 
  title={GPU based Non-dominated Sorting Genetic Algorithm-II for multi-objective traffic light signaling optimization with agent based modeling}, 
  year={2013},
  volume={},
  number={},
  pages={1840-1845},
  abstract={Micro-simulation becomes more and more important in the Intelligent Transportation Systems (ITS) research, because it can provide detailed descriptions of the system. For a multi-agent systems (MAS) modeling of an ITS, the computation burden is large, as it involves the computation of the state changing of all the agents. And, there are many multi-objective optimization problems in the ITS research. In this paper, we solve the traffic light signaling optimization problem and we take the average delay time and the average stop times as two objectives. We use a famous method of Non-dominated Sorting Genetic Algorithm II (NSGA-II). As NSGA-II can be viewed as an intelligent way of running a number of micro-simulations, usually the computation burden is huge. Graphics Processing Units (GPUs) have been a popular tool for parallel computing. The real transportation system runs in parallel and we think that a parallel tool is more suitable for the simulation and optimization of the system. We test GPU based NSGA-II method on a 4 intersection lattice road network, and on the 18 intersection road network of the Zhongguancun area of Beijing. Compared with the CPU version, the GPU version implementation achieves a speedup factor of 21.46 and 27.64 respectively.},
  keywords={Roads;Graphics processing units;Control systems;Topology;Time measurement;Convergence},
  doi={10.1109/ITSC.2013.6728496},
  ISSN={2153-0017},
  month={Oct},}@ARTICLE{486756,
  author={Beichl, I. and Sullivan, F.},
  journal={IEEE Computational Science and Engineering}, 
  title={Tree-lookup for partial sums or: how can I find this stuff quickly?}, 
  year={1996},
  volume={3},
  number={1},
  pages={13-15},
  abstract={Suppose that you need to maintain a large list of data that is to be searched and modified frequently in the course of a computation. You can almost always arrange for both operations to be done efficiently by storing the data in a structure other than a single array. Although there are several elegant ways to do this, we present just one: a simple tree that doesn't require a lot of thinking to implement. It can speed up execution tremendously because instead of searching through a list item after item for each update, possibly examining n items, you need only examine O(log n) items per operation. (More advanced methods can reduce this to log*n at the cost of more complex programming. Here, log*n is the number of iterations of log/sub 2/ that are required to get below 1. For numbers having less than 65K bits, log* is less than 5.).},
  keywords={Monte Carlo methods;Costs;Data structures;Molecular beam epitaxial growth;Epitaxial growth;Springs;Random number generation;Physics computing;Binary trees},
  doi={10.1109/99.486756},
  ISSN={1558-190X},
  month={Spring},}@INPROCEEDINGS{9111490,
  author={Tunstel, Edward},
  booktitle={2019 IEEE 13th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={Next-Level Robotic Intelligence : Plenary Talk}, 
  year={2019},
  volume={},
  number={},
  pages={000011-000012},
  abstract={Recent advances have been effective for progressing the state of robotics toward its next level of intelligence. At this stage, further advancement is needed with sharper focus on increased robustness, cognitive facilities, and more sophisticated behavior. Advances to date are impacting individual elements of what would become a robotic intelligence pipeline but the paths to effective integration of those elements that will realize practical intelligent robots and robotic systems are unclear. This talk offers thoughts and considerations for active researchers to ponder and appreciate in the context of their research programs. From a perspective on current stages of technology development, and looking toward the progress horizon from that vista, the talk discusses a number of topics within the SACI 2019 scope using examples from research projects and deployed systems. Aspects of intelligent robotics associated with different domains and applications are discussed such as planetary robotics, disaster response and wearable robotics. Also addressed are future considerations for the evolution of related technology toward increased robotic autonomy and advanced intelligence for robotic systems. Motivating this discourse are multiple considerations for next-level robotic intelligence such as enhancing perception capabilities beyond the visual modality, moving beyond object recognition and grasping to knowledge and reasoning about object properties, enabling smart human-collaborative robots that are responsive to intuitive, physical, and brain-interfaced interaction, advancing from robot learning for X (perception, control, etc.) to autonomous or developmental learning and knowledge or skill transfer, the need to realize smart behavior for not only singular robots but for multi-robot systems, and some of the related systems engineering considerations. The aim is to broaden the thinking of current researchers leading to the collective leverage that will boost robotic intelligence to the next level enabling robots that are multi-functional in the real-world.},
  keywords={},
  doi={10.1109/SACI46893.2019.9111490},
  ISSN={},
  month={May},}@INPROCEEDINGS{9098288,
  author={Wang, Ningqi and Niu, Chang and Li, Zizhong},
  booktitle={2019 12th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={RLayout: Interior Design System Based on Reinforcement Learning}, 
  year={2019},
  volume={1},
  number={},
  pages={117-120},
  abstract={The advanced artificial intelligence technologies have promoted the development of other industries. As a combination of AI technologies and art, intelligent design has become a research hotspot in recent years. Intelligent design uses computer to simulate human thinking activities with AI technologies, enabling the computers to undertake more complex design tasks in a better way. At the same time, reinforcement learning plays an increasingly important role in many fields, such as system control, game theory, computer network, decision making, etc. In this work, an intelligent design system based on the reinforcement learning algorithm was proposed, and corresponding reward rules were developed according to the design principles. The system can help the designer to generate the optimal scheme automatically, which can be extended and applied to find the best scheme in many problems, including interior design, daily schedule, resource arrangement, etc. Our demo shows that the system can offer excellent design scheme according to pre-set reward rules, and reduce workload of related designers.},
  keywords={Learning (artificial intelligence);Layout;Machine learning;Training;Intelligent systems;reinforcement learning;intelligent design;interior design},
  doi={10.1109/ISCID.2019.00033},
  ISSN={2473-3547},
  month={Dec},}@INPROCEEDINGS{5492514,
  author={Freudenthal, Eric and Ogrey, Alexandria N. and Roy, Mary K. and Siegel, Alan},
  booktitle={IEEE EDUCON 2010 Conference}, 
  title={A computational introduction to STEM studies}, 
  year={2010},
  volume={},
  number={},
  pages={663-672},
  abstract={We report on the content and early evaluation of a new introductory programming course “Media Propelled Computational Thinking,” (abbreviated MPCT and pronounced iMPaCT). MPCT is integrated into a freshman-level program designed for under-prepared students with interests in a STEM discipline. It is intended to reduce attrition rates by fostering student intuition in, appreciation of, and confidence about basic pre-calculus concepts. The MPCT curriculum is problem-driven, with analytical challenge exercises that are intended to motivate inquiry and to illustrate the reasoning used in the STEM professions Preliminary evaluation results are encouraging - students from a wide range of academic majors found MPCT engaging, and report that the course conveyed insight, and decreased anxiety about foundational mathematical concepts.},
  keywords={Programming profession;Computer science;Electrostatic precipitators;Mathematical programming;Algorithm design and analysis;Engineering profession;Propulsion;Calculus;Art;Mathematics;introductory computing curriculum;CS0;MPCT;entering students program;CCLI;CPATH},
  doi={10.1109/EDUCON.2010.5492514},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{9545008,
  author={Narayanan, S. Krishna and Dhanasekaran, S. and Vasudevan, V.},
  booktitle={2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={A shared computational model using distributed processing in a CPS enabled environment}, 
  year={2021},
  volume={},
  number={},
  pages={841-846},
  abstract={Cyber-Physical Systems (CPS) usually include a mix of movable things, embedded computers, and systems to keep track as well as actuate together with the encompassing real life. These computing components are generally wireless, interconnected to talk about interaction and data with one another, with the server component, and with cloud computing expertise. When it comes to such a heterogeneous atmosphere, brand new uses develop in order to meet ever-increasing requirements as well as these're a crucial problem on the processing features of products. For instance, instant traveling methods, producing locations, wise community managing, and so on. In order to fulfill the demands of stated application program contexts, the device is able to make computing procedures to disperse the work above the system and also a cloud computing server. Several choices develop within relation to what network nodes must support the delivery of all of the procedures. This particular paper concentrates on this issue by introducing a sent-out computational design and dynamically discuss the activities among the computing nodes as well as thinking about the natural variability on the context inside the locations. The approach of ours encourages the integration of the computing online resources, with externally provided cloud expertise, to satisfy contemporary program demands. The outcome of the Proposed design satisfies the shared computation level with energy efficient schemes and aslo achieved the response level in good level.},
  keywords={Wireless communication;Performance evaluation;Cloud computing;Power demand;Diversity reception;Atmosphere;Prototypes;CPS;Internet of things;Mobile computing (MC);Modeling;Distributed computation},
  doi={10.1109/ICIRCA51532.2021.9545008},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8914397,
  author={Dimirovski, Georgi and Warwick, Kevin and Stefanovski, Jovan},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, 
  title={Complexity Symbiosis of Glia-Neuron Cells and Computational Cybernetics of Hopfield Recurrent Network: Novel Neuron Model}, 
  year={2019},
  volume={},
  number={},
  pages={1396-1401},
  abstract={Science of artificial neural networks and relevant computing mechanisms since McCullock-Pitts artificial neuron (1943) up via neurons and networks of Anderson (1972), Barto et al (1983), Grosberg (1967, 1976), Hopfield (1982, 1984), Kohonen (1972) to Kasabov's evolving connectionist systems with spiking-neurons (2003) have undergone developments beyond any conceivable predictions. The computational efficiency and functionality of all kinds of neural network implies stable operating steady-state equilibrium is fast established and guaranteed. In parallel, Neurophysiology has yielded many insights Gayton-Hall (2006) converging to paradigm of systems biology. It appeared, on the crossroad of these findings with Hilbert's Thirteen problem and Kolmogorov's Superposition Representations in conjunction with Lyapunov foundations of stability and LaSalle invariance principle certain delicate subtle issues emerged Siljak (2008) and Sprecher (2017). This re-thinking the foundations of neural networks via the quest for parallels between artificial and living neurons is believed to open a new horizon. This belief follows obtained results on cultured-neuron controllers and recurrent neural networks with time-varying delays. A closer look into how animal and/or human brain cells can be cultivated as a controlling brain for a mobile robot (physical body) such that can move around and interact with the world. In turn, a new kind of artificial intelligence may be created, which is emulated by stabilized complex highly non-linear complex neural network system.},
  keywords={Neurons;Symbiosis;Artificial neural networks;Cybernetics;Biological neural networks;Hopfield neural networks;Artificial intelligence},
  doi={10.1109/SMC.2019.8914397},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{8190595,
  author={Nias, Jaye and Marshall, Brandeis and Thompson, Tayloir and Blunt, Takeria},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={EvergreenLP: Using a social network as a learning platform}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={We are living more of our lives situated within online networks and communities where digital artifacts can be collected and processed to showcase individual and group behavior representations. Growing data bandwidth coupled with amplified computational resources are aligning to allow for analysis of human behaviors at unprecedented scales. The proper data generation, collection, storage and analysis techniques are mostly untaught in the undergraduate experience. Pedagogical research shows that project based learning encourages and supports design thinking and collaborative work; skills that are important to practitioners in data science centric industries. To address these academic needs, we develop the Evergreen Learning Platform (EvergreenLP). EvergreenLP is an interdisciplinary project based learning framework that leverages pedagogy rooted in Critical Media Literacy. Students take advantage of design-learning principles on the front-end and computational discipline standards on the back end. Students are engaged in the design, development and use of this platform while simultaneously contributing data content on the chosen social media platform. Our data analysis and visualization environment allows the student coders and non-coders to explore data science principles in context of a current event or topic trending on twitter. In this paper, we experimentally assess and present the benefits of introducing culturally relevant data techniques to African-American female students in an interdisciplinary seminar on #BlackGirlMagic (#BGM).},
  keywords={Media;Twitter;Data science;Data visualization;Tagging;project-based learning;critical media literacy;social media},
  doi={10.1109/FIE.2017.8190595},
  ISSN={},
  month={Oct},}@ARTICLE{5406490,
  author={Kelly, Rory},
  journal={Computing in Science & Engineering}, 
  title={GPU Computing for Atmospheric Modeling}, 
  year={2010},
  volume={12},
  number={4},
  pages={26-33},
  abstract={Much success has been achieved using GPUs to accelerate existing applications that are highly data parallel, or that are dominated by small, intense computational kernels. What are the prospects for porting existing large scientific models that do not fit this mold? We take an expensive routine from the CAM atmosphere model, and port it to a GPU using CUDA. We use the experience gained as a guide in thinking about porting the full application to an accelerator based system. We consider the best path forward for getting large scientific models running on accelerator based systems, and identify cases where porting may be feasible, and where a complete redesign may be the best option.},
  keywords={Atmospheric modeling;Atmosphere;Computer aided manufacturing;CADCAM;Acceleration;Computational modeling;Land surface;Sea surface;Clouds;Kernel;emerging technologies;threads;graphics processors;computations on discrete structures},
  doi={10.1109/MCSE.2010.26},
  ISSN={1558-366X},
  month={July},}
