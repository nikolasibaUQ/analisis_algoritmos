@ARTICLE{8710277,
  author={Lai, Rong and Qiu, Xiaoyu and Wu, Jiajing},
  journal={IEEE Access}, 
  title={Robustness of Asymmetric Cyber-Physical Power Systems Against Cyber Attacks}, 
  year={2019},
  volume={7},
  number={},
  pages={61342-61352},
  abstract={In this paper, we propose a realistic model to investigate the cascading failure process in a cyber-physical power system (CPPS) which can be topologically modeled as an interdependent system consisting of a power network and a cyber-network. To evaluate the robustness of CPPS against cyber-attacks, we take into consideration the effects of computer malware spreading, power redistribution and overloading, and the interdependency between the coupled networks, and then adopt the stochastic failure model to calculate the time interval between the initial cyber-attack and a given level of power loss. We conduct a critical node analysis on the power network to identify the important buses whose removals are likely to trigger a serious blackout. Based on the results of the critical node analysis, we propose both deterministic and stochastic coupling strategies for an asymmetric CPPS with two subnetworks with unequal sizes, to improve its robustness against both random and intentional cyber-attacks. The simulation results on CPPSs built on IEEE 118 Bus and 300 Bus power systems indicate that the proposed coupling methods can effectively improve the system robustness against cyber-attacks.},
  keywords={Power system faults;Power system protection;Computational modeling;Cyberattack;Robustness;Malware;Cascading failure;complex networks;robustness;cyber physical system;smart grids},
  doi={10.1109/ACCESS.2019.2915927},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7782918,
  author={Larsen, Kasper Green and Nelson, Jelani and Nguyen, Huy L. and Thorup, Mikkel},
  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)}, 
  title={Heavy Hitters via Cluster-Preserving Clustering}, 
  year={2016},
  volume={},
  number={},
  pages={61-70},
  abstract={In the turnstile ℓp heavy hitters problem with parameter ε, one must maintain a high-dimensional vector x ∈ ℝn subject to updates of the form update (i,Δ) causing the change xi ← xi + Δ, where i ε[n], Δ ∈ ℝ. Upon receiving a query, the goal is to report every "heavy hitter" i ∈ [n] with |xi| ≥ ε ∥x∥p as part of a list L ⊆ [n] of size O(1/εp), i.e. proportional to the maximum possible number of heavy hitters. For any pε(0,2] the COUNTSKETCH of [CCFC04] solves ℓp heavy hitters using O(ε-p lg n) words of space with O(lg n) update time, O(n lg n) query time to output L, and whose output after any query is correct with high probability (whp) 1 - 1/poly(n) [JST11, Section 4.4]. This space bound is optimal even in the strict turnstile model [JST11] in which it is promised that xi ≥ 0 for all i ∈ [n] at all points in the stream, but unfortunately the query time is very slow. To remedy this, the work [CM05] proposed the "dyadic trick" for the COUNTMIN sketch for p = 1 in the strict turnstile model, which to maintain whp correctness achieves suboptimal space O(ε-1lg2 n), worse update time O(lg2 n), but much better query time O(ε-1poly(lg n)). An extension to all p ∈ (0,2] appears in [KNPW11, Theorem 1], and can be obtained from [Pag13]. We show that this tradeoff between space and update time versus query time is unnecessary. We provide a new algorithm, EXPANDERSKETCH, which in the most general turnstile model achieves optimal O(ε-plog n) space, O(log n) update time, and fast O(ε-ppoly(log n)) query time, providing correctness whp. In fact, a simpler version of our algorithm for p = 1 in the strict turnstile model answers queries even faster than the "dyadic trick" by roughly a log n factor, dominating it in all regards. Our main innovation is an efficient reduction from the heavy hitters to a clustering problem in which each heavy hitter is encoded as some form of noisy spectral cluster in a much bigger graph, and the goal is to identify every cluster. Since every heavy hitter must be found, correctness requires that every cluster be found. We thus need a "cluster-preserving clustering" algorithm, that partitions the graph into clusters with the promise of not destroying any original cluster. To do this we first apply standard spectral graph partitioning, and then we use some novel combinatorial techniques to modify the cuts obtained so as to make sure that the original clusters are sufficiently preserved. Our cluster-preserving clustering may be of broader interest much beyond heavy hitters.},
  keywords={Clustering algorithms;Computational modeling;Partitioning algorithms;Algorithm design and analysis;Complexity theory;Estimation;heavy hitters;streaming;clustering},
  doi={10.1109/FOCS.2016.16},
  ISSN={0272-5428},
  month={Oct},}@ARTICLE{9366776,
  author={Miikkulainen, Risto and Francon, Olivier and Meyerson, Elliot and Qiu, Xin and Sargent, Darren and Canzani, Elisa and Hodjat, Babak},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={From Prediction to Prescription: Evolutionary Optimization of Nonpharmaceutical Interventions in the COVID-19 Pandemic}, 
  year={2021},
  volume={25},
  number={2},
  pages={386-401},
  abstract={Several models have been developed to predict how the COVID-19 pandemic spreads, and how it could be contained with nonpharmaceutical interventions, such as social distancing restrictions and school and business closures. This article demonstrates how evolutionary AI can be used to facilitate the next step, i.e., determining most effective intervention strategies automatically. Through evolutionary surrogate-assisted prescription, it is possible to generate a large number of candidate strategies and evaluate them with predictive models. In principle, strategies can be customized for different countries and locales, and balance the need to contain the pandemic and the need to minimize their economic impact. Early experiments suggest that workplace and school restrictions are the most important and need to be designed carefully. They also demonstrate that results of lifting restrictions can be unreliable, and suggest creative ways in which restrictions can be implemented softly, e.g., by alternating them over time. As more data becomes available, the approach can be increasingly useful in dealing with COVID-19 as well as possible future pandemics.},
  keywords={Predictive models;Computational modeling;Biological system modeling;Pandemics;Diseases;Optimization;COVID-19;Decision support systems;evolutionary computation;neural networks;neuroevolution;predictive models;prescriptive models;surrogate modeling;uncertainty estimation},
  doi={10.1109/TEVC.2021.3063217},
  ISSN={1941-0026},
  month={April},}@INPROCEEDINGS{7822368,
  author={Padilla, Jose J. and Lynch, Christopher J. and Diallo, Saikou Y. and Gore, Ross J. and Barraco, Anthony and Kavak, Hamdi and Jenkins, Bakari},
  booktitle={2016 Winter Simulation Conference (WSC)}, 
  title={Using simulation games for teaching and learning discrete-event simulation}, 
  year={2016},
  volume={},
  number={},
  pages={3375-3384},
  abstract={Capturing and retaining the attention of students while learning complex topics like modeling and simulation is a critical task. In discrete-event simulation (DES), educators rely on examples like queueing systems in fast food restaurants or manufacturing organizations to provide the necessary context for learning. In many instances, these examples fall short in capturing the attention of students, especially at the middle and high school levels. One approach for learning complex topics, like creating simulations, is through gaming. This paper reports on the creative use of regular simulation tools to develop simulation games with entertainment content aimed towards engaging young learners. Two games are presented: one focuses on the use of decision nodes while the second focuses on the use of batch/separator nodes. As part of future work, we propose to use these games to evaluate how much knowledge transfers from an entertainment context to one using simulations for real-life situations.},
  keywords={Games;Computational modeling;Context;Urban areas;Context modeling;Servers},
  doi={10.1109/WSC.2016.7822368},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{9879110,
  author={Wang, Hanqing and Liang, Wei and Shen, Jianbing and Van Gool, Luc and Wang, Wenguan},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Counterfactual Cycle-Consistent Learning for Instruction Following and Generation in Vision-Language Navigation}, 
  year={2022},
  volume={},
  number={},
  pages={15450-15460},
  abstract={Since the rise of vision-language navigation (VLN), great progress has been made in instruction following - building a follower to navigate environments under the guidance of instructions. However, far less attention has been paid to the inverse task: instruction generation - learning a speaker to generate grounded descriptions for navigation routes. Existing VLN methods train a speaker independently and often treat it as a data augmentation tool to strengthen the follower, while ignoring rich cross-task relations. Here we describe an approach that learns the two tasks simultaneously and exploits their intrinsic correlations to boost the training of each: the follower judges whether the speaker-created instruction explains the original navigation route correctly, and vice versa. Without the need of aligned instruction-path pairs, such cycle-consistent learning scheme is complementary to task-specific training targets defined on labeled data, and can also be applied over unlabeled paths (sampled without paired instructions). Another agent, called creator is added to generate counterfactual environments. It greatly changes current scenes yet leaves novel items - which are vital for the execution of original instructions - unchanged. Thus more informative training scenes are synthesized and the three agents compose a powerful VLN learning system. Extensive experiments on a standard benchmark show that our approach improves the performance of various follower models and produces accurate navigation instructions.},
  keywords={Training;Learning systems;Computer vision;Correlation;Navigation;Computational modeling;Buildings;Vision + language},
  doi={10.1109/CVPR52688.2022.01503},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{8450962,
  author={Uskov, Vladimir and Bakken, Jeffrey P. and Aluri, Lavanya and Rachakonda, Rama and Rayala, Narmada and Uskova, Maria},
  booktitle={2018 IEEE World Engineering Education Conference (EDUNINE)}, 
  title={Smart Pedagogy: Innovative Teaching and Learning Strategies in Engineering Education}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Multiple innovative teaching and learning strategies emerged in the recent years. However, there are no published analysis data and validated outcomes regarding how good those innovative approaches support the main concepts of Smart Education, Smart Classroom and Smart Pedagogy, i.e. their “smartness” levels such as 1) adaptivity, 2) sensing, 3) inferring, 4) anticipation, 5) self-learning, and 6) self-organization. This paper presents the outcomes of the ongoing research, design and development project at the InterLabs Research Institute at Bradley University (IL, U.S.A.) aimed to identify, analyze, test, implement and recommend various components of Smart Pedagogy for Science-Technology-Engineering-Mathematics (STEM) education. The obtained research data and student feedback undoubtedly demonstrate students' keen interest in Smart Pedagogy.},
  keywords={Education;Information systems;Computational modeling;Computer science;Sensor phenomena and characterization;Organizations;Smart pedagogy;STEM;engineering education;smart education;smart university},
  doi={10.1109/EDUNINE.2018.8450962},
  ISSN={},
  month={March},}@ARTICLE{8638845,
  author={De Capitani di Vimercati, Sabrina and Foresti, Sara and Livraga, Giovanni and Piuri, Vincenzo and Samarati, Pierangela},
  journal={IEEE Systems Journal}, 
  title={A Fuzzy-Based Brokering Service for Cloud Plan Selection}, 
  year={2019},
  volume={13},
  number={4},
  pages={4101-4109},
  abstract={The current cloud market features a multitude of cloud services that differ from one another in terms of functionality or of security/performance guarantees. Users wishing to use a cloud service for storing, processing, or sharing their data must be able to select the service that best matches their desiderata. In this paper, we propose a novel, user centric, brokering service for supporting users in the specification of requirements and enabling their evaluation against available cloud plans, assessing how much the different plans can satisfy the user's desiderata. Our brokering service allows users to specify their desiderata in an easy and intuitive way by using natural language expressions and high-level concepts. Fuzzy logic and fuzzy inference systems are adopted to quantitatively assess the compliance of cloud services with the users' desiderata, and hence to help users in the cloud service selection process.},
  keywords={Cloud computing;Linguistics;Throughput;Bandwidth;Fuzzy logic;Computational modeling;Brokering service;cloud computing;cloud service selection;fuzzy inference;fuzzy logic;natural language},
  doi={10.1109/JSYST.2019.2893212},
  ISSN={1937-9234},
  month={Dec},}@INPROCEEDINGS{9611337,
  author={Chaudhuri, Arjun and Chen, Ching-Yuan and Talukdar, Jonti and Madala, Siddarth and Dubey, Abhishek Kumar and Chakrabarty, Krishnendu},
  booktitle={2021 IEEE International Test Conference (ITC)}, 
  title={Efficient Fault-Criticality Analysis for AI Accelerators using a Neural Twin}, 
  year={2021},
  volume={},
  number={},
  pages={73-82},
  abstract={Owing to the inherent fault tolerance of deep neural network (DNN) models used for classification, many structural faults in the processing elements (PEs) of a systolic array-based AI accelerator are functionally benign. Brute-force fault simulation for determining fault criticality is computationally expensive due to many potential fault sites in the accelerator array and the dependence of criticality characterization of PEs on the functional input data. Supervised learning techniques can be used to accurately estimate fault criticality but it requires ground truth for model training. The ground-truth collection involves extensive and computationally expensive fault simulations. We present a framework for analyzing fault criticality with a negligible amount of ground-truth data. We incorporate the gate-level structural and functional information of the PEs in their "neural twins", referred to as "PE-Nets". The PE netlist is translated into a trainable PE-Net, where the standard-cell instances are substituted by their corresponding "Cell-Nets" and the wires translate to neural connections. Each Cell-Net is a pre-trained DNN that models the Boolean-logic behavior of the corresponding standard cell. In the PE-Net, every neural connection is associated with a bias that represents a perturbation in the signal propagated by that connection. We utilize a recently proposed misclassification-driven training algorithm to sensitize and identify biases that are critical to the functioning of the accelerator for a given application workload. The proposed framework achieves up to 100% accuracy in fault-criticality classification in 16-bit and 32-bit PEs by using the criticality knowledge of only 2% of the total faults in a PE.},
  keywords={Training;Computational modeling;Perturbation methods;Wires;Supervised learning;AI accelerators;Systolic arrays},
  doi={10.1109/ITC50571.2021.00015},
  ISSN={2378-2250},
  month={Oct},}@INPROCEEDINGS{1021322,
  author={Walenstein, A.},
  booktitle={Proceedings 10th International Workshop on Program Comprehension}, 
  title={Theory-based analysis of cognitive support in software comprehension tools}, 
  year={2002},
  volume={},
  number={},
  pages={75-84},
  abstract={Past research on software comprehension tools has produced a wealth of lessons in building good tools. However, our explanations of these tools tend to be weakly grounded in existing theories of cognition and human-computer interaction. As a result, the interesting rationales underlying their design are poorly articulated, leaving the lessons primarily implicit. This paper describes a way of using existing program comprehension theories to rationalize tool designs. To illustrate the technique, key design rationales underlying a prominent reverse engineering tool (the Reflexion Model Tool) are reconstructed. The reconstruction shows that theories of cognitive support can be applied to existing cognitive models of software developer behaviour. The method for constructing the rationales is described, and implications are drawn for codifying existing design knowledge, evaluating tools and improving design reasoning.},
  keywords={Software tools;Cognition;Psychology;Reverse engineering;Humans;Cognitive science;Computer science;Buildings;Computational efficiency;Software design},
  doi={10.1109/WPC.2002.1021322},
  ISSN={1092-8138},
  month={June},}@INPROCEEDINGS{1620788,
  author={Nagarajan, R. and Xia Chen and McDonald, R.G. and Burger, D. and Keckler, S.W.},
  booktitle={2006 IEEE International Symposium on Performance Analysis of Systems and Software}, 
  title={Critical path analysis of the TRIPS architecture}, 
  year={2006},
  volume={},
  number={},
  pages={37-47},
  abstract={Fast, accurate, and effective performance analysis is essential for the design of modern processor architectures and improving application performance. Recent trends toward highly concurrent processors make this goal increasingly difficult. Conventional techniques, based on simulators and performance monitors, are ill-equipped to analyze how a plethora of concurrent events interact and how they affect performance. Prior research has shown the utility of critical path analysis in solving this problem. This analysis abstracts the execution of a program with a dependence graph. With simple manipulations on the graph, designers can gain insights into the bottlenecks of a design. This paper extends critical path analysis to understand the performance of a next-generation, high-ILP architecture. The TRIPS architecture introduces new features not present in conventional superscalar architectures. We show how dependence constraints introduced by these features, specifically the execution model and operand communication links, can be modeled with a dependence graph. We describe a new algorithm that tracks critical path information at a fine-grained level and yet can deliver an order of magnitude (30x) improvement in performance over previously proposed techniques. Finally, we provide a breakdown of the critical path for a select set of benchmarks and show an example where we use this information to improve the performance of a heavily-hand-optimized program by as much as 11%.},
  keywords={Performance analysis;Analytical models;Computer architecture;Hardware;Microarchitecture;Abstracts;Laboratories;Process design;Application software;Computational modeling},
  doi={10.1109/ISPASS.2006.1620788},
  ISSN={},
  month={March},}@ARTICLE{8329010,
  author={Redondo, Jose Manuel},
  journal={IEEE Transactions on Education}, 
  title={Improving Student Assessment of a Server Administration Course Promoting Flexibility and Competitiveness}, 
  year={2019},
  volume={62},
  number={1},
  pages={19-26},
  abstract={Contribution: This paper describes a highly flexible design for a master's-level server administration course that uses updated technologies, addresses the most important course design challenges and extracts useful feedback from student work. The main contribution of this design is eliminating the self-regulation challenge students encounter in similar highly flexible computer-related courses. This is attributed to the introduction of orientation lectures and a competitive element; these may have helped students to achieve their goals on time. Background: The Web server administration course on the master's of the Web engineering program was intended to inculcate a series of competences, such as common administration techniques, procedures to increase security, efficient website deployment, and an introduction to clusters and infrastructure deployment automation. The course generally failed to transmit these competencies effectively; complaints were made about the difficulty of the course and the low applicability of its contents. Intended Outcomes: The design facilitates students finding assessment activities that better suit their profiles or previous experience, and enables them to customize their assessment, thus encouraging them and giving future value to their work. Application Design: The course design maximizes assessment flexibility by providing students with many optional activities from which to choose. It also promotes a healthy competitive spirit to improve student's motivation and results. Findings: Complaints about the difficulty or lack of applicability were no longer made. The course is highly valued by the students, achieving a very high pass rate and average score.},
  keywords={Web servers;Security;Computational modeling;Europe;Creativity;Face;Competitivity;computer engineering;course design;flexibility;flipped classroom;master’s students;student assessment},
  doi={10.1109/TE.2018.2816571},
  ISSN={1557-9638},
  month={Feb},}@INPROCEEDINGS{1532840,
  author={Garner, C. and Jin, M. and Gu, X. and Qin, H.},
  booktitle={VIS 05. IEEE Visualization, 2005.}, 
  title={Topology-driven surface mappings with robust feature alignment}, 
  year={2005},
  volume={},
  number={},
  pages={543-550},
  abstract={Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.},
  keywords={Robustness;Topology;Shape;Computer graphics;Solid modeling;Application software;Visualization;Surface texture;Computational geometry;Horses},
  doi={10.1109/VISUAL.2005.1532840},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9438337,
  author={Abcouwer, Neil and Daftry, Shreyansh and del Sesto, Tyler and Toupet, Olivier and Ono, Masahiro and Venkatraman, Siddarth and Lanka, Ravi and Song, Jialin and Yue, Yisong},
  booktitle={2021 IEEE Aerospace Conference (50100)}, 
  title={Machine Learning Based Path Planning for Improved Rover Navigation}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={Enhanced AutoNav (ENav), the baseline surface navigation software for NASA's Perseverance rover, sorts a list of candidate paths for the rover to traverse, then uses the Approximate Clearance Evaluation (ACE) algorithm to evaluate whether the most highly ranked paths are safe. ACE is crucial for maintaining the safety of the rover, but is computationally expensive. If the most promising candidates in the list of paths are all found to be infeasible, ENav must continue to search the list and run time-consuming ACE evaluations until a feasible path is found. In this paper, we present two heuristics that, given a terrain heightmap around the rover, produce cost estimates that more effectively rank the candidate paths before ACE evaluation. The first heuristic uses Sobel operators and convolution to incorporate the cost of traversing high-gradient terrain. The second heuristic uses a machine learning (ML) model to predict areas that will be deemed untraversable by ACE. We used physics simulations to collect training data for the ML model and to run Monte Carlo trials to quantify navigation performance across a variety of terrains with various slopes and rock distributions. Compared to ENav's baseline performance, integrating the heuristics can lead to a significant reduction in ACE evaluations and average computation time per planning cycle, increase path efficiency, and maintain or improve the rate of successful traverses. This strategy of targeting specific bottlenecks with ML while maintaining the original ACE safety checks provides an example of how ML can be infused into planetary science missions and other safety-critical software.},
  keywords={Navigation;Computational modeling;Software algorithms;Training data;Machine learning;Software;Inference algorithms},
  doi={10.1109/AERO50100.2021.9438337},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{8870959,
  author={Valdenegro-Toro, Matias},
  booktitle={2019 European Conference on Mobile Robots (ECMR)}, 
  title={Learning Objectness from Sonar Images for Class-Independent Object Detection}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Detecting novel objects without class information is not trivial, as it is difficult to generalize from a small training set. This is an interesting problem for underwater robotics, as modeling marine objects is inherently more difficult in sonar images, and training data might not be available apriori. Detection proposals algorithms can be used for this purpose but usually requires a large amount of output bounding boxes. In this paper we propose the use of a fully convolutional neural network that regresses an objectness value directly from a Forward-Looking sonar image. By ranking objectness, we can produce high recall (96 %) with only 100 proposals per image. In comparison, EdgeBoxes requires 5000 proposals to achieve a slightly better recall of 97 %, while Selective Search requires 2000 proposals to achieve 95 % recall. We also show that our method outperforms a template matching baseline by a considerable margin, and is able to generalize to completely new objects. We expect that this kind of technique can be used in the field to find lost objects under the sea.},
  keywords={Proposals;Microsoft Windows;Robots;Sonar detection;Training;Computational modeling},
  doi={10.1109/ECMR.2019.8870959},
  ISSN={},
  month={Sep.},}@ARTICLE{10042116,
  author={Singh, Amika M. and Singh, Munindar P.},
  journal={Computer}, 
  title={Wasabi: A Conceptual Model for Trustworthy Artificial Intelligence}, 
  year={2023},
  volume={56},
  number={2},
  pages={20-28},
  abstract={The expansion of artificial intelligence (AI) into our lives and livelihoods makes it clear that we must develop AI to be ethical and trustworthy. We propose Wasabi, a novel conceptual model for trustworthy AI based on an adaptation of the well-known ability–benevolence–integrity model of trust to trustworthiness.},
  keywords={Adaptation models;Ethics;Computational modeling;Artificial intelligence;Trust computing},
  doi={10.1109/MC.2022.3212022},
  ISSN={1558-0814},
  month={Feb},}@INPROCEEDINGS{4591571,
  author={Oyama, Katsunori and Jaygarl, Hojun and Xia, Jinchun and Chang, Carl K. and Takeuchi, Atsushi and Fujimoto, Hiroshi},
  booktitle={2008 32nd Annual IEEE International Computer Software and Applications Conference}, 
  title={A Human-Machine Dimensional Inference Ontology that Weaves Human Intentions and Requirements of Context Awareness Systems}, 
  year={2008},
  volume={},
  number={},
  pages={287-294},
  abstract={Changing system requirements, especially for context awareness (CA) systems, often cause modifications in the software systems in order to adapt to dynamic environments. Since the requirements may become temporarily obsolete or contrary to human intentions, the CA systems need to be tuned to resolve the conflict. On the other hand, most CA design methods rely on pre-defined requirements and reasoning engine, thus, fail to address all the possible situations. Consequently, services provided by such a CA system are limited to accommodate some situations and unable to react as expected. Therefore, it is critical for CA systems to capture exceptions at runtime, infer changed human intentions, and adapt to these changes. This study focuses on inference of ever-changing human intentions and monitoring human intentions to handle system evolution. In this paper, we present an inference mechanism of human intentions via the human-machine dimensional inference ontology (HDIO). This ontology gives inference rules based on the BDI logic to deduce human intentions from contexts. Furthermore, the inference exercises of a healthcare system example shows how user intentions relate to system requirements and how they help improve self-adaptability of CA systems.},
  keywords={Ontologies;Context modeling;Cognition;Computational modeling;Pervasive computing;Computers;Man machine systems;Human Intention;Ontology;Context Awareness;BDI Logic},
  doi={10.1109/COMPSAC.2008.238},
  ISSN={0730-3157},
  month={July},}@ARTICLE{4448425,
  author={Hung, Yen-Chu},
  journal={IEEE Transactions on Education}, 
  title={The Effect of Problem-Solving Instruction on Computer Engineering Majors' Performance in Verilog Programming}, 
  year={2008},
  volume={51},
  number={1},
  pages={131-137},
  abstract={This study investigated the effect of instruction in problem-solving skills on computer engineering majors' performance in programming in the Verilog. Comparisons were made among two treatment groups (deduction and analogy) and a control group, whose pretest and posttest scores were analyzed with the analysis of covariance (ANCOVA) statistical procedure. Results showed that problem-solving skills' instruction significantly increased students' achievement.},
  keywords={Problem-solving;Programming;Computers;Programming profession;Computational modeling;Computer languages;Psychology;Cognition;Analogy;deduction;problem solving;programming;Verilog},
  doi={10.1109/TE.2007.906912},
  ISSN={1557-9638},
  month={Feb},}@INPROCEEDINGS{7967121,
  author={Friese, Ryan D. and Tallent, Nathan R. and Vishnu, Abhinav and Kerbyson, Darren J. and Hoisie, Adolfy},
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Generating Performance Models for Irregular Applications}, 
  year={2017},
  volume={},
  number={},
  pages={317-326},
  abstract={Many applications have irregular behavior - e.g., input-dependent solvers, irregular memory accesses, or unbiased branches - that cannot be captured using today's automated performance modeling techniques. We describe new hierarchical critical path analyses for the Palm model generation tool. To obtain a good tradeoff between model accuracy, generality, and generation cost, we combine static and dynamic analysis. To create a model's outer structure, we capture tasks along representative MPI critical paths. We create a histogram of critical tasks with parameterized task arguments and instance counts. To model each task, we identify hot instruction-level paths and model each path based on data flow, data locality, and microarchitectural constraints. We describe application models that generate accurate predictions for strong scaling when varying CPU speed, cache and memory speed, microarchitecture, and (with supervision) input data class. Our models' errors are usually below 8%; and always below 13%.},
  keywords={Analytical models;Histograms;Data models;Load modeling;Computational modeling;Synchronization;Parallel processing;analytical performance models;model genera- tion;critical path analysis;Palm},
  doi={10.1109/IPDPS.2017.61},
  ISSN={1530-2075},
  month={May},}@INPROCEEDINGS{10201110,
  author={Ravishankar, T. Nadana and Kumar, ATA. Kishore and Venkatesh, J. and Prabhu, M.Ramkumar and Bhargavi, V. Sharmila and MuthamilSelvan.S},
  booktitle={2023 International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)}, 
  title={Empirical Assessment and Detection of Suicide Related Posts in Twitter using Artificial Intelligence enabled Classification Logic}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The identification of suicidal thoughts in online social networks is an expanding field of study fraught with major challenges. Recent studies have shown that the readily available data, dispersed over many online life phases, contains useful clues for accurately identifying persons with suicidal intentions. The primary challenge in preventing suicide is learning to recognize and respond appropriately to the sometimes-confusing risk factors and warning indications that may precipitate an attempt. Indicators useful for diagnosing people with suicide thoughts can be found in publicly available material shared over social media platforms, according to recent studies. Understanding and recognizing the myriad risk factors and warning symptoms that may precede a suicide attempt is the primary difficulty in this area of public health. In this research, we developed a benchmark for multi-class categorization using machine learning models. We used a majority classifier, a frequency-based technique, and two deep learning models as our models. Both deep learning models outperformed the majority and the word frequency classifier, with results that were very comparable. These classification results are on par with the state-of-the-art on similar problems and, in most cases, with human results.},
  keywords={Deep learning;Social networking (online);Computational modeling;Blogs;Support vector machine classification;Learning (artificial intelligence);Benchmark testing;Twitter;Tweets;Suicidal note;Deep Learning Model;Support Vector Machine},
  doi={10.1109/ACCAI58221.2023.10201110},
  ISSN={},
  month={May},}@INPROCEEDINGS{9392692,
  author={Haque, Farsheed and Nur, Ragib Un and Jahan, Shaeekh Al and Mahmud, Zarar and Shah, Faisal Muhammad},
  booktitle={2020 23rd International Conference on Computer and Information Technology (ICCIT)}, 
  title={A Transformer Based Approach To Detect Suicidal Ideation Using Pre-Trained Language Models}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Detection of Suicidal Ideation in social media has gained special attention in recent years. Different mental health issues like depression, frustration, hopelessness etc directly or indirectly influence suicidal thoughts. Early detection of suicidal thoughts can help people to diagnose and get proper treatment in time. Machine Learning and Deep Learning are playing a vital role in this area to automatize Suicidal Ideation detection. In our study, we wanted to take this trend to the next level and proposed a new detection approach with the help of the Transformer models in the language domain. Basically with Transformers we wanted to analyze raw social media posts and classify the indication of suicidal ideation in them. First, we applied BiLSTM(Bidirectional Long Short- Term Memory) and from there took a jump to Transformer models like BERT (Bidirectional Encoder Representations from Transformers), ALBERT, ROBERTa and XLNET - a complete robust Transformer model based study. The main advantage of Transformer models is having pre-trained language models. Because of this, these models usually perform better. We found they work far better than conventional Deep Learning architecture like Bi-LSTM in our work.},
  keywords={Deep learning;Social networking (online);Computational modeling;Bit error rate;Mental health;Linguistics;Depression;Suicidal Ideation;Transformer Model;Deep Learning;Natural Language Processing},
  doi={10.1109/ICCIT51783.2020.9392692},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10343467,
  author={Zastudil, Cynthia and Rogalska, Magdalena and Kapp, Christine and Vaughn, Jennifer and MacNeil, Stephen},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generative AI in Computing Education: Perspectives of Students and Instructors}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.},
  keywords={Codes;Systematics;Computational modeling;Education;Natural languages;Curriculum development;Stakeholders;Generative models;large language models;computing education;student perceptions;instructor perceptions},
  doi={10.1109/FIE58773.2023.10343467},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9273973,
  author={Frezza, Stephen and Clear, Tony and Clear, Alison},
  booktitle={2020 IEEE Frontiers in Education Conference (FIE)}, 
  title={Unpacking Dispositions in the CC2020 Computing Curriculum Overview Report}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Computing Curriculum models have been historically framed from a cognitive perspective. Typically, the focus has been on bodies of knowledge and increasingly the notion of supporting skills and abilities. More recent curriculum documents such as the IT2017 curriculum have moved towards a professional competency approach and have included the further important notion of dispositions.While these dispositions are seen as complementing and supporting the traditional elements of knowledge and skills, exactly how they are conceptualised and operationalised is still being developed. The ACM/IEEE-CS Computing Curriculum 2020 Overview Project (CC2020) has been working towards this goal, in part driven by the very practical purpose of enabling visualisation of the multiple components of the existing and differing curriculum reports, incorporating the notion of dispositions and enabling them to be mapped to clusters of knowledge and skills embodied in selected curriculum statements.This paper reports on progress to date towards conceptualising and operationalising the notion of dispositions within the CC2020 project, reviews the research challenges faced, the models adopted and the findings to date.},
  keywords={Education;Computational modeling;Vocabulary;Task analysis;Security;Computer architecture;Buildings;Competency Modelling;Curriculum Design;CC2020 Computing Curricula;Computing Education;Disposition},
  doi={10.1109/FIE44824.2020.9273973},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6721723,
  author={Saltzman, Robert M. and Roeder, Theresa M.},
  booktitle={2013 Winter Simulations Conference (WSC)}, 
  title={Perspectives on teaching simulation in a college of business}, 
  year={2013},
  volume={},
  number={},
  pages={3620-3629},
  abstract={In this paper, we explore the challenges and opportunities we face teaching computer simulation at a business school. While our students tend not to be as technically savvy as most engineering students, at times limiting the technical complexity of what we can cover in our courses, we are able to use simulation as a tool to analyze and discuss business problems in-depth. We explore the differences both between business and non-business simulation courses, as well as those between our graduate and undergraduate courses.},
  keywords={Computational modeling;Educational institutions;Analytical models;Programming;Proposals},
  doi={10.1109/WSC.2013.6721723},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{7328184,
  author={Wang, Lei and Tang, YuXing and Deng, Yu and Qin, Fangyan and Dou, Qiang and Zhang, Guangda and Zhang, Feipeng},
  booktitle={2015 IEEE 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip}, 
  title={A Scalable and Fast Microprocessor Design Space Exploration Methodology}, 
  year={2015},
  volume={},
  number={},
  pages={33-40},
  abstract={Design space exploration of microprocessor is still a challenging task for processor designers. Due to the huge design space, it is hard to determine the optimal configuration of microarchitecture parameters to satisfy the target performance and power requirements within limited time at the early stage of processor design. In this paper, a Critical Path Analysis directed Design Space Exploration (CPADSE) methodology for design space exploration of microprocessors is proposed. In CPADSE, a dependence graph model is constructed using the profile information generated during the program simulation. Then the critical paths of the dependence graph model are computed and patterns of the critical path are identified. The microarchitecture parameters mostly affecting processor`s performance or other metrics can be identified using the Plackett-Burman design method, which is always referenced as sensitivity analysis. Then the result of critical path analysis and sensitivity analysis is further used to guide the selection of search direction in both SA-CPADSE and TB-CPADSE design space search algorithms, which are proposed in this paper. Experiment result shows that for the design space exploration on SPEC 2000 benchmarks, SA-CPADSE obtains 2x speedup over baseline design space exploration algorithm SA-DSE. Additionally, TB-CPADSE on average obtains 4.3x speedup over SA-CPADSE and 7x speedup over SA-DSE. At the end of this paper, we have a detailed discussion about how to extend CPADSE methodology to design space exploration of multicore processors.},
  keywords={Algorithm design and analysis;Microarchitecture;Space exploration;Computational modeling;Sensitivity analysis;Benchmark testing;Design methodology;Design Space Exploration;Critical Path Analysis;Microprocessor},
  doi={10.1109/MCSoC.2015.30},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{5456947,
  author={Luckenbill, Samuel and Lee, Ju-Yueh and Hu, Yu and Majumdar, Rupak and He, Lei},
  booktitle={2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)}, 
  title={RALF: Reliability Analysis for Logic Faults — An exact algorithm and its applications}, 
  year={2010},
  volume={},
  number={},
  pages={783-788},
  abstract={Reliability analysis for a logic circuit is one of the primary tasks in fault-tolerant logic synthesis. Given a fault model, it quantifies the impact of faults on the full-chip fault rate. We present RALF, an exact algorithm for calculating the reliability of a logic circuit. RALF is based on the compilation of a circuit to deterministic decomposable negation normal form (d-DNNF), a representation for Boolean formulas that can be more succinct than BDDs. Our algorithm can solve a large set of MCNC benchmark circuits within 5 minutes, enabling an optimality study of Monte Carlo simulation, a popular estimation method for reliability analysis, on real benchmark circuits. Our study shows that Monte Carlo simulation with a small set of random vectors generally has a high fidelity for the computation of full-chip fault rates and the criticality of single gates. While we focus on reliability analysis, RALF can also be used to efficiently locate random pattern resistant faults. This can be used to identify where methods other than random simulation should be used for accurate criticality calculations and where to enhance the testability of a circuit.},
  keywords={Algorithm design and analysis;Circuit faults;Logic circuits;Data structures;Boolean functions;Circuit testing;Fault tolerance;Circuit synthesis;Pattern analysis;Computational modeling},
  doi={10.1109/DATE.2010.5456947},
  ISSN={1558-1101},
  month={March},}
