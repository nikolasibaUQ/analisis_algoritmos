@INPROCEEDINGS{6168331,
  author={Goyal, S.B. and Goyal, Aarti and Sharma, Pratima and Singhal, Neha},
  booktitle={2012 Second International Conference on Advanced Computing & Communication Technologies}, 
  title={Analyzing Object Models with Theory of Innovative Solution}, 
  year={2012},
  volume={},
  number={},
  pages={46-50},
  abstract={Object-Oriented Modeling is a modeling paradigm mainly used in computer programming that assists the programmer to address the complexity of a problem domain by considering the problem and reduce the effect on model caused by such problem and make designs more robust, more maintainable, and more reusable. It is a design strategy where system designers think in terms of 'things' instead of operations or functions. Object-Oriented software projects are becoming more popular than structured or functional technology based projects. While Object-Oriented modeling are already arriving in the marketplace but their formal foundations are still under development. Object Technology offers support to deliver products to market more quickly and to provide high quality with lower maintenance costs. Quality Assurance is an important field of software engineering and there is need for good Object-Oriented metrics and models for both process and product. The quality of object-oriented design has a decisive impact on the quality of a software product, but due to the diversity and complexity of design properties like coupling, encapsulation etc their assessment and correlation with external quality attributes like maintenance, portability etc is hard. To address these issues, we will use the innovative solution (TRIZ) to enhance quality with available Object-oriented metrics and affecting factors. TRIZ is a problem-solving, analysis and forecasting tool that is abbreviation of Russian word Teoriya Resheniya Izobretatelskikh Zadatch which typically rendered as the Theory of Inventive Problem Solving. The objective of TRIZ is development of an algorithmic approach to the invention of new systems, and the refinement of existing ones. In this paper we will apply TRIZ to Object-oriented Models to enhance the quality of Object-oriented design. This paper describes a method based on TRIZ principles and tools that can be easily applied to maintain the quality of Object-Oriented based models.},
  keywords={Object oriented modeling;Unified modeling language;Software;Analytical models;Computational modeling;Business;Programming;Database Management System;Innovation Solution;Object-oriented Model;Object Technology;Problem Solving Tool;software Engineering},
  doi={10.1109/ACCT.2012.29},
  ISSN={2327-0659},
  month={Jan},}@INPROCEEDINGS{10403173,
  author={Wu, Renkai and Liang, Pengchen and Huang, Xuan and Yang, Ziyuan and Shi, Liu and Gu, Yuandong and Zhu, Haiqin and Chang, Qing},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)}, 
  title={Automatic Skin Lesion Segmentation Based on Higher-Order Spatial Interaction Model}, 
  year={2023},
  volume={},
  number={},
  pages={447-452},
  abstract={Dermoscopic image segmentation is a key step in computer-aided diagnosis of skin lesions. The current medical image segmentation model mainstream uses standard convolution and Transformers as the most important components of the model. However, standard convolution is unable to handle the problems of remote information interaction and long distance spatial dependence. Transformers is a hindrance to its application when dealing with medical clinical data, the insufficient amount of data and the large memory and time required for computation are hindering factors. Recently, HorNet, a high-order spatial interaction model that performs well in natural scenarios, has drawn our attention because the high-order interaction model has the common advantages of both convolution and Transformers. In this paper, we propose a new system that uses the HorNet model, which performs well in natural scenes, for medical image segmentation (skin lesion segmentation). To the best of our knowledge, we are the first to use a higher-order interaction model for medical image segmentation. We validate our system on three public datasets and do external validation on our own clinical dataset. The experimental results show that our system outperforms other current medical image segmentation models in several metrics. We think this is due to the higher spatial interaction capability and larger perceptual domain of gnconv in HorNet, which can fully and comprehensively capture the information of the overall medical image, which is crucial for medical image processing.},
  keywords={Image segmentation;Convolution;Computational modeling;Transformers;Skin;Lesions;Medical diagnostic imaging;Computer-aided diagnosis;Deep Learning;Higher-order spatial interaction;Skin lesion segmentation;Au-tomatic segmentation},
  doi={10.1109/MedAI59581.2023.00066},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7494248,
  author={Ren Feiyi and Yu Jinsong},
  booktitle={2015 12th IEEE International Conference on Electronic Measurement & Instruments (ICEMI)}, 
  title={Fault diagnosis methods for advanced diagnostics and prognostics testbed (ADAPT): A review}, 
  year={2015},
  volume={01},
  number={},
  pages={175-180},
  abstract={Nowadays in industrial processes, whether producers or users think highly of performance reliability and robustness of equipments. Therefore, the FDI (Fault detection and isolation) and maintenance techniques have become hot topics for health management of industrial units, as a safety guarantee indeed. As a consequence, researchers have made great efforts to develop, verify and refine diverse diagnosis techniques, meanwhile compare and screening them in order to apply them properly in practice. And then, NASA Ames has built the Advanced Diagnostics and Prognostics Testbed, a real-world system as a general platform for verification and validation (V&V) of diagnosis techniques. Until now, many researchers have developed effective diagnosis algorithms specially applied to this system. In this paper, we introduce the ADAPT and the diagnosis competition around the system, and we review a variety of diagnosis methods divided mainly in three types, model-based, optimization-based and artificial intelligence-based methods, while elaborating the first type in detail by two sorts of model: physical and graphic, of which the second attracts more and more attention of scientists in actual research. Finally, we make a comparison among them based on simplified metrics of qualification, which plays an important role in choosing appropriate methods for diagnosing a special problem.},
  keywords={Circuit faults;Adaptation models;Object oriented modeling;Mathematical model;Integrated circuit modeling;Computational modeling;Load modeling;ADAPT;diagnosis method;model-based;optimization-based},
  doi={10.1109/ICEMI.2015.7494248},
  ISSN={},
  month={July},}@ARTICLE{10258164,
  author={Charoenwong, Ben and Kirby, Robert M. and Reiter, Jonathan},
  journal={IEEE Access}, 
  title={Computer Science Abstractions to Help Reason About Decentralized Stablecoin Design}, 
  year={2023},
  volume={11},
  number={},
  pages={103201-103213},
  abstract={Computer science uses abstractions as a tool for reasoning. It is no surprise that computer science might have something valuable to lend to the world of decentralized stablecoin design, as it is a “computing” problem. In this paper, we examine the possibility of a decentralized and capital-efficient stablecoin using smart contracts that algorithmically trade to maintain stability. By exploiting traditional abstractions from computer science, we show that a capital-efficient algorithmic stablecoin cannot be provably stable. Additionally, we provide a formal exposition of the workings of Central Bank Digital Currencies, connecting this framing to the space of possible stablecoin designs. We then discuss several outstanding conjectures from both academics and practitioners and finally highlight the regulatory similarities between money-market funds and working stablecoins. Our work builds upon the current and growing interplay between the realms of engineering and financial services, and it also demonstrates how ways of thinking as a computer scientist can aid practitioners. We believe this research is vital for understanding and developing the future of financial technology.},
  keywords={Computer science;Economics;Currencies;Smart contracts;Stability analysis;Monopoly;Computational modeling;Financial management;Cryptocurrency;Smart contracts;algorithmic stablecoin;financial stability;DeFi;cryptocurrency},
  doi={10.1109/ACCESS.2023.3317891},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10638941,
  author={Yasmin, Sadaf and Mishra, Swati and Islam, Asharul and Hussain, Rashid},
  booktitle={2024 IEEE 7th International Conference on Advanced Technologies, Signal and Image Processing (ATSIP)}, 
  title={A Mobile Cloud Architecture for M-Commerce Business Application’s Execution Performance}, 
  year={2024},
  volume={1},
  number={},
  pages={632-637},
  abstract={Many researchers have come up with different ways to build a business model architecture for efficient services to run m-commerce applications. The framework for developing mobile commerce applications needs to change at the same time as the IT expansion and business transformation. We are pursuing a theoretical business framework to find an optimal solution for the seamless service-oriented m-commerce application performance. In this approach, we identify the components of m -commerce applications that could reduce mobility barriers and improve application execution time and device energy efficiency. This led us to propose a framework for m-commerce application performance that uses the Mobile Cloud Computing (MCC) solutions. This plan focuses on making the application run faster and use less energy, and making it easier for users to move around. We help mobile commerce application developers make smart RDMCA (Resource-Demanding M-commerce Applications) that provide good services for mobile commerce businesses and consumers. A theoretical proposed business framework is being set up to find an optimal solution for service-oriented m -commerce application performance. In this way, we find the important parts of the m -commerce system (signal range determiner) that help make the application run faster, use less energy, and make it easier to move around. We think that improving this framework will help mobile commerce app developers to make RDMCA’s that provide good services for both mobile commerce enterprises and end users.},
  keywords={Performance evaluation;Cloud computing;Energy consumption;Image processing;Computer architecture;Energy efficiency;Computational efficiency;Mobile Cloud Architecture;Business Performance;M-Commerce Resource-Demanding Applications},
  doi={10.1109/ATSIP62566.2024.10638941},
  ISSN={2687-878X},
  month={July},}@INPROCEEDINGS{8858854,
  author={Gupta, Prashant K. and Muhuri, Pranab K.},
  booktitle={2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Linguistic optimization problems: solution methodology using perceptual reasoning}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={A number of real-life scenarios involving decision making may be modelled as optimization problems. In these optimization problems, the human preferences and thinking constrain achieving the optimal value of the problem objective(s). If there is a single objective, then the optimization problems are called single objective optimization problems (SOOPs) else the multi-objective optimization problems (MOOPs). Various solution methodologies have been proposed for SOOPs and MOOPs, which are useful, as long as the SOOPs and MOOPs involve the numeric data. However, the data is generally in linguistic form (or words), when elicited by the human beings. Therefore, the SOOPs and MOOPs are referred as single objective linguistic optimization problems (SOLOPs) and multiobjective linguistic optimization problems (MOLOPs), respectively, in such situations, to emphasize the existence of linguistic information in optimization problems. In these LOPs, the value of the objective function(s) may not be known at all points of the decision space, and therefore, the objective function(s) as well as problem constraints are linked through if- then rules. Previously, the Tsukamoto's inference method was used to solve these types of LOPs; however, it suffers from drawbacks. As, the use of linguistic information inevitably calls for the utilization of computing with words (CWW), hence, in this paper, we discuss the solution methodologies for LOPs based on the perceptual reasoning (PR). PR is a novel CWW engine design for the CWW approach of perceptual computing. We also demonstrate the applicability of PR based solution methodology for LOPs to the case study of car purchase modelled as LOP.},
  keywords={Linguistics;Optimization;Linear programming;Firing;Cognition;Computational modeling;Fuzzy sets;Computing with words;Interval type 2 fuzzy sets;Linguistic optimization problems;Perceptual reasoning.},
  doi={10.1109/FUZZ-IEEE.2019.8858854},
  ISSN={1558-4739},
  month={June},}@INPROCEEDINGS{5326389,
  author={Zhu, Feng and Carpenter, Sandra and Kulkarni, Ajinkya and Chidambaram, Chockalingam and Pathak, Shruti},
  booktitle={2009 6th Annual International Mobile and Ubiquitous Systems: Networking & Services, MobiQuitous}, 
  title={Understanding and minimizing identity exposure in ubiquitous computing environments}, 
  year={2009},
  volume={},
  number={},
  pages={1-10},
  abstract={Various miniaturized computing devices that store our identities are emerging rapidly. They allow our identity information to be easily exposed and accessed via wireless networks. When identity information is associated with our personal and context information that is gathered by ubiquitous computing devices, personal privacy might be unprecedentedly sacrificed. People, however, have different privacy protection skills, awareness, and privacy preferences. Individuals can be uniquely identified on the basis of only a few identity elements used in combination. To the best of our knowledge, this is the first study to understand the following issues and their relations: a) what identity elements people think are important; b) what actions people claim to take to protect their identities and privacy; c) privacy concerns; d) how people expose their identities in ubiquitous computing environments; and e) how our rational identity exposure model can help to minimize identity exposure. We build a simulated ubiquitous computing shopping system, called InfoSource. It consists of two applications and our rational identity exposure model. We present our experiments and statistical analysis results. Our data show that exposure decisions depend on participants' attitudes about maintaining privacy, but they do not depend on participants' concerns and claimed actions related to identity exposure. Our RationalExposure model helped participants to minimize unnecessary exposures.},
  keywords={Ubiquitous computing;Protection;Pervasive computing;Data privacy;Wireless networks;Game theory;Internet;Computational modeling;Statistical analysis;Identity management systems;game theory;identity management;privacy;ubiqitous computing},
  doi={10.4108/ICST.MOBIQUITOUS2009.6853},
  ISSN={},
  month={July},}@INPROCEEDINGS{8265113,
  author={Liu, Qingwei and Han, Ming and Feng, Ling},
  booktitle={2017 13th International Conference on Semantics, Knowledge and Grids (SKG)}, 
  title={Dynamic Sale Prediction of the Time-Sensitive Products Based on Conformity}, 
  year={2017},
  volume={},
  number={},
  pages={90-97},
  abstract={In these years, many online shopping and investment becomes more time-sensitive such as crowdfunding, online auction, time-limit sale and group buying. Most of them have deadlines. Consequently, people need to make faster decisions than other products leading to more conformity in this area. Though there is much work about the conformity and social influence in social networks, there lacks work of conformity in the online shopping and investment, because in these scenarios there is usually no such "strong" connection. However, we think the conformity information is also important for the sale prediction of time-sensitive products, since conformity impacts people's purchase decisions. In this paper, we propose a model which captures the dynamic conformity and apply it to the similarity computation and sale prediction of time-sensitive products. It can be dynamically adjusted to fit the target product and the prediction moment, which means it is well self-adaptive. Since it also gives the consideration to other static and latent features in a collaborative way, it alleviates the "cold start" problem nicely and is free from the presetting hypotheses. Experiments on the real large-scale dataset shows that our method exceeds other comparison methods by 33.2% in the sale prediction.},
  keywords={Market research;Investment;Predictive models;Adaptation models;Social network services;Computational modeling;Collaboration;Conformity;sales prediction;time sensitive;Machine learning},
  doi={10.1109/SKG.2017.00023},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10257974,
  author={Zhu, Chang and Luo, Xizi and Liu, Yuxuan},
  booktitle={2023 IEEE International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Data Mining Study of Wordle Based on Multi-Model Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={979-984},
  abstract={As a game that spreads across the Internet and stimulates people to think and learn, data mining of Wordle's report counts and their distribution is particularly important. In this paper, an ARIMA model and a BP neural network model based on the WOA are developed to perform in-depth data mining on Wordle. For model I, this paper uses ARIMA model fitting to fit the trend of the total number of historical report results over time, and obtains the R2 of the model as 0.986. Based on this, this paper establishes a prediction model for the interval of the total number of reports, and gives the prediction interval of the total number of report results on March 1, 2023 as [21211], [21814]. For Model II, this paper defines word attributes as the following four indicators: for example, the commonness of the word, the number of occurrences of the same letter in the word. The Spearman correlation coefficient between the percentage of reported scores to the total reported scores in the Hard mode and the word attributes was calculated. Finally, in the Hard model, the percentage of reported scores out of the total reported scores was significantly correlated with how common the word was and whether it began with a vowel letter. For Model III, this paper constructed a BP Neural network model based on WOA, which, in this paper, uses word attributes as the input layer and the report distribution of words as the output layer. In the WOA, the optimal weights and thresholds of the BP neural network are obtained in this paper by continuous search and approximation. The final model has a Mean Absolute Error value of 0.38, both of which have good performance. At the same time, this paper predicts the results of “EERIE”, and the obtained distribution results are rounded to [1], [7], [20], [22], [21], [19], [10]. Through the above modelling and calculation, this paper mines Wordle's user data, which has some theoretical significance for the healthy development of Wordle.},
  keywords={Computational modeling;Image processing;Neural networks;Fitting;Games;Predictive models;Market research;Wordle;number of reports;ARIMA;word attributes;BP Neural network model},
  doi={10.1109/ICIPCA59209.2023.10257974},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{6089119,
  author={Shiah, Dah-Ming and Hung, Chin-Tun and Huang, Kuang-Hua},
  booktitle={2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)}, 
  title={Using voronoi grouping to solve set covering problem - Building an Integrated Delivering System for Taichung City}, 
  year={2011},
  volume={},
  number={},
  pages={268-273},
  abstract={The traditional set covering models did not consider the equity of users that carried by each set. We developed a new method to solve that for the Integrated Delivering System (IDS) in medical service in Taichung city. This method requires grouping the clinics in equal market share in a way that satisfy the equity conditions given. It uses Voronoi blocks as market share for each clinic within the study area and calculates the house and clinic ratios as the equity conditions. For each scan, the selected block merges with one of the adjacent blocks using five conditions with different weights. This process continues until the objective functions are met. This model opens up a new way of thinking for set covering by grouping the block objects to obtain optimal result. The result is workable and can be reproduced by computer program if the same data set existed.},
  keywords={Mathematical model;Cities and towns;Computational modeling;Urban areas;Hospitals;Pattern recognition;set covering;geography information system;IDS;spatial analysis},
  doi={10.1109/SoCPaR.2011.6089119},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6597794,
  author={Vlachonasiou, Eleni},
  booktitle={2013 9th International Conference on Intelligent Environments}, 
  title={Digital Techniques of Representation and Theoretical Discourse: From Folded Space to Intelligent Architectural Environments}, 
  year={2013},
  volume={},
  number={},
  pages={77-83},
  abstract={The adoption of digital techniques of representation in the 21st century has often been associated with a lack of theory in architecture. This paper attempts to trace changes in architectural thinking between two different periods, to address issues of theory in architecture and to find links between these changes and the singularities of digital techniques of representation.},
  keywords={Computer architecture;Media;Artificial intelligence;Production;Proposals;History;Computational modeling;Representation;technique;digital design;emergence;intelligence},
  doi={10.1109/IE.2013.28},
  ISSN={},
  month={July},}@INPROCEEDINGS{5479642,
  author={Powell, Steven R.},
  booktitle={2010 Wireless Telecommunications Symposium (WTS)}, 
  title={Wireless telecommunications in Latin America: A comparison of the market portfolios of America Movil and Telefonica}, 
  year={2010},
  volume={},
  number={},
  pages={1-11},
  abstract={With the growth of their Latin American mobile telecommunications markets slowing, regulatory pressures intensifying, and new entrants worsening an already unfavorable competitive environment, and in order to capitalize on the opportunity to increase revenues by providing new wireless data and video services to subscribers, Telefonica and America Movil management have begun to restructure their companies and re-think their internationalization strategies. This paper focuses on the two companies' Latin American market portfolios in 2008, comparing the portfolios with respect to the attractiveness of their markets and the companies' competitive positions in them, and how they changed from 2002 to 2008. The degrees of market attractiveness and competitive strength the portfolios possessed, as well as their variability across the markets in the portfolios, are considered. The portfolio analysis technique employed in the paper may have wider applicability for formulating corporate strategy.},
  keywords={Portfolios;Telecommunication control;Costs;Europe;Computational Intelligence Society;Environmental management;Government;Investments;Regulators;Proportional control},
  doi={10.1109/WTS.2010.5479642},
  ISSN={1934-5070},
  month={April},}@INPROCEEDINGS{10650485,
  author={Li, Gang and Zhang, Cheng and Han, Delong and Gao, Letian and Zhou, Mingle},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Gradient-YOLO: Exploring the integration of gradient architecture into the YOLO network}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Object detection is an essential task in the field of computer vision. The one-stage object detection model directly completes object detection through a single forward propagation and has fast real-time object detection capabilities, making it widely used—especially the model of the You Only Look Once (YOLO) series. Improving the detection accuracy of the YOLO model has always been a research topic. The gradient architecture cascades feature information extraction and aggregates all features at the end, which can improve the feature fusion ability of the network. Combining the idea of gradient architecture, this paper proposes a YOLO based on gradient architecture: Gradient-YOLO. Specifically, this paper integrates gradient architecture into the backbone, neck, and bottleneck structures in the YOLO network, obtaining gradient backbone, gradient neck, and gradient bottleneck, respectively. By combining gradient architecture, various network parts in Gradient-YOLO can fully aggregate multi-layer features, reduce feature loss, and thus improve detection accuracy. This paper takes the mature YOLOv5 model and the latest YOLOv8 model as the baseline and combines gradient thinking to obtain Gradient-YOLOv5 and GradientYOLOv8. Moreover, conduct experimental testing on the MS COCO dataset. Regarding the mAP@.5 detection indicator, compared to YOLOv5s, Gradient-YOLOv5s increased by 5.07%. Compared to YOLOv8n, Gradient-YOLOv8n has increased by 4.63%. Therefore, the combination of gradient architecture can improve the detection accuracy of YOLO networks.},
  keywords={YOLO;Accuracy;Aggregates;Computational modeling;Computer architecture;Feature extraction;Real-time systems;Object detection;Gradient architecture;YOLO;Feature fusion},
  doi={10.1109/IJCNN60899.2024.10650485},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{8377691,
  author={Chen, Tsung Teng and Lee, Maria R.},
  booktitle={2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)}, 
  title={Deciphering Big Data Research Themes}, 
  year={2018},
  volume={01},
  number={},
  pages={432-437},
  abstract={Big Data is a relatively novel research field that has attracted high interest from the industry and academia for its wide applicability. Numerous definitions of Big Data have been given by scholars from different perspectives. We think the Big Data research field could be better appreciated by analyzing the relevant scientific articles published over the years. However, the sheer volume of the Big Data related literature needs a more efficient way to analyze them. As such, we utilize the knowledge domain analysis techniques developed by information scientists to build the intellectual structure and uncover the main research themes, which afford us a holistic view of the overall Big Data research field. Based on our analysis, the research themes of Big Data may be classified into four main categories: the first one deals with the technologies and architectures aspect of Big Data; the second one relates to the prospective applications of the Big Data analytics; the third one covers levels of parallelism in the Big Data processing stacks; the rest encompasses mostly machine learning related studies and some miscellaneous topics that may benefit from the Big Data processing capabilities.},
  keywords={Big Data;Computer architecture;Loading;Parallel processing;Computational modeling;NIST;Analytical models;Big Data, citation analysis, intellectual structure},
  doi={10.1109/COMPSAC.2018.00066},
  ISSN={0730-3157},
  month={July},}@INPROCEEDINGS{10499013,
  author={Gautam, Mayank and Ahuja, Sachin and Kumar, Abhishek},
  booktitle={2024 11th International Conference on Computing for Sustainable Global Development (INDIACom)}, 
  title={Intrusion Detection Techniques in Internet of Things: A Bird’s Eye View}, 
  year={2024},
  volume={},
  number={},
  pages={622-628},
  abstract={With many gaps and shortcomings in the field of IoT security, no matter how simple you think it is on your side what goes inside an intrusion detection system technique to detect attacks. This study explores the current state of IDS in IoT. The most important points of vulnerability are identified, and we examine ways to address them immediately. One key finding of the research is that interoperability problems between differing IoT devices and platforms loom as two big roadblocks. Besides, the lack of standardized evaluation standards or sets for intrusion detection models in IoT environments turns out to be an important gap between what is being researched currently and reality. The ambiguity of how to upscale in large IoT networks is cited as an issue left unresolved by the study. In addition, it points toward the crucial role intrusion detection plays in safeguarding IoT systems and also reveals existing areas of weakness with regard to adaptability, scalability and standardization..},
  keywords={Adaptation models;Scalability;Computational modeling;Intrusion detection;Internet of Things;Security;Standards;IoT security;intrusion detection systems (IDS) Research gaps;adaptability;scalability standardization},
  doi={10.23919/INDIACom61295.2024.10499013},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{6759121,
  author={Schrödl, Holger and Simkin, Paulina},
  booktitle={2014 47th Hawaii International Conference on System Sciences}, 
  title={Greening the Service Selection in Cloud Computing: The Case of Federated ERP Solutions}, 
  year={2014},
  volume={},
  number={},
  pages={4200-4209},
  abstract={The increasing industrial acceptance of cloud-based IT services has led to a paradigm shift in the development and operation of complex business applications. IT managers are incorporating cloud-based IT services as replacements and/or as enhancements for existing on-site solutions. This strategy leads to the concept of a federated business application, which consists of a variety of on-site and cloud-based subparts, dynamically orchestrated to a single solution. In this setting, the selection of appropriate IT services is critical. Following the discussions of environmental thinking in IT aspects like Green IT and Green IS, the issue of appropriate IT service depends on not only functionality and costs, but additionally also on the environmental impact of the service selection. To address this issue, this paper presents a service selection model for cloud-based services with a focus on the environmental aspects of the selection process. This is done by modeling a multi-criteria decision model based on the rational choice theory. The proposed model provides a selection process which leads to maximal service functionality coverage with minimal environmental impact for a given service provider setting. The application of the model is illustrated in a typical industry case.},
  keywords={Green products;Cloud computing;Computational modeling;Companies;Biological system modeling;Cloud Computing;Green IS;Service Selection;Federated ERP},
  doi={10.1109/HICSS.2014.519},
  ISSN={1530-1605},
  month={Jan},}@INPROCEEDINGS{10442827,
  author={Vashist, Ansh and Jain, Tarun and Sharma, Vijay Shankar},
  booktitle={2023 3rd International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)}, 
  title={Directed Machine Learning Approaches for Determining Alzheimer Disease}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Alzheimer's is a neurogenic disease which progress into neurological disorder that primarily affects cognitive function and memory. It's a Neurodegenerative (ND) disease, characterized by the gradual deterioration of cognitive function, memory, thinking, and behaviour. There are two most common diseases among neurodegenerative diseases: (a) Alzheimer's Disease and (b) Parkinson's Disease. We used 12 classifiers on the given dataset on UC Irvine Machine Learning Repository. The machine learning algorithms were engaged to identify Alzheimer Disease. Our research results showed that the XGB Model is the one that shows the best accuracy, of 100%, of all the 12 classifiers.},
  keywords={Support vector machines;Parkinson's disease;Computational modeling;Alzheimer's disease;Regression tree analysis;Random forests;Diseases;Alzheimer's;Disease Detection;Machine Learning;Classification;Logistic Regression;Binary Decision Tree Model;Random Forest;SGD Model;XG Boost Model;AdaBoost Model;ANN Model;Ensemble Voting Model;Gaussian Naive Baye Model;Complement Naive Baye Model;Multinomial Naive Baye Model},
  doi={10.1109/SMARTGENCON60755.2023.10442827},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9197911,
  author={Rajput, Aditi and Jain, Madhuri},
  booktitle={2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={A Multi Criteria Integrated Dynamic Futuristic Group Decision Making Model for Implementation of Intelligent Transportation System in India}, 
  year={2020},
  volume={},
  number={},
  pages={1038-1043},
  abstract={In this paper, a totally new Multi-criteria Integrated Dynamic Futuristic Group Decision Making (MIDFGDM) model is developed for implementation of Intelligent Transportation System in megacities of India by the year 2025 AD. The developed model is a non-linear structure which analyzes inductive and deductive iterative dynamic futuristic thinking for allowing the consideration of generated multi futuristic decision parameters at a time. The crucial scenarios and effective action plan are generated by computing Global Futuristic Judgment (GFJ) Weights from the developed model. Any real world societal and managerial problem can be solved by using the developed model.},
  keywords={Vehicle dynamics;Transportation;Decision making;Monitoring;Computational modeling;Information systems;Intelligent Transportation System;Multi Criteria Decision Making;Traffic Congestion;Global Futuristic Judgment Weights;Scenarios.},
  doi={10.1109/ICRITO48877.2020.9197911},
  ISSN={},
  month={June},}@INPROCEEDINGS{10515330,
  author={Somanathan Pillai, Sanjaikanth E Vadakkethil and Vallabhaneni, Rohith and Pareek, Piyush Kumar and Dontu, Sravanthi},
  booktitle={2024 International Conference on Distributed Computing and Optimization Techniques (ICDCOT)}, 
  title={Financial Fraudulent Detection using Vortex Search Algorithm based Efficient 1DCNN Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Repeated loan fraud threatens financial stability and drives away clients. Financial and banking institutions must immediately recognize network fraud. The banking sector in India and other countries is using AI-driven technology and machine learning algorithms to tackle fraud and unauthorized access. Innovative thinking, increased globalization, and technical developments are raising fraud detection costs. The suggested study would help banks identify credit application fraudsters. The study automated data preprocessing using Kaggle's K-Nearest Neighbor (KNN) algorithm. A one-dimensional convolutional neural network classified. Using the Vortex Search Algorithm (VSA) to fine-tune the classifier hyperparameters improved results. VSA determined the model's hyperparameter sweet spot. The suggested model outperforms other categorization methods with 98.62% accuracy. Better lending banking fraud detection may result from the proposed approach. The VSA-based 1DCNN model detects fraud faster and more precisely.},
  keywords={Machine learning algorithms;Computational modeling;Banking;Trademarks;Stability analysis;Fraud;Classification algorithms;Fraudulent Detection;Convolution Neural Network;Vortex Search Algorithm;Financial Fraudulent},
  doi={10.1109/ICDCOT61034.2024.10515330},
  ISSN={},
  month={March},}@INPROCEEDINGS{10090213,
  author={Wu, Haoyu and Lin, Zhibin and Lin, Borong and Li, Zhenhao and Jin, Nanlin and Zhu, Xiaohui},
  booktitle={2022 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)}, 
  title={Deep Learning To Model The Complexity Of Algal Bloom}, 
  year={2022},
  volume={},
  number={},
  pages={114-122},
  abstract={Literature of studying algal growth has started to take advantages of data mining and machine learning methods, such as classification, clustering, regression, correlation analysis and principal component analysis. However, the performance of such methods might heavily rely on the data collectable for the studies sites. Moreover, some factors directly relate to algal growth, including hydrodynamics, weather and ecology, are notoriously difficult to model and predict. In this paper we present a study to model algal bloom using deep learning methods. It is assumed that algal bloom is the consequence of all factors that are more or less associated with the growth of algal. This offers a new way of thinking that even unknown factors or those factors far too complicated to model can still be inexplicitly represented by the deep learning models. We evaluate this new approach through our studies of algal bloom in the JinJi Lake, Suzhou, China. The experimental results are compared with the popular machine learning methods used in literature. It has been found that the deep learning method can achieve a better accuracy in comparison with other well applied machine learning methods.},
  keywords={Deep learning;Biological system modeling;Computational modeling;Ecosystems;Predictive models;Data models;Sensors;Machine Learning;Deep Learning;Data mining;Regression;Decision Tree;Green-blue algae},
  doi={10.1109/CyberC55534.2022.00027},
  ISSN={2833-8898},
  month={Oct},}@INPROCEEDINGS{10616950,
  author={G, Sathi and Varshney, Neeraj and Sharma, Praveen and Punitha, B.Jasmine and Sundar, R. and SubbaRao, S P V},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={A Development of Cloud Based Robotics Design Networks for Industry Applications}, 
  year={2024},
  volume={},
  number={},
  pages={320-325},
  abstract={In modern robots, the usage of computationally expensive models involving deep neural networks, also referred to as DNNs, for tasks such as the localization of operations awareness, planning, and object recognition is becoming prominent. Nevertheless, resource-constrained machinery, such as low-power aerial vehicles, often lack the requisite internal computing resources to easily run cutting-edge simulations of neural networks. Cloud robotics appears as an answer, allowing robots to offload processing to centralized computers for greater precision models. Nonetheless, the ignored downside of cloud robots lies in the possible delay and data loss experienced during contact over crowded wireless networks. This study discusses the Robot Transferring responsibility Problem, exploring when and where robots should offload sense tasks that improve accuracy while reducing the costs involved with cloud communication. The method involves framing shifting as a sequence decision-making issue concerning robots and suggesting a remedy using sophisticated reinforcement learning. Through models and hardware tests employing advanced thinking DNNs, what was suggested sharing strategy improves vision task efficacy by 1.3 2.6 times as a result of standard strategies, allowing robots to increase their sense accuracy while incurring minimal communication via cloud costs.},
  keywords={Computers;Costs;Accuracy;Service robots;Computational modeling;Reinforcement learning;Robot sensing systems;cloud robotics;deep neural networks;Robot Transferring responsibility Problem;network congestion;cloud communication costs;Markov Decision Process;reinforcement learning;Advantage-2 Actor-Critic method;LIDAR data offloading expenses},
  doi={10.1109/ICACITE60783.2024.10616950},
  ISSN={},
  month={May},}@INPROCEEDINGS{10442800,
  author={Nieto-Chaupis, Huber},
  booktitle={2023 International Conference on Electrical, Communication and Computer Engineering (ICECCE)}, 
  title={Can artificial intelligence do the job of a theoretical physicist?}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={If Artificial Intelligence is powerful, then it would cover a wide spectrum of jobs that commonly is done by humans that might require a high level of abstraction and mathematical creation. In this paper, the possibility that Machine Learning through the criteria of Mitchell can produce original contribution at basic sciences, such for example at the theoretical physics, is investigated. Basically, it is shown that theoretical physics is essentially based in laws by which are employed mathematical apparatus based at differential equations, integrations, commutators of operators, closed-form algebra, etc. In this way, the Mitchell criteria might constitute an algorithm to generate new theoretical structures in physics. It is investigated if it is appropriate to claim that Artificial Intelligence is able to replace the human thinking to create new theoretical physics with relevance and with a solid prospectiveness.},
  keywords={Computational modeling;Large Hadron Collider;Machine learning;Solids;Mathematical models;Data models;Physics;Artificial Intelligence;Machine Learning;Algorithms},
  doi={10.1109/ICECCE61019.2023.10442800},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{6362974,
  author={Berg, Celina and Erickson, Josh and Kiemele, Liam and Schröter, Adrian and Gulliver, Aaron and Coady, Yvonne and Hoeberechts, Maia and de Grasse, Claire},
  booktitle={2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={PREDICT: Parallel Resources for Early Detection of Immediate Causes of Tsunamis}, 
  year={2012},
  volume={},
  number={},
  pages={234-240},
  abstract={In this paper we propose a re-thinking of ICT infrastructure to include a framework that exploits commodity many-core systems to evaluate models. The framework permits comparison, evaluation and improvement of competing and complementary models. Our proposal focuses on the computationally intensive tasks associated with near-field parallelism to process environmental conditions in real-time to deliver informed warnings to populations at risk. By keeping a human-in-the-loop, we include new services that support crowd-sourcing within the framework, allowing integration of sensor data with media-rich voluntary participant input. Monte Carlo simulations of relevant ocean models highlight necessary precursors and likelihoods of potential threats. This paper provides a survey of existing systems, both from tsunami modeling and other domains with similar real-time constraints, and evaluates the applicability of our proposed framework, PREDICT, for near-field tsunami early warning.},
  keywords={Tsunami;Computational modeling;Mathematical model;Monte Carlo methods;Propagation;Real-time systems;Graphics processing units;tsunami warning;real-time;scalable},
  doi={10.1109/3PGCIC.2012.57},
  ISSN={},
  month={Nov},}@ARTICLE{9818939,
  author={Bardram, Jakob E.},
  journal={IEEE Pervasive Computing}, 
  title={From Sensing to Acting—Can Pervasive Computing Change the World?}, 
  year={2022},
  volume={21},
  number={3},
  pages={17-23},
  abstract={Computing technology has indeed become pervasive. Taking a quick look around me, I see computing systems in literally everything—in the cars, televisions, smartphones, restaurants, ski-lifts, heating systems, sports trackers, medical devices, etc. This has been realized by a tremendous development in hardware and software technology in terms of CPUs, memory, sensors, operating systems, network, display, etc. However, looking back at this technology development—and the research done in the field—it strikes me that something is missing. One of the grand visions was to make the computer “invisible,” as framed by Weiser. But it seems like instead of computing becoming more invisible, it is taking up more of the user’s attention. In this article, I argue that this is because (pervasive) computing has only come halfway. Much effort has been done in terms of sensing and understanding the world around the user, while much less effort has been put into helping the user actually doing anything. By providing examples mostly taken from the medical domain, this article discusses if moving from “sensing” and “thinking” to actually “doing” something is possible and what challenges are associated with this movement.},
  keywords={Sensors;Pervasive computing;Actuators;Robot sensing systems;Computational modeling;Artificial intelligence},
  doi={10.1109/MPRV.2022.3182489},
  ISSN={1558-2590},
  month={July},}@INPROCEEDINGS{10578742,
  author={Hammer, Sabine and Ottinger, Sarah and Zönnchen, Benedikt and Hohendanner, Michel and Hobelsberger, Martin and Thurner, Veronika},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in Higher Education: Perceptions of Computer Science-Related Students}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={In the field of education ChatGPT has sparked both admiration and controversy. This study explores students' perspectives, specifically focusing on those in computer science-related fields. We investigated their motivations, trust, perceptions of utility, and reliability of ChatGPT by conducting two surveys-one at the beginning and another at the end of the semester. During the semester, students were encouraged to engage with ChatGPT. Our findings highlight the tool's multifaceted use in an academic settings, establishing it as a valuable resource for a variety of learning tasks. Most students have incorporated ChatGPT into their regular academic activities and view it as a beneficial aid. They perceive it as a multi-task solver and anticipate significant advancements in its writing assistance features in the near future. Many, not only attribute high accuracy to it but think that it adheres to appropriate content and structural norms. Our results suggest that active confrontation with ChatGPT enhances understanding of its capabilities, limitations and autoregressive nature. Consequently, we recommend an approach of informed engagement that includes the distinction between language processing and genuine language understanding and a carefully crafted terminology.},
  keywords={Accuracy;Terminology;Computational modeling;Focusing;Writing;Chatbots;Multitasking;ChatGPT;large language models;higher education;educational technology},
  doi={10.1109/EDUCON60312.2024.10578742},
  ISSN={2165-9567},
  month={May},}
