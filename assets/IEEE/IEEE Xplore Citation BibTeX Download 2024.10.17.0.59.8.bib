@ARTICLE{6425442,
  author={Erdman, Arthur G. and Keefe, Daniel F. and Schiestl, Randall},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Grand Challenge: Applying Regulatory Science and Big Data to Improve Medical Device Innovation}, 
  year={2013},
  volume={60},
  number={3},
  pages={700-706},
  abstract={Understanding how proposed medical devices will interface with humans is a major challenge that impacts both the design of innovative new devices and approval and regulation of existing devices. Today, designing and manufacturing medical devices requires extensive and expensive product cycles. Bench tests and other preliminary analyses are used to understand the range of anatomical conditions, and animal and clinical trials are used to understand the impact of design decisions upon actual device success. Unfortunately, some scenarios are impossible to replicate on the bench, and competitive pressures often accelerate initiation of animal trials without sufficient understanding of parameter selections. We believe that these limitations can be overcome through advancements in data-driven and simulation-based medical device design and manufacturing, a research topic that draws upon and combines emerging work in the areas of Regulatory Science and Big Data. We propose a cross-disciplinary grand challenge to develop and holistically apply new thinking and techniques in these areas to medical devices in order to improve and accelerate medical device innovation.},
  keywords={Computational modeling;Data visualization;Humans;Data models;Information management;Data handling;Data storage systems;Big data;medical devices;modeling and simulation;regulatory science;virtual reality;visualization},
  doi={10.1109/TBME.2013.2244600},
  ISSN={1558-2531},
  month={March},}@INPROCEEDINGS{7424189,
  author={Smaradottir, Berglind Fjola and Martinez, Santiago and Holen-Rabbersvik, Elisabeth and Fensli, Rune},
  booktitle={2015 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={eHealth-Extended Care Coordination: Development of a Collaborative System for Inter-municipal Dementia Teams: A Research Project with a User-Centered Design Approach}, 
  year={2015},
  volume={},
  number={},
  pages={749-753},
  abstract={In Norway, a health reform was recently adopted to improve continuity of care. Services that were carried out in hospitals were transferred to municipalities. Small and medium size municipalities have established inter-municipal cooperation to provide specialized services across borders. The research project eHealth-extended Care Coordination studied the inter-municipal cooperation for assessment of dementia, identifying a need for improved communication and coordination. This paper presents the development process of a collaborative information system for dementia assessment using a user-centered design approach. Mixed methods, such as observations, semi-structured interviews and questionnaire, were used for data collection. The results showed that end-user involvement usefully informed the development. The information system effectively supported collaborative work and shared access to information for the inter-municipal team.},
  keywords={Dementia;Usability;Information systems;Collaboration;Interviews;Conferences;User-centered Design;Usability;Inter-municipal Cooperation;Dementia Assessment;Health Information System},
  doi={10.1109/CSCI.2015.79},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{236673,
  author={Malevsky, A.V. and Yuen, D.A. and Jordan, K.E.},
  booktitle={Supercomputing '92:Proceedings of the 1992 ACM/IEEE Conference on Supercomputing}, 
  title={Simulation of particle mixing by turbulent convective flows on the Connection Machine}, 
  year={1992},
  volume={},
  number={},
  pages={294-300},
  abstract={Mixing of particles by chaotic flow fields was simulated on the Connection Machine. Each cell was assigned to the processor, and the coordinates of particles residing on the cell were kept in the local memory of the processor. This approach implies the exchange between the local memories, when a particle moves from one cell to another. Approximately 10/sup 5/ particles were injected into a time-dependent flow field obtained by solving the nonlinear system of partial differential equations describing turbulent thermal convection. The flow field was calculated on a CRAY, and data were transferred to a CM-200 through a high-speed HIPPI channel.<>},
  keywords={Computational modeling;Supercomputers;Finite element methods;Lagrangian functions;High performance computing;Chaos;Nonlinear systems;Parallel programming;Finite difference methods;Nearest neighbor searches},
  doi={10.1109/SUPERC.1992.236673},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8560946,
  author={Herbert, Nicole},
  booktitle={2017 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={An Assessment Scheme for Short-Term Placements}, 
  year={2017},
  volume={},
  number={},
  pages={1067-1072},
  abstract={Industry placements have been lauded as providing benefits to students, industry and academia. While semester-long placements that require a break from study are reported as the most effective, not all students want to extend their course. Short-term placements can also have positive outcomes for student employability, industry skilled-worker supply and enhancement of curriculum. Assessment of student performance though is challenging, as their focus during the placement needs to be on completing tasks for a sponsor. This paper is a case study of a successful short-term placement program used to identify the important factors and components of an assessment scheme for a short-term placement.},
  keywords={Placements;WIL;Internship;Assessment;Authentic Learning},
  doi={10.1109/CSCI.2017.186},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10590542,
  author={Bessas, Nikos and Tzanaki, Eleni and Vavougios, Dionisios and Plagianakos, Vassilis P.},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Implementing AI in Physics Lessons in the High School}, 
  year={2023},
  volume={},
  number={},
  pages={1775-1779},
  abstract={ChatGPT is a relatively recent application, free to the general public, released at the end of November 2022 and rooted in artificial intelligence. The educational community is still debating how such an application could be used in the teaching and learning area, with the facilities it offers and the risks it entails. The purpose of this paper is to present how such an application responds to physics topics at the high school level, and to suggest ways to use it properly. In order to cover the issue comprehensively, it is approached from both the teacher's and the student's point of view.},
  keywords={Ethics;Data privacy;Scientific computing;Education;Learning (artificial intelligence);Chatbots;Task analysis;Artificial Intelligence;ChatGPT;Physics;Education;Teaching;Learning},
  doi={10.1109/CSCI62032.2023.00293},
  ISSN={2769-5654},
  month={Dec},}@ARTICLE{9387490,
  author={Granger, Brian E. and Pérez, Fernando},
  journal={Computing in Science & Engineering}, 
  title={Jupyter: Thinking and Storytelling With Code and Data}, 
  year={2021},
  volume={23},
  number={2},
  pages={7-14},
  abstract={Project Jupyter is an open-source project for interactive computing widely used in data science, machine learning, and scientific computing. We argue that even though Jupyter helps users perform complex, technical work, Jupyter itself solves problems that are fundamentally human in nature. Namely, Jupyter helps humans to think and tell stories with code and data. We illustrate this by describing three dimensions of Jupyter: 1) interactive computing; 2) computational narratives; and 3) the idea that Jupyter is more than software. We illustrate the impact of these dimensions on a community of practice in earth and climate science.},
  keywords={Open source software;Scientific computing;Machine learning;Data science;Open source software;Meteorology},
  doi={10.1109/MCSE.2021.3059263},
  ISSN={1558-366X},
  month={March},}@ARTICLE{5386178,
  author={van der Aalst, W.M.P.},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Process Discovery: Capturing the Invisible}, 
  year={2010},
  volume={5},
  number={1},
  pages={28-41},
  abstract={Processes are everywhere. Organizations have business processes to manufacture products, provide services, purchase goods, handle applications, etc. Also in our daily lives we are involved in a variety of processes, for example when we use our car or when we book a trip via the Internet. Although such operational processes are omnipresent, they are at the same time intangible. Unlike a product or a piece of data, processes are less concrete because of their dynamic nature. However, more and more information about these processes is captured in the form of event logs. Contemporary systems ranging from copiers and medical devices to enterprise information systems and cloud infrastructures record events. These events can be used to make processes visible. Using process mining techniques it is possible to discover processes. This provides the insights necessary to manage, control, and improve processes. Process mining has been successfully applied in a variety of domains ranging from healthcare and e-business to high-tech systems and auditing. Despite these successes, there are still many challenges as process discovery shows that the real processes are more "spaghetti-like" than people like to think. It is still very difficult to capture the complex reality in a suitable model. Given the nature of these challenges, techniques originating from Computational Intelligence may assist in the discovery of complex processes.},
  keywords={Manufacturing processes;Books;Internet;Concrete;Management information systems;Clouds;Medical control systems;Process control;Medical services;Computational intelligence},
  doi={10.1109/MCI.2009.935307},
  ISSN={1556-6048},
  month={Feb},}@ARTICLE{8896008,
  author={Chalk, Cameron and Kornerup, Niels and Reeves, Wyatt and Soloveichik, David},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={Composable Rate-Independent Computation in Continuous Chemical Reaction Networks}, 
  year={2021},
  volume={18},
  number={1},
  pages={250-260},
  abstract={Biological regulatory networks depend upon chemical interactions to process information. Engineering such molecular computing systems is a major challenge for synthetic biology and related fields. The chemical reaction network (CRN) model idealizes chemical interactions, allowing rigorous reasoning about the computational power of chemical kinetics. Here we focus on function computation with CRNs, where we think of the initial concentrations of some species as the input and the equilibrium concentration of another species as the output. Specifically, we are concerned with CRNs that are rate-independent (the computation must be correct independent of the reaction rate law) and composable ($f\circ g$f∘g can be computed by concatenating the CRNs computing $f$f and $g$g). Rate independence and composability are important engineering desiderata, permitting implementations that violate mass-action kinetics, or even “well-mixedness”, and allowing the systematic construction of complex computation via modular design. We show that to construct composable rate-independent CRNs, it is necessary and sufficient to ensure that the output species of a module is not a reactant in any reaction within the module. We then exactly characterize the functions computable by such CRNs as superadditive, positive-continuous, and piecewise rational linear. Thus composability severely limits rate-independent computation unless more sophisticated input/output encodings are used.},
  keywords={Chemicals;Biological system modeling;Computational modeling;Biological information theory;Synthetic biology;Kinetic theory;Encoding},
  doi={10.1109/TCBB.2019.2952836},
  ISSN={1557-9964},
  month={Jan},}@ARTICLE{6633027,
  author={Sun, Changhao and Duan, Haibin and Shi, Yuhui},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Optimal Satellite Formation Reconfiguration Based on Closed-Loop Brain Storm Optimization}, 
  year={2013},
  volume={8},
  number={4},
  pages={39-51},
  abstract={In recent years, satellite formation flying has become an increasingly hot topic for both the astronomy and earth science communities due to its potential merits compared with a single monolithic spacecraft system. This paper proposes a novel approach based on closed-loop brain storm optimization (CLBSO) algorithms to address the optimal formation reconfiguration of multiple satellites using two-impulse control. The optimal satellite formation reconfiguration is formulated as an optimization problem with the constraints of overall fuel cost minimization, final configuration, and collision avoidance. Three versions of CLBSOs are developed by replacing the creating operator in basic brain storm optimization (BSO) with closed-loop strategies, which facilitate search characteristic capture and enhance the optimization performance by taking advantage of feedback information in the search process. Numerical simulations are carried out using particle swarm optimization (PSO), basic BSO, and the three versions of CLBSOs. Comparison results show that all versions of CLBSOs outperform PSO and the original BSO in terms of final results and convergence speed. In addition, CLBSO reduces the computation burden and shortens CPU time to a certain extent in contrast with basic BSO. Furthermore, among the three CLBSO algorithms, the one using the strategy of difference with the best gains the best overall performance, which is inspired by the updating rule in PSO that each particle tends to move towards the individual with the best fitness.},
  keywords={Satellites;Optimization;Orbits;Space vehicles;Space missions;Closed loop systems},
  doi={10.1109/MCI.2013.2279560},
  ISSN={1556-6048},
  month={Nov},}@ARTICLE{4274794,
  author={Perlovsky, Leonid I.},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Evolution of Languages, Consciousness and Cultures}, 
  year={2007},
  volume={2},
  number={3},
  pages={25-39},
  abstract={The knowledge instinct is a fundamental mechanism of the mind that drives evolution of higher cognitive functions. Neural modeling fields and dynamic logic describe it mathematically and relate to language, concepts, emotions, and behavior. Perception and cognition, consciousness and unconsciousness, are described, while overcoming past mathematical difficulties of modeling intelligence. The two main aspects of the knowledge instinct determining evolution are differentiation and synthesis. Differentiation proceeds from and unconscious states to more crisp and conscious, from less knowledge to more knowledge; it separates concepts from emotions, Its main mechanism is language. Synthesis strives to achieve unity and meaning of knowledge; it is necessary for resolving contradictions, concentrating will and for purposeful actions. Synthesis connects language and cognition. Its main mechanisms are emotionality of languages and the hierarchy of the mind. Differentiation and synthesis are in complex relationship of symbiosis and opposition. This Leads to complex dynamics of evolution of consciousness and languages. Its mathematical modeling predicts evolution of cultures. We discuss existing evidence and future research directions.},
  keywords={Cognition;Mathematical model;Cultural differences;Humans;Logic;Competitive intelligence;Symbiosis;Educational institutions;Earth;Military computing},
  doi={10.1109/MCI.2007.385364},
  ISSN={1556-6048},
  month={Aug},}@INPROCEEDINGS{4630611,
  author={Grana, Manuel},
  booktitle={2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)}, 
  title={A brief review of lattice computing}, 
  year={2008},
  volume={},
  number={},
  pages={1777-1781},
  abstract={Defining lattice computing as the class of algorithms that either apply lattice operators inf and sup or use lattice theory to produce generalizations or fusions of previous approaches, we find that a host of algorithms for data processing, classification, signal filtering, have been produced over the last decades. We give a fast and brief review, which by no means could be exhaustive; with the aim of showing that this area has been growing during the past decades and to highlight the ones that we think are broad avenues for future research. Although our emphasis is on Artificial Neural Networks and Fuzzy Systems in this review we include Mathematical Morphology as a notorious instance of Lattice Computing.},
  keywords={Lattices;Artificial neural networks;Conferences;Fuzzy systems;Associative memory;Joints;Classification algorithms},
  doi={10.1109/FUZZY.2008.4630611},
  ISSN={1098-7584},
  month={June},}@INPROCEEDINGS{7850033,
  author={Woźniak, Marcin and Połap, Dawid},
  booktitle={2016 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={On manipulation of initial population search space in heuristic algorithm through the use of parallel processing approach}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Increasing use of heuristic algorithms in various fields of science causes numerous modifications of the original algorithms in need for better performance and efficiency. The main problem of heuristics is time required to find optimal solution. For this purpose, we propose to use parallel processing in the initial phase of heuristic methods to decrease computing time. Implemented technique models migration of individuals by adjusting initial population to required conditions. Proposed approach is simulating parallel processes that take place in human brain while solving tasks. In this case, human intelligence is working parallel on various aspects of the problem to compare them in the end before final decision. Proposed approach is simulating this parallelization of thinking threads in the process of optimization. Presented experimental tests have been carried out and discussed in terms of advantages and disadvantages.},
  keywords={Whales;Sociology;Statistics;Optimization;Heuristic algorithms;Mathematical model;Parallel processing},
  doi={10.1109/SSCI.2016.7850033},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10361797,
  author={Geng, Yanjun},
  booktitle={2023 International Conference on Electronics and Devices, Computational Science (ICEDCS)}, 
  title={Construction of Intelligent Financial Management Platform Based on Hierarchical Inheritance Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={663-668},
  abstract={The Hierarchical Inheritance Algorithm (HGA) is an optimization technique inspired by biological principles of natural selection and heredity. This approach is versatile, finding applications in fields such as combinatorial optimization, machine learning, adaptive control, and more. It stands as a cornerstone in the realm of intelligent computing. This study bridges the gap between information technology and progressive management methodologies, aiming to adapt outdated financial management strategies to the demands of a digitalized environment, thereby pioneering a centralized financial management paradigm in the digital realm. The focus of this paper is to explore this digitally-centered financial management framework and propose a design tailored to the online ecosystem. Our findings indicate that the concept of smart finance goes beyond a mere blend of "AI and finance." Implementing its technologies involves a unique methodology that thrives on "closed-loop thinking." By gleaning insights from AI applications in diverse sectors, we've outlined the foundational pillars of smart finance application: digital transformation of specialized financial operations, algorithms rooted in financial logic that are fine-tuned through iterations, the fusion of data analytics within financial operations leading to product-centric solutions, and achieving a significant 90.00% platform integration for these smart financial solutions. As artificial intelligence technology continues to evolve, financial management will undoubtedly gravitate towards being instantaneous, user-centric, and intelligent. This will usher in heightened efficiency and benefits, heralding a new age in financial management.},
  keywords={Visualization;Machine learning algorithms;Scientific computing;Neural networks;Ecosystems;Finance;Machine learning;hierarchical inheritance algorithm;Intelligent financial management platform},
  doi={10.1109/ICEDCS60513.2023.00128},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{6803219,
  author={Khandan, Hamed and Ono, Kenji},
  booktitle={2014 IEEE World Forum on Internet of Things (WF-IoT)}, 
  title={Knowledge request-broker architecture: A possible foundation for a resource-constrained dynamic and autonomous global system}, 
  year={2014},
  volume={},
  number={},
  pages={506-507},
  abstract={Significant gap between software programming model and execution model is one major slowing factor in the development of the emerging field of Internet-of-Things. It is also one of the main reasons why software systems often lag behind hardware technologies and fail to capture the full potentials of modern day hardware infrastructure, which is mostly parallel and distributed. We need to change the way we think about software fundamentally, and make it, at its most basic level, to work like the physical world works: distributed, parallel, loosely connected, and asynchronous. KnoRBA achieves this by making the basic components of any program, such as a common word processor, to be asynchronous mobile agents. Then through provision of implementation and location transparency it establishes integration across a distributed environment. This extended abstract is an early introduction to the new revision of KnoRBA that makes it efficient in a domain like sensor networks where power and bandwidth are critical factors.},
  keywords={Servers;Computer architecture;Programming;Hardware;Computational modeling;Software systems;Internet of Things;Ambient Intelligence;Distributed Software Systems;Low Energy Devices;Software Architecture;Multi-agent Systems;Knowledge Request-Broker Architecture},
  doi={10.1109/WF-IoT.2014.6803219},
  ISSN={},
  month={March},}@INPROCEEDINGS{825318,
  author={Chang, M.S. and Kobayashi, I. and Sugeno, M.},
  booktitle={IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)}, 
  title={Development of a travel consultation system based on exchange of meaning}, 
  year={1999},
  volume={2},
  number={},
  pages={540-545 vol.2},
  abstract={Human activity naturally contains ambiguities and contradictions that cannot be solved mathematically or logically. We think that human intelligence is closely related to the use of language. Therefore, in order to achieve intelligent computing as human beings do, we need to realize the architecture in which language is used as an information medium on a computer. In this paper we study on the development of a travel consultation system based on the above architecture as an example of information processing in intelligent computing, and show how language functions in information processing.},
  keywords={Natural languages;Humans;Information processing;Context;Competitive intelligence;Computer architecture;Computational intelligence;Information analysis;Computer science;Social factors},
  doi={10.1109/ICSMC.1999.825318},
  ISSN={1062-922X},
  month={Oct},}@ARTICLE{9490241,
  author={Tedre, Matti and Toivonen, Tapani and Kahila, Juho and Vartiainen, Henriikka and Valtonen, Teemu and Jormanainen, Ilkka and Pears, Arnold},
  journal={IEEE Access}, 
  title={Teaching Machine Learning in K–12 Classroom: Pedagogical and Technological Trajectories for Artificial Intelligence Education}, 
  year={2021},
  volume={9},
  number={},
  pages={110558-110572},
  abstract={Over the past decades, numerous practical applications of machine learning techniques have shown the potential of AI-driven and data-driven approaches in a large number of computing fields. Machine learning is increasingly included in computing curricula in higher education, and a quickly growing number of initiatives are expanding it in K-12 computing education, too. As machine learning enters K-12 computing education, understanding how intuition and agency in the context of such systems is developed becomes a key research area. But as schools and teachers are already struggling with integrating traditional computational thinking and traditional artificial intelligence into school curricula, understanding the challenges behind teaching machine learning in K-12 is an even more daunting challenge for computing education research. Despite the central position of machine learning and AI in the field of modern computing, the computing education research body of literature contains remarkably few studies of how people learn to train, test, improve, and deploy machine learning systems. This is especially true of the K-12 curriculum space. This article charts the emerging trajectories in educational practice, theory, and technology related to teaching machine learning in K-12 education. The article situates the existing work in the context of computing education in general, and describes some differences that K-12 computing educators should take into account when facing this challenge. The article focuses on key aspects of the paradigm shift that will be required in order to successfully integrate machine learning into the broader K-12 computing curricula. A crucial step is abandoning the belief that rule-based “traditional” programming is a central aspect and building block in developing next generation computational thinking.},
  keywords={Education;Machine learning;Programming profession;Automation;Task analysis;Terminology;Technological innovation;Machine learning;artificial intelligence;K-12;school;computing education;computational thinking;pedagogy},
  doi={10.1109/ACCESS.2021.3097962},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10184658,
  author={Guo, Shengnan and Lin, Youfang and Gong, Letian and Wang, Chenyu and Zhou, Zeyu and Shen, Zekai and Huang, Yiheng and Wan, Huaiyu},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)}, 
  title={Self-Supervised Spatial-Temporal Bottleneck Attentive Network for Efficient Long-term Traffic Forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={1585-1596},
  abstract={In intelligent transportation systems, accurate long-term traffic forecasting is informative for administrators and travelers to make wise decisions in advance. Recently proposed spatial-temporal forecasting models perform well for short-term traffic forecasting, but two challenges hinder their applications for long-term forecasting in practice. Firstly, existing traffic forecasting models do not have satisfactory scalability on effectiveness and efficiency, i.e., as the prediction time spans extend, existing models either cannot capture the long-term spatial-temporal dynamics of traffic data or equip global receptive fields at the cost of quadratic computational complexity. Secondly, the dilemma between the models’ strong appetite for high-quality training data and their generalization ability is also a challenge we have to face. Thus how to improve data utilization efficiency deserves thoughtful thinking. Aiming at solving the long-term traffic forecasting problem and facilitating the deployment of traffic forecasting models in practice, this paper proposes an efficient and effective Self-supervised Spatial-Temporal Bottleneck Attentive Network (SSTBAN). Specifically, SSTBAN follows a multi-task framework by incorporating a self-supervised learner to produce robust latent representations for historical traffic data, so as to improve its generalization performance and robustness for forecasting. Besides, we design a spatial-temporal bottleneck attention mechanism, reducing the computational complexity meanwhile encoding global spatial-temporal dynamics. Extensive experiments on real-world long-term traffic forecasting tasks, including traffic speed forecasting and traffic flow forecasting under nine scenarios, demonstrate that SSTBAN not only achieves the overall best performance but also has good computation efficiency and data utilization efficiency.},
  keywords={Computational modeling;Training data;Predictive models;Data models;Robustness;Computational efficiency;Forecasting;traffic forecasting;spatial-temporal graph data;self-supervised learning},
  doi={10.1109/ICDE55515.2023.00125},
  ISSN={2375-026X},
  month={April},}@ARTICLE{10571575,
  author={Bari, Salman and Wang, Xiagong and Schoha Haidari, Ahmad and Wollherr, Dirk},
  journal={IEEE Open Journal of Intelligent Transportation Systems}, 
  title={Factor Graph-Based Planning as Inference for Autonomous Vehicle Racing}, 
  year={2024},
  volume={5},
  number={},
  pages={380-392},
  abstract={Factor graph, as a bipartite graphical model, offers a structured representation by revealing local connections among graph nodes. This study explores the utilization of factor graphs in modeling the autonomous racecar planning problem, presenting an alternate perspective to the traditional optimizationbased formulation. We model the planning problem as a probabilistic inference over a factor graph, with factor nodes capturing the joint distribution of motion objectives. By leveraging the duality between optimization and inference, a fast solution to the maximum a posteriori estimation of the factor graph is obtained via least-squares optimization. The localized design thinking inherent in this formulation ensures that motion objectives depend on a small subset of variables. We exploit the locality feature of the factor graph structure to integrate the minimum curvature path and local planning computations into a unified algorithm. This diverges from the conventional separation of global and local planning modules, where curvature minimization occurs at the global level. The evaluation of the proposed framework demonstrated superior performance for cumulative curvature and average speed across the racetrack. Furthermore, the results highlight the computational efficiency of our approach. While acknowledging the structural design advantages and computational efficiency of the proposed methodology, we also address its limitations and outline potential directions for future research.},
  keywords={Planning;Optimization;Computational efficiency;Computational modeling;Probabilistic logic;Minimization;Collision avoidance;Motion planning;autonomous racing vehicles;probabilistic inference;factor graph;model predictive control},
  doi={10.1109/OJITS.2024.3418956},
  ISSN={2687-7813},
  month={},}@INPROCEEDINGS{10441858,
  author={Feng, Siqi and Shi, Jinfeng and Zhang, Rui and Wang, Yuyang and Chen, Fan and Wang, Xu},
  booktitle={2023 IEEE International Conference on Electrical, Automation and Computer Engineering (ICEACE)}, 
  title={Optimization of Credit Score Card Portfolio Based on QUBO Model with Quantum Annealing Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={1187-1195},
  abstract={With the progress of science and technology, quantum computing plays an increasingly important role in various fields, solving the traditional arithmetic bottleneck. In the financial field, credit scoring is the core of the lending industry and one of the most common risk management tools. Researchers are trying to find the best threshold-setting scheme to maximize revenue through quantum computing. This approach not only solves the optimization problem in the field of credit score cards, but also provides a new way of thinking about optimization problems in other fields. In this paper, three traditional computational models, one-fold credit card strategy, two-fold credit card combination strategy, and three-fold credit card combination strategy, are proposed, and the credit score card scheme that maximizes the final revenue is solved for each of the three models. The results show that under the one-fold credit card strategy, the final income is maximized at $54,087.2; under the two-fold credit card combination strategy, the final income is maximized at $41,106.3; and under the three-fold credit card combination strategy, the final income is maximized at $27,914.8. Secondly, this paper converts these three strategies to the QUBO model and obtains the maximum final income that is consistent with the maximum under the traditional model, with an accuracy of 96.3%, 92.7%, and 89.9% for the three combination strategies, respectively.},
  keywords={Analytical models;Computational modeling;Credit cards;Quantum annealing;Risk management;Optimization;Portfolios;Quantum computing;Credit scoring;Computational model;QUBO model},
  doi={10.1109/ICEACE60673.2023.10441858},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9105248,
  author={Boesl, Dominik},
  booktitle={2019 IEEE 19th International Symposium on Computational Intelligence and Informatics and 7th IEEE International Conference on Recent Achievements in Mechatronics, Automation, Computer Sciences and Robotics (CINTI-MACRo)}, 
  title={Disruption Cannot be Planned! On Robotics, Automation, Flying Cars and Smart Digital Solutions: PLENARY PAPER}, 
  year={2019},
  volume={},
  number={},
  pages={000111-000112},
  abstract={Is robotics, automation, digitalization, artificial intelligence or any of the current buzzwords really going to disrupt our world? Prof. Dominik Boesl thinks so – in fact, it can even been proven! In order to predict technological breakthroughs, the domains of foresight, future studies and technology assessment offer interesting methods. One of the most know might be the analysis of megatrends. Dominik Boesl is researching the future of robotics, automation and AI and their impact on society out of HDBW (Hochschule der Bayerischen Wirtschaft) in Munich. He is convinced, that our grandchildren will grow up as first Generation R of Robotic Natives – leaving us the last generation of Robotic Immigrants (still with analogue migration background, but …). These future generations will not be afraid of robotics and smart systems permeating their living realm. But technology is never good or bad out of itself – it depends on us how we apply it. The bigger the disruption, the larger the responsibility that comes with it. As chair of the global IEEE TechEthics initiative, Dominik fosters educated discourse about the application of technology and its impact on society and humankind. He is founder and chairman of the Robotic & AI Governance Foundation, pushing for governance structures to (self-)regulate the research, development and productization of automation technologies.},
  keywords={Robots;Automation;Artificial intelligence;Automobiles;Mechatronics;Informatics;Computational intelligence},
  doi={10.1109/CINTI-MACRo49179.2019.9105248},
  ISSN={2471-9269},
  month={Nov},}@INPROCEEDINGS{6381073,
  author={Sowah, Robert A. and Mills, Godfrey A. and Bremang, Appah and Armoo, Stephen K.},
  booktitle={2012 IEEE 4th International Conference on Adaptive Science & Technology (ICAST)}, 
  title={Integrating MATLAB/Simulink technical computing environment into engineering education pedagogy in Ghanaian Universities: — A case study for University of Ghana, Computer Engineering Department}, 
  year={2012},
  volume={},
  number={},
  pages={92-97},
  abstract={In this paper we proposed a joint model of simultaneous instruction with laboratory sessions to reinforce and enrich the learning experience so as to train better engineers able to compete globally. In accomplishing this, we integrated MATLAB/Simulink, the de facto standard for technical computing into the university curriculum for teaching four Computer Engineering courses namely Numerical Methods, Signals and Systems, Digital Control Systems and Digital Signal Processing during the 2010/2011 academic year at the University of Ghana. The course modules were developed in consultation with others and taught over the period of 13 weeks. The semester examinations consisted of laboratory and written exams sessions of three hours duration. After grading and collating of examinations results, it was clearly demonstrated by students that they have learnt the key requirements in engineering education. The statistics was staggering and interesting; for example 90 students registered the Numerical Methods, one withdrew due to ill-health and 89 students passed the seemingly difficult course with good grades.},
  keywords={Decision support systems;Conferences;Nonlinear dynamical systems;brain research;computational science;lecture labs;educational pedagogy},
  doi={10.1109/ICASTech.2012.6381073},
  ISSN={2326-9448},
  month={Oct},}@INPROCEEDINGS{9178698,
  author={Zou, Sheng-rong and Shu, Yu-dan and Chen, Li and Shi, Xu-qing},
  booktitle={2020 5th International Conference on Computational Intelligence and Applications (ICCIA)}, 
  title={Refinement of the Cytokine Portion of the Immune System Based on Event-B}, 
  year={2020},
  volume={},
  number={},
  pages={145-149},
  abstract={The Event-B method is a kind of formal software development method, which is mainly used for the functional requirements of the system modeling and validation.The immune system is a large abstract model with high complexity.This paper adopts a new way of thinking,by studying the relationship between immune cytokines and immune cells,the interaction between cells and cytokines in the process of immunity was further explored.At the same time, based on Rodin platform, the formal method Event-B method was adopted, and the top-down strategy was used to refine and verify the immune system model layer by layer.The ideological method of Event-B specification verification was used to solve the problem of high error rate and low efficiency caused by non-formalization in the traditional software design process.},
  keywords={Immune system;Context modeling;Computational modeling;Cells (biology);Presses;Software;Biological system modeling;event-B;immune system;formal verification},
  doi={10.1109/ICCIA49625.2020.00035},
  ISSN={},
  month={June},}@ARTICLE{4580541,
  author={Resnyansky, Lucy},
  journal={IEEE Intelligent Systems}, 
  title={Social Modeling as an Interdisciplinary Research Practice}, 
  year={2008},
  volume={23},
  number={4},
  pages={20-27},
  abstract={Social modeling applies computational methods and techniques to the analysis of social processes and human behavior. It's expected to provide conceptual and technological tools for supporting analysis and decision making in areas related to national and public security, political stability, law and order, and sociocultural changes. Modeling social and cultural processes must draw on the knowledge obtained within social sciences, including conceptual models, cultural insights, and empirical data. However, how to best integrate social scientific knowledge into modeling remains an open research problem. The author presents the perspective of a social scientist to describe why modeling can be useful for social research on political violence, social conflicts, and cultural changes. She develops an interactionist approach to interdisciplinary research practice and discusses how this approach can help identify the problems related to the integration of social scientific knowledge in modeling. The discussion focuses upon research on political violence and related sociocultural processes.},
  keywords={Ontologies;Cultural differences;Lenses;Equations;Context modeling;Computational modeling;Humans;Decision making;Data security;National security;simulation;sociology},
  doi={10.1109/MIS.2008.72},
  ISSN={1941-1294},
  month={July},}@INPROCEEDINGS{9740932,
  author={Kavitha, T. and Hemalatha, S. and Saravanan, T.M. and Singh, Aashu Kumar and Alam, Mohamad Imtiyaj and Warshi, Shahbaz},
  booktitle={2022 International Conference on Computer Communication and Informatics (ICCCI)}, 
  title={Survey on Cloud Computing Security and Scheduling}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={The purpose of this study is to look at Cloud Computing Security. The term “cloud computing” refers to a way of delivering services over the internet. As a network service, computing resources are made available. These services are cost-effective, scalable, and self-contained. Cloud computing is responsible for the IT industry's rapid growth. Despite its many benefits, it has a number of security concerns that must be addressed. In order to make Cloud Computing even more secure and trustworthy, some efforts must be made against the model's hazards. All of the risks linked with Cloud Computing, as well as potential cures, are evaluated in this paper. Various resources like as memory, software, CPU, and network services are offered on-demand via the internet in cloud computing. Because all resources such as hardware, software, and network are used without physically purchasing them, the company's primary investment in the cloud is retained. Many advances are being implemented in the cloud platform to deliver a better experience for cloud users.},
  keywords={Cloud computing;Job shop scheduling;Processor scheduling;Cloud computing security;Service computing;Computer architecture;Side-channel attacks;Cloud computing;security threats;challenges;scheduling are all terms that come to mind when thinking about cloud computing},
  doi={10.1109/ICCCI54379.2022.9740932},
  ISSN={2329-7190},
  month={Jan},}@INPROCEEDINGS{10389248,
  author={Akinyemi, Lateef Adesola and Oshinuga, Olamide Peter and Eshilokun, Oluwafikunmi Adegbenga and Oladejo, Sunday Oladayo and Ekwe, Stephen Obono},
  booktitle={2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)}, 
  title={Development of Phylum Chordata Sound Recognition System using Machine Learning and Deep Learning Techniques: A Case Study of Catfish}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Sound recognition refers to the technology or process of identifying and classifying different sounds or audio signals. This study aims to develop a sound recognition system using machine learning (ML) and deep learning (DL) techniques to classify and identify the gender of catfish based on their speech patterns. The study explores a range of supervised ML and DL algorithms, such as the Artificial Neural Network (ANN), Naïve Bayes (NB), and others, to predict the gender of catfish. The extracted features from the audio signals of the catfish serve as inputs to these algorithms, which produce binary predictions classifying the catfish samples as either male or female. This study further explores data analysis of the audio signals from the male and female catfish. The automated sound recognition system proves to be a more efficient and accurate approach compared to traditional methods, which rely on time-consuming visual observations. Evaluation metrics such as Accuracy, Sensitivity, and more, were employed to gauge the effectiveness of the algorithms in predicting the gender of catfish based on speech patterns. Among the employed algorithms, ANN and NB demonstrate the highest accuracy, achieving a score of 89.47%.},
  keywords={Deep learning;Machine learning algorithms;Artificial neural networks;Prediction algorithms;Feature extraction;Classification algorithms;Sound recognition;Sound Recognition;Deep Learning;Machine Learning Audio Data Analysis;Catfish;Gender Prediction},
  doi={10.1109/ICECET58911.2023.10389248},
  ISSN={},
  month={Nov},}
