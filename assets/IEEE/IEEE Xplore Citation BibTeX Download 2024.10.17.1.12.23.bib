@INPROCEEDINGS{9735116,
  author={Al-Momani, Mohammad M. and Odienate, Abdullah and Algharaibeh, Seba F. and Awasa, Khaled and Radaideh, Omar},
  booktitle={2022 Advances in Science and Engineering Technology International Conferences (ASET)}, 
  title={Modified Connectivity Matrix Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Connectivity Matrix Algorithm (CMA) is a straightforward algorithm presented to obtain the optimal location of the PMUs in any system. This paper proposed a modification to the connectivity matrix algorithm (MCMA) to consider n-1 criteria. The modified algorithm is valid to get the optimal PMU placement thinking of any level of redundancy in the measurements at any location. The modified algorithm is validated by considering zero injection bus (ZIB) and without for the double redundancy condition. The algorithm applies to different size test systems: IEEE-14 bus, IEEE-30 bus, IEEE 57-bus, and IEEE-118 bus. The computational time of the MCMA is less than 10% of the fastest algorithm in the literature.},
  keywords={Measurement units;Redundancy;Area measurement;Phasor measurement units;Time measurement;connectivity matrix algorithm (CMA);phasor measuring unit (PMU);optimal PMU placement (OPP);zero injection bus (ZIB)},
  doi={10.1109/ASET53988.2022.9735116},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{6068413,
  author={Franklin, Michael J.},
  booktitle={2011 IEEE 12th International Conference on Mobile Data Management}, 
  title={Mobile Data Management - A Dozen Years Later}, 
  year={2011},
  volume={1},
  number={},
  pages={3-3},
  abstract={In 1999 I had the honor of presenting a Keynote talk entitled "Databases Unplugged: Challenges in Ubiquitous Data Management" at the inaugural MDM conference in Hong Kong. In that talk I spoke about the anticipated ubiquity of mobile devices and mobile applications and predicted some of the data management research challenges that could be foreseen from this sea change in the computational landscape. My views at the time were in sync with the influential Asilomar Report on Database Research [1], published in 1998, to which I contributed. The Asilomar report featured mobile devices as a "major driver" for the data management research agenda and predicted that "In ten years, billions of people will be using the Web, but a trillion "gizmos" will also be connected to the Web." Despite this optimism, The research agenda I described in my MDM talk [2] was driven in many ways by what I saw as the expected limitations of the mobile environment. Among these were: intermittent connectivity, poor battery life, and low-function user interfaces. Thus, my expectation was that technologies such as synchronization and conflict resolution, broadcast-based data dissemination, micro-kernel database systems and context-aware prefetching were technologies that would play a central role in making such devices usable as data management platforms. Rolling the clock forward twelve years, it appears that the Asilomar prediction of the number of connected devices was overly optimistic by about 3 orders of magnitude, and the technical limitations I was concerned about were substantially mitigated by tremendous innovation in mobile devices and mobile user interfaces as well as massive global investment in wireless infrastructure. On the other hand, we were both right about the huge impact of mobile computing on the way people acquire, interact with, and share information, and the fact that the ubiquity of such devices would have profound implications for data management. Undeterred by the paper trail outlined above, in this talk I plan to survey the state of the mobile data management field as it stands twelve years later. I'll review progress in areas such as sensor networks, integration with cloud computing, and location-based services. I'll also discuss what I see as a fundamental game changer brought about by mobile technology the closer integration of people into the entire data management lifecycle [3]. Social computing, crowd sourcing, and hyper-personalization are examples of ways in which the personalized nature of mobile devices is changing the way that we interact with information. I'll argue that such human-centric concerns will cause a rethinking of systems architectures and their components, and will require new ways of thinking about query processing, data quality and data-intensive applications. And if I get to do this again in 2023, we'll see how that turns out.},
  keywords={Mobile communication;Mobile handsets;Databases;Synchronization;Social network services;Awards activities;Educational institutions},
  doi={10.1109/MDM.2011.102},
  ISSN={2375-0324},
  month={June},}@INPROCEEDINGS{8612887,
  author={Halabi-Echeverry, Ana Ximena and Vergara-Silva, Juan Carlos and Karray, Mohamed Hedi},
  booktitle={2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Semantic Intelligence in a Seaport Context}, 
  year={2018},
  volume={},
  number={},
  pages={1-2},
  abstract={This research work proposes the framework for seaport partners to interact on a semantic level and scope related with jurisdictions/ecosystems and regions to share knowledge among partners. New steps towards dealing with the traditional common sense for managing or governing the seaport are required for assisting the new generation of managers and port authorities. Sematic intelligence answers dilemmas of complex realities and alignments of strategies such as which strategic position may have the seaport facing the growing number of international networks and international treaties. In Management and Computational Sciences, semantic intelligence has been discussed mostly from technological perspectives; however, a higher thinking intelligence for managing and govern the seaport surplus the classical intelligence approach found in literature.},
  keywords={Seaports;Semantics;Law;Couplings;Ecosystems;Standards;semantic intelligence;seaport context},
  doi={10.1109/AICCSA.2018.8612887},
  ISSN={2161-5330},
  month={Oct},}@INPROCEEDINGS{6867533,
  author={Fortson, Lucy and Lynn, Stuart},
  booktitle={2014 International Conference on Collaboration Technologies and Systems (CTS)}, 
  title={Talking in the Zooniverse: A collaborative tool for citizen scientists}, 
  year={2014},
  volume={},
  number={},
  pages={1-2},
  abstract={Researchers in fields as diverse as astrophysics, ecology and papyrology face a commom problem: as the size and complexity of digital datasets increases dramatically, new strategies in computational thinking are needed to transform data into knowledge, Virtual Citizen Science (VCS) a form of collaborative research involving the general public as volunteers in online reporting or analysis of data. [1], has proven to be one successful approach to solving this Big Data problem. In particular, the Zooniverse.org platform for citizen science has provided a unique crowdsourcing solution for these challenges across, a wide range of disciplines by harnessing the visual processing capabilities. of over a million volunteers and asking them to make observations. on data sets of complex objects presented in online interfaces.},
  keywords={Educational institutions;Collaboration;Astrophysics;Communities;Context;virtual citizen science;crowdsourcing;objecs-oriented discussion;serendipitous discovery},
  doi={10.1109/CTS.2014.6867533},
  ISSN={},
  month={May},}@INPROCEEDINGS{8939650,
  author={Hemberg, Erik and Biswas, Sagar and Bajwa, Ayesha and Law, Nancy and O’Reilly, Una-May},
  booktitle={2019 IEEE Learning With MOOCS (LWMOOCS)}, 
  title={Categorizing Resources and Learners for a Finer-Grained Analysis of MOOC Viewing & Doing}, 
  year={2019},
  volume={},
  number={},
  pages={116-121},
  abstract={We categorize MOOC resources with a learning design lens in order to investigate the relation between learning design and learner behavior in a computational thinking MOOC, MIT×6.00.1× Introduction to Computer Science and Programming Using Python. Videos are categorized by knowledge type (procedural, conceptual and factual), practice exercises are categorized by teaching intent, and problem sets and practice exercises are scored by difficulty. We consider video viewing and complete watching behavior, recap and review behavioral trajectories, and problem attempts. The analysis is cross-sectioned by learner prior level of experience. Our fine grained analyses, showing variation in learner behavior at a detailed level, provide instructors with a clearer picture of how specific learners interact with particular learning resources and achieve learning outcomes.},
  keywords={Videos;Electronic learning;Computer aided instruction;Lenses;Trajectory;Programming;Learning Design;Learning Analytics;MOOC},
  doi={10.1109/LWMOOCS47620.2019.8939650},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9238207,
  author={Benetti, Elisa and Mazzini, Gianluca},
  booktitle={2020 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Coding Training Proposal for Kindergarten}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Computational thinking in recent years has been universally defined as the ”new English”, or basic knowledge necessary for everyone. As English, is important to include it as early as possible in teaching programs, right from preschool. This need is so felt as to make it, for example, compulsory in kindergarten in Italy since 2022. Obviously, this implies the use of simple tools that do not provide reading and writing skills. This work proposes a learning program which could be carried out precisely during the three years of kindergarten, from 3 to 6 years of age, and prepares children for coding, a teaching subject that has already been proposed in Italy for primary school since a few years.},
  keywords={Training;Writing;Encoding;Software;Computer networks;Telecommunications;Proposals},
  doi={10.23919/SoftCOM50211.2020.9238207},
  ISSN={1847-358X},
  month={Sep.},}@INPROCEEDINGS{552698,
  author={Kosheleva, O. and Cabrera, S.D. and Gibson, G.A. and Koshelev, M.},
  booktitle={Proceedings of IEEE 5th International Fuzzy Systems}, 
  title={Fast implementations of fuzzy arithmetic operations using fast Fourier transform (FFT)}, 
  year={1996},
  volume={3},
  number={},
  pages={1958-1964 vol.3},
  abstract={In engineering applications of fuzzy logic, the main goal is not to simulate the way the experts really think, but to come up with a good engineering solution that would (ideally) be better than the expert's control. In such applications, it makes perfect sense to restrict ourselves to simplified approximate expressions for membership functions. If we need to perform arithmetic operations with the resulting fuzzy numbers, then we can use simple and fast algorithms that are known for operations with simple membership functions. In other applications, especially the ones that are related to humanities, simulating experts is one of the main goals. In such applications, we must use membership functions that capture every nuance of the expert's opinion; these functions an therefore complicated, and fuzzy arithmetic operations with the corresponding fuzzy numbers become a computational problem. In this paper, we design a new algorithm for performing such operations. This algorithm uses fast Fourier transforms (FFTs) to reduce computation time from O(n/sup 2/) to O(nlog(n)) (when n is the number of points x at which we know the membership functions /spl mu/(x)). To compute FFT even faster, we propose to use special hardware.},
  keywords={Data processing;Fuzzy logic;Humans;Fuzzy control;Digital arithmetic;Temperature control;Heat engines;Psychology;Decision making;Marine vehicles},
  doi={10.1109/FUZZY.1996.552698},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10476921,
  author={Bu, Yinyan and Rajamäki, Robin and Sarangi, Pulak and Pal, Piya},
  booktitle={2023 57th Asilomar Conference on Signals, Systems, and Computers}, 
  title={Harnessing Holes for Spatial Smoothing with Applications in Automotive Radar}, 
  year={2023},
  volume={},
  number={},
  pages={1308-1312},
  abstract={This paper studies spatial smoothing using sparse arrays in single-snapshot Direction of Arrival (DOA) estimation. We consider the application of automotive MIMO radar, which traditionally synthesizes a large uniform virtual array by appropriate waveform and physical array design. We explore deliberately introducing holes into this virtual array to leverage resolution gains provided by the increased aperture. The presence of these holes requires re-thinking DOA estimation, as conventional algorithms may no longer be easily applicable and alternative techniques, such as array interpolation, may be computationally expensive. Consequently, we study sparse array geometries that permit the direct application of spatial smoothing. We show that a sparse array geometry is amenable to spatial smoothing if it can be decomposed into the sum set of two subsets of suitable cardinality. Furthermore, we demonstrate that many such decompositions may exist-not all of them yielding equal identifiability or aperture. We derive necessary and sufficient conditions to guarantee identifiability of a given number of targets, which gives insight into choosing desirable decompositions for spatial smoothing. This provides uniform recovery guarantees and enables estimating DOAs at increased resolution and reduced computational complexity. 1},
  keywords={Geometry;Sufficient conditions;Smoothing methods;Direction-of-arrival estimation;Estimation;Apertures;Radar applications},
  doi={10.1109/IEEECONF59524.2023.10476921},
  ISSN={2576-2303},
  month={Oct},}@INPROCEEDINGS{5568730,
  author={Siming Wang and Yingli Fan},
  booktitle={2010 The 2nd Conference on Environmental Science and Information Application Technology}, 
  title={A vision location algorithm for CCD camera based on geometric knowledge}, 
  year={2010},
  volume={1},
  number={},
  pages={430-433},
  abstract={In this paper, a simple and practical new algorithm was proposed to solve the monocular vision-based camera positioning of spatial objects as well as the alternating invariance principle based on projective geometry. The new algorithm avoids the cumbersome camera calibration and the accurate solution of matrix equations. It solves the non-linear single-mapping of single chart taken by non-standard orders CCD camera from the 2D image plane to the true 3D planar according to a simple geometrical relationship. It also revises the lens to reach the high accuracy and the low computational. The experimental result shows that this new algorithm has a high availability in several cases, and it provides a new way of thinking for the measurement, positioning as well as three-dimensional reconstruction of the computer vision problems.},
  keywords={Optical imaging;camera spatial orientation;geometric knowledge;the cross-ratio invariance;computer vision},
  doi={10.1109/ESIAT.2010.5568730},
  ISSN={},
  month={July},}@ARTICLE{6362366,
  author={Boroni, G. and Clausse, A. and D'Amato, J. P. and Bauza, C. G.},
  journal={IEEE Latin America Transactions}, 
  title={Thermal insulation in houses and sheds}, 
  year={2012},
  volume={10},
  number={5},
  pages={2195-2201},
  abstract={Thermal insulation is usually needed for large buildings because of the requirement to comply with quality standards while for residential houses usually the builders suggest some kind of insulation. in general, the users do not know the subject and think that both heating and cooling of rooms is solved using air conditioning systems. Moreover, most people do not know how to reduce electricity bills, gas, etc. and they spend large amounts of money because they believe that is the price to pay for these services. In this paper is presented a computational tool to analyze the influence of thermal insulation on heat transfer by conduction through the roof of a certain room. The application displays the advantages of installing thermal insulation in different weather conditions in various regions of Argentina, and provides economic arguments for design and evaluation of each work.},
  keywords={Artificial intelligence;Thermal management;Insulation;Biological system modeling;Human computer interaction;Decision support systems;Energy conservation;Insulation thermal factors},
  doi={10.1109/TLA.2012.6362366},
  ISSN={1548-0992},
  month={Sep.},}@INPROCEEDINGS{8190711,
  author={Mishra, Sumita and Raj, Rajendra K. and Tymann, Paul and Fagan, Jamie and Miller, Sage},
  booktitle={2017 IEEE Frontiers in Education Conference (FIE)}, 
  title={CyberCSP: Integrating cybersecurity into the computer science principles course}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={The demand for cybersecurity professionals is projected to grow substantially, with the US Bureau of Labor Statistics reporting that employment in cybersecurity within the US will grow by 18% from 2014 to 2024, much faster than the average for all occupations. As creating a cyberspace workforce has become a matter of national security for every country, cybersecurity needs to be taught at all levels, to all students, in the educational system. The good news is that cybersecurity is also a topic that students from a wide variety of backgrounds find interesting, and as a result, it motivates them to study computing too. Over the past two decades, there has been an increased effort worldwide to incorporate computer science and computational thinking into the middle and high school curriculum. The CS10K initiative in the US has led to projects to introduce computer science at the K-12 educational level. One of these initiatives, the new Advanced Placement (AP) course in Computer Science Principles (CSP), was designed to introduce computer science in an engaging way, show students how computing is relevant in their lives, and to attract a diverse group of students to computing. The CSP Curriculum Framework allows for multiple implementations of the CSP course, permitting course designers to develop courses to engage and attract specific groups of students and that focus on specific themes in computing. This paper describes an approach to develop a new CSP course, CyberCSP, which integrates cybersecurity first principles throughout the course. The approach builds on an CSP course that was created from a previous collaboration between the Computer Science Department at Rochester Institute of Technology, Rochester, New York, and the Webster Central School District in Webster, New York. The paper discusses the background, details of the earlier CSP course, how relevant cybersecurity content was identified, and then integrated into the CSP course to create the CyberCSP variant of the Computer Science Principles course.},
  keywords={Computer science;Collaboration;Employment;Computer crime},
  doi={10.1109/FIE.2017.8190711},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9962741,
  author={Agarwal, Jutshi and Piatt, Emily and Imbrie, P. K.},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Team formation in engineering classrooms using multi-criteria optimization with genetic algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The research-to-practice paper presents applications of genetic algorithms using multi-criterion optimization to designate student-teams in an academic setting. Teamwork skills are becoming a more desirable trait in industry today and hence more instructors are using teamwork in their engineering courses. ABET also requires engineering degree programs to have student outcomes that provide them with "an ability to function effectively on a team whose members together provide leadership, create a collaborative and inclusive environment, establish goals, plan tasks, and meet objectives." This, however, comes with its challenges because the literature suggests that random or student-selected teams tend to lead to dysfunctional behaviors. Instructor-designated academic teams based on skills, learning personalities, and demographics are known to be more effective in promoting learning and positive interactions. Creating optimal homogeneous or heterogeneous teams based on multiple criteria (e.g., prior knowledge, skills, abilities, psychosocial, demographics) can be a complex and time-consuming task when done manually, especially when large numbers of students are involved.This study presents an expansion of previous work that used single-criterion genetic algorithm optimization of teams in a first-year classroom. The research question answered in this study is, how do teams formed using an algorithm that optimizes multiple criteria with genetic algorithms represent heterogeneity when compared to teams formed manually? Using a Vector Evaluated Genetic Algorithm (VEGA), optimization of multiple skills is conducted to attain uniform heterogeneity in the classroom. The algorithm uses discrete integer-type representations as a basic unit of team configuration. Self-reported student competency data on three different computational skills were used. Teams were formed for approximately 1300 students enrolled in a first-year engineering design thinking course at a large Midwestern University. Four-member teams were maximized with a minimum number of teams with 3 students in each section. Average skills of the teams are calculated and the standard deviation in class is minimized for each of three skills parallelly. The algorithm also aims to maintain diversity of teams based on gender and ethnicity.Results presented include visualization of team-configurations and comparison with teams formed manually using the same criteria. The aim of the algorithm is to optimize students into teams that have skills and demographics uniformly distributed across the classroom. Future implications of this study include the potential to use flexible algorithm-based team formations that are built with standard genetic operators so that optimization criteria can be modified by the instructor. Such algorithms can reduce the time needed to manually form teams by a considerable amount and optimize the distribution of skills more uniformly. Steps to further this study will involve investigating whether teams formed using these criteria are more effective.},
  keywords={Industries;Leadership;Genetics;Question answering (information retrieval);Teamwork;Behavioral sciences;Task analysis;genetic algorithm;multi-criteria optimization;team formation},
  doi={10.1109/FIE56618.2022.9962741},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{6182548,
  author={Yonghu Chang and Feng Liu},
  booktitle={Proceedings of 2011 International Conference on Computer Science and Network Technology}, 
  title={Wireless sensor intrusion detection system based on the theory of evidence}, 
  year={2011},
  volume={4},
  number={},
  pages={2811-2814},
  abstract={According to the feature that normal data and abnormal data in wireless sensor networks have no significant difference, this paper proposes intrusion detection model based on D-S evidence theory. Intrusion detection model views the standard deviation between data flow and historical data of each sensor as intrusion detection feature value, and then all these values treated as a group of data will be clustered. At last, the model fuses the clustering results by using D-S evidence theory to obtain a comprehensive assessment result, which can reflect the security of the sensor. The way of this algorithm to recognize the target is similar to human thinking, with high reliability, and has obvious advantages on computational complexity.},
  keywords={Communication system security;Wireless communication;Hardware;Wireless sensor networks;Educational institutions;IDS;Wireless sensor network;evidence theory;BPN},
  doi={10.1109/ICCSNT.2011.6182548},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9323777,
  author={Chaabane, Ferdaous and Réjichi, Safa and Tupin, Florence},
  booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Comparison Between Multitemporal Graph Based Classical Learning and LSTM Model Classifications for Sits Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={144-147},
  abstract={Very High Resolution (VHR) multispectral Satellite Image Time Series (SITS) enables the production of temporal land cover maps, thanks to high spatial, temporal and spectral resolution of modern earth observation programs. Besides, statistical learning methods applied to SITS monitoring and analysis have created relatively efficient semi-automatic classification techniques. It would therefore be natural to think that the use of deep learning methods on SITS would lead to advances comparable to those known in the field of computer vision. However, when applied to concrete cases, the results are not as convincing. This paper proposes a comparison between a SOTAG (Spatial-Object Temporal Adjacency Graphs) SVM based spatio-temporal classification approach and the Recurrent Neuronal Network (RNN), LSTM (Long Short-Term Memory) model which is trained by historical SITS. The trained LSTM networks are then used to predict new time series data. Both methods perform a spatio-temporal map indicating the temporal profiles of cartographic regions. The proposed approaches will be applied on real and simulated SITS data. We will demonstrate that both results are comparable despite computational times and algorithms complexity.},
  keywords={Support vector machines;Remote sensing;Deep learning;Monitoring;Indexes;Image color analysis;Classification algorithms;SITS analysis;temporal profiles classification;Graph based SVM classification;RNN;LSTM model etc.},
  doi={10.1109/IGARSS39084.2020.9323777},
  ISSN={2153-7003},
  month={Sep.},}@INPROCEEDINGS{6860891,
  author={Thomas, Gabriel and Annamalai, Manickavasagan},
  booktitle={2014 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings}, 
  title={Texture analysis using income inequality metrics}, 
  year={2014},
  volume={},
  number={},
  pages={988-992},
  abstract={Texture analysis on digital images can be used to correctly segment areas of an image and/or classify different objects within the field of view of a digital camera. Depending on the application, one can use a Gray Level Co-occurrence Matrix (GLCM) to detect patterns or a simple contrast measure such as variance can be a good metric as well. In this work, our main objective is to define a set of new texture metrics simple enough to be computationally efficient so that fast processing is feasible. Thus in our previous two texture techniques mentioned before, GLCM and variance, metrics such as variance would be selected for comparison purposes as they require less computational time. Thinking outside the box, we would like to introduce the use of income inequality metrics used in the field of economy to measure the distribution of income and wealth inequality within a population. We found that these metrics can be used on texture analysis of digital images.},
  keywords={Measurement;Indexes;Training;Sociology;Statistics;Computer vision;Computers;texture analysis;Gini index;Theil index;Atkinson Index;entropy;income inequality metrics},
  doi={10.1109/I2MTC.2014.6860891},
  ISSN={1091-5281},
  month={May},}@ARTICLE{4302680,
  author={Shum, Simon Buckingham},
  journal={IEEE Software}, 
  title={There's Nothing Like a Good Argument ...}, 
  year={2007},
  volume={24},
  number={5},
  pages={21-23},
  abstract={Since computing pioneers Vannevar Bush and Doug Engelbart envisioned computational support for argumentation, many have pursued the exciting vision of tools for capturing and augmenting collective reasoning. Designers would be able to capture their deliberations on the fly during design sessions, with intuitive visualizations assisting participatory analysis by diverse stakeholders. These traces would later help recover design rationale. When managing requirements, we can think of argument schemes as reusable patterns for tightening up deliberations. Project reviews are an obvious candidate, where decisions must be justified, often to be signed off, and resources committed. As meeting capture becomes a practical reality, we have the basis for requirements platforms that provide new forms of multimedia requirements and rationale traceability.},
  keywords={Indexing;Engineering management;Software engineering;Software testing;System testing;Design engineering;Knowledge engineering;Software libraries;Software tools;Real time systems;software requirements;argument schemes;concept mapping;tools},
  doi={10.1109/MS.2007.148},
  ISSN={1937-4194},
  month={Sep.},}@INPROCEEDINGS{5692316,
  author={Soria-Alcaraz, Jorge A. and Santigo-Montero, Raúl, and Carpio, Martín},
  booktitle={2010 IEEE Electronics, Robotics and Automotive Mechanics Conference}, 
  title={One Criterion for the Selection of the Cardinality of Learning Set Used by the Associative Pattern Classifier}, 
  year={2010},
  volume={},
  number={},
  pages={80-84},
  abstract={The Associative Pattern Classifier (CAP) is a novel approach to solve the pattern classification problem. Recent experiments of the behavior of this classifier in different applications have given encouraging results. Due a this evidence, It has been thinking about the existence of a minimum number for which a higher value of samples used in the learning phase of this classifier brings a very low effect over their classification performance. This paper present an empiric way to obtain this minimum number based in the structure of the used database. this method allows us to define a minimum size for the set used in the learning phase of CAP for which the final classification performance will be reasonably stable, optimizing time and computational resources in the process.},
  keywords={Databases;Glass;Lenses;Training;Vectors;Support vector machine classification;Associative memory;CAP;Learning phase;Pattern Classification problem;Pattern Recognition},
  doi={10.1109/CERMA.2010.20},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8470577,
  author={Darrah, Timothy and Hutchins, Nicole and Biswas, Gautam},
  booktitle={ISR 2018; 50th International Symposium on Robotics}, 
  title={Design and Development of a Low-Cost Open-Source Robotics Education Platform}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={The impact of robotics has grown beyond research laboratories and industrial facilities into home environments and primary and secondary school classrooms. Of particular interest to us are robots for education. In general, educational robotics kits are expensive and proprietary, or cheap and unreliable. This research seeks to bridge that gap by providing a hands on open-source robotics learning environment that is both inexpensive and reliable. In this paper, we review the applicability of such environments to support the synergistic learning of computational thinking (CT) and STEM, with an emphasis on Computer Science (CS) concepts and practices. The CT and Advanced Placement CS Principles frameworks (from the US) govern the design and implementation of our system. We discuss the hardware system of the robot and the accompanying software architecture that runs on Linux-based single board computers. We conclude with results from a small pilot study analyzing the usability and curricular effectiveness of the system.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}@INPROCEEDINGS{773593,
  author={Yhao Yongping and Huang Fang and Guo Jingjun},
  booktitle={IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293)}, 
  title={Desertification research based on digital Earth}, 
  year={1999},
  volume={1},
  number={},
  pages={646-648 vol.1},
  abstract={Digital Earth is the trend for geospatial research, it will help effective and efficient sharing of spatial data all over the world. In this paper, the authors through analyzing the developing background and trend of information society, think that with the development of global spatial information infrastructure, the technologies needed for digital Earth such as computational science, satellite imagery, and metadata etc. have matured. So it is the time to do some experimental application research based on digital Earth. Desertification is a key reason to influence environment change, it is a spatial related globalization problem. Now with the development of remote sensing, geographic information system, and network technology, people have with the probability to deal with mass desertification data through Internet, and the direction of it is to connect with digital Earth. So the author selected Horqin desertification area as an experimental region with the technology support of them and got an good result. According to the dynamic research, for the people's activity, the desertification in the area developed fast from 1950s to 1970s, and more fast than before from 1970s to 1990s. If detracted the people's bad factor to the area or by the help of them, the ecological environment would be recovered again. The research result is gotten by commuter rather than go to investigation in the place, so the method will have an important meaning for the general improvement and the ecological environment recovering of Horqin sandy area, it also has a good role for making decision by the support of digital Earth technology for government.},
  keywords={Earth;Image analysis;Information analysis;Geoscience;Satellites;Globalization;Remote sensing;Geographic Information Systems;IP networks;Government},
  doi={10.1109/IGARSS.1999.773593},
  ISSN={},
  month={June},}@INPROCEEDINGS{8456081,
  author={Jäger, Markus and Nadschläger, Stefan and Küng, Josef},
  booktitle={2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)}, 
  title={Concepts for Trust Propagation in Knowledge Processing Systems - A Brief Introduction and Overview}, 
  year={2018},
  volume={},
  number={},
  pages={1502-1505},
  abstract={What is "Trust"? Everybody has a sense of trusting people or institutions, but how is trust defined? The definition of trust always depends on the specific field of research and application, which makes it hard to answer this question in general at a computational level. Thinking of knowledge processing systems we face this question twice. How can we define and calculate trust values for the input data and, more challenging, what is the trust value of the output? Within this paper we consider a binary, a probabilistic, an opinion-space and - our recently developed approach - a weighted arithmetic mean trust model. Then we show ways, how knowledge processing systems can handle these trust values and propagate them through a network of processing steps in a way that the final results are representative. With these presented and developed models, we can give insights to the topic of defining and propagating trust in knowledge processing systems.},
  keywords={Probabilistic logic;Knowledge engineering;Semantic Web;Cognition;Uncertainty;Conferences;Measurement;Trust;Propagation;Knowledge Processing Systems;Trust Metrics;Trust Models;Precision},
  doi={10.1109/TrustCom/BigDataSE.2018.00212},
  ISSN={2324-9013},
  month={Aug},}@INPROCEEDINGS{4663749,
  author={Reed, Daniel A.},
  booktitle={2008 IEEE International Conference on Cluster Computing}, 
  title={Clouds, clusters and ManyCore: The revolution ahead}, 
  year={2008},
  volume={},
  number={},
  pages={1-1},
  abstract={Without doubt, scientific discovery, business practice and social interactions are moving rapidly from a world of homogeneous and local systems to a world of distributed software, virtual organizations and cloud computing infrastructure, all powered by multicore processors and large-scale infrastructure. In science, a tsunami of new experimental and computational data and a suite of increasingly ubiquitous sensors pose vexing problems in data analysis, transport, visualization and collaboration. In society and business, software as a service and cloud computing are empowering distributed groups. Letpsilas step back and think about the longer term future. Where is the technology going and what are the implications? What architectures are appropriate? How to we manage power and scale? What are the right size building blocks? How do we come to grips with the fact that our clusters and data centers are now bigger than the Internet was just a few years ago? How do we develop and support malleable software? What is the ecosystem of components in which distributed, data rich applications will operate? How do we optimize performance and reliability? How do we program these systems?},
  keywords={},
  doi={10.1109/CLUSTR.2008.4663749},
  ISSN={2168-9253},
  month={Sep.},}@INBOOK{10183895,
  author={Paulo, Sergio Rufino Henrique and Ramjee, Prasad},
  booktitle={6G Visions for a Sustainable and People-centric Future: From Communications to Services, the CONASENSE Perspective}, 
  title={2 CONASENSE, Challenges, and Use Cases Beyond 2030}, 
  year={2023},
  volume={},
  number={},
  pages={5-14},
  abstract={6G is currently under definition, often being addressed from a plain telecommunications perspective as an evolutionary paradigm that represents an extension of 5G. Having as its horizon 2030, 6G initiatives are being deployed across the globe, to further ignite the development of 6G services. In its philosophy core, 6G embodies the &#x201C;human in the loop&#x201D; principle. The research effort aimed at 6G requires an interdisciplinary approach that ignites discussion across different key technological sectors, ranging from communications to services and business cases. The contribution of this book to research in the field concerns an evolutionary and interdisciplinary design of 6G as a paradigm that can be addressed by working together the four different computational areas of CONASENSE: communications; satellites and navigation; sensing; services. This book starts with a perspective on 6G challenges towards sustainability and addressing new business models, moving on to key topics concerning communications. It ends with chapters focusing on 6G service design. This book is, therefore, envisioned to assist in developing critical thinking to back up novel networking, applications, and services towards 6G.},
  keywords={},
  doi={},
  ISSN={},
  publisher={River Publishers},
  isbn={9788770227506},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10183895},}@INPROCEEDINGS{10372895,
  author={Chung, Victor and Bravo, Jessie and Heredia, Armando Moreno and Alarcón, Roger},
  booktitle={2023 IEEE 3rd International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={Digital Competence of Mathematics teachers based on DigCompEdu in Regular Basic Education in the Lambayeque region}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The current study aimed to assess the digital competence level among 41 mathematics teachers from the regular basic education sector in the public domain of the Lambayeque region. Utilizing the European Framework for the Digital Competence of Educators (DigCompEdu), key areas such as Professional Engagement, Teaching and Learning, and Open Education were scrutinized. Findings indicated a competent level in Professional Engagement, yet they revealed that teachers are still at initial stages regarding the integration of digital tools in teaching and the use of open educational resources. Although variables like gender, age, and academic background showed no significant differences, it was noted that both the technological infrastructure of institutions and support for professional development positively impact digital competences. This underlines the importance of reinforcing educational policies related to training and digital resources to promote a substantial improvement in mathematics teaching, as a key factor for the development of students’ critical and computational thinking.},
  keywords={Training;Education;Europe;Open Educational Resources;Market research;Mathematics;digital competencies;teacher;DigCompEdu;mathematics;regular basic education},
  doi={10.1109/ICALTER61411.2023.10372895},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{736857,
  author={Leon de la Barra, G.E. and Leon de la Barra, M.B. and Urbina, A.M.},
  booktitle={FIE '98. 28th Annual Frontiers in Education Conference. Moving from 'Teacher-Centered' to 'Learner-Centered' Education. Conference Proceedings (Cat. No.98CH36214)}, 
  title={Real and virtual workshops in mathematics [engineering education]}, 
  year={1998},
  volume={1},
  number={},
  pages={319-321 vol.1},
  abstract={It is well known that many engineering students, mainly freshmen have a lack of teamwork and effective communication skills. It is also apparent that the amazing development of multimedia computer software and communication technologies have made more evident those weaknesses and, at the same time, have shown that many freshman students need to be trained, in order to use more efficiently the computational technology. In order to overcome these weaknesses, the authors have designed a long-term program in mathematics organized in stages and oriented to freshman engineering and architecture students. In the first stage, they ran two workshops incorporated to the regular first year maths course of engineering and architecture and developed in the classroom. In both workshops, they used cooperative learning techniques and divergent thinking methods. They also have developed a new assessment scheme to evaluate the students' performance. In the second stage they have offered a special course in mathematics for freshman architecture students that combines a traditional lecture format with "hands on" student's activities, i.e., by using multimedia resources and Internet tools as instructional media.},
  keywords={Engineering education},
  doi={10.1109/FIE.1998.736857},
  ISSN={0190-5848},
  month={Nov},}@INPROCEEDINGS{5203821,
  author={Ferrin, Giovanni and Snidaro, Lauro and Foresti, Gian Luca},
  booktitle={2009 12th International Conference on Information Fusion}, 
  title={Structuring relations for fusion in intelligence}, 
  year={2009},
  volume={},
  number={},
  pages={1621-1626},
  abstract={Humans daily infer causal structure from patterns of correlation and learn about categories and hidden properties of objects based on experience and knowledge. A Bayesian approach seems to best model human reasoning over structures, relations and links, and it is possible to provide a detailed computational account of how a number of basic structural forms can be inferred from various types of data (feature sets, similarity matrices, relations). In the literature some algorithms have been proposed that generate candidate model structures from graph grammars, compute the probability of the data given each candidate model, and identify the model with maximum posterior probability given the data. The structural representation, being generated by algorithms comparable to human thinking (according to the cognitive sciences community) should be also easily understandable and usable by analysts for further investigation.},
  keywords={Intelligent structures;Humans;Intelligent sensors;Bayesian methods;Logic;Mathematics;Computer science;Fusion power generation;Inference algorithms;Algorithm design and analysis;Hard soft data fusion;Defense and intelligence;Probability Theory;Bayesian inference},
  doi={},
  ISSN={},
  month={July},}
